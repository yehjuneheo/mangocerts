[
    {
        "Question Number": "1",
        "Situation": "Une entreprise de commerce électronique connaît des pics saisonniers de trafic sur son site web pendant les ventes de vacances. Pour garantir une haute disponibilité et distribuer efficacement le trafic entrant, l'entreprise souhaite mettre en œuvre une solution d'équilibrage de charge capable de router les demandes en fonction du contenu des requêtes.",
        "Question": "Quelle solution d'équilibrage de charge AWS le concepteur de solutions devrait-il recommander ?",
        "Options": {
            "1": "Classic Load Balancer configuré avec un routage en round-robin",
            "2": "Network Load Balancer avec des adresses IP statiques",
            "3": "Application Load Balancer avec des règles de routage basées sur le chemin",
            "4": "AWS Global Accelerator avec un routage basé sur DNS"
        },
        "Correct Answer": "Application Load Balancer avec des règles de routage basées sur le chemin",
        "Explanation": "L'Application Load Balancer (ALB) est conçu pour gérer le trafic HTTP et HTTPS et peut router les demandes en fonction du contenu des requêtes, telles que les chemins d'URL ou les en-têtes d'hôte. Cela le rend idéal pour une entreprise de commerce électronique qui doit distribuer efficacement le trafic pendant les pics saisonniers et router les demandes vers différents services en fonction du contenu. Le routage basé sur le chemin permet à l'ALB de diriger le trafic vers des services backend spécifiques en fonction du chemin d'URL, ce qui est particulièrement utile pour une application avec plusieurs services ou microservices.",
        "Other Options": [
            "Le Classic Load Balancer est une option héritée qui ne prend pas en charge le routage basé sur le contenu. Il utilise principalement un routage en round-robin ou des sessions persistantes, ce qui est moins flexible pour les applications nécessitant un routage basé sur le contenu des requêtes.",
            "Le Network Load Balancer est optimisé pour gérer le trafic TCP et est capable de traiter des millions de requêtes par seconde tout en maintenant des latences ultra-basses. Cependant, il ne prend pas en charge le routage basé sur le contenu, ce qui est une exigence dans ce scénario.",
            "AWS Global Accelerator est conçu pour améliorer la disponibilité et les performances des applications avec des utilisateurs mondiaux en dirigeant le trafic vers des points de terminaison optimaux en fonction de la santé, de la géographie et des politiques de routage. Cependant, il ne fournit pas de capacités de routage basé sur le contenu, ce qui le rend inadapté à la nécessité spécifique de router les demandes en fonction de leur contenu."
        ]
    },
    {
        "Question Number": "2",
        "Situation": "Une entreprise souhaite sécuriser ses données sur des volumes Amazon EBS attachés à des instances EC2, en s'assurant que les données restent chiffrées au repos. Ils prévoient également de prendre des instantanés de ces volumes à des fins de sauvegarde.",
        "Question": "Laquelle des options suivantes décrit correctement le fonctionnement du chiffrement EBS pour ce cas d'utilisation ? (Choisissez deux.)",
        "Options": {
            "1": "Les volumes EBS ne peuvent être chiffrés que s'ils sont attachés à des instances dédiées, et le chiffrement doit être appliqué manuellement à chaque instantané pris.",
            "2": "Chaque volume EBS utilise une clé de chiffrement de données unique (DEK) générée par AWS KMS, et tous les instantanés et futurs volumes créés à partir de ces instantanés utiliseront la même DEK.",
            "3": "Le chiffrement EBS repose uniquement sur le chiffrement au niveau de l'instance et ne nécessite pas d'intégration KMS, rendant le chiffrement transparent pour le volume.",
            "4": "Activer le chiffrement par défaut pour tous les volumes EBS en utilisant des clés gérées par AWS KMS, garantissant que tous les instantanés existants et nouveaux sont automatiquement chiffrés.",
            "5": "Le chiffrement EBS ne chiffre que les instantanés, pas les données du volume actif stockées au repos sur les instances EC2."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Chaque volume EBS utilise une clé de chiffrement de données unique (DEK) générée par AWS KMS, et tous les instantanés et futurs volumes créés à partir de ces instantanés utiliseront la même DEK.",
            "Activer le chiffrement par défaut pour tous les volumes EBS en utilisant des clés gérées par AWS KMS, garantissant que tous les instantanés existants et nouveaux sont automatiquement chiffrés."
        ],
        "Explanation": "Chaque volume EBS utilise une clé de chiffrement de données unique (DEK) générée par AWS KMS. Cette DEK est utilisée pour chiffrer le volume, et tous les instantanés pris à partir du volume, ainsi que tous les futurs volumes créés à partir de ces instantanés, utiliseront également la même DEK. Cela garantit que les données restent chiffrées au repos. De plus, AWS vous permet d'activer le chiffrement par défaut pour tous les volumes EBS en utilisant des clés gérées par AWS KMS. Cela garantit que tous les instantanés existants et nouveaux sont automatiquement chiffrés, offrant une couche de sécurité supplémentaire.",
        "Other Options": [
            "Les volumes EBS ne peuvent être chiffrés que s'ils sont attachés à des instances dédiées, et le chiffrement doit être appliqué manuellement à chaque instantané pris. Cela est incorrect car le chiffrement EBS n'est pas limité aux instances dédiées, et les instantanés pris à partir de volumes chiffrés sont automatiquement chiffrés.",
            "Le chiffrement EBS repose uniquement sur le chiffrement au niveau de l'instance et ne nécessite pas d'intégration KMS, rendant le chiffrement transparent pour le volume. Cela est incorrect car le chiffrement EBS nécessite une intégration avec AWS KMS pour générer et gérer les clés de chiffrement.",
            "Le chiffrement EBS ne chiffre que les instantanés, pas les données du volume actif stockées au repos sur les instances EC2. Cela est incorrect car le chiffrement EBS chiffre à la fois les données du volume actif et les instantanés."
        ]
    },
    {
        "Question Number": "3",
        "Situation": "Une entreprise de jeux vidéo mondiale lance un nouveau jeu en ligne multijoueur qui attire des joueurs du monde entier. L'entreprise souhaite garantir une latence minimale et une expérience de jeu fluide pour tous les joueurs, quelle que soit leur localisation géographique. De plus, elle vise à protéger ses serveurs de jeu contre les attaques DDoS.",
        "Question": "Quels services AWS le concepteur de solutions devrait-il recommander pour optimiser la livraison de contenu et améliorer la sécurité à la périphérie ? (Choisissez deux.)",
        "Options": {
            "1": "Amazon CloudFront avec AWS Shield Advanced",
            "2": "AWS Global Accelerator avec Amazon Route 53",
            "3": "AWS Direct Connect avec AWS WAF",
            "4": "Amazon ElastiCache avec AWS Firewall Manager",
            "5": "AWS Global Accelerator avec AWS Shield Advanced"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon CloudFront avec AWS Shield Advanced",
            "AWS Global Accelerator avec AWS Shield Advanced"
        ],
        "Explanation": "Amazon CloudFront avec AWS Shield Advanced et AWS Global Accelerator avec AWS Shield Advanced sont les bonnes réponses. Amazon CloudFront est un réseau de distribution de contenu (CDN) qui livre des données, des vidéos, des applications et des API à des clients du monde entier avec une faible latence et des vitesses de transfert élevées. AWS Shield Advanced fournit une protection DDoS rentable pour les ressources fonctionnant sur AWS, ce qui est crucial pour l'entreprise de jeux afin de protéger ses serveurs contre les attaques DDoS. AWS Global Accelerator est un service de mise en réseau qui envoie le trafic de vos utilisateurs à travers l'infrastructure réseau mondiale d'Amazon Web Services, améliorant les performances de vos utilisateurs Internet jusqu'à 60 %. Lorsqu'il est combiné avec AWS Shield Advanced, il améliore non seulement les performances mais fournit également une protection DDoS.",
        "Other Options": [
            "AWS Global Accelerator avec Amazon Route 53 n'est pas une solution complète. Bien qu'AWS Global Accelerator améliore la disponibilité et les performances des applications, Amazon Route 53 est un service web de système de noms de domaine (DNS) évolutif mais ne fournit pas de protection DDoS.",
            "AWS Direct Connect avec AWS WAF n'est pas la meilleure solution. AWS Direct Connect est une solution de service cloud qui facilite l'établissement d'une connexion réseau dédiée de vos locaux à AWS, et AWS WAF est un pare-feu d'application web qui aide à protéger vos applications web contre les exploits web courants, mais aucun de ces services n'optimise la livraison de contenu ou ne fournit une protection DDoS à la périphérie.",
            "Amazon ElastiCache avec AWS Firewall Manager n'est pas la solution correcte. Amazon ElastiCache est un service web qui facilite le déploiement, l'exploitation et la mise à l'échelle d'un cache en mémoire dans le cloud, et AWS Firewall Manager est un service de gestion de la sécurité qui vous permet de configurer et de gérer centralement les règles de pare-feu à travers vos comptes et applications dans AWS Organization. Cependant, aucun de ces services n'optimise la livraison de contenu ou ne fournit une protection DDoS à la périphérie."
        ]
    },
    {
        "Question Number": "4",
        "Situation": "Une entreprise de vente au détail souhaite mettre en place un système de surveillance où des actions spécifiques sont déclenchées automatiquement lorsque certains événements se produisent dans leur environnement AWS. Par exemple, si une instance EC2 change d'état de \"arrêtée\" à \"en cours d'exécution\", une fonction Lambda devrait être déclenchée pour enregistrer cette activité. Ils souhaitent également planifier des tâches périodiques, telles que des sauvegardes nocturnes, en utilisant le même service.",
        "Question": "Quelle configuration de service AWS répondrait le mieux à ces exigences ?",
        "Options": {
            "1": "Amazon CloudWatch Logs avec des requêtes planifiées",
            "2": "AWS Lambda avec des paramètres d'invocation périodiques",
            "3": "Amazon EventBridge avec des règles de modèle d'événements et des règles de planification",
            "4": "AWS Step Functions avec des modèles de réessai"
        },
        "Correct Answer": "Amazon EventBridge avec des règles de modèle d'événements et des règles de planification",
        "Explanation": "Amazon EventBridge est conçu pour faciliter les architectures basées sur les événements et peut réagir aux changements d'état dans les ressources AWS, telles que les instances EC2. Il vous permet de créer des modèles d'événements qui déclenchent des actions (comme invoquer une fonction Lambda) lorsque des événements spécifiques se produisent, comme un changement d'état d'une instance EC2. De plus, EventBridge prend en charge les événements planifiés, vous permettant de configurer des tâches périodiques comme des sauvegardes nocturnes. Cela en fait la meilleure option pour les exigences décrites dans le scénario.",
        "Other Options": [
            "Amazon CloudWatch Logs avec des requêtes planifiées est principalement utilisé pour la journalisation et l'interrogation des données de journal. Bien qu'il puisse aider à surveiller les journaux, il ne fournit pas intrinsèquement la capacité de déclencher des actions basées sur des événements ou de planifier des tâches directement.",
            "AWS Lambda avec des paramètres d'invocation périodiques peut exécuter des fonctions selon un calendrier, mais il ne gère pas nativement les déclencheurs basés sur les événements en fonction des changements d'état des ressources. Il nécessiterait une configuration supplémentaire pour surveiller les changements d'état des EC2.",
            "AWS Step Functions est un service pour orchestrer des flux de travail complexes et gérer l'état à travers plusieurs services. Bien qu'il puisse gérer des réessais et gérer des flux de travail, il n'est pas spécifiquement conçu pour des déclencheurs basés sur des événements ou pour planifier des tâches directement, ce qui le rend moins adapté aux exigences énoncées."
        ]
    },
    {
        "Question Number": "5",
        "Situation": "Une application web doit gérer des charges de trafic fluctuantes, et l'entreprise souhaite utiliser une stratégie d'équilibrage de charge qui minimise les coûts tout en distribuant efficacement le trafic entre les instances. Ils souhaitent également optimiser les coûts en utilisant l'équilibrage de charge de couche 7 (couche applicative).",
        "Question": "Quelle option d'équilibrage de charge serait la plus rentable pour cette exigence ?",
        "Options": {
            "1": "Utiliser un Classic Load Balancer avec une mise à l'échelle manuelle",
            "2": "Déployer un Application Load Balancer (ALB) avec la mise à l'échelle automatique activée",
            "3": "Utiliser un Network Load Balancer (NLB) pour gérer le trafic HTTP/HTTPS",
            "4": "Déployer des équilibreurs de charge individuels pour chaque zone de disponibilité"
        },
        "Correct Answer": "Déployer un Application Load Balancer (ALB) avec la mise à l'échelle automatique activée",
        "Explanation": "Un Application Load Balancer (ALB) est spécifiquement conçu pour gérer le trafic HTTP et HTTPS à la couche 7, ce qui permet un routage avancé et une gestion du trafic en fonction du contenu des requêtes. En activant la mise à l'échelle automatique, l'application peut ajuster automatiquement le nombre d'instances en fonction de la charge de trafic actuelle, garantissant une utilisation efficace des ressources et une rentabilité. Cette combinaison permet à l'entreprise de distribuer efficacement le trafic tout en minimisant les coûts associés à la surprovisionnement des ressources.",
        "Other Options": [
            "Utiliser un Classic Load Balancer avec une mise à l'échelle manuelle n'est pas rentable car cela nécessite une intervention manuelle pour ajuster le nombre d'instances en fonction de la charge de trafic, ce qui peut entraîner soit une sous-utilisation, soit une sur-utilisation des ressources, augmentant ainsi les coûts.",
            "Utiliser un Network Load Balancer (NLB) n'est pas adapté pour le trafic HTTP/HTTPS car il fonctionne à la couche 4 et ne fournit pas les capacités de routage avancées qu'un ALB offre. De plus, les NLB sont généralement plus coûteux et n'optimisent pas les coûts aussi efficacement pour les applications web.",
            "Déployer des équilibreurs de charge individuels pour chaque zone de disponibilité est inefficace et coûteux. Cette approche nécessiterait de maintenir plusieurs équilibreurs de charge, entraînant une augmentation des frais d'exploitation et des coûts, plutôt que d'utiliser un seul ALB qui peut gérer efficacement le trafic entre plusieurs zones."
        ]
    },
    {
        "Question Number": "6",
        "Situation": "Une entreprise d'analytique marketing souhaite migrer son entrepôt de données à grande échelle vers AWS. Les données sont structurées pour des requêtes analytiques complexes plutôt que pour des charges de travail transactionnelles, et l'entreprise a besoin d'une solution qui puisse facilement s'intégrer à ses outils BI basés sur SQL existants. De plus, l'entreprise souhaite interroger des données historiques stockées dans Amazon S3 directement sans les charger dans l'entrepôt de données.",
        "Question": "Quelle combinaison de service et de fonctionnalité AWS le responsable des solutions devrait-il recommander ?",
        "Options": {
            "1": "Amazon Redshift avec Redshift Spectrum",
            "2": "Amazon RDS avec des réplicas de lecture",
            "3": "Amazon DynamoDB avec des tables globales",
            "4": "Amazon S3 avec Athena pour des requêtes ad-hoc"
        },
        "Correct Answer": "Amazon Redshift avec Redshift Spectrum",
        "Explanation": "Amazon Redshift est un service d'entrepôt de données entièrement géré qui est conçu pour des requêtes analytiques complexes, ce qui le rend adapté aux besoins de l'entreprise d'analytique marketing. Redshift Spectrum permet aux utilisateurs d'exécuter des requêtes sur des données stockées dans Amazon S3 sans avoir besoin de les charger dans Redshift, ce qui est idéal pour interroger des données historiques. Cette combinaison permet une intégration transparente avec les outils BI basés sur SQL existants, car Redshift utilise SQL standard pour les requêtes.",
        "Other Options": [
            "Amazon RDS avec des réplicas de lecture est principalement conçu pour des charges de travail transactionnelles et la gestion de bases de données relationnelles, ce qui ne correspond pas au besoin de l'entreprise pour des requêtes analytiques complexes et l'interrogation directe de données historiques dans S3.",
            "Amazon DynamoDB avec des tables globales est un service de base de données NoSQL qui est optimisé pour des charges de travail transactionnelles à haute vélocité, et non pour des requêtes analytiques complexes. Il ne prend pas en charge les outils BI basés sur SQL aussi efficacement que Redshift.",
            "Amazon S3 avec Athena pour des requêtes ad-hoc est une option viable pour interroger des données directement dans S3, mais elle peut ne pas fournir le même niveau de performance et d'optimisation pour des requêtes analytiques complexes que Amazon Redshift avec Redshift Spectrum."
        ]
    },
    {
        "Question Number": "7",
        "Situation": "Une entreprise de biotechnologie effectue des analyses de séquençage génomique à grande échelle qui nécessitent des ressources de calcul importantes de manière intermittente. L'entreprise souhaite optimiser ses coûts en s'assurant que les ressources de calcul ne sont utilisées que lorsque cela est nécessaire et peuvent évoluer automatiquement en fonction des demandes de charge de travail.",
        "Question": "Quel service de calcul AWS le solutions architect devrait-il recommander pour ce scénario ?",
        "Options": {
            "1": "Amazon EC2 Auto Scaling",
            "2": "AWS Lambda",
            "3": "AWS Batch",
            "4": "Amazon ECS sur EC2"
        },
        "Correct Answer": "AWS Batch",
        "Explanation": "AWS Batch est conçu spécifiquement pour exécuter des charges de travail de calcul par lots de manière efficace à n'importe quelle échelle. Il provisionne automatiquement la quantité et le type optimaux de ressources de calcul (par exemple, des instances optimisées pour le CPU ou la mémoire) en fonction du volume et des exigences spécifiques des ressources des travaux par lots soumis. Cela le rend idéal pour les besoins de l'entreprise de biotechnologie, car il peut gérer des analyses de séquençage génomique à grande échelle qui nécessitent des ressources de calcul importantes de manière intermittente, optimisant ainsi les coûts en n'utilisant les ressources que lorsque cela est nécessaire et en évoluant automatiquement en fonction des demandes de charge de travail.",
        "Other Options": [
            "Amazon EC2 Auto Scaling est utile pour gérer les instances EC2 et les faire évoluer en fonction de la demande, mais il n'est pas spécifiquement adapté aux charges de travail de traitement par lots. Il nécessite une configuration et une gestion plus manuelles par rapport à AWS Batch, qui est conçu pour les travaux par lots.",
            "AWS Lambda est un service de calcul sans serveur qui exécute du code en réponse à des événements et gère automatiquement les ressources de calcul requises. Cependant, il n'est pas adapté aux travaux par lots de longue durée comme les analyses de séquençage génomique, car il a une limite de temps d'exécution maximale de 15 minutes par invocation.",
            "Amazon ECS sur EC2 est un service d'orchestration de conteneurs qui vous permet d'exécuter et de gérer des conteneurs Docker. Bien qu'il puisse évoluer en fonction de la demande, il nécessite plus de gestion et n'est pas spécifiquement optimisé pour les charges de travail de traitement par lots comme AWS Batch, ce qui le rend moins adapté aux besoins intermittents de ressources de calcul de l'entreprise."
        ]
    },
    {
        "Question Number": "8",
        "Situation": "Une plateforme d'éducation en ligne connaît un fort trafic de lecture pour le contenu des cours pendant les heures de pointe. Pour améliorer les temps de réponse et réduire la charge sur la base de données, l'entreprise souhaite mettre en place une couche de mise en cache.",
        "Question": "Quelle solution de mise en cache le solutions architect devrait-il recommander pour obtenir la meilleure amélioration de performance ?",
        "Options": {
            "1": "Mettre en œuvre Amazon S3 avec Transfer Acceleration pour une livraison de contenu plus rapide.",
            "2": "Déployer Amazon ElastiCache en utilisant Redis pour mettre en cache le contenu des cours fréquemment consulté.",
            "3": "Utiliser Amazon CloudFront pour mettre en cache les requêtes de base de données aux emplacements de périphérie.",
            "4": "Configurer un cache en mémoire sur chaque serveur d'application pour stocker le contenu des cours."
        },
        "Correct Answer": "Déployer Amazon ElastiCache en utilisant Redis pour mettre en cache le contenu des cours fréquemment consulté.",
        "Explanation": "Amazon ElastiCache utilisant Redis est un magasin de données en mémoire qui fournit un accès à haute vitesse aux données fréquemment consultées. En mettant en cache le contenu des cours en mémoire, cela réduit considérablement les temps de réponse pour les requêtes de lecture et allège la charge sur la base de données pendant les heures de trafic de pointe. Redis est particulièrement bien adapté aux scénarios où une faible latence et un haut débit sont requis, ce qui en fait un choix idéal pour améliorer les performances d'une plateforme d'éducation en ligne.",
        "Other Options": [
            "Mettre en œuvre Amazon S3 avec Transfer Acceleration est principalement axé sur l'amélioration de la vitesse des téléchargements et des téléchargements de fichiers, et non sur la mise en cache de contenu dynamique ou de requêtes de base de données. Bien qu'il puisse améliorer la livraison de contenu pour des actifs statiques, il ne répond pas efficacement au besoin de mise en cache du contenu des cours fréquemment consulté.",
            "Utiliser Amazon CloudFront pour mettre en cache les requêtes de base de données aux emplacements de périphérie n'est pas un cas d'utilisation typique pour CloudFront, qui est conçu pour mettre en cache du contenu web statique et dynamique plutôt que des requêtes de base de données. Bien qu'il puisse améliorer la livraison de contenu pour des actifs statiques, il ne fournit pas le même niveau d'amélioration de performance pour le contenu dynamique fréquemment consulté qu'un cache en mémoire comme Redis.",
            "Configurer un cache en mémoire sur chaque serveur d'application peut entraîner des incohérences et une complexité accrue dans la gestion de la synchronisation du cache entre plusieurs serveurs. Cette approche peut également ne pas bien évoluer à mesure que le nombre de serveurs d'application augmente, ce qui la rend moins efficace par rapport à une solution de mise en cache centralisée comme Amazon ElastiCache."
        ]
    },
    {
        "Question Number": "9",
        "Situation": "Une entreprise construit une application qui implique plusieurs étapes, y compris l'invocation de fonctions Lambda, l'attente d'une période de temps spécifique et le passage de données entre différentes tâches. Ils souhaitent s'assurer que les tâches sont exécutées dans le bon ordre et sont évolutives, fiables et gérables. L'entreprise envisage différents services AWS pour orchestrer le flux de travail de ces tâches.",
        "Question": "Quel service AWS l'entreprise devrait-elle utiliser à cette fin ?",
        "Options": {
            "1": "Utiliser AWS Step Functions pour définir et exécuter une machine d'état qui gère le flux des tâches et les transitions entre elles.",
            "2": "Utiliser AWS Lambda pour orchestrer les tâches en invoquant d'autres fonctions Lambda en séquence, en passant des données via des variables d'environnement.",
            "3": "Utiliser Amazon SQS pour mettre en file d'attente les tâches et les traiter séquentiellement en utilisant des instances EC2.",
            "4": "Utiliser Amazon EC2 Auto Scaling pour gérer l'exécution des tâches et évoluer automatiquement en fonction du nombre de tâches à réaliser."
        },
        "Correct Answer": "Utiliser AWS Step Functions pour définir et exécuter une machine d'état qui gère le flux des tâches et les transitions entre elles.",
        "Explanation": "AWS Step Functions est spécifiquement conçu pour orchestrer des flux de travail complexes qui impliquent plusieurs étapes, y compris l'invocation de fonctions AWS Lambda, l'attente de périodes de temps spécifiques et le passage de données entre les tâches. Il vous permet de définir une machine d'état qui décrit clairement la séquence des tâches et leurs transitions, garantissant qu'elles sont exécutées dans le bon ordre. Step Functions offre également une gestion des erreurs intégrée, des tentatives de reprise et la capacité de gérer l'état, ce qui en fait une solution fiable et gérable pour orchestrer des flux de travail.",
        "Other Options": [
            "Utiliser AWS Lambda pour orchestrer les tâches en invoquant d'autres fonctions Lambda en séquence n'est pas idéal car Lambda est principalement conçu pour exécuter des fonctions uniques plutôt que de gérer des flux de travail complexes. Bien que vous puissiez invoquer des fonctions en séquence, il lui manque les fonctionnalités intégrées de gestion d'état et de gestion des erreurs que Step Functions fournit.",
            "Utiliser Amazon SQS pour mettre en file d'attente les tâches et les traiter séquentiellement en utilisant des instances EC2 n'est pas le meilleur choix pour orchestrer des flux de travail. SQS est un service de messagerie qui peut aider à découpler les composants mais ne gère pas intrinsèquement l'ordre d'exécution ou l'état des tâches, ce qui est crucial pour le scénario décrit.",
            "Utiliser Amazon EC2 Auto Scaling pour gérer l'exécution des tâches et évoluer automatiquement en fonction du nombre de tâches à réaliser n'est pas adapté pour orchestrer des flux de travail. EC2 Auto Scaling se concentre sur l'évolution des instances EC2 en fonction de la demande mais ne fournit pas de capacités d'orchestration de flux de travail, qui sont essentielles pour gérer la séquence et les dépendances des tâches."
        ]
    },
    {
        "Question Number": "10",
        "Situation": "Une entreprise souhaite s'assurer que son environnement AWS respecte le principe du moindre privilège afin de minimiser les risques de sécurité. L'entreprise a plusieurs applications fonctionnant sur AWS, chacune nécessitant des autorisations spécifiques pour accéder à certaines ressources.",
        "Question": "Quelle est l'approche la PLUS efficace pour mettre en œuvre cette meilleure pratique de sécurité ?",
        "Options": {
            "1": "Attribuer à chaque application la politique AdministratorAccess pour s'assurer qu'elle dispose de toutes les autorisations sur toutes les ressources.",
            "2": "Créer des politiques IAM personnalisées qui accordent uniquement les autorisations nécessaires à chaque application et les attacher aux rôles IAM respectifs des applications.",
            "3": "Utiliser le compte utilisateur root pour toutes les applications et suivre manuellement les autorisations pour chaque application.",
            "4": "Accorder à tous les utilisateurs IAM du compte des autorisations complètes et compter sur les contrôles internes de l'application pour restreindre l'accès."
        },
        "Correct Answer": "Créer des politiques IAM personnalisées qui accordent uniquement les autorisations nécessaires à chaque application et les attacher aux rôles IAM respectifs des applications.",
        "Explanation": "Créer des politiques IAM personnalisées qui accordent uniquement les autorisations nécessaires à chaque application est le moyen le plus efficace de mettre en œuvre le principe du moindre privilège. Cette approche garantit que chaque application a accès uniquement aux ressources nécessaires à son fonctionnement, réduisant ainsi le risque d'accès non autorisé ou de modifications accidentelles d'autres ressources. En attachant ces politiques à des rôles IAM spécifiques, l'entreprise peut gérer les autorisations de manière centralisée et les ajuster au besoin sans affecter d'autres applications.",
        "Other Options": [
            "Attribuer à chaque application la politique AdministratorAccess n'est pas une pratique sécurisée, car cela accorde des autorisations complètes sur toutes les ressources, ce qui contredit le principe du moindre privilège et augmente considérablement les risques de sécurité.",
            "Utiliser le compte utilisateur root pour toutes les applications est fortement déconseillé car le compte root a un accès illimité à toutes les ressources AWS. Cette pratique pose un risque de sécurité important, car toute compromission du compte root entraînerait un contrôle total sur l'environnement AWS.",
            "Accorder à tous les utilisateurs IAM du compte des autorisations complètes et compter sur les contrôles internes de l'application n'est pas une approche sécurisée. Cela expose l'environnement AWS à un usage abusif potentiel, car tout utilisateur IAM pourrait accéder à n'importe quelle ressource sans restrictions, sapant ainsi le principe du moindre privilège."
        ]
    },
    {
        "Question Number": "11",
        "Situation": "Une plateforme d'éducation en ligne a besoin d'une solution de base de données qui peut s'adapter automatiquement en fonction de la demande. Leur trafic varie considérablement, avec des pics à certains moments de la journée. Ils souhaitent une solution rentable qui ajuste la capacité automatiquement sans intervention manuelle.",
        "Question": "Quelle stratégie de planification de capacité de base de données répondrait le mieux à ces exigences ?",
        "Options": {
            "1": "Capacité provisionnée avec mise à l'échelle manuelle pendant les périodes de pointe",
            "2": "Instances réservées avec un engagement de 3 ans",
            "3": "Capacité à la demande avec mise à l'échelle automatique activée",
            "4": "Utiliser des réplicas en lecture pour gérer les périodes de fort trafic"
        },
        "Correct Answer": "Capacité à la demande avec mise à l'échelle automatique activée",
        "Explanation": "La capacité à la demande avec mise à l'échelle automatique activée est la meilleure solution pour la plateforme d'éducation en ligne car elle permet à la base de données d'ajuster automatiquement sa capacité en fonction de la demande en temps réel sans aucune intervention manuelle. Cela est particulièrement important pour gérer des modèles de trafic variables, car cela garantit que la plateforme peut gérer efficacement les charges de pointe tout en étant rentable pendant les périodes creuses. La fonctionnalité de mise à l'échelle automatique alloue dynamiquement des ressources selon les besoins, ce qui correspond parfaitement à l'exigence d'une solution capable de s'adapter aux niveaux de trafic fluctuants.",
        "Other Options": [
            "La capacité provisionnée avec mise à l'échelle manuelle pendant les périodes de pointe nécessite une intervention manuelle pour ajuster la capacité, ce qui ne répond pas à l'exigence d'une mise à l'échelle automatique en fonction de la demande. Cela pourrait entraîner des problèmes de performance lors de pics de trafic inattendus si la mise à l'échelle n'est pas effectuée à temps.",
            "Les instances réservées avec un engagement de 3 ans enferment la plateforme dans une capacité et un coût fixes, ce qui n'est pas idéal pour une situation avec un trafic très variable. Cette stratégie ne fournit pas la flexibilité nécessaire pour s'adapter automatiquement à la demande, ce qui pourrait entraîner un surprovisionnement et des coûts inutiles pendant les périodes de faible trafic.",
            "Utiliser des réplicas en lecture pour gérer les périodes de fort trafic peut aider à répartir les demandes de lecture, mais ne traite pas la planification globale de la capacité pour la base de données. Cette stratégie peut ne pas être suffisante si la base de données principale elle-même ne peut pas évoluer pour gérer des opérations d'écriture accrues ou une charge globale, et elle nécessite également une configuration et une gestion manuelles."
        ]
    },
    {
        "Question Number": "12",
        "Situation": "Une entreprise migre sa base de données Oracle sur site vers AWS. Elle souhaite minimiser les changements apportés à l'application tout en passant à un service de base de données géré.",
        "Question": "Quel service de base de données AWS le solutions architecte devrait-il recommander pour cette migration hétérogène ?",
        "Options": {
            "1": "Amazon Aurora avec compatibilité PostgreSQL",
            "2": "Amazon RDS pour Oracle",
            "3": "Amazon DynamoDB",
            "4": "Amazon Redshift"
        },
        "Correct Answer": "Amazon RDS pour Oracle",
        "Explanation": "Amazon RDS pour Oracle est le meilleur choix pour migrer une base de données Oracle sur site vers AWS tout en minimisant les changements apportés à l'application. RDS pour Oracle fournit un service de base de données géré qui prend en charge les fonctionnalités de la base de données Oracle, permettant une transition plus fluide sans nécessiter de changements significatifs dans le code de l'application ou les requêtes de base de données. Ce service gère également les tâches de base de données courantes telles que les sauvegardes, les mises à jour et la mise à l'échelle, ce qui peut aider à réduire les frais d'exploitation.",
        "Other Options": [
            "Amazon Aurora avec compatibilité PostgreSQL est un service de base de données relationnelle qui offre une compatibilité avec PostgreSQL. Cependant, cela nécessiterait des changements dans l'application pour s'adapter au dialecte et aux fonctionnalités de PostgreSQL, le rendant moins adapté à une migration transparente depuis Oracle.",
            "Amazon DynamoDB est un service de base de données NoSQL conçu pour des performances élevées et une évolutivité. Migrer d'une base de données relationnelle Oracle vers une base de données NoSQL nécessiterait des changements significatifs dans l'architecture de l'application et le modèle de données, ce qui contredit l'objectif de minimiser les changements pendant la migration.",
            "Amazon Redshift est un service d'entrepôt de données optimisé pour l'analyse et le reporting. Il n'est pas conçu pour des charges de travail transactionnelles comme celles généralement gérées par une base de données Oracle. Migrer vers Redshift nécessiterait une refonte complète de l'application et des modèles d'accès aux données, ce qui en fait un choix inadapté pour ce scénario."
        ]
    },
    {
        "Question Number": "13",
        "Situation": "Une entreprise résout des problèmes de performance dans son application basée sur des microservices déployée sur AWS. Elle souhaite obtenir une visibilité approfondie sur l'architecture de son application afin d'identifier les goulets d'étranglement et d'améliorer les temps de réponse.",
        "Question": "Quel service AWS l'entreprise devrait-elle utiliser pour suivre et analyser les requêtes à travers ses microservices et obtenir des informations détaillées sur la performance de l'application ?",
        "Options": {
            "1": "Utilisez AWS X-Ray pour tracer et analyser le flux des requêtes à travers l'application, fournissant des informations sur les latences et les goulets d'étranglement en temps réel.",
            "2": "Utilisez Amazon CloudWatch Logs pour surveiller et stocker les journaux de l'application, mais analysez manuellement les données de performance en utilisant des instances EC2.",
            "3": "Utilisez AWS CloudTrail pour suivre les requêtes API, mais configurez des journaux personnalisés supplémentaires pour des informations spécifiques sur la performance.",
            "4": "Utilisez Amazon RDS Performance Insights pour analyser la performance de la base de données et identifier les requêtes lentes dans l'application."
        },
        "Correct Answer": "Utilisez AWS X-Ray pour tracer et analyser le flux des requêtes à travers l'application, fournissant des informations sur les latences et les goulets d'étranglement en temps réel.",
        "Explanation": "AWS X-Ray est spécifiquement conçu pour tracer les requêtes dans les architectures de microservices. Il fournit des informations détaillées sur la performance des applications en permettant aux développeurs de visualiser le flux des requêtes à travers divers services, d'identifier les latences et de localiser les goulets d'étranglement. Cette visibilité approfondie est cruciale pour résoudre les problèmes de performance et optimiser les temps de réponse dans un environnement de microservices.",
        "Other Options": [
            "Amazon CloudWatch Logs est utile pour surveiller et stocker les journaux, mais il ne fournit pas le même niveau de traçage et d'analyse des flux de requêtes qu'AWS X-Ray. L'analyse manuelle utilisant des instances EC2 serait chronophage et moins efficace pour identifier les goulets d'étranglement de performance.",
            "AWS CloudTrail est principalement axé sur le suivi des requêtes API et des modifications des ressources AWS, et non sur l'analyse de la performance de l'application. Bien qu'il puisse fournir certaines informations sur l'utilisation des API, il n'offre pas le traçage détaillé des requêtes nécessaire pour identifier les problèmes de performance dans les microservices.",
            "Amazon RDS Performance Insights est conçu pour analyser la performance de la base de données et identifier les requêtes lentes, mais il ne fournit pas d'informations sur la performance globale de l'application ou le flux des requêtes à travers les microservices. Il est limité à l'analyse au niveau de la base de données et ne traite pas l'architecture plus large de l'application."
        ]
    },
    {
        "Question Number": "14",
        "Situation": "Une entreprise développe une application pilotée par des événements où divers composants doivent réagir à des événements en temps réel, tels que des commandes clients et des mises à jour d'inventaire. Le système doit garantir que les composants sont faiblement couplés pour améliorer l'évolutivité et la fiabilité. L'entreprise souhaite également la capacité de gérer les événements de manière asynchrone, afin que chaque service puisse les traiter indépendamment.",
        "Question": "Quel service AWS l'entreprise devrait-elle utiliser pour mettre en œuvre un modèle de messagerie publish/subscribe ? (Choisissez deux.)",
        "Options": {
            "1": "Utilisez Amazon SNS (Simple Notification Service) pour publier des événements, et abonnez différents composants de l'application (comme les fonctions AWS Lambda) aux sujets SNS pour le traitement.",
            "2": "Utilisez Amazon SQS (Simple Queue Service) pour des files de messages directes entre les composants sans mettre en œuvre un modèle publish/subscribe.",
            "3": "Utilisez AWS Direct Connect pour établir une connexion privée entre les composants et publier les événements directement via le lien réseau dédié.",
            "4": "Utilisez Amazon EventBridge pour créer des bus d'événements et définir des règles pour acheminer les événements vers plusieurs cibles, permettant un modèle publish/subscribe.",
            "5": "Utilisez Amazon S3 pour stocker des événements et laissez les composants interroger le bucket S3 pour traiter de nouveaux événements."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Utilisez Amazon SNS (Simple Notification Service) pour publier des événements, et abonnez différents composants de l'application (comme les fonctions AWS Lambda) aux sujets SNS pour le traitement.",
            "Utilisez Amazon EventBridge pour créer des bus d'événements et définir des règles pour acheminer les événements vers plusieurs cibles, permettant un modèle publish/subscribe."
        ],
        "Explanation": "Amazon SNS (Simple Notification Service) est un service web qui coordonne et gère la livraison ou l'envoi de messages aux points de terminaison ou clients abonnés. Il est conçu pour prendre en charge le modèle de messagerie publish/subscribe, qui est exactement ce dont l'entreprise a besoin. Les fonctions AWS Lambda peuvent être abonnées aux sujets SNS et traiter les événements de manière asynchrone. Amazon EventBridge est un service de bus d'événements sans serveur qui facilite la connexion des applications entre elles en utilisant des données provenant de vos propres applications, d'applications SaaS intégrées et de services AWS. Il vous permet de créer un paradigme de messagerie pub/sub, avec des bus d'événements et des règles pour acheminer les événements vers plusieurs cibles.",
        "Other Options": [
            "Amazon SQS (Simple Queue Service) est un service de mise en file d'attente de messages entièrement géré qui vous permet de découpler et de faire évoluer des microservices, des systèmes distribués et des applications sans serveur. Cependant, il ne prend pas en charge intrinsèquement un modèle publish/subscribe, ce qui est une exigence dans le scénario donné.",
            "AWS Direct Connect est une solution de service cloud qui facilite l'établissement d'une connexion réseau dédiée de vos locaux à AWS. Il ne prend pas en charge un modèle de messagerie publish/subscribe, et il ne fournit pas intrinsèquement de gestion asynchrone des événements.",
            "Amazon S3 (Simple Storage Service) est un service de stockage d'objets qui offre une évolutivité, une disponibilité des données, une sécurité et des performances de premier plan dans l'industrie. Cependant, il n'est pas conçu pour des applications pilotées par des événements en temps réel ou pour mettre en œuvre un modèle de messagerie publish/subscribe. Utiliser S3 nécessiterait que les composants interrogent en continu pour de nouveaux événements, ce qui est inefficace et non en temps réel."
        ]
    },
    {
        "Question Number": "15",
        "Situation": "Une entreprise utilise Amazon Elastic Container Service (ECS) pour déployer une application basée sur des microservices dans un environnement de production. L'application gère des données sensibles des clients, et l'entreprise souhaite s'assurer que la sécurité est correctement mise en œuvre à tous les niveaux de l'application.",
        "Question": "Quelles pratiques suivantes devraient être mises en œuvre pour sécuriser les conteneurs ECS et garantir que les données sont protégées ?",
        "Options": {
            "1": "Utilisez Amazon ECS avec AWS Fargate pour la gestion de conteneurs sans serveur et assurez-vous que toutes les données sensibles sont stockées dans Amazon S3 avec le chiffrement activé.",
            "2": "Utilisez des rôles IAM pour les tâches ECS afin d'attribuer les permissions minimales requises pour accéder aux ressources AWS, et configurez les groupes de sécurité pour les instances de conteneurs afin de restreindre le trafic entrant.",
            "3": "Comptez uniquement sur le chiffrement au niveau des tâches Amazon ECS pour protéger les données sensibles au repos, car cela fournit un chiffrement de bout en bout pour l'ensemble de l'application.",
            "4": "Activez les adresses IP publiques pour les instances ECS afin d'assurer l'accès aux conteneurs depuis Internet, et configurez les groupes de sécurité pour un flux de trafic flexible."
        },
        "Correct Answer": "Utilisez des rôles IAM pour les tâches ECS afin d'attribuer les permissions minimales requises pour accéder aux ressources AWS, et configurez les groupes de sécurité pour les instances de conteneurs afin de restreindre le trafic entrant.",
        "Explanation": "L'utilisation de rôles IAM pour les tâches ECS vous permet d'attribuer les permissions de moindre privilège nécessaires pour que les conteneurs accèdent aux ressources AWS, ce qui est un principe fondamental de sécurité. Cela minimise le risque d'accès non autorisé aux données sensibles. De plus, la configuration des groupes de sécurité pour les instances de conteneurs aide à contrôler le trafic entrant et sortant, garantissant que seules les sources de confiance peuvent communiquer avec les conteneurs, renforçant ainsi la sécurité.",
        "Other Options": [
            "Utiliser Amazon ECS avec AWS Fargate pour la gestion de conteneurs sans serveur et stocker des données sensibles dans Amazon S3 avec le chiffrement activé est une bonne pratique, mais cela ne répond pas au besoin de contrôles d'accès appropriés et de sécurité réseau pour les conteneurs ECS eux-mêmes. Bien que le chiffrement soit important, il devrait faire partie d'une stratégie de sécurité plus large qui inclut des rôles IAM et des groupes de sécurité.",
            "Compter uniquement sur le chiffrement au niveau des tâches Amazon ECS n'est pas suffisant pour protéger les données sensibles au repos. Bien que le chiffrement au niveau des tâches puisse aider, il ne fournit pas une sécurité complète pour l'ensemble de l'application, et il ne traite pas d'autres aspects critiques tels que le contrôle d'accès et la sécurité réseau.",
            "Activer les adresses IP publiques pour les instances ECS pose un risque de sécurité significatif en exposant les conteneurs à Internet. Cela peut entraîner un accès non autorisé et des attaques. Au lieu de cela, les meilleures pratiques de sécurité recommandent de restreindre l'accès via des groupes de sécurité et d'utiliser des IP privées lorsque cela est possible."
        ]
    },
    {
        "Question Number": "16",
        "Situation": "Une plateforme de trading financier traite des milliers de transactions par seconde et nécessite un service de mise en file d'attente hautement évolutif pour gérer un volume important de messages avec un débit presque illimité. Le système de trading ne nécessite pas d'ordre de message et peut tolérer des messages en double occasionnels, tant qu'il garantit que chaque message est traité au moins une fois.",
        "Question": "Quelle configuration Amazon SQS répondrait le mieux à ces exigences ?",
        "Options": {
            "1": "Configurer une file d'attente Amazon SQS FIFO pour garantir un traitement exactement une fois et maintenir l'ordre des messages",
            "2": "Utiliser une file d'attente Amazon SQS Standard avec une livraison au moins une fois, permettant un haut débit et des doublons occasionnels",
            "3": "Mettre en place un sujet Amazon SNS avec une livraison de messages FIFO pour assurer un haut débit et une faible latence",
            "4": "Déployer Amazon Kinesis Data Streams pour fournir un traitement de messages ordonnés et une livraison au moins une fois pour le traitement des transactions en temps réel"
        },
        "Correct Answer": "Utiliser une file d'attente Amazon SQS Standard avec une livraison au moins une fois, permettant un haut débit et des doublons occasionnels",
        "Explanation": "Une file d'attente Amazon SQS Standard est conçue pour un haut débit et peut gérer un volume important de messages avec une évolutivité presque illimitée. Elle fournit une livraison au moins une fois, ce qui signifie que bien que les messages puissent être livrés plusieurs fois, elle garantit que chaque message sera traité au moins une fois. Cela correspond parfaitement aux exigences du système de trading, qui n'a pas besoin d'ordre de message et peut tolérer des doublons occasionnels.",
        "Other Options": [
            "Configurer une file d'attente Amazon SQS FIFO ne serait pas approprié car les files d'attente FIFO sont conçues pour des scénarios où l'ordre des messages est critique et garantissent un traitement exactement une fois. Cela se fait au prix d'un débit inférieur par rapport aux files d'attente Standard, ce qui n'est pas idéal pour une plateforme de trading à fort volume.",
            "Mettre en place un sujet Amazon SNS avec une livraison de messages FIFO n'est pas approprié car SNS est principalement utilisé pour la messagerie pub/sub et n'est pas conçu pour mettre en file d'attente des messages de la même manière que SQS. De plus, les sujets FIFO sont également limités en débit par rapport aux files d'attente Standard.",
            "Déployer Amazon Kinesis Data Streams fournirait un traitement de messages ordonnés et une livraison au moins une fois, mais c'est plus complexe et généralement utilisé pour l'analyse en temps réel plutôt que pour des besoins de mise en file d'attente simples. Les exigences du système de trading ne nécessitent pas la complexité supplémentaire de Kinesis alors qu'une file d'attente Standard suffirait."
        ]
    },
    {
        "Question Number": "17",
        "Situation": "Une organisation utilise Amazon S3 pour stocker des données confidentielles et nécessite une méthode de chiffrement côté serveur qui permet à AWS Key Management Service (KMS) de gérer les clés. De plus, elle souhaite des fonctionnalités telles que le contrôle de rotation des clés et la séparation des rôles.",
        "Question": "Quelle option de chiffrement S3 répond le mieux à ces besoins ?",
        "Options": {
            "1": "Chiffrement côté client",
            "2": "Chiffrement côté serveur avec des clés gérées par S3 (SSE-S3)",
            "3": "Chiffrement côté serveur avec des clés fournies par le client (SSE-C)",
            "4": "Chiffrement côté serveur avec des clés gérées par AWS KMS (SSE-KMS)"
        },
        "Correct Answer": "Chiffrement côté serveur avec des clés gérées par AWS KMS (SSE-KMS)",
        "Explanation": "SSE-KMS est la meilleure option pour ce scénario car il permet à AWS Key Management Service (KMS) de gérer les clés de chiffrement. Cette méthode offre des fonctionnalités de sécurité améliorées telles que le contrôle de rotation des clés, qui permet à l'organisation de faire tourner automatiquement les clés selon un calendrier, et la séparation des rôles, qui garantit que différents rôles peuvent se voir attribuer des autorisations pour l'utilisation et la gestion des clés. Cela correspond parfaitement aux exigences de l'organisation pour gérer des données confidentielles de manière sécurisée.",
        "Other Options": [
            "Le chiffrement côté client nécessite que le client gère les clés de chiffrement, ce qui n'utilise pas AWS KMS pour la gestion des clés et manque des fonctionnalités de rotation des clés et de séparation des rôles dont l'organisation a besoin.",
            "Le chiffrement côté serveur avec des clés gérées par S3 (SSE-S3) utilise Amazon S3 pour gérer les clés de chiffrement, mais ne fournit pas le même niveau de contrôle sur la gestion des clés, comme la rotation des clés et la séparation des rôles, que SSE-KMS offre.",
            "Le chiffrement côté serveur avec des clés fournies par le client (SSE-C) permet aux clients de gérer leurs propres clés de chiffrement, ce qui signifie que l'organisation devrait gérer elle-même la gestion et la rotation des clés, n'utilisant pas AWS KMS et manquant des fonctionnalités souhaitées."
        ]
    },
    {
        "Question Number": "18",
        "Situation": "Une startup développe un backend mobile qui nécessite le traitement des téléchargements des utilisateurs, la réalisation de transformations d'images et le stockage des résultats. L'équipe souhaite minimiser la charge opérationnelle et s'assurer que le backend peut évoluer de manière transparente avec la demande des utilisateurs.",
        "Question": "Quel service AWS sans serveur le concepteur de solutions devrait-il utiliser pour gérer les tâches de traitement d'images ? (Choisissez deux.)",
        "Options": {
            "1": "AWS Fargate",
            "2": "Amazon EC2",
            "3": "AWS Lambda",
            "4": "Amazon ECS",
            "5": "Notifications d'événements Amazon S3"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "AWS Lambda",
            "Notifications d'événements Amazon S3"
        ],
        "Explanation": "AWS Lambda est un service de calcul sans serveur qui vous permet d'exécuter votre code sans provisionner ou gérer des serveurs. Il évolue automatiquement avec votre application avec une haute disponibilité, et vous ne payez que pour le temps de calcul que vous consommez. Cela en fait un choix parfait pour gérer les tâches de traitement d'images de manière évolutive et rentable. Les notifications d'événements Amazon S3 peuvent être utilisées en conjonction avec AWS Lambda pour déclencher les tâches de traitement d'images chaque fois qu'une nouvelle image est téléchargée dans un bucket S3. Cela permet au système de réagir immédiatement aux téléchargements des utilisateurs, réduisant ainsi la charge opérationnelle.",
        "Other Options": [
            "AWS Fargate est un moteur de calcul sans serveur pour conteneurs. Bien qu'il puisse être utilisé pour exécuter des tâches de traitement d'images, il n'est pas aussi simple ou rentable qu'AWS Lambda pour ce cas d'utilisation spécifique. Il ne fournit également pas la réponse immédiate aux téléchargements des utilisateurs qui peut être obtenue avec les notifications d'événements S3.",
            "Amazon EC2 est un service web qui fournit une capacité de calcul redimensionnable dans le cloud. Ce n'est pas sans serveur, ce qui signifie qu'il nécessite une mise à l'échelle manuelle et une gestion des serveurs, ce qui contredit le désir de l'équipe de minimiser la charge opérationnelle.",
            "Amazon ECS (Elastic Container Service) est un service d'orchestration de conteneurs hautement évolutif et performant. Bien qu'il puisse être utilisé pour des tâches de traitement d'images, il n'est pas sans serveur et nécessite plus de charge opérationnelle qu'AWS Lambda. Il ne fournit également pas la réponse immédiate aux téléchargements des utilisateurs qui peut être obtenue avec les notifications d'événements S3."
        ]
    },
    {
        "Question Number": "19",
        "Situation": "Une entreprise met en place un contrôle d'accès pour son environnement AWS et souhaite s'assurer que chaque membre de l'équipe dispose du niveau d'accès approprié aux services AWS. L'entreprise a plusieurs départements, tels que le développement, les finances et les ressources humaines, chacun ayant besoin de différents niveaux de permissions.",
        "Question": "Quelle structure IAM serait la manière la plus efficace et gérable d'attribuer des permissions aux utilisateurs dans ces départements ?",
        "Options": {
            "1": "Créer des utilisateurs IAM individuels pour chaque membre de l'équipe et attacher des politiques directement à chaque utilisateur.",
            "2": "Créer des groupes IAM pour chaque département, assigner les utilisateurs au groupe approprié et attacher des politiques spécifiques au département à chaque groupe.",
            "3": "Utiliser un seul rôle IAM avec des permissions complètes et faire en sorte que tous les utilisateurs assument ce rôle au besoin.",
            "4": "Créer des comptes AWS séparés pour chaque département et gérer l'accès au niveau du compte."
        },
        "Correct Answer": "Créer des groupes IAM pour chaque département, assigner les utilisateurs au groupe approprié et attacher des politiques spécifiques au département à chaque groupe.",
        "Explanation": "Créer des groupes IAM pour chaque département est la manière la plus efficace et gérable d'attribuer des permissions car cela permet une gestion centralisée des permissions. En attachant des politiques à des groupes plutôt qu'à des utilisateurs individuels, l'entreprise peut facilement gérer les niveaux d'accès à mesure que les membres de l'équipe rejoignent ou quittent l'organisation ou changent de rôle. Cette approche réduit la charge administrative de gestion des permissions et garantit que tous les utilisateurs d'un département ont des droits d'accès cohérents qui correspondent à leurs fonctions.",
        "Other Options": [
            "Créer des utilisateurs IAM individuels pour chaque membre de l'équipe et attacher des politiques directement à chaque utilisateur peut conduire à une situation complexe et ingérable à mesure que le nombre d'utilisateurs augmente. Il devient difficile de maintenir des permissions cohérentes entre les utilisateurs, et tout changement de niveaux d'accès devrait être effectué individuellement pour chaque utilisateur.",
            "Utiliser un seul rôle IAM avec des permissions complètes pour tous les utilisateurs n'est pas une pratique sécurisée. Cela viole le principe du moindre privilège, car cela accorde à tous les utilisateurs l'accès à toutes les ressources, augmentant le risque d'actions accidentelles ou malveillantes qui pourraient compromettre l'environnement AWS.",
            "Créer des comptes AWS séparés pour chaque département complique la gestion et peut entraîner des coûts accrus et une charge administrative supplémentaire. Cela rend également difficile le partage de ressources entre les départements et nécessite des stratégies de facturation et de gestion des accès plus complexes."
        ]
    },
    {
        "Question Number": "20",
        "Situation": "Une entreprise utilise un groupe Auto Scaling (ASG) pour gérer des instances EC2 en fonction de la demande fluctuante. Elle souhaite ajuster automatiquement la capacité des instances pour maintenir une utilisation CPU agrégée de 40%.",
        "Question": "Quel type de politique de mise à l'échelle devraient-ils mettre en œuvre, et pourquoi ?",
        "Options": {
            "1": "Mise à l'échelle manuelle, car elle permet un contrôle direct sur la capacité souhaitée en fonction de la surveillance en temps réel.",
            "2": "Mise à l'échelle planifiée, qui ajustera la capacité à des moments spécifiques selon les modèles de demande prévus.",
            "3": "Mise à l'échelle dynamique avec suivi d'objectif, car elle ajuste automatiquement la capacité pour maintenir l'objectif CPU spécifié.",
            "4": "Mise à l'échelle simple, qui permet d'augmenter ou de diminuer la capacité en fonction de conditions de seuil CPU uniques."
        },
        "Correct Answer": "Mise à l'échelle dynamique avec suivi d'objectif",
        "Explanation": "La mise à l'échelle dynamique avec suivi d'objectif est l'option la plus adaptée pour ce scénario car elle ajuste automatiquement le nombre d'instances EC2 dans le groupe Auto Scaling pour maintenir un objectif spécifié d'utilisation CPU—dans ce cas, 40%. Ce type de politique de mise à l'échelle surveille en continu l'utilisation CPU et effectue des ajustements au besoin, garantissant que l'application peut répondre à la demande fluctuante sans intervention manuelle.",
        "Other Options": [
            "La mise à l'échelle manuelle nécessite une intervention humaine pour ajuster la capacité souhaitée, ce qui n'est pas efficace pour maintenir un objectif d'utilisation CPU spécifique, surtout dans un environnement dynamique.",
            "La mise à l'échelle planifiée est utile pour des charges de travail prévisibles où la demande peut être anticipée à des moments spécifiques, mais elle ne répond pas aux changements en temps réel de l'utilisation CPU, ce qui la rend moins efficace pour maintenir un niveau d'utilisation cible.",
            "La mise à l'échelle simple réagit à des seuils spécifiques mais ne fournit pas l'ajustement continu nécessaire pour maintenir un objectif d'utilisation CPU moyen comme 40%. Elle peut conduire à une sur-provision ou à une sous-provision si la demande fluctue fréquemment."
        ]
    },
    {
        "Question Number": "21",
        "Situation": "Une entreprise souhaite sécuriser son bucket Amazon S3 et restreindre l'accès uniquement via sa distribution CloudFront. Elle décide d'utiliser une identité d'accès d'origine (OAI) pour y parvenir.",
        "Question": "Quelle est la fonction principale de l'OAI dans cette configuration ?",
        "Options": {
            "1": "L'OAI agit comme un utilisateur qui peut être ajouté aux politiques IAM pour restreindre l'accès aux buckets S3.",
            "2": "L'OAI devient une identité associée à CloudFront, permettant uniquement aux requêtes de CloudFront d'accéder au bucket S3, avec tout accès direct bloqué par défaut.",
            "3": "L'OAI permet un accès direct au bucket S3 depuis n'importe quel emplacement, contournant les restrictions de CloudFront.",
            "4": "L'OAI est utilisé pour fournir un accès public au bucket S3 via un en-tête personnalisé."
        },
        "Correct Answer": "L'OAI devient une identité associée à CloudFront, permettant uniquement aux requêtes de CloudFront d'accéder au bucket S3, avec tout accès direct bloqué par défaut.",
        "Explanation": "L'identité d'accès d'origine (OAI) est une fonctionnalité spéciale de CloudFront qui vous permet de restreindre l'accès à votre bucket Amazon S3 afin que seul CloudFront puisse y accéder. En associant une OAI à votre distribution CloudFront, vous vous assurez que les requêtes vers le bucket S3 ne peuvent provenir que de CloudFront, bloquant ainsi efficacement tout accès direct au bucket S3 depuis Internet. Cela renforce la sécurité en empêchant l'accès non autorisé au contenu S3 tout en permettant aux utilisateurs d'y accéder via CloudFront.",
        "Other Options": [
            "L'OAI n'agit pas comme un utilisateur qui peut être ajouté aux politiques IAM. Au contraire, c'est une fonctionnalité de CloudFront qui fournit un moyen de restreindre l'accès aux buckets S3 spécifiquement pour CloudFront.",
            "Cette option est en fait la bonne réponse, car elle décrit avec précision la fonction de l'OAI dans ce contexte.",
            "L'OAI ne permet pas un accès direct au bucket S3 depuis n'importe quel emplacement. En fait, elle fait le contraire en s'assurant que seul CloudFront peut accéder au bucket S3, bloquant tout autre accès direct."
        ]
    },
    {
        "Question Number": "22",
        "Situation": "Une entreprise technologique héberge une application critique sur des instances Amazon EC2. Pour améliorer la sécurité, elle doit contrôler l'accès aux instances et garantir la protection des données à plusieurs niveaux, y compris les couches réseau et application. Elle est également préoccupée par l'accès non autorisé, elle souhaite donc appliquer des politiques d'accès sécurisées et surveiller les menaces potentielles.",
        "Question": "Quelles sont les meilleures pratiques qu'elle devrait mettre en œuvre pour garantir la sécurité de son environnement EC2 ? (Choisissez deux.)",
        "Options": {
            "1": "Attacher des groupes de sécurité aux instances EC2 pour restreindre le trafic entrant et sortant, utiliser des rôles IAM pour gérer les autorisations, et activer la journalisation CloudTrail pour surveiller l'accès et l'activité.",
            "2": "Déployer toutes les instances EC2 dans un sous-réseau public avec un accès illimité, permettant une gestion et un accès à distance plus faciles pour les utilisateurs.",
            "3": "Activer AWS Shield sur les instances EC2 pour gérer tous les besoins en matière de sécurité et empêcher l'accès non autorisé en bloquant tout le trafic entrant.",
            "4": "Utiliser des paires de clés EC2 pour gérer l'accès de tous les utilisateurs et stocker les clés directement sur les instances pour faciliter les connexions rapides.",
            "5": "Mettre en œuvre des ACL réseau en plus des groupes de sécurité pour une sécurité réseau en couches et activer Amazon GuardDuty pour la détection des menaces."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Attacher des groupes de sécurité aux instances EC2 pour restreindre le trafic entrant et sortant, utiliser des rôles IAM pour gérer les autorisations, et activer la journalisation CloudTrail pour surveiller l'accès et l'activité.",
            "Mettre en œuvre des ACL réseau en plus des groupes de sécurité pour une sécurité réseau en couches et activer Amazon GuardDuty pour la détection des menaces."
        ],
        "Explanation": "Les groupes de sécurité agissent comme un pare-feu virtuel pour les instances EC2 afin de contrôler le trafic entrant et sortant. Les rôles IAM fournissent un accès sécurisé et contrôlé aux services et ressources AWS. La journalisation CloudTrail aide à surveiller et à enregistrer l'activité du compte liée aux actions sur l'infrastructure AWS. Les ACL réseau fournissent une couche de sécurité supplémentaire, permettant de contrôler le trafic entrant et sortant d'un ou plusieurs sous-réseaux. Amazon GuardDuty est un service de détection des menaces qui surveille en continu les comportements malveillants ou non autorisés.",
        "Other Options": [
            "Déployer toutes les instances EC2 dans un sous-réseau public avec un accès illimité n'est pas une bonne pratique en matière de sécurité. Cela expose les instances à des menaces potentielles provenant d'Internet et ne fournit aucun contrôle sur qui peut accéder aux instances.",
            "Bien qu'AWS Shield offre une protection contre les DDoS, il ne gère pas tous les besoins en matière de sécurité pour les instances EC2. Il ne bloque pas tout le trafic entrant, ce qui n'est pas souhaitable car cela empêcherait l'accès légitime aux instances.",
            "Utiliser des paires de clés EC2 pour gérer l'accès est une bonne pratique, mais stocker les clés directement sur les instances ne l'est pas. Si une instance est compromise, les clés pourraient être accessibles, entraînant un accès non autorisé supplémentaire."
        ]
    },
    {
        "Question Number": "23",
        "Situation": "Une organisation mondiale de presse doit déployer son application de livraison de contenu dans plusieurs régions géographiques pour réduire la latence et améliorer l'expérience utilisateur pour les téléspectateurs du monde entier. L'application nécessite une synchronisation des mises à jour de contenu en temps réel dans toutes les régions.",
        "Question": "Quel service AWS le responsable des solutions devrait-il recommander pour répondre à cette exigence de calcul distribué ?",
        "Options": {
            "1": "Amazon CloudFront",
            "2": "AWS Global Accelerator",
            "3": "Amazon Route 53",
            "4": "Amazon ElastiCache"
        },
        "Correct Answer": "Amazon CloudFront",
        "Explanation": "Amazon CloudFront est un service de réseau de distribution de contenu (CDN) qui met en cache le contenu dans des emplacements périphériques à travers le monde, ce qui aide à réduire la latence pour les utilisateurs accédant à l'application depuis différentes régions géographiques. Il prend également en charge les mises à jour de contenu en temps réel, permettant une synchronisation dans toutes les régions, ce qui le rend idéal pour une organisation mondiale de presse qui doit fournir des mises à jour en temps opportun à ses téléspectateurs.",
        "Other Options": [
            "AWS Global Accelerator améliore la disponibilité et les performances des applications en dirigeant le trafic vers des points de terminaison optimaux, mais il ne fournit pas de capacités de livraison de contenu ou de mise en cache comme le fait CloudFront.",
            "Amazon Route 53 est un service web de système de noms de domaine (DNS) évolutif qui fournit l'enregistrement de domaine et le routage, mais il ne gère pas la livraison de contenu ou la synchronisation des mises à jour de contenu.",
            "Amazon ElastiCache est un service qui fournit un cache en mémoire pour améliorer les performances des applications, mais il n'est pas conçu pour la livraison de contenu à travers des régions géographiques et ne prend pas en charge la synchronisation en temps réel des mises à jour de contenu."
        ]
    },
    {
        "Question Number": "24",
        "Situation": "Une entreprise financière internationale doit garantir une haute disponibilité pour son application principale qui doit rester opérationnelle même en cas de pannes régionales. Elle vise à mettre en œuvre une stratégie de basculement qui minimise les temps d'arrêt et redirige automatiquement le trafic vers un environnement de secours dans une autre région si la région principale échoue.",
        "Question": "Étant donné leurs exigences, quelle stratégie de basculement AWS serait la plus appropriée, et pourquoi ?",
        "Options": {
            "1": "Pilot Light, car elle maintient une version minimale de l'application dans une autre région, permettant un démarrage rapide lors des événements de basculement.",
            "2": "Warm Standby, car elle exécute une version réduite de l'application dans une autre région, permettant un basculement plus rapide avec un temps de configuration minimal.",
            "3": "Basculement Actif-Actif, où les deux régions exécutent la charge complète de l'application, permettant un routage immédiat du trafic vers la région secondaire en cas de défaillance.",
            "4": "Sauvegarde et Restauration, car cela implique de restaurer à partir de sauvegardes stockées dans une autre région, offrant une solution économique pour les applications non critiques."
        },
        "Correct Answer": "Basculement Actif-Actif, où les deux régions exécutent la charge complète de l'application, permettant un routage immédiat du trafic vers la région secondaire en cas de défaillance.",
        "Explanation": "La stratégie de Basculement Actif-Actif est la plus appropriée pour l'entreprise financière internationale car elle permet aux deux régions d'exécuter simultanément la charge complète de l'application. Cela signifie que si une région subit une panne, le trafic peut être immédiatement redirigé vers l'autre région sans aucun temps d'arrêt. Cette approche garantit une haute disponibilité et répond à l'exigence de l'entreprise d'un temps d'arrêt minimal lors des pannes régionales, ce qui en fait la solution la plus efficace pour son application principale.",
        "Other Options": [
            "Pilot Light n'est pas adapté car il ne maintient qu'une version minimale de l'application dans une autre région, ce qui nécessiterait du temps pour se développer lors d'un événement de basculement, entraînant un temps d'arrêt potentiel.",
            "Warm Standby, bien qu'il soit meilleur que Pilot Light, exécute toujours une version réduite de l'application. Bien qu'il permette un basculement plus rapide que Pilot Light, il peut ne pas fournir le routage immédiat du trafic nécessaire pour une haute disponibilité, car il nécessite un certain temps de configuration pour atteindre la pleine capacité.",
            "Sauvegarde et Restauration n'est pas approprié pour ce scénario car cela implique de restaurer à partir de sauvegardes, ce qui peut prendre un temps considérable et n'est pas conçu pour une haute disponibilité. Cette stratégie est plus adaptée aux applications non critiques où un temps d'arrêt peut être toléré."
        ]
    },
    {
        "Question Number": "25",
        "Situation": "Une entreprise stocke des données sensibles de clients dans une base de données Amazon RDS MySQL. Pour se conformer aux exigences de sécurité et réglementaires, elle doit s'assurer que les données sont chiffrées au repos, avec un contrôle strict sur qui peut accéder aux clés de chiffrement. De plus, elle doit s'assurer que les sauvegardes et les instantanés de la base de données sont également chiffrés.",
        "Question": "Quelle solution répondrait le mieux à ces exigences ? (Choisissez deux.)",
        "Options": {
            "1": "Activer le chiffrement RDS au repos en utilisant AWS Key Management Service (KMS) avec une CMK gérée par le client, en s'assurant que seuls des rôles IAM spécifiques ont les autorisations d'accès à la clé.",
            "2": "Utiliser la fonctionnalité de chiffrement intégrée de MySQL pour chiffrer les données au repos et configurer RDS pour activer le chiffrement sur les sauvegardes automatisées et les instantanés.",
            "3": "Activer le Transparent Data Encryption (TDE) dans MySQL et gérer les clés de chiffrement en utilisant AWS CloudHSM pour s'assurer que les clés de chiffrement ne sont pas accessibles par AWS.",
            "4": "Stocker les données en texte clair dans la base de données RDS mais activer SSL/TLS pour un accès sécurisé, en s'appuyant sur la sécurité réseau pour protéger les données au repos.",
            "5": "Configurer RDS pour utiliser le chiffrement en transit avec SSL/TLS et chiffrer manuellement les sauvegardes avant de les stocker dans Amazon S3."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Activer le chiffrement RDS au repos en utilisant AWS Key Management Service (KMS) avec une CMK gérée par le client, en s'assurant que seuls des rôles IAM spécifiques ont les autorisations d'accès à la clé.",
            "Activer le Transparent Data Encryption (TDE) dans MySQL et gérer les clés de chiffrement en utilisant AWS CloudHSM pour s'assurer que les clés de chiffrement ne sont pas accessibles par AWS."
        ],
        "Explanation": "AWS Key Management Service (KMS) permet le chiffrement au repos et donne au client le contrôle sur qui peut accéder aux clés de chiffrement en attribuant des autorisations à des rôles IAM spécifiques. Cela répond à l'exigence d'un contrôle strict sur l'accès aux clés de chiffrement. L'option 3 est correcte car le Transparent Data Encryption (TDE) dans MySQL fournit un chiffrement au repos, et AWS CloudHSM permet de gérer les clés de chiffrement de manière à ce qu'elles ne soient pas accessibles par AWS, répondant ainsi à l'exigence d'un contrôle strict sur l'accès aux clés de chiffrement.",
        "Other Options": [
            "Bien que la fonctionnalité de chiffrement intégrée de MySQL puisse chiffrer les données au repos, elle ne fournit pas le niveau de contrôle sur l'accès aux clés de chiffrement qui est requis dans ce scénario.",
            "Stocker des données en texte clair dans la base de données RDS ne fournit pas de chiffrement au repos, ce qui est une exigence dans ce scénario. Bien que SSL/TLS offre un accès sécurisé, cela ne protège pas les données au repos.",
            "Bien qu'il fournisse un chiffrement en transit avec SSL/TLS et permette le chiffrement manuel des sauvegardes, cela ne fournit pas de chiffrement au repos pour les données dans la base de données RDS, ce qui est une exigence dans ce scénario."
        ]
    },
    {
        "Question Number": "26",
        "Situation": "Une agence gouvernementale doit ingérer des données sensibles provenant de plusieurs bureaux de branche dans un lac de données Amazon S3. Les points d'ingestion de données doivent être sécurisés pour empêcher tout accès non autorisé et garantir l'intégrité des données pendant le transfert.",
        "Question": "Quelle solution le concepteur de solutions devrait-il mettre en œuvre pour sécuriser l'accès aux points d'ingestion de données ?",
        "Options": {
            "1": "Utiliser des URL pré-signées Amazon S3 pour chaque bureau de branche afin de télécharger des données directement vers S3.",
            "2": "Mettre en place une connexion VPN entre chaque bureau de branche et le VPC AWS, et restreindre l'accès S3 aux points de terminaison VPC.",
            "3": "Mettre en œuvre des utilisateurs IAM avec des clés d'accès S3 pour chaque bureau de branche.",
            "4": "Activer l'accès public au compartiment S3 et utiliser le chiffrement au niveau des objets."
        },
        "Correct Answer": "Mettre en place une connexion VPN entre chaque bureau de branche et le VPC AWS, et restreindre l'accès S3 aux points de terminaison VPC.",
        "Explanation": "Mettre en place une connexion VPN entre chaque bureau de branche et le VPC AWS garantit que tous les transferts de données se font par un canal sécurisé et chiffré. Cela protège les données sensibles contre tout accès non autorisé pendant la transmission. En restreignant l'accès S3 aux points de terminaison VPC, vous renforcez encore la sécurité en vous assurant que seul le trafic provenant du VPC peut accéder au compartiment S3, l'isolant efficacement d'Internet et réduisant le risque d'exposition à des menaces potentielles.",
        "Other Options": [
            "Utiliser des URL pré-signées Amazon S3 permet un accès temporaire pour télécharger des données directement vers S3, mais cela ne fournit pas un canal sécurisé pour le transfert de données. Si l'URL pré-signée est interceptée, des utilisateurs non autorisés pourraient accéder au compartiment S3, compromettant la sécurité des données.",
            "Mettre en œuvre des utilisateurs IAM avec des clés d'accès S3 pour chaque bureau de branche peut fournir un contrôle d'accès, mais cela ne sécurise pas le transfert de données lui-même. Si les clés d'accès sont compromises, des utilisateurs non autorisés pourraient accéder au compartiment S3. De plus, cette méthode ne chiffre pas les données en transit, les laissant vulnérables à l'interception.",
            "Activer l'accès public au compartiment S3 et utiliser le chiffrement au niveau des objets est très peu sécurisé. L'accès public signifie que quiconque sur Internet peut potentiellement accéder aux données, ce qui contredit l'exigence de prévenir tout accès non autorisé. Le chiffrement au niveau des objets protège les données au repos, mais ne sécurise pas les données pendant le transfert, les laissant vulnérables à l'interception."
        ]
    },
    {
        "Question Number": "27",
        "Situation": "Une entreprise de streaming média souhaite améliorer les performances de son application, qui délivre du contenu vidéo aux utilisateurs du monde entier. L'entreprise doit minimiser la latence et réduire la charge sur les serveurs backend.",
        "Question": "Quelle stratégie de mise en cache l'entreprise devrait-elle utiliser pour garantir une livraison rapide du contenu et maintenir une haute disponibilité ?",
        "Options": {
            "1": "Utiliser Amazon CloudFront comme réseau de distribution de contenu (CDN) pour mettre en cache le contenu vidéo aux emplacements de périphérie, et stocker le contenu fréquemment accédé dans Amazon S3 pour un stockage à long terme.",
            "2": "Utiliser Amazon ElastiCache pour mettre en cache les requêtes de base de données et stocker le contenu vidéo dans Amazon DynamoDB, garantissant des temps d'accès rapides pour les utilisateurs.",
            "3": "Utiliser des instances Amazon EC2 avec un équilibreur de charge pour mettre en cache le contenu vidéo, et stocker le contenu dans un système de fichiers traditionnel pour un accès facile.",
            "4": "Utiliser Amazon RDS avec des réplicas en lecture pour mettre en cache les données et optimiser la livraison vidéo, et stocker le contenu multimédia dans Amazon EFS pour un accès partagé."
        },
        "Correct Answer": "Utiliser Amazon CloudFront comme réseau de distribution de contenu (CDN) pour mettre en cache le contenu vidéo aux emplacements de périphérie, et stocker le contenu fréquemment accédé dans Amazon S3 pour un stockage à long terme.",
        "Explanation": "Utiliser Amazon CloudFront comme CDN permet à l'entreprise de streaming média de mettre en cache le contenu vidéo aux emplacements de périphérie dans le monde entier. Cela réduit considérablement la latence pour les utilisateurs en livrant le contenu depuis un emplacement plus proche d'eux, plutôt que depuis un serveur centralisé. De plus, stocker le contenu fréquemment accédé dans Amazon S3 fournit une solution de stockage évolutive et durable, garantissant que le contenu est facilement disponible pour la récupération. Cette combinaison optimise les performances et maintient une haute disponibilité, ce qui en fait le meilleur choix pour une livraison rapide du contenu.",
        "Other Options": [
            "Utiliser Amazon ElastiCache pour mettre en cache les requêtes de base de données et stocker le contenu vidéo dans Amazon DynamoDB n'est pas idéal pour la livraison de contenu vidéo. ElastiCache est principalement utilisé pour mettre en cache des données en mémoire afin d'accélérer les requêtes de base de données, tandis que DynamoDB est une base de données NoSQL qui peut ne pas être optimisée pour servir efficacement de gros fichiers vidéo.",
            "Utiliser des instances Amazon EC2 avec un équilibreur de charge pour mettre en cache le contenu vidéo et stocker le contenu dans un système de fichiers traditionnel n'est pas une stratégie efficace. Cette approche nécessiterait plus de gestion et d'efforts de mise à l'échelle, et les systèmes de fichiers traditionnels peuvent ne pas offrir les mêmes avantages de performance qu'un CDN pour la livraison de contenu mondial.",
            "Utiliser Amazon RDS avec des réplicas en lecture pour mettre en cache les données et optimiser la livraison vidéo n'est pas adapté au contenu vidéo. RDS est conçu pour les bases de données relationnelles et n'est pas optimisé pour servir de gros fichiers multimédias. De plus, Amazon EFS est un service de stockage de fichiers qui peut ne pas offrir les mêmes avantages de performance qu'un CDN pour le streaming vidéo."
        ]
    },
    {
        "Question Number": "28",
        "Situation": "Une entreprise exécute une application sur des instances Amazon EC2 qui doivent accéder aux données stockées dans un compartiment Amazon S3. Pour éviter de gérer des identifiants à long terme, l'entreprise souhaite fournir de manière sécurisée les autorisations nécessaires aux instances.",
        "Question": "Quelle configuration répondrait le mieux à ces exigences ?",
        "Options": {
            "1": "Attacher un rôle IAM avec les autorisations nécessaires pour accéder au compartiment S3 à chaque instance EC2. Le rôle fournira des identifiants temporaires qui sont automatiquement renouvelés.",
            "2": "Générer manuellement une clé d'accès IAM et une clé d'accès secrète avec des autorisations S3 et les stocker sur chaque instance EC2 pour que l'application puisse les utiliser.",
            "3": "Créer un utilisateur IAM avec des autorisations d'accès S3, configurer les identifiants de l'utilisateur sur chaque instance EC2 et mettre en place un travail planifié pour renouveler manuellement les identifiants.",
            "4": "Utiliser AWS Secrets Manager pour stocker les identifiants d'accès S3 et les récupérer dans le code de l'application exécutée sur les instances EC2."
        },
        "Correct Answer": "Attacher un rôle IAM avec les autorisations nécessaires pour accéder au compartiment S3 à chaque instance EC2. Le rôle fournira des identifiants temporaires qui sont automatiquement renouvelés.",
        "Explanation": "Attacher un rôle IAM à une instance EC2 est la meilleure pratique pour fournir des autorisations d'accès aux ressources AWS comme S3. Cette méthode permet à l'instance d'assumer le rôle et de recevoir des identifiants de sécurité temporaires qui sont automatiquement renouvelés par AWS. Cela élimine le besoin d'identifiants à long terme, renforce la sécurité et simplifie la gestion puisque les identifiants sont gérés par AWS et n'ont pas besoin d'être stockés ou renouvelés manuellement.",
        "Other Options": [
            "Générer manuellement une clé d'accès IAM et une clé d'accès secrète et les stocker sur chaque instance EC2 n'est pas sécurisé. Si ces identifiants sont compromis, ils peuvent être utilisés indéfiniment jusqu'à ce qu'ils soient révoqués manuellement. De plus, gérer et renouveler ces identifiants peut être fastidieux et sujet à erreurs.",
            "Créer un utilisateur IAM avec des autorisations d'accès S3 et configurer les identifiants de l'utilisateur sur chaque instance EC2 est également peu sécurisé. Comme dans l'option précédente, cette approche nécessite une gestion manuelle des identifiants à long terme, ce qui peut entraîner des vulnérabilités de sécurité si les identifiants sont divulgués ou ne sont pas renouvelés correctement.",
            "Utiliser AWS Secrets Manager pour stocker les identifiants d'accès S3 et les récupérer dans le code de l'application est une meilleure approche que de stocker directement les identifiants sur l'instance. Cependant, cela implique toujours de gérer des identifiants, ce qui est inutile lorsque les rôles IAM peuvent fournir des identifiants temporaires automatiquement. Cela ajoute de la complexité sans avantages significatifs dans ce scénario."
        ]
    },
    {
        "Question Number": "29",
        "Situation": "Une institution financière, SecureBank, a des exigences strictes en matière de conformité pour le chiffrement des données et la gestion des clés. Pour répondre aux normes réglementaires, SecureBank doit utiliser un module de sécurité matériel (HSM) conforme à FIPS 140-2 Niveau 3 pour le stockage et la gestion des clés. Ils envisagent AWS CloudHSM et AWS Key Management Service (KMS) pour répondre à ces exigences. SecureBank souhaite un contrôle total sur le processus de gestion des clés et la capacité de s'intégrer à des API standard de l'industrie pour des flux de travail de chiffrement personnalisés. Ils veulent également comprendre les différences en matière de contrôle client, de niveaux de conformité et d'intégration avec les services AWS entre AWS CloudHSM et AWS KMS.",
        "Question": "Laquelle des options suivantes explique le mieux les principales différences entre AWS CloudHSM et AWS Key Management Service (KMS) concernant le contrôle client et les niveaux de conformité, en particulier lorsqu'il s'agit de normes de sécurité strictes comme FIPS 140-2 Niveau 3 ?",
        "Options": {
            "1": "AWS CloudHSM et AWS KMS fournissent tous deux une conformité FIPS 140-2 Niveau 3 ; cependant, seul AWS CloudHSM est un service entièrement géré et multi-locataire, permettant aux clients de gérer leurs clés de chiffrement dans un environnement partagé.",
            "2": "AWS CloudHSM est un module de sécurité matériel (HSM) à locataire unique provisionné par AWS mais entièrement géré par le client, offrant une conformité FIPS 140-2 Niveau 3. En revanche, AWS KMS fournit généralement une conformité de Niveau 2 et offre une intégration plus profonde avec les services AWS, mais avec moins de contrôle client sur la gestion des clés.",
            "3": "AWS CloudHSM est conçu pour s'intégrer nativement avec des services AWS tels que le chiffrement côté serveur S3, offrant une gestion du chiffrement sans faille. AWS KMS, cependant, est plus adapté aux environnements axés sur la conformité nécessitant un HSM contrôlé par le client.",
            "4": "Contrairement à AWS CloudHSM, AWS KMS permet aux clients d'utiliser des API standard de l'industrie, y compris les bibliothèques PKCS#11 et CNG, pour s'intégrer à d'autres flux de travail de chiffrement, ce qui le rend plus adapté aux implémentations cryptographiques personnalisées."
        },
        "Correct Answer": "AWS CloudHSM est un module de sécurité matériel (HSM) à locataire unique provisionné par AWS mais entièrement géré par le client, offrant une conformité FIPS 140-2 Niveau 3. En revanche, AWS KMS fournit généralement une conformité de Niveau 2 et offre une intégration plus profonde avec les services AWS, mais avec moins de contrôle client sur la gestion des clés.",
        "Explanation": "AWS CloudHSM offre aux clients un contrôle total sur leurs clés de chiffrement et est conçu pour répondre à des exigences de conformité strictes, y compris FIPS 140-2 Niveau 3. C'est une solution à locataire unique, ce qui signifie que le matériel est dédié à un seul client, ce qui renforce la sécurité et le contrôle. D'autre part, AWS Key Management Service (KMS) est un service multi-locataire qui simplifie la gestion des clés et s'intègre parfaitement avec d'autres services AWS, mais il ne fournit pas le même niveau de contrôle sur la gestion des clés que CloudHSM. KMS répond généralement à la conformité FIPS 140-2 Niveau 2, ce qui peut ne pas satisfaire les exigences réglementaires les plus strictes auxquelles SecureBank est confrontée.",
        "Other Options": [
            "L'option 1 affirme incorrectement qu'AWS CloudHSM et AWS KMS fournissent tous deux une conformité FIPS 140-2 Niveau 3. Bien que CloudHSM respecte cette norme, KMS répond généralement à la conformité de Niveau 2, ce qui est une distinction critique pour les besoins de SecureBank.",
            "L'option 3 déforme les capacités d'AWS CloudHSM et d'AWS KMS. CloudHSM n'est pas principalement conçu pour s'intégrer avec des services AWS comme S3 ; il est plutôt axé sur la fourniture d'un environnement sécurisé pour la gestion des clés. KMS est effectivement plus intégré avec les services AWS mais n'offre pas le même niveau de contrôle que CloudHSM.",
            "L'option 4 affirme incorrectement qu'AWS KMS permet l'utilisation d'API standard de l'industrie comme PKCS#11 et CNG pour des implémentations cryptographiques personnalisées. En réalité, AWS CloudHSM prend en charge ces API, offrant la flexibilité nécessaire pour des flux de travail de chiffrement personnalisés, tandis que KMS n'offre pas le même niveau de contrôle ou de support API."
        ]
    },
    {
        "Question Number": "30",
        "Situation": "Une application mobile connaît de fortes augmentations d'utilisation lors d'événements majeurs, nécessitant que l'application s'adapte rapidement. L'application doit gérer ces pics efficacement tout en maîtrisant les coûts.",
        "Question": "Quelles stratégies de mise à l'échelle répondraient le mieux à ces besoins ? (Choisissez deux.)",
        "Options": {
            "1": "Mise à l'échelle verticale en passant à des types d'instances plus grands pendant les périodes de forte affluence",
            "2": "Mise à l'échelle horizontale avec un groupe Auto Scaling et des politiques de mise à l'échelle dynamique",
            "3": "Mise à l'échelle planifiée pour ajouter des ressources pendant les périodes d'événements",
            "4": "Mise à l'échelle manuelle en ajoutant des instances en fonction de la demande projetée",
            "5": "Mise en œuvre de la mise à l'échelle prédictive en utilisant Amazon CloudWatch pour anticiper les pics de trafic et ajuster la capacité de manière proactive"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Mise à l'échelle horizontale avec un groupe Auto Scaling et des politiques de mise à l'échelle dynamique",
            "Mise en œuvre de la mise à l'échelle prédictive en utilisant Amazon CloudWatch pour anticiper les pics de trafic et ajuster la capacité de manière proactive"
        ],
        "Explanation": "La mise à l'échelle horizontale avec un groupe Auto Scaling et des politiques de mise à l'échelle dynamique est une réponse correcte car elle permet à l'application d'ajouter plus d'instances à mesure que la demande augmente, et de les supprimer lorsque la demande diminue, ce qui est idéal pour gérer de fortes augmentations d'utilisation. La mise en œuvre de la mise à l'échelle prédictive en utilisant Amazon CloudWatch est également correcte car elle utilise des algorithmes d'apprentissage automatique pour prédire la demande future et ajuster la capacité de manière proactive, ce qui peut aider à gérer efficacement les pics de trafic et à maîtriser les coûts.",
        "Other Options": [
            "La mise à l'échelle verticale en passant à des types d'instances plus grands pendant les périodes de forte affluence n'est pas une solution idéale car elle implique d'augmenter la capacité d'une seule instance, ce qui peut être coûteux et ne pas fournir la flexibilité nécessaire pour gérer de fortes augmentations d'utilisation.",
            "La mise à l'échelle planifiée pour ajouter des ressources pendant les périodes d'événements peut ne pas être efficace car elle nécessite une prédiction précise du moment où les pics se produiront, ce qui n'est pas toujours possible.",
            "La mise à l'échelle manuelle en ajoutant des instances en fonction de la demande projetée n'est pas la meilleure stratégie car elle nécessite une intervention manuelle et peut ne pas être en mesure de répondre rapidement aux pics soudains de demande."
        ]
    },
    {
        "Question Number": "31",
        "Situation": "Une entreprise, XYZ Corp, gère des informations sensibles telles que des identifiants de base de données, des clés API et d'autres secrets nécessaires pour divers microservices dans leur application. Ils souhaitent stocker ces secrets de manière sécurisée et s'assurer que chaque application puisse y accéder uniquement lorsque cela est nécessaire. De plus, XYZ Corp souhaite que les secrets soient automatiquement renouvelés sans nécessiter de mises à jour manuelles des applications ou d'interruption pour des changements de configuration. L'équipe de sécurité a choisi AWS Secrets Manager pour gérer et renouveler ces secrets. Ils veulent également s'assurer que les secrets sont chiffrés lorsqu'ils sont au repos et uniquement accessibles aux services et applications autorisés.",
        "Question": "Les étapes suivantes décrivent-elles correctement comment AWS Secrets Manager gère la récupération et le renouvellement des secrets pour un accès sécurisé par les applications ?",
        "Options": {
            "1": "Secrets Manager récupère les secrets depuis AWS Key Management Service (KMS) et les met à jour périodiquement dans l'application directement pour maintenir la synchronisation.",
            "2": "L'application récupère les secrets depuis Secrets Manager en utilisant un SDK, et Secrets Manager utilise AWS Lambda pour le renouvellement automatique des secrets, avec des secrets chiffrés au repos en utilisant KMS.",
            "3": "Secrets Manager fournit un renouvellement automatique en stockant tous les secrets au sein des rôles IAM, qui sont périodiquement renouvelés via des politiques AWS Identity and Access Management (IAM).",
            "4": "AWS Secrets Manager récupère les identifiants directement depuis IAM pour l'autorisation, et les secrets sont automatiquement renouvelés sans avoir besoin de fonctions Lambda."
        },
        "Correct Answer": "L'application récupère les secrets depuis Secrets Manager en utilisant un SDK, et Secrets Manager utilise AWS Lambda pour le renouvellement automatique des secrets, avec des secrets chiffrés au repos en utilisant KMS.",
        "Explanation": "AWS Secrets Manager permet aux applications de récupérer des secrets de manière sécurisée en utilisant les SDK AWS. Lorsqu'une application a besoin d'un secret, elle appelle l'API de Secrets Manager, qui récupère le secret depuis un stockage sécurisé. Secrets Manager prend également en charge le renouvellement automatique des secrets, qui peut être mis en œuvre à l'aide de fonctions AWS Lambda. Cela signifie que les secrets peuvent être mis à jour sans intervention manuelle, et les applications peuvent continuer à fonctionner sans interruption. De plus, les secrets sont chiffrés au repos en utilisant AWS Key Management Service (KMS), garantissant que les informations sensibles sont protégées.",
        "Other Options": [
            "AWS Secrets Manager ne récupère pas les secrets directement depuis KMS. Au lieu de cela, il gère les secrets lui-même et utilise KMS pour le chiffrement au repos. Les secrets ne sont pas mis à jour périodiquement dans l'application directement ; les applications récupèrent plutôt la dernière version du secret lorsque cela est nécessaire.",
            "AWS Secrets Manager ne stocke pas les secrets au sein des rôles IAM. IAM est utilisé pour gérer les autorisations et le contrôle d'accès, mais Secrets Manager gère les secrets eux-mêmes et utilise Lambda pour le renouvellement, pas les politiques IAM.",
            "AWS Secrets Manager ne récupère pas les identifiants directement depuis IAM. Au lieu de cela, il gère les secrets de manière indépendante et utilise des fonctions Lambda pour le renouvellement automatique. IAM est utilisé pour l'autorisation et le contrôle d'accès, mais il ne gère pas la récupération des secrets."
        ]
    },
    {
        "Question Number": "32",
        "Situation": "Une entreprise gère ses clés de chiffrement en utilisant AWS Key Management Service (AWS KMS) et souhaite contrôler l'accès à ces clés en fonction des rôles des utilisateurs.",
        "Question": "Quelle méthode l'entreprise devrait-elle utiliser pour définir les autorisations d'accès pour les clés KMS ?",
        "Options": {
            "1": "Attribuer des autorisations directement aux utilisateurs IAM",
            "2": "Utiliser des politiques basées sur les ressources sur les clés KMS",
            "3": "Activer la suppression MFA sur les clés KMS",
            "4": "Configurer des listes de contrôle d'accès (ACL) pour les clés KMS"
        },
        "Correct Answer": "Utiliser des politiques basées sur les ressources sur les clés KMS",
        "Explanation": "AWS Key Management Service (KMS) vous permet de définir des autorisations d'accès pour les clés KMS en utilisant des politiques basées sur les ressources. Ces politiques sont attachées directement aux clés KMS et spécifient quels utilisateurs IAM, rôles ou services peuvent effectuer des actions spécifiques sur les clés. Cette méthode offre un contrôle granulaire sur l'accès et est l'approche recommandée pour gérer les autorisations pour les clés KMS, car elle permet de définir des autorisations au niveau des ressources plutôt qu'au niveau des utilisateurs.",
        "Other Options": [
            "Attribuer des autorisations directement aux utilisateurs IAM n'est pas la meilleure pratique pour gérer l'accès aux clés KMS, car cela ne fournit pas la granularité nécessaire et peut entraîner une complexité de gestion. Les politiques basées sur les ressources sont préférées pour la gestion des clés.",
            "Activer la suppression MFA est une fonctionnalité principalement associée à Amazon S3 et ne s'applique pas aux clés KMS. Bien que MFA (authentification multi-facteurs) puisse améliorer la sécurité, cela ne contrôle pas directement les autorisations d'accès pour les clés KMS.",
            "Configurer des listes de contrôle d'accès (ACL) n'est pas applicable aux clés KMS. KMS utilise des politiques IAM et des politiques basées sur les ressources pour le contrôle d'accès, tandis que les ACL sont généralement utilisées dans d'autres services AWS comme S3."
        ]
    },
    {
        "Question Number": "33",
        "Situation": "Une entreprise doit stocker du contenu généré par les utilisateurs, y compris des images, des vidéos et des documents, avec la capacité de faire évoluer le stockage facilement et de fournir un accès rapide. L'entreprise recherche une solution capable de gérer de grandes quantités de données non structurées et de supporter une haute disponibilité. Ils souhaitent également s'assurer que la solution de stockage est rentable et facilement accessible par plusieurs services.",
        "Question": "Quel type de stockage AWS l'entreprise devrait-elle utiliser pour stocker ces données, et quelles sont ses caractéristiques ?",
        "Options": {
            "1": "Utiliser Amazon S3 (stockage d'objets) pour stocker des fichiers, car il est hautement évolutif et adapté aux données non structurées avec un accès facile via HTTP/HTTPS.",
            "2": "Utiliser Amazon EBS (stockage par blocs) pour stocker de grands fichiers vidéo, car il fournit un accès à faible latence aux données et un haut débit pour les applications sensibles à la performance.",
            "3": "Utiliser Amazon EFS (stockage de fichiers) pour stocker du contenu généré par les utilisateurs, car il fournit un accès partagé aux fichiers à travers plusieurs instances EC2 avec une capacité de stockage évolutive.",
            "4": "Utiliser Amazon RDS (base de données relationnelle) pour stocker du contenu généré par les utilisateurs en raison de sa forte cohérence et de son modèle de données structuré."
        },
        "Correct Answer": "Utiliser Amazon S3 (stockage d'objets) pour stocker des fichiers, car il est hautement évolutif et adapté aux données non structurées avec un accès facile via HTTP/HTTPS.",
        "Explanation": "Amazon S3 (Simple Storage Service) est conçu pour stocker et récupérer n'importe quelle quantité de données depuis n'importe où sur le web. C'est un service de stockage d'objets qui est hautement évolutif, ce qui le rend idéal pour le contenu généré par les utilisateurs tel que des images, des vidéos et des documents. S3 prend en charge les données non structurées et offre une haute disponibilité, permettant un accès facile via HTTP/HTTPS. De plus, il est rentable, car les utilisateurs ne paient que pour le stockage qu'ils utilisent, et il s'intègre bien avec divers services AWS, le rendant accessible pour plusieurs applications.",
        "Other Options": [
            "Utiliser Amazon EBS (Elastic Block Store) n'est pas idéal pour stocker de grands fichiers vidéo dans ce scénario, car EBS est un stockage par blocs principalement utilisé pour des données nécessitant un accès à faible latence et un haut débit, généralement pour des applications fonctionnant sur des instances EC2. Il n'est pas conçu pour le stockage de données non structurées à grande échelle et est plus adapté aux bases de données ou aux applications nécessitant un accès rapide aux blocs de données.",
            "Utiliser Amazon EFS (Elastic File System) pourrait fournir un accès partagé aux fichiers à travers plusieurs instances EC2, mais il est plus adapté aux scénarios où un stockage de fichiers est nécessaire plutôt qu'un stockage d'objets. EFS est également généralement plus coûteux que S3 pour de grandes quantités de données non structurées et n'offre pas le même niveau d'évolutivité et de rentabilité que S3 pour le stockage de grands volumes de contenu généré par les utilisateurs.",
            "Utiliser Amazon RDS (Relational Database Service) est inapproprié pour stocker du contenu généré par les utilisateurs car RDS est conçu pour des données structurées et des bases de données relationnelles. Il n'est pas optimisé pour des données non structurées comme des images et des vidéos, et l'utiliser à de telles fins ne serait pas rentable ni efficace, car cela nécessiterait des schémas de base de données complexes et une gestion."
        ]
    },
    {
        "Question Number": "34",
        "Situation": "Une organisation a fédéré son fournisseur d'identité sur site avec AWS pour permettre aux utilisateurs d'assumer des rôles en utilisant SAML. L'organisation souhaite imposer l'authentification multi-facteurs (MFA) pour tous les utilisateurs fédérés accédant à la console de gestion AWS.",
        "Question": "Quelle est la meilleure approche pour imposer la MFA dans ce scénario ? (Choisissez deux.)",
        "Options": {
            "1": "Configurer les paramètres MFA dans les rôles AWS IAM utilisés pour l'accès fédéré",
            "2": "Exiger la MFA via le fournisseur d'identité sur site de l'organisation",
            "3": "Activer la MFA au niveau du compte racine AWS",
            "4": "Mettre en place un pool d'utilisateurs Amazon Cognito avec des exigences de MFA",
            "5": "Utiliser des politiques AWS IAM pour exiger l'authentification MFA pour l'assumption de rôle"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Exiger la MFA via le fournisseur d'identité sur site de l'organisation",
            "Utiliser des politiques AWS IAM pour exiger l'authentification MFA pour l'assumption de rôle"
        ],
        "Explanation": "Dans ce scénario, la meilleure approche pour imposer la MFA pour tous les utilisateurs fédérés accédant à la console de gestion AWS est d'exiger la MFA via le fournisseur d'identité sur site de l'organisation et d'utiliser des politiques AWS IAM pour exiger l'authentification MFA pour l'assumption de rôle. Le fournisseur d'identité sur site est responsable de l'authentification initiale de l'utilisateur, y compris la MFA. Après que l'utilisateur a été authentifié, le fournisseur d'identité génère une assertion SAML qui est utilisée pour demander des informations d'identification de sécurité temporaires et assumer un rôle IAM. Les politiques AWS IAM peuvent être utilisées pour imposer la MFA au moment de l'assumption de rôle, garantissant que l'utilisateur s'est authentifié avec la MFA avant de pouvoir assumer le rôle.",
        "Other Options": [
            "Configurer les paramètres MFA dans les rôles AWS IAM utilisés pour l'accès fédéré n'est pas possible car l'imposition de la MFA n'est pas un paramètre qui peut être configuré directement dans les rôles IAM.",
            "Activer la MFA au niveau du compte racine AWS n'imposerait pas la MFA pour les utilisateurs fédérés. La MFA au niveau du compte racine ne s'applique qu'à l'utilisateur racine du compte, pas aux utilisateurs IAM ou aux utilisateurs fédérés.",
            "Mettre en place un pool d'utilisateurs Amazon Cognito avec des exigences de MFA n'imposerait pas la MFA pour les utilisateurs fédérés accédant à la console de gestion AWS. Amazon Cognito est utilisé pour construire, sécuriser et mettre à l'échelle l'authentification des utilisateurs dans des applications mobiles et web, et non pour imposer la MFA pour les utilisateurs fédérés accédant à la console de gestion AWS."
        ]
    },
    {
        "Question Number": "35",
        "Situation": "Une application de traitement des données de trading boursier en temps réel nécessite une haute performance CPU mais n'a pas besoin de beaucoup de mémoire. L'entreprise souhaite optimiser les coûts en choisissant le type d'instance le plus adapté.",
        "Question": "Quelle famille d'instances répondrait le mieux à ces exigences de performance et de coût ?",
        "Options": {
            "1": "Optimisé pour la mémoire",
            "2": "Optimisé pour le calcul",
            "3": "Optimisé pour le stockage",
            "4": "Calcul accéléré"
        },
        "Correct Answer": "Optimisé pour le calcul",
        "Explanation": "La famille d'instances Optimisé pour le calcul est spécifiquement conçue pour les applications nécessitant une haute performance CPU. Étant donné que l'application en question traite des données de trading boursier en temps réel, elle bénéficiera de la puissance de traitement accrue fournie par ces instances. De plus, les instances Optimisé pour le calcul sont généralement plus rentables pour les charges de travail intensives en CPU par rapport à d'autres types d'instances qui peuvent offrir plus de mémoire ou de capacités de stockage que nécessaire.",
        "Other Options": [
            "Les instances Optimisé pour la mémoire sont conçues pour les applications nécessitant une haute performance mémoire. Étant donné que l'application n'a pas besoin de beaucoup de mémoire, cette option ne serait pas adaptée et entraînerait probablement des coûts inutiles.",
            "Les instances Optimisé pour le stockage sont adaptées aux charges de travail nécessitant un haut débit de stockage et des IOPS. Étant donné que l'application n'a pas de besoins de stockage significatifs, ce type d'instance ne serait pas approprié et n'optimiserait pas les coûts.",
            "Les instances Calcul accéléré sont conçues pour les charges de travail qui bénéficient des accélérateurs matériels, tels que les GPU. Ces instances sont généralement utilisées pour l'apprentissage automatique, le rendu graphique ou d'autres tâches spécialisées. Étant donné que l'application se concentre sur la performance CPU et ne nécessite pas d'accélération, cette option ne répondrait pas efficacement aux exigences."
        ]
    },
    {
        "Question Number": "36",
        "Situation": "Une plateforme de commerce électronique connaît un fort trafic de lecture pour les catalogues de produits, ce qui impacte la performance de la base de données principale. L'entreprise souhaite décharger les opérations de lecture pour améliorer la scalabilité sans compromettre la cohérence des données.",
        "Question": "Quelle stratégie le solutions architecte devrait-il mettre en œuvre pour y parvenir ?",
        "Options": {
            "1": "Activer le déploiement Multi-AZ pour l'instance Amazon RDS afin de répartir le trafic de lecture.",
            "2": "Créer des Réplicas de Lecture Amazon RDS et configurer l'application pour diriger les requêtes de lecture vers les réplicas.",
            "3": "Utiliser Amazon DynamoDB avec des Tables Globales pour gérer la scalabilité des lectures.",
            "4": "Mettre en œuvre une configuration de réplication maître-esclave en utilisant des instances Amazon EC2 et MySQL."
        },
        "Correct Answer": "Créer des Réplicas de Lecture Amazon RDS et configurer l'application pour diriger les requêtes de lecture vers les réplicas.",
        "Explanation": "Créer des Réplicas de Lecture Amazon RDS permet à la plateforme de commerce électronique de décharger le trafic de lecture de la base de données principale. Les réplicas de lecture sont spécifiquement conçus pour gérer les opérations de lecture, ce qui aide à améliorer la scalabilité et la performance sans compromettre la cohérence des données. Les réplicas répliquent les données de manière asynchrone à partir de la base de données principale, garantissant que les requêtes de lecture peuvent être dirigées vers ces réplicas, réduisant ainsi la charge sur l'instance principale et améliorant la performance globale de l'application.",
        "Other Options": [
            "Activer le déploiement Multi-AZ pour l'instance Amazon RDS se concentre principalement sur la haute disponibilité et les capacités de basculement plutôt que sur la scalabilité des opérations de lecture. Bien qu'il offre de la redondance, cela n'aide pas à répartir efficacement le trafic de lecture.",
            "Utiliser Amazon DynamoDB avec des Tables Globales est une solution de base de données différente qui peut ne pas être adaptée si l'architecture existante repose sur Amazon RDS. De plus, cela peut introduire une complexité dans la migration des données et garantir la compatibilité avec l'application actuelle.",
            "Mettre en œuvre une configuration de réplication maître-esclave en utilisant des instances Amazon EC2 et MySQL nécessite plus de gestion et ne tire pas parti des capacités intégrées d'Amazon RDS. Cette approche peut également introduire des défis de cohérence et est moins efficace par rapport à l'utilisation des Réplicas de Lecture RDS."
        ]
    },
    {
        "Question Number": "37",
        "Situation": "Une équipe marketing doit analyser des données de clickstream stockées dans Amazon S3 pour obtenir des informations sur le comportement des utilisateurs et améliorer l'engagement sur le site web. Ils souhaitent exécuter des requêtes SQL directement sur ces données sans mettre en place un entrepôt de données complet ni gérer des serveurs. De plus, ils recherchent une solution qui leur permet de ne payer que pour les données qu'ils interrogent réellement, ce qui permet des économies tout en maintenant une infrastructure minimale et sans serveur.",
        "Question": "Quel service AWS répondrait le mieux à leurs besoins ?",
        "Options": {
            "1": "Amazon Redshift",
            "2": "Amazon EMR",
            "3": "Amazon RDS",
            "4": "Amazon Athena"
        },
        "Correct Answer": "Amazon Athena",
        "Explanation": "Amazon Athena est un service de requête interactif sans serveur qui permet aux utilisateurs d'analyser des données directement dans Amazon S3 en utilisant SQL standard. Il est conçu pour des requêtes ad hoc et ne nécessite aucune gestion d'infrastructure, ce qui le rend idéal pour les besoins de l'équipe marketing. Avec Athena, les utilisateurs ne paient que pour les requêtes qu'ils exécutent, ce qui s'aligne avec leur objectif d'économies tout en maintenant l'infrastructure minimale.",
        "Other Options": [
            "Amazon Redshift est un service d'entrepôt de données entièrement géré qui nécessite la mise en place d'un cluster et la gestion des ressources. Ce n'est pas un service sans serveur et impliquerait des coûts et une complexité plus élevés pour l'équipe marketing, qui recherche une solution plus simple.",
            "Amazon EMR (Elastic MapReduce) est une plateforme de big data cloud qui permet de traiter de grandes quantités de données en utilisant des frameworks comme Apache Hadoop et Apache Spark. Cependant, cela nécessite plus de gestion et de configuration par rapport à une solution sans serveur comme Athena, ce qui la rend moins adaptée aux besoins de l'équipe.",
            "Amazon RDS (Relational Database Service) est un service de base de données relationnelle géré qui nécessite la provision et la gestion d'instances de base de données. Il n'est pas conçu pour interroger des données directement depuis S3 et impliquerait plus de surcharge que ce que l'équipe marketing désire."
        ]
    },
    {
        "Question Number": "38",
        "Situation": "Une société de production vidéo stocke des milliers de fichiers vidéo, qui sont rarement consultés après la production initiale. Ils souhaitent une solution de stockage économique qui leur permette d'archiver ces fichiers tout en pouvant les récupérer en quelques minutes si nécessaire.",
        "Question": "Quel service de stockage AWS répondrait le mieux à ces exigences ?",
        "Options": {
            "1": "Amazon EFS",
            "2": "Amazon S3 Glacier Instant Retrieval",
            "3": "Amazon FSx for Windows File Server",
            "4": "Amazon EBS Provisioned IOPS"
        },
        "Correct Answer": "Amazon S3 Glacier Instant Retrieval",
        "Explanation": "Amazon S3 Glacier Instant Retrieval est spécifiquement conçu pour l'archivage de données à long terme avec la capacité de récupérer des données rapidement, généralement en quelques millisecondes. Ce service est idéal pour la société de production vidéo car il leur permet de stocker de grandes quantités de fichiers vidéo rarement consultés de manière économique tout en offrant la possibilité d'accéder à ces fichiers en quelques minutes si nécessaire. La fonctionnalité 'Instant Retrieval' garantit que le temps de récupération est conforme à l'exigence de l'entreprise pour un accès rapide aux fichiers archivés.",
        "Other Options": [
            "Amazon EFS (Elastic File System) est conçu pour un accès à faible latence au stockage de fichiers partagé et n'est pas économique pour l'archivage à long terme de données rarement consultées. Il est mieux adapté aux applications nécessitant un accès fréquent aux données.",
            "Amazon FSx for Windows File Server fournit des systèmes de fichiers Windows entièrement gérés mais n'est pas non plus optimisé pour l'archivage à long terme. Il est plus adapté aux applications nécessitant un stockage de fichiers partagé avec compatibilité Windows et accès à faible latence.",
            "Amazon EBS (Elastic Block Store) Provisioned IOPS est conçu pour un stockage de blocs haute performance pour les instances EC2. Il n'est pas adapté à l'archivage de grandes quantités de données rarement consultées, car il est plus coûteux et destiné aux charges de travail nécessitant des performances constantes et à faible latence."
        ]
    },
    {
        "Question Number": "39",
        "Situation": "Une organisation utilise un groupe Auto Scaling (ASG) pour gérer sa flotte d'instances EC2, répondant à des niveaux de demande variables. Leur objectif est d'ajuster automatiquement le nombre d'instances pour maintenir une moyenne d'utilisation du CPU globale de 40%.",
        "Question": "Quel type de politique de mise à l'échelle l'organisation devrait-elle mettre en œuvre pour atteindre cet objectif efficacement, et pourquoi ?",
        "Options": {
            "1": "Mise à l'échelle manuelle : Fournit un contrôle direct sur la capacité souhaitée en fonction de la surveillance en temps réel.",
            "2": "Mise à l'échelle planifiée : Ajuste la capacité à des moments prédéterminés en fonction des tendances de demande prévues.",
            "3": "Mise à l'échelle dynamique avec suivi des cibles : Modifie automatiquement la capacité pour maintenir l'objectif d'utilisation du CPU spécifié.",
            "4": "Mise à l'échelle simple : Augmente ou diminue la capacité en fonction des déclencheurs de seuil CPU individuels."
        },
        "Correct Answer": "Mise à l'échelle dynamique avec suivi des cibles",
        "Explanation": "La mise à l'échelle dynamique avec suivi des cibles est la politique de mise à l'échelle la plus efficace pour l'objectif de l'organisation de maintenir une moyenne d'utilisation du CPU globale de 40%. Cette politique ajuste automatiquement le nombre d'instances EC2 dans le groupe Auto Scaling en fonction des métriques en temps réel, ciblant spécifiquement le niveau d'utilisation du CPU spécifié. En surveillant en continu l'utilisation du CPU et en effectuant des ajustements si nécessaire, l'organisation peut s'assurer qu'elle atteint ses objectifs de performance sans intervention manuelle, optimisant ainsi l'utilisation des ressources et les coûts.",
        "Other Options": [
            "La mise à l'échelle manuelle nécessite une intervention humaine directe pour ajuster la capacité souhaitée, ce qui n'est pas efficace pour répondre à des niveaux de demande variables. Cette approche ne fournit pas l'automatisation nécessaire pour maintenir efficacement un objectif d'utilisation du CPU spécifique.",
            "La mise à l'échelle planifiée ajuste la capacité à des moments prédéterminés, ce qui peut ne pas correspondre aux fluctuations réelles de la demande. Cette méthode est moins réactive aux changements en temps réel de la charge de travail et peut entraîner un surprovisionnement ou un sous-provisionnement des ressources.",
            "La mise à l'échelle simple augmente ou diminue la capacité en fonction des déclencheurs de seuil CPU individuels, ce qui peut entraîner des actions de mise à l'échelle rapides qui peuvent ne pas stabiliser l'utilisation du CPU au niveau moyen souhaité de 40%. Cette méthode manque de la fonctionnalité d'ajustement continu du suivi des cibles, ce qui la rend moins adaptée pour maintenir un niveau d'utilisation spécifique."
        ]
    },
    {
        "Question Number": "40",
        "Situation": "Une entreprise déploie une base de données hautement disponible sur AWS en utilisant Amazon RDS et souhaite garantir un basculement automatique vers une instance de secours en cas de panne. Elle doit également décharger une partie du trafic de lecture et améliorer les performances de lecture.",
        "Question": "Quelle configuration Amazon RDS devraient-ils choisir, et quels avantages cela offre-t-il ? (Choisissez deux.)",
        "Options": {
            "1": "Utilisez l'architecture d'instance Multi-AZ d'Amazon RDS pour la réplication synchrone vers une instance de secours, offrant un basculement automatique dans la même région, avec des sauvegardes effectuées à partir de l'instance de secours pour améliorer les performances.",
            "2": "Configurez l'architecture de cluster Multi-AZ d'Amazon RDS avec un écrivain et deux instances de lecture réparties sur différentes zones de disponibilité, permettant de décharger le trafic de lecture et offrant des temps de basculement plus rapides avec une réplication basée sur les journaux de transactions.",
            "3": "Configurez Amazon RDS dans une seule zone de disponibilité avec des instantanés fréquents vers S3 pour la sauvegarde, garantissant la durabilité des données mais ne fournissant pas de basculement automatique.",
            "4": "Déployez Amazon RDS avec une réplication inter-régionale pour permettre le basculement vers une autre région AWS, réduisant le risque de pannes régionales mais ne prenant pas en charge la réplication synchrone.",
            "5": "Implémentez des réplicas de lecture Amazon RDS dans la même région pour répartir le trafic de lecture et améliorer les performances de lecture, tout en maintenant une configuration Multi-AZ pour le basculement automatique."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Utilisez l'architecture d'instance Multi-AZ d'Amazon RDS pour la réplication synchrone vers une instance de secours, offrant un basculement automatique dans la même région, avec des sauvegardes effectuées à partir de l'instance de secours pour améliorer les performances.",
            "Implémentez des réplicas de lecture Amazon RDS dans la même région pour répartir le trafic de lecture et améliorer les performances de lecture, tout en maintenant une configuration Multi-AZ pour le basculement automatique."
        ],
        "Explanation": "La première réponse correcte est valide car les déploiements Multi-AZ d'Amazon RDS offrent une haute disponibilité et un support de basculement pour les instances de base de données. Ils fonctionnent en répliquant automatiquement les données vers une instance de secours dans une zone de disponibilité (AZ) différente. En cas de panne, Amazon RDS effectue un basculement automatique vers l'instance de secours, permettant de reprendre les opérations de base de données dès que le basculement est terminé. La deuxième réponse correcte est valide car les réplicas de lecture Amazon RDS offrent des performances et une durabilité améliorées pour les instances de base de données (DB). Cette fonctionnalité facilite l'évolutivité élastique au-delà des contraintes de capacité d'une seule instance de base de données pour des charges de travail de base de données à forte lecture.",
        "Other Options": [
            "L'option 'Configurez l'architecture de cluster Multi-AZ d'Amazon RDS avec un écrivain et deux instances de lecture réparties sur différentes zones de disponibilité, permettant de décharger le trafic de lecture et offrant des temps de basculement plus rapides avec une réplication basée sur les journaux de transactions.' est incorrecte car Amazon RDS ne prend pas en charge une configuration avec un écrivain et deux instances de lecture dans un déploiement Multi-AZ.",
            "L'option 'Configurez Amazon RDS dans une seule zone de disponibilité avec des instantanés fréquents vers S3 pour la sauvegarde, garantissant la durabilité des données mais ne fournissant pas de basculement automatique.' est incorrecte car cette configuration ne fournit pas de basculement automatique, ce qui est une exigence dans la question.",
            "L'option 'Déployez Amazon RDS avec une réplication inter-régionale pour permettre le basculement vers une autre région AWS, réduisant le risque de pannes régionales mais ne prenant pas en charge la réplication synchrone.' est incorrecte car la réplication inter-régionale ne prend pas en charge la réplication synchrone, ce qui est nécessaire pour un basculement automatique."
        ]
    },
    {
        "Question Number": "41",
        "Situation": "Une application fonctionnant sur des instances Amazon EC2 dans un sous-réseau public doit communiquer de manière sécurisée avec une base de données Amazon RDS hébergée dans un sous-réseau privé.",
        "Question": "Comment l'application doit-elle être configurée pour permettre un accès sécurisé à la base de données ?",
        "Options": {
            "1": "Ajoutez une règle entrante au groupe de sécurité RDS pour autoriser tout le trafic provenant d'Internet",
            "2": "Utilisez une passerelle NAT pour acheminer le trafic du sous-réseau public vers le sous-réseau privé",
            "3": "Créez une connexion de peering VPC entre les sous-réseaux public et privé",
            "4": "Configurez les instances EC2 pour utiliser l'adresse IP privée de la base de données et autorisez l'accès via le groupe de sécurité RDS"
        },
        "Correct Answer": "Configurez les instances EC2 pour utiliser l'adresse IP privée de la base de données et autorisez l'accès via le groupe de sécurité RDS",
        "Explanation": "Pour permettre un accès sécurisé des instances EC2 dans le sous-réseau public à la base de données RDS dans le sous-réseau privé, les instances EC2 doivent se connecter en utilisant l'adresse IP privée de la base de données. Cela garantit que le trafic ne traverse pas Internet public, maintenant ainsi la sécurité. De plus, le groupe de sécurité RDS doit être configuré pour autoriser le trafic entrant du groupe de sécurité des instances EC2, garantissant que seul le trafic autorisé est permis.",
        "Other Options": [
            "Ajouter une règle entrante au groupe de sécurité RDS pour autoriser tout le trafic provenant d'Internet est peu sûr et n'est pas recommandé. Cela exposerait la base de données RDS à des attaques potentielles de toute source Internet, compromettant sa sécurité.",
            "Utiliser une passerelle NAT pour acheminer le trafic du sous-réseau public vers le sous-réseau privé n'est pas nécessaire dans ce scénario. Les passerelles NAT sont généralement utilisées pour permettre aux instances dans un sous-réseau privé d'accéder à Internet, et non pour la communication entre des sous-réseaux publics et privés au sein du même VPC.",
            "Créer une connexion de peering VPC entre les sous-réseaux public et privé est inutile car les deux sous-réseaux font déjà partie du même VPC. Le peering VPC est utilisé pour connecter différents VPC, et non des sous-réseaux au sein du même VPC."
        ]
    },
    {
        "Question Number": "42",
        "Situation": "Une entreprise de biotechnologie déploie une application haute performance qui nécessite une orchestration de conteneurs à travers plusieurs zones de disponibilité pour la résilience et l'évolutivité. Elle préfère une solution gérée qui s'intègre avec des services AWS comme IAM pour la sécurité et EBS pour le stockage. La plateforme doit également être open-source et cloud-agnostique pour offrir une flexibilité pour de futurs déploiements en dehors d'AWS.",
        "Question": "Quelle configuration de service AWS répondrait le mieux à ces exigences ?",
        "Options": {
            "1": "Amazon ECS avec Fargate et intégration EBS",
            "2": "Amazon EKS avec des groupes de nœuds gérés et un plan de contrôle multi-AZ",
            "3": "Instances Amazon EC2 avec Docker et réplication inter-AZ",
            "4": "AWS Batch avec réplication inter-régionale"
        },
        "Correct Answer": "Amazon EKS avec des groupes de nœuds gérés et un plan de contrôle multi-AZ",
        "Explanation": "Amazon EKS (Elastic Kubernetes Service) est un service Kubernetes géré qui fournit une orchestration de conteneurs à travers plusieurs zones de disponibilité, garantissant résilience et évolutivité. Il s'intègre parfaitement avec des services AWS comme IAM pour la sécurité et EBS pour le stockage. EKS est également open-source et cloud-agnostique, permettant une flexibilité pour de futurs déploiements en dehors d'AWS. Les groupes de nœuds gérés simplifient la gestion des instances EC2 sous-jacentes, et le plan de contrôle multi-AZ améliore la disponibilité et la tolérance aux pannes.",
        "Other Options": [
            "Amazon ECS avec Fargate et intégration EBS est une option viable pour l'orchestration de conteneurs, mais elle n'est pas aussi cloud-agnostique que EKS. ECS est plus étroitement intégré aux services AWS et ne fournit pas le même niveau de flexibilité pour de futurs déploiements en dehors d'AWS.",
            "Les instances Amazon EC2 avec Docker et réplication inter-AZ nécessiteraient plus de gestion manuelle et de configuration par rapport à un service géré comme EKS. Bien qu'elles puissent atteindre les résultats souhaités, elles n'offrent pas le même niveau d'intégration avec les services AWS ni la facilité d'utilisation qu'offre une solution gérée.",
            "AWS Batch avec réplication inter-régionale est conçu pour le traitement par lots plutôt que pour des applications haute performance continues. Il ne fournit pas les capacités d'orchestration de conteneurs nécessaires pour le scénario décrit et n'est pas adapté aux applications nécessitant une mise à l'échelle en temps réel et une résilience."
        ]
    },
    {
        "Question Number": "43",
        "Situation": "Une entreprise de services financiers nécessite une connexion sécurisée et à faible latence entre son centre de données sur site et AWS pour soutenir le traitement des données en temps réel et les opérations de trading. Pour réduire les coûts réseau tout en garantissant la fiabilité, l'entreprise recherche une connexion privée et cohérente pour les transferts de données critiques qui contourne Internet public, évitant ainsi les risques de sécurité et de performance associés.",
        "Question": "Quelle option de connectivité réseau répondrait le mieux à ces besoins ?",
        "Options": {
            "1": "Établir un VPN Site-à-Site AWS, permettant un transfert de données chiffré sur Internet public pour une solution à faible coût",
            "2": "Mettre en place AWS Direct Connect pour une connexion réseau dédiée et privée qui fournit une bande passante sécurisée et cohérente",
            "3": "Utiliser une connexion Internet classique avec AWS Shield pour se protéger contre les attaques DDoS et garantir la sécurité",
            "4": "Configurer le VPC Peering pour établir un lien direct entre le centre de données sur site et AWS, fournissant une connectivité sécurisée"
        },
        "Correct Answer": "Mettre en place AWS Direct Connect pour une connexion réseau dédiée et privée qui fournit une bande passante sécurisée et cohérente",
        "Explanation": "AWS Direct Connect est spécifiquement conçu pour fournir une connexion dédiée et privée entre un centre de données sur site et AWS. Cette option contourne Internet public, garantissant une latence plus faible, une fiabilité accrue et une sécurité améliorée pour les transferts de données critiques. Elle est idéale pour le traitement des données en temps réel et les opérations de trading, car elle offre une bande passante cohérente et des coûts réseau réduits par rapport aux connexions Internet traditionnelles.",
        "Other Options": [
            "Établir un VPN Site-à-Site AWS permet un transfert de données chiffré sur Internet public, ce qui ne répond pas à l'exigence d'une connexion privée. Bien que ce soit une solution à faible coût, elle introduit de la latence et des risques de sécurité potentiels associés au trafic Internet public.",
            "Utiliser une connexion Internet classique avec AWS Shield offre une protection contre les attaques DDoS, mais ne fournit pas la connexion dédiée et privée requise par l'entreprise. Cette option dépend toujours d'Internet public, ce qui peut entraîner des problèmes de performance et des vulnérabilités de sécurité.",
            "Configurer le VPC Peering crée un lien direct entre deux VPC, mais n'établit pas de connexion entre un centre de données sur site et AWS. Ce n'est pas adapté aux besoins de l'entreprise car cela ne fournit pas la connexion réseau dédiée et privée requise pour des transferts de données sécurisés et cohérents."
        ]
    },
    {
        "Question Number": "44",
        "Situation": "Une entreprise conçoit une application résiliente à l'échelle mondiale qui nécessite une haute disponibilité et une faible latence pour les utilisateurs dans plusieurs régions géographiques. Elle souhaite également s'assurer que les pannes dans une région ou une zone de disponibilité (AZ) n'impactent pas la disponibilité de l'application ailleurs.",
        "Question": "Quel service ou fonctionnalité AWS soutient le mieux ces besoins en tirant parti de l'infrastructure mondiale d'AWS ?",
        "Options": {
            "1": "Utiliser Amazon Route 53 avec un routage basé sur la latence pour diriger les utilisateurs vers la région AWS la plus proche, améliorant ainsi la faible latence et permettant l'isolation des pannes régionales.",
            "2": "Déployer l'application dans une seule zone de disponibilité au sein d'une région AWS, en utilisant des instantanés pour sauvegarder les données pour la résilience.",
            "3": "Utiliser Amazon S3 avec une réplication inter-régionale pour refléter les données à travers plusieurs zones de disponibilité au sein d'une seule région.",
            "4": "Déployer globalement en utilisant les emplacements de points de présence Amazon CloudFront pour garantir un accès à faible latence, sans isolation complète des pannes au niveau régional ou AZ."
        },
        "Correct Answer": "Utiliser Amazon Route 53 avec un routage basé sur la latence pour diriger les utilisateurs vers la région AWS la plus proche, améliorant ainsi la faible latence et permettant l'isolation des pannes régionales.",
        "Explanation": "Amazon Route 53 est un service web de système de noms de domaine (DNS) hautement disponible et évolutif qui fournit un routage basé sur la latence. Cette fonctionnalité permet à l'application de diriger les utilisateurs vers la région AWS la plus proche, ce qui minimise la latence et améliore les performances. De plus, en dirigeant le trafic vers différentes régions, cela garantit que si une région subit une panne, les utilisateurs peuvent toujours accéder à l'application depuis une autre région, assurant ainsi l'isolation des pannes régionales et une haute disponibilité à travers les emplacements géographiques.",
        "Other Options": [
            "Déployer l'application dans une seule zone de disponibilité au sein d'une région AWS ne fournit pas la résilience ou la haute disponibilité nécessaires. Si cette AZ échoue, l'application serait complètement indisponible, ce qui contredit l'exigence d'isolation des pannes.",
            "Utiliser Amazon S3 avec une réplication inter-régionale ne traite que de la durabilité et de la disponibilité des données, mais ne garantit pas une faible latence pour les utilisateurs ni ne fournit une isolation des pannes au niveau de l'application. Il est principalement axé sur le stockage des données plutôt que sur les performances de l'application à travers les régions.",
            "Déployer globalement en utilisant les emplacements de points de présence Amazon CloudFront peut améliorer la latence pour la livraison de contenu, mais ne fournit pas une isolation complète des pannes au niveau régional ou AZ. Si le serveur d'origine dans une région spécifique échoue, les utilisateurs peuvent toujours subir des temps d'arrêt, ce qui ne répond pas à l'exigence de haute disponibilité."
        ]
    },
    {
        "Question Number": "45",
        "Situation": "Une entreprise de médias doit livrer du contenu rapidement à un public mondial, réduisant la latence et améliorant l'expérience utilisateur. Elle souhaite également mettre en cache le contenu plus près des utilisateurs pour réduire la charge sur ses serveurs d'origine.",
        "Question": "Quel service AWS répondrait le mieux à ces exigences, et quel avantage offre-t-il ?",
        "Options": {
            "1": "Amazon CloudFront",
            "2": "Amazon S3",
            "3": "AWS Direct Connect",
            "4": "Amazon API Gateway"
        },
        "Correct Answer": "Amazon CloudFront",
        "Explanation": "Amazon CloudFront est un service de réseau de distribution de contenu (CDN) qui met en cache le contenu dans des emplacements de points de présence à travers le monde. Cela permet de réduire la latence et d'accélérer la livraison de contenu aux utilisateurs, car le contenu est servi depuis un emplacement plus proche d'eux. En mettant en cache le contenu plus près des utilisateurs, CloudFront réduit également la charge sur les serveurs d'origine, améliorant ainsi les performances globales et l'expérience utilisateur. Cela en fait le meilleur choix pour l'entreprise de médias cherchant à livrer du contenu rapidement et efficacement à un public mondial.",
        "Other Options": [
            "Amazon S3 est un service de stockage évolutif qui vous permet de stocker et de récupérer n'importe quelle quantité de données. Bien qu'il puisse être utilisé pour stocker du contenu, il ne fournit pas les fonctionnalités de mise en cache et de distribution mondiale qui sont essentielles pour réduire la latence et améliorer l'expérience utilisateur dans ce scénario.",
            "AWS Direct Connect est un service qui fournit une connexion réseau dédiée de vos locaux à AWS. Il est principalement utilisé pour établir une connexion privée aux services AWS, ce qui peut améliorer la bande passante et réduire la latence pour le transfert de données, mais il ne répond pas au besoin de livraison de contenu et de mise en cache pour un public mondial.",
            "Amazon API Gateway est un service pour créer, publier et gérer des API. Bien qu'il puisse aider à construire des applications sans serveur et à gérer les appels d'API, il ne fournit pas les capacités de livraison de contenu et de mise en cache requises pour livrer rapidement du contenu médiatique à un public mondial."
        ]
    },
    {
        "Question Number": "46",
        "Situation": "Un fournisseur de soins de santé stocke des données patients sur AWS et doit se conformer aux réglementations sur la protection des données et la vie privée, qui exigent un contrôle d'accès strict et une gestion du cycle de vie des données. Le fournisseur doit s'assurer que l'accès aux données est limité aux utilisateurs autorisés, que les données sont cryptées et que les anciennes données sont archivées ou supprimées conformément à la politique.",
        "Question": "Quelles actions le fournisseur de soins de santé devrait-il entreprendre pour mettre en œuvre des politiques d'accès sécurisé aux données, de gestion du cycle de vie et de protection ?",
        "Options": {
            "1": "Utiliser des politiques IAM pour contrôler l'accès aux données, mettre en œuvre des politiques de cycle de vie S3 pour gérer l'âge des données et configurer le cryptage via AWS KMS.",
            "2": "Stocker toutes les données dans Amazon Glacier pour s'assurer qu'elles sont archivées et supprimer automatiquement les données après cinq ans.",
            "3": "Activer la journalisation AWS CloudTrail pour archiver automatiquement toutes les données, garantissant ainsi la gestion du cycle de vie des données sans politiques supplémentaires.",
            "4": "Utiliser AWS Shield pour la gestion du cycle de vie et pour contrôler l'accès aux données sensibles en conformité avec les réglementations."
        },
        "Correct Answer": "Utiliser des politiques IAM pour contrôler l'accès aux données, mettre en œuvre des politiques de cycle de vie S3 pour gérer l'âge des données et configurer le cryptage via AWS KMS.",
        "Explanation": "Cette option est correcte car elle répond de manière exhaustive aux besoins du fournisseur de soins de santé en matière d'accès sécurisé aux données, de gestion du cycle de vie et de protection des données. Les politiques IAM (Identity and Access Management) permettent au fournisseur de définir qui peut accéder à des données spécifiques, garantissant ainsi que seuls les utilisateurs autorisés ont accès. Les politiques de cycle de vie S3 permettent au fournisseur d'automatiser la transition des données vers différentes classes de stockage ou de les supprimer après une période spécifiée, gérant ainsi efficacement l'âge des données. De plus, l'utilisation d'AWS KMS (Key Management Service) pour le cryptage garantit que les données sont protégées à la fois au repos et en transit, conformément aux réglementations sur la protection des données.",
        "Other Options": [
            "Cette option est incorrecte car bien que le stockage des données dans Amazon Glacier soit un bon moyen d'archiver les données, cela ne fournit pas une solution complète pour le contrôle d'accès ou le cryptage. Cela ne répond pas non plus au besoin de gérer l'accès aux données ou les politiques de cycle de vie au-delà d'une simple archivage et suppression après cinq ans.",
            "Cette option est incorrecte car l'activation de la journalisation AWS CloudTrail est principalement destinée à l'audit et à la surveillance des appels API et ne gère pas directement le cycle de vie des données ou le contrôle d'accès. CloudTrail n'archive pas automatiquement les données ni n'impose des politiques de gestion du cycle de vie ; cela nécessite des configurations supplémentaires pour atteindre ces objectifs.",
            "Cette option est incorrecte car AWS Shield est un service conçu pour protéger les applications contre les attaques DDoS et ne fournit pas de fonctionnalités pour la gestion du cycle de vie ou le contrôle d'accès. Cela ne répond pas aux besoins spécifiques de protection des données et de conformité aux réglementations décrites dans le scénario."
        ]
    },
    {
        "Question Number": "47",
        "Situation": "Une entreprise de commerce électronique redessine son système de traitement des commandes pour améliorer la fiabilité et l'évolutivité. Le système doit gérer un volume élevé de commandes et garantir que chaque commande est traitée exactement une fois, même en cas de défaillance des composants.",
        "Question": "Quel service AWS le concepteur de solutions devrait-il mettre en œuvre pour découpler efficacement la soumission de commandes des composants de traitement des commandes ?",
        "Options": {
            "1": "Amazon SNS (Simple Notification Service)",
            "2": "Amazon SQS (Simple Queue Service)",
            "3": "AWS Step Functions",
            "4": "Amazon MQ"
        },
        "Correct Answer": "Amazon SQS (Simple Queue Service)",
        "Explanation": "Amazon SQS est un service de mise en file d'attente de messages entièrement géré qui permet de découpler les microservices, les systèmes distribués et les applications sans serveur. Il permet au composant de soumission de commandes d'envoyer des messages à une file d'attente, qui peut ensuite être traitée indépendamment par le composant de traitement des commandes. Cela garantit que chaque commande est traitée exactement une fois, même en cas de défaillance des composants, car SQS fournit une livraison au moins une fois et peut être configuré pour un traitement exactement une fois grâce à l'utilisation de fonctionnalités de dé-duplication. De plus, SQS peut gérer un volume élevé de messages, ce qui le rend adapté aux exigences d'évolutivité du système de commerce électronique.",
        "Other Options": [
            "Amazon SNS (Simple Notification Service) est principalement utilisé pour la messagerie pub/sub et n'est pas conçu pour découpler la soumission de commandes du traitement d'une manière qui garantit un traitement exactement une fois. SNS est mieux adapté pour diffuser des messages à plusieurs abonnés plutôt que de mettre en file d'attente des messages pour traitement.",
            "AWS Step Functions est un service d'orchestration sans serveur qui vous permet de coordonner plusieurs services AWS en flux de travail sans serveur. Bien qu'il puisse gérer des flux de travail complexes, il n'est pas spécifiquement conçu pour découpler des composants comme SQS. Il est plus adapté à l'orchestration de tâches qu'à la gestion de la mise en file d'attente de messages.",
            "Amazon MQ est un service de courtage de messages géré qui prend en charge divers protocoles de messagerie. Bien qu'il puisse être utilisé pour découpler des composants, il est plus complexe à configurer et à gérer par rapport à SQS. De plus, il peut ne pas fournir le même niveau d'évolutivité et de fiabilité pour le traitement des commandes à volume élevé que SQS."
        ]
    },
    {
        "Question Number": "48",
        "Situation": "Une entreprise de médias utilise Amazon RDS pour plusieurs applications dans différents départements. Ils souhaitent suivre et allouer les coûts de base de données à chaque département pour comprendre les dépenses et optimiser l'utilisation.",
        "Question": "Quelle fonctionnalité de gestion des coûts AWS les aiderait le mieux à accomplir cela ? (Choisissez deux.)",
        "Options": {
            "1": "Activer la facturation multi-comptes entre départements",
            "2": "Appliquer des balises d'allocation des coûts à chaque instance de base de données RDS par département",
            "3": "Configurer des budgets AWS séparés pour chaque département",
            "4": "Utiliser le niveau gratuit AWS pour toutes les bases de données des départements",
            "5": "Mettre en œuvre des catégories de coûts AWS pour regrouper les coûts en fonction de critères spécifiques aux départements"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Appliquer des balises d'allocation des coûts à chaque instance de base de données RDS par département",
            "Mettre en œuvre des catégories de coûts AWS pour regrouper les coûts en fonction de critères spécifiques aux départements"
        ],
        "Explanation": "Appliquer des balises d'allocation des coûts à chaque instance de base de données RDS par département permet à l'entreprise de suivre et d'allouer les coûts à chaque département. Ces balises peuvent être utilisées pour catégoriser les coûts dans des rapports de facturation détaillés. Les catégories de coûts AWS peuvent être utilisées pour regrouper les coûts en fonction de critères spécifiques aux départements. Cela permet à l'entreprise de personnaliser la manière dont elle visualise et gère les coûts, et peut les aider à comprendre les coûts associés à l'utilisation des ressources AWS par chaque département.",
        "Other Options": [
            "Activer la facturation multi-comptes entre départements n'est pas la meilleure solution car cela nécessiterait que chaque département ait son propre compte AWS, ce qui peut ne pas être pratique ou efficace. Cette option n'aide pas non plus directement à suivre et à allouer les coûts à chaque département.",
            "Configurer des budgets AWS séparés pour chaque département pourrait aider à gérer les coûts, mais cela n'aide pas directement à suivre et à allouer les coûts à chaque département. C'est plus une question de définition et de gestion des limites de dépenses plutôt que de suivi et d'allocation des coûts.",
            "Utiliser le niveau gratuit AWS pour toutes les bases de données des départements n'est pas une solution viable car le niveau gratuit a des limites d'utilisation, et une entreprise de médias avec plusieurs applications dans différents départements est susceptible de dépasser ces limites. De plus, cette option n'aide pas à suivre et à allouer les coûts."
        ]
    },
    {
        "Question Number": "49",
        "Situation": "Une organisation doit fournir un accès temporaire à un fournisseur tiers pour accéder à certaines ressources dans son compte AWS. L'accès du fournisseur doit être limité à une durée spécifique, et l'organisation souhaite s'assurer que le fournisseur ne peut pas se connecter directement en tant qu'utilisateur IAM.",
        "Question": "Quelles approches l'organisation devrait-elle adopter pour accorder au fournisseur un accès temporaire et sécurisé ? (Choisissez deux.)",
        "Options": {
            "1": "Créer un utilisateur IAM pour le fournisseur avec les autorisations nécessaires et supprimer le compte utilisateur une fois l'accès n'est plus nécessaire.",
            "2": "Configurer un groupe IAM avec les autorisations requises, ajouter le fournisseur au groupe, puis le retirer une fois l'accès n'est plus requis.",
            "3": "Utiliser des rôles IAM et le Service de jetons sécurisés (STS) pour fournir au fournisseur un accès temporaire par le biais d'une hypothèse de rôle.",
            "4": "Attacher une politique au compte racine pour permettre temporairement l'accès au fournisseur, puis la retirer après la durée requise.",
            "5": "Utiliser AWS IAM Identity Center (AWS Single Sign-On) pour attribuer un rôle d'accès temporaire au fournisseur."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Utiliser des rôles IAM et le Service de jetons sécurisés (STS) pour fournir au fournisseur un accès temporaire par le biais d'une hypothèse de rôle.",
            "Utiliser AWS IAM Identity Center (AWS Single Sign-On) pour attribuer un rôle d'accès temporaire au fournisseur."
        ],
        "Explanation": "Les rôles IAM et le Service de jetons sécurisés (STS) sont conçus pour fournir un accès temporaire aux ressources AWS. En utilisant l'hypothèse de rôle, le fournisseur peut se voir accorder les autorisations nécessaires sans avoir à créer un utilisateur IAM permanent. Les autorisations peuvent être révoquées simplement en supprimant le rôle. AWS IAM Identity Center (AWS Single Sign-On) permet également l'attribution d'accès temporaire, qui peut être révoqué une fois que l'accès du fournisseur n'est plus nécessaire. Ces deux méthodes garantissent que le fournisseur ne peut pas se connecter directement en tant qu'utilisateur IAM, répondant ainsi aux exigences de l'organisation.",
        "Other Options": [
            "Créer un utilisateur IAM pour le fournisseur et le supprimer une fois l'accès n'est plus nécessaire n'est pas une approche recommandée car cela implique de créer et de gérer des utilisateurs IAM permanents, ce qui peut représenter un risque de sécurité. De plus, cela ne prévient pas le fournisseur de se connecter directement en tant qu'utilisateur IAM.",
            "Configurer un groupe IAM et ajouter le fournisseur au groupe n'est également pas une approche recommandée. Bien que cela permette de gérer les autorisations au niveau du groupe, cela implique toujours de créer un utilisateur IAM permanent pour le fournisseur, ce qui n'est pas souhaité dans ce scénario.",
            "Attacher une politique au compte racine pour permettre temporairement l'accès au fournisseur n'est pas une bonne pratique. Le compte racine a un accès complet à toutes les ressources du compte AWS, et il n'est pas recommandé de l'utiliser pour des interactions quotidiennes ou pour accorder un accès temporaire à des tiers."
        ]
    },
    {
        "Question Number": "50",
        "Situation": "Une société de production médiatique doit migrer 20 To de séquences vidéo haute définition archivées de son stockage sur site vers AWS pour un stockage à long terme et un traitement occasionnel. Les données sont situées sur plusieurs sites, et la société préfère une solution à la fois économique et offrant une certaine capacité de traitement des données pendant le processus de transfert.",
        "Question": "Quelle solution de migration de données AWS conviendrait le mieux aux besoins de la société ?",
        "Options": {
            "1": "AWS Snowball avec des appareils de 80 To",
            "2": "AWS Snowball Edge avec des appareils optimisés pour le stockage",
            "3": "AWS Snowmobile",
            "4": "AWS Direct Connect avec une connexion dédiée"
        },
        "Correct Answer": "AWS Snowball Edge avec des appareils optimisés pour le stockage",
        "Explanation": "AWS Snowball Edge avec des appareils optimisés pour le stockage est la meilleure solution pour les besoins de la société car elle permet le transfert de grandes quantités de données (jusqu'à 100 To par appareil) tout en offrant des capacités de traitement sur l'appareil. Cela signifie que la société peut effectuer un certain traitement des données pendant le transfert, ce qui est essentiel compte tenu de leur besoin de traitement occasionnel des séquences archivées. De plus, les appareils Snowball Edge sont conçus pour le calcul en périphérie, ce qui les rend adaptés pour gérer les données sur plusieurs sites de manière efficace.",
        "Other Options": [
            "AWS Snowball avec des appareils de 80 To n'est pas la meilleure option car bien qu'il puisse gérer de grands transferts de données, il ne fournit pas le même niveau de capacités de traitement que les appareils Snowball Edge. La société a spécifiquement besoin d'une certaine capacité de traitement pendant le transfert, ce que Snowball ne propose pas.",
            "AWS Snowmobile est une option viable pour des migrations de données extrêmement grandes (jusqu'à 100 Po), mais elle est plus adaptée aux scénarios où les données sont situées sur un seul site et nécessitent un transfert physique à grande échelle. Étant donné que les données sont réparties sur plusieurs sites et que la société préfère une solution plus flexible, Snowmobile n'est pas la meilleure option.",
            "AWS Direct Connect fournit une connexion réseau dédiée à AWS, ce qui peut faciliter le transfert de données mais ne fournit pas intrinsèquement un moyen de migrer de grandes quantités de données de manière efficace ou d'offrir des capacités de traitement pendant le transfert. Cette option serait probablement plus coûteuse et moins efficace pour les besoins spécifiques de la société par rapport à l'utilisation de Snowball Edge."
        ]
    },
    {
        "Question Number": "51",
        "Situation": "Une entreprise configure la sécurité réseau pour son environnement AWS et souhaite comprendre le comportement des pare-feu d'état et sans état. L'équipe de sécurité doit permettre aux clients d'initier des connexions HTTPS vers le serveur web de l'entreprise et s'assurer que les réponses sont renvoyées correctement.",
        "Question": "Comment l'entreprise devrait-elle configurer les règles de sécurité pour permettre cette connexion tout en comprenant la différence entre le filtrage d'état et sans état ?",
        "Options": {
            "1": "Utiliser un pare-feu d'état qui permet automatiquement les réponses entrantes à une demande sortante, en configurant uniquement une règle sortante pour HTTPS (port 443) du client vers le serveur.",
            "2": "Utiliser un pare-feu sans état, en configurant à la fois des règles sortantes et entrantes sur le port 443 pour permettre le trafic HTTPS du client vers le serveur et la réponse du serveur vers le client.",
            "3": "Utiliser un pare-feu d'état, en configurant à la fois des règles sortantes et entrantes sur le port 443, car les pare-feu d'état ne suivent pas automatiquement les états de connexion.",
            "4": "Utiliser un pare-feu sans état, en configurant uniquement une règle entrante sur le port 443, car la réponse sortante sera autorisée automatiquement."
        },
        "Correct Answer": "Utiliser un pare-feu d'état qui permet automatiquement les réponses entrantes à une demande sortante, en configurant uniquement une règle sortante pour HTTPS (port 443) du client vers le serveur.",
        "Explanation": "Un pare-feu d'état suit l'état des connexions actives et permet automatiquement le trafic de retour pour les connexions établies. Dans ce scénario, lorsque le client initie une connexion HTTPS vers le serveur web, le pare-feu d'état permettra la réponse entrante du serveur vers le client sans avoir besoin d'une règle entrante séparée. Par conséquent, seule une règle sortante pour le trafic HTTPS du client vers le serveur est nécessaire, car le pare-feu d'état gérera automatiquement le trafic entrant correspondant.",
        "Other Options": [
            "Utiliser un pare-feu sans état nécessite des règles explicites pour le trafic entrant et sortant. Par conséquent, configurer uniquement une règle sortante pour HTTPS ne permettrait pas à la réponse du serveur d'atteindre le client, car le pare-feu sans état ne suit pas les états de connexion et bloquerait la réponse entrante.",
            "Cette option indique incorrectement que les pare-feu d'état ne suivent pas automatiquement les états de connexion. En fait, les pare-feu d'état suivent les états de connexion, c'est pourquoi seule une règle sortante est nécessaire pour la demande initiale, permettant ainsi la réponse entrante automatiquement.",
            "Cette option est incorrecte car un pare-feu sans état ne permet pas automatiquement les réponses sortantes. Il nécessite des règles explicites pour les deux directions. Configurer uniquement une règle entrante ne permettrait pas à la réponse du serveur d'atteindre le client, car la demande sortante n'aurait pas de règle correspondante pour autoriser le trafic de retour."
        ]
    },
    {
        "Question Number": "52",
        "Situation": "Une entreprise de vente au détail souhaite collecter des données de clickstream en temps réel depuis son site e-commerce à fort trafic afin d'analyser les comportements des utilisateurs et d'améliorer l'engagement client. Les données doivent être transformées à la volée, y compris le nettoyage et le marquage des données, avant d'être livrées à Amazon Redshift pour l'analyse et à Amazon S3 pour l'archivage à long terme. L'entreprise recherche une solution gérée et évolutive capable de gérer un flux de données continu avec un minimum de frais opérationnels et des capacités de transformation en temps réel.",
        "Question": "Quelle configuration de service AWS répondrait le mieux à ces exigences ?",
        "Options": {
            "1": "Utiliser Amazon Kinesis Data Streams en conjonction avec AWS Lambda pour transformer les données en temps réel puis les livrer à Amazon S3 pour le stockage",
            "2": "Mettre en œuvre Amazon Kinesis Data Firehose avec une fonction AWS Lambda pour la transformation en temps réel et le configurer pour livrer les données transformées à la fois à Amazon Redshift et à Amazon S3",
            "3": "Utiliser Amazon S3 comme principal stockage de données et traiter les transformations de données par lots à l'aide d'AWS Glue avant de les charger dans Amazon Redshift",
            "4": "Configurer Amazon Managed Streaming for Apache Kafka pour gérer l'ingestion de données en streaming, avec AWS Lambda effectuant la transformation puis livrant les données à Redshift"
        },
        "Correct Answer": "Mettre en œuvre Amazon Kinesis Data Firehose avec une fonction AWS Lambda pour la transformation en temps réel et le configurer pour livrer les données transformées à la fois à Amazon Redshift et à Amazon S3",
        "Explanation": "Amazon Kinesis Data Firehose est spécifiquement conçu pour l'ingestion et la transformation de données en temps réel. Il permet une intégration transparente avec AWS Lambda, qui peut être utilisé pour effectuer le nettoyage et le marquage des données à la volée. Cette configuration permet à l'entreprise de vente au détail de collecter et de traiter efficacement les données de clickstream en temps réel, livrant les données transformées à la fois à Amazon Redshift pour l'analyse et à Amazon S3 pour le stockage à long terme. Cette solution est gérée et évolutive, minimisant les frais opérationnels tout en répondant à l'exigence d'un flux de données continu.",
        "Other Options": [
            "Utiliser Amazon Kinesis Data Streams avec AWS Lambda est une option viable pour le traitement de données en temps réel ; cependant, cela nécessite des étapes supplémentaires pour gérer la livraison des données à la fois à Amazon Redshift et à Amazon S3, ce qui le rend moins direct que l'utilisation de Kinesis Data Firehose, qui peut gérer cela directement.",
            "Utiliser Amazon S3 comme principal stockage de données et traiter les transformations de données par lots avec AWS Glue ne répond pas à l'exigence de transformation de données en temps réel, car cela repose sur le traitement par lots, ce qui introduit de la latence et n'est pas adapté à un flux de données continu.",
            "Configurer Amazon Managed Streaming for Apache Kafka peut gérer efficacement l'ingestion de données en streaming, mais cela ajoute de la complexité en termes de gestion et de frais opérationnels par rapport à Kinesis Data Firehose. De plus, cela nécessiterait plus de configuration pour s'intégrer avec AWS Lambda pour les transformations et pour livrer les données à Redshift."
        ]
    },
    {
        "Question Number": "53",
        "Situation": "Une institution financière exploite des applications critiques qui nécessitent une connectivité stable, à large bande et à faible latence entre ses centres de données sur site et AWS pour soutenir le traitement de données en temps réel et les activités de trading. Ils souhaitent s'assurer que tous les transferts de données se font par une connexion sécurisée et privée qui contourne Internet public, protégeant ainsi contre les risques de sécurité potentiels et la variabilité des performances.",
        "Question": "Quelle option répondrait le mieux à leurs exigences ?",
        "Options": {
            "1": "Utiliser une ligne louée à haute vitesse d'un fournisseur de télécommunications directement vers AWS",
            "2": "Établir un VPN Site-à-Site AWS sur Internet public",
            "3": "Déployer AWS Direct Connect pour une connexion réseau privée et dédiée",
            "4": "Configurer un protocole de transfert de fichiers (FTP) chiffré pour des synchronisations de données périodiques"
        },
        "Correct Answer": "Déployer AWS Direct Connect pour une connexion réseau privée et dédiée",
        "Explanation": "AWS Direct Connect fournit une connexion dédiée et privée entre les centres de données sur site et AWS. Cette option répond aux exigences de l'institution financière en matière de connectivité stable, à large bande et à faible latence, essentielles pour des applications critiques comme le traitement de données en temps réel et le trading. Direct Connect contourne Internet public, réduisant considérablement les risques de sécurité et la variabilité des performances, ce qui en fait le meilleur choix pour des transferts de données sécurisés et fiables.",
        "Other Options": [
            "Utiliser une ligne louée à haute vitesse d'un fournisseur de télécommunications directement vers AWS peut offrir une large bande, mais cela ne garantit pas le même niveau d'intégration et de fiabilité qu'AWS Direct Connect. De plus, cela peut impliquer des coûts plus élevés et une complexité dans la configuration et la gestion.",
            "Établir un VPN Site-à-Site AWS sur Internet public offre un chiffrement et une sécurité, mais ne fournit pas les exigences de faible latence et de large bande nécessaires pour des applications en temps réel. Les VPN peuvent également être sujets à des variations de performance en raison de leur dépendance à Internet public.",
            "Configurer un protocole de transfert de fichiers (FTP) chiffré pour des synchronisations de données périodiques ne répond pas à l'exigence de traitement de données en temps réel et d'activités de trading. Cette méthode est plus adaptée au traitement par lots plutôt qu'au transfert de données continu et à faible latence, qui est critique pour les opérations de l'institution."
        ]
    },
    {
        "Question Number": "54",
        "Situation": "Une entreprise possède deux comptes AWS : un compte de développement et un compte de production. Les développeurs du compte de développement ont besoin d'un accès temporaire à des ressources spécifiques dans le compte de production à des fins de test. L'entreprise souhaite appliquer le principe du moindre privilège et s'assurer que les développeurs ne peuvent accéder qu'aux ressources nécessaires pour une durée limitée.",
        "Question": "Quelle approche l'entreprise devrait-elle utiliser pour atteindre cet objectif ?",
        "Options": {
            "1": "Créer des utilisateurs IAM dans le compte de production et attacher des politiques qui accordent l'accès aux ressources requises.",
            "2": "Utiliser AWS Security Token Service (STS) pour créer des identifiants de sécurité temporaires, permettant aux développeurs d'assumer un rôle dans le compte de production avec des autorisations pour accéder aux ressources nécessaires.",
            "3": "Mettre en place un accès inter-comptes en créant un groupe IAM dans le compte de développement et en attachant une politique qui accorde l'accès aux ressources dans le compte de production.",
            "4": "Utiliser AWS Organizations pour répliquer automatiquement les autorisations du compte de développement vers le compte de production pour tous les développeurs."
        },
        "Correct Answer": "Utiliser AWS Security Token Service (STS) pour créer des identifiants de sécurité temporaires, permettant aux développeurs d'assumer un rôle dans le compte de production avec des autorisations pour accéder aux ressources nécessaires.",
        "Explanation": "Utiliser AWS Security Token Service (STS) pour créer des identifiants de sécurité temporaires est la meilleure approche pour ce scénario car cela permet aux développeurs d'assumer un rôle dans le compte de production avec des autorisations spécifiques. Cette méthode respecte le principe du moindre privilège en accordant l'accès uniquement aux ressources nécessaires pour une durée limitée. Les identifiants temporaires fournis par STS expirent après une durée spécifiée, garantissant que l'accès n'est pas permanent et réduisant le risque d'accès non autorisé aux ressources de production.",
        "Other Options": [
            "Créer des utilisateurs IAM dans le compte de production et attacher des politiques qui accordent l'accès aux ressources requises n'est pas idéal car cela impliquerait de créer des comptes utilisateurs permanents, ce qui contredit le principe du moindre privilège et ne fournit pas d'accès temporaire.",
            "Mettre en place un accès inter-comptes en créant un groupe IAM dans le compte de développement et en attachant une politique qui accorde l'accès aux ressources dans le compte de production est incorrect car les groupes IAM ne prennent pas en charge les autorisations inter-comptes directement. Au lieu de cela, des rôles devraient être utilisés pour l'accès inter-comptes.",
            "Utiliser AWS Organizations pour répliquer automatiquement les autorisations du compte de développement vers le compte de production pour tous les développeurs n'est pas approprié car cela accorderait un accès plus large que nécessaire, violant le principe du moindre privilège. Cette approche ne permet pas le contrôle granulaire requis pour un accès temporaire."
        ]
    },
    {
        "Question Number": "55",
        "Situation": "Une entreprise souhaite concevoir une architecture d'application évolutive capable de gérer de grands volumes de tâches asynchrones et nécessite que les composants communiquent sans dépendances directes entre eux.",
        "Question": "Quel service AWS serait le plus approprié pour mettre en œuvre une architecture décentralisée et pilotée par des événements, et pourquoi ?",
        "Options": {
            "1": "Amazon SQS",
            "2": "Amazon RDS",
            "3": "Amazon DynamoDB",
            "4": "AWS Lambda"
        },
        "Correct Answer": "Amazon SQS",
        "Explanation": "Amazon SQS (Simple Queue Service) est conçu spécifiquement pour découpler les composants d'une application distribuée. Il permet une communication asynchrone entre différentes parties d'une application en utilisant des files d'attente de messages. Cela signifie que les composants peuvent envoyer des messages à la file d'attente sans avoir besoin de connaître les autres composants qui traiteront ces messages, permettant ainsi une architecture décentralisée. SQS peut gérer de grands volumes de messages, ce qui le rend adapté aux applications nécessitant évolutivité et fiabilité dans le traitement des tâches asynchrones.",
        "Other Options": [
            "Amazon RDS (Relational Database Service) est un service de base de données relationnelle géré principalement utilisé pour stocker des données structurées. Il ne fournit pas l'architecture pilotée par des événements ni le découplage des composants que SQS offre, car il nécessite des connexions directes entre l'application et la base de données.",
            "Amazon DynamoDB est un service de base de données NoSQL qui offre des performances rapides et prévisibles avec une évolutivité sans faille. Bien qu'il puisse gérer de grands volumes de données, il n'est pas spécifiquement conçu pour gérer des tâches asynchrones ou pour découpler des composants dans une architecture pilotée par des événements comme SQS.",
            "AWS Lambda est un service de calcul sans serveur qui exécute du code en réponse à des événements. Bien qu'il puisse faire partie d'une architecture pilotée par des événements, il ne sert pas de service de messagerie à lui seul. Il est souvent utilisé en conjonction avec SQS ou d'autres services pour traiter des messages, mais ne fournit pas le mécanisme de mise en file d'attente qui permet un découplage entre les composants."
        ]
    },
    {
        "Question Number": "56",
        "Situation": "Un architecte de solutions doit s'assurer que seuls certains rôles IAM au sein du compte AWS de l'entreprise peuvent accéder à des données sensibles spécifiques stockées dans Amazon S3. L'entreprise suit un modèle d'accès strict basé sur le principe du moindre privilège.",
        "Question": "Quelle méthode est la PLUS appropriée pour faire respecter cette exigence ?",
        "Options": {
            "1": "Utiliser des politiques de bucket S3 qui accordent l'accès uniquement à des rôles IAM spécifiques",
            "2": "Activer la suppression MFA sur le bucket S3",
            "3": "Configurer une alarme Amazon CloudWatch pour les tentatives d'accès non autorisées",
            "4": "Activer l'accélération de transfert S3"
        },
        "Correct Answer": "Utiliser des politiques de bucket S3 qui accordent l'accès uniquement à des rôles IAM spécifiques",
        "Explanation": "Utiliser des politiques de bucket S3 pour accorder l'accès uniquement à des rôles IAM spécifiques est la méthode la plus appropriée pour faire respecter l'exigence de limiter l'accès aux données sensibles. Les politiques de bucket permettent un contrôle granulaire sur qui peut accéder aux données stockées dans le bucket S3, en accord avec le modèle d'accès basé sur le moindre privilège. En spécifiant quels rôles IAM peuvent accéder au bucket, l'architecte de solutions peut s'assurer que seuls les rôles autorisés disposent des permissions nécessaires pour accéder aux données sensibles, renforçant ainsi la sécurité.",
        "Other Options": [
            "Activer la suppression MFA sur le bucket S3 est une fonctionnalité de sécurité qui empêche la suppression accidentelle d'objets dans le bucket et nécessite une authentification multi-facteurs pour les opérations de suppression. Bien qu'elle ajoute une couche de sécurité, elle ne contrôle pas l'accès aux données elles-mêmes, ce qui la rend moins pertinente pour l'exigence de restriction d'accès basée sur les rôles IAM.",
            "Configurer une alarme Amazon CloudWatch pour les tentatives d'accès non autorisées peut aider à surveiller et à alerter sur des activités suspectes, mais cela ne prévient pas l'accès. Cette approche est davantage axée sur la détection plutôt que sur l'application du contrôle d'accès, qui est la préoccupation principale dans ce scénario.",
            "Activer l'accélération de transfert S3 améliore la vitesse de transfert des données vers et depuis S3 mais n'est pas lié au contrôle d'accès. Cette option ne répond pas à l'exigence de restriction d'accès aux données sensibles en fonction des rôles IAM."
        ]
    },
    {
        "Question Number": "57",
        "Situation": "Un portail d'actualités en ligne reçoit des millions d'interactions d'utilisateurs chaque jour, y compris des clics, des vues et des partages. Ces interactions doivent être ingérées en temps réel pour l'analyse et la livraison de contenu personnalisé. L'entreprise s'attend à ce que le volume d'interactions croisse rapidement au cours de l'année prochaine.",
        "Question": "Quel modèle d'ingestion de données l'architecte de solutions devrait-il concevoir pour gérer ce scénario efficacement ?",
        "Options": {
            "1": "Ingestion par lots avec des transferts de données quotidiens",
            "2": "Ingestion en streaming en temps réel",
            "3": "Téléchargements manuels de données via la console de gestion AWS",
            "4": "Ingestion programmée utilisant AWS Data Pipeline"
        },
        "Correct Answer": "Ingestion en streaming en temps réel",
        "Explanation": "L'ingestion en streaming en temps réel est le modèle le plus adapté à ce scénario car le portail d'actualités en ligne nécessite un traitement immédiat des interactions des utilisateurs telles que les clics, les vues et les partages. Étant donné la croissance rapide attendue du volume d'interactions, une approche en temps réel permet un flux de données continu et une analyse immédiate, facilitant la livraison de contenu personnalisé et des insights en temps opportun. Cette méthode garantit que les données sont traitées à mesure qu'elles arrivent, ce qui est essentiel pour maintenir une expérience utilisateur engageante et s'adapter au comportement des utilisateurs en temps réel.",
        "Other Options": [
            "L'ingestion par lots avec des transferts de données quotidiens n'est pas appropriée pour ce scénario car elle implique de collecter des données sur une période et de les traiter en une seule fois. Cela entraînerait des retards dans l'analyse et la livraison de contenu, ce qui n'est pas adapté à une plateforme qui repose sur des interactions utilisateur en temps réel.",
            "Les téléchargements manuels de données via la console de gestion AWS sont impraticables pour gérer des millions d'interactions quotidiennes. Cette méthode est laborieuse et ne s'adapte pas bien, ce qui la rend inadaptée à un environnement à fort volume où l'automatisation et la rapidité sont essentielles.",
            "L'ingestion programmée utilisant AWS Data Pipeline peut offrir un certain niveau d'automatisation, mais elle fonctionne toujours sur un calendrier prédéfini plutôt qu'en temps réel. Cela ne répondrait pas aux besoins du portail d'actualités pour un traitement immédiat des données et pourrait entraîner des analyses et une livraison de contenu obsolètes."
        ]
    },
    {
        "Question Number": "58",
        "Situation": "Une startup construit une plateforme d'analytique en temps réel sur AWS. La plateforme doit ingérer des données provenant de milliers de dispositifs IoT, traiter les données en temps réel et stocker les données traitées pour une analyse ultérieure. La solution doit être hautement évolutive et minimiser les frais d'exploitation.",
        "Question": "Quelle combinaison de services AWS le concepteur de solutions devrait-il utiliser pour construire cette plateforme ? (Choisissez DEUX.)",
        "Options": {
            "1": "AWS Lambda",
            "2": "Amazon Kinesis Data Streams",
            "3": "Amazon RDS for MySQL",
            "4": "Amazon S3",
            "5": "Amazon QuickSight"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "AWS Lambda",
            "Amazon Kinesis Data Streams"
        ],
        "Explanation": "AWS Lambda est un service de calcul sans serveur qui vous permet d'exécuter votre code sans provisionner ou gérer des serveurs. Il peut être utilisé pour traiter les données en temps réel, ce qui est une exigence dans le scénario donné. Amazon Kinesis Data Streams est un service de streaming de données en temps réel, évolutif et durable, qui peut capturer en continu des gigaoctets de données par seconde provenant de centaines de milliers de sources telles que les flux de clics de sites Web, les flux d'événements de bases de données, les transactions financières, les flux de médias sociaux, les journaux informatiques et les événements de suivi de localisation. Cela en fait un choix approprié pour ingérer des données provenant de milliers de dispositifs IoT en temps réel.",
        "Other Options": [
            "Amazon RDS for MySQL est un service de base de données relationnelle. Bien qu'il puisse être utilisé pour stocker des données, il n'est pas conçu pour l'ingestion et le traitement de données en temps réel, ce qui est une exigence dans le scénario donné.",
            "Amazon S3 est un service de stockage. Bien qu'il puisse être utilisé pour stocker des données traitées, il ne prend pas en charge l'ingestion et le traitement de données en temps réel.",
            "Amazon QuickSight est un service d'analytique commerciale. Bien qu'il puisse être utilisé pour analyser des données, il ne prend pas en charge l'ingestion, le traitement et le stockage de données en temps réel, qui sont des exigences dans le scénario donné."
        ]
    },
    {
        "Question Number": "59",
        "Situation": "Une entreprise utilise des instances Amazon EC2 pour héberger une application héritée. L'application nécessite un accès à des fichiers stockés sur un système de fichiers réseau et doit prendre en charge plusieurs connexions simultanées avec une faible latence. L'entreprise a besoin d'une solution gérée qui offre un stockage évolutif avec une haute disponibilité.",
        "Question": "Quel service AWS le concepteur de solutions devrait-il recommander ?",
        "Options": {
            "1": "Amazon S3",
            "2": "Amazon EFS (Elastic File System)",
            "3": "Amazon FSx for Windows File Server",
            "4": "Amazon EBS (Elastic Block Store)"
        },
        "Correct Answer": "Amazon EFS (Elastic File System)",
        "Explanation": "Amazon EFS (Elastic File System) est un service de stockage de fichiers entièrement géré, évolutif et élastique, conçu pour être utilisé avec des instances Amazon EC2. Il prend en charge plusieurs connexions simultanées et fournit un accès à faible latence aux fichiers, ce qui le rend idéal pour les applications nécessitant un accès partagé à un système de fichiers. EFS s'adapte automatiquement à mesure que des fichiers sont ajoutés ou supprimés, garantissant une haute disponibilité et durabilité, ce qui correspond parfaitement aux exigences de l'application héritée décrite dans la situation.",
        "Other Options": [
            "Amazon S3 est un service de stockage d'objets qui n'est pas adapté aux applications nécessitant une interface de système de fichiers et un accès à faible latence. Il est conçu pour stocker et récupérer de grandes quantités de données non structurées, mais ne prend pas en charge les sémantiques de système de fichiers nécessaires pour un accès simultané par plusieurs instances.",
            "Amazon FSx for Windows File Server fournit un système de fichiers Windows entièrement géré qui prend en charge le protocole SMB et est adapté aux applications basées sur Windows. Bien qu'il offre une haute disponibilité et évolutivité, il est spécifiquement conçu pour les environnements Windows et peut ne pas être nécessaire si l'application héritée ne nécessite pas de fonctionnalités spécifiques à Windows.",
            "Amazon EBS (Elastic Block Store) fournit un stockage par blocs pour les instances EC2 et est adapté aux cas d'utilisation à instance unique. Il ne prend pas en charge plusieurs connexions simultanées provenant de différentes instances, ce qui est une exigence pour l'application héritée. EBS n'est également pas un système de fichiers géré, car il nécessite une gestion manuelle des volumes."
        ]
    },
    {
        "Question Number": "60",
        "Situation": "Une entreprise d'analytique dispose de plusieurs instances Amazon EC2 dans un sous-réseau privé qui nécessitent un accès Internet pour les mises à jour logicielles et la synchronisation de données externes. Pour maintenir leurs coûts réseau bas, elle envisage des options pour mettre en place une Traduction d'Adresse Réseau (NAT) afin de permettre l'accès Internet sortant pour ces instances. L'entreprise souhaite une approche rentable pour fournir une connectivité Internet sans déployer une infrastructure excessive.",
        "Question": "Quelle approche serait la plus rentable ?",
        "Options": {
            "1": "Déployer une passerelle NAT dans chaque zone de disponibilité, assurant la redondance et l'équilibrage du trafic entre plusieurs zones",
            "2": "Utiliser une seule instance NAT pour gérer le trafic de toutes les instances EC2 dans le sous-réseau privé, minimisant les coûts d'infrastructure",
            "3": "Déployer des passerelles NAT séparées pour chaque VPC, permettant à chaque réseau virtuel de gérer ses propres besoins d'accès Internet de manière indépendante",
            "4": "Utiliser des passerelles NAT avec des IP Elastic dans plusieurs régions pour fournir un accès Internet et garantir une haute disponibilité"
        },
        "Correct Answer": "Utiliser une seule instance NAT pour gérer le trafic de toutes les instances EC2 dans le sous-réseau privé, minimisant les coûts d'infrastructure",
        "Explanation": "Utiliser une seule instance NAT est la solution la plus rentable pour fournir un accès Internet à plusieurs instances EC2 dans un sous-réseau privé. Les instances NAT sont généralement moins chères que les passerelles NAT, et une seule instance peut gérer le trafic sortant pour toutes les instances du sous-réseau. Cette approche minimise les coûts d'infrastructure tout en permettant une connectivité Internet nécessaire pour les mises à jour logicielles et la synchronisation des données.",
        "Other Options": [
            "Déployer une passerelle NAT dans chaque zone de disponibilité fournirait de la redondance et un équilibrage de charge, mais cela augmenterait considérablement les coûts en raison des tarifs plus élevés des passerelles NAT par rapport aux instances NAT. Cette option n'est pas rentable pour les besoins de l'entreprise.",
            "Déployer des passerelles NAT séparées pour chaque VPC entraînerait également des coûts supplémentaires, chaque passerelle engendrant des frais. Cette approche est inutile si l'objectif est de minimiser les coûts d'infrastructure tout en fournissant un accès Internet.",
            "Utiliser des passerelles NAT avec des IP Elastic dans plusieurs régions garantirait une haute disponibilité mais serait très coûteux. Les passerelles NAT sont facturées à l'heure et par Go de données traitées, rendant cette option impraticable pour une exigence sensible aux coûts."
        ]
    },
    {
        "Question Number": "61",
        "Situation": "Une entreprise utilise plusieurs comptes AWS pour gérer différents environnements, tels que le développement, les tests et la production. L'équipe de sécurité souhaite appliquer des politiques de sécurité cohérentes sur tous les comptes tout en permettant une gestion et une surveillance centralisées.",
        "Question": "Quel service AWS l'entreprise devrait-elle utiliser pour mettre en place un environnement multi-comptes sécurisé, et quelle fonctionnalité peut aider à appliquer des contrôles de sécurité spécifiques sur chaque compte ?",
        "Options": {
            "1": "Utiliser AWS Identity and Access Management (IAM) avec des limites de permission pour chaque compte.",
            "2": "Utiliser AWS Control Tower avec des politiques de contrôle de service (SCP) pour gérer les politiques de sécurité entre les comptes.",
            "3": "Mettre en œuvre AWS Shield pour appliquer des règles de sécurité sur les différents comptes.",
            "4": "Utiliser Amazon GuardDuty pour gérer et appliquer des politiques de sécurité entre les comptes."
        },
        "Correct Answer": "Utiliser AWS Control Tower avec des politiques de contrôle de service (SCP) pour gérer les politiques de sécurité entre les comptes.",
        "Explanation": "AWS Control Tower est spécifiquement conçu pour aider les organisations à configurer et à gouverner un environnement AWS multi-comptes sécurisé. Il fournit un moyen centralisé de gérer les comptes et d'appliquer des politiques à travers eux. Les politiques de contrôle de service (SCP) sont une fonctionnalité d'AWS Organizations qui vous permet de définir des garde-fous de permission pour vos comptes, garantissant que des contrôles de sécurité spécifiques sont appliqués de manière cohérente sur tous les comptes. Cela en fait le meilleur choix pour le besoin de l'entreprise d'appliquer des politiques de sécurité cohérentes tout en permettant une gestion et une surveillance centralisées.",
        "Other Options": [
            "AWS Identity and Access Management (IAM) avec des limites de permission est utile pour gérer les permissions au sein d'un seul compte, mais ne fournit pas un moyen centralisé d'appliquer des politiques sur plusieurs comptes. Par conséquent, il n'est pas adapté à l'environnement multi-comptes de l'entreprise.",
            "AWS Shield est un service de protection DDoS géré qui aide à protéger les applications contre les attaques DDoS. Bien qu'il améliore la sécurité, il ne fournit pas de mécanisme pour appliquer des politiques de sécurité sur plusieurs comptes, ce qui le rend inadapté aux besoins de l'entreprise.",
            "Amazon GuardDuty est un service de détection des menaces qui surveille en continu les activités malveillantes et les comportements non autorisés. Bien qu'il fournisse des informations sur la sécurité, il n'applique pas de politiques de sécurité entre les comptes, ce qui est une exigence clé pour l'entreprise."
        ]
    },
    {
        "Question Number": "62",
        "Situation": "Une entreprise conçoit un système hautement disponible et tolérant aux pannes qui doit gérer des pics de trafic et des pannes potentielles de composants tout en maintenant un service cohérent. Le système utilisera des microservices et doit garantir la résilience et l'évolutivité.",
        "Question": "Quel modèle de conception distribué l'entreprise devrait-elle utiliser pour atteindre cet objectif ?",
        "Options": {
            "1": "Utiliser le modèle de disjoncteur pour s'assurer que les pannes de service sont détectées et gérées de manière proactive, permettant au système de maintenir ses performances pendant les pannes partielles.",
            "2": "Utiliser le modèle monolithique pour réduire la complexité et s'assurer que tous les composants sont étroitement intégrés et dépendent les uns des autres.",
            "3": "Utiliser le modèle de réessai pour réessayer continuellement les opérations échouées, même si le système subit un trafic élevé ou des pannes de composants.",
            "4": "Utiliser le modèle d'état pour s'assurer que les services conservent les données de session entre les requêtes, leur permettant de gérer les pics de trafic."
        },
        "Correct Answer": "Utiliser le modèle de disjoncteur pour s'assurer que les pannes de service sont détectées et gérées de manière proactive, permettant au système de maintenir ses performances pendant les pannes partielles.",
        "Explanation": "Le modèle de disjoncteur est conçu pour détecter les pannes et empêcher le système d'effectuer des appels à un service susceptible d'échouer. Cela est particulièrement utile dans une architecture de microservices où les services sont interdépendants. En mettant en œuvre un disjoncteur, le système peut rapidement échouer et rediriger le trafic ou fournir des options de secours, maintenant ainsi les performances et la disponibilité globales du système pendant les pannes partielles. Ce modèle améliore la résilience en permettant au système de se rétablir gracieusement des pannes et de gérer efficacement les pics de trafic.",
        "Other Options": [
            "Le modèle monolithique n'est pas adapté à un système hautement disponible et tolérant aux pannes qui utilise des microservices. Les architectures monolithiques couplent étroitement tous les composants, rendant difficile l'évolutivité et la gestion des services individuels de manière indépendante, ce qui contredit les objectifs de résilience et d'évolutivité.",
            "Le modèle de réessai, bien qu'utile dans certains scénarios, peut aggraver les problèmes lors de trafic élevé ou de pannes de composants. Réessayer continuellement les opérations échouées sans stratégie peut entraîner une charge accrue sur le système et des pannes en cascade potentielles, ce qui n'est pas idéal pour maintenir un service cohérent pendant les pannes.",
            "Le modèle d'état peut compliquer l'évolutivité et la résilience dans une architecture de microservices. Maintenir les données de session entre les requêtes peut entraîner des défis dans la distribution de la charge et la gestion des pannes, car les services d'état peuvent ne pas facilement évoluer ou se rétablir des pannes sans perdre les informations de session."
        ]
    },
    {
        "Question Number": "63",
        "Situation": "Une entreprise utilise Amazon Kinesis pour traiter des données de streaming en temps réel. Elle souhaite s'assurer que seuls les utilisateurs autorisés peuvent accéder aux flux de données, et que les données sont chiffrées à la fois en transit et au repos.",
        "Question": "Quelles actions l'entreprise devrait-elle entreprendre pour sécuriser ses flux de données Kinesis ?",
        "Options": {
            "1": "Activer le chiffrement côté serveur (SSE) en utilisant AWS Key Management Service (KMS) pour chiffrer les données au repos, et utiliser des politiques IAM pour contrôler l'accès aux flux.",
            "2": "Configurer Kinesis Data Streams pour utiliser le chiffrement uniquement au repos, mais ne pas activer le chiffrement en transit, car cela n'est pas nécessaire pour les communications internes AWS.",
            "3": "Activer le peering VPC entre Kinesis et d'autres services AWS, en s'assurant que les données sont transmises par des connexions réseau privées pour améliorer la sécurité.",
            "4": "Autoriser un accès ouvert aux flux Kinesis sans chiffrement pour garantir que les données peuvent être rapidement accessibles par diverses applications, et utiliser CloudTrail pour surveiller les journaux d'accès."
        },
        "Correct Answer": "Activer le chiffrement côté serveur (SSE) en utilisant AWS Key Management Service (KMS) pour chiffrer les données au repos, et utiliser des politiques IAM pour contrôler l'accès aux flux.",
        "Explanation": "Activer le chiffrement côté serveur (SSE) en utilisant AWS Key Management Service (KMS) garantit que les données stockées dans Kinesis Data Streams sont chiffrées au repos, fournissant une couche de sécurité contre l'accès non autorisé. De plus, l'utilisation de politiques IAM permet à l'entreprise de définir qui peut accéder aux flux et quelles actions ils peuvent effectuer, garantissant que seuls les utilisateurs autorisés ont accès aux données sensibles. Cette combinaison de chiffrement et de contrôle d'accès est essentielle pour sécuriser les données dans un environnement cloud.",
        "Other Options": [
            "Configurer Kinesis Data Streams pour utiliser le chiffrement uniquement au repos, mais ne pas activer le chiffrement en transit est insuffisant car les données peuvent être interceptées pendant la transmission. Le chiffrement en transit est crucial pour protéger les données lorsqu'elles circulent sur le réseau, en particulier dans un contexte de streaming en temps réel.",
            "Activer le peering VPC peut améliorer la sécurité en permettant une communication privée entre les services AWS, mais cela ne répond pas au besoin de chiffrement au repos ou en transit. Sans chiffrement, les données pourraient toujours être vulnérables à un accès non autorisé, rendant cette option incomplète pour sécuriser les flux de données Kinesis.",
            "Autoriser un accès ouvert aux flux Kinesis sans chiffrement pose un risque de sécurité significatif, car cela expose des données sensibles à quiconque peut accéder aux flux. Surveiller les journaux d'accès avec CloudTrail ne prévient pas l'accès non autorisé ; cela ne fournit qu'une visibilité après coup. Cette approche est contraire aux meilleures pratiques en matière de sécurité des données."
        ]
    },
    {
        "Question Number": "64",
        "Situation": "Imaginez que vous lancez un site web mondial pour le streaming de contenu média de haute qualité. Vous devez vous assurer que vos utilisateurs connaissent une latence minimale et une lecture fluide, peu importe leur emplacement géographique. Pour y parvenir, vous décidez d'utiliser Amazon CloudFront pour la livraison de contenu.",
        "Question": "Quel composant de CloudFront est responsable de la mise en cache du contenu plus près des utilisateurs pour un accès plus rapide, et comment contribue-t-il à réduire la latence ?",
        "Options": {
            "1": "Distribution, car elle fournit la configuration principale et définit le comportement de mise en cache.",
            "2": "Edge Location, car elle stocke le contenu mis en cache plus près des utilisateurs, ce qui entraîne des temps d'accès plus rapides pour les données fréquemment demandées.",
            "3": "Regional Edge Cache, qui fonctionne comme une version plus grande des Edge Locations pour contenir plus de données et améliorer l'efficacité de la mise en cache.",
            "4": "Origin, car il contient le contenu original qui est récupéré par CloudFront sur demande de l'utilisateur."
        },
        "Correct Answer": "Edge Location, car elle stocke le contenu mis en cache plus près des utilisateurs, ce qui entraîne des temps d'accès plus rapides pour les données fréquemment demandées.",
        "Explanation": "Les Edge Locations sont le composant clé d'Amazon CloudFront qui met en cache le contenu à divers emplacements géographiques à travers le monde. En stockant des copies de contenu plus près des utilisateurs, les Edge Locations réduisent considérablement la distance que les données doivent parcourir, ce qui minimise la latence et améliore la vitesse de livraison du contenu. Cela est particulièrement important pour le streaming de médias de haute qualité, car les utilisateurs s'attendent à un accès rapide au contenu sans mise en mémoire tampon.",
        "Other Options": [
            "La Distribution est une configuration qui définit comment CloudFront livre le contenu, y compris les paramètres pour le comportement de mise en cache, mais elle ne met pas directement en cache le contenu elle-même. Il s'agit davantage de la configuration globale que de la mise en cache physique du contenu.",
            "Le Regional Edge Cache sert d'intermédiaire entre l'origine et les Edge Locations, contenant de plus grandes quantités de données pour améliorer l'efficacité de la mise en cache. Cependant, ce n'est pas le composant principal responsable de la mise en cache du contenu le plus proche des utilisateurs ; ce rôle est spécifiquement rempli par les Edge Locations.",
            "L'Origin fait référence à la source originale du contenu, comme un bucket S3 ou un serveur web. Bien qu'il soit essentiel pour récupérer le contenu lorsqu'il n'est pas disponible dans le cache, il ne contribue pas à réduire la latence car il est généralement situé plus loin des utilisateurs finaux par rapport aux Edge Locations."
        ]
    },
    {
        "Question Number": "65",
        "Situation": "Vous concevez un système de traitement de tâches où les messages doivent être traités dans un ordre spécifique, et aucun doublon n'est autorisé. Cependant, vous souhaitez équilibrer ce besoin d'ordre avec une grande évolutivité, car le volume de messages peut varier considérablement.",
        "Question": "Quel type de file d'attente Amazon SQS devriez-vous choisir pour répondre à ces exigences, et pourquoi ?",
        "Options": {
            "1": "Standard Queue, car elle permet un débit illimité et est optimisée pour une grande évolutivité sans ordre strict.",
            "2": "FIFO Queue, car elle fournit un traitement exactement une fois et préserve l'ordre strict des messages, ce qui est crucial pour vos exigences.",
            "3": "Standard Queue, car elle offre une livraison au moins une fois, ce qui la rend adaptée à la gestion de volumes de messages variables.",
            "4": "FIFO Queue, car elle n'impose aucune limite sur le TPS et est optimisée pour un ordre de meilleure effort, ce qui la rend idéale pour les applications à fort volume."
        },
        "Correct Answer": "FIFO Queue, car elle fournit un traitement exactement une fois et préserve l'ordre strict des messages, ce qui est crucial pour vos exigences.",
        "Explanation": "Une FIFO (First-In-First-Out) Queue dans Amazon SQS est spécifiquement conçue pour garantir que les messages sont traités dans l'ordre exact dans lequel ils sont envoyés et que chaque message est traité exactement une fois. Cela est essentiel pour les scénarios où l'ordre de traitement des messages est critique et où les doublons doivent être évités. Étant donné les exigences de maintien d'un ordre strict et de prévention des doublons, une FIFO Queue est le choix le plus approprié.",
        "Other Options": [
            "Standard Queue, car elle permet un débit illimité et est optimisée pour une grande évolutivité sans ordre strict. Cependant, cette option ne répond pas à l'exigence d'un ordre strict et pourrait entraîner des doublons de messages.",
            "FIFO Queue, car elle fournit un traitement exactement une fois et préserve l'ordre strict des messages, ce qui est crucial pour vos exigences. Cette option est en fait correcte, mais elle est répétée dans la question, ce qui la rend trompeuse.",
            "Standard Queue, car elle offre une livraison au moins une fois, ce qui la rend adaptée à la gestion de volumes de messages variables. Bien que cette option permette une grande évolutivité, elle ne garantit pas l'ordre des messages et peut entraîner des doublons, ce qui ne répond pas aux exigences."
        ]
    }
]