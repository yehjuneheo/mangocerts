[
    {
        "Question Number": "1",
        "Situation": "금융 서비스 조직이 더 나은 효율성과 확장성을 위해 기계 학습 워크플로우를 자동화하려고 합니다. 데이터 준비, 훈련 및 배포를 위해 조정이 필요한 여러 가지 모델이 있습니다. ML 엔지니어는 AWS 서비스와 원활하게 통합하고 복잡한 워크플로우를 관리할 수 있는 가장 적합한 오케스트레이터를 선택해야 합니다.",
        "Question": "ML 엔지니어가 기계 학습 워크플로우 관리를 위해 고려해야 할 배포 오케스트레이터는 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "AWS Step Functions",
            "2": "SageMaker Pipelines",
            "3": "Apache Airflow",
            "4": "Kubernetes",
            "5": "TensorFlow Extended (TFX)"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "SageMaker Pipelines",
            "AWS Step Functions"
        ],
        "Explanation": "SageMaker Pipelines는 AWS에서 엔드 투 엔드 기계 학습 워크플로우를 구축, 관리 및 자동화하기 위해 특별히 설계되었습니다. AWS Step Functions는 다양한 AWS 서비스의 오케스트레이션을 가능하게 하며 SageMaker와 통합하여 복잡한 워크플로우를 관리할 수 있어 ML 워크플로우 배포에 적합한 두 가지 옵션입니다.",
        "Other Options": [
            "Apache Airflow는 강력한 오케스트레이션 도구이지만 AWS 서비스와 효과적으로 통합하기 위해 추가 구성이 필요하므로 SageMaker Pipelines와 같은 기본 솔루션에 비해 덜 최적입니다.",
            "Kubernetes는 주로 컨테이너 오케스트레이션 플랫폼이며 AWS에서 기계 학습 워크플로우에 최적화되어 있지 않아 이 시나리오에 덜 적합합니다.",
            "TensorFlow Extended (TFX)는 프로덕션 준비가 된 기계 학습 플랫폼이지만 주로 TensorFlow 워크플로우를 위해 설계되었으며 SageMaker Pipelines 또는 AWS Step Functions에 비해 다른 AWS 서비스와 원활하게 통합되지 않을 수 있습니다."
        ]
    },
    {
        "Question Number": "2",
        "Situation": "기계 학습 엔지니어는 구독 기반 서비스의 고객 이탈을 실시간으로 예측하는 배포된 기계 학습 모델을 유지 관리하는 책임이 있습니다. 이 모델은 Amazon SageMaker에 호스팅되며 시간이 지남에 따라 성능을 모니터링해야 합니다.",
        "Question": "기계 학습 인프라가 효율적이고 효과적으로 운영되고 있는지 확인하기 위해 엔지니어가 모니터링해야 할 주요 성능 지표는 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "Amazon S3 저장 비용",
            "2": "모델 지연 시간",
            "3": "데이터 전처리 시간",
            "4": "Amazon SageMaker 엔드포인트 가용성",
            "5": "모델 드리프트 비율"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "모델 지연 시간",
            "Amazon SageMaker 엔드포인트 가용성"
        ],
        "Explanation": "모델 지연 시간을 모니터링하는 것은 사용자 경험에 직접적인 영향을 미치기 때문에 매우 중요합니다. 높은 지연 시간은 실시간 예측에 영향을 미치는 지연을 초래할 수 있습니다. 또한 Amazon SageMaker 엔드포인트 가용성을 추적하면 모델이 일관되게 추론에 접근할 수 있도록 보장하여 서비스 수준을 유지하는 데 필수적입니다.",
        "Other Options": [
            "Amazon S3 저장 비용은 ML 인프라 성능의 직접적인 지표가 아니며, 운영 효율성이나 모델 성능보다는 저장 비용과 관련이 있습니다.",
            "모델 드리프트 비율은 모델의 예측 성능이 시간이 지남에 따라 저하되고 있는지 이해하는 데 관련이 있지만, 현재 운영에 영향을 미치는 직접적인 인프라 성능 지표는 아닙니다.",
            "데이터 전처리 시간은 전체 파이프라인에 중요하지만 배포된 ML 모델이나 그 인프라의 성능을 직접적으로 측정하지 않습니다."
        ]
    },
    {
        "Question Number": "3",
        "Situation": "금융 기관은 신용 점수 및 사기 탐지를 위해 여러 기계 학습 모델을 배포했습니다. 모델이 효과적이고 규정을 준수하도록 보장하기 위해 조직은 기계 학습 운영(MLOps)에 대한 모범 사례를 준수하는 강력한 모니터링 및 유지 관리 전략을 구현하고자 합니다.",
        "Question": "ML 엔지니어가 프로덕션에서 배포된 ML 모델을 효과적으로 모니터링하기 위해 우선해야 할 설계 원칙은 무엇입니까?",
        "Options": {
            "1": "성능 데이터나 모델 드리프트를 고려하지 않고 모든 모델을 고정된 일정에 따라 정기적으로 재훈련합니다.",
            "2": "훈련 중 모델의 정확성에만 집중하고 배포 후에는 지속적인 모니터링을 무시합니다.",
            "3": "모델 성능 지표를 시간에 따라 측정하고 편차에 대한 경고를 설정하기 위해 로깅 및 모니터링을 구현합니다.",
            "4": "특정 사용 사례나 데이터 변경과 관계없이 모든 모델 성능 지표에 대해 단일 정적 임계값을 사용합니다."
        },
        "Correct Answer": "모델 성능 지표를 시간에 따라 측정하고 편차에 대한 경고를 설정하기 위해 로깅 및 모니터링을 구현합니다.",
        "Explanation": "프로덕션에서 효과적인 모니터링은 모델 성능 지표를 적극적으로 추적하고 중요한 변화에 대해 경고를 받는 것을 포함합니다. 이를 통해 모델이 예상대로 작동하고 규정 준수 요구 사항을 준수하도록 적시에 개입할 수 있습니다.",
        "Other Options": [
            "배포 후 지속적인 모니터링을 무시하면 모델 저하, 규정 준수 문제 및 궁극적으로 구식 모델에 기반한 잘못된 의사 결정으로 이어질 수 있습니다.",
            "성능 데이터를 평가하지 않고 고정된 일정에 따라 모델을 재훈련하면 자원이 낭비될 수 있으며 실제 모델 드리프트를 해결하지 못할 수 있어 비효율적인 업데이트로 이어질 수 있습니다.",
            "성능 지표에 대해 단일 정적 임계값을 사용하면 특정 사용 사례에 대해 중요할 수 있는 모델 성능의 특정 변화를 간과하게 되어 궁극적으로 의사 결정 품질에 해를 끼칠 수 있습니다."
        ]
    },
    {
        "Question Number": "4",
        "Situation": "한 금융 서비스 회사가 사기 탐지를 위한 머신 러닝 모델을 개발했습니다. Amazon SageMaker를 사용하여 모델을 훈련한 후, 회사는 대규모 데이터 세트를 주기적으로 처리하기 위해 배치 추론을 위해 모델을 배포해야 합니다. 배포는 다양한 작업 부하를 처리하고 비용 효율성을 보장하기 위해 효율적으로 관리되어야 합니다.",
        "Question": "대규모 데이터 세트에 대해 배치 추론을 수행하기 위해 모델을 배포하는 데 가장 적합한 AWS 서비스는 무엇입니까? 쉽게 오케스트레이션하고 확장할 수 있도록 하면서요.",
        "Options": {
            "1": "Amazon ECS with Fargate",
            "2": "Amazon SageMaker Batch Transform",
            "3": "AWS Lambda",
            "4": "Amazon EKS with Kubeflow"
        },
        "Correct Answer": "Amazon SageMaker Batch Transform",
        "Explanation": "Amazon SageMaker Batch Transform은 배치 추론을 위해 특별히 설계되어 대규모 데이터 세트를 효율적으로 처리할 수 있습니다. 기본 인프라를 자동으로 관리하며 다양한 작업 부하를 처리할 수 있어 이 시나리오에 가장 적합한 선택입니다.",
        "Other Options": [
            "Amazon ECS with Fargate는 컨테이너화된 애플리케이션에 더 적합하지만 SageMaker Batch Transform만큼 머신 러닝 모델의 배치 처리에 대한 통합 수준을 제공하지 않습니다.",
            "Amazon EKS with Kubeflow는 설정 및 관리에 더 많은 운영 오버헤드를 요구하며, SageMaker Batch Transform에 비해 간단한 배치 추론 작업에는 이상적이지 않을 수 있습니다.",
            "AWS Lambda는 일반적으로 실시간 추론에 사용되며 실행 시간 및 페이로드 크기에 제한이 있어 대규모 데이터 세트의 배치 처리에는 적합하지 않습니다."
        ]
    },
    {
        "Question Number": "5",
        "Situation": "한 소매 회사가 전자 상거래 플랫폼에서 실시간 제품 추천을 처리하기 위해 머신 러닝 모델을 배포하고 있습니다. 모델은 피크 트래픽 시간 동안 자동으로 확장되어 낮은 대기 시간과 높은 가용성을 유지해야 합니다. 팀은 모델 배포의 효과적인 자동 확장을 위해 사용할 메트릭을 평가하고 있습니다.",
        "Question": "고트래픽 기간 동안 머신 러닝 모델이 낮은 대기 시간을 유지하도록 보장하기 위해 가장 적합한 메트릭은 무엇입니까?",
        "Options": {
            "1": "모델을 실행하는 인스턴스의 메모리 사용량.",
            "2": "모델을 호스팅하는 인스턴스의 CPU 사용률.",
            "3": "호출당 밀리초로 측정된 모델 대기 시간.",
            "4": "모델 인스턴스당 호출 수."
        },
        "Correct Answer": "호출당 밀리초로 측정된 모델 대기 시간.",
        "Explanation": "모델 대기 시간은 피크 트래픽 동안 반응적인 사용자 경험을 유지하는 데 가장 중요한 메트릭입니다. 대기 시간을 모니터링하고 이에 따라 확장함으로써 배포는 사용자가 추천을 신속하게 받을 수 있도록 보장하여 고객 만족도에 영향을 줄 수 있는 지연을 최소화합니다.",
        "Other Options": [
            "모델 인스턴스당 호출 수는 트래픽 수준에 대한 통찰력을 제공할 수 있지만, 사용자 경험에 중요한 응답 시간 측면에서 모델의 성능을 직접적으로 측정하지는 않습니다.",
            "CPU 사용률은 인스턴스의 부하를 이해하는 데 중요하지만, CPU만으로 확장하는 것은 낮은 대기 시간을 보장하지 않을 수 있으며, 높은 CPU 사용량이 인스턴스 용량에 따라 여전히 허용 가능한 대기 시간 수준을 초래할 수 있습니다.",
            "메모리 사용량은 처리되는 데이터 양을 나타낼 수 있지만, 모델이 요청에 응답하는 속도와 직접적으로 연관되지 않으므로 낮은 대기 시간을 유지하기 위한 주요 메트릭으로는 덜 효과적입니다."
        ]
    },
    {
        "Question Number": "6",
        "Situation": "데이터 과학 팀이 높은 처리량과 낮은 대기 시간이 필요한 실시간 이미지 분류 모델을 배포할 준비를 하고 있습니다. 팀은 AWS에서 제공하는 GPU 및 CPU 옵션의 사양을 고려하여 모델을 효율적으로 호스팅할 적절한 컴퓨팅 환경을 선택해야 합니다. 팀은 또한 다양한 컴퓨팅 옵션의 비용 영향을 우려하고 있습니다.",
        "Question": "실시간 이미지 분류 모델의 높은 처리량, 낮은 대기 시간 및 비용 효율성 요구 사항을 가장 잘 충족하는 컴퓨팅 환경 옵션은 무엇입니까?",
        "Options": {
            "1": "추론을 위해 Amazon EC2 T3 인스턴스를 사용합니다.",
            "2": "최대 메모리 할당 및 타임아웃 설정을 가진 AWS Lambda를 사용합니다.",
            "3": "다중 모델 엔드포인트 구성을 가진 Amazon SageMaker Endpoint를 사용합니다.",
            "4": "추론을 위해 NVIDIA V100 GPU가 장착된 Amazon EC2 P3 인스턴스를 사용합니다."
        },
        "Correct Answer": "추론을 위해 NVIDIA V100 GPU가 장착된 Amazon EC2 P3 인스턴스를 사용합니다.",
        "Explanation": "NVIDIA V100 GPU가 장착된 Amazon EC2 P3 인스턴스는 고성능 머신 러닝 작업을 위해 특별히 설계되었습니다. 이들은 실시간 추론에 필요한 계산 능력을 제공하여 높은 처리량과 낮은 대기 시간을 보장하며, 이미지 분류 모델 배포에 이상적인 선택입니다.",
        "Other Options": [
            "Amazon EC2 T3 인스턴스는 일반적인 용도의 작업을 위해 설계되었으며 고성능 ML 추론 작업에 최적화되어 있지 않습니다. 이들은 GPU 인스턴스에 비해 더 높은 대기 시간과 낮은 처리량을 초래할 수 있어 실시간 이미지 분류에 적합하지 않습니다.",
            "다중 모델 엔드포인트를 가진 Amazon SageMaker Endpoint는 단일 엔드포인트에서 여러 모델을 제공하여 비용을 절감할 수 있지만, 모델 로딩 시간으로 인해 대기 시간이 추가될 수 있으며 전용 GPU 인스턴스만큼 실시간 성능에 최적화되어 있지 않습니다.",
            "AWS Lambda는 서버리스 컴퓨팅 서비스로, 고차원 이미지 데이터의 실시간 추론에 필요한 성능을 제공하지 않을 수 있습니다. 실행 시간 및 리소스 할당에 대한 제한은 모델의 성능을 저해할 수 있어 이 사용 사례에 덜 적합합니다."
        ]
    },
    {
        "Question Number": "7",
        "Situation": "소매 회사는 기존 고객 데이터를 활용하여 제품 추천을 개선하고자 합니다. 그들은 추천을 위한 사전 훈련된 모델을 보유하고 있지만, 사용자 상호작용 및 제품 선호도에 대한 맞춤형 데이터셋을 사용하여 이를 미세 조정하고자 합니다. 이 회사는 이 작업을 수행하기 위해 Amazon SageMaker를 사용하는 것을 고려하고 있습니다.",
        "Question": "회사가 맞춤형 데이터셋을 사용하여 사전 훈련된 추천 모델을 효과적으로 미세 조정하기 위해 어떤 접근 방식을 취해야 합니까?",
        "Options": {
            "1": "Amazon Rekognition을 사용하여 제품 및 고객의 이미지를 분석하여 추천 시스템을 개선합니다.",
            "2": "맞춤형 데이터셋을 Amazon S3에 업로드하고 SageMaker를 사용하여 새로운 데이터로 사전 훈련된 모델을 미세 조정하는 훈련 작업을 생성합니다.",
            "3": "사전 훈련된 모델을 엔드포인트로 배포하고 맞춤형 데이터셋을 사용하여 미세 조정 대신 배치 예측을 수행합니다.",
            "4": "맞춤형 데이터셋을 사용하지 않고 Amazon SageMaker에서 사전 훈련된 모델의 매개변수를 직접 수정합니다."
        },
        "Correct Answer": "맞춤형 데이터셋을 Amazon S3에 업로드하고 SageMaker를 사용하여 새로운 데이터로 사전 훈련된 모델을 미세 조정하는 훈련 작업을 생성합니다.",
        "Explanation": "이 접근 방식은 회사가 맞춤형 데이터셋을 효과적으로 활용하고 관련 사용자 상호작용 및 선호도로 사전 훈련된 모델의 성능을 향상시킬 수 있게 합니다.",
        "Other Options": [
            "이 옵션은 사전 훈련된 모델의 매개변수를 수정하는 것만으로는 효과적인 학습이나 모델 성능 향상으로 이어지지 않기 때문에 잘못된 것입니다.",
            "이 옵션은 배치 예측을 수행하는 것이 모델을 미세 조정하는 것과 관련이 없기 때문에 올바르지 않습니다. 미세 조정은 맞춤형 데이터셋으로 모델을 재훈련하여 정확성을 향상시키는 것을 요구합니다.",
            "이 옵션은 Amazon Rekognition이 주로 이미지 및 비디오 분석에 사용되며 고객 상호작용이나 선호도를 기반으로 추천 모델을 미세 조정하는 데 사용되지 않기 때문에 잘못된 것입니다."
        ]
    },
    {
        "Question Number": "8",
        "Situation": "데이터 과학 팀은 Amazon SageMaker를 사용하여 기계 학습 모델을 배포하려고 하며, 확장성과 컨테이너화에 중점을 두고 있습니다. 그들은 클라우드 네이티브 환경에서 컨테이너화된 애플리케이션을 효율적으로 관리할 수 있는 워크플로우를 보장하고자 합니다. 이들은 이 과정을 용이하게 하기 위해 다양한 오케스트레이션 솔루션을 고려하고 있습니다.",
        "Question": "팀이 Amazon SageMaker와 함께 기계 학습 워크플로우를 오케스트레이션하고 컨테이너를 효과적으로 관리하기 위해 활용할 수 있는 AWS 서비스는 무엇입니까?",
        "Options": {
            "1": "Amazon EC2 Auto Scaling",
            "2": "Amazon Elastic Kubernetes Service (Amazon EKS)",
            "3": "AWS Fargate",
            "4": "AWS Lambda"
        },
        "Correct Answer": "Amazon Elastic Kubernetes Service (Amazon EKS)",
        "Explanation": "Amazon Elastic Kubernetes Service (EKS)는 Kubernetes를 사용하여 컨테이너화된 애플리케이션을 오케스트레이션하기 위해 특별히 설계되었으며, SageMaker로 배포된 기계 학습 워크플로우를 관리하는 데 이상적인 선택입니다. EKS는 확장성, 높은 가용성 및 다른 AWS 서비스와의 통합을 제공하여 팀이 컨테이너화된 ML 애플리케이션을 효율적으로 관리할 수 있도록 합니다.",
        "Other Options": [
            "AWS Lambda는 이벤트에 응답하여 코드를 실행하는 서버리스 컴퓨팅 서비스로, 일반적으로 기계 학습 워크플로우에 관련된 장기 실행 컨테이너 오케스트레이션 작업을 위해 설계되지 않았습니다.",
            "Amazon EC2 Auto Scaling은 부하에 따라 EC2 인스턴스 수를 자동으로 조정하는 데 중점을 두지만, 컨테이너화된 애플리케이션을 관리하기 위해 EKS가 제공하는 컨테이너 오케스트레이션 기능을 제공하지 않습니다.",
            "AWS Fargate는 컨테이너를 위한 서버리스 컴퓨팅 엔진이지만, 복잡한 기계 학습 워크플로우를 위해 Amazon EKS가 제공하는 Kubernetes의 전체 오케스트레이션 기능을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "9",
        "Situation": "금융 서비스 조직은 기계 학습 모델을 배포하기 위해 지속적인 통합 및 지속적인 배포(CI/CD) 파이프라인을 구현하고 있습니다. 팀은 AWS 서비스인 CodeBuild, CodeDeploy 및 CodePipeline을 사용하여 워크플로우를 자동화하고 있습니다. 그들은 모델이 효율적으로 구축, 테스트 및 배포되면서 버전 관리 및 롤백 기능을 유지할 수 있도록 해야 합니다.",
        "Question": "AWS 서비스의 어떤 기능이 ML 워크플로우의 효과적인 배포 및 오케스트레이션을 촉진할 수 있습니까? (두 가지 선택)",
        "Options": {
            "1": "CodeDeploy는 실패한 배포에 대해 자동 롤백을 제공합니다.",
            "2": "CodeDeploy는 AWS뿐만 아니라 온프레미스 서버에도 배포할 수 있습니다.",
            "3": "CodePipeline은 서드파티 CI/CD 도구와의 통합을 지원합니다.",
            "4": "CodeBuild는 각 빌드 단계에 대해 수동 개입이 필요합니다.",
            "5": "CodePipeline은 ML 워크플로우의 빌드, 테스트 및 배포 단계를 자동화합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "CodePipeline은 ML 워크플로우의 빌드, 테스트 및 배포 단계를 자동화합니다.",
            "CodeDeploy는 실패한 배포에 대해 자동 롤백을 제공합니다."
        ],
        "Explanation": "CodePipeline은 ML 워크플로우의 빌드, 테스트 및 배포를 포함하여 전체 CI/CD 프로세스를 자동화하도록 설계되어 있어 효율성을 보장하고 수동 오류를 줄입니다. CodeDeploy는 자동 롤백 기능을 제공하여 배포 신뢰성을 향상시키고, 팀이 실패 시 이전 버전으로 원활하게 되돌릴 수 있도록 합니다.",
        "Other Options": [
            "CodeBuild는 각 빌드 단계에 대해 수동 개입이 필요하지 않으며, CI/CD 파이프라인의 일환으로 자동으로 빌드를 실행하도록 설계되었습니다.",
            "CodePipeline은 서드파티 도구와 통합할 수 있지만, 이는 ML 워크플로우를 위해 특별히 설계된 핵심 기능이 아니므로 질문의 초점과 관련성이 떨어집니다.",
            "CodeDeploy는 주로 AWS 서비스에 애플리케이션을 배포하는 데 중점을 두며, 추가 구성 없이 온프레미스 서버에 배포를 용이하게 하지 않습니다."
        ]
    },
    {
        "Question Number": "10",
        "Situation": "한 금융 서비스 회사가 대출 채무 불이행 위험을 예측하기 위한 기계 학습 모델을 개발했습니다. 이 모델은 실시간으로 들어오는 대출 신청에 대한 예측을 제공하고, 분석을 위해 대량의 과거 대출 데이터를 처리할 수 있는 방식으로 배포되어야 합니다. 이 회사는 비용 효율성과 기존 시스템과의 통합 용이성을 중요하게 생각합니다.",
        "Question": "실시간 및 배치 처리 요구 사항을 모두 충족하기 위해 기계 학습 모델을 배포하는 가장 좋은 접근 방식은 무엇입니까?",
        "Options": {
            "1": "모델을 Amazon EC2를 사용하여 실시간 및 배치 예측 모두에 배포합니다.",
            "2": "실시간 예측을 위해 AWS Lambda를 활용하고, 데이터의 배치 처리를 위해 Amazon S3를 사용합니다.",
            "3": "온프레미스 서버를 사용하여 실시간 및 배치 배포를 위한 맞춤형 솔루션을 구현합니다.",
            "4": "실시간 엔드포인트를 위해 AWS SageMaker를 사용하고, 예측의 배치 처리를 위해 AWS Batch를 사용합니다."
        },
        "Correct Answer": "실시간 엔드포인트를 위해 AWS SageMaker를 사용하고, 예측의 배치 처리를 위해 AWS Batch를 사용합니다.",
        "Explanation": "AWS SageMaker를 사용하면 실시간 추론 기능을 갖춘 기계 학습 모델을 쉽게 배포할 수 있으며, AWS Batch는 배치 작업을 효율적으로 실행하도록 설계되었습니다. 이 조합은 실시간 및 배치 처리 요구를 모두 충족할 수 있는 확장 가능하고 비용 효율적인 방법을 제공합니다.",
        "Other Options": [
            "모델을 Amazon EC2를 사용하여 배포하는 것도 가능하지만, 관리 오버헤드가 더 많이 필요하고 AWS SageMaker 및 AWS Batch와 같은 수준의 통합 및 확장성을 제공하지 않습니다.",
            "실시간 예측을 위해 AWS Lambda를 활용하는 것은 특정 시나리오에 적합하지만, 실행 시간 및 리소스 제약에 제한이 있어 대규모 데이터 세트의 배치 처리에는 덜 이상적입니다.",
            "온프레미스 서버를 사용하여 맞춤형 솔루션을 구현하는 것은 AWS SageMaker 및 AWS Batch와 같은 클라우드 서비스가 제공하는 확장성, 유연성 및 통합 용이성이 부족하여 덜 바람직한 옵션입니다."
        ]
    },
    {
        "Question Number": "11",
        "Situation": "기계 학습 엔지니어가 Amazon SageMaker를 사용하여 훈련된 모델을 배포해야 하며, 다양한 작업 부하를 처리할 수 있도록 확장 가능하면서도 실시간 예측을 위한 낮은 대기 시간을 유지해야 합니다.",
        "Question": "모델을 배포하고 호스팅하기 위한 엔지니어의 요구 사항을 가장 잘 충족하는 접근 방식은 무엇입니까?",
        "Options": {
            "1": "트래픽에 따라 용량을 조정할 수 있도록 자동 확장이 활성화된 SageMaker 엔드포인트로 모델을 배포합니다.",
            "2": "실시간 추론을 위해 AWS Lambda 함수에서 모델을 호스팅하고, 수요에 따라 자동으로 확장할 수 있도록 합니다.",
            "3": "Amazon SageMaker Batch Transform을 사용하여 대량의 데이터에 대한 예측을 필요에 따라 제공합니다.",
            "4": "Amazon EC2 인스턴스를 사용하여 모델을 배포하고 관찰된 트래픽 패턴에 따라 수동으로 확장을 관리합니다."
        },
        "Correct Answer": "트래픽에 따라 용량을 조정할 수 있도록 자동 확장이 활성화된 SageMaker 엔드포인트로 모델을 배포합니다.",
        "Explanation": "자동 확장이 활성화된 SageMaker 엔드포인트로 모델을 배포하면 엔지니어가 들어오는 트래픽에 따라 인스턴스 수를 자동으로 조정할 수 있어 낮은 대기 시간과 다양한 작업 부하를 효과적으로 처리할 수 있습니다.",
        "Other Options": [
            "Amazon EC2 인스턴스를 사용하여 모델을 배포하는 것은 확장을 수동으로 관리해야 하므로 SageMaker의 자동 확장 기능을 사용하는 것에 비해 대기 시간이 증가하고 운영 오버헤드가 발생할 수 있습니다.",
            "AWS Lambda 함수에서 모델을 호스팅하는 것은 자동 확장을 제공하지만, 실행 시간 및 페이로드 크기에 제한이 있어 처리 시간이 더 긴 특정 유형의 기계 학습 모델에는 덜 적합할 수 있습니다.",
            "Amazon SageMaker Batch Transform은 배치 예측을 위해 설계되었으며, 개별 요청을 신속하게 제공하기보다는 대량의 데이터를 한 번에 처리하므로 실시간 추론 요구에는 적합하지 않습니다."
        ]
    },
    {
        "Question Number": "12",
        "Situation": "한 소매 회사가 Amazon FSx 파일 시스템에 저장된 제품 이미지로 딥 러닝 모델을 훈련할 준비를 하고 있습니다. 데이터 과학자는 이미지가 접근 가능하고 Amazon SageMaker에서 모델 훈련을 위해 적절하게 포맷되어 있는지 확인해야 합니다. 이미지는 훈련을 용이하게 하기 위해 효율적으로 조직되고 로드되어야 합니다.",
        "Question": "데이터 과학자가 모델 훈련 프로세스를 위해 이미지 데이터를 효율적으로 조직하고 준비하기 위해 사용해야 할 AWS 서비스는 무엇입니까?",
        "Options": {
            "1": "AWS Data Pipeline",
            "2": "Amazon SageMaker Processing",
            "3": "AWS Glue DataBrew",
            "4": "Amazon S3 Select"
        },
        "Correct Answer": "Amazon SageMaker Processing",
        "Explanation": "Amazon SageMaker Processing은 모델 훈련에 사용되기 전에 데이터를 전처리하고 변환할 수 있는 기능을 제공하므로 SageMaker에서 훈련을 위해 이미지 데이터를 효율적으로 조직하고 준비하는 데 가장 적합한 선택입니다.",
        "Other Options": [
            "AWS Glue DataBrew는 주로 데이터 정리 및 변환에 사용되지만, SageMaker Processing만큼 효과적으로 SageMaker의 모델 훈련 워크플로우와 직접 통합되지 않습니다.",
            "Amazon S3 Select는 S3 객체에서 특정 데이터를 쿼리할 수 있게 해주지만, SageMaker의 맥락에서 모델 훈련을 위해 데이터를 조직하고 준비하는 데 설계되지 않았습니다.",
            "AWS Data Pipeline은 데이터 워크플로우를 조정하기 위한 서비스이지만, SageMaker Processing에 비해 기계 학습 모델 훈련을 위한 데이터 전처리에 대한 전용 기능이 부족합니다."
        ]
    },
    {
        "Question Number": "13",
        "Situation": "데이터 과학 팀이 기계 학습 모델 훈련을 위한 대규모 데이터 세트를 준비하고 있습니다. 이 데이터 세트는 여러 열로 구성된 구조화된 데이터로, 읽기 및 쓰기 작업을 위해 자주 접근됩니다.",
        "Question": "효율적인 쿼리를 최적화하고 저장 비용을 최소화하기 위해 팀이 선택해야 할 데이터 형식은 무엇입니까?",
        "Options": {
            "1": "JSON",
            "2": "Parquet",
            "3": "XML",
            "4": "CSV"
        },
        "Correct Answer": "Parquet",
        "Explanation": "Parquet는 효율적인 쿼리를 위해 최적화된 열 기반 저장 형식으로, 데이터를 효과적으로 압축할 수 있어 저장 비용을 최소화합니다. 이는 대규모 데이터 세트를 포함하는 사용 사례, 특히 읽기 성능이 중요한 분석 및 기계 학습 시나리오에 이상적입니다.",
        "Other Options": [
            "CSV는 행 기반 저장 형식으로, 대규모 데이터 세트에 대한 효율적인 저장 또는 쿼리 기능을 제공하지 않아 기계 학습 데이터 준비에 덜 적합합니다.",
            "JSON은 유연하고 사람이 읽을 수 있지만 성능에 최적화되어 있지 않아 Parquet와 같은 열 기반 형식에 비해 저장 비용이 증가하고 쿼리 시간이 느려질 수 있습니다.",
            "XML은 JSON과 유사하게 장황하고 성능에 최적화되어 있지 않습니다. 일반적으로 더 많은 저장 공간이 필요하며 Parquet와 같은 더 효율적인 형식에 비해 데이터 접근 시간을 느리게 할 수 있습니다."
        ]
    },
    {
        "Question Number": "14",
        "Situation": "데이터 과학 팀이 산업 기계의 예측 유지보수 모델을 개발하는 임무를 맡고 있습니다. 이 모델은 실패를 예측하는 데 효과적이어야 하며, 훈련 시간과 운영 비용의 균형을 맞춰야 합니다.",
        "Question": "모델 성능, 훈련 시간 및 비용 간의 균형을 달성하기 위해 가장 효과적인 접근 방식은 무엇입니까?",
        "Options": {
            "1": "기본 매개변수를 사용하여 결정 트리 모델을 생성합니다.",
            "2": "사전 훈련된 딥 러닝 모델을 사용하여 전이 학습을 채택합니다.",
            "3": "광범위한 하이퍼파라미터 조정을 포함한 복잡한 앙상블 모델을 활용합니다.",
            "4": "최소한의 특성 엔지니어링을 사용하여 더 간단한 선형 회귀 모델을 구현합니다."
        },
        "Correct Answer": "사전 훈련된 딥 러닝 모델을 사용하여 전이 학습을 채택합니다.",
        "Explanation": "사전 훈련된 딥 러닝 모델을 사용한 전이 학습은 훈련 시간과 비용을 크게 줄이면서 높은 성능을 유지할 수 있습니다. 특히 레이블이 있는 데이터가 제한적일 때 기존의 유사한 작업에서 지식을 활용하여 세 가지 주요 요소 간의 균형을 맞추는 전략적 선택이 됩니다.",
        "Other Options": [
            "복잡한 앙상블 모델을 활용하면 성능을 향상시킬 수 있지만, 복잡성과 광범위한 조정 필요성으로 인해 훈련 시간이 증가하고 운영 비용이 높아지는 경우가 많습니다.",
            "더 간단한 선형 회귀 모델을 구현하면 훈련 시간을 줄일 수 있지만, 비선형 관계가 존재하는 복잡한 시나리오에서는 모델 성능이 희생될 수 있습니다.",
            "기본 매개변수를 사용하여 결정 트리 모델을 생성하는 것은 빠르고 저렴할 수 있지만, 정확성과 일반화 측면에서 더 정교한 모델에 비해 성능이 떨어지는 경우가 많습니다."
        ]
    },
    {
        "Question Number": "15",
        "Situation": "소매 회사가 Amazon SageMaker를 사용하여 여러 기계 학습 모델을 배포하고 있습니다. 그들은 다양한 고객 요청에 따라 여러 모델을 동시에 제공할 수 있도록 비용과 대기 시간을 줄이기 위해 배포 전략을 최적화하고자 합니다. ML 엔지니어는 이 목적을 위해 다중 모델 엔드포인트와 다중 컨테이너 엔드포인트 중에서 고려하고 있습니다.",
        "Question": "여러 모델을 제공하기 위한 비용 효율성과 낮은 대기 시간을 달성하기 위해 ML 엔지니어가 선택해야 할 배포 전략은 무엇입니까?",
        "Options": {
            "1": "모델의 복잡성과 예상 트래픽에 따라 다중 모델과 다중 컨테이너 엔드포인트를 모두 사용하는 하이브리드 접근 방식을 구현합니다.",
            "2": "모든 모델을 동시에 배포하기 위해 다중 컨테이너 엔드포인트를 사용하여 낮은 대기 시간을 보장하지만, 자원 사용으로 인해 비용이 증가할 수 있습니다.",
            "3": "비용을 줄이기 위해 단일 다중 모델 엔드포인트에 여러 모델을 배포하여 필요에 따라 모델을 온디맨드로 로드할 수 있도록 합니다.",
            "4": "각 모델을 개별적으로 별도의 엔드포인트에 배포하여 제어와 유연성을 극대화하지만, 운영 비용이 더 높아질 수 있습니다."
        },
        "Correct Answer": "비용을 줄이기 위해 단일 다중 모델 엔드포인트에 여러 모델을 배포하여 필요에 따라 모델을 온디맨드로 로드할 수 있도록 합니다.",
        "Explanation": "다중 모델 엔드포인트를 사용하면 모델을 동적으로 로드할 수 있어 현재 사용 중인 모델만 메모리에 로드되므로 비용이 크게 줄어듭니다. 이 접근 방식은 모든 모델이 동시에 활성화될 필요가 없는 시나리오에 효율적이며, 다양한 고객 요청에 이상적입니다.",
        "Other Options": [
            "다중 컨테이너 엔드포인트를 사용하면 모든 모델이 동시에 사용 가능하므로 낮은 대기 시간을 보장할 수 있지만, 각 모델에 전용 자원이 필요하므로 비용이 증가할 수 있습니다.",
            "하이브리드 접근 방식은 배포 전략에 복잡성을 추가하여 관리하기 어렵게 만들 수 있으며, 신중하게 최적화하지 않으면 대기 시간과 비용이 증가할 수 있습니다.",
            "각 모델을 개별적으로 별도의 엔드포인트에 배포하면 제어를 극대화하지만, 운영 비용과 자원 사용이 크게 증가하여 비용을 고려한 배포 전략에는 적합하지 않습니다."
        ]
    },
    {
        "Question Number": "19",
        "Situation": "한 헬스케어 스타트업이 의료 이미징 데이터에서 질병을 식별하기 위한 머신 러닝 모델을 준비하고 있습니다. 데이터셋은 정확한 레이블 지정을 보장하기 위해 인간 주석이 필요한 수천 개의 이미지로 구성되어 있습니다. 스타트업은 헬스케어 규정을 준수하면서 이미지를 레이블링하기 위한 신뢰할 수 있고 확장 가능한 방법이 필요합니다.",
        "Question": "데이터 프라이버시 요구 사항을 준수하면서 이미지 데이터를 효율적으로 레이블링하기 위한 적합한 솔루션을 제공하는 AWS 서비스는 무엇입니까?",
        "Options": {
            "1": "Amazon Rekognition을 활용하여 사전 훈련된 모델을 기반으로 인간 개입 없이 이미지를 자동으로 레이블링합니다.",
            "2": "AWS Lambda를 사용하여 S3에 업로드되는 이미지를 실시간으로 처리하는 맞춤형 레이블링 솔루션을 만듭니다.",
            "3": "Amazon Mechanical Turk를 배포하여 이미지 레이블링 프로세스를 크라우드소싱하고 유연한 인력을 허용합니다.",
            "4": "Amazon SageMaker Ground Truth를 활용하여 내장된 워크플로우와 품질 관리 조치를 갖춘 레이블링 작업을 생성합니다."
        },
        "Correct Answer": "Amazon SageMaker Ground Truth를 활용하여 내장된 워크플로우와 품질 관리 조치를 갖춘 레이블링 작업을 생성합니다.",
        "Explanation": "Amazon SageMaker Ground Truth는 데이터 레이블링 작업을 위해 특별히 설계되었으며, 고품질 레이블을 보장하기 위한 내장 품질 관리 메커니즘을 포함하여 레이블링 작업을 생성하기 위한 강력한 프레임워크를 제공합니다. 이 서비스는 데이터 접근 및 레이블링 워크플로우에 대한 제어를 허용하여 헬스케어 규정을 준수하는 데에도 지원을 제공합니다.",
        "Other Options": [
            "Amazon Rekognition은 주로 이미지 및 비디오 분석에 사용되지만, 전문가의 입력이 자주 필요한 의료 이미지를 정확하게 주석 달기 위해 필요한 인간 레이블링 기능을 제공하지 않습니다.",
            "AWS Lambda를 사용한 맞춤형 레이블링 솔루션은 대규모 데이터셋에 대해 확장 가능하거나 효율적이지 않을 수 있으며, 특히 규제가 많은 산업에서 적절한 데이터 레이블링을 위해 중요한 내장 품질 관리 및 관리 기능이 부족합니다.",
            "Amazon Mechanical Turk는 크라우드소싱 레이블링을 허용하지만, 헬스케어 규정 준수 요구 사항을 충족하기 위해 필요한 데이터 프라이버시 제어 및 품질 보증을 제공하지 않을 수 있어 민감한 의료 이미징 데이터에는 적합하지 않습니다."
        ]
    },{
        "Question Number": "16",
        "Situation": "ML 엔지니어가 Amazon SageMaker를 사용하여 머신러닝 모델을 개발하고 있으며, 하이퍼파라미터 튜닝을 통해 모델 성능을 최적화하고자 합니다.",
        "Question": "Amazon SageMaker에서 하이퍼파라미터 튜닝에 사용할 수 있는 방법은 무엇인가요? (두 가지 선택)",
        "Options": {
            "1": "그리드 서치",
            "2": "하이퍼밴드",
            "3": "베이지안 최적화",
            "4": "신경망 구조 검색",
            "5": "랜덤 서치"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "베이지안 최적화",
            "랜덤 서치"
        ],
        "Explanation": "베이지안 최적화와 랜덤 서치는 모두 Amazon SageMaker에서 하이퍼파라미터 튜닝을 위한 지원 방법입니다. 베이지안 최적화는 하이퍼파라미터를 목표 메트릭에 매핑하는 함수의 확률 모델을 구축하여 최적의 하이퍼파라미터를 찾는 데 효과적입니다. 반면, 랜덤 서치는 지정된 범위에서 하이퍼파라미터를 무작위로 샘플링하여, 종종 소모적인 탐색 방법보다 짧은 시간 안에 좋은 결과를 제공합니다.",
        "Other Options": [
            "그리드 서치는 지정된 하이퍼파라미터 조합의 하위 집합을 철저히 검색하므로 계산 비용이 많이 들고 시간이 소요될 수 있어 제공된 옵션에 비해 효율성이 떨어집니다.",
            "신경망 구조 검색은 기존 모델의 하이퍼파라미터 튜닝이 아니라 최적의 신경망 구조를 자동으로 검색하는 데 사용되는 더 고급 기술입니다.",
            "하이퍼밴드는 하이퍼파라미터 튜닝을 위해 설계된 최적화 알고리즘이지만 SageMaker에 직접 구현되어 있지 않습니다. 이는 랜덤 서치와 조기 중지를 결합하여 다양한 구성 간의 자원 할당을 최적화합니다."
        ]
    },
    {
        "Question Number": "17",
        "Situation": "데이터 과학 팀이 Amazon SageMaker를 사용하여 머신 러닝 모델을 배포하는 작업을 하고 있습니다. 이들은 모델과 관련된 S3 버킷에 접근할 수 있는 권한이 있는 인원만 접근할 수 있도록 보장해야 합니다. 팀은 또한 이러한 리소스에 대한 접근을 모니터링하고 감사하는 강력한 시스템을 구현하여 보안 정책을 준수하고자 합니다.",
        "Question": "이 시나리오에서 머신 러닝 모델과 그 데이터에 대한 접근을 제어하기 위해 필수적인 AWS IAM 구성은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "S3 버킷 정책",
            "2": "IAM 정책",
            "3": "IAM 그룹",
            "4": "IAM 역할",
            "5": "AWS Cognito 사용자 풀"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "IAM 정책",
            "IAM 역할"
        ],
        "Explanation": "IAM 정책과 IAM 역할은 AWS에서 권한 및 접근 제어를 정의하는 데 필수적입니다. IAM 정책은 특정 리소스에 대해 허용되거나 거부되는 작업을 지정하며, IAM 역할은 서비스가 자격 증명을 저장할 필요 없이 리소스에 안전하게 접근할 수 있도록 합니다. 이러한 구성은 권한이 있는 인원만이 머신 러닝 모델과 관련된 S3 버킷에 접근할 수 있도록 보장합니다.",
        "Other Options": [
            "S3 버킷 정책은 버킷 수준에서 접근을 관리하는 데 사용되지만 IAM 사용자 및 역할에 대해 IAM 정책만큼 세분화된 제어를 제공하지 않습니다.",
            "AWS Cognito 사용자 풀은 주로 사용자 인증에 사용되며 IAM 역할 및 정책처럼 AWS 리소스에 대한 접근을 관리하지 않습니다.",
            "IAM 그룹은 사용자 권한을 집합적으로 관리하는 데 유용하지만 IAM 정책 및 역할처럼 리소스에 대한 접근을 직접적으로 제어하지는 않습니다."
        ]
    },
    {
        "Question Number": "18",
        "Situation": "머신러닝 엔지니어가 분류 문제를 위한 모델 개발을 맡았습니다. 모델의 성능을 정확하게 평가할 수 있도록 하기 위해, 엔지니어는 향후 모델의 반복 버전을 비교할 수 있는 성능 기준을 설정해야 합니다. 엔지니어는 역사적 데이터와 다양한 평가 지표에 접근할 수 있습니다.",
        "Question": "머신러닝 엔지니어가 모델의 성능 기준을 만들기 위해 어떤 두 가지 방법을 사용해야 합니까? (두 가지 선택)",
        "Options": {
            "1": "데이터를 훈련 세트와 테스트 세트로 나누어 홀드아웃 검증 세트를 구현합니다.",
            "2": "무작위 샘플링 방법을 사용하여 성능 테스트를 위한 데이터의 여러 하위 집합을 생성합니다.",
            "3": "모델의 성능을 이해하기 위해 전체 데이터셋을 사용하여 교차 검증을 수행합니다.",
            "4": "비즈니스 요구 사항 및 역사적 모델 성능에 따라 성능 기준을 설정합니다.",
            "5": "훈련 데이터셋에 대해 정확도, 정밀도 및 재현율과 같은 성능 지표를 적용합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "데이터를 훈련 세트와 테스트 세트로 나누어 홀드아웃 검증 세트를 구현합니다.",
            "비즈니스 요구 사항 및 역사적 모델 성능에 따라 성능 기준을 설정합니다."
        ],
        "Explanation": "성능 기준을 만드는 것은 모델의 성능을 보지 않은 데이터에서 평가하기 위해 홀드아웃 검증 세트를 사용하는 것을 포함하며, 이는 편향 없는 평가를 제공합니다. 또한, 비즈니스 요구 사항 및 역사적 성능에 따라 성능 기준을 설정하면 모델이 배포에 필요한 특정 기준을 충족하는지 확인할 수 있습니다.",
        "Other Options": [
            "전체 데이터셋을 사용하여 모델을 교차 검증하는 것은 적절한 기준을 제공하지 않으며, 이는 과적합과 모델 성능에 대한 낙관적인 관점을 초래할 수 있습니다.",
            "무작위 샘플링 방법을 사용하여 하위 집합을 생성하면 변동성이 생길 수 있으며 전체 데이터셋을 정확하게 나타내지 않을 수 있어 기준 설정에 신뢰성이 떨어집니다.",
            "훈련 데이터셋에 대해 정확도, 정밀도 및 재현율과 같은 성능 지표를 적용하는 것은 모델이 보지 않은 데이터에서 어떻게 수행되는지를 진정으로 나타내지 않으므로 기준 설정에 적합하지 않습니다."
        ]
    },
    {
        "Question Number": "20",
        "Situation": "데이터 과학 팀이 머신 러닝 모델 훈련을 위한 대규모 데이터셋을 준비하고 있습니다. 그들은 수동 노력을 최소화하면서 데이터를 효율적으로 정리, 변환 및 풍부하게 만들 필요가 있습니다. 그들은 데이터 준비 작업을 단순화하고 시각적 인터페이스를 제공하며 다른 AWS 서비스와 잘 통합되는 AWS 서비스를 사용하고자 합니다.",
        "Question": "팀이 최소한의 수동 개입으로 데이터 준비를 촉진하기 위해 사용해야 할 AWS 서비스는 무엇입니까?",
        "Options": {
            "1": "AWS Glue DataBrew를 사용하여 시각적 데이터 준비 및 변환을 수행합니다.",
            "2": "AWS Glue ETL 작업을 사용하여 자동화된 데이터 추출 및 변환을 수행합니다.",
            "3": "Amazon SageMaker Data Wrangler를 사용하여 데이터 준비 워크플로우를 구축합니다.",
            "4": "Amazon EMR과 Apache Spark를 사용하여 맞춤형 데이터 처리 스크립트를 작성합니다."
        },
        "Correct Answer": "AWS Glue DataBrew를 사용하여 시각적 데이터 준비 및 변환을 수행합니다.",
        "Explanation": "AWS Glue DataBrew는 시각적 데이터 준비를 위해 특별히 설계되어 사용자가 코드를 작성하지 않고도 데이터를 정리하고 변환할 수 있도록 합니다. 이는 전체 데이터 준비 프로세스를 단순화하는 사용자 친화적인 인터페이스를 제공하여 효율성과 사용 용이성을 찾는 팀에 이상적입니다.",
        "Other Options": [
            "Amazon EMR과 Apache Spark는 DataBrew와 같은 시각적 도구에 비해 더 많은 수동 코딩 및 구성이 필요하므로 최소한의 수동 개입을 원하는 팀에는 적합하지 않습니다.",
            "Amazon SageMaker Data Wrangler는 데이터 준비에 강력한 옵션이지만 SageMaker 워크플로우와의 통합에 더 중점을 두고 있어 DataBrew와 같은 수준의 시각적 데이터 준비 기능을 제공하지 않을 수 있습니다.",
            "AWS Glue ETL 작업은 데이터 변환에 강력하지만 더 많은 기술 전문 지식과 수동 설정이 필요하므로 수동 노력을 최소화하려는 팀의 목표와 일치하지 않을 수 있습니다."
        ]
    },
    {
        "Question Number": "21",
        "Situation": "머신 러닝 팀이 프로덕션 환경에 새로운 모델 버전을 배포할 준비를 하고 있습니다. 그들은 새로운 버전이 기존 서비스를 방해하지 않도록 하고 문제가 발생할 경우 신속하게 롤백할 수 있도록 하기를 원합니다. 팀은 다양한 배포 전략을 고려하고 있습니다.",
        "Question": "팀이 필요할 경우 신속한 롤백을 허용하면서 영향을 최소화하기 위해 선택해야 할 배포 전략은 무엇입니까?",
        "Options": {
            "1": "모든 사용자가 즉시 최신 모델을 경험할 수 있도록 한 번에 모든 것을 배포합니다.",
            "2": "새로운 모델 버전으로의 트래픽을 점진적으로 증가시키기 위해 선형 배포를 채택합니다.",
            "3": "소수의 사용자와 함께 모델을 테스트하기 위해 카나리 배포를 구현합니다.",
            "4": "두 환경 간에 트래픽을 즉시 전환하기 위해 블루/그린 배포를 활용합니다."
        },
        "Correct Answer": "소수의 사용자와 함께 모델을 테스트하기 위해 카나리 배포를 구현합니다.",
        "Explanation": "카나리 배포는 새로운 모델 버전을 소수의 사용자와 함께 테스트하면서 대다수는 안정적인 버전을 유지할 수 있도록 합니다. 이는 광범위한 문제의 위험을 최소화하고 문제가 감지될 경우 신속한 롤백을 가능하게 합니다.",
        "Other Options": [
            "블루/그린 배포는 신속한 롤백을 허용하지만 두 개의 별도 환경을 유지해야 하므로 모든 배포 시나리오에 필요하지 않을 수 있습니다.",
            "선형 배포는 새로운 버전으로의 트래픽을 점진적으로 증가시키지만, 롤아웃 중 문제가 발생할 경우 여전히 위험을 초래할 수 있어 즉각적인 롤백에는 덜 이상적입니다.",
            "한 번에 모든 것을 배포하는 것은 가장 높은 위험을 초래하며, 이는 실제 사용자 조건에서 모델을 테스트할 수 없게 하고 문제가 발생할 경우 롤백을 더 복잡하게 만듭니다."
        ]
    },
    {
        "Question Number": "22",
        "Situation": "소매 회사가 제품 수요를 예측하기 위해 머신 러닝 모델을 배포하고 있습니다. 이 모델은 피크 시간 동안 들어오는 요청의 양이 많기 때문에 정확성, 추론 비용 및 응답 시간의 균형을 맞춰야 합니다. ML 엔지니어는 다양한 배포 전략을 평가하고 있습니다.",
        "Question": "ML 엔지니어가 성능, 비용 및 지연 시간을 최적화하기 위해 어떤 배포 전략을 선택해야 합니까?",
        "Options": {
            "1": "지연 시간을 최소화하기 위해 단일 고성능 인스턴스에 모델을 배포하되, 피크 시간 동안 더 높은 비용을 감수합니다.",
            "2": "수요에 따라 자동으로 확장되는 서버리스 아키텍처를 사용하여 비용 효율성을 유지하면서 허용 가능한 지연 시간을 보장합니다.",
            "3": "여러 저비용 인스턴스에 걸쳐 다중 인스턴스 배포를 구현하여 비용을 최소화하고 허용 가능한 성능을 유지합니다.",
            "4": "성능을 극대화하기 위해 전용 하드웨어 가속기에 모델을 배포하되, 운영 비용이 증가할 수 있습니다."
        },
        "Correct Answer": "수요에 따라 자동으로 확장되는 서버리스 아키텍처를 사용하여 비용 효율성을 유지하면서 허용 가능한 지연 시간을 보장합니다.",
        "Explanation": "서버리스 아키텍처는 요청 수에 따라 모델이 자동으로 확장되거나 축소되도록 하여 사용된 컴퓨팅 시간에 대해서만 요금을 부과함으로써 비용을 최적화합니다. 이 접근 방식은 자원을 동적으로 프로비저닝하여 피크 시간 동안 낮은 지연 시간을 유지할 수 있습니다.",
        "Other Options": [
            "단일 고성능 인스턴스에 배포하면 지연 시간을 최소화할 수 있지만, 수요에 따라 확장되지 않으며 피크 트래픽 동안 높은 운영 비용으로 이어질 수 있습니다.",
            "여러 저비용 인스턴스에 걸쳐 다중 인스턴스 배포를 구현하면 비용을 줄일 수 있지만, 로드 밸런싱의 복잡성을 초래할 수 있으며 피크 시간 동안 요구되는 낮은 지연 시간을 제공하지 못할 수 있습니다.",
            "전용 하드웨어 가속기에 배포하면 성능을 극대화할 수 있지만, 이러한 인프라와 관련된 높은 운영 비용은 수요가 변동할 경우 지속 가능하지 않을 수 있습니다."
        ]
    },
    {
        "Question Number": "23",
        "Situation": "의료 제공자가 치료 계획에 따라 환자 결과를 분석할 머신 러닝 모델을 위한 데이터를 준비하고 있습니다. 제공자는 보호 건강 정보(PHI) 사용에 대한 규정 준수를 보장해야 합니다.",
        "Question": "의료 제공자가 데이터 준비 단계에서 데이터 보호 규정 준수를 보장하기 위해 어떤 전략을 우선시해야 합니까?",
        "Options": {
            "1": "실제 환자 정보를 피하면서 합성 데이터를 사용하여 모델을 훈련합니다.",
            "2": "개별 기록을 노출하지 않고 요약 통계를 생성하기 위해 데이터를 집계합니다.",
            "3": "환자를 식별할 수 있는 모든 데이터 필드를 제거합니다.",
            "4": "기밀성을 유지하기 위해 처리하기 전에 모든 PHI 데이터를 암호화합니다."
        },
        "Correct Answer": "기밀성을 유지하기 위해 처리하기 전에 모든 PHI 데이터를 암호화합니다.",
        "Explanation": "처리하기 전에 모든 PHI 데이터를 암호화하는 것은 기밀성을 유지하고 규정 준수 요구 사항을 충족하는 데 필수적입니다. 이 전략은 데이터에 무단으로 접근하더라도 읽을 수 없게 유지되어 환자 프라이버시를 보호합니다.",
        "Other Options": [
            "데이터를 집계하는 것은 개별 기록 노출 위험을 줄이는 데 도움이 될 수 있지만, 집계된 데이터가 여전히 개인으로 추적될 수 있다면 규정을 완전히 준수하지 않을 수 있습니다.",
            "환자를 식별할 수 있는 데이터 필드를 제거하는 것은 좋은 관행이지만, 그것만으로는 충분하지 않을 수 있습니다. 데이터에 여전히 규정을 위반하는 다른 간접 식별자가 남아 있을 수 있습니다.",
            "합성 데이터를 사용하는 것은 위험을 완화하는 유용한 방법이 될 수 있지만, 항상 실제 시나리오를 정확하게 나타내지 않을 수 있어 모델의 효과를 제한할 수 있습니다. 또한, 규정 준수는 사용되는 실제 데이터의 신중한 처리를 여전히 요구할 수 있습니다."
        ]
    },
    {
        "Question Number": "24",
        "Situation": "금융 서비스 회사가 AWS SageMaker를 사용하여 대출 디폴트를 예측하는 머신 러닝 모델을 배포했습니다. 예측에 대한 수요는 하루 동안 크게 변동하며, 회사는 모델이 수요에 따라 원활하게 확장할 수 있도록 하면서 비용을 최소화해야 합니다.",
        "Question": "ML 엔지니어가 예측 요청의 변동을 효율적으로 처리하기 위해 SageMaker 엔드포인트에 자동 확장을 구현하기 위해 어떤 접근 방식을 취해야 합니까?",
        "Options": {
            "1": "피크 수요 시간 동안 SageMaker 엔드포인트의 인스턴스 수를 수동으로 조정하여 부하를 효과적으로 처리할 수 있도록 합니다.",
            "2": "시간에 따라 인스턴스 수를 변경하는 예약된 확장 정책을 구현하되, 실제 요청량과는 관계없이 수행합니다.",
            "3": "요청량이 낮을 때 SageMaker 인스턴스를 자동으로 종료하기 위해 AWS Lambda 함수를 사용하여 비용을 절감합니다.",
            "4": "들어오는 요청 수에 따라 목표 추적 확장 정책을 설정하고 최소 및 최대 인스턴스 한계를 구성하여 가용성을 보장합니다."
        },
        "Correct Answer": "들어오는 요청 수에 따라 목표 추적 확장 정책을 설정하고 최소 및 최대 인스턴스 한계를 구성하여 가용성을 보장합니다.",
        "Explanation": "목표 추적 확장 정책을 구현하면 SageMaker 엔드포인트가 실제 요청량에 따라 인스턴스 수를 자동으로 조정할 수 있어 시스템이 수요 변동을 효율적으로 처리하면서 가용성을 유지할 수 있습니다. 이 접근 방식은 수요가 낮을 때 축소하여 비용 최적화도 가능하게 합니다.",
        "Other Options": [
            "인스턴스 수를 수동으로 조정하는 것은 수요 변화에 대한 효율적이거나 시기적절한 대응을 제공하지 않으며, 과도한 프로비저닝 또는 부족한 프로비저닝으로 이어질 수 있습니다.",
            "시간에 따른 예약된 확장은 실제 사용 패턴을 고려하지 않으므로 비피크 시간 동안 불필요한 비용이 발생하거나 피크 시간 동안 충분한 용량을 제공하지 못할 수 있습니다.",
            "AWS Lambda 함수를 사용하여 인스턴스를 종료하는 것은 높은 수요 기간 동안 서비스 중단을 초래할 수 있으며, 실시간 예측 요청에 대한 확장을 관리하는 효과적인 방법이 아닙니다."
        ]
    },
    {
        "Question Number": "25",
        "Situation": "금융 서비스 회사가 AWS를 사용하여 사기 탐지를 위한 머신 러닝 모델을 배포하고 있습니다. 훈련 데이터셋과 훈련된 모델을 포함한 모델 아티팩트는 Amazon S3 버킷에 저장됩니다. ML 엔지니어는 최소 권한 원칙을 준수하면서 특정 IAM 사용자만 이러한 아티팩트에 접근할 수 있도록 보장하는 임무를 맡고 있습니다.",
        "Question": "ML 엔지니어가 S3 버킷의 ML 아티팩트에 대한 최소 권한 접근을 구성하기 위해 어떤 AWS 서비스를 사용해야 합니까?",
        "Options": {
            "1": "AWS Secrets Manager",
            "2": "AWS Identity and Access Management (IAM)",
            "3": "AWS Lake Formation",
            "4": "Amazon S3 Access Points"
        },
        "Correct Answer": "AWS Identity and Access Management (IAM)",
        "Explanation": "AWS Identity and Access Management (IAM)는 AWS 리소스에 대한 사용자 및 권한을 생성하고 관리할 수 있게 해줍니다. IAM 정책을 정의함으로써 ML 엔지니어는 S3 버킷의 ML 아티팩트에 접근이 필요한 사용자에게 특정 권한을 부여할 수 있어, 승인된 사용자만 중요한 리소스에 접근할 수 있도록 보장합니다.",
        "Other Options": [
            "AWS Secrets Manager는 API 키 및 데이터베이스 자격 증명과 같은 민감한 정보를 관리하는 데 주로 사용되며, S3 아티팩트에 대한 접근을 구성하는 데는 사용되지 않습니다.",
            "AWS Lake Formation은 데이터 레이크를 관리하고 그 안에 저장된 데이터에 대한 접근을 제어하는 데 도움을 주지만, 데이터 레이크 작업 외부의 S3 버킷 아티팩트에 대한 세밀한 접근 제어를 위해 특별히 설계된 것은 아닙니다.",
            "Amazon S3 Access Points는 S3에서 공유 데이터 세트에 대한 접근을 관리하는 방법을 제공하지만, 최소 권한 접근을 효과적으로 시행하기 위해 IAM 정책의 필요성을 대체하지는 않습니다."
        ]
    },
    {
        "Question Number": "26",
        "Situation": "머신 러닝 엔지니어가 추천 시스템의 성능을 개선하는 임무를 맡고 있습니다. 현재 모델은 정확도와 재현율 지표 측면에서 성능이 저조합니다. 엔지니어는 모델의 예측력을 향상시키기 위한 다양한 방법을 고려하고 있습니다. 이 시나리오에서 가장 효과적인 접근 방식은 무엇일까요?",
        "Question": "엔지니어가 모델의 성능을 개선하기 위해 우선적으로 고려해야 할 방법은 무엇입니까?",
        "Options": {
            "1": "모델에서 사용되는 특성의 수를 줄이기",
            "2": "추가 테스트 없이 더 복잡한 알고리즘으로 전환하기",
            "3": "모델의 학습을 향상시키기 위해 더 많은 훈련 데이터 수집하기",
            "4": "더 많은 레이어를 추가하여 모델 복잡성 증가시키기"
        },
        "Correct Answer": "모델의 학습을 향상시키기 위해 더 많은 훈련 데이터 수집하기",
        "Explanation": "더 많은 훈련 데이터를 수집하면 모델이 학습할 수 있는 추가 예제를 제공하여 성능을 크게 향상시킬 수 있습니다. 특히 원래 데이터셋이 작거나 문제 도메인을 대표하지 않는 경우에 더욱 그렇습니다.",
        "Other Options": [
            "모델 복잡성을 증가시키면 과적합으로 이어질 수 있으며, 특히 훈련 데이터가 제한적일 경우 더욱 그렇습니다. 더 복잡한 모델은 보지 못한 데이터에 잘 일반화되지 않을 수 있습니다.",
            "특성의 수를 줄이면 모델이 더 나은 예측을 하는 데 도움이 될 수 있는 중요한 정보를 잃을 수 있습니다. 특성 선택은 데이터 분석에 기반하여 신중하게 이루어져야 합니다.",
            "추가 테스트 없이 더 복잡한 알고리즘으로 전환하는 것은 더 나은 결과를 가져오지 않을 수 있으며 불필요한 복잡성을 초래할 수 있습니다. 이러한 변경을 하기 전에 모델 평가 및 실험이 중요합니다."
        ]
    },
    {
        "Question Number": "27",
        "Situation": "의료 기관이 만성 질환에 걸릴 위험이 있는 환자를 식별하기 위한 예측 모델을 개발하고 있습니다. 데이터 과학 팀은 모델이 다양한 인구 통계 그룹에서 정확하고 공정하도록 보장하고자 합니다.",
        "Question": "모델의 정확성을 보장하고 편향을 감지하기 위해 팀이 우선적으로 고려해야 할 평가 지표와 관행은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "다양한 인구 통계 그룹에서 정밀도와 재현율 분석하기.",
            "2": "혼동 행렬을 사용하여 예측에서 모델의 편향 식별하기.",
            "3": "모델 평가에서 정밀도와 재현율의 균형을 맞추기 위해 F1 점수 사용하기.",
            "4": "모델 성능 측정을 위해 정확도에만 집중하기.",
            "5": "모델 일반화를 개선하기 위해 k-겹 교차 검증 구현하기."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "모델 평가에서 정밀도와 재현율의 균형을 맞추기 위해 F1 점수 사용하기.",
            "다양한 인구 통계 그룹에서 정밀도와 재현율 분석하기."
        ],
        "Explanation": "F1 점수는 특히 불균형 클래스의 경우 모델을 평가하는 데 중요한 지표로, 정밀도와 재현율 간의 균형을 제공합니다. 또한, 다양한 인구 통계 그룹에서 정밀도와 재현율을 분석하면 모델의 공정성에 영향을 미칠 수 있는 편향을 식별하는 데 도움이 됩니다.",
        "Other Options": [
            "k-겹 교차 검증은 모델 일반화를 개선하기 위한 좋은 관행이지만, 편향 감지 또는 정확성과 관련된 평가 지표를 직접적으로 다루지는 않습니다. 이는 모델 검증에 더 가깝습니다.",
            "정확도에만 집중하는 것은 특히 불균형 데이터셋에서 오해를 불러일으킬 수 있습니다. 이는 잘못된 긍정과 잘못된 부정 간의 균형을 무시하여 모델 예측의 편향을 가릴 수 있습니다.",
            "혼동 행렬을 사용하는 것은 분류 모델의 성능을 이해하는 데 유용하지만, 편향을 명시적으로 측정하지는 않습니다. 주로 모델이 저지른 오류의 유형에 대한 통찰을 제공하며 인구 통계적 불균형을 다루지는 않습니다."
        ]
    },
    {
        "Question Number": "28",
        "Situation": "데이터 엔지니어가 머신 러닝 모델 훈련을 위한 데이터셋을 준비하고 있습니다. 데이터셋은 Amazon S3 버킷과 관계형 데이터베이스를 포함한 여러 출처에서 병합되어야 합니다. 엔지니어는 병합 과정이 효율적이며 대량의 데이터를 처리할 수 있도록 하고 싶어합니다. 다음 중 이 작업에 가장 적합한 접근 방식은 무엇입니까?",
        "Question": "데이터 엔지니어가 머신 러닝을 위해 여러 출처의 데이터를 효율적으로 병합하기 위해 어떤 방법을 사용해야 합니까?",
        "Options": {
            "1": "AWS Lambda 함수를 사용하여 두 출처에서 데이터 검색을 트리거하고, 메모리에서 데이터를 병합한 후 결과를 DynamoDB에 저장합니다.",
            "2": "Amazon S3와 관계형 데이터베이스에서 데이터를 수동으로 다운로드하고, 로컬 스크립트를 사용하여 병합한 후 병합된 데이터셋을 다시 Amazon S3에 업로드합니다.",
            "3": "AWS Glue를 사용하여 Amazon S3와 관계형 데이터베이스에서 데이터를 추출하고 필요에 따라 변환한 후 병합된 데이터셋을 새로운 S3 위치에 로드하는 ETL 작업을 생성합니다.",
            "4": "Apache Spark를 Amazon EMR에서 사용하여 S3 버킷과 관계형 데이터베이스에서 데이터를 읽고, 병합 작업을 수행한 후 출력을 S3에 다시 씁니다."
        },
        "Correct Answer": "AWS Glue를 사용하여 Amazon S3와 관계형 데이터베이스에서 데이터를 추출하고 필요에 따라 변환한 후 병합된 데이터셋을 새로운 S3 위치에 로드하는 ETL 작업을 생성합니다.",
        "Explanation": "AWS Glue는 다양한 출처에서 데이터셋을 병합하는 과정을 간소화하는 완전 관리형 ETL(추출, 변환, 로드) 서비스입니다. 자동화된 데이터 검색, 스키마 추론을 지원하며 대규모 데이터 병합을 효율적으로 처리할 수 있는 서버리스 환경을 제공합니다. 이는 머신 러닝 작업을 위한 데이터 준비에 특히 적합합니다.",
        "Other Options": [
            "데이터를 수동으로 다운로드하고 병합하는 것은 비효율적이며, 특히 대량의 데이터셋에 대해 오류가 발생하기 쉽습니다. 이 접근 방식은 클라우드 기능을 활용하지 않으며 데이터 일관성과 품질을 관리하기 위해 상당한 수작업이 필요합니다.",
            "AWS Lambda를 데이터 병합에 사용하는 것은 대량의 데이터셋에 적합하지 않습니다. Lambda는 메모리와 실행 시간 제한이 있기 때문에 메모리에서 병합하는 것은 상당한 양의 데이터를 처리할 때 실패하거나 시간 초과를 초래할 수 있습니다.",
            "Amazon EMR의 Apache Spark는 빅 데이터 처리에 강력한 옵션이지만, AWS Glue에 비해 더 많은 설정과 관리가 필요합니다. Glue는 기본 복잡성을 많이 추상화하여 머신 러닝 목적의 데이터 병합을 더 쉽고 빠르게 구현할 수 있게 합니다."
        ]
    },
    {
        "Question Number": "29",
        "Situation": "ML 엔지니어가 Amazon SageMaker를 사용하여 모델을 배포하고 있으며, 시간이 지남에 따라 정확성을 유지하기 위해 지속적으로 성능을 모니터링하고 싶어합니다. 엔지니어는 잠재적인 데이터 드리프트에 대해 우려하고 있으며 모델 성능 문제에 대한 자동 알림을 설정하고자 합니다.",
        "Question": "프로덕션에서 모델을 효과적으로 모니터링하기 위해 어떤 서비스를 활용해야 합니까? (두 가지 선택)",
        "Options": {
            "1": "Amazon SageMaker Model Monitor",
            "2": "Amazon CloudWatch",
            "3": "Amazon QuickSight",
            "4": "AWS Lambda",
            "5": "Amazon Athena"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon CloudWatch",
            "Amazon SageMaker Model Monitor"
        ],
        "Explanation": "Amazon CloudWatch는 AWS 리소스와 애플리케이션을 모니터링하여 메트릭과 로그를 추적할 수 있게 하며, 이는 모델 성능을 관찰하는 데 중요합니다. Amazon SageMaker Model Monitor는 프로덕션에서 머신 러닝 모델의 품질을 모니터링하고 데이터 드리프트 및 모델 정확성에 영향을 미칠 수 있는 기타 문제를 확인할 수 있게 합니다.",
        "Other Options": [
            "AWS Lambda는 이벤트에 응답하여 코드를 실행할 수 있는 서버리스 컴퓨팅 서비스이지만, 직접적인 모델 모니터링 기능을 제공하지 않습니다.",
            "Amazon QuickSight는 데이터를 시각화하고 보고서를 생성하기 위한 비즈니스 분석 서비스이지만, ML 모델 성능의 실시간 모니터링을 위해 설계되지 않았습니다.",
            "Amazon Athena는 표준 SQL을 사용하여 Amazon S3의 데이터를 분석할 수 있는 대화형 쿼리 서비스이지만, ML 모델 모니터링을 위한 메커니즘을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "30",
        "Situation": "머신 러닝 팀이 프로덕션에서 다양한 작업을 위해 여러 ML 모델을 배포했습니다. 모델이 최적의 성능을 발휘하도록 하고 필요할 때 재훈련 프로세스를 용이하게 하기 위해 팀은 강력한 모니터링 및 로깅 관행을 구현해야 합니다. 그들은 AWS CloudTrail을 사용하여 이러한 모델의 재훈련 활동과 관련된 변경 사항 및 상호작용을 추적하고자 합니다.",
        "Question": "ML 모델의 재훈련 활동을 로깅하고 모니터링하기 위해 AWS CloudTrail을 활용하는 가장 좋은 접근 방식은 무엇입니까?",
        "Options": {
            "1": "CloudTrail을 설정하여 ML 모델 재훈련과 관련된 특정 이벤트를 필터링하지 않고 AWS 계정의 모든 사용자 활동을 로깅합니다.",
            "2": "모델 훈련과 관련된 AWS 서비스에 대한 API 호출을 로깅하도록 CloudTrail을 활성화하고 특정 이벤트에 따라 재훈련을 호출합니다.",
            "3": "모델 재훈련과 관련된 비용만 모니터링하고 실제 활동은 모니터링하지 않습니다.",
            "4": "훈련 데이터가 저장된 S3 버킷에 대한 사용자 접근을 로깅하도록 CloudTrail을 구성하고 다른 AWS 서비스는 무시합니다."
        },
        "Correct Answer": "모델 훈련과 관련된 AWS 서비스에 대한 API 호출을 로깅하도록 CloudTrail을 활성화하고 특정 이벤트에 따라 재훈련을 호출합니다.",
        "Explanation": "이 접근 방식은 팀이 모델 훈련 프로세스와 관련된 모든 API 호출을 추적할 수 있게 합니다. 이는 재훈련을 트리거할 수 있는 특정 이벤트를 모니터링할 수 있게 하여 프로덕션에서 ML 모델의 관리 및 유지보수를 더 잘 할 수 있도록 합니다.",
        "Other Options": [
            "비용만 모니터링하는 것은 실제 훈련 활동이나 ML 모델의 성능에 대한 통찰력을 제공하지 않으며, 이는 효과적인 유지보수에 중요합니다.",
            "S3 버킷 접근을 모니터링하는 것은 중요하지만, 모든 관련 AWS 서비스에서 모델 훈련 및 재훈련 활동의 더 넓은 맥락을 포착하지 못합니다.",
            "특정 이벤트를 필터링하지 않고 모든 사용자 활동을 로깅하면 정보 과부하가 발생할 수 있으며, ML 모델 재훈련과 관련된 실행 가능한 통찰력을 추출하기 어려워질 수 있습니다."
        ]
    },
    {
        "Question Number": "31",
        "Situation": "한 머신 러닝 엔지니어가 Amazon SageMaker에서 훈련 중 수렴이 좋지 않은 징후를 보이는 딥 러닝 모델을 작업하고 있습니다. 엔지니어는 SageMaker Model Debugger를 활용하여 모델의 훈련 과정에서 발생할 수 있는 문제를 식별하고자 합니다.",
        "Question": "엔지니어가 모델의 훈련 메트릭을 분석하고 수렴 문제를 식별하기 위해 SageMaker Model Debugger의 어떤 기능을 사용할 수 있습니까?",
        "Options": {
            "1": "훈련 중 리소스 사용량을 모니터링하기 위해 SageMaker Debugger의 프로파일링을 활성화합니다.",
            "2": "디버거의 규칙을 사용하여 일반적인 수렴 문제에 대한 훈련 작업을 분석합니다.",
            "3": "자동 모델 튜닝을 구현하여 실시간으로 하이퍼파라미터를 조정합니다.",
            "4": "모델의 예측을 이해하기 위해 모델 설명 가능성 기능을 활용합니다."
        },
        "Correct Answer": "디버거의 규칙을 사용하여 일반적인 수렴 문제에 대한 훈련 작업을 분석합니다.",
        "Explanation": "SageMaker Model Debugger는 손실 및 기울기와 같은 훈련 메트릭을 분석하여 수렴과 관련된 문제를 식별할 수 있는 내장 규칙을 제공합니다. 이를 통해 엔지니어는 훈련 과정을 효과적으로 진단할 수 있습니다.",
        "Other Options": [
            "프로파일링은 리소스 사용량을 모니터링하는 데 도움이 될 수 있지만, 모델 성능과 관련된 수렴 문제를 직접적으로 식별하지는 않습니다.",
            "자동 모델 튜닝은 훈련 중 수렴 문제를 진단하기보다는 하이퍼파라미터 최적화에 중점을 둡니다.",
            "모델 설명 가능성 기능은 예측을 이해하는 데 유용하지만, 훈련 단계에서 수렴 문제를 진단하는 데는 도움이 되지 않습니다."
        ]
    },
    {
        "Question Number": "32",
        "Situation": "한 소매 회사가 실시간 재고 관리를 위한 머신 러닝 모델을 배포하고 있습니다. 모델은 피크 쇼핑 시간 동안 지연 문제를 겪고 있어 고객 경험에 영향을 미칩니다. ML 엔지니어는 모델이 변동하는 부하를 처리하고 낮은 지연을 유지할 수 있도록 해야 합니다.",
        "Question": "엔지니어가 ML 모델의 지연 및 확장 문제를 모니터링하고 해결하기 위해 어떤 전략을 구현할 수 있습니까? (두 가지 선택)",
        "Options": {
            "1": "AWS Lambda를 사용하여 이벤트에 응답하여 모델을 호출하여 지연 문제를 제거합니다.",
            "2": "Amazon CloudWatch를 활용하여 모델 성능 메트릭을 모니터링하고 지연 급증에 대한 알람을 설정합니다.",
            "3": "AWS에서 자동 확장 정책을 구현하여 트래픽에 따라 리소스를 동적으로 조정합니다.",
            "4": "리소스 할당을 최소화하고 비용을 줄이기 위해 모델을 단일 EC2 인스턴스에 배포합니다.",
            "5": "AWS X-Ray를 통합하여 요청을 추적하고 모델 아키텍처의 병목 현상을 식별합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon CloudWatch를 활용하여 모델 성능 메트릭을 모니터링하고 지연 급증에 대한 알람을 설정합니다.",
            "AWS에서 자동 확장 정책을 구현하여 트래픽에 따라 리소스를 동적으로 조정합니다."
        ],
        "Explanation": "Amazon CloudWatch를 사용하면 엔지니어가 실시간으로 성능 메트릭을 추적할 수 있어 지연 문제를 사전에 모니터링하고 경고할 수 있습니다. 자동 확장 정책을 구현하면 변동하는 부하를 처리하기 위해 계산 리소스를 자동으로 조정할 수 있어, 모델이 피크 사용 시간에도 낮은 지연을 유지할 수 있습니다.",
        "Other Options": [
            "모델을 단일 EC2 인스턴스에 배포하면 확장성이 제한되고 수요가 높을 때 지연이 증가할 수 있어 문제에 대한 효과적인 해결책이 아닙니다.",
            "AWS Lambda를 사용하는 것은 이벤트 기반 아키텍처에 도움이 될 수 있지만, 지속적인 낮은 지연 접근이 필요한 모델에는 적합하지 않을 수 있으며, 이는 콜드 스타트 문제를 유발하고 실행 시간을 제한합니다.",
            "AWS X-Ray는 요청을 추적하는 데 유용하지만, 리소스의 확장이나 지연 문제를 직접적으로 해결하지 않으며, 오히려 문제가 발생한 후 진단하는 데 도움이 됩니다."
        ]
    },
    {
        "Question Number": "33",
        "Situation": "한 의료 기관이 개인 식별 정보(PII) 및 보호된 건강 정보(PHI)를 포함한 민감한 데이터를 사용하여 환자 결과를 예측하는 머신 러닝 모델을 구축할 계획입니다. 기관은 데이터를 준비하는 동안 규정을 준수해야 하며, 특히 데이터 거주지 및 보안에 관한 사항을 고려해야 합니다.",
        "Question": "PII 및 PHI 규정을 준수하면서 머신 러닝을 위한 민감한 데이터를 준비하기 위한 모범 사례는 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "모델 훈련에 사용하기 전에 PII 및 PHI 데이터를 익명화하여 준수 위험을 최소화합니다.",
            "2": "처리 중 민감한 정보를 보호하기 위해 데이터 암호화를 저장 및 전송 중에 구현합니다.",
            "3": "보안 조치를 구현하지 않고 향상된 통찰력을 위해 원시 데이터를 제3자 공급업체와 공유합니다.",
            "4": "훈련 목적으로 식별할 수 없는 데이터 세트를 생성하기 위해 합성 데이터 생성 기술을 사용합니다.",
            "5": "접근을 단순화하기 위해 데이터 거주지 법을 고려하지 않고 모든 데이터를 중앙 집중식 위치에 저장합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "처리 중 민감한 정보를 보호하기 위해 데이터 암호화를 저장 및 전송 중에 구현합니다.",
            "모델 훈련에 사용하기 전에 PII 및 PHI 데이터를 익명화하여 준수 위험을 최소화합니다."
        ],
        "Explanation": "데이터 암호화를 구현하면 민감한 정보가 저장 및 전송 중에 보호되며, 준수 요구 사항을 충족합니다. PII 및 PHI를 익명화하면 민감한 정보 노출 위험이 줄어들어 준수 위험을 최소화하면서 기관이 데이터를 모델 훈련에 활용할 수 있게 됩니다.",
        "Other Options": [
            "합성 데이터 생성 사용은 유용할 수 있지만, 데이터의 성격과 특정 규정에 따라 항상 실행 가능하거나 준수할 수 있는 것은 아닙니다. 또한, 합성 데이터에만 의존하면 실제 데이터의 미세한 차이를 포착하지 못할 수 있습니다.",
            "모든 데이터를 중앙 집중식 위치에 저장하되 데이터 거주지 법을 고려하지 않는 것은 준수 요구 사항을 위반하는 것이며, 상당한 법적 결과를 초래할 수 있습니다.",
            "보안 조치를 구현하지 않고 원시 데이터를 제3자 공급업체와 공유하는 것은 민감한 정보를 노출시키고 준수 규정을 위반하여 잠재적인 데이터 유출 및 법적 문제를 초래할 수 있습니다."
        ]
    },
    {
        "Question Number": "34",
        "Situation": "한 금융 서비스 회사가 머신 러닝 모델을 위한 지속적인 통합 및 지속적인 배포(CI/CD) 파이프라인을 구현하려고 합니다. 그들은 모델이나 데이터에 대한 변경 사항이 최소한의 수동 개입으로 자동으로 테스트되고 프로덕션에 배포되도록 보장하고자 합니다. 팀은 또한 다양한 환경에서 일관성과 재현성을 유지하는 것에 대해 우려하고 있습니다.",
        "Question": "다음 전략 중 머신 러닝 워크플로우에서 CI/CD 원칙을 구현하는 데 가장 효과적인 것은 무엇입니까?",
        "Options": {
            "1": "정식 CI/CD 프로세스 없이 주기적으로 모델을 업데이트하는 배치 작업을 실행하기 위해 Amazon EC2 인스턴스를 활용합니다.",
            "2": "모델 코드를 저장하기 위해 Git 리포지토리를 설정하고 변경 사항이 있을 때마다 수동으로 배포를 트리거합니다.",
            "3": "AWS CodePipeline을 사용하여 머신 러닝 모델의 빌드, 테스트 및 배포 단계를 자동화합니다.",
            "4": "모델이 의도한 대로 작동하는지 확인하기 위해 로컬에서 테스트한 후 수동으로 모델을 프로덕션에 배포합니다."
        },
        "Correct Answer": "AWS CodePipeline을 사용하여 머신 러닝 모델의 빌드, 테스트 및 배포 단계를 자동화합니다.",
        "Explanation": "AWS CodePipeline은 CI/CD 프로세스를 자동화하도록 특별히 설계되어 머신 러닝 모델의 통합 및 배포를 원활하게 수행할 수 있습니다. 이는 변경 사항을 테스트하고 배포하는 구조화된 접근 방식을 제공하여 일관성을 보장하고 인적 오류의 가능성을 줄입니다.",
        "Other Options": [
            "모델을 프로덕션에 수동으로 배포하는 것은 인적 개입에 의존하므로 위험과 지연을 초래하며 배포 관행의 일관성을 저해할 수 있습니다.",
            "Git 리포지토리를 설정하고 수동으로 배포를 트리거하는 것은 CI/CD 파이프라인의 자동화 및 효율성이 부족하여 일관된 워크플로우를 유지하는 데 덜 효과적입니다.",
            "Amazon EC2 인스턴스를 배치 작업에 활용하는 것은 CI/CD 원칙과 일치하지 않으며, 신뢰할 수 있는 모델 배포에 필요한 자동화 및 테스트 단계를 결여하고 있습니다."
        ]
    },
    {
        "Question Number": "35",
        "Situation": "한 ML 엔지니어가 AWS에서 머신 러닝 워크로드와 관련된 비용을 관리하는 임무를 맡고 있습니다. 그들은 최적의 리소스 활용을 보장하면서 비용을 효과적으로 모니터링하고 제어할 수 있는 메커니즘을 구현해야 합니다.",
        "Question": "ML 엔지니어가 AWS 서비스에 대한 비용 할당량을 설정하고 지출을 최적화하는 데 가장 적합한 도구는 무엇입니까?",
        "Options": {
            "1": "AWS Lambda",
            "2": "AWS CodePipeline",
            "3": "AWS CloudFormation",
            "4": "AWS Budgets"
        },
        "Correct Answer": "AWS Budgets",
        "Explanation": "AWS Budgets는 사용자가 사용자 정의 비용 및 사용 예산을 설정할 수 있게 해주며, 예산 금액을 초과할 경우 사용자에게 알림을 보낼 수 있습니다. 이 도구는 비용 모니터링 및 지출 최적화를 위해 특별히 설계되어 있어 비용 할당량 설정에 가장 적합한 선택입니다.",
        "Other Options": [
            "AWS CloudFormation은 인프라를 코드로 사용하여 AWS 리소스를 프로비저닝하고 관리하는 데 사용됩니다. 비용 모니터링이나 예산 기능을 제공하지 않습니다.",
            "AWS Lambda는 이벤트에 응답하여 코드를 실행하는 서버리스 컴퓨팅 서비스입니다. 리소스를 자동으로 확장하여 비용 최적화에 도움을 줄 수 있지만, 예산 설정이나 비용 모니터링 도구는 제공하지 않습니다.",
            "AWS CodePipeline은 애플리케이션 개발의 빌드, 테스트 및 배포 단계를 자동화하는 데 사용되는 지속적인 통합 및 지속적인 배포 서비스입니다. 비용 관리나 예산 관련 기능을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "36",
        "Situation": "한 금융 서비스 회사가 Amazon S3에 저장된 다양한 파일 유형(CSV, JSON, 이미지 등)으로 구성된 대규모 데이터 세트를 보유하고 있습니다. 그들은 이 데이터를 Amazon SageMaker에서 머신 러닝 모델 교육을 위해 효율적으로 준비하면서 데이터가 적절하게 접근 가능하고 성능을 최적화하도록 해야 합니다.",
        "Question": "이 시나리오에서 머신 러닝 모델 교육을 위해 데이터를 구성하는 가장 효과적인 방법은 무엇입니까?",
        "Options": {
            "1": "AWS Glue를 사용하여 데이터를 카탈로그하고 Amazon SageMaker에 로드하기 전에 단일 형식으로 변환합니다.",
            "2": "Amazon EFS를 사용하여 데이터를 저장하고 교육 중 Amazon SageMaker에서 직접 접근합니다.",
            "3": "Amazon FSx를 사용하여 S3 데이터를 복제하여 SageMaker가 교육 목적으로 복제된 데이터 세트에 접근할 수 있도록 합니다.",
            "4": "AWS Data Pipeline을 사용하여 변환 없이 Amazon S3에서 Amazon SageMaker로 데이터를 직접 이동합니다."
        },
        "Correct Answer": "AWS Glue를 사용하여 데이터를 카탈로그하고 Amazon SageMaker에 로드하기 전에 단일 형식으로 변환합니다.",
        "Explanation": "AWS Glue를 사용하면 머신 러닝에 적합한 형식으로 데이터를 효율적으로 카탈로그하고 변환할 수 있습니다. 이 과정은 Amazon SageMaker에서 교육을 위한 데이터 세트를 최적화하여 모델이 일관된 구조와 형식을 활용할 수 있도록 보장합니다. 이는 효과적인 학습에 매우 중요합니다.",
        "Other Options": [
            "Amazon EFS를 사용하면 파일에 직접 접근할 수 있지만, 효과적인 모델 교육에 필수적인 데이터 변환 및 카탈로그 필요성을 해결하지 않습니다.",
            "Amazon FSx를 사용하면 파일 시스템 인터페이스를 제공할 수 있지만, 불필요한 복잡성을 추가할 수 있으며 머신 러닝을 위한 데이터 변환이나 최적화를 본질적으로 촉진하지 않습니다.",
            "AWS Data Pipeline을 사용하여 변환 없이 데이터를 직접 이동하는 것은 머신 러닝 모범 사례에 맞는 형식으로 데이터를 준비해야 할 필요성을 무시하며, 이는 모델 교육 중 비효율성을 초래할 수 있습니다."
        ]
    },
    {
        "Question Number": "37",
        "Situation": "소매 회사가 다양한 제품의 미래 판매를 예측하기 위한 수요 예측 모델을 구축하고 있습니다. 데이터 과학 팀은 Amazon SageMaker의 스크립트 모드를 활용하여 TensorFlow 및 PyTorch와 같은 지원되는 프레임워크를 사용하여 모델을 효율적으로 훈련하고자 합니다. 그들은 SageMaker의 분산 훈련 기능의 힘을 활용하면서 훈련 스크립트를 사용자 정의할 수 있는지 확인해야 합니다.",
        "Question": "팀이 SageMaker 스크립트 모드를 사용하여 수요 예측 모델을 효과적으로 훈련하기 위해 어떤 접근 방식을 취해야 합니까? (두 가지 선택)",
        "Options": {
            "1": "모델 훈련 전에 데이터를 전처리하기 위해 SageMaker Processing을 활용합니다.",
            "2": "TensorFlow 또는 PyTorch를 사용하여 사용자 정의 훈련 스크립트를 생성하고 이를 SageMaker 내에 배포합니다.",
            "3": "자동화된 훈련 및 하이퍼파라미터 튜닝을 위해 SageMaker의 내장 알고리즘을 사용합니다.",
            "4": "사용자 정의 PyTorch 훈련 루프를 사용하여 SageMaker의 스크립트 모드로 모델을 훈련합니다.",
            "5": "실시간 예측을 위한 기능을 관리하고 검색하기 위해 SageMaker에 기능 저장소를 구현합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "TensorFlow 또는 PyTorch를 사용하여 사용자 정의 훈련 스크립트를 생성하고 이를 SageMaker 내에 배포합니다.",
            "사용자 정의 PyTorch 훈련 루프를 사용하여 SageMaker의 스크립트 모드로 모델을 훈련합니다."
        ],
        "Explanation": "SageMaker의 스크립트 모드를 사용하면 팀이 TensorFlow 또는 PyTorch와 같은 프레임워크를 사용하여 사용자 정의 훈련 스크립트를 생성할 수 있어 수요 예측 접근 방식을 맞춤화할 수 있습니다. 이러한 스크립트를 SageMaker에 배포할 수 있는 능력은 훈련을 위한 강력하고 확장 가능한 환경을 제공합니다. 또한, 사용자 정의 PyTorch 훈련 루프를 구현하면 모델 아키텍처와 훈련 방법론에서 더 큰 유연성을 제공합니다.",
        "Other Options": [
            "SageMaker의 내장 알고리즘은 특정 사용 사례에 유용하지만, 복잡한 수요 예측 모델에 필요한 사용자 정의를 제공하지 않을 수 있어 이 시나리오에는 적합하지 않습니다.",
            "SageMaker Processing은 데이터 전처리에 훌륭하지만, 모델 훈련 과정에 직접적으로 기여하지 않으며, 이는 이 질문의 주요 초점입니다.",
            "기능 저장소를 구현하는 것은 기능을 관리하는 데 유용하지만, 모델 훈련 자체와는 직접적인 관련이 없으며, 이는 여기서의 핵심 요구 사항입니다."
        ]
    },
    {
        "Question Number": "38",
        "Situation": "데이터 과학자가 기계 학습 모델 훈련을 위한 대규모 데이터 세트를 준비하고 있습니다. 데이터 세트는 다양한 파일 형식으로 구성되어 있으며, 각 형식은 성능, 확장성 및 사용 용이성에 대한 장단점이 다릅니다. 데이터 과학자는 효율성과 AWS 서비스와의 호환성을 균형 있게 고려한 형식을 선택해야 합니다.",
        "Question": "AWS 분석 서비스와의 호환성을 보장하면서 대규모 데이터 세트를 효율적으로 저장하고 빠르게 검색하기에 가장 적합한 데이터 형식은 무엇입니까?",
        "Options": {
            "1": "Apache Parquet",
            "2": "CSV",
            "3": "Apache Avro",
            "4": "JSON"
        },
        "Correct Answer": "Apache Parquet",
        "Explanation": "Apache Parquet는 대규모 데이터 세트 사용에 최적화된 열 기반 저장 형식으로, 효율적인 데이터 압축 및 인코딩 방식을 제공합니다. 분석에 특히 적합하며, Amazon Athena, Amazon Redshift 및 Amazon EMR과 같은 다양한 AWS 서비스와 호환되어 빅 데이터 애플리케이션에 선호되는 선택입니다.",
        "Other Options": [
            "JSON은 유연한 형식이지만 대규모 데이터 세트에 최적화되어 있지 않으며, Parquet와 같은 열 기반 형식에 비해 저장 비용 증가 및 느린 쿼리 성능을 초래할 수 있습니다.",
            "CSV는 데이터 저장 및 교환에 널리 사용되는 형식이지만, 복잡한 데이터 유형에 대한 지원이 부족하고 효율적인 압축을 제공하지 않아 파일 크기가 커지고 읽기 시간이 느려질 수 있습니다.",
            "Apache Avro는 데이터 직렬화 및 스키마 진화에 적합한 형식이지만, 일반적으로 대규모 분석보다는 스트리밍 시나리오에서 사용되므로 이 맥락에서 Parquet보다 덜 적합합니다."
        ]
    },
    {
        "Question Number": "39",
        "Situation": "기계 학습 엔지니어가 이미지 분류 모델을 개발하고 있으며, 모델이 훈련 데이터에서는 잘 작동하지만 검증 세트에서는 성능이 저조하다는 것을 발견했습니다. 엔지니어는 과적합에 대해 우려하고 있으며, 훈련 데이터에서 학습하는 모델의 능력을 손상시키지 않으면서 일반화를 개선하기 위한 전략을 구현하고자 합니다.",
        "Question": "엔지니어가 모델의 학습 능력을 유지하면서 과적합을 효과적으로 완화하기 위해 어떤 기술을 구현해야 합니까?",
        "Options": {
            "1": "모델을 더 큰 데이터 세트에서 훈련하되 성능을 검증하지 않습니다.",
            "2": "가장 관련성이 높은 샘플에 집중하기 위해 훈련 데이터 세트의 크기를 줄입니다.",
            "3": "신경망에 더 많은 레이어를 추가하여 모델의 복잡성을 증가시킵니다.",
            "4": "훈련 중 모델의 손실 함수에 L2 정규화를 적용합니다."
        },
        "Correct Answer": "훈련 중 모델의 손실 함수에 L2 정규화를 적용합니다.",
        "Explanation": "L2 정규화를 적용하면 큰 가중치에 패널티를 부여하고 모델을 더 단순하게 유지하여 과적합을 방지하는 데 도움이 됩니다. 이를 통해 모델은 훈련 데이터 세트에서 효과적으로 학습하면서도 보지 못한 데이터에 대해 더 잘 일반화할 수 있습니다.",
        "Other Options": [
            "모델의 복잡성을 증가시켜 더 많은 레이어를 추가하는 것은 과적합을 악화시킬 가능성이 높으며, 복잡한 모델은 훈련 데이터를 암기할 수 있습니다.",
            "훈련 데이터 세트의 크기를 줄이면 모델이 기본 패턴을 효과적으로 학습할 수 있는 충분한 데이터가 없을 수 있어 과소적합으로 이어질 수 있습니다.",
            "모델을 더 큰 데이터 세트에서 훈련하되 성능을 검증하지 않으면 모델이 적절하게 정규화되지 않을 경우 과적합으로 이어질 수 있으며, 데이터의 노이즈를 학습할 수 있습니다."
        ]
    },
    {
        "Question Number": "40",
        "Situation": "기계 학습 엔지니어가 새로운 이미지 분류 모델을 프로덕션에 배포하는 임무를 맡았습니다. 이 모델은 TensorFlow를 사용하여 구축되었으며, 엔지니어는 컨테이너화를 활용하여 모델이 이식 가능하고 다양한 환경에서 쉽게 관리될 수 있도록 하기를 원합니다.",
        "Question": "엔지니어가 AWS 컨테이너 서비스를 사용하여 TensorFlow 모델을 효율적으로 배포하기 위해 어떤 접근 방식을 취해야 합니까?",
        "Options": {
            "1": "미리 구축된 TensorFlow 컨테이너를 사용하여 SageMaker 엔드포인트를 생성하여 모델에 대한 자동 스케일링 및 관리를 제공합니다.",
            "2": "컨테이너화 없이 EC2 인스턴스에 모델을 수동으로 배포하여 환경에 대한 완전한 제어를 유지합니다.",
            "3": "TensorFlow 모델에 대한 Docker 이미지를 구축하고, 이를 Amazon ECR에 푸시한 후 Amazon ECS를 사용하여 Fargate 런치 타입으로 배포합니다.",
            "4": "AWS Lambda를 사용하여 컨테이너화 없이 모델을 직접 배포하고 TensorFlow에 대한 내장 지원을 활용합니다."
        },
        "Correct Answer": "TensorFlow 모델에 대한 Docker 이미지를 구축하고, 이를 Amazon ECR에 푸시한 후 Amazon ECS를 사용하여 Fargate 런치 타입으로 배포합니다.",
        "Explanation": "TensorFlow 모델에 대한 Docker 이미지를 구축하고 Amazon ECS를 통해 Fargate로 배포하면 서버리스 컨테이너 관리 접근 방식을 가능하게 하여 운영 오버헤드를 최소화하고 다양한 환경에서 이식성을 보장합니다.",
        "Other Options": [
            "컨테이너화 없이 AWS Lambda를 사용하여 배포하면 모델의 기능이 제한되며, 특히 무거운 계산이 필요하거나 Lambda가 지원하지 않을 수 있는 특정 종속성이 있는 경우 더욱 그렇습니다.",
            "컨테이너화 없이 EC2 인스턴스에 모델을 수동으로 배포하면 이식성과 관리 용이성과 같은 컨테이너의 이점을 활용하지 못하며 운영 부담이 증가할 수 있습니다.",
            "미리 구축된 TensorFlow 컨테이너를 사용하여 SageMaker 엔드포인트를 생성하는 것은 유효한 접근 방식이지만, 특히 마이크로서비스 아키텍처에서 ECS를 통해 모델을 배포하는 것만큼의 유연성과 제어를 제공하지 않을 수 있습니다."
        ]
    },
    {
        "Question Number": "41",
        "Situation": "소매 회사가 고객의 탐색 기록을 기반으로 제품을 추천하는 추천 시스템을 구현하고자 합니다. 그들은 AWS에서 제공하는 다양한 도구와 프레임워크를 고려하고 있습니다.",
        "Question": "AWS 서비스를 사용하여 추천 시스템을 신속하게 배포하기에 가장 적합한 접근 방식은 무엇입니까?",
        "Options": {
            "1": "Amazon SageMaker JumpStart를 활용하여 추천 시스템에 맞춘 미리 구축된 솔루션 템플릿을 활용합니다.",
            "2": "TensorFlow를 사용하여 맞춤형 추천 알고리즘을 처음부터 구축하고 EC2 인스턴스에 배포합니다.",
            "3": "정적 규칙을 사용하여 간단한 휴리스틱 기반 추천 시스템을 개발하고 온프레미스 서버에 배포합니다.",
            "4": "기존 AWS 솔루션을 고려하지 않고 여러 알고리즘을 사용하여 복잡한 앙상블 모델을 구현합니다."
        },
        "Correct Answer": "Amazon SageMaker JumpStart를 활용하여 추천 시스템에 맞춘 미리 구축된 솔루션 템플릿을 활용합니다.",
        "Explanation": "Amazon SageMaker JumpStart는 추천 시스템을 포함한 일반적인 기계 학습 작업을 위해 특별히 설계된 미리 구축된 템플릿과 알고리즘을 제공합니다. 이를 통해 더 빠른 배포가 가능하고 처음부터 모델을 구축하는 복잡성을 줄일 수 있습니다.",
        "Other Options": [
            "맞춤형 추천 알고리즘을 처음부터 구축하는 것은 시간 소모가 크고 상당한 전문 지식과 자원이 필요하여, 사용 가능한 솔루션을 사용하는 것에 비해 비효율적입니다.",
            "휴리스틱 기반 추천 시스템은 기계 학습 모델의 정교함과 적응성이 부족하여 덜 효과적인 추천을 초래할 수 있습니다.",
            "기존 솔루션을 활용하지 않고 복잡한 앙상블 모델을 구현하면 불필요한 복잡성과 긴 개발 시간을 초래할 수 있으며, 특히 더 간단하고 검증된 옵션이 있는 경우 더욱 그렇습니다."
        ]
    },
    {
        "Question Number": "42",
        "Situation": "기계 학습 엔지니어가 '색상', '크기', '재료'와 같은 특성을 포함하는 범주형 데이터 세트로 작업하고 있습니다. 엔지니어는 이러한 범주형 특성을 기계 학습 모델 훈련에 적합한 숫자 형식으로 변환해야 합니다.",
        "Question": "엔지니어가 효과적인 데이터 준비를 위해 고려해야 할 두 가지 인코딩 기술은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "'색상'과 '크기'에 대한 원-핫 인코딩",
            "2": "'색상'과 '재료'에 대한 레이블 인코딩",
            "3": "'색상'과 '크기'에 대한 카운트 인코딩",
            "4": "'크기'와 '재료'에 대한 이진 인코딩",
            "5": "'재료'에 대한 토큰화"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "'색상'과 '크기'에 대한 원-핫 인코딩",
            "'색상'과 '재료'에 대한 레이블 인코딩"
        ],
        "Explanation": "원-핫 인코딩은 '색상'과 '크기'와 같이 순서 관계가 없는 범주형 변수에 효과적이며, 각 범주에 대해 이진 열을 생성합니다. 레이블 인코딩은 '색상'과 '재료'와 같은 범주형 특성에 사용할 수 있으며, 자연스러운 순서가 있거나 모델이 정수 값을 적절하게 해석할 수 있는 경우에 적합합니다.",
        "Other Options": [
            "토큰화는 일반적으로 범주형 특성보다는 텍스트 데이터에 사용됩니다. 이 경우 '재료'에 적합하지 않습니다.",
            "이진 인코딩은 해석 가능성이 떨어질 수 있으며, 일반적으로 고차원 범주형 특성에 사용됩니다. 이 맥락에서 '크기'와 '재료'에 최적이 아닙니다.",
            "카운트 인코딩은 유용하지만 '색상'과 '크기'와 같은 범주형 특성에 대해 원-핫 인코딩이나 레이블 인코딩만큼의 해석 가능성을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "43",
        "Situation": "머신 러닝 엔지니어가 주어진 데이터셋에서 성능을 개선하기 위해 딥 러닝 모델을 조정하고 있습니다. 엔지니어는 과적합을 완화하고 일반화를 향상시키기 위해 정규화 기법을 구현하는 것을 고려하고 있습니다. 그들은 결정을 내리기 전에 다양한 정규화 방법의 이점을 이해하고 싶어합니다.",
        "Question": "다음 중 훈련 중에 뉴런을 무작위로 드롭아웃하여 과적합을 줄이는 데 주로 사용되는 정규화 기법은 무엇입니까?",
        "Options": {
            "1": "드롭아웃, 이는 각 훈련 반복 동안 뉴런의 일부를 무작위로 비활성화합니다.",
            "2": "L1 정규화, 이는 절대 가중치에 대한 패널티를 부여하여 모델 매개변수의 희소성을 촉진합니다.",
            "3": "가중치 감소, 이는 모델의 큰 가중치에 패널티를 부여하여 단순성을 촉진합니다.",
            "4": "L2 정규화, 이는 가중치의 제곱에 기반한 패널티를 적용하여 큰 가중치를 억제합니다."
        },
        "Correct Answer": "드롭아웃, 이는 각 훈련 반복 동안 뉴런의 일부를 무작위로 비활성화합니다.",
        "Explanation": "드롭아웃은 각 훈련 반복 동안 네트워크의 일부 뉴런을 무작위로 비활성화하여 과적합을 방지하는 데 도움이 되는 정규화 기법입니다. 이는 모델이 보지 못한 데이터에 더 잘 일반화되는 더 강력한 특징을 학습하도록 강요합니다.",
        "Other Options": [
            "가중치 감소는 주로 큰 가중치에 패널티를 부여하여 모델 복잡성을 줄이는 데 도움이 되지만, 뉴런을 무작위로 드롭하는 것과는 관련이 없습니다.",
            "L1 정규화는 가중치의 절대값에 기반한 패널티를 추가하여 모델 매개변수의 희소성을 촉진하지만, 드롭아웃과는 관련이 없습니다.",
            "L2 정규화는 가중치의 제곱에 기반한 패널티를 추가하여 큰 가중치를 억제하지만, 드롭아웃처럼 뉴런을 무작위로 드롭하는 메커니즘은 포함되어 있지 않습니다."
        ]
    },
    {
        "Question Number": "44",
        "Situation": "데이터 과학자가 Amazon SageMaker에서 머신 러닝 모델을 위한 데이터셋을 준비하고 있습니다. 데이터셋은 여러 S3 버킷에 걸쳐 여러 CSV 파일로 저장되어 있습니다. 과학자는 Amazon SageMaker Data Wrangler를 사용하여 데이터를 효율적으로 통합하고 변환하여 모델 훈련을 위한 단일 기능 세트를 만들고자 합니다.",
        "Question": "Amazon SageMaker Data Wrangler 내에서 데이터를 수집하고 준비하는 가장 효율적인 접근 방식은 무엇입니까?",
        "Options": {
            "1": "각 CSV 파일을 수동으로 다운로드하고, 이를 단일 CSV로 결합한 후 Data Wrangler가 접근할 수 있도록 S3에 다시 업로드합니다.",
            "2": "Amazon SageMaker Data Wrangler의 내장 커넥터를 사용하여 S3 버킷에서 CSV 파일을 직접 단일 Data Wrangler 흐름으로 가져옵니다.",
            "3": "CSV 파일을 Amazon RDS로 내보낸 다음, Amazon SageMaker Data Wrangler를 사용하여 RDS 인스턴스에 연결하여 데이터 준비를 수행합니다.",
            "4": "S3에 새로운 CSV가 업로드될 때 트리거되는 Lambda 함수를 생성하여 파일을 결합하고, Data Wrangler를 위한 출력물을 새로운 S3 버킷에 저장합니다."
        },
        "Correct Answer": "Amazon SageMaker Data Wrangler의 내장 커넥터를 사용하여 S3 버킷에서 CSV 파일을 직접 단일 Data Wrangler 흐름으로 가져옵니다.",
        "Explanation": "Amazon SageMaker Data Wrangler는 사용자가 수동 다운로드나 업로드 없이 S3 버킷을 포함한 다양한 소스에서 데이터를 직접 가져올 수 있도록 하는 내장 커넥터를 제공합니다. 이는 데이터 준비 프로세스를 간소화하고 효율성을 향상시킵니다.",
        "Other Options": [
            "이 옵션은 파일을 다운로드하고 업로드하는 수동 개입이 필요하므로 Data Wrangler의 기능을 사용하는 것에 비해 시간 소모적이고 비효율적입니다.",
            "Lambda 함수를 생성하면 일부 프로세스를 자동화할 수 있지만, S3에서 CSV 파일을 처리하는 데 필요한 복잡성을 불필요하게 추가합니다.",
            "Amazon RDS로 내보내는 것은 복잡성을 추가하며, Data Wrangler가 S3에서 CSV 파일에 직접 접근할 수 있기 때문에 필요하지 않습니다."
        ]
    },
    {
        "Question Number": "45",
        "Situation": "ML 엔지니어는 배포된 ML 모델이 다양한 트래픽을 처리할 수 있도록 적절하게 확장되면서 비용을 관리 가능하게 유지하도록 하는 임무를 맡고 있습니다. 엔지니어는 피크 시간 동안 모델이 용량 부족으로 인해 지연 문제를 겪고 있으며, 이로 인해 운영 비용이 증가하고 있음을 발견했습니다. 엔지니어는 수요에 따라 자동으로 확장할 수 있는 솔루션을 찾고 있으며, 자원 사용을 최적화하고자 합니다.",
        "Question": "비용을 최소화하면서 ML 모델의 용량을 자동으로 확장하는 가장 좋은 접근 방식은 무엇입니까?",
        "Options": {
            "1": "AWS Lambda를 프로비저닝된 동시성으로 구성하여 피크 부하 동안 일관된 성능을 보장합니다.",
            "2": "Amazon SageMaker Auto Scaling을 구현하여 트래픽 패턴에 따라 ML 엔드포인트 수를 동적으로 조정합니다.",
            "3": "Amazon EC2 스팟 인스턴스를 사용하여 트래픽 급증을 처리하고 확장과 관련된 비용을 줄입니다.",
            "4": "AWS CloudWatch를 설정하여 트래픽을 모니터링하고 관찰된 패턴에 따라 수동으로 인스턴스 수를 조정합니다."
        },
        "Correct Answer": "Amazon SageMaker Auto Scaling을 구현하여 트래픽 패턴에 따라 ML 엔드포인트 수를 동적으로 조정합니다.",
        "Explanation": "Amazon SageMaker Auto Scaling을 사용하면 실시간 트래픽 패턴에 따라 ML 엔드포인트 수를 동적으로 조정할 수 있어, 수동 개입 없이 최적의 성능과 비용 효율성을 보장합니다.",
        "Other Options": [
            "AWS Lambda를 프로비저닝된 동시성으로 구성하는 것은 SageMaker에 배포된 ML 모델에는 적합하지 않으며, 주로 서버리스 함수에 사용되므로 ML 모델 트래픽을 직접 처리하는 데 적용되지 않을 수 있습니다.",
            "Amazon EC2 스팟 인스턴스를 사용하는 것은 비용을 줄이는 데 도움이 될 수 있지만, 변동하는 트래픽을 효과적으로 처리하기 위한 자동 확장 기능을 제공하지 않아 예기치 않은 급증 시 지연 문제를 초래할 수 있습니다.",
            "AWS CloudWatch를 설정하여 트래픽을 모니터링하고 수동으로 인스턴스 수를 조정하는 것은 비효율적이며, 수요 변화에 대한 자동 응답 대신 인간의 개입이 필요하므로 확장 지연을 초래할 수 있습니다."
        ]
    },
    {
        "Question Number": "46",
        "Situation": "ML 엔지니어가 대규모 이미지 분류 모델을 프로덕션에 배포할 준비를 하고 있으며 최적의 성능을 보장해야 합니다. 이 모델은 특히 추론 중에 상당한 계산 자원을 요구합니다. 엔지니어는 배포를 위해 자원 요구 사항에 따라 다양한 인스턴스 유형을 고려하고 있습니다.",
        "Question": "GPU 자원에 크게 의존하는 이 이미지 분류 모델의 최상의 성능을 달성하기 위해 엔지니어가 선택해야 할 AWS 인스턴스 유형은 무엇인가요?",
        "Options": {
            "1": "t3.medium",
            "2": "m5.large",
            "3": "p3.2xlarge",
            "4": "c5.4xlarge"
        },
        "Correct Answer": "p3.2xlarge",
        "Explanation": "p3.2xlarge 인스턴스는 고성능 GPU가 필요한 머신 러닝 작업을 위해 특별히 설계되어 대규모 이미지 분류 모델을 효율적으로 실행하는 데 이상적입니다. 이 인스턴스는 추론 프로세스를 크게 가속화할 수 있는 강력한 NVIDIA V100 GPU를 제공합니다.",
        "Other Options": [
            "t3.medium 인스턴스는 제한된 CPU와 GPU 기능이 없는 범용 인스턴스 유형으로, 이미지 분류와 같은 요구가 높은 ML 작업에는 적합하지 않습니다.",
            "m5.large 인스턴스는 메모리 집약적인 애플리케이션에 최적화되어 있지만 GPU 지원이 부족하여 GPU에 의존하는 이미지 분류 모델의 성능에 필수적입니다.",
            "c5.4xlarge 인스턴스는 계산 집약적인 작업에 최적화되어 있지만, 딥 러닝 모델의 계산 요구 사항을 효율적으로 처리하는 데 필요한 GPU 자원을 포함하지 않습니다."
        ]
    },
    {
        "Question Number": "47",
        "Situation": "머신 러닝 팀이 ML 모델 배포를 위한 CI/CD 파이프라인을 구현하고 있습니다. 그들은 민감한 데이터를 보호하고 무단 접근을 방지하기 위해 파이프라인이 보안 모범 사례를 준수하도록 하고 싶어합니다.",
        "Question": "CI/CD 파이프라인의 보안을 강화하기 위해 우선적으로 고려해야 할 관행은 무엇인가요?",
        "Options": {
            "1": "파이프라인에 대한 역할 기반 접근 제어를 구현합니다.",
            "2": "모든 파이프라인 활동에 대한 로깅을 활성화합니다.",
            "3": "검증 단계 없이 모델 테스트를 자동화합니다.",
            "4": "모델 저장을 위해 공개 저장소를 사용합니다."
        },
        "Correct Answer": "파이프라인에 대한 역할 기반 접근 제어를 구현합니다.",
        "Explanation": "역할 기반 접근 제어(RBAC)를 구현하면 권한이 있는 사용자만 CI/CD 파이프라인 내의 특정 자원과 작업에 접근할 수 있도록 하여 보안 태세를 크게 향상시킵니다.",
        "Other Options": [
            "모델 저장을 위해 공개 저장소를 사용하는 것은 민감한 데이터와 지적 재산을 무단 사용자에게 노출할 수 있어 상당한 보안 위험이 있습니다.",
            "모든 파이프라인 활동에 대한 로깅을 활성화하는 것은 감사 및 모니터링에 중요하지만, 접근을 직접 제한하거나 누가 파이프라인과 상호작용할 수 있는지를 제어하지 않기 때문에 주요 보안 조치로서는 효과적이지 않습니다.",
            "검증 단계 없이 모델 테스트를 자동화하면 적절히 검토되지 않은 모델이 배포될 수 있어 취약점을 초래하고 파이프라인의 보안을 위협할 수 있습니다."
        ]
    },
    {
        "Question Number": "48",
        "Situation": "머신 러닝 엔지니어가 Amazon SageMaker에서 모델을 배포하는 임무를 맡고 있으며, 하루 동안 변동하는 트래픽 수요에 따라 엔드포인트가 자동으로 확장되도록 해야 합니다.",
        "Question": "SageMaker 엔드포인트가 실시간 수요에 따라 자동으로 용량을 조정할 수 있도록 가장 잘 구성할 수 있는 방법은 무엇인가요?",
        "Options": {
            "1": "목표 활용률을 설정하고 피크 시간에 대한 예약된 스케일링 정책을 구성합니다.",
            "2": "변동하는 트래픽을 처리하면서 비용을 관리하기 위해 고정 인스턴스 수를 사용합니다.",
            "3": "실제 요청 속도에 실시간으로 반응하는 동적 스케일링 정책을 구현합니다.",
            "4": "예상 트래픽 패턴에 따라 매주 인스턴스 수를 수동으로 조정합니다."
        },
        "Correct Answer": "실제 요청 속도에 실시간으로 반응하는 동적 스케일링 정책을 구현합니다.",
        "Explanation": "동적 스케일링 정책은 SageMaker 엔드포인트가 실시간 수요에 따라 인스턴스 수를 자동으로 조정할 수 있도록 하여 시스템이 트래픽의 변동을 효율적으로 처리할 수 있도록 합니다.",
        "Other Options": [
            "목표 활용률을 설정하고 예약된 스케일링 정책을 구성하는 것은 피크 시간 외의 예측되지 않은 트래픽을 고려하지 않으므로, 예상치 못한 부하가 발생할 때 성능 문제를 초래할 수 있습니다.",
            "인스턴스 수를 수동으로 조정하는 것은 비효율적이며 피크 시간 동안 서비스 저하를 초래하거나 저트래픽 기간 동안 불필요한 비용을 초래할 수 있습니다.",
            "고정 인스턴스 수를 사용하는 것은 변화하는 트래픽 수요에 적응하지 않으므로, 높은 수요 시 성능 병목 현상을 초래하거나 낮은 수요 시 자원이 낭비될 수 있습니다."
        ]
    },
    {
        "Question Number": "49",
        "Situation": "한 금융 서비스 회사는 기계 학습 모델과 관련된 AWS 서비스에 대한 모든 API 호출이 준수 및 모니터링 목적으로 기록되도록 해야 합니다. 이 회사는 모델 훈련 및 추론에 관련된 AWS 리소스에서 수행된 모든 작업에 대한 감사 추적을 생성하고자 합니다. ML 엔지니어가 이 솔루션을 구현하는 임무를 맡았습니다.",
        "Question": "API 호출 모니터링을 위한 CloudTrail 트레일을 생성하기 위해 엔지니어가 어떤 조치를 취해야 합니까? (두 가지 선택)",
        "Options": {
            "1": "모든 API에 대한 관리 이벤트를 기록하도록 CloudTrail을 구성합니다.",
            "2": "다양한 AWS 계정에 여러 개의 CloudTrail 트레일을 생성합니다.",
            "3": "CloudTrail 로그를 직접 모니터링하기 위해 Amazon CloudWatch를 설정합니다.",
            "4": "ML 리소스와 동일한 AWS 리전에서 CloudTrail 트레일을 생성합니다.",
            "5": "모델 훈련에 사용되는 S3 버킷에 대한 데이터 이벤트 로깅을 활성화합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "ML 리소스와 동일한 AWS 리전에서 CloudTrail 트레일을 생성합니다.",
            "모든 API에 대한 관리 이벤트를 기록하도록 CloudTrail을 구성합니다."
        ],
        "Explanation": "ML 리소스와 동일한 AWS 리전에서 CloudTrail 트레일을 생성하면 해당 리소스와 관련된 모든 API 호출이 캡처됩니다. 모든 API에 대한 관리 이벤트를 기록하도록 CloudTrail을 구성하면 기계 학습 모델이 사용하는 인프라 및 리소스에 영향을 미치는 작업을 포괄적으로 추적할 수 있습니다.",
        "Other Options": [
            "CloudTrail 로그를 직접 모니터링하기 위해 Amazon CloudWatch를 설정하는 것은 트레일을 생성하기 위한 필수 단계가 아닙니다. CloudTrail 로그는 CloudWatch 통합 없이도 다른 방법으로 모니터링할 수 있습니다.",
            "모델 훈련에 사용되는 S3 버킷에 대한 데이터 이벤트 로깅을 활성화하는 것은 유용하지만, 모든 API 호출을 캡처하기 위해 CloudTrail 트레일을 생성하는 요구 사항을 해결하지 않습니다.",
            "다양한 AWS 계정에 여러 개의 CloudTrail 트레일을 생성하는 것은 불필요하며 감사 프로세스를 복잡하게 만듭니다. 적절한 리전에서 단일 트레일이면 일반적으로 충분합니다."
        ]
    },
    {
        "Question Number": "50",
        "Situation": "한 의료 기관이 환자 재입원을 예측하기 위해 기계 학습 모델을 배포했습니다. 모델을 운영 환경에서 모니터링한 결과, 특정 사용자 행동과 일치하는 예측의 비정상적인 급증이 발견되어 데이터 변조 또는 무단 접근과 같은 잠재적인 보안 문제에 대한 우려가 제기되었습니다.",
        "Question": "모델의 예측과 관련된 보안 문제를 해결하기 위해 팀이 우선적으로 취해야 할 조치는 무엇입니까?",
        "Options": {
            "1": "모델 및 예측에 대한 접근을 추적하기 위해 로깅 및 모니터링을 구현합니다.",
            "2": "비정상적인 급증을 반영하기 위해 새로운 데이터로 모델을 재훈련합니다.",
            "3": "모델에 입력되는 데이터 소스에 대한 보안 감사를 수행합니다.",
            "4": "알림 수를 줄이기 위해 모델의 예측 임계값을 높입니다."
        },
        "Correct Answer": "모델 및 예측에 대한 접근을 추적하기 위해 로깅 및 모니터링을 구현합니다.",
        "Explanation": "로깅 및 모니터링을 구현하는 것은 모델의 예측에 대한 무단 접근 또는 조작을 식별하는 데 필수적입니다. 이 조치는 사용 패턴에 대한 통찰력을 제공하고 보안 위반을 나타낼 수 있는 이상 징후를 감지하는 데 도움이 됩니다.",
        "Other Options": [
            "모델을 재훈련하는 것은 근본적인 보안 문제를 직접 해결하지 못할 수 있으며, 급증의 원인을 이해하기 전에 새로운 문제를 초래할 수 있습니다.",
            "모델의 예측 임계값을 높이는 것은 보안 문제를 해결하지 않으며, 단순히 모델의 민감도를 변경하여 더 많은 예측을 놓칠 수 있습니다.",
            "데이터 소스에 대한 보안 감사를 수행하는 것은 중요하지만, 즉각적인 로깅 및 모니터링이 없으면 팀이 모델의 행동에 대한 중요한 실시간 통찰력을 놓칠 수 있습니다."
        ]
    },
    {
        "Question Number": "51",
        "Situation": "한 전자상거래 플랫폼은 사용자의 탐색 기록 및 구매 행동을 기반으로 제품 추천을 개인화하기 위해 기계 학습을 사용합니다. 시스템이 데이터 보호 규정을 준수하도록 보장하기 위해 회사는 기계 학습 모델을 모니터링하고 감사하기 위한 강력한 솔루션이 필요합니다. 특히 사용자 데이터 사용 및 모델 성능의 변화에 대한 모니터링이 필요합니다.",
        "Question": "전자상거래 플랫폼에 배포된 기계 학습 모델의 성능 및 준수를 모니터링하고 이상이나 문제를 신속하게 감지하기 위한 가장 효과적인 방법은 무엇입니까?",
        "Options": {
            "1": "사용자 상호작용 및 모델 예측을 캡처하는 맞춤형 로깅 솔루션을 배포하여 성능 및 준수를 수동으로 검토합니다.",
            "2": "모델 성능 지표를 모니터링하고 설정된 임계값에서의 편차에 대한 경고를 설정하기 위해 Amazon CloudWatch를 구현합니다.",
            "3": "로그 및 사용자 피드백을 수동으로 검사하여 모델 성능에 대한 정기적인 감사를 예약합니다.",
            "4": "Amazon SageMaker Model Monitor를 사용하여 데이터 품질, 모델 품질을 자동으로 추적하고 정기적인 보고서를 생성하여 준수를 보장합니다."
        },
        "Correct Answer": "Amazon SageMaker Model Monitor를 사용하여 데이터 품질, 모델 품질을 자동으로 추적하고 정기적인 보고서를 생성하여 준수를 보장합니다.",
        "Explanation": "Amazon SageMaker Model Monitor는 기계 학습 모델 모니터링을 위해 특별히 설계되어 데이터 및 모델 품질을 자동으로 추적합니다. 데이터 보호 규정 준수를 평가하는 데 사용할 수 있는 보고서를 생성하여 설명된 시나리오에 가장 효과적인 솔루션입니다.",
        "Other Options": [
            "Amazon CloudWatch를 구현하는 것은 지표 모니터링에 유용하지만, ML 특정 통찰력 및 준수 보고를 위한 SageMaker Model Monitor가 제공하는 전문 기능이 부족합니다.",
            "맞춤형 로깅 솔루션은 상당한 개발 및 유지 관리 노력이 필요할 수 있으며, SageMaker Model Monitor가 제공하는 포괄적인 자동 통찰력을 제공하지 못할 수 있습니다.",
            "수동 검사를 통한 정기적인 감사는 시간이 많이 소요되고 인적 오류가 발생할 수 있어 SageMaker Model Monitor에서 제공하는 자동화된 기능에 비해 효율성이 떨어집니다."
        ]
    },
    {
        "Question Number": "52",
        "Situation": "ML 엔지니어가 프로덕션 환경에 머신러닝 모델을 배포하는 임무를 맡았습니다. 엔지니어는 최적의 성능을 유지하면서 다양한 작업 부하에 따라 배포가 효율적으로 확장될 수 있도록 해야 합니다.",
        "Question": "배포된 ML 모델의 자동 확장을 구성하는 데 가장 적합한 메트릭 조합은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "사용률을 평가하기 위한 인스턴스당 호출 수.",
            "2": "데이터 읽기/쓰기 속도를 평가하기 위한 디스크 I/O 속도.",
            "3": "자원 사용량 및 확장 필요성을 모니터링하기 위한 CPU 사용률.",
            "4": "인스턴스의 부하를 결정하기 위한 메모리 사용량.",
            "5": "최종 사용자에게 빠른 응답 시간을 보장하기 위한 모델 대기 시간."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "최종 사용자에게 빠른 응답 시간을 보장하기 위한 모델 대기 시간.",
            "자원 사용량 및 확장 필요성을 모니터링하기 위한 CPU 사용률."
        ],
        "Explanation": "모델 대기 시간을 모니터링하면 엔지니어가 사용자 요청에 대한 응답이 적시에 이루어지도록 보장하여 사용자 경험을 향상시킬 수 있습니다. CPU 사용률은 인스턴스의 처리 용량이 얼마나 사용되고 있는지를 효과적으로 나타내어 확장 결정에 중요한 메트릭이 됩니다.",
        "Other Options": [
            "메모리 사용량은 중요하지만 모델의 성능을 반드시 반영하지는 않습니다. CPU 사용률이나 모델 대기 시간만큼 확장 필요성을 나타내지 않을 수 있습니다.",
            "인스턴스당 호출 수는 사용량을 알 수 있지만 성능이나 자원 최적화와 직접적으로 상관관계가 없을 수 있습니다.",
            "디스크 I/O 속도는 일반적으로 배포된 모델의 성능을 측정하기보다는 데이터 처리 작업에 더 관련이 있어 자동 확장 결정에 덜 적합합니다."
        ]
    },
    {
        "Question Number": "53",
        "Situation": "데이터 과학 팀이 고객 이탈 예측 모델의 정확성을 개선하기 위해 노력하고 있습니다. 그들은 다양한 알고리즘과 하이퍼파라미터를 실험했지만 원하는 성능 수준에 도달하지 못했습니다. 그들은 여러 모델을 결합하여 각 모델의 강점을 활용하고 개별 약점을 완화하는 방법을 탐색하기로 결정했습니다.",
        "Question": "여러 모델의 출력을 결합하여 예측 성능을 향상시키는 목표에 가장 적합한 머신러닝 기법은 무엇입니까?",
        "Options": {
            "1": "앙상블",
            "2": "부스팅",
            "3": "배깅",
            "4": "스태킹"
        },
        "Correct Answer": "앙상블",
        "Explanation": "앙상블은 여러 모델을 결합하여 전체 성능을 개선하고 과적합의 위험을 줄이는 과정입니다. 이를 통해 팀은 다양한 모델의 강점을 활용하여 최종 출력의 예측 정확성을 향상시킬 수 있습니다.",
        "Other Options": [
            "부스팅은 약한 학습자를 강한 학습자로 변환하기 위해 잘못 분류된 인스턴스의 가중치를 조정하는 특정 앙상블 기법을 의미합니다. 모델 성능을 개선할 수 있지만 모델 결합을 위한 가장 포괄적인 용어는 아닙니다.",
            "배깅, 또는 부트스트랩 집계는 서로 다른 데이터 하위 집합에서 훈련된 여러 모델의 예측을 평균하여 분산을 줄이는 또 다른 앙상블 방법입니다. 그러나 모든 모델 결합 방법을 포함하지는 않습니다.",
            "스태킹은 여러 기본 모델의 예측을 결합하기 위해 메타 모델을 훈련하는 기법입니다. 성능을 개선하기 위한 유효한 접근 방식이지만 앙상블이라는 더 넓은 개념 아래의 특정 기법입니다."
        ]
    },
    {
        "Question Number": "54",
        "Situation": "금융 서비스 회사가 대출 채무 불이행 위험을 예측하는 머신러닝 애플리케이션을 개발하고 있습니다. 그들은 다양한 작업 부하에 따라 비용과 반응성을 최적화하는 방식으로 모델을 배포해야 합니다. 모델은 변동하는 트래픽 패턴을 경험할 것이며 팀은 자원 할당을 위한 최선의 접근 방식을 고려하고 있습니다.",
        "Question": "회사가 비용을 최소화하면서 다양한 작업 부하를 효율적으로 처리하기 위해 선택해야 할 배포 전략은 무엇입니까?",
        "Options": {
            "1": "자동 확장 기능이 있는 온디맨드 리소스.",
            "2": "고정 인스턴스 유형의 온디맨드 리소스.",
            "3": "정적 용량의 프로비저닝된 리소스.",
            "4": "자동 확장이 활성화된 프로비저닝된 리소스."
        },
        "Correct Answer": "자동 확장 기능이 있는 온디맨드 리소스.",
        "Explanation": "자동 확장 기능이 있는 온디맨드 리소스는 애플리케이션이 트래픽 수요에 따라 인스턴스 수를 자동으로 조정할 수 있도록 하여, 낮은 트래픽 기간 동안 비용을 최소화하면서도 높은 수요를 효율적으로 처리할 수 있도록 합니다.",
        "Other Options": [
            "자동 확장이 활성화된 프로비저닝된 리소스는 효과적일 수 있지만 항상 프로비저닝된 기준 용량이 필요하여 사용량이 낮은 기간 동안 더 높은 비용이 발생할 수 있습니다.",
            "고정 인스턴스 유형의 온디맨드 리소스는 확장에 유연성을 허용하지 않아 피크 부하 동안 성능 문제를 초래하거나 낮은 사용량 기간 동안 불필요한 비용이 발생할 수 있습니다.",
            "정적 용량의 프로비저닝된 리소스는 변화하는 작업 부하에 적응하지 않아 과도한 프로비저닝 또는 부족한 프로비저닝을 초래할 수 있으며, 이는 불필요한 비용을 발생시키거나 성능을 저하시킬 수 있습니다."
        ]
    },
    {
        "Question Number": "55",
        "Situation": "한 의료 기관이 환자 재입원을 예측하기 위한 머신러닝 모델을 배포해야 합니다. 이 모델은 새로운 환자 데이터를 기반으로 정기적으로 업데이트되어야 하며, 최소한의 다운타임을 보장해야 합니다. 현재 기관은 다양한 배포 전략을 평가하고 있습니다.",
        "Question": "모델이 정기적으로 업데이트되고 다운타임 없이 들어오는 예측을 처리할 수 있도록 하기 위해 기관이 선택해야 할 배포 전략은 무엇입니까?",
        "Options": {
            "1": "예약된 AWS Lambda 함수를 사용한 배치 추론.",
            "2": "Amazon SageMaker 엔드포인트를 사용한 실시간 추론.",
            "3": "여러 모델 버전을 동시에 배포하여 A/B 테스트.",
            "4": "오프라인 모델 업데이트를 통한 주기적인 재훈련."
        },
        "Correct Answer": "Amazon SageMaker 엔드포인트를 사용한 실시간 추론.",
        "Explanation": "Amazon SageMaker 엔드포인트를 사용한 실시간 추론은 기관이 모델을 배포하여 들어오는 예측 요청을 즉시 처리할 수 있도록 하며, 정기적인 업데이트도 가능하게 합니다. 이 접근 방식은 최소한의 다운타임을 보장하고 최신 모델을 즉시 사용할 수 있도록 합니다.",
        "Other Options": [
            "예약된 AWS Lambda 함수를 사용한 배치 추론은 예측에 지연을 초래하므로 즉각적인 응답이 필요한 시나리오에는 적합하지 않습니다.",
            "여러 모델 버전을 동시에 배포하여 A/B 테스트는 정기적인 업데이트보다는 서로 다른 모델을 비교하는 데 주로 사용되며, 배포 전략을 복잡하게 만들 수 있습니다.",
            "오프라인 모델 업데이트를 통한 주기적인 재훈련은 새로운 모델을 배포해야 하므로 더 긴 다운타임을 초래할 수 있으며, 이는 기관의 지속적인 가용성 요구를 충족하지 못할 수 있습니다."
        ]
    },
    {
        "Question Number": "56",
        "Situation": "한 머신러닝 팀이 Amazon SageMaker와 Amazon S3를 포함한 다양한 서비스를 사용하는 AWS 기반 솔루션을 배포했습니다. 그들은 ML 워크플로의 다양한 구성 요소와 관련된 비용을 효과적으로 추적하고, 예산 관리를 위해 특정 프로젝트에 비용을 할당하고자 합니다. 팀은 리소스 추적 및 비용 할당을 위한 다양한 기법을 고려하고 있습니다.",
        "Question": "그들의 머신러닝 리소스에 대한 AWS에서 비용을 추적하고 할당하는 가장 효과적인 방법은 무엇입니까?",
        "Options": {
            "1": "리소스에 태그를 지정하지 않고 AWS Billing Dashboard에서 비용 보고서를 분석하여 통찰력을 얻습니다.",
            "2": "CloudTrail을 설정하여 모든 AWS 서비스 사용을 기록하여 회고적 비용 분석을 수행합니다.",
            "3": "AWS Budgets를 활용하여 머신러닝 서비스의 지출 한도를 모니터링합니다.",
            "4": "AWS 리소스에 비용 할당 태그를 구현하여 프로젝트별로 지출을 분류합니다."
        },
        "Correct Answer": "AWS 리소스에 비용 할당 태그를 구현하여 프로젝트별로 지출을 분류합니다.",
        "Explanation": "비용 할당 태그를 사용하면 팀이 AWS Billing Dashboard에서 서로 다른 프로젝트나 서비스와 관련된 비용을 분류하고 추적할 수 있어 지출에 대한 명확한 가시성을 제공하고 예산 관리를 용이하게 합니다.",
        "Other Options": [
            "AWS Budgets는 지출 한도를 모니터링하는 데 도움이 될 수 있지만, 태그 없이 특정 프로젝트에 대한 비용 할당에 대한 세부적인 통찰력을 제공하지 않습니다.",
            "리소스에 태그를 지정하지 않고 비용 보고서를 분석하는 것은 효율적인 분류를 허용하지 않으므로 특정 프로젝트에 대한 비용을 정확하게 할당하기 어렵습니다.",
            "CloudTrail을 설정하는 것은 주로 감사 목적으로 API 호출을 기록하며, 비용 추적이나 할당과 직접적으로 연관되지 않으므로 그들의 필요에 충분하지 않습니다."
        ]
    },
    {
        "Question Number": "57",
        "Situation": "한 머신러닝 팀이 Amazon SageMaker를 사용하여 분류 모델을 개발하고 있습니다. 그들은 모델의 예측이 해석 가능하고 편향이 없도록 보장하고자 하며, 특히 민감한 애플리케이션에서 사용될 예정입니다. 이 작업을 돕기 위해 SageMaker Clarify를 사용하는 것을 고려하고 있습니다.",
        "Question": "SageMaker Clarify가 제공하는 다음 기능 중 모델의 예측 공정성을 평가하는 데 가장 유익한 것은 무엇입니까?",
        "Options": {
            "1": "편향 탐지 메트릭",
            "2": "데이터 드리프트 탐지",
            "3": "특징 중요도 분석",
            "4": "모델 설명 가능성 보고서"
        },
        "Correct Answer": "편향 탐지 메트릭",
        "Explanation": "편향 탐지 메트릭은 모델이 서로 다른 인구 통계 그룹에 대해 얼마나 공정하게 예측하고 있는지를 평가하기 위해 특별히 설계되었습니다. 이 기능은 특정 그룹이 모델의 예측으로 인해 불리한 영향을 받고 있는지를 식별하는 데 도움이 되며, 민감한 애플리케이션에서 공정성을 보장하는 데 중요합니다.",
        "Other Options": [
            "특징 중요도 분석은 모델의 예측에 가장 많이 기여하는 특징을 이해하는 데 중점을 두지만, 이러한 예측의 공정성이나 편향을 직접적으로 평가하지는 않습니다.",
            "데이터 드리프트 탐지는 시간에 따른 입력 데이터 분포의 변화를 모니터링하며, 이는 모델 성능에 중요하지만 모델 공정성 평가와는 직접적인 관련이 없습니다.",
            "모델 설명 가능성 보고서는 모델이 결정을 내리는 방법에 대한 통찰력을 제공하지만, 편향 탐지나 공정성 메트릭을 특별히 목표로 하지는 않습니다."
        ]
    },
    {
        "Question Number": "58",
        "Situation": "ML 엔지니어가 Amazon SageMaker를 사용하여 머신 러닝 모델을 배포했습니다. 배포 후, 엔지니어는 모델이 예상치 못한 결과를 반환하고 있음을 발견합니다. 모델의 보안과 무결성을 보장하기 위해, 엔지니어는 모델의 성능에 영향을 미쳤을 수 있는 잠재적인 보안 문제를 해결해야 합니다.",
        "Question": "Amazon SageMaker에서 배포된 모델의 예상치 못한 결과의 가장 가능성이 높은 이유는 무엇입니까?",
        "Options": {
            "1": "모델의 훈련 데이터가 전처리되지 않아 데이터 품질 문제가 발생했습니다.",
            "2": "모델의 엔드포인트가 안전한 접근을 위해 AWS PrivateLink를 사용하도록 구성되지 않았습니다.",
            "3": "모델이 무단 접근에 노출되어 악의적인 사용자가 입력 데이터를 조작할 수 있습니다.",
            "4": "모델이 적절하게 버전 관리되지 않아 예측의 일관성이 떨어집니다."
        },
        "Correct Answer": "모델이 무단 접근에 노출되어 악의적인 사용자가 입력 데이터를 조작할 수 있습니다.",
        "Explanation": "배포된 모델이 무단 접근에 노출되면 악의적인 행위자가 입력 데이터를 변경할 수 있어 예상치 못한 부정확한 결과를 초래할 수 있습니다. 모델 예측의 무결성을 유지하기 위해 적절한 보안 조치를 마련하는 것이 중요합니다.",
        "Other Options": [
            "적절한 버전 관리는 변경 사항을 추적하는 데 중요하지만 잘못된 버전이 배포되지 않는 한 예상치 못한 결과로 이어지지 않습니다. 문제는 주로 보안 노출과 관련이 있습니다.",
            "AWS PrivateLink를 사용하는 것은 서비스를 안전하게 접근하기 위한 보안 조치이지만 모델의 출력에 본질적으로 영향을 미치지 않습니다. 예상치 못한 결과는 무단 데이터 조작과 더 관련이 있습니다.",
            "전처리로 인한 데이터 품질 문제는 결과에 영향을 미칠 수 있지만 보안 취약성과는 연결되지 않습니다. 여기서는 보안 문제가 예상치 못한 모델 동작으로 이어질 수 있는 방법에 초점을 맞추고 있습니다."
        ]
    },
    {
        "Question Number": "59",
        "Situation": "데이터 엔지니어링 팀이 머신 러닝 모델을 위한 데이터셋을 준비하고 있습니다. 모델에 데이터를 공급하기 전에 데이터셋이 깨끗하고 잘 구조화되어 있으며 고품질인지 확인해야 합니다. 팀은 AWS에서 데이터 품질을 검증하고 개선하기 위해 사용할 수 있는 도구를 고려하고 있습니다.",
        "Question": "팀이 데이터셋의 품질을 검증하기 위해 사용할 수 있는 AWS 서비스는 무엇입니까? (두 개 선택)",
        "Options": {
            "1": "AWS Glue Data Quality를 활용하여 데이터셋의 이상을 자동으로 분석합니다.",
            "2": "Amazon SageMaker Data Wrangler를 사용하여 데이터셋을 다른 형식으로 변환합니다.",
            "3": "AWS Glue ETL 작업을 구현하여 품질 검사 없이 데이터셋을 재구성합니다.",
            "4": "AWS Lambda 함수를 사용하여 수동으로 데이터셋을 검증합니다.",
            "5": "AWS Glue DataBrew를 활용하여 데이터셋을 시각적으로 검사하고 정리합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "AWS Glue DataBrew를 활용하여 데이터셋을 시각적으로 검사하고 정리합니다.",
            "AWS Glue Data Quality를 활용하여 데이터셋의 이상을 자동으로 분석합니다."
        ],
        "Explanation": "AWS Glue DataBrew는 데이터 준비 작업을 위한 시각적 인터페이스를 제공하여 데이터 엔지니어가 데이터셋을 효과적으로 정리하고 검사할 수 있도록 합니다. AWS Glue Data Quality는 데이터 품질에 대한 자동 검사 및 통찰력을 제공하여 이상을 식별하고 데이터셋이 머신 러닝 워크플로우에 적합한지 확인하는 데 도움을 줍니다.",
        "Other Options": [
            "Amazon SageMaker Data Wrangler는 주로 데이터를 변환하고 준비하는 데 사용되지만 데이터 품질 검증에 특별히 초점을 맞추지 않습니다.",
            "AWS Lambda 함수는 서버리스 컴퓨팅 서비스이며 데이터 검증을 위해 명시적으로 설계되지 않았습니다; 다양한 작업에 사용할 수 있지만 내장된 데이터 품질 기능이 부족합니다.",
            "AWS Glue ETL 작업은 데이터를 변환할 수 있지만 데이터 품질 검증 기능을 본질적으로 포함하지 않으며, 데이터 처리에 중점을 두고 있습니다."
        ]
    },
    {
        "Question Number": "60",
        "Situation": "금융 기관이 고객 거래를 분석하여 사기 탐지를 위한 머신 러닝 모델을 개발하고 있습니다. 규제 기준을 준수하기 위해 ML 아티팩트(모델 및 데이터셋 등)에 대한 접근이 필요한 사람에게만 제한되어야 합니다.",
        "Question": "ML 아티팩트에 대한 최소 권한 접근을 구성하기 위한 모범 사례는 무엇입니까? (두 개 선택)",
        "Options": {
            "1": "특정 작업에 필요한 최소 권한으로 IAM 역할을 할당합니다.",
            "2": "정의된 접근 권한을 가진 ML 엔지니어 전용 사용자 그룹을 생성합니다.",
            "3": "모든 AWS 계정에 접근을 허용하는 리소스 기반 정책을 활성화합니다.",
            "4": "감사를 위해 ML 아티팩트에 대한 접근을 모니터링하는 로깅을 구현합니다.",
            "5": "ML 아티팩트를 포함하는 S3 버킷에 대한 공개 접근을 허용하는 버킷 정책을 사용합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "특정 작업에 필요한 최소 권한으로 IAM 역할을 할당합니다.",
            "정의된 접근 권한을 가진 ML 엔지니어 전용 사용자 그룹을 생성합니다."
        ],
        "Explanation": "최소 권한으로 IAM 역할을 할당하면 사용자가 자신의 직무 기능을 수행하는 데 필요한 리소스에만 접근할 수 있도록 보장하여 최소 권한 원칙을 준수합니다. 정의된 접근 권한을 가진 전용 사용자 그룹을 생성하면 권한을 효과적으로 조직할 수 있어, 승인된 사용자만 민감한 ML 아티팩트에 접근할 수 있도록 합니다.",
        "Other Options": [
            "S3 버킷에 대한 공개 접근을 허용하는 버킷 정책을 사용하는 것은 최소 권한 원칙에 반하며, 이는 민감한 ML 아티팩트를 인터넷의 누구에게나 노출시킵니다.",
            "모든 AWS 계정에 접근을 허용하는 리소스 기반 정책을 활성화하면 여러 계정에서 무단 사용자에게 무제한 접근을 허용하여 보안을 저해합니다.",
            "접근 모니터링을 위한 로깅 구현은 감사에 중요하지만, ML 아티팩트에 대한 최소 권한 접근을 직접 구성하지 않으며, 접근을 제한하지 않습니다."
        ]
    },
    {
        "Question Number": "61",
        "Situation": "데이터 과학 팀이 Amazon SageMaker를 사용하여 머신 러닝 모델을 배포할 준비를 하고 있습니다. 보안상의 이유로 모델이 가상 사설 클라우드(VPC) 내에서만 접근 가능하도록 하기를 원합니다. 팀은 또한 다양한 트래픽 부하를 효율적으로 처리하기 위해 엔드포인트 구성을 관리해야 합니다.",
        "Question": "VPC 내에서만 접근 가능하면서 트래픽을 효과적으로 관리하는 SageMaker 엔드포인트를 구성하는 최선의 방법은 무엇입니까?",
        "Options": {
            "1": "VPC 설정 없이 자동으로 확장할 수 있도록 SageMaker의 내장 엔드포인트 구성을 사용합니다.",
            "2": "트래픽을 처리하기 위해 VPC의 퍼블릭 서브넷에 SageMaker 엔드포인트를 배포합니다.",
            "3": "프라이빗 서브넷에 SageMaker 엔드포인트를 배포하고 AWS Lambda를 사용하여 트래픽을 관리합니다.",
            "4": "VPC의 프라이빗 서브넷 내에 SageMaker 엔드포인트를 배포하고 애플리케이션 로드 밸런서를 설정합니다."
        },
        "Correct Answer": "VPC의 프라이빗 서브넷 내에 SageMaker 엔드포인트를 배포하고 애플리케이션 로드 밸런서를 설정합니다.",
        "Explanation": "VPC의 프라이빗 서브넷 내에 SageMaker 엔드포인트를 배포하면 공개적으로 접근할 수 없게 되어 보안이 강화됩니다. 애플리케이션 로드 밸런서는 들어오는 트래픽을 효율적으로 관리하고 수요에 따라 엔드포인트에 분배하여 자원 활용을 최적화합니다.",
        "Other Options": [
            "SageMaker 엔드포인트를 퍼블릭 서브넷에 배포하면 인터넷에 노출되어 VPC 접근 제한 요구 사항에 위배됩니다.",
            "VPC 설정 없이 SageMaker의 내장 엔드포인트 구성을 사용하는 것은 접근 제어가 부족하여 필요한 보안 제한을 제공하지 않습니다.",
            "프라이빗 서브넷에 SageMaker 엔드포인트를 배포하고 AWS Lambda를 사용하여 트래픽을 관리하는 것은 불필요하며 복잡성을 더합니다. 애플리케이션 로드 밸런서는 이러한 부하 분산을 위해 설계되었습니다."
        ]
    },
    {
        "Question Number": "62",
        "Situation": "데이터 과학자가 민감한 사용자 정보를 포함하는 머신 러닝 프로젝트를 위한 데이터셋을 준비하고 있습니다. 과학자는 사용자 프라이버시를 침해하지 않으면서 데이터를 훈련에 활용할 수 있도록 해야 합니다. 그들은 민감한 데이터를 처리하기 위한 다양한 기술을 고려하고 있습니다.",
        "Question": "데이터 과학자가 익명화된 데이터에 대한 분석을 수행할 수 있도록 하면서 데이터셋에서 개인 식별 정보(PII)를 영구적으로 제거하기 위해 어떤 기술을 사용해야 합니까?",
        "Options": {
            "1": "집계와 함께 데이터 익명화",
            "2": "암호화와 함께 데이터 분류",
            "3": "동적 대체와 함께 데이터 마스킹",
            "4": "일반화와 함께 데이터 익명화"
        },
        "Correct Answer": "일반화와 함께 데이터 익명화",
        "Explanation": "일반화와 함께 데이터 익명화는 민감한 정보의 범주를 넓혀 데이터의 구체성을 줄이는 효과적인 기술로, 프라이버시를 유지하면서 데이터셋에 대한 유용한 분석을 수행할 수 있게 합니다.",
        "Other Options": [
            "동적 대체와 함께 데이터 마스킹은 비생산 환경에서 민감한 데이터를 보호하는 데 주로 사용되지만, 주어진 시나리오에 필요한 PII를 영구적으로 제거하지는 않습니다.",
            "암호화와 함께 데이터 분류는 데이터를 분류하고 암호화를 통해 보호하는 데 중점을 두지만, 데이터셋에서 PII를 제거할 필요를 구체적으로 다루지 않습니다.",
            "집계와 함께 데이터 익명화는 개별 데이터 포인트를 드러내지 않고 통찰력을 제공하기 위해 데이터를 요약하는 것이지만, 이 경우 필수적인 모든 PII를 효과적으로 제거하지 못할 수 있습니다."
        ]
    },
    {
        "Question Number": "63",
        "Situation": "머신 러닝 엔지니어는 배포된 모델을 쉽게 추적하고 감사하며 필요 시 롤백할 수 있도록 하는 임무를 맡고 있습니다. 팀은 모델 훈련 및 배포를 위해 Amazon SageMaker를 사용하고 있습니다.",
        "Question": "모델 버전을 효과적으로 관리하고 반복 가능성과 감사 가능성을 보장하기 위해 엔지니어가 Amazon SageMaker의 어떤 기능을 활용해야 합니까?",
        "Options": {
            "1": "SageMaker 훈련 작업을 사용하여 별도의 모델 인스턴스를 생성합니다.",
            "2": "버전 관리를 위해 SageMaker 모델 레지스트리를 사용합니다.",
            "3": "버전 관리 없이 Amazon S3에 모델을 저장합니다.",
            "4": "모델 아티팩트를 위한 외부 버전 관리 시스템을 구현합니다."
        },
        "Correct Answer": "버전 관리를 위해 SageMaker 모델 레지스트리를 사용합니다.",
        "Explanation": "SageMaker 모델 레지스트리는 모델 버전을 관리하고 메타데이터를 추적하며 필요 시 모델을 감사하고 롤백할 수 있도록 설계되었습니다. 모델 버전을 체계적으로 관리할 수 있게 해주어 이 시나리오에 가장 적합한 선택입니다.",
        "Other Options": [
            "외부 버전 관리 시스템은 SageMaker와 원활하게 통합되지 않을 수 있어 SageMaker 환경 내에서 모델 아티팩트를 관리하기 어렵고 버전 추적을 복잡하게 만들 수 있습니다.",
            "버전 관리 없이 Amazon S3에 모델을 저장하는 것은 변경 사항을 추적하거나 다양한 버전을 관리할 수 있는 메커니즘을 제공하지 않으며, 이는 감사 가능성과 반복 가능성에 중요합니다.",
            "SageMaker 훈련 작업을 사용하여 별도의 모델 인스턴스를 생성하는 것은 본질적으로 버전 관리 메커니즘을 제공하지 않습니다. 이는 배포된 모델 버전 관리보다는 훈련에 중점을 두고 있습니다."
        ]
    },
    {
        "Question Number": "64",
        "Situation": "기계 학습 엔지니어가 기존 텍스트 분류 모델의 성능을 개선하는 임무를 맡았습니다. 이 모델은 대규모 데이터셋으로 훈련되었지만, 엔지니어는 특정 도메인에 맞춘 소규모 데이터셋에 접근할 수 있어, 이를 사용하여 모델을 미세 조정하여 특정 맥락에서 더 나은 정확도를 달성할 수 있습니다.",
        "Question": "엔지니어가 이 사용자 정의 데이터셋으로 사전 훈련된 모델을 효율적으로 미세 조정하기 위해 어떤 AWS 서비스를 사용해야 합니까?",
        "Options": {
            "1": "Amazon S3",
            "2": "Amazon SageMaker Data Wrangler",
            "3": "Amazon Comprehend",
            "4": "Amazon SageMaker JumpStart"
        },
        "Correct Answer": "Amazon SageMaker JumpStart",
        "Explanation": "Amazon SageMaker JumpStart는 다양한 기계 학습 작업을 위한 사전 훈련된 모델과 예제를 제공하여, 사용자 정의 데이터셋으로 기존 모델을 미세 조정하는 데 이상적인 선택입니다. 사용자는 처음부터 시작하지 않고도 특정 사용 사례에 맞게 모델을 신속하게 조정할 수 있습니다.",
        "Other Options": [
            "Amazon Comprehend는 텍스트에서 통찰력을 제공하는 자연어 처리 서비스이지만, 사용자 정의 데이터셋으로 사전 훈련된 모델을 미세 조정하는 것을 특별히 지원하지 않습니다.",
            "Amazon S3는 저장 서비스이며 모델 훈련이나 미세 조정 기능을 제공하지 않으므로 이 작업에 적합하지 않습니다.",
            "Amazon SageMaker Data Wrangler는 주로 데이터 준비에 사용되며, 사용자 정의 데이터셋으로 사전 훈련된 모델의 미세 조정에 중점을 두지 않습니다."
        ]
    },
    {
        "Question Number": "65",
        "Situation": "ML 엔지니어가 Amazon SageMaker를 사용하여 고객 이탈 예측을 위한 기계 학습 모델을 최적화하고 있습니다. 엔지니어는 하이퍼파라미터 조정이 모델 성능에 상당한 영향을 미칠 수 있다는 것을 알고 있습니다. 하이퍼파라미터 공간을 효율적으로 탐색하기 위해 엔지니어는 다양한 조정 기법을 고려하고 있습니다.",
        "Question": "어떤 하이퍼파라미터 조정 기법이 엔지니어가 탐색과 활용의 균형을 맞추면서 자원을 효율적으로 활용할 수 있도록 할까요?",
        "Options": {
            "1": "다양한 하이퍼파라미터 값을 위한 랜덤 검색.",
            "2": "시도와 오류에 기반한 수동 조정.",
            "3": "하이퍼파라미터 성능을 모델링하기 위한 베이지안 최적화.",
            "4": "모든 하이퍼파라미터 조합을 평가하기 위한 그리드 검색."
        },
        "Correct Answer": "하이퍼파라미터 성능을 모델링하기 위한 베이지안 최적화.",
        "Explanation": "베이지안 최적화는 하이퍼파라미터를 성능 메트릭에 매핑하는 함수의 확률 모델을 구축하는 효율적인 하이퍼파라미터 조정 방법으로, 새로운 하이퍼파라미터 값을 탐색하는 것과 알려진 좋은 값을 활용하는 균형을 맞출 수 있습니다. 이는 다른 방법에 비해 더 적은 평가로 더 나은 성능을 이끌어낼 수 있습니다.",
        "Other Options": [
            "그리드 검색은 모든 하이퍼파라미터 조합을 평가하는 무차별 접근 방식으로, 특히 고차원 공간에서 비효율적이고 자원을 많이 소모할 수 있습니다.",
            "랜덤 검색은 하이퍼파라미터 값을 무작위로 샘플링하는 방법으로 효과적일 수 있지만, 베이지안 최적화처럼 하이퍼파라미터 공간을 전략적으로 탐색하지는 않습니다.",
            "수동 조정은 엔지니어의 직관에 의존하며, 하이퍼파라미터 공간을 체계적으로 탐색하지 않기 때문에 매우 비효율적일 수 있으며, 최적이 아닌 결과를 초래할 수 있습니다."
        ]
    }
]