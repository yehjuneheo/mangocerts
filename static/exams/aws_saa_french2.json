[
    {
        "Question Number": "1",
        "Situation": "Une entreprise de services financiers collecte des données de transaction dans divers formats provenant de multiples sources. Avant de procéder à l'analyse, les données doivent être nettoyées, normalisées et enrichies. L'entreprise recherche une solution sans serveur qui puisse automatiser ce processus ETL (Extraire, Transformer, Charger).",
        "Question": "Quel service AWS le concepteur de solutions devrait-il recommander pour la transformation des données ?",
        "Options": {
            "1": "Amazon EMR",
            "2": "AWS Glue",
            "3": "AWS Lambda",
            "4": "Amazon Redshift Spectrum"
        },
        "Correct Answer": "AWS Glue",
        "Explanation": "AWS Glue est un service ETL (Extraire, Transformer, Charger) entièrement géré, conçu spécifiquement pour la préparation et la transformation des données. Il automatise le processus de découverte, de catalogage et de transformation des données, ce qui le rend idéal pour l'entreprise de services financiers qui doit nettoyer, normaliser et enrichir les données de transaction provenant de diverses sources. AWS Glue peut gérer des opérations sans serveur, ce qui correspond à l'exigence de l'entreprise pour une solution sans serveur.",
        "Other Options": [
            "Amazon EMR est une plateforme de cluster gérée qui simplifie l'exécution de frameworks de big data tels qu'Apache Hadoop et Apache Spark. Bien qu'il puisse effectuer des tâches ETL, ce n'est pas une solution sans serveur et nécessite plus de gestion et de configuration par rapport à AWS Glue.",
            "AWS Lambda est un service de calcul sans serveur qui exécute du code en réponse à des événements. Bien qu'il puisse être utilisé pour la transformation des données, il n'est pas spécifiquement conçu pour les processus ETL et manque des capacités intégrées de catalogage des données et d'inférence de schéma qu'AWS Glue fournit.",
            "Amazon Redshift Spectrum vous permet d'exécuter des requêtes sur des données stockées dans S3 sans les charger dans Redshift. Cependant, c'est principalement un service de requête plutôt qu'un service ETL, et il ne fournit pas les capacités de transformation des données nécessaires pour nettoyer et enrichir les données avant l'analyse."
        ]
    },
    {
        "Question Number": "2",
        "Situation": "Une entreprise utilise Amazon CloudWatch pour surveiller la sécurité de ses ressources AWS. L'entreprise doit mettre en place un système qui peut répondre automatiquement aux menaces potentielles à la sécurité en déclenchant des actions de remédiation lorsqu'un modèle inhabituel est détecté dans le trafic réseau ou des tentatives d'accès non autorisées.",
        "Question": "Quelle configuration l'entreprise devrait-elle mettre en œuvre pour s'assurer que les incidents de sécurité sont détectés et remédiés en temps réel ?",
        "Options": {
            "1": "Utiliser CloudWatch Logs pour collecter les journaux des instances EC2 et configurer des alarmes CloudWatch pour déclencher des fonctions Lambda pour des actions de remédiation lorsque des modèles spécifiques sont détectés dans les journaux.",
            "2": "Utiliser CloudWatch Metrics pour surveiller la santé des instances EC2 et configurer un dimensionnement automatique lorsque les seuils de sécurité sont dépassés, sans intégrer d'autres services de sécurité AWS.",
            "3": "Mettre en place des événements CloudWatch pour transférer les données de journal de CloudTrail vers un système SIEM (Gestion des informations et des événements de sécurité) externe pour une analyse en temps réel et une remédiation automatisée.",
            "4": "Activer les tableaux de bord CloudWatch pour visualiser les métriques EC2 et inspecter manuellement les données pour détecter des menaces à la sécurité, en déclenchant des alertes via Amazon SNS si nécessaire."
        },
        "Correct Answer": "Utiliser CloudWatch Logs pour collecter les journaux des instances EC2 et configurer des alarmes CloudWatch pour déclencher des fonctions Lambda pour des actions de remédiation lorsque des modèles spécifiques sont détectés dans les journaux.",
        "Explanation": "Cette option est correcte car elle répond directement au besoin de détection et de remédiation en temps réel des incidents de sécurité. En utilisant CloudWatch Logs pour collecter les journaux des instances EC2, l'entreprise peut surveiller des modèles spécifiques qui indiquent des menaces potentielles à la sécurité. La configuration d'alarmes CloudWatch permet des réponses automatisées via des fonctions AWS Lambda, qui peuvent exécuter immédiatement des actions de remédiation prédéfinies lorsqu'une menace est détectée. Cette configuration garantit que les incidents de sécurité ne sont pas seulement détectés en temps réel, mais également traités automatiquement, améliorant ainsi la posture de sécurité globale des ressources AWS.",
        "Other Options": [
            "Cette option est incorrecte car bien qu'elle suggère d'utiliser CloudWatch Logs et des alarmes, elle ne précise pas l'utilisation de fonctions Lambda pour la remédiation automatisée. Sans automatisation, la réponse aux menaces détectées ne serait pas en temps réel, ce qui est crucial pour une gestion efficace de la sécurité.",
            "Cette option est incorrecte car elle se concentre sur la surveillance de la santé des instances EC2 et le dimensionnement automatique, ce qui n'est pas directement lié à la détection et à la remédiation des menaces à la sécurité. Bien que la surveillance de la santé des instances soit importante, elle ne répond pas au besoin spécifique de réagir aux incidents de sécurité tels que le trafic réseau inhabituel ou les tentatives d'accès non autorisées.",
            "Cette option est incorrecte car bien que le transfert des données de journal vers un système SIEM externe puisse être bénéfique pour l'analyse, il ne fournit pas de mécanisme direct pour des actions de remédiation en temps réel. La dépendance à un système externe introduit une latence dans le temps de réponse, ce qui n'est pas adapté à une atténuation immédiate des menaces."
        ]
    },
    {
        "Question Number": "3",
        "Situation": "Une entreprise de services financiers doit s'assurer que son application de trading critique peut être restaurée et opérationnelle dans un délai très court en cas de catastrophe. Pour répondre à ses exigences opérationnelles, l'entreprise a établi un Objectif de Temps de Récupération (RTO) de 15 minutes, ce qui signifie que l'application doit être de nouveau en ligne dans ce délai en cas de panne.",
        "Question": "Quelle stratégie de récupération après sinistre répondrait le mieux à cette exigence de RTO ?",
        "Options": {
            "1": "Sauvegarde et restauration, en utilisant une sauvegarde nocturne stockée dans Amazon S3, qui peut être restaurée pour remettre l'application en ligne si nécessaire",
            "2": "Pilot Light, maintenant une infrastructure préconfigurée qui reste éteinte mais peut être rapidement lancée pour restaurer l'application lorsque cela est nécessaire",
            "3": "Warm Standby, avec une version minimale de l'application qui peut être montée en charge jusqu'à la capacité de production complète dans le délai de 15 minutes",
            "4": "Configuration Multi-site Active-Active, où des ressources entièrement opérationnelles sont maintenues dans plusieurs emplacements, garantissant un basculement instantané et zéro temps d'arrêt"
        },
        "Correct Answer": "Configuration Multi-site Active-Active, où des ressources entièrement opérationnelles sont maintenues dans plusieurs emplacements, garantissant un basculement instantané et zéro temps d'arrêt",
        "Explanation": "La configuration Multi-site Active-Active est la meilleure stratégie de récupération après sinistre pour répondre à l'Objectif de Temps de Récupération (RTO) de 15 minutes car elle garantit que des ressources entièrement opérationnelles sont disponibles à tout moment dans plusieurs emplacements. En cas de catastrophe, le système peut basculer instantanément vers un autre site sans aucun temps d'arrêt, répondant ainsi à l'exigence stricte de remettre l'application en ligne immédiatement. Cette configuration offre le plus haut niveau de disponibilité et de résilience, ce qui la rend idéale pour des applications de trading critiques qui ne peuvent se permettre de retards.",
        "Other Options": [
            "La sauvegarde et la restauration ne répondraient pas à l'exigence de RTO de 15 minutes, car la restauration à partir d'une sauvegarde nocturne peut prendre beaucoup plus de temps que 15 minutes, surtout si la sauvegarde est volumineuse ou s'il y a des problèmes lors du processus de restauration.",
            "Pilot Light implique de maintenir une infrastructure minimale qui peut être rapidement lancée, mais cela nécessite encore du temps pour démarrer les ressources nécessaires et ne garantit pas que l'application puisse être entièrement opérationnelle dans le délai de 15 minutes.",
            "Warm Standby maintient une version minimale de l'application qui peut être montée en charge, mais le passage à la capacité de production complète peut prendre plus de 15 minutes, surtout s'il y a des contraintes de ressources ou si l'application nécessite un temps d'initialisation significatif."
        ]
    },
    {
        "Question Number": "4",
        "Situation": "Une application de calcul haute performance (HPC) fonctionnant sur des instances Amazon EC2 nécessite une latence ultra-faible et le plus grand nombre possible d'IOPS pour le stockage temporaire des données. Les données n'ont pas besoin d'être conservées si l'instance est arrêtée ou échoue, et le coût est une préoccupation principale.",
        "Question": "Quelle option de stockage le concepteur de solutions devrait-il recommander ?",
        "Options": {
            "1": "Amazon EBS General Purpose SSD (gp3)",
            "2": "Amazon EBS Provisioned IOPS SSD (io2)",
            "3": "Instance Store",
            "4": "Amazon S3 with Transfer Acceleration"
        },
        "Correct Answer": "Instance Store",
        "Explanation": "Instance Store offre le plus grand nombre possible d'IOPS et une latence ultra-faible car il est physiquement attaché au serveur hôte. Cela le rend idéal pour les applications de calcul haute performance qui nécessitent un stockage temporaire rapide des données. Étant donné que les données n'ont pas besoin d'être conservées si l'instance est arrêtée ou échoue, l'utilisation d'Instance Store est rentable car elle n'entraîne pas de frais supplémentaires comme le font les volumes EBS.",
        "Other Options": [
            "Amazon EBS General Purpose SSD (gp3) offre de bonnes performances et est rentable, mais il ne fournit pas le même niveau d'IOPS et de latence qu'Instance Store, ce qui le rend moins adapté aux applications HPC nécessitant une latence ultra-faible.",
            "Amazon EBS Provisioned IOPS SSD (io2) fournit un haut niveau d'IOPS et est conçu pour des applications nécessitant des performances soutenues, mais il est plus coûteux qu'Instance Store et n'est pas nécessaire pour un stockage temporaire des données qui n'a pas besoin d'être conservé.",
            "Amazon S3 with Transfer Acceleration est conçu pour le transfert de données à haute vitesse sur Internet et n'est pas adapté aux exigences de latence ultra-faible. De plus, S3 est un service de stockage d'objets, ce qui n'est pas approprié pour le stockage temporaire des données dans les applications HPC nécessitant un accès rapide."
        ]
    },
    {
        "Question Number": "5",
        "Situation": "Une entreprise de commerce électronique a besoin d'une solution de reprise après sinistre pour récupérer rapidement sa base de données en cas de défaillance régionale inattendue. Elle nécessite un temps d'arrêt minimal et une perte de données réduite.",
        "Question": "Quel service AWS et quelle stratégie l'entreprise devrait-elle envisager pour atteindre un objectif de point de récupération (RPO) faible et un objectif de temps de récupération (RTO) faible ?",
        "Options": {
            "1": "Amazon RDS avec un déploiement Multi-AZ et des réplicas de lecture inter-région, car il fournit un basculement automatique et une réplication inter-région pour une récupération rapide avec une perte de données minimale.",
            "2": "Amazon S3 avec la versionnage activé, car il garantit la durabilité des données en conservant plusieurs versions de chaque objet à travers les zones de disponibilité.",
            "3": "AWS Backup pour des instantanés réguliers de la base de données, car il fournit une récupération à un instant donné de la base de données à travers plusieurs régions.",
            "4": "Amazon EC2 Auto Scaling avec des sauvegardes programmées, car il permet un dimensionnement automatisé et une récupération périodique des données."
        },
        "Correct Answer": "Amazon RDS avec un déploiement Multi-AZ et des réplicas de lecture inter-région, car il fournit un basculement automatique et une réplication inter-région pour une récupération rapide avec une perte de données minimale.",
        "Explanation": "Amazon RDS avec un déploiement Multi-AZ est conçu pour une haute disponibilité et durabilité. Dans une configuration Multi-AZ, RDS réplique automatiquement la base de données vers une instance de secours dans une zone de disponibilité différente, ce qui permet un basculement automatique en cas de panne. Cette configuration minimise le temps d'arrêt (RTO faible) et garantit que les données sont continuellement répliquées, atteignant ainsi un objectif de point de récupération (RPO) faible. De plus, l'utilisation de réplicas de lecture inter-région permet une redondance supplémentaire des données et une récupération plus rapide en cas de défaillance régionale, ce qui en fait une solution idéale pour les besoins de l'entreprise.",
        "Other Options": [
            "Amazon S3 avec la versionnage activé est principalement destiné au stockage d'objets et ne fournit pas les capacités de récupération de base de données nécessaires. Bien qu'il garantisse la durabilité des données en conservant plusieurs versions des objets, il ne répond pas au besoin d'un RPO et d'un RTO faibles pour une base de données.",
            "AWS Backup pour des instantanés réguliers de la base de données peut fournir une récupération à un instant donné, mais il peut ne pas répondre aux exigences de RPO et de RTO faibles aussi efficacement qu'un déploiement Multi-AZ avec des réplicas de lecture inter-région. Les instantanés peuvent prendre du temps à restaurer, ce qui pourrait entraîner un temps d'arrêt plus long.",
            "Amazon EC2 Auto Scaling avec des sauvegardes programmées est axé sur le dimensionnement des instances EC2 et ne fournit pas intrinsèquement une solution de reprise après sinistre pour les bases de données. Les sauvegardes programmées peuvent ne pas offrir le basculement immédiat et le RPO/RTO faibles que l'entreprise nécessite."
        ]
    },
    {
        "Question Number": "6",
        "Situation": "Une entreprise exécute une application web sur Amazon RDS et souhaite améliorer les performances de lecture de l'application en déchargeant les requêtes de lecture de la base de données principale. L'entreprise doit s'assurer que la base de données principale n'est pas submergée pendant les heures de pointe. Elle envisage d'utiliser des réplicas de lecture pour gérer l'augmentation de la charge de lecture.",
        "Question": "Laquelle des options suivantes décrit le mieux quand l'entreprise devrait utiliser des réplicas de lecture ?",
        "Options": {
            "1": "Utiliser des réplicas de lecture lorsque l'application nécessite un débit d'écriture élevé et doit répartir les écritures sur plusieurs régions.",
            "2": "Utiliser des réplicas de lecture lorsque l'application a un grand nombre de requêtes lourdes en lecture et doit augmenter la capacité de lecture sur plusieurs réplicas.",
            "3": "Utiliser des réplicas de lecture lorsque l'application doit stocker des données non structurées telles que des images ou des documents et nécessite une haute disponibilité.",
            "4": "Utiliser des réplicas de lecture uniquement à des fins de migration de données, pas pour améliorer les performances de l'application."
        },
        "Correct Answer": "Utiliser des réplicas de lecture lorsque l'application a un grand nombre de requêtes lourdes en lecture et doit augmenter la capacité de lecture sur plusieurs réplicas.",
        "Explanation": "Les réplicas de lecture sont spécifiquement conçus pour décharger le trafic de lecture de la base de données principale. Lorsque qu'une application connaît un volume élevé de requêtes de lecture, l'utilisation de réplicas de lecture permet à l'application de répartir ces requêtes sur plusieurs instances, améliorant ainsi les performances de lecture et garantissant que la base de données principale n'est pas submergée pendant les heures de pointe. Cette configuration améliore la scalabilité et la réactivité pour les charges de travail lourdes en lecture.",
        "Other Options": [
            "Utiliser des réplicas de lecture lorsque l'application nécessite un débit d'écriture élevé et doit répartir les écritures sur plusieurs régions. Ceci est incorrect car les réplicas de lecture sont destinés aux opérations de lecture, pas à la répartition des opérations d'écriture. Les écritures sont toujours dirigées vers la base de données principale.",
            "Utiliser des réplicas de lecture lorsque l'application doit stocker des données non structurées telles que des images ou des documents et nécessite une haute disponibilité. Ceci est incorrect car les réplicas de lecture ne sont pas utilisés pour stocker des données non structurées ; ils sont utilisés pour améliorer les performances de lecture des données structurées dans les bases de données.",
            "Utiliser des réplicas de lecture uniquement à des fins de migration de données, pas pour améliorer les performances de l'application. Ceci est incorrect car bien que les réplicas de lecture puissent être utilisés lors de la migration des données, leur objectif principal est d'améliorer les performances de l'application en gérant les requêtes de lecture, pas seulement pour la migration."
        ]
    },
    {
        "Question Number": "7",
        "Situation": "Une société de production médiatique nécessite un stockage haute performance pour le montage vidéo tout en souhaitant maintenir des coûts bas. Elle a un mélange de charges de travail haute performance et basse performance et doit choisir des types de stockage par blocs appropriés.",
        "Question": "Quelles combinaisons d'options de stockage par blocs la société devrait-elle utiliser pour optimiser les coûts tout en répondant aux exigences de performance ? (Choisissez deux.)",
        "Options": {
            "1": "Provisioned IOPS SSD (io2) pour tous les volumes",
            "2": "General Purpose SSD (gp3) pour les tâches haute performance et Throughput Optimized HDD (st1) pour les tâches de moindre performance",
            "3": "Cold HDD (sc1) pour tous les volumes",
            "4": "Utiliser Amazon S3 au lieu du stockage par blocs pour toutes les données",
            "5": "General Purpose SSD (gp3) pour la plupart des charges de travail et Cold HDD (sc1) pour les besoins de stockage d'archives"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Provisioned IOPS SSD (io2) pour tous les volumes",
            "General Purpose SSD (gp3) pour les tâches haute performance et Throughput Optimized HDD (st1) pour les tâches de moindre performance"
        ],
        "Explanation": "Provisioned IOPS SSD (io2) est une option de stockage haute performance qui offre un débit rapide, prévisible et constant, ce qui la rend adaptée aux charges de travail haute performance telles que le montage vidéo. Cependant, elle est plus coûteuse que d'autres options. D'autre part, General Purpose SSD (gp3) offre un équilibre entre prix et performance, ce qui la rend adaptée à une large gamme de charges de travail. Throughput Optimized HDD (st1) est une option à faible coût qui fournit une performance modérée, ce qui la rend adaptée aux tâches moins exigeantes.",
        "Other Options": [
            "Cold HDD (sc1) pour tous les volumes n'est pas une option appropriée car il est conçu pour des données froides ou de stockage d'archives rarement accessibles, à long terme et séquentielles. Il ne fournit pas la haute performance requise pour le montage vidéo.",
            "Utiliser Amazon S3 au lieu du stockage par blocs pour toutes les données n'est pas idéal car S3 est un service de stockage d'objets, pas un service de stockage par blocs. Il n'est pas conçu pour des charges de travail haute performance comme le montage vidéo, qui nécessitent un accès à faible latence aux données.",
            "General Purpose SSD (gp3) pour la plupart des charges de travail et Cold HDD (sc1) pour les besoins de stockage d'archives n'est pas la meilleure option car bien que gp3 soit adapté à la plupart des charges de travail, sc1 n'est pas adapté aux tâches haute performance. Il est conçu pour des données froides ou de stockage d'archives rarement accessibles, à long terme et séquentielles."
        ]
    },
    {
        "Question Number": "8",
        "Situation": "Dans une grande architecture multi-VPC, vous rencontrez des défis pour maintenir de nombreuses connexions point à point et une complexité réseau croissante.",
        "Question": "Quelle solution simplifierait le mieux votre architecture réseau tout en améliorant l'évolutivité et la résilience ?",
        "Options": {
            "1": "Mettre en place une connexion VPN entre chaque paire de VPC pour assurer une communication directe et améliorer la sécurité.",
            "2": "Utiliser AWS Direct Connect pour chaque VPC, permettant à chacun de se connecter indépendamment à votre réseau sur site.",
            "3": "Mettre en œuvre un Transit Gateway (TGW) pour agir comme un hub central, connectant tous les VPC et réduisant le besoin de connexions individuelles.",
            "4": "Configurer une connexion de peering entre chaque VPC pour maintenir une haute disponibilité et garantir une latence minimale entre les connexions."
        },
        "Correct Answer": "Mettre en œuvre un Transit Gateway (TGW) pour agir comme un hub central, connectant tous les VPC et réduisant le besoin de connexions individuelles.",
        "Explanation": "Un Transit Gateway (TGW) simplifie l'architecture réseau en agissant comme un hub central pour interconnecter plusieurs VPC et réseaux sur site. Cela réduit la complexité de la gestion de nombreuses connexions point à point, car tous les VPC peuvent communiquer via le TGW. Cela améliore l'évolutivité car vous pouvez facilement ajouter plus de VPC sans avoir besoin d'établir de nouvelles connexions pour chaque paire. De plus, cela améliore la résilience en fournissant un point unique de gestion et de surveillance, ce qui peut faciliter le dépannage et la maintenance.",
        "Other Options": [
            "Mettre en place une connexion VPN entre chaque paire de VPC créerait un maillage complexe de connexions, entraînant une augmentation de la charge de gestion et des goulets d'étranglement potentiels en termes de performance. Cette approche ne s'adapte pas bien à mesure que le nombre de VPC augmente.",
            "Utiliser AWS Direct Connect pour chaque VPC permet des connexions indépendantes aux réseaux sur site mais ne résout pas la complexité de la communication inter-VPC. Chaque VPC nécessiterait toujours sa propre configuration et gestion, ce qui peut entraîner une architecture réseau fragmentée.",
            "Configurer une connexion de peering entre chaque VPC créerait également un réseau maillé complexe. Bien que cela puisse fournir des connexions à faible latence, la gestion de nombreuses connexions de peering devient lourde à mesure que le nombre de VPC augmente, rendant cela moins évolutif par rapport à un Transit Gateway."
        ]
    },
    {
        "Question Number": "9",
        "Situation": "Une entreprise de santé doit sauvegarder les données des patients sur AWS à des fins de reprise après sinistre. Pour réduire les coûts, elle nécessite une solution qui minimise les coûts de stockage tout en garantissant une conservation à long terme des sauvegardes. Elle souhaite également avoir la possibilité de récupérer les données dans quelques heures si nécessaire.",
        "Question": "Quelle stratégie de sauvegarde répondrait le mieux à ces exigences ?",
        "Options": {
            "1": "Stocker les sauvegardes dans Amazon S3 Standard",
            "2": "Utiliser Amazon S3 Glacier Flexible Retrieval pour le stockage d'archives",
            "3": "Stocker les sauvegardes dans Amazon S3 Standard-IA",
            "4": "Utiliser les instantanés Amazon EBS stockés dans la même région"
        },
        "Correct Answer": "Utiliser Amazon S3 Glacier Flexible Retrieval pour le stockage d'archives",
        "Explanation": "Amazon S3 Glacier Flexible Retrieval est conçu pour l'archivage de données à long terme et offre une solution économique pour le stockage de données rarement accessibles. Il permet la récupération de données dans quelques heures, ce qui correspond à l'exigence de l'entreprise de santé de récupérer les sauvegardes de manière opportune. Cette option minimise les coûts de stockage tout en garantissant que les données sont conservées pendant de longues périodes, ce qui en fait le meilleur choix pour les besoins de reprise après sinistre.",
        "Other Options": [
            "Stocker les sauvegardes dans Amazon S3 Standard n'est pas rentable pour le stockage à long terme car il est conçu pour des données fréquemment accessibles. Cette option entraînerait des coûts plus élevés par rapport à Glacier pour la même quantité de données au fil du temps.",
            "Utiliser Amazon S3 Glacier Flexible Retrieval pour le stockage d'archives est la bonne réponse, mais si nous considérons l'option de S3 Glacier Deep Archive, cela serait encore moins cher pour le stockage à long terme. Cependant, cela ne répond pas à l'exigence de récupérer les données dans quelques heures, car les temps de récupération peuvent prendre jusqu'à 12 heures.",
            "Stocker les sauvegardes dans Amazon S3 Standard-IA (Infrequent Access) est une meilleure option que Standard mais pas aussi rentable que Glacier pour le stockage à long terme. Bien qu'il soit adapté aux données qui sont moins fréquemment accessibles, il ne fournit pas le même niveau d'économies de coûts pour la conservation à long terme que Glacier."
        ]
    },
    {
        "Question Number": "10",
        "Situation": "Une entreprise SaaS propose une application web qui se connecte à une base de données centrale Amazon RDS pour MySQL. L'application connaît des pics de connexion intermittents qui dépassent parfois le nombre maximum de connexions autorisées sur la base de données.",
        "Question": "Quelle solution l'architecte de solutions devrait-il mettre en œuvre pour gérer efficacement les connexions à la base de données et éviter de dépasser la limite de connexion ?",
        "Options": {
            "1": "Augmenter le nombre maximum de connexions autorisées sur l'instance Amazon RDS.",
            "2": "Déployer un cluster Amazon ElastiCache pour gérer les requêtes de base de données et réduire les connexions directes.",
            "3": "Mettre en œuvre Amazon RDS Proxy pour regrouper et partager efficacement les connexions à la base de données.",
            "4": "Utiliser des fonctions AWS Lambda pour gérer et distribuer dynamiquement les connexions à la base de données."
        },
        "Correct Answer": "Mettre en œuvre Amazon RDS Proxy pour regrouper et partager efficacement les connexions à la base de données.",
        "Explanation": "Amazon RDS Proxy est conçu pour gérer efficacement les connexions à la base de données en regroupant et en partageant les connexions entre plusieurs instances d'application. Cela aide à réduire le nombre de connexions simultanées à la base de données, ce qui est particulièrement utile dans les scénarios où l'application connaît des pics de demandes de connexion. En utilisant RDS Proxy, l'application peut maintenir un nombre réduit de connexions actives à la base de données, évitant ainsi de dépasser la limite de connexion et améliorant la performance et la fiabilité globales de l'application.",
        "Other Options": [
            "Augmenter le nombre maximum de connexions autorisées sur l'instance Amazon RDS peut fournir une solution temporaire, mais cela ne résout pas le problème sous-jacent des pics de connexion. Cette approche peut entraîner une consommation de ressources plus élevée et peut ne pas être durable si l'application continue de croître.",
            "Déployer un cluster Amazon ElastiCache peut aider à réduire la charge sur la base de données en mettant en cache les données fréquemment consultées, mais cela ne gère pas directement les connexions à la base de données. Bien que cela puisse améliorer la performance en réduisant le nombre de requêtes envoyées à la base de données, cela ne résout pas le problème de dépassement de la limite de connexion maximale.",
            "Utiliser des fonctions AWS Lambda pour gérer et distribuer dynamiquement les connexions à la base de données n'est pas une solution efficace pour ce scénario. Les fonctions Lambda sont sans état et conçues pour des architectures basées sur des événements, ce qui peut ne pas fournir les capacités nécessaires de regroupement et de gestion des connexions requises pour gérer les pics de connexions à la base de données."
        ]
    },
    {
        "Question Number": "11",
        "Situation": "Une entreprise cherche à déployer une solution de base de données sur AWS et souhaite conserver la flexibilité pour les correctifs personnalisés du système d'exploitation et les installations de logiciels tout en bénéficiant d'un service géré pour les sauvegardes et la mise à l'échelle. Elle envisage Amazon RDS, RDS Custom et l'exécution de la base de données sur EC2.",
        "Question": "Quelle option s'aligne le mieux avec leurs exigences pour un équilibre entre contrôle et services gérés ?",
        "Options": {
            "1": "Amazon RDS, car il offre une gestion complète par AWS avec des sauvegardes automatiques et une mise à l'échelle, mais une personnalisation limitée du système d'exploitation et des installations de logiciels.",
            "2": "RDS Custom, qui permet à l'entreprise de gérer des correctifs personnalisés du système d'exploitation et des installations de logiciels tout en laissant AWS gérer les sauvegardes et la mise à l'échelle.",
            "3": "EC2 avec une base de données autogérée, offrant un contrôle total sur le système d'exploitation et les logiciels, mais nécessitant que l'entreprise gère toutes les tâches de gestion, y compris les sauvegardes.",
            "4": "Amazon RDS avec Multi-AZ activé, car cela équilibre disponibilité et sauvegardes mais ne permet pas d'accès au niveau du système d'exploitation pour la personnalisation."
        },
        "Correct Answer": "RDS Custom, qui permet à l'entreprise de gérer des correctifs personnalisés du système d'exploitation et des installations de logiciels tout en laissant AWS gérer les sauvegardes et la mise à l'échelle.",
        "Explanation": "RDS Custom est spécifiquement conçu pour offrir la flexibilité des correctifs personnalisés du système d'exploitation et des installations de logiciels tout en bénéficiant des services gérés qu'AWS propose, tels que les sauvegardes automatisées et la mise à l'échelle. Cette option trouve le bon équilibre entre contrôle et gestion, permettant à l'entreprise d'adapter son environnement de base de données à ses besoins spécifiques sans sacrifier les avantages d'un service géré.",
        "Other Options": [
            "Amazon RDS offre une gestion complète par AWS, y compris des sauvegardes automatiques et une mise à l'échelle, mais ne permet pas la personnalisation du système d'exploitation ou des installations de logiciels, ce qui ne répond pas à l'exigence de flexibilité de l'entreprise.",
            "EC2 avec une base de données autogérée offre un contrôle total sur le système d'exploitation et les logiciels, mais nécessite que l'entreprise gère tous les aspects de la base de données, y compris les sauvegardes et la mise à l'échelle, ce qui contredit leur désir d'un service géré.",
            "Amazon RDS avec Multi-AZ activé améliore la disponibilité et fournit des sauvegardes automatisées, mais comme le RDS standard, il ne permet pas d'accès au niveau du système d'exploitation ou de personnalisation, ce qui le rend inadapté aux besoins de l'entreprise."
        ]
    },
    {
        "Question Number": "12",
        "Situation": "Une entreprise avec plusieurs comptes AWS souhaite mettre en œuvre une approche centralisée pour gérer la sécurité et les autorisations sur tous les comptes. L'entreprise exige que chaque compte respecte des politiques de conformité strictes, tout en permettant aux administrateurs de comptes individuels de gérer les utilisateurs au sein de leurs comptes.",
        "Question": "Quel service AWS l'entreprise devrait-elle utiliser pour atteindre ces exigences ?",
        "Options": {
            "1": "AWS IAM Identity Center (AWS Single Sign-On)",
            "2": "AWS Organizations avec des politiques de contrôle de service (SCP)",
            "3": "AWS IAM avec des rôles inter-comptes",
            "4": "Amazon Cognito"
        },
        "Correct Answer": "AWS Organizations avec des politiques de contrôle de service (SCP)",
        "Explanation": "AWS Organizations vous permet de gérer de manière centralisée plusieurs comptes AWS et d'appliquer des politiques à ces comptes. Les politiques de contrôle de service (SCP) sont une fonctionnalité d'AWS Organizations qui vous permet de définir des garde-fous d'autorisation pour vos comptes, garantissant la conformité avec des politiques strictes tout en permettant aux administrateurs de comptes individuels de gérer les utilisateurs et les autorisations au sein de leurs propres comptes. Cette configuration répond à l'exigence de l'entreprise pour une gestion centralisée et une application de la conformité sur plusieurs comptes.",
        "Other Options": [
            "AWS IAM Identity Center (AWS Single Sign-On) est principalement utilisé pour gérer l'accès des utilisateurs et le single sign-on entre les comptes et applications AWS. Bien qu'il aide à la gestion des utilisateurs, il ne fournit pas les capacités d'application de politique centralisée qu'offre AWS Organizations avec des SCP.",
            "AWS IAM avec des rôles inter-comptes permet d'accorder des autorisations entre différents comptes AWS, mais ne fournit pas un moyen centralisé d'appliquer des politiques de conformité sur plusieurs comptes. Chaque compte devrait encore gérer ses propres politiques IAM sans le contrôle global fourni par les SCP.",
            "Amazon Cognito est conçu pour l'authentification et la gestion des utilisateurs pour les applications web et mobiles. Il n'est pas adapté à la gestion des autorisations et de la conformité sur plusieurs comptes AWS, car il se concentre sur l'identité des utilisateurs plutôt que sur l'application des politiques au niveau des comptes."
        ]
    },
    {
        "Question Number": "13",
        "Situation": "Une entreprise de commerce électronique, ABC Online, héberge son site web et ses API sur AWS en utilisant des services tels que CloudFront, Application Load Balancer (ALB), AppSync et API Gateway. Pour se protéger contre des menaces telles que l'injection SQL, le cross-site scripting (XSS) et les attaques basées sur l'IP, ABC Online souhaite mettre en œuvre une solution de pare-feu capable de bloquer dynamiquement le trafic malveillant tout en permettant aux utilisateurs légitimes un accès ininterrompu. Ils envisagent d'utiliser AWS Web Application Firewall (WAF) ainsi que des listes de contrôle d'accès web (Web ACLs) pour sécuriser leurs applications à travers plusieurs services AWS. L'équipe de sécurité souhaite configurer des règles personnalisées et contrôler le flux de trafic en fonction de critères spécifiques pour prévenir les attaques qui pourraient compromettre leur application et les données des clients.",
        "Question": "Laquelle des affirmations suivantes décrit le mieux comment AWS Web Application Firewall (WAF) et les Web ACLs fonctionnent pour protéger les applications déployées sur des services AWS tels que CloudFront, ALB, AppSync et API Gateway ?",
        "Options": {
            "1": "AWS WAF applique des règles prédéfinies pour autoriser ou refuser automatiquement tout le trafic entrant sans ajustements ou mises à jour manuels, offrant une protection statique contre les menaces courantes.",
            "2": "Les Web ACLs dans AWS WAF se composent de règles et de groupes de règles qui peuvent être appliqués à des ressources spécifiques, telles que CloudFront ou des services régionaux, pour contrôler l'accès en fonction de critères définis comme la réputation IP, l'injection SQL et les attaques de cross-site scripting (XSS).",
            "3": "AWS WAF fonctionne en utilisant des Web ACLs, qui bloquent uniquement le trafic provenant d'adresses IP spécifiques, ce qui le rend efficace uniquement pour prévenir les attaques basées sur l'IP.",
            "4": "Les Web ACLs ne sont compatibles qu'avec les distributions CloudFront et ne peuvent pas être utilisées avec d'autres services AWS tels que ALB, AppSync ou API Gateway."
        },
        "Correct Answer": "Les Web ACLs dans AWS WAF se composent de règles et de groupes de règles qui peuvent être appliqués à des ressources spécifiques, telles que CloudFront ou des services régionaux, pour contrôler l'accès en fonction de critères définis comme la réputation IP, l'injection SQL et les attaques de cross-site scripting (XSS).",
        "Explanation": "AWS WAF permet aux utilisateurs de créer des listes de contrôle d'accès web (Web ACLs) contenant des règles et des groupes de règles pour filtrer le trafic web. Ces règles peuvent être personnalisées pour cibler des menaces spécifiques, telles que l'injection SQL et le XSS, et peuvent être appliquées à divers services AWS, y compris CloudFront, ALB, AppSync et API Gateway. Cette flexibilité permet aux organisations de bloquer dynamiquement le trafic malveillant tout en permettant aux utilisateurs légitimes un accès ininterrompu, ce qui est essentiel pour maintenir la sécurité des applications.",
        "Other Options": [
            "AWS WAF ne repose pas uniquement sur des règles prédéfinies ; il permet la création de règles personnalisées et nécessite des ajustements manuels pour s'adapter aux menaces évolutives. Il fournit une protection dynamique plutôt que statique.",
            "AWS WAF n'est pas limité à bloquer le trafic provenant d'adresses IP spécifiques. Il peut bloquer ou autoriser le trafic en fonction d'un large éventail de critères, y compris l'injection SQL et le XSS, ce qui en fait une solution complète pour la sécurité des applications web.",
            "Les Web ACLs sont compatibles avec plusieurs services AWS, pas seulement CloudFront. Elles peuvent également être appliquées aux Application Load Balancers, API Gateway et d'autres services régionaux, offrant une approche unifiée de la sécurité des applications web à travers diverses plateformes."
        ]
    },
    {
        "Question Number": "14",
        "Situation": "Une entreprise souhaite déployer une base de données relationnelle hautement disponible sur AWS qui peut basculer sans interruption en cas de panne d'une zone de disponibilité. Elle est également intéressée par le déchargement du trafic de lecture et le maintien de sauvegardes pour la récupération en cas de sinistre.",
        "Question": "Quelle configuration AWS RDS devraient-ils utiliser pour répondre à ces exigences ?",
        "Options": {
            "1": "Configurer Amazon RDS avec des déploiements Multi-AZ pour la réplication synchrone vers une instance de secours, et créer des réplicas de lecture dans différentes régions pour la scalabilité de lecture.",
            "2": "Utiliser une seule instance Amazon RDS avec des snapshots EBS réguliers et configurer un adressage public pour permettre l'accès à distance pour la bascule.",
            "3": "Configurer Amazon RDS avec des déploiements Multi-AZ et une réplication asynchrone pour des réplicas de lecture au sein de la même zone de disponibilité.",
            "4": "Déployer Amazon RDS avec une réplication inter-régionale, permettant la bascule vers une instance principale dans une autre région AWS lorsque l'instance principale échoue."
        },
        "Correct Answer": "Configurer Amazon RDS avec des déploiements Multi-AZ pour la réplication synchrone vers une instance de secours, et créer des réplicas de lecture dans différentes régions pour la scalabilité de lecture.",
        "Explanation": "Cette configuration répond à toutes les exigences décrites dans la situation. Les déploiements Multi-AZ offrent une haute disponibilité en basculant automatiquement vers une instance de secours dans une autre zone de disponibilité en cas de panne, garantissant une bascule sans interruption. La réplication synchrone assure que les données sont répliquées de manière cohérente vers l'instance de secours. De plus, la création de réplicas de lecture dans différentes régions permet à l'entreprise de décharger le trafic de lecture et de faire évoluer les opérations de lecture, tout en offrant des options de récupération en cas de sinistre grâce aux sauvegardes.",
        "Other Options": [
            "Utiliser une seule instance Amazon RDS avec des snapshots EBS réguliers ne fournit pas de haute disponibilité ni de bascule sans interruption, car cela repose sur une intervention manuelle pour la récupération. L'adressage public n'améliore pas la disponibilité et peut exposer la base de données à des risques de sécurité.",
            "Configurer Amazon RDS avec des déploiements Multi-AZ et une réplication asynchrone pour des réplicas de lecture au sein de la même zone de disponibilité ne fournit pas les capacités de haute disponibilité et de bascule requises, car cela n'utilise pas les avantages de Multi-AZ pour la bascule et ne permet pas de décharger efficacement le trafic de lecture.",
            "Déployer Amazon RDS avec une réplication inter-régionale n'est pas nécessaire pour les exigences énoncées, car cela complique la configuration et peut introduire de la latence. L'accent principal devrait être mis sur les déploiements Multi-AZ pour une haute disponibilité au sein de la même région, avec des réplicas de lecture pour la scalabilité."
        ]
    },
    {
        "Question Number": "15",
        "Situation": "Une entreprise met en place une distribution CloudFront pour servir du contenu de manière sécurisée en utilisant SSL. Elle souhaite utiliser un nom de domaine alternatif et garantir des connexions sécurisées des spectateurs vers CloudFront, puis de CloudFront vers ses origines, qui incluent un bucket S3 et un Application Load Balancer (ALB).",
        "Question": "Quelles étapes doivent-ils suivre pour garantir des connexions SSL sécurisées tout au long du processus ?",
        "Options": {
            "1": "Configurer un certificat SSL dans CloudFront en utilisant ACM dans la région où CloudFront est déployé.",
            "2": "Configurer un certificat SSL dans ACM pour le bucket S3, permettant à CloudFront d'utiliser le bucket directement avec HTTPS.",
            "3": "Utiliser un certificat d'ACM pour l'ALB et un certificat externe pour toutes les origines personnalisées ; les certificats auto-signés sont acceptables.",
            "4": "Configurer le support SNI dans CloudFront pour gérer plusieurs sites HTTPS sur une seule IP, et générer un certificat ACM dans us-east-1 pour le nom de domaine alternatif."
        },
        "Correct Answer": "Configurer un certificat SSL dans CloudFront en utilisant ACM dans la région où CloudFront est déployé.",
        "Explanation": "Pour garantir des connexions SSL sécurisées tout au long de la configuration, l'entreprise doit configurer un certificat SSL dans CloudFront en utilisant AWS Certificate Manager (ACM). Ce certificat sera utilisé pour chiffrer la connexion entre les spectateurs et CloudFront. Il est important de noter que CloudFront nécessite que le certificat SSL soit dans la région US East (N. Virginia) (us-east-1) pour qu'il puisse être utilisé avec des noms de domaine alternatifs. Cette étape garantit que le contenu servi par CloudFront est livré de manière sécurisée via HTTPS.",
        "Other Options": [
            "Configurer un certificat SSL dans ACM pour le bucket S3 n'est pas nécessaire car CloudFront peut servir du contenu depuis S3 via HTTPS sans avoir besoin d'un certificat SSL séparé pour le bucket lui-même. CloudFront gère la terminaison SSL.",
            "Utiliser un certificat d'ACM pour l'ALB et un certificat externe pour toutes les origines personnalisées n'est pas la meilleure pratique. Toutes les origines devraient idéalement utiliser des certificats ACM pour la cohérence et la facilité de gestion. Les certificats auto-signés ne sont généralement pas recommandés pour les environnements de production en raison de problèmes de confiance.",
            "Configurer le support SNI dans CloudFront n'est pas nécessaire pour ce scénario. Bien que SNI (Server Name Indication) permette de servir plusieurs certificats SSL à partir d'une seule adresse IP, l'exigence principale est d'avoir le certificat SSL configuré correctement dans ACM pour CloudFront, qui gère la terminaison SSL pour le nom de domaine alternatif."
        ]
    },
    {
        "Question Number": "16",
        "Situation": "Une entreprise doit établir une connexion sécurisée et fiable entre son centre de données sur site et son environnement AWS pour accéder à des données sensibles. L'entreprise nécessite une faible latence, une bande passante élevée et un chiffrement pour les données en transit.",
        "Question": "Quelle solution répondrait le mieux à ces exigences ?",
        "Options": {
            "1": "Mettre en place une connexion AWS Direct Connect avec un VPN overlay pour fournir un chiffrement et une transmission sécurisée des données entre le site et AWS.",
            "2": "Configurer une passerelle Internet standard dans le VPC et utiliser des tunnels VPN IPsec pour chiffrer les données pendant le transit.",
            "3": "Utiliser une passerelle Internet avec AWS Shield pour la protection DDoS et s'appuyer sur HTTPS pour le chiffrement.",
            "4": "Établir une connexion de peering VPC entre le centre de données sur site et le VPC AWS pour garantir une communication sécurisée et à faible latence."
        },
        "Correct Answer": "Mettre en place une connexion AWS Direct Connect avec un VPN overlay pour fournir un chiffrement et une transmission sécurisée des données entre le site et AWS.",
        "Explanation": "AWS Direct Connect fournit une connexion réseau dédiée du centre de données sur site à AWS, ce qui garantit une faible latence et une bande passante élevée. En ajoutant un VPN overlay, les données en transit peuvent être chiffrées, répondant ainsi à l'exigence de l'entreprise pour une transmission sécurisée des données sensibles. Cette combinaison offre à la fois les avantages de performance de Direct Connect et la sécurité d'un VPN, ce qui en fait la meilleure solution pour le scénario donné.",
        "Other Options": [
            "Configurer une passerelle Internet standard dans le VPC et utiliser des tunnels VPN IPsec fournirait un chiffrement, mais la passerelle Internet s'appuie sur Internet public, ce qui peut introduire une latence plus élevée et moins de fiabilité par rapport à une connexion dédiée comme Direct Connect.",
            "Utiliser une passerelle Internet avec AWS Shield pour la protection DDoS et s'appuyer sur HTTPS pour le chiffrement ne répond pas aux exigences de faible latence et de bande passante élevée. HTTPS est adapté pour sécuriser les données en transit, mais la dépendance à Internet public peut entraîner des performances variables, ce qui n'est pas idéal pour accéder à des données sensibles.",
            "Établir une connexion de peering VPC ne s'applique pas dans ce contexte, car le peering VPC est utilisé pour connecter deux VPC au sein d'AWS, et non pour connecter un centre de données sur site à AWS. De plus, le peering VPC ne fournit pas de chiffrement ni de connexion dédiée, qui sont critiques pour les besoins de l'entreprise."
        ]
    },
    {
        "Question Number": "17",
        "Situation": "Une entreprise a déployé une application sur des instances Amazon EC2 dans un sous-réseau privé d'un VPC. L'application doit accéder à Internet pour télécharger des mises à jour et communiquer avec d'autres services publics, mais ne doit pas être directement accessible depuis Internet.",
        "Question": "Quelle configuration l'entreprise devrait-elle utiliser pour répondre à ces exigences ?",
        "Options": {
            "1": "Attacher une passerelle Internet au sous-réseau privé et configurer les instances EC2 avec des IP publiques pour un accès sortant.",
            "2": "Déployer une passerelle NAT dans un sous-réseau public, associer une table de routage au sous-réseau privé pour diriger le trafic 0.0.0.0/0 vers la passerelle NAT, et s'assurer que la passerelle NAT a une IP élastique.",
            "3": "Utiliser le peering VPC pour connecter le sous-réseau privé à un autre VPC qui a accès à Internet et configurer le routage entre les deux VPC.",
            "4": "Mettre en place une connexion VPN entre le sous-réseau privé et un réseau sur site avec accès à Internet, permettant aux instances EC2 de passer par le réseau sur site pour le trafic sortant."
        },
        "Correct Answer": "Déployer une passerelle NAT dans un sous-réseau public, associer une table de routage au sous-réseau privé pour diriger le trafic 0.0.0.0/0 vers la passerelle NAT, et s'assurer que la passerelle NAT a une IP élastique.",
        "Explanation": "Une passerelle NAT permet aux instances dans un sous-réseau privé d'initier un trafic sortant vers Internet tout en empêchant le trafic entrant depuis Internet. En déployant une passerelle NAT dans un sous-réseau public et en associant la table de routage du sous-réseau privé avec une route dirigeant le trafic 0.0.0.0/0 vers la passerelle NAT, les instances EC2 peuvent accéder à Internet pour des mises à jour et des communications sans être directement accessibles depuis Internet. L'IP élastique attribuée à la passerelle NAT fournit une IP publique pour le trafic sortant, garantissant une connectivité Internet appropriée.",
        "Other Options": [
            "Attacher une passerelle Internet au sous-réseau privé et configurer les instances EC2 avec des IP publiques exposerait les instances directement à Internet, ce qui contredit l'exigence de ne pas être directement accessible depuis Internet.",
            "Utiliser le peering VPC pour connecter le sous-réseau privé à un autre VPC avec accès à Internet ne fournit pas de route directe pour les instances du sous-réseau privé pour accéder à Internet. Le peering VPC ne facilite pas l'accès à Internet pour les sous-réseaux privés sans configurations supplémentaires, telles que NAT.",
            "Mettre en place une connexion VPN entre le sous-réseau privé et un réseau sur site avec accès à Internet compliquerait l'architecture et introduirait de la latence. Cela ne répond pas non plus directement à l'exigence pour les instances EC2 d'accéder à Internet sans être exposées, car cela repose sur un réseau externe pour l'accès à Internet."
        ]
    },
    {
        "Question Number": "18",
        "Situation": "Une entreprise de services financiers génère et stocke de grands volumes de données clients sur site chaque jour. En raison de strictes exigences réglementaires et de conformité, elle doit conserver ces données localement mais souhaite décharger les données plus anciennes et peu consultées vers AWS pour économiser sur les coûts de stockage. Elle a besoin d'une solution qui puisse étendre sans problème son infrastructure de stockage actuelle vers AWS, permettant l'accès aux données archivées sans perturber ses applications ou flux de travail existants.",
        "Question": "Quel service AWS répondrait le mieux aux exigences de l'entreprise ? (Choisissez deux.)",
        "Options": {
            "1": "Amazon S3 avec des politiques de cycle de vie",
            "2": "AWS Direct Connect",
            "3": "AWS Storage Gateway",
            "4": "Exportation de snapshot Amazon EBS",
            "5": "Amazon Glacier Deep Archive avec Vault Lock"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon S3 avec des politiques de cycle de vie",
            "AWS Storage Gateway"
        ],
        "Explanation": "Amazon S3 avec des politiques de cycle de vie est une réponse correcte car elle permet la migration automatique des données vers différentes classes de stockage en fonction de règles définies, ce qui peut aider l'entreprise à économiser sur les coûts de stockage pour les données peu consultées. AWS Storage Gateway est également correct car il fournit un moyen transparent de connecter les applications sur site au stockage AWS. Il prend en charge les types de stockage de fichiers, de volumes et de bandes, et peut être utilisé pour stocker des données dans S3, Glacier et EBS, ce qui en fait un bon choix pour les exigences de l'entreprise.",
        "Other Options": [
            "AWS Direct Connect est principalement utilisé pour établir une connexion réseau dédiée de vos locaux à AWS, pas spécifiquement pour le stockage ou l'archivage.",
            "L'exportation de snapshot Amazon EBS vous permet d'exporter un snapshot Amazon EBS vers un bucket Amazon S3, mais elle ne fournit pas une extension transparente de l'infrastructure de stockage sur site vers AWS.",
            "Amazon Glacier Deep Archive avec Vault Lock est une classe de stockage pour l'archivage de données et la sauvegarde à long terme à des coûts très bas. Cependant, elle ne fournit pas un moyen transparent d'étendre le stockage sur site vers AWS, et les temps de récupération des données peuvent aller jusqu'à 12 heures, ce qui peut ne pas répondre aux besoins de l'entreprise pour accéder aux données archivées."
        ]
    },
    {
        "Question Number": "19",
        "Situation": "Un service de streaming vidéo connaît des pics imprévisibles de trafic de spectateurs, en particulier lors d'événements en direct. Le service doit s'assurer qu'il peut gérer des augmentations soudaines de charge sans intervention manuelle tout en minimisant les coûts pendant les périodes creuses.",
        "Question": "Quelle fonctionnalité AWS le concepteur de solutions doit-il configurer pour ajuster automatiquement le nombre d'instances EC2 en fonction des modèles de trafic ?",
        "Options": {
            "1": "AWS Elastic Beanstalk scaling",
            "2": "Amazon CloudWatch Alarms",
            "3": "Amazon EC2 Auto Scaling",
            "4": "AWS Lambda auto-scaling"
        },
        "Correct Answer": "Amazon EC2 Auto Scaling",
        "Explanation": "Amazon EC2 Auto Scaling est conçu pour ajuster automatiquement le nombre d'instances EC2 en réponse à des modèles de trafic changeants. Il peut augmenter le nombre d'instances pendant les périodes de pointe et le réduire pendant les périodes creuses sans intervention manuelle. Cette fonctionnalité est idéale pour gérer des pics imprévisibles de trafic de spectateurs, comme lors d'événements en direct, tout en minimisant les coûts pendant les périodes de faible demande.",
        "Other Options": [
            "Le scaling d'AWS Elastic Beanstalk est une fonctionnalité qui permet la gestion des applications et de leurs environnements, y compris le scaling, mais elle n'est pas aussi directement axée sur la gestion des instances EC2 que l'EC2 Auto Scaling. Elle est plus adaptée aux applications qu'au scaling brut des instances basé sur les modèles de trafic.",
            "Les alarmes Amazon CloudWatch peuvent surveiller des métriques et déclencher des actions basées sur des seuils, mais elles ne scalent pas directement les instances EC2. Elles peuvent être utilisées en conjonction avec EC2 Auto Scaling pour déclencher des actions de scaling, mais elles ne réalisent pas le scaling elles-mêmes.",
            "Le auto-scaling d'AWS Lambda est lié à l'informatique sans serveur et ajuste automatiquement le nombre d'instances de fonctions Lambda en fonction du nombre de requêtes entrantes. Cependant, il n'est pas applicable pour le scaling des instances EC2, ce qui est la nécessité dans ce scénario."
        ]
    },
    {
        "Question Number": "20",
        "Situation": "Une entreprise exécute des applications critiques sur des instances Amazon EC2 dans la région us-east-1 pour garantir une disponibilité continue et une résilience. Pour atteindre une architecture hautement disponible, elle doit concevoir son déploiement EC2 pour résister à des pannes potentielles à différents niveaux, tels que des hôtes individuels, des zones de disponibilité (AZ) ou des instances.",
        "Question": "Quelle approche parmi les suivantes soutient le mieux une architecture EC2 résiliente ? (Choisissez deux.)",
        "Options": {
            "1": "Déployer des instances EC2 à travers plusieurs zones de disponibilité dans la région pour fournir une isolation des pannes et une redondance en cas de défaillance d'une AZ.",
            "2": "Déployer des instances EC2 dans une seule zone de disponibilité, mais utiliser EC2 Auto Scaling pour remplacer immédiatement les instances défaillantes.",
            "3": "Placer toutes les instances EC2 sur un hôte dédié dans une zone de disponibilité pour maximiser l'utilisation des ressources et simplifier la gestion.",
            "4": "Configurer les instances EC2 avec uniquement des volumes de stockage d'instance pour garantir des performances élevées, en s'appuyant sur des instantanés pour la durabilité.",
            "5": "Utiliser Elastic Load Balancing (ELB) en conjonction avec des groupes Auto Scaling répartis sur plusieurs zones de disponibilité pour distribuer le trafic et gérer les défaillances d'instances de manière transparente."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Déployer des instances EC2 à travers plusieurs zones de disponibilité dans la région pour fournir une isolation des pannes et une redondance en cas de défaillance d'une AZ.",
            "Utiliser Elastic Load Balancing (ELB) en conjonction avec des groupes Auto Scaling répartis sur plusieurs zones de disponibilité pour distribuer le trafic et gérer les défaillances d'instances de manière transparente."
        ],
        "Explanation": "Déployer des instances EC2 à travers plusieurs zones de disponibilité dans la région fournit une isolation des pannes et une redondance en cas de défaillance d'une AZ. Cela garantit que même si une AZ tombe en panne, l'application reste disponible dans les autres AZ. Utiliser Elastic Load Balancing (ELB) en conjonction avec des groupes Auto Scaling répartis sur plusieurs zones de disponibilité permet de distribuer le trafic et de gérer les défaillances d'instances de manière transparente. ELB garantit que le trafic est réparti uniformément entre les instances, et Auto Scaling veille à ce que le nombre d'instances augmente ou diminue en fonction de la demande, offrant ainsi une haute disponibilité et une tolérance aux pannes.",
        "Other Options": [
            "Déployer des instances EC2 dans une seule zone de disponibilité et utiliser EC2 Auto Scaling pour remplacer immédiatement les instances défaillantes ne fournit pas de tolérance aux pannes au niveau de l'AZ. Si la seule AZ tombe en panne, l'ensemble de l'application devient indisponible.",
            "Placer toutes les instances EC2 sur un hôte dédié dans une zone de disponibilité pour maximiser l'utilisation des ressources et simplifier la gestion ne fournit pas de tolérance aux pannes au niveau de l'AZ. Si la seule AZ tombe en panne, l'ensemble de l'application devient indisponible.",
            "Configurer les instances EC2 avec uniquement des volumes de stockage d'instance pour garantir des performances élevées, en s'appuyant sur des instantanés pour la durabilité, ne fournit pas de tolérance aux pannes au niveau de l'AZ. Les volumes de stockage d'instance sont éphémères et les données sont perdues si l'instance est arrêtée ou échoue, rendant cette option moins résiliente."
        ]
    },
    {
        "Question Number": "21",
        "Situation": "Une startup construit un pipeline de traitement de données sur AWS qui ingère des données provenant de diverses sources, les traite et stocke les résultats pour analyse. Le pipeline doit gérer des charges de travail variables et s'adapter automatiquement en fonction du volume de données entrantes. L'entreprise souhaite minimiser la charge opérationnelle de gestion des serveurs.",
        "Question": "Quelle combinaison de services AWS le concepteur de solutions devrait-il recommander pour ce pipeline ? (Choisissez DEUX.)",
        "Options": {
            "1": "Instances Amazon EC2 avec Auto Scaling",
            "2": "AWS Lambda",
            "3": "Amazon EMR",
            "4": "Amazon Kinesis Data Firehose",
            "5": "Amazon RDS"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "AWS Lambda",
            "Amazon Kinesis Data Firehose"
        ],
        "Explanation": "AWS Lambda est un service de calcul sans serveur qui exécute votre code en réponse à des événements et gère automatiquement les ressources de calcul sous-jacentes pour vous, ce qui correspond à l'exigence de l'entreprise de minimiser la charge opérationnelle. Il peut également s'adapter automatiquement en fonction du volume de données entrantes, ce qui est idéal pour gérer des charges de travail variables. Amazon Kinesis Data Firehose est le moyen le plus simple de charger de manière fiable des données en streaming dans des lacs de données, des magasins de données et des services d'analyse. Il peut capturer, transformer et charger des données en streaming dans des services AWS tels qu'Amazon S3, Amazon Redshift, Amazon Elasticsearch Service et Splunk, permettant une analyse quasi en temps réel avec des outils et tableaux de bord de business intelligence existants.",
        "Other Options": [
            "Instances Amazon EC2 avec Auto Scaling : Bien que les instances EC2 avec Auto Scaling puissent gérer des charges de travail variables et s'adapter en fonction du volume de données entrantes, cela ne minimise pas la charge opérationnelle de gestion des serveurs, car l'entreprise devrait toujours gérer les instances EC2.",
            "Amazon EMR : Amazon EMR est une plateforme de big data native du cloud, permettant de traiter rapidement et de manière rentable d'énormes quantités de données à l'échelle en utilisant des frameworks distribués populaires tels qu'Apache Spark et Hadoop. Cependant, cela nécessite la gestion de clusters de serveurs, ce qui ne correspond pas à l'exigence de l'entreprise de minimiser la charge opérationnelle.",
            "Amazon RDS : Amazon RDS est un service de base de données relationnelle, qui ne correspond pas aux exigences d'un pipeline de traitement de données qui doit gérer des charges de travail variables et s'adapter automatiquement en fonction du volume de données entrantes."
        ]
    },
    {
        "Question Number": "22",
        "Situation": "Une plateforme de streaming vidéo connaît des pics de trafic imprévisibles, notamment lors d'événements en direct qui attirent des millions de spectateurs. Pour maintenir la performance et éviter les interruptions, la plateforme doit rapidement et efficacement augmenter sa capacité de calcul. L'application de streaming fonctionne actuellement sur des instances Amazon EC2 dans plusieurs zones de disponibilité, et l'équipe souhaite s'assurer que ces instances sont provisionnées automatiquement en fonction de la demande, en particulier lors de pics de trafic inattendus, afin d'éviter toute dégradation de la performance.",
        "Question": "Quelle configuration le solutions architect doit-il mettre en œuvre pour répondre à ces exigences ? (Choisissez deux.)",
        "Options": {
            "1": "Définir un nombre fixe d'instances EC2 dans toutes les zones de disponibilité pour gérer les charges de pointe",
            "2": "Utiliser un groupe Auto Scaling configuré avec des politiques de mise à l'échelle dynamique basées sur des métriques telles que l'utilisation du CPU pour augmenter et diminuer automatiquement la capacité en fonction des fluctuations de la demande",
            "3": "Surveiller manuellement les modèles de trafic et ajouter des instances EC2 au besoin lors d'événements à fort trafic",
            "4": "Héberger le contenu du site web sur Amazon S3 et supprimer le besoin d'instances EC2 pour gérer le trafic du site web",
            "5": "Mettre en œuvre une mise à l'échelle prédictive en utilisant Amazon CloudWatch pour anticiper les pics de trafic et ajuster proactivement la capacité"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Utiliser un groupe Auto Scaling configuré avec des politiques de mise à l'échelle dynamique basées sur des métriques telles que l'utilisation du CPU pour augmenter et diminuer automatiquement la capacité en fonction des fluctuations de la demande",
            "Mettre en œuvre une mise à l'échelle prédictive en utilisant Amazon CloudWatch pour anticiper les pics de trafic et ajuster proactivement la capacité"
        ],
        "Explanation": "Les groupes Auto Scaling dans AWS permettent une mise à l'échelle dynamique des instances EC2 en fonction de la demande. Cela signifie qu'à mesure que la demande augmente, davantage d'instances peuvent être provisionnées pour gérer la charge, et lorsque la demande diminue, les instances peuvent être arrêtées pour économiser des coûts. Cela est idéal pour gérer des pics de trafic imprévisibles. La mise à l'échelle prédictive dans Amazon CloudWatch utilise des algorithmes d'apprentissage automatique pour prédire la demande future et ajuster la capacité à l'avance. Cela est utile pour anticiper les pics de trafic et mettre à l'échelle de manière proactive pour répondre à la demande.",
        "Other Options": [
            "Définir un nombre fixe d'instances EC2 dans toutes les zones de disponibilité pour gérer les charges de pointe n'est pas une solution efficace. Cela ne prend pas en compte les fluctuations de la demande et peut conduire à un surprovisionnement (gaspillage de ressources lorsque la demande est faible) ou à un sous-provisionnement (ne pas avoir suffisamment de ressources lorsque la demande est élevée).",
            "Surveiller manuellement les modèles de trafic et ajouter des instances EC2 au besoin lors d'événements à fort trafic n'est pas une solution évolutive ou efficace. Cela nécessite une surveillance constante et une intervention manuelle, et il peut y avoir des retards dans la montée en charge qui pourraient affecter la performance.",
            "Héberger le contenu du site web sur Amazon S3 et supprimer le besoin d'instances EC2 pour gérer le trafic du site web n'est pas une solution adaptée pour une plateforme de streaming vidéo. Bien que S3 soit excellent pour l'hébergement de sites web statiques, une plateforme de streaming vidéo nécessite une livraison de contenu dynamique et une capacité de calcul, qui sont mieux gérées par des instances EC2."
        ]
    },
    {
        "Question Number": "23",
        "Situation": "Une entreprise envisage AWS Direct Connect pour améliorer la cohérence et la vitesse de la connectivité réseau entre son centre de données sur site et AWS.",
        "Question": "Lequel des éléments suivants décrit avec précision un avantage et une limitation de l'utilisation d'AWS Direct Connect à cette fin ?",
        "Options": {
            "1": "AWS Direct Connect fournit un transfert de données sécurisé via une ligne dédiée privée avec une résilience intégrée ; cependant, il est limité à une bande passante de 1 Gbps par connexion.",
            "2": "AWS Direct Connect peut fournir à la fois une connectivité à haute vitesse et à faible latence directement aux services publics et privés d'AWS sans dépendance à Internet ; cependant, il ne fournit pas intrinsèquement de résilience, car il repose sur des câbles physiques qui peuvent être affectés par des pannes.",
            "3": "AWS Direct Connect offre un transfert de données à haute vitesse et résilient entre AWS et les environnements sur site, avec l'option de basculement automatique ; cependant, il n'est disponible que dans certaines régions AWS dans le monde.",
            "4": "AWS Direct Connect fournit une solution économique pour le transfert de données basé sur Internet, permettant aux données d'être acheminées via des points de terminaison publics AWS ; cependant, il peut rencontrer une latence plus élevée que les solutions basées sur VPN en raison de l'infrastructure partagée."
        },
        "Correct Answer": "AWS Direct Connect peut fournir à la fois une connectivité à haute vitesse et à faible latence directement aux services publics et privés d'AWS sans dépendance à Internet ; cependant, il ne fournit pas intrinsèquement de résilience, car il repose sur des câbles physiques qui peuvent être affectés par des pannes.",
        "Explanation": "AWS Direct Connect est conçu pour offrir des connexions à haute vitesse et à faible latence aux services AWS, contournant Internet public, ce qui améliore la performance et la fiabilité. Cependant, bien qu'il fournisse une connexion dédiée, il n'inclut pas automatiquement de redondance ou de résilience ; si la connexion physique est interrompue, cela peut entraîner des pannes. Par conséquent, les utilisateurs doivent mettre en œuvre des mesures supplémentaires, telles que l'utilisation de connexions multiples ou de stratégies de basculement, pour garantir la résilience.",
        "Other Options": [
            "Bien qu'AWS Direct Connect fournisse un transfert de données sécurisé via une ligne privée, il n'a pas de limitation stricte de 1 Gbps de bande passante par connexion. AWS Direct Connect propose plusieurs vitesses de connexion, y compris 10 Gbps et plus, en fonction des besoins.",
            "AWS Direct Connect propose des options de résilience, telles que la possibilité de créer des connexions redondantes dans différents emplacements. De plus, il est disponible dans de nombreuses régions AWS, pas seulement dans certaines, ce qui améliore son accessibilité.",
            "AWS Direct Connect n'est pas une solution basée sur Internet ; il fournit une connexion dédiée qui entraîne généralement une latence plus faible par rapport aux solutions VPN. Il ne route pas les données via des points de terminaison publics, ce qui est un avantage clé de l'utilisation de Direct Connect."
        ]
    },
    {
        "Question Number": "24",
        "Situation": "Une multinationale prévoit de déployer une nouvelle application destinée aux clients sur AWS qui servira des utilisateurs en Amérique du Nord, en Europe et en Asie. Pour optimiser la performance de l'application et se conformer aux réglementations sur la résidence des données dans chaque région, la multinationale souhaite s'assurer que les données des utilisateurs sont à la fois traitées et stockées près des emplacements géographiques des utilisateurs. De plus, elle souhaite minimiser la latence en servant la base d'utilisateurs de chaque région avec l'infrastructure la plus proche.",
        "Question": "Quelle est la stratégie la plus appropriée pour déployer cette application ?",
        "Options": {
            "1": "Déployer l'application dans une seule région AWS avec des instances à haute capacité, en utilisant les ressources de la région pour gérer tous les utilisateurs mondiaux depuis un emplacement centralisé",
            "2": "Déployer l'application dans plusieurs régions AWS, en veillant à ce que chaque région dispose d'une infrastructure locale pour servir sa base d'utilisateurs et respecter les exigences de résidence des données",
            "3": "Déployer l'application dans une région AWS centrale, puis utiliser un réseau de distribution de contenu (CDN) pour mettre en cache les données dans d'autres régions, améliorant ainsi les vitesses d'accès",
            "4": "Utiliser des zones de disponibilité au sein d'une seule région AWS pour servir les utilisateurs mondiaux, en garantissant la redondance sans déployer dans plusieurs régions"
        },
        "Correct Answer": "Déployer l'application dans plusieurs régions AWS, en veillant à ce que chaque région dispose d'une infrastructure locale pour servir sa base d'utilisateurs et respecter les exigences de résidence des données",
        "Explanation": "Déployer l'application dans plusieurs régions AWS permet à la multinationale de traiter et de stocker les données des utilisateurs à proximité des utilisateurs en Amérique du Nord, en Europe et en Asie. Cette stratégie optimise non seulement la performance de l'application en réduisant la latence pour les utilisateurs accédant à l'application, mais elle garantit également la conformité avec les réglementations sur la résidence des données qui exigent que les données soient stockées dans des emplacements géographiques spécifiques. En ayant une infrastructure locale dans chaque région, la multinationale peut efficacement servir sa base d'utilisateurs tout en respectant les exigences légales.",
        "Other Options": [
            "Déployer l'application dans une seule région AWS avec des instances à haute capacité créerait un point de défaillance centralisé et augmenterait la latence pour les utilisateurs situés loin de cette région. Cette approche ne répond pas aux réglementations sur la résidence des données, qui peuvent exiger que les données soient stockées dans des emplacements géographiques spécifiques.",
            "Utiliser un réseau de distribution de contenu (CDN) pour mettre en cache les données dans d'autres régions peut améliorer les vitesses d'accès pour le contenu statique, mais cela ne résout pas le problème des exigences de résidence et de traitement des données. Le traitement et le stockage des données dynamiques doivent toujours avoir lieu dans les régions appropriées pour se conformer aux réglementations.",
            "Utiliser des zones de disponibilité au sein d'une seule région AWS offre de la redondance et une haute disponibilité, mais ne répond pas au besoin de distribution géographique. Cette option entraînerait toujours une latence accrue pour les utilisateurs situés loin de cette seule région et ne respecterait pas les exigences de résidence des données."
        ]
    },
    {
        "Question Number": "25",
        "Situation": "Une organisation de santé recherche une solution de sauvegarde complète pour des données sensibles de patients stockées sur plusieurs services AWS, y compris des instances Amazon EC2, des bases de données RDS et des systèmes de fichiers EFS. Elle nécessite une solution capable de gérer les sauvegardes à travers plusieurs comptes et régions AWS, d'assurer l'intégrité des données avec la conformité WORM (write-once, read-many) pour prévenir les modifications accidentelles, et d'offrir une récupération à un moment donné pour répondre aux besoins réglementaires et opérationnels en matière de protection des données critiques.",
        "Question": "Quelle configuration de service AWS répondrait le mieux à ces exigences ?",
        "Options": {
            "1": "Configurer des snapshots manuels pour chaque ressource et activer la réplication inter-régionale pour une redondance supplémentaire",
            "2": "Utiliser AWS Backup avec des plans de sauvegarde, Vault Lock pour la conformité WORM, et la récupération à un moment donné (PITR) pour des sauvegardes et récupérations fiables",
            "3": "Stocker les sauvegardes dans Amazon S3 avec la versioning et la réplication activées pour assurer l'intégrité des données et la disponibilité inter-régionale",
            "4": "Activer AWS CloudTrail pour la journalisation et créer des procédures de récupération manuelles basées sur les données de journal."
        },
        "Correct Answer": "Utiliser AWS Backup avec des plans de sauvegarde, Vault Lock pour la conformité WORM, et la récupération à un moment donné (PITR) pour des sauvegardes et récupérations fiables",
        "Explanation": "AWS Backup est spécifiquement conçu pour centraliser et automatiser la sauvegarde des ressources AWS à travers plusieurs comptes et régions. Il permet aux utilisateurs de créer des plans de sauvegarde qui définissent la fréquence et les politiques de conservation des sauvegardes. De plus, AWS Backup prend en charge Vault Lock, qui fournit la conformité WORM pour prévenir les modifications accidentelles des données de sauvegarde, garantissant ainsi l'intégrité des données. La fonctionnalité de récupération à un moment donné (PITR) permet de restaurer les données à un moment précis, ce qui est crucial pour répondre aux besoins réglementaires et opérationnels en matière de protection des données critiques.",
        "Other Options": [
            "Configurer des snapshots manuels pour chaque ressource et activer la réplication inter-régionale peut fournir un certain niveau de redondance, mais cela manque d'automatisation et de gestion centralisée. Cette approche est laborieuse et ne garantit pas la conformité WORM ou la récupération à un moment donné, ce qui la rend moins adaptée aux besoins de sauvegarde complets de l'organisation.",
            "Stocker les sauvegardes dans Amazon S3 avec la versioning et la réplication activées peut aider à l'intégrité et à la disponibilité des données, mais cela ne fournit pas les fonctionnalités de gestion nécessaires pour les sauvegardes à travers plusieurs services ou comptes AWS. De plus, cela n'offre pas intrinsèquement la conformité WORM ou la récupération à un moment donné, qui sont critiques pour les données sensibles des patients.",
            "Activer AWS CloudTrail pour la journalisation et créer des procédures de récupération manuelles basées sur les données de journal n'est pas une solution de sauvegarde. CloudTrail est principalement destiné à l'audit et à la surveillance des appels API, et bien qu'il puisse aider à comprendre les modifications apportées aux ressources, il ne fournit pas de mécanisme pour sauvegarder ou récupérer des données, ni ne répond aux exigences de conformité WORM ou de récupération à un moment donné."
        ]
    },
    {
        "Question Number": "26",
        "Situation": "Une entreprise technologique configure un groupe Auto Scaling pour ses instances EC2. Elle vise à mettre en place une configuration qui permet des mises à jour sans avoir à recréer l'ensemble de l'infrastructure chaque fois qu'un changement est nécessaire.",
        "Question": "Quelle option l'entreprise devrait-elle choisir pour faciliter efficacement les mises à jour de configuration, et quelle est la justification de ce choix ?",
        "Options": {
            "1": "Utiliser des configurations de lancement, car elles prennent en charge la versioning et permettent des mises à jour sans avoir besoin de recréer.",
            "2": "Employer des modèles de lancement, car ils offrent des capacités de versioning, permettant des mises à jour de configuration sans créer de nouveaux modèles.",
            "3": "Choisir des configurations de lancement pour leur facilité de gestion et leurs fonctionnalités de versioning inhérentes.",
            "4": "Opter pour des modèles de lancement, qui permettent des mises à jour en direct directement au sein du groupe Auto Scaling sans nécessiter de contrôle de version."
        },
        "Correct Answer": "Employer des modèles de lancement, car ils offrent des capacités de versioning, permettant des mises à jour de configuration sans créer de nouveaux modèles.",
        "Explanation": "Les modèles de lancement sont le choix préféré pour configurer des groupes Auto Scaling car ils prennent en charge la versioning, ce qui permet aux utilisateurs de créer plusieurs versions d'un modèle. Cela signifie que lorsque des changements de configuration sont nécessaires, l'entreprise peut simplement créer une nouvelle version du modèle existant sans avoir à recréer l'ensemble de l'infrastructure. Cette fonctionnalité rationalise le processus de mise à jour des configurations et améliore l'efficacité de la gestion, facilitant le retour à des versions précédentes si nécessaire.",
        "Other Options": [
            "Utiliser des configurations de lancement, car elles prennent en charge la versioning et permettent des mises à jour sans avoir besoin de recréer. (Incorrect car les configurations de lancement ne prennent pas en charge la versioning ; elles sont statiques et ne peuvent pas être mises à jour une fois créées. Tout changement nécessite la création d'une nouvelle configuration de lancement.)",
            "Choisir des configurations de lancement pour leur facilité de gestion et leurs fonctionnalités de versioning inhérentes. (Incorrect car les configurations de lancement manquent de capacités de versioning, ce qui les rend moins flexibles pour les mises à jour de configuration par rapport aux modèles de lancement.)",
            "Opter pour des modèles de lancement, qui permettent des mises à jour en direct directement au sein du groupe Auto Scaling sans nécessiter de contrôle de version. (Incorrect car bien que les modèles de lancement permettent la versioning, ils ne permettent pas de mises à jour en direct directement au sein du groupe Auto Scaling ; les mises à jour nécessitent toujours la création d'une nouvelle version du modèle.)"
        ]
    },
    {
        "Question Number": "27",
        "Situation": "Une équipe de recherche exécute des simulations de modélisation scientifique hautement complexes qui nécessitent une puissance CPU extrêmement élevée et des vitesses de traitement rapides pour générer des résultats précis rapidement. Ces simulations sont intensives en calcul et incluent des tâches telles que l'encodage multimédia, la dynamique des fluides computationnelle et l'entraînement de modèles d'apprentissage automatique. L'équipe n'a pas besoin d'une grande mémoire ou d'un support GPU, car ces tâches sont principalement liées au CPU.",
        "Question": "Quelle catégorie d'instance EC2 conviendrait le mieux à leurs besoins ?",
        "Options": {
            "1": "Usage Général",
            "2": "Optimisé pour la Mémoire",
            "3": "Optimisé pour le Calcul",
            "4": "Calcul Accéléré"
        },
        "Correct Answer": "Optimisé pour le Calcul",
        "Explanation": "La catégorie d'instance EC2 Optimisé pour le Calcul est spécifiquement conçue pour des tâches intensives en calcul qui nécessitent une haute performance CPU. Étant donné que les simulations de l'équipe de recherche sont liées au CPU et ne nécessitent pas de grande mémoire ou de support GPU, les instances Optimisées pour le Calcul fourniront la puissance de traitement et la vitesse nécessaires pour gérer efficacement des tâches telles que l'encodage multimédia, la dynamique des fluides computationnelle et l'entraînement de modèles d'apprentissage automatique. Ces instances sont idéales pour des charges de travail qui exigent une grande capacité de calcul et peuvent réduire considérablement le temps nécessaire pour générer des résultats précis.",
        "Other Options": [
            "Les instances à usage général offrent un équilibre entre les ressources de calcul, de mémoire et de mise en réseau, ce qui les rend adaptées à une variété de charges de travail mais pas spécifiquement optimisées pour des tâches intensives en calcul. Elles peuvent ne pas fournir la haute performance CPU requise pour les simulations décrites.",
            "Les instances optimisées pour la mémoire sont conçues pour des charges de travail nécessitant une grande capacité de mémoire et un débit élevé, telles que les bases de données en mémoire et l'analyse de big data en temps réel. Étant donné que l'équipe de recherche n'a pas besoin d'un support mémoire élevé, cette catégorie n'est pas adaptée à leurs simulations intensives en calcul.",
            "Les instances de calcul accéléré sont adaptées aux charges de travail qui bénéficient d'accélérateurs matériels, tels que les GPU ou les FPGA. Ces instances sont idéales pour des tâches comme l'inférence d'apprentissage automatique et le traitement graphique, mais ne sont pas nécessaires pour des tâches liées au CPU, ce qui les rend moins appropriées pour les besoins de l'équipe."
        ]
    },
    {
        "Question Number": "28",
        "Situation": "Une entreprise de logistique doit traiter les données des véhicules de livraison en temps réel pour surveiller les itinéraires et les conditions de circulation. Elle souhaite traiter les données aussi près de la source que possible pour réduire la latence et minimiser la quantité de données envoyées vers le cloud.",
        "Question": "Quelle stratégie de calcul distribué répondrait le mieux à ces besoins ?",
        "Options": {
            "1": "Exécuter tout le traitement des données sur des instances Amazon EC2 dans la région AWS la plus proche",
            "2": "Utiliser le traitement en périphérie pour gérer les données localement sur les appareils",
            "3": "Envoyer les données à AWS Lambda pour un traitement sans serveur",
            "4": "Utiliser un rack AWS Outposts dans le centre de données de l'entreprise"
        },
        "Correct Answer": "Utiliser le traitement en périphérie pour gérer les données localement sur les appareils",
        "Explanation": "Le traitement en périphérie permet de traiter les données aussi près de la source que possible, ce qui est crucial pour la surveillance en temps réel des véhicules de livraison. En gérant les données localement sur les appareils, l'entreprise de logistique peut réduire considérablement la latence, car les données n'ont pas besoin de voyager vers un serveur cloud distant pour être traitées. Cette approche minimise également la quantité de données envoyées vers le cloud, s'alignant parfaitement avec les besoins de l'entreprise en matière d'efficacité et de rapidité dans le traitement des données.",
        "Other Options": [
            "Exécuter tout le traitement des données sur des instances Amazon EC2 dans la région AWS la plus proche introduirait une latence en raison de la distance que les données doivent parcourir pour atteindre le cloud. Cette option ne répond pas aussi efficacement à l'exigence de traitement en temps réel que le traitement en périphérie.",
            "Envoyer des données à AWS Lambda pour un traitement sans serveur impliquerait également une latence puisque les données doivent être transmises au cloud pour le traitement. Bien qu'AWS Lambda soit efficace pour de nombreux cas d'utilisation, il n'est pas optimal pour le traitement en temps réel des données générées par des véhicules de livraison nécessitant une analyse immédiate.",
            "Utiliser un rack AWS Outposts dans le centre de données de l'entreprise pourrait offrir certains avantages d'un traitement local, mais cela nécessite toujours une configuration physique et peut ne pas être aussi agile ou rentable qu'un véritable traitement en périphérie. De plus, cela peut ne pas être aussi proche de la source de données que les appareils en périphérie, ce qui peut entraîner une latence accrue par rapport à un traitement directement sur les appareils."
        ]
    },
    {
        "Question Number": "29",
        "Situation": "Une entreprise héberge deux applications web, chacune avec un nom de domaine HTTPS unique. Elle doit réduire le nombre de répartiteurs de charge qu'elle utilise, tout en maintenant le support HTTPS pour les deux applications.",
        "Question": "Quel type de répartiteur de charge AWS serait le mieux adapté à cette exigence, et pourquoi ?",
        "Options": {
            "1": "Classic Load Balancer (CLB), car il permet de consolider plusieurs domaines en un seul répartiteur de charge.",
            "2": "Application Load Balancer (ALB), car il prend en charge le routage basé sur l'hôte avec Server Name Indication (SNI), permettant plusieurs domaines HTTPS sur un seul répartiteur de charge.",
            "3": "Network Load Balancer (NLB), car il fournit un routage de couche 4 et peut gérer plusieurs domaines HTTPS.",
            "4": "Elastic Load Balancer (ELB) avec des sessions persistantes, car il permet plusieurs groupes cibles sous le même répartiteur de charge."
        },
        "Correct Answer": "Application Load Balancer (ALB), car il prend en charge le routage basé sur l'hôte avec Server Name Indication (SNI), permettant plusieurs domaines HTTPS sur un seul répartiteur de charge.",
        "Explanation": "L'Application Load Balancer (ALB) est spécifiquement conçu pour gérer le trafic HTTP et HTTPS et prend en charge des fonctionnalités de routage avancées, y compris le routage basé sur l'hôte. Cela signifie qu'il peut diriger les demandes vers différents groupes cibles en fonction du nom d'hôte dans la demande, ce qui est essentiel pour héberger plusieurs applications web avec des noms de domaine HTTPS uniques. De plus, l'ALB prend en charge Server Name Indication (SNI), ce qui lui permet de servir plusieurs certificats SSL sur une seule adresse IP, permettant des connexions sécurisées pour chaque domaine sans avoir besoin de répartiteurs de charge séparés.",
        "Other Options": [
            "Le Classic Load Balancer (CLB) ne prend pas en charge le routage basé sur l'hôte ou SNI, ce qui le rend moins adapté pour gérer efficacement plusieurs domaines HTTPS. Il est principalement conçu pour un équilibrage de charge de base et manque des fonctionnalités avancées nécessaires pour ce scénario.",
            "Le Network Load Balancer (NLB) fonctionne à la couche 4 et est optimisé pour gérer le trafic TCP. Bien qu'il puisse gérer plusieurs domaines, il ne fournit pas les fonctionnalités nécessaires pour la terminaison SSL ou le routage basé sur l'hôte, qui sont cruciales pour gérer efficacement le trafic HTTPS.",
            "L'Elastic Load Balancer (ELB) est un terme général qui englobe à la fois l'ALB et le NLB. Bien que des sessions persistantes puissent être configurées, elles ne répondent pas à l'exigence de prise en charge de plusieurs domaines HTTPS sur un seul répartiteur de charge. L'ALB est le type spécifique qui répond aux besoins de ce scénario."
        ]
    },
    {
        "Question Number": "30",
        "Situation": "Une entreprise prévoit de migrer ses applications sur site vers AWS. Ces applications s'appuient fortement sur Active Directory pour l'authentification des utilisateurs et la gestion des groupes. L'équipe informatique souhaite une solution gérée sur AWS qui prend en charge jusqu'à 3 000 utilisateurs, s'intègre avec Amazon Workspaces, et ne nécessite pas d'intégration complexe sur site. De plus, elle a besoin d'une solution qui puisse prendre en charge des environnements Windows avec le même nom d'utilisateur et mot de passe pour la gestion centralisée des ressources.",
        "Question": "Quelle option de AWS Directory Service répondrait le mieux à ces exigences ?",
        "Options": {
            "1": "Simple AD avec une instance Small pour la gestion de répertoire autonome",
            "2": "AWS Managed Microsoft AD avec déploiement multi-AZ",
            "3": "AWS SSO (Single Sign-On) pour l'accès inter-comptes",
            "4": "Amazon Cognito pour la gestion des pools d'utilisateurs"
        },
        "Correct Answer": "AWS Managed Microsoft AD avec déploiement multi-AZ",
        "Explanation": "AWS Managed Microsoft AD est conçu pour fournir un Active Directory entièrement géré dans le cloud AWS. Il prend en charge les environnements Windows et permet une intégration transparente avec les applications qui s'appuient sur Active Directory pour l'authentification et la gestion des groupes. Il peut prendre en charge jusqu'à 50 000 utilisateurs, ce qui dépasse l'exigence de 3 000 utilisateurs. De plus, il s'intègre bien avec Amazon Workspaces, permettant aux utilisateurs d'avoir le même nom d'utilisateur et mot de passe pour une gestion centralisée, répondant ainsi aux besoins de l'entreprise sans nécessiter d'intégration complexe sur site. Le déploiement multi-AZ garantit une haute disponibilité et une résilience.",
        "Other Options": [
            "Simple AD avec une instance Small est un service de répertoire de base qui ne prend en charge qu'un ensemble limité de fonctionnalités Active Directory et n'est pas adapté aux applications nécessitant des capacités complètes d'Active Directory. Il ne prend également pas en charge le même niveau d'intégration avec Amazon Workspaces que AWS Managed Microsoft AD.",
            "AWS SSO (Single Sign-On) est principalement conçu pour gérer l'accès à plusieurs comptes AWS et applications, mais il ne fournit pas les fonctionnalités complètes d'Active Directory nécessaires pour l'authentification des utilisateurs et la gestion des groupes dans un environnement Windows. Ce n'est pas un remplacement direct d'Active Directory.",
            "Amazon Cognito est axé sur l'authentification et la gestion des utilisateurs pour les applications web et mobiles, mais il ne fournit pas les capacités d'Active Directory requises pour les applications de l'entreprise. Il est plus adapté aux pools d'utilisateurs et aux identités fédérées plutôt qu'à la gestion des environnements Windows avec intégration Active Directory."
        ]
    },
    {
        "Question Number": "31",
        "Situation": "Une entreprise déploie une application web sur plusieurs instances Amazon EC2 dans différentes zones de disponibilité. L'application a besoin d'un système de fichiers partagé pour stocker et accéder au contenu généré par les utilisateurs. L'entreprise souhaite également la flexibilité de connecter son centre de données sur site au stockage partagé dans AWS.",
        "Question": "Quelle solution AWS l'architecte des solutions devrait-il recommander pour répondre à ces exigences ?",
        "Options": {
            "1": "Amazon EBS avec Multi-Attach à travers les zones de disponibilité",
            "2": "Amazon EFS avec des cibles de montage dans chaque zone de disponibilité et accès via VPN ou Direct Connect pour la connectivité sur site",
            "3": "Amazon S3 avec Transfer Acceleration pour un accès inter-régional",
            "4": "Amazon RDS avec des réplicas de lecture dans chaque zone de disponibilité"
        },
        "Correct Answer": "Amazon EFS avec des cibles de montage dans chaque zone de disponibilité et accès via VPN ou Direct Connect pour la connectivité sur site",
        "Explanation": "Amazon EFS (Elastic File System) est un service de stockage de fichiers entièrement géré qui peut être monté sur plusieurs instances EC2 dans différentes zones de disponibilité, fournissant un système de fichiers partagé pour les applications. Il prend en charge les protocoles NFS (Network File System), ce qui le rend adapté aux applications nécessitant un accès partagé aux fichiers. De plus, EFS peut être accessible depuis des centres de données sur site via un VPN ou AWS Direct Connect, répondant ainsi à l'exigence de connectivité entre le stockage sur site et AWS.",
        "Other Options": [
            "Amazon EBS (Elastic Block Store) avec Multi-Attach permet à plusieurs instances EC2 de se connecter à un seul volume EBS, mais il est limité à une seule zone de disponibilité. Cela ne répond pas à l'exigence d'un système de fichiers partagé à travers plusieurs zones de disponibilité.",
            "Amazon S3 (Simple Storage Service) est un service de stockage d'objets et bien qu'il puisse stocker du contenu généré par les utilisateurs, il ne fournit pas une interface de système de fichiers traditionnelle que les applications nécessitent généralement pour un accès partagé. Transfer Acceleration est destiné à accélérer les téléchargements et les mises en ligne, mais ne répond pas au besoin d'un système de fichiers partagé entre les instances EC2.",
            "Amazon RDS (Relational Database Service) est un service de base de données géré et bien qu'il puisse avoir des réplicas de lecture dans différentes zones de disponibilité pour une haute disponibilité, il n'est pas adapté pour stocker du contenu généré par les utilisateurs dans un format de système de fichiers partagé. RDS est conçu pour des données structurées et des cas d'utilisation de bases de données relationnelles, pas pour le stockage de fichiers."
        ]
    },
    {
        "Question Number": "32",
        "Situation": "Une entreprise de médias diffuse du contenu vidéo à l'échelle mondiale et doit améliorer la vitesse de livraison et réduire la latence pour les utilisateurs dans différentes régions géographiques. L'entreprise constate une forte demande pendant les heures de pointe, et le buffering du contenu affecte l'expérience utilisateur. Elle doit également réduire la charge sur ses serveurs d'origine pour prévenir l'épuisement des ressources.",
        "Question": "Quel service AWS l'entreprise devrait-elle utiliser pour atteindre ces objectifs, et quels avantages cela offre-t-il ?",
        "Options": {
            "1": "Utiliser Amazon CloudFront comme un CDN pour mettre en cache le contenu aux emplacements de périphérie dans le monde entier, réduisant ainsi la latence et déchargeant le trafic des serveurs d'origine.",
            "2": "Utiliser Amazon Route 53 avec le routage par géolocalisation pour diriger les utilisateurs vers le seau S3 le plus proche, où le contenu vidéo est stocké.",
            "3": "Utiliser Amazon S3 pour le stockage et diriger les utilisateurs vers une seule instance EC2 dans une région pour servir tout le contenu vidéo.",
            "4": "Utiliser AWS Direct Connect pour établir des connexions réseau dédiées à tous les clients dans le monde pour une livraison de contenu plus rapide."
        },
        "Correct Answer": "Utiliser Amazon CloudFront comme un CDN pour mettre en cache le contenu aux emplacements de périphérie dans le monde entier, réduisant ainsi la latence et déchargeant le trafic des serveurs d'origine.",
        "Explanation": "Amazon CloudFront est un réseau de distribution de contenu (CDN) qui met en cache le contenu aux emplacements de périphérie dans le monde entier. En utilisant CloudFront, l'entreprise de médias peut livrer du contenu vidéo plus près des utilisateurs, réduisant ainsi considérablement la latence et améliorant la vitesse de livraison. Ce mécanisme de mise en cache décharge également le trafic des serveurs d'origine, ce qui aide à prévenir l'épuisement des ressources pendant les périodes de forte demande. Dans l'ensemble, CloudFront améliore l'expérience utilisateur en minimisant le buffering et en garantissant un accès plus rapide au contenu.",
        "Other Options": [
            "Utiliser Amazon Route 53 avec le routage par géolocalisation pourrait aider à diriger les utilisateurs vers les ressources les plus proches, mais cela ne met pas en cache le contenu ni ne réduit efficacement la latence. Cela gère principalement le routage DNS et ne traite pas les problèmes de buffering ou la charge sur les serveurs d'origine.",
            "Utiliser Amazon S3 pour le stockage et diriger les utilisateurs vers une seule instance EC2 dans une région ne serait pas efficace pour la livraison de contenu à l'échelle mondiale. Cette approche pourrait entraîner une latence élevée pour les utilisateurs éloignés de l'instance EC2 et ne soulagerait pas la charge sur les serveurs d'origine, entraînant des problèmes de performance potentiels pendant les heures de pointe.",
            "AWS Direct Connect fournit des connexions réseau dédiées mais n'est pas conçu pour la livraison de contenu. Il est plus adapté à l'établissement de connexions privées entre des centres de données sur site et AWS, plutôt qu'à l'amélioration de la vitesse de livraison de contenu aux utilisateurs finaux à l'échelle mondiale."
        ]
    },
    {
        "Question Number": "33",
        "Situation": "Une organisation souhaite établir une connexion sécurisée entre son centre de données sur site et son environnement AWS. La connexion doit prendre en charge une haute disponibilité et un lien à faible latence pour les données critiques des applications.",
        "Question": "Quelle solution répond le mieux à ces exigences ?",
        "Options": {
            "1": "Mettre en place une connexion VPN via Internet",
            "2": "Utiliser AWS Direct Connect avec une connexion redondante",
            "3": "Configurer un Elastic Load Balancer pour distribuer le trafic",
            "4": "Utiliser une connexion de peering VPC"
        },
        "Correct Answer": "Utiliser AWS Direct Connect avec une connexion redondante",
        "Explanation": "AWS Direct Connect fournit une connexion réseau dédiée du centre de données sur site à AWS, ce qui est idéal pour des exigences de haute disponibilité et de faible latence. En utilisant Direct Connect avec une connexion redondante, l'organisation peut s'assurer qu'il y a un lien de secours disponible en cas de défaillance du lien principal, maintenant ainsi une haute disponibilité. Cette solution est spécifiquement conçue pour la connectivité au niveau des entreprises et peut gérer efficacement les données critiques des applications.",
        "Other Options": [
            "Mettre en place une connexion VPN via Internet peut fournir une connexion sécurisée, mais elle ne garantit généralement pas une faible latence ou une haute disponibilité par rapport à une connexion dédiée comme AWS Direct Connect. Les connexions VPN peuvent être affectées par le trafic Internet et peuvent introduire de la variabilité dans la latence.",
            "Configurer un Elastic Load Balancer n'est pas pertinent pour établir une connexion directe entre le centre de données sur site et AWS. Les équilibreurs de charge sont utilisés pour distribuer le trafic d'application entrant sur plusieurs cibles, mais ils ne facilitent pas la connexion sécurisée nécessaire dans ce scénario.",
            "Utiliser une connexion de peering VPC est utile pour connecter deux VPC au sein d'AWS, mais cela ne répond pas à l'exigence de connecter un centre de données sur site à AWS. Le peering VPC ne fournit pas de connexion dédiée à faible latence et n'est pas adapté à ce scénario."
        ]
    },
    {
        "Question Number": "34",
        "Situation": "Une entreprise doit accorder un accès temporaire à un bucket S3 à des entrepreneurs externes. L'accès doit expirer automatiquement après une période spécifiée et doit être limité à des actions spécifiques.",
        "Question": "Quelles solutions l'entreprise devrait-elle mettre en œuvre ? (Choisissez deux.)",
        "Options": {
            "1": "Créer des utilisateurs IAM pour chaque entrepreneur et attacher une politique d'accès S3",
            "2": "Utiliser AWS IAM Identity Center (AWS Single Sign-On) avec un rôle d'accès temporaire",
            "3": "Générer des URL pré-signées pour les objets S3 auxquels les entrepreneurs doivent accéder",
            "4": "Attacher une politique de bucket avec une condition temporelle pour restreindre l'accès",
            "5": "Mettre en œuvre des identifiants de sécurité temporaires en utilisant AWS Security Token Service (STS)"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Générer des URL pré-signées pour les objets S3 auxquels les entrepreneurs doivent accéder",
            "Mettre en œuvre des identifiants de sécurité temporaires en utilisant AWS Security Token Service (STS)"
        ],
        "Explanation": "Les URL pré-signées offrent un moyen d'accorder un accès temporaire à des objets S3 spécifiques. Elles sont générées avec une heure d'expiration, après quoi elles ne sont plus valides. Cela correspond à l'exigence d'avoir un accès qui expire automatiquement après une période spécifiée. AWS Security Token Service (STS) est un service web qui vous permet de demander des identifiants temporaires à privilèges limités pour les utilisateurs AWS Identity and Access Management (IAM). Vous pouvez spécifier les autorisations pour ces identifiants de sécurité temporaires, ce qui permet de limiter les actions que les entrepreneurs peuvent effectuer.",
        "Other Options": [
            "Créer des utilisateurs IAM pour chaque entrepreneur et attacher une politique d'accès S3 n'est pas une solution temporaire et n'expire pas automatiquement. Cela nécessiterait une intervention manuelle pour révoquer l'accès.",
            "Utiliser AWS IAM Identity Center (AWS Single Sign-On) avec un rôle d'accès temporaire pourrait être utilisé pour accorder un accès temporaire, mais cela ne limite pas intrinsèquement l'accès à des actions ou objets S3 spécifiques.",
            "Attacher une politique de bucket avec une condition temporelle pour restreindre l'accès n'est pas une solution réalisable car AWS ne prend pas en charge les conditions temporelles dans les politiques de bucket."
        ]
    },
    {
        "Question Number": "35",
        "Situation": "Une entreprise conçoit une application web et souhaite mettre en œuvre une architecture multi-niveaux pour séparer les préoccupations et améliorer la scalabilité. Elle s'attend à voir des charges de travail fluctuantes en fonction de la demande des utilisateurs, et l'architecture doit se mettre à l'échelle automatiquement en fonction des modèles de trafic. L'entreprise cherche également à améliorer la sécurité en isolant les couches pour prévenir tout accès non autorisé.",
        "Question": "Laquelle des options suivantes décrit le mieux l'architecture que l'entreprise devrait mettre en œuvre ? (Choisissez deux.)",
        "Options": {
            "1": "Utiliser une instance Amazon EC2 comme couche web, Amazon RDS comme couche de base de données, et un Application Load Balancer (ALB) pour distribuer le trafic entre les instances de la couche web.",
            "2": "Utiliser des fonctions AWS Lambda pour les couches web et de base de données afin de réduire la gestion de l'infrastructure et permettre une mise à l'échelle automatique.",
            "3": "Utiliser Amazon S3 pour le stockage, des instances Amazon EC2 pour le calcul, et AWS Direct Connect pour une communication sécurisée entre les couches.",
            "4": "Mettre en œuvre un VPC avec des sous-réseaux publics pour le niveau web et des sous-réseaux privés pour les niveaux application et base de données, utiliser des groupes de mise à l'échelle automatique pour les couches web et application, et déployer une instance RDS dans le sous-réseau privé.",
            "5": "Utiliser une seule instance EC2 pour les couches web et de base de données et les connecter via un Virtual Private Cloud (VPC) pour l'isolation."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Utiliser une instance Amazon EC2 comme couche web, Amazon RDS comme couche de base de données, et un Application Load Balancer (ALB) pour distribuer le trafic entre les instances de la couche web.",
            "Mettre en œuvre un VPC avec des sous-réseaux publics pour le niveau web et des sous-réseaux privés pour les niveaux application et base de données, utiliser des groupes de mise à l'échelle automatique pour les couches web et application, et déployer une instance RDS dans le sous-réseau privé."
        ],
        "Explanation": "La première réponse correcte utilise Amazon EC2 pour la couche web, qui peut gérer des charges de travail fluctuantes et peut être mise à l'échelle automatiquement. Amazon RDS est utilisé pour la couche de base de données, qui fournit une solution évolutive et sécurisée pour la gestion des bases de données. L'Application Load Balancer distribue le trafic entre les instances de la couche web, ce qui aide à gérer les charges de travail fluctuantes. La deuxième réponse correcte utilise un VPC avec des sous-réseaux publics pour le niveau web et des sous-réseaux privés pour les niveaux application et base de données, ce qui fournit une isolation et améliore la sécurité. Les groupes de mise à l'échelle automatique sont utilisés pour les couches web et application, qui peuvent gérer des charges de travail fluctuantes et peuvent être mises à l'échelle automatiquement. Une instance RDS est déployée dans le sous-réseau privé, ce qui fournit une solution évolutive et sécurisée pour la gestion des bases de données.",
        "Other Options": [
            "Utiliser des fonctions AWS Lambda pour les couches web et de base de données peut effectivement réduire la gestion de l'infrastructure et permettre une mise à l'échelle automatique. Cependant, cela peut ne pas fournir l'isolation nécessaire entre les couches pour améliorer la sécurité.",
            "Utiliser Amazon S3 pour le stockage, des instances Amazon EC2 pour le calcul, et AWS Direct Connect pour une communication sécurisée entre les couches peut fournir une architecture multi-niveaux. Cependant, cela ne mentionne aucun mécanisme pour gérer les charges de travail fluctuantes ou pour se mettre à l'échelle automatiquement en fonction des modèles de trafic.",
            "Utiliser une seule instance EC2 pour les couches web et de base de données et les connecter via un Virtual Private Cloud (VPC) pour l'isolation ne fournit pas une architecture multi-niveaux. Cela ne mentionne également aucun mécanisme pour gérer les charges de travail fluctuantes ou pour se mettre à l'échelle automatiquement en fonction des modèles de trafic."
        ]
    },
    {
        "Question Number": "36",
        "Situation": "Une application de santé doit stocker les dossiers des patients de manière sécurisée. Les dossiers doivent être fréquemment accessibles pour des mises à jour et doivent maintenir une hiérarchie de fichiers et des métadonnées. L'équipe de l'application souhaite optimiser les coûts de stockage mais nécessite également un accès cohérent et à faible latence.",
        "Question": "Quel type de stockage répondrait le mieux à ces exigences ?",
        "Options": {
            "1": "Stockage d'objets (Amazon S3)",
            "2": "Stockage de fichiers (Amazon EFS)",
            "3": "Stockage en blocs (Amazon EBS)",
            "4": "Stockage à froid (Amazon S3 Glacier)"
        },
        "Correct Answer": "Stockage de fichiers (Amazon EFS)",
        "Explanation": "Le stockage de fichiers, tel qu'Amazon EFS (Elastic File System), est conçu pour des cas d'utilisation qui nécessitent une hiérarchie de fichiers et des métadonnées, ce qui le rend idéal pour stocker les dossiers des patients. EFS fournit un accès à faible latence et permet à plusieurs instances d'accéder simultanément aux mêmes données, ce qui est essentiel pour les applications qui doivent fréquemment mettre à jour les dossiers des patients. De plus, EFS peut se mettre à l'échelle automatiquement, optimisant ainsi les coûts de stockage tout en maintenant la performance.",
        "Other Options": [
            "Le stockage d'objets (Amazon S3) n'est pas adapté à ce scénario car il est conçu pour des données non structurées et ne maintient pas une hiérarchie de fichiers ni ne prend en charge les sémantiques traditionnelles des systèmes de fichiers, qui sont nécessaires pour gérer efficacement les dossiers des patients.",
            "Le stockage en blocs (Amazon EBS) est généralement utilisé pour des applications nécessitant un stockage haute performance pour des bases de données ou des machines virtuelles. Bien qu'il offre un accès à faible latence, il ne fournit pas de hiérarchie de fichiers ni de partage facile de fichiers entre plusieurs instances, ce qui est une exigence pour l'application de santé.",
            "Le stockage à froid (Amazon S3 Glacier) est conçu pour des données qui sont rarement accessibles et n'est pas adapté aux applications nécessitant des mises à jour fréquentes et un accès à faible latence. Il est principalement utilisé pour l'archivage de données plutôt que pour la gestion active des données."
        ]
    },
    {
        "Question Number": "37",
        "Situation": "Une entreprise possède un bucket S3 contenant des données sensibles qui doivent être accessibles par des rôles IAM spécifiques à travers plusieurs comptes AWS. L'entreprise souhaite s'assurer que seuls ces rôles ont accès tout en gardant la gestion simple et en évitant la nécessité de configurations complexes d'utilisateurs IAM.",
        "Question": "Quelles sont les manières les plus appropriées de mettre en œuvre ce contrôle d'accès ? (Choisissez deux.)",
        "Options": {
            "1": "Créer une politique IAM dans chaque compte qui accorde l'accès au bucket S3 et l'attacher aux rôles requis.",
            "2": "Attacher une politique de bucket au bucket S3 qui accorde explicitement l'accès aux rôles IAM requis dans chaque compte.",
            "3": "Utiliser AWS Secrets Manager pour stocker et gérer les identifiants d'accès pour chaque rôle IAM qui a besoin d'accéder au bucket.",
            "4": "Configurer des points de terminaison VPC dans chaque compte pour contrôler l'accès au bucket S3 en fonction de la configuration du réseau VPC.",
            "5": "Utiliser les points d'accès Amazon S3 avec des politiques qui spécifient les rôles IAM autorisés à travers plusieurs comptes."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Créer une politique IAM dans chaque compte qui accorde l'accès au bucket S3 et l'attacher aux rôles requis.",
            "Attacher une politique de bucket au bucket S3 qui accorde explicitement l'accès aux rôles IAM requis dans chaque compte."
        ],
        "Explanation": "Créer une politique IAM dans chaque compte qui accorde l'accès au bucket S3 et l'attacher aux rôles requis est une réponse correcte car les politiques IAM sont un moyen de gérer les autorisations pour plusieurs comptes AWS. Cette approche permet à l'entreprise de spécifier quels rôles dans chaque compte ont accès au bucket S3. Attacher une politique de bucket au bucket S3 qui accorde explicitement l'accès aux rôles IAM requis dans chaque compte est également correct. Une politique de bucket s'applique à tous les objets dans ce bucket et peut être utilisée pour accorder un accès inter-comptes au bucket S3, ce que l'entreprise souhaite.",
        "Other Options": [
            "Utiliser AWS Secrets Manager pour stocker et gérer les identifiants d'accès pour chaque rôle IAM qui a besoin d'accéder au bucket n'est pas la meilleure option car cela ajouterait une complexité inutile à la gestion des identifiants d'accès. L'entreprise souhaite éviter des configurations complexes d'utilisateurs IAM, et utiliser Secrets Manager ne simplifierait pas la gestion de l'accès au bucket S3.",
            "Configurer des points de terminaison VPC dans chaque compte pour contrôler l'accès au bucket S3 en fonction de la configuration du réseau VPC n'est pas la meilleure option car cela ne contrôlerait pas directement quels rôles IAM ont accès au bucket S3. Les points de terminaison VPC sont utilisés pour connecter votre VPC de manière privée à des services AWS pris en charge, et non pour gérer l'accès aux buckets S3 au niveau des rôles IAM.",
            "Utiliser les points d'accès Amazon S3 avec des politiques qui spécifient les rôles IAM autorisés à travers plusieurs comptes n'est pas la meilleure option car les points d'accès S3 sont utilisés pour simplifier la gestion de l'accès aux données à grande échelle pour les applications utilisant des ensembles de données partagés. Ils ne fournissent pas un moyen de gérer l'accès aux buckets S3 au niveau des rôles IAM à travers plusieurs comptes."
        ]
    },
    {
        "Question Number": "38",
        "Situation": "Une entreprise souhaite concevoir une application web hautement disponible qui peut résister aux pannes d'infrastructure au sein d'une région et fournir un accès à faible latence aux utilisateurs à travers plusieurs emplacements.",
        "Question": "Quel service AWS l'entreprise devrait-elle utiliser pour gérer la distribution du trafic à travers plusieurs zones de disponibilité, et quel avantage cela procure-t-il ?",
        "Options": {
            "1": "Amazon Route 53",
            "2": "AWS Direct Connect",
            "3": "Amazon S3",
            "4": "Amazon DynamoDB"
        },
        "Correct Answer": "Amazon Route 53",
        "Explanation": "Amazon Route 53 est un service web de système de noms de domaine (DNS) évolutif qui fournit un enregistrement de nom de domaine hautement fiable et rentable, un routage DNS et une vérification de l'état des ressources. Il peut gérer la distribution du trafic à travers plusieurs zones de disponibilité en dirigeant les demandes des utilisateurs vers le point de terminaison sain le plus proche, garantissant un accès à faible latence et une haute disponibilité. Cela en fait un choix idéal pour les applications qui doivent résister aux pannes d'infrastructure et maintenir des performances à travers différents emplacements géographiques.",
        "Other Options": [
            "AWS Direct Connect est un service cloud qui fournit une connexion réseau dédiée de vos locaux à AWS. Bien qu'il puisse améliorer les performances du réseau, il ne gère pas la distribution du trafic à travers les zones de disponibilité.",
            "Amazon S3 (Simple Storage Service) est un service de stockage d'objets qui fournit un stockage hautement évolutif pour les données. Il ne gère pas la distribution du trafic ou le routage pour les applications web.",
            "Amazon DynamoDB est un service de base de données NoSQL entièrement géré qui fournit des performances rapides et prévisibles avec une évolutivité transparente. Il n'est pas conçu pour la distribution du trafic ou la gestion des demandes des utilisateurs à travers plusieurs zones de disponibilité."
        ]
    },
    {
        "Question Number": "39",
        "Situation": "Une entreprise souhaite intégrer de manière sécurisée sa fonction AWS Lambda avec DynamoDB et S3. Elle doit s'assurer que la fonction Lambda ne peut effectuer que des actions spécifiques sur ces services, tout en limitant quels autres services et comptes AWS peuvent invoquer la fonction.",
        "Question": "Quelle approche devraient-ils adopter pour y parvenir ?",
        "Options": {
            "1": "Attacher une politique inline à la fonction Lambda qui spécifie les actions autorisées sur DynamoDB et S3, et appliquer une politique de ressource qui restreint quels services et comptes peuvent invoquer la fonction Lambda.",
            "2": "Utiliser un rôle d'exécution Lambda qui accorde des autorisations pour les actions nécessaires sur DynamoDB et S3, et ajouter une politique de ressource Lambda pour contrôler les autorisations d'invocation.",
            "3": "Attacher une politique IAM gérée à la fonction Lambda pour accéder à DynamoDB et S3, et configurer une limite de permission Lambda pour restreindre l'invocation.",
            "4": "Créer un rôle lié au service pour la fonction Lambda afin d'accéder à DynamoDB et S3 et utiliser une politique de bucket S3 pour restreindre l'invocation."
        },
        "Correct Answer": "Utiliser un rôle d'exécution Lambda qui accorde des autorisations pour les actions nécessaires sur DynamoDB et S3, et ajouter une politique de ressource Lambda pour contrôler les autorisations d'invocation.",
        "Explanation": "Utiliser un rôle d'exécution Lambda est la meilleure pratique pour accorder des autorisations aux fonctions AWS Lambda. Ce rôle permet à la fonction d'effectuer des actions spécifiques sur DynamoDB et S3, garantissant que seules les autorisations nécessaires sont accordées. De plus, une politique de ressource Lambda peut être appliquée pour contrôler quels services et comptes AWS peuvent invoquer la fonction Lambda, fournissant un moyen sécurisé et flexible de gérer l'accès.",
        "Other Options": [
            "Attacher une politique inline à la fonction Lambda n'est pas recommandé car les politiques inline sont liées à une ressource spécifique et peuvent devenir difficiles à gérer. Un rôle d'exécution Lambda est une approche plus évolutive et gérable. Bien qu'une politique de ressource soit importante, le rôle d'exécution est le principal moyen d'accorder des autorisations pour accéder à d'autres services AWS.",
            "Attacher une politique IAM gérée à la fonction Lambda n'est pas la meilleure approche car les politiques gérées sont plus larges et peuvent accorder plus d'autorisations que nécessaire. De plus, bien qu'une limite de permission puisse aider à restreindre les autorisations, ce n'est pas le principal moyen de contrôler les autorisations d'invocation, qui est mieux géré par une politique de ressource.",
            "Créer un rôle lié au service pour la fonction Lambda n'est pas applicable dans ce cas, car les rôles liés au service sont des rôles prédéfinis que les services AWS utilisent pour effectuer des actions en votre nom. Ils ne fournissent pas la granularité nécessaire pour contrôler l'accès à DynamoDB et S3. Une politique de bucket S3 n'est également pas adaptée pour contrôler les autorisations d'invocation Lambda, car elle est spécifique à S3 et ne s'applique pas aux fonctions Lambda."
        ]
    },
    {
        "Question Number": "40",
        "Situation": "Une plateforme de trading financier mondial doit minimiser la latence pour les utilisateurs dans différentes parties du monde. La plateforme nécessite un transfert de données rapide et constant avec un minimum de sauts pour réduire le risque de retards ou de perte de paquets. De plus, elle doit prendre en charge le trafic TCP et UDP pour diverses applications en temps réel.",
        "Question": "Quel service AWS répondrait le mieux à ces exigences ?",
        "Options": {
            "1": "Amazon CloudFront avec mise en cache en bordure",
            "2": "AWS Direct Connect pour des connexions dédiées",
            "3": "AWS Global Accelerator avec adresses IP Anycast",
            "4": "Amazon Route 53 avec routage basé sur la latence"
        },
        "Correct Answer": "AWS Global Accelerator avec adresses IP Anycast",
        "Explanation": "AWS Global Accelerator est conçu spécifiquement pour améliorer la disponibilité et les performances des applications avec des utilisateurs répartis dans le monde entier. Il utilise des adresses IP Anycast pour acheminer le trafic des utilisateurs vers l'emplacement AWS le plus proche, minimisant ainsi la latence et fournissant un chemin cohérent pour le transfert de données. Ce service prend en charge à la fois le trafic TCP et UDP, ce qui le rend idéal pour les applications en temps réel nécessitant une faible latence et un transfert de données à haute vitesse. De plus, il réduit le nombre de sauts entre l'utilisateur et l'application, ce qui aide à minimiser les retards et la perte de paquets.",
        "Other Options": [
            "Amazon CloudFront avec mise en cache en bordure est principalement un réseau de distribution de contenu (CDN) qui met en cache le contenu aux emplacements en bordure pour réduire la latence de la livraison de contenu statique. Bien qu'il puisse améliorer les performances pour certains types d'applications, il n'est pas optimisé pour les applications en temps réel nécessitant un transfert de données constant et à haute vitesse et un support pour le trafic TCP et UDP.",
            "AWS Direct Connect fournit des connexions réseau dédiées de vos locaux à AWS, ce qui peut réduire la latence pour le transfert de données. Cependant, il est plus adapté aux architectures de cloud hybride et ne fournit pas intrinsèquement de routage mondial ou de support pour le trafic TCP et UDP à travers plusieurs régions, ce qui le rend moins idéal pour une plateforme de trading financier mondial.",
            "Amazon Route 53 avec routage basé sur la latence est un service DNS qui dirige les demandes des utilisateurs vers la région AWS la plus proche en fonction de la latence. Bien qu'il puisse aider à améliorer les performances, il ne fournit pas le même niveau de transfert de données constant, à haute vitesse et avec un minimum de sauts que AWS Global Accelerator, ni ne prend en charge directement le trafic TCP et UDP de la même manière."
        ]
    },
    {
        "Question Number": "41",
        "Situation": "Un administrateur IAM met en place l'accès pour une équipe de développeurs qui a besoin d'un accès à long terme aux ressources AWS. Pour réduire la charge de gestion, l'administrateur souhaite appliquer les mêmes autorisations à plusieurs membres de l'équipe tout en s'assurant que les politiques sont réutilisables et peuvent être facilement mises à jour.",
        "Question": "Quelle approche l'administrateur devrait-il adopter pour mettre en œuvre ces exigences ?",
        "Options": {
            "1": "Attacher des politiques en ligne individuelles à chaque utilisateur IAM avec des autorisations spécifiques.",
            "2": "Créer une politique gérée par le client et l'attacher à un groupe IAM, puis ajouter les utilisateurs au groupe.",
            "3": "Utiliser une politique gérée par AWS et l'attacher directement à chaque utilisateur IAM.",
            "4": "Définir une politique de ressource avec les autorisations nécessaires et l'appliquer directement aux ressources."
        },
        "Correct Answer": "Créer une politique gérée par le client et l'attacher à un groupe IAM, puis ajouter les utilisateurs au groupe.",
        "Explanation": "Créer une politique gérée par le client permet à l'administrateur IAM de définir un ensemble d'autorisations qui peuvent être réutilisées par plusieurs utilisateurs. En attachant cette politique à un groupe IAM, tous les utilisateurs de ce groupe héritent des autorisations définies dans la politique. Cette approche réduit la charge de gestion car si des autorisations doivent être mises à jour, l'administrateur peut simplement modifier la politique à un seul endroit plutôt que de mettre à jour chaque utilisateur individuellement. Cette méthode garantit également que les autorisations sont cohérentes entre tous les membres de l'équipe.",
        "Other Options": [
            "Attacher des politiques en ligne individuelles à chaque utilisateur IAM crée une politique unique pour chaque utilisateur, ce qui augmente la charge de gestion et rend difficile le maintien d'autorisations cohérentes au sein de l'équipe. Les politiques en ligne ne sont pas réutilisables et doivent être mises à jour individuellement pour chaque utilisateur.",
            "Utiliser une politique gérée par AWS et l'attacher directement à chaque utilisateur IAM peut entraîner des défis dans la gestion des autorisations, car les politiques gérées par AWS sont prédéfinies et peuvent ne pas répondre aux besoins spécifiques de l'équipe de développeurs. De plus, si des modifications sont nécessaires, chaque utilisateur devra être mis à jour individuellement, ce qui augmente la charge de gestion.",
            "Définir une politique de ressource avec les autorisations nécessaires et l'appliquer directement aux ressources n'est pas adapté à la gestion des autorisations des utilisateurs. Les politiques de ressource sont destinées à contrôler l'accès à des ressources AWS spécifiques plutôt qu'à gérer les autorisations des utilisateurs à travers plusieurs utilisateurs. Cette approche ne répond pas à l'exigence d'autorisations réutilisables et facilement mises à jour pour une équipe d'utilisateurs."
        ]
    },
    {
        "Question Number": "42",
        "Situation": "Une entreprise stocke des données commerciales critiques dans AWS et doit choisir une solution de stockage qui offre une haute durabilité et une réplication à travers plusieurs régions pour la récupération après sinistre.",
        "Question": "Quelle option de stockage l'entreprise devrait-elle choisir pour garantir la durabilité et la réplication des données ?",
        "Options": {
            "1": "Utiliser Amazon EBS (Elastic Block Store) avec des instantanés pour la sauvegarde et la réplication, en s'assurant que les données sont répliquées dans une autre zone de disponibilité.",
            "2": "Utiliser Amazon S3 avec la versionnage activé et la réplication inter-régionale pour garantir la durabilité des données et la réplication mondiale.",
            "3": "Utiliser Amazon EFS (Elastic File System) pour un accès partagé, car il offre une réplication automatique mais ne garantit pas la durabilité des données à travers les régions.",
            "4": "Utiliser Amazon Glacier pour le stockage d'archives, car il offre une durabilité à faible coût mais ne prend pas en charge la réplication à travers les régions."
        },
        "Correct Answer": "Utiliser Amazon S3 avec la versionnage activé et la réplication inter-régionale pour garantir la durabilité des données et la réplication mondiale.",
        "Explanation": "Amazon S3 est conçu pour une haute durabilité et disponibilité, avec un SLA de 99.999999999% (11 nines) de durabilité. En activant la versionnage, l'entreprise peut conserver plusieurs versions d'un objet, ce qui aide à récupérer des suppressions ou des écrasements accidentels. La réplication inter-régionale (CRR) permet à l'entreprise de répliquer automatiquement les données à travers différentes régions AWS, fournissant une couche supplémentaire de récupération après sinistre et garantissant que les données critiques sont disponibles même si une région subit une panne. Cela fait de S3 le meilleur choix pour les besoins de l'entreprise en matière de durabilité et de réplication à travers plusieurs régions.",
        "Other Options": [
            "Utiliser Amazon EBS avec des instantanés offre durabilité et la possibilité de créer des sauvegardes, mais il réplique principalement les données au sein de la même zone de disponibilité ou peut être copié dans une autre région manuellement. EBS n'est pas conçu pour une réplication automatique inter-régionale, ce qui le rend moins adapté à la récupération après sinistre à travers plusieurs régions.",
            "Amazon EFS fournit un système de fichiers géré qui peut être accessible par plusieurs instances, et il offre un certain niveau de redondance et de disponibilité. Cependant, il ne réplique pas automatiquement les données à travers les régions, ce qui est une exigence critique pour la récupération après sinistre dans ce scénario.",
            "Amazon Glacier est principalement conçu pour le stockage d'archives à long terme et offre une durabilité à faible coût. Bien qu'il soit très durable, il ne prend pas en charge la réplication automatique à travers les régions, ce qui le rend inadapté aux besoins de l'entreprise en matière d'accès immédiat et de capacités de récupération après sinistre."
        ]
    },
    {
        "Question Number": "43",
        "Situation": "Une entreprise souhaite s'assurer qu'elle dispose d'une stratégie de sauvegarde résiliente pour sa base de données Amazon RDS afin de récupérer des données en cas de défaillance. Elle exige que les sauvegardes soient automatiquement créées et conservées pendant 35 jours, avec la possibilité de restaurer à un moment précis si nécessaire.",
        "Question": "Quelle configuration devraient-ils utiliser pour répondre à ces exigences, et quelles sont les caractéristiques clés ? (Choisissez deux.)",
        "Options": {
            "1": "Configurer des sauvegardes automatisées pour conserver les données pendant 35 jours, avec des sauvegardes incrémentielles après le premier instantané complet. Les sauvegardes automatisées permettent une récupération à un moment précis à n'importe quel intervalle de 5 minutes dans la période de conservation.",
            "2": "Utiliser des instantanés manuels quotidiennement et conserver chaque instantané indéfiniment pour garantir la récupération des données, car les sauvegardes automatisées ne prennent pas en charge la récupération à un moment précis.",
            "3": "Mettre en place une réplication inter-régionale pour les sauvegardes afin de garantir leur résilience à travers plusieurs régions, mais limiter la conservation à 7 jours pour réduire les coûts.",
            "4": "Implémenter une seule sauvegarde complète une fois et activer des instantanés RDS automatiques toutes les 5 minutes pour répondre à l'exigence de récupération à un moment précis.",
            "5": "Activer la sauvegarde continue vers Amazon S3 avec le versionnage activé, permettant la restauration à tout état précédent dans les 35 jours."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Configurer des sauvegardes automatisées pour conserver les données pendant 35 jours, avec des sauvegardes incrémentielles après le premier instantané complet. Les sauvegardes automatisées permettent une récupération à un moment précis à n'importe quel intervalle de 5 minutes dans la période de conservation.",
            "Activer la sauvegarde continue vers Amazon S3 avec le versionnage activé, permettant la restauration à tout état précédent dans les 35 jours."
        ],
        "Explanation": "Les sauvegardes automatisées dans Amazon RDS sont une fonctionnalité qui crée automatiquement une sauvegarde de votre base de données, avec la possibilité de conserver ces sauvegardes pendant 35 jours. Elles permettent également une récupération à un moment précis, ce qui signifie que vous pouvez restaurer votre base de données à un moment spécifique dans la période de conservation. Cela répond à l'exigence de l'entreprise pour la création et la conservation automatiques des sauvegardes, ainsi que la capacité de restaurer à un moment précis. La sauvegarde continue vers Amazon S3 avec le versionnage activé répond également à ces exigences, car elle permet la restauration à tout état précédent dans la période de conservation.",
        "Other Options": [
            "Les instantanés manuels ne répondent pas à l'exigence de création automatique de sauvegardes. De plus, bien qu'ils puissent être conservés indéfiniment, ils ne prennent pas en charge la récupération à un moment précis, ce qui est une exigence.",
            "La réplication inter-régionale pour les sauvegardes offre une résilience, mais limiter la conservation à 7 jours ne répond pas à l'exigence de conservation jusqu'à 35 jours.",
            "Implémenter une seule sauvegarde complète et activer des instantanés RDS automatiques toutes les 5 minutes ne répond pas à l'exigence de conservation jusqu'à 35 jours, car cela ne précise pas combien de temps ces instantanés seraient conservés."
        ]
    },
    {
        "Question Number": "44",
        "Situation": "Une entreprise de commerce électronique gère un grand volume de données de transaction et souhaite garantir la durabilité et la disponibilité des données à travers les régions. Elle a besoin d'une stratégie de sauvegarde et de réplication fiable qui lui permettra de restaurer rapidement les données en cas de catastrophe ou de corruption des données. Pour répondre à ces exigences, l'entreprise doit déterminer les services et configurations AWS les plus appropriés pour mettre en œuvre des sauvegardes et une réplication inter-régionale.",
        "Question": "Que devraient-ils considérer lors de la mise en place de cette stratégie de sauvegarde et de réplication ?",
        "Options": {
            "1": "Utiliser Amazon S3 avec la réplication inter-régionale activée pour dupliquer automatiquement les données à travers différentes régions et mettre en place des politiques de cycle de vie pour gérer les sauvegardes.",
            "2": "Compter sur des instantanés Amazon EC2 et transférer manuellement les fichiers de sauvegarde entre les régions pour chaque instance.",
            "3": "Activer AWS Shield Advanced pour répliquer et protéger les données en cas de catastrophe.",
            "4": "Stocker les sauvegardes uniquement dans Amazon Glacier et les récupérer en cas d'urgence pour réduire les coûts de stockage."
        },
        "Correct Answer": "Utiliser Amazon S3 avec la réplication inter-régionale activée pour dupliquer automatiquement les données à travers différentes régions et mettre en place des politiques de cycle de vie pour gérer les sauvegardes.",
        "Explanation": "Utiliser Amazon S3 avec la réplication inter-régionale (CRR) est la stratégie la plus efficace pour garantir la durabilité et la disponibilité des données à travers les régions. La CRR réplique automatiquement les objets dans les compartiments S3 vers une autre région AWS, offrant redondance et options de récupération rapide en cas de perte ou de corruption des données. De plus, la mise en place de politiques de cycle de vie permet à l'entreprise de gérer la conservation des données et de transférer les données plus anciennes vers des classes de stockage à coût réduit, optimisant ainsi les coûts tout en garantissant que les données sont sauvegardées de manière appropriée.",
        "Other Options": [
            "Compter sur des instantanés Amazon EC2 et transférer manuellement les fichiers de sauvegarde entre les régions n'est pas idéal pour un grand volume de données de transaction. Les instantanés sont liés à des instances EC2 individuelles et ne fournissent pas le même niveau d'automatisation et d'efficacité que S3 avec CRR. Cette méthode augmente également le risque d'erreur humaine et peut entraîner des sauvegardes incohérentes.",
            "Activer AWS Shield Advanced est principalement axé sur la protection DDoS et ne fournit pas de capacités de sauvegarde ou de réplication. Bien qu'il soit important pour la sécurité, il ne répond pas au besoin de l'entreprise en matière de durabilité et de disponibilité des données à travers les régions.",
            "Stocker les sauvegardes uniquement dans Amazon Glacier n'est pas adapté aux besoins de récupération rapide. Glacier est conçu pour le stockage d'archives à long terme et les temps de récupération peuvent être de plusieurs heures, ce qui n'est pas idéal pour les scénarios de récupération après sinistre où un accès immédiat aux données est requis. Cette option ne fournit également pas de réplication inter-régionale."
        ]
    },
    {
        "Question Number": "45",
        "Situation": "Une entreprise met en place un Elastic Load Balancer (ELB) dans AWS pour distribuer le trafic entrant sur plusieurs instances EC2 dans différentes zones de disponibilité (AZ). Elle souhaite que le répartiteur de charge soit accessible depuis Internet, mais veut également contrôler l'accès aux instances publiques et privées au sein de son VPC.",
        "Question": "Quelle configuration devraient-ils choisir, et pourquoi cette configuration est-elle bénéfique pour gérer le trafic à grande échelle ?",
        "Options": {
            "1": "Configurer un ELB orienté Internet avec des IP publiques assignées aux nœuds, permettant de router le trafic vers des instances EC2 publiques et privées au sein du VPC. Cette configuration prend en charge l'évolutivité à travers les AZ et offre une haute disponibilité.",
            "2": "Utiliser un répartiteur de charge interne avec des IP privées, restreignant l'accès au VPC et garantissant que seul le trafic interne est équilibré entre les instances.",
            "3": "Mettre en place un ELB orienté Internet avec uniquement des instances EC2 privées pour limiter l'accès public tout en maintenant l'évolutivité.",
            "4": "Configurer le répartiteur de charge comme une configuration à nœud unique dans une AZ pour optimiser l'utilisation des ressources et limiter l'évolutivité à travers plusieurs AZ."
        },
        "Correct Answer": "Configurer un ELB orienté Internet avec des IP publiques assignées aux nœuds, permettant de router le trafic vers des instances EC2 publiques et privées au sein du VPC. Cette configuration prend en charge l'évolutivité à travers les AZ et offre une haute disponibilité.",
        "Explanation": "Un Elastic Load Balancer (ELB) orienté Internet est conçu pour gérer le trafic entrant depuis Internet et peut router les demandes vers des instances EC2 publiques et privées. En assignant des IP publiques à l'ELB, il peut recevoir directement le trafic de sources externes tout en gérant le trafic interne vers les instances privées. Cette configuration permet une haute disponibilité et une tolérance aux pannes en distribuant le trafic sur plusieurs instances EC2 dans différentes zones de disponibilité (AZ), garantissant que si une AZ tombe en panne, les autres peuvent toujours gérer la charge. Cette configuration est bénéfique pour gérer le trafic à grande échelle car elle permet une montée en charge transparente des ressources en fonction de la demande tout en maintenant le contrôle sur l'accès aux instances.",
        "Other Options": [
            "Utiliser un répartiteur de charge interne avec des IP privées restreint l'accès uniquement au trafic interne au sein du VPC, ce qui ne répond pas à l'exigence d'être accessible depuis Internet. Cette option ne permettrait pas aux utilisateurs externes d'accéder aux services hébergés sur les instances EC2.",
            "Mettre en place un ELB orienté Internet avec uniquement des instances EC2 privées ne fonctionnerait pas car les instances privées ne peuvent pas être directement accessibles depuis Internet. Cette configuration empêcherait l'ELB de router le trafic efficacement, car il n'aurait pas d'instances publiques pour gérer les demandes entrantes.",
            "Configurer le répartiteur de charge comme une configuration à nœud unique dans une AZ limite les avantages de l'équilibrage de charge, tels que la haute disponibilité et la tolérance aux pannes. Cette configuration n'exploite pas les avantages de la distribution du trafic à travers plusieurs AZ, ce qui est crucial pour gérer le trafic à grande échelle."
        ]
    },
    {
        "Question Number": "46",
        "Situation": "Une startup souhaite surveiller de près ses coûts mensuels de réseau sur AWS et recevoir des alertes si les dépenses dépassent le montant budgété. Elle souhaite également analyser les coûts de transfert de données entre les régions au fil du temps.",
        "Question": "Quels outils de gestion des coûts AWS devraient-ils utiliser pour atteindre ces objectifs ?",
        "Options": {
            "1": "AWS Cost and Usage Report et AWS Trusted Advisor",
            "2": "AWS Budgets et AWS Cost Explorer",
            "3": "AWS Trusted Advisor et AWS Budgets",
            "4": "AWS Support et AWS Cost Explorer"
        },
        "Correct Answer": "AWS Budgets et AWS Cost Explorer",
        "Explanation": "AWS Budgets permet aux utilisateurs de définir des budgets personnalisés de coûts et d'utilisation qui peuvent déclencher des alertes lorsque les dépenses dépassent les seuils définis. Cela est essentiel pour la startup afin de surveiller ses coûts mensuels de réseau et de recevoir des alertes. AWS Cost Explorer fournit des informations détaillées sur les modèles de coûts et d'utilisation au fil du temps, ce qui est utile pour analyser les coûts de transfert de données entre les régions. Ensemble, ces outils répondent efficacement aux exigences de la startup en matière de surveillance budgétaire et d'analyse des coûts.",
        "Other Options": [
            "AWS Cost and Usage Report fournit des informations de facturation détaillées mais n'offre pas de capacités d'alerte. AWS Trusted Advisor propose des recommandations de bonnes pratiques mais n'est pas spécifiquement conçu pour la surveillance budgétaire ou l'analyse détaillée des coûts.",
            "Bien qu'AWS Budgets soit correctement identifié pour la surveillance budgétaire, AWS Cost Explorer est le meilleur choix pour analyser les coûts au fil du temps par rapport à AWS Trusted Advisor, qui se concentre sur l'optimisation des ressources plutôt que sur la gestion des coûts.",
            "AWS Support est un service d'assistance technique et ne fournit pas de fonctionnalités de gestion des coûts. AWS Cost Explorer est utile pour analyser les coûts, mais sans AWS Budgets, la startup manquerait de la fonctionnalité d'alerte nécessaire pour la surveillance budgétaire."
        ]
    },
    {
        "Question Number": "47",
        "Situation": "Une application de commerce électronique utilise Amazon DynamoDB pour stocker les données du catalogue de produits et doit gérer un volume élevé de demandes de lecture lors des ventes flash. L'équipe de l'application souhaite réduire la latence des demandes de lecture, garantissant que les utilisateurs peuvent accéder aux détails des produits presque instantanément. Cependant, ils n'ont pas besoin de lectures fortement cohérentes.",
        "Question": "Quelle solution répondrait le mieux à ces exigences ?",
        "Options": {
            "1": "Activer DynamoDB Auto Scaling pour gérer la charge accrue lors des ventes flash",
            "2": "Intégrer DynamoDB avec Amazon ElastiCache pour Redis pour un accès en lecture plus rapide",
            "3": "Activer DynamoDB Accelerator (DAX) pour fournir un cache en mémoire pour les charges de travail lourdes en lecture",
            "4": "Utiliser les tables globales DynamoDB pour répliquer le catalogue de produits dans plusieurs régions"
        },
        "Correct Answer": "Activer DynamoDB Accelerator (DAX) pour fournir un cache en mémoire pour les charges de travail lourdes en lecture",
        "Explanation": "DynamoDB Accelerator (DAX) est spécifiquement conçu pour fournir un cache en mémoire rapide pour DynamoDB, ce qui réduit considérablement la latence des lectures. Étant donné que l'application n'exige pas de lectures fortement cohérentes, DAX peut servir des lectures de cohérence éventuelle avec une latence très faible, ce qui le rend idéal pour gérer des volumes élevés de demandes de lecture lors des ventes flash. DAX peut gérer des pics de trafic et améliorer les performances des charges de travail lourdes en lecture, garantissant que les utilisateurs peuvent accéder aux détails des produits presque instantanément.",
        "Other Options": [
            "Activer DynamoDB Auto Scaling aiderait à gérer la charge accrue en ajustant automatiquement la capacité de lecture et d'écriture en fonction des modèles de trafic. Cependant, cela ne traite pas directement le problème de latence pour les demandes de lecture, qui est critique lors des ventes flash.",
            "Intégrer DynamoDB avec Amazon ElastiCache pour Redis pourrait améliorer les performances de lecture en mettant en cache les données fréquemment consultées. Cependant, cela ajoute de la complexité à l'architecture et peut ne pas être aussi étroitement intégré à DynamoDB que DAX, qui est spécifiquement optimisé à cet effet.",
            "Utiliser les tables globales DynamoDB permettrait de répliquer le catalogue de produits dans plusieurs régions, améliorant la disponibilité et réduisant la latence pour les utilisateurs dans différentes zones géographiques. Cependant, cette solution ne traite pas directement le besoin de réduire la latence lors d'une forte demande de lecture, car elle se concentre davantage sur la disponibilité des données et la redondance."
        ]
    },
    {
        "Question Number": "48",
        "Situation": "Une entreprise de jeux en ligne doit stocker des données de joueurs, y compris des profils, des états de jeu et des objets d'inventaire. Les données doivent être hautement disponibles et durables, avec la capacité de gérer des millions de demandes de lecture et d'écriture par seconde. L'entreprise anticipe également une croissance rapide et nécessite une solution de stockage qui peut évoluer sans effort pour répondre à la demande croissante sans compromettre les performances.",
        "Question": "Quelle solution de stockage le concepteur de solutions devrait-il recommander pour répondre à ces exigences ?",
        "Options": {
            "1": "Amazon RDS pour MySQL",
            "2": "Amazon DynamoDB",
            "3": "Amazon S3 Intelligent-Tiering",
            "4": "Amazon Redshift"
        },
        "Correct Answer": "Amazon DynamoDB",
        "Explanation": "Amazon DynamoDB est un service de base de données NoSQL entièrement géré qui offre une haute disponibilité et durabilité. Il est conçu pour gérer des millions de demandes de lecture et d'écriture par seconde, ce qui le rend idéal pour les applications ayant des exigences de débit élevées, comme les jeux en ligne. DynamoDB évolue automatiquement pour s'adapter à la demande croissante sans compromettre les performances, ce qui correspond parfaitement au besoin de l'entreprise d'une solution de stockage capable de croître rapidement à mesure que la base de joueurs s'élargit. De plus, il offre des fonctionnalités telles que des sauvegardes automatiques et une réplication mondiale, garantissant la durabilité et la disponibilité des données.",
        "Other Options": [
            "Amazon RDS pour MySQL est un service de base de données relationnelle qui convient aux données structurées et prend en charge les requêtes SQL. Cependant, il peut ne pas gérer le même niveau de débit que DynamoDB et nécessite plus de gestion pour l'évolutivité, ce qui le rend moins idéal pour les besoins d'une plateforme de jeux en ligne en forte croissance et hautement disponible.",
            "Amazon S3 Intelligent-Tiering est un service de stockage d'objets conçu pour stocker de grandes quantités de données non structurées. Bien qu'il offre durabilité et disponibilité, il n'est pas optimisé pour des opérations de lecture et d'écriture à haute fréquence comme celles requises pour les données des joueurs dans un contexte de jeux en ligne, ce qui le rend inadapté à ce scénario.",
            "Amazon Redshift est un service d'entrepôt de données optimisé pour les requêtes analytiques et les rapports. Il n'est pas conçu pour des charges de travail transactionnelles à haute vitesse comme celles nécessaires pour la gestion des données des joueurs en temps réel dans les jeux, ce qui en fait un choix inapproprié pour les exigences décrites."
        ]
    },
    {
        "Question Number": "49",
        "Situation": "Une entreprise conçoit une architecture VPC sécurisée pour ses applications sur AWS. Elle doit contrôler à la fois le trafic entrant et sortant vers des instances spécifiques au sein d'un sous-réseau et appliquer des contrôles de sécurité supplémentaires au niveau du sous-réseau.",
        "Question": "Laquelle des options suivantes explique correctement l'utilisation et les différences entre les NACL et les groupes de sécurité à cette fin ? (Choisissez deux.)",
        "Options": {
            "1": "Les NACL fonctionnent au niveau de l'instance et fournissent un filtrage de trafic avec état, tandis que les groupes de sécurité fonctionnent au niveau du sous-réseau et offrent des contrôles sans état pour chaque demande.",
            "2": "Les groupes de sécurité sont appliqués au niveau de l'instance et fournissent des contrôles avec état, permettant ou refusant des adresses IP spécifiques, tandis que les NACL sont appliqués au niveau du sous-réseau et peuvent être configurés pour autoriser ou refuser des plages d'adresses IP spécifiques de manière sans état.",
            "3": "Les NACL s'appliquent uniquement au trafic entrant au niveau du sous-réseau, tandis que les groupes de sécurité contrôlent à la fois le trafic entrant et sortant et sont avec état par défaut.",
            "4": "Les groupes de sécurité et les NACL fonctionnent tous deux au niveau de l'instance, mais les NACL sont avec état, permettant un filtrage dynamique des paquets à travers plusieurs instances.",
            "5": "Les NACL fournissent une couche de sécurité supplémentaire en agissant comme un pare-feu pour contrôler le trafic entrant et sortant d'un ou plusieurs sous-réseaux, indépendamment des groupes de sécurité."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Les groupes de sécurité sont appliqués au niveau de l'instance et fournissent des contrôles avec état, permettant ou refusant des adresses IP spécifiques, tandis que les NACL sont appliqués au niveau du sous-réseau et peuvent être configurés pour autoriser ou refuser des plages d'adresses IP spécifiques de manière sans état.",
            "Les NACL fournissent une couche de sécurité supplémentaire en agissant comme un pare-feu pour contrôler le trafic entrant et sortant d'un ou plusieurs sous-réseaux, indépendamment des groupes de sécurité."
        ],
        "Explanation": "Les groupes de sécurité dans AWS sont appliqués au niveau de l'instance et fournissent des contrôles avec état, ce qui signifie qu'ils suivent l'état des connexions réseau et autorisent automatiquement le trafic de retour pour les connexions sortantes autorisées. Ils peuvent être configurés pour autoriser ou refuser des adresses IP spécifiques. D'autre part, les listes de contrôle d'accès réseau (NACL) sont appliquées au niveau du sous-réseau et fournissent des contrôles sans état, ce qui signifie qu'elles évaluent chaque paquet individuellement sans tenir compte des connexions existantes. Elles peuvent être configurées pour autoriser ou refuser des plages d'adresses IP spécifiques. Les NACL fournissent également une couche de sécurité supplémentaire en agissant comme un pare-feu pour contrôler le trafic entrant et sortant d'un ou plusieurs sous-réseaux, indépendamment des groupes de sécurité.",
        "Other Options": [
            "Les NACL fonctionnent au niveau du sous-réseau et fournissent un filtrage de trafic sans état, pas au niveau de l'instance. De plus, les groupes de sécurité fonctionnent au niveau de l'instance et offrent des contrôles avec état, pas au niveau du sous-réseau.",
            "Les NACL s'appliquent au trafic entrant et sortant au niveau du sous-réseau, pas seulement au trafic entrant.",
            "Les groupes de sécurité et les NACL ne fonctionnent pas tous deux au niveau de l'instance. Les groupes de sécurité fonctionnent au niveau de l'instance, tandis que les NACL fonctionnent au niveau du sous-réseau. De plus, les NACL sont sans état, pas avec état."
        ]
    },
    {
        "Question Number": "50",
        "Situation": "Une entreprise de médias met en place une architecture sans serveur pour gérer l'afflux de téléchargements de vidéos de vacances de ses utilisateurs. Elle souhaite que la configuration soit entièrement gérée, qu'elle s'adapte automatiquement pour gérer un trafic imprévisible et qu'elle permette aux utilisateurs de s'authentifier sans problème. Le flux de travail idéal devrait impliquer des téléchargements de vidéos, un traitement pour plusieurs formats et un stockage, le tout avec un minimum de frais généraux.",
        "Question": "Étant donné ce scénario, quelle combinaison de services AWS soutiendrait le mieux cette architecture, et qu'est-ce qui en fait le choix optimal ?",
        "Options": {
            "1": "Exploiter Amazon Cognito pour l'authentification des utilisateurs afin d'échanger en toute sécurité les jetons de fournisseur d'identité contre des identifiants temporaires AWS, permettant des téléchargements directs vers un bucket S3. Déclencher une fonction AWS Lambda à chaque téléchargement pour démarrer le pipeline de traitement vidéo.",
            "2": "Utiliser une flotte d'instances Amazon EC2 pour l'authentification des utilisateurs, les téléchargements de vidéos et le transcodage, en stockant les fichiers vidéo sur des volumes EBS attachés. Échelonner manuellement les instances pour répondre aux pics de demande.",
            "3": "Configurer Amazon S3 pour le stockage vidéo, initier une fonction AWS Lambda par téléchargement de vidéo pour le traitement, et enregistrer les détails des travaux de traitement dans une base de données Amazon RDS pour la résilience.",
            "4": "Authentifier les utilisateurs en utilisant des rôles IAM, stocker les vidéos dans DynamoDB, et utiliser des instances EC2 pour gérer les tâches de traitement, avec les vidéos traitées finales stockées à nouveau dans S3 pour récupération."
        },
        "Correct Answer": "Exploiter Amazon Cognito pour l'authentification des utilisateurs afin d'échanger en toute sécurité les jetons de fournisseur d'identité contre des identifiants temporaires AWS, permettant des téléchargements directs vers un bucket S3. Déclencher une fonction AWS Lambda à chaque téléchargement pour démarrer le pipeline de traitement vidéo.",
        "Explanation": "Cette option est optimale car elle utilise des services entièrement gérés qui s'adaptent automatiquement et nécessitent peu de frais opérationnels. Amazon Cognito fournit une authentification des utilisateurs sans faille, permettant aux utilisateurs de télécharger des vidéos directement vers un bucket S3, qui est conçu pour une haute disponibilité et durabilité. L'utilisation d'AWS Lambda pour déclencher le traitement vidéo lors du téléchargement garantit que le traitement peut s'adapter automatiquement au nombre de téléchargements, gérant efficacement un trafic imprévisible. Cette architecture s'aligne parfaitement avec les exigences d'être sans serveur et entièrement gérée.",
        "Other Options": [
            "Utiliser une flotte d'instances Amazon EC2 pour l'authentification des utilisateurs, les téléchargements de vidéos et le transcodage introduit une charge de gestion significative et ne fournit pas de mise à l'échelle automatique. Les instances EC2 nécessitent une intervention manuelle pour s'échelonner, ce qui n'est pas idéal pour des modèles de trafic imprévisibles, rendant cette option moins adaptée.",
            "Configurer Amazon S3 pour le stockage vidéo et initier une fonction AWS Lambda par téléchargement de vidéo pour le traitement est une bonne approche, mais enregistrer les détails des travaux de traitement dans une base de données Amazon RDS ajoute une complexité et une charge de gestion inutiles. L'accent devrait être mis sur la minimisation des frais généraux, et l'utilisation d'une base de données à cette fin peut ne pas être nécessaire dans une architecture sans serveur entièrement gérée.",
            "Authentifier les utilisateurs en utilisant des rôles IAM n'est pas adapté pour l'authentification des utilisateurs dans ce contexte, car les rôles IAM sont généralement utilisés pour les autorisations de service AWS plutôt que pour l'authentification des utilisateurs. Stocker des vidéos dans DynamoDB n'est également pas idéal pour de gros fichiers vidéo, car S3 est spécifiquement conçu pour de tels cas d'utilisation. De plus, utiliser des instances EC2 pour les tâches de traitement contredit l'exigence d'une architecture sans serveur."
        ]
    },
    {
        "Question Number": "51",
        "Situation": "Une entreprise utilise Amazon Elastic Block Store (EBS) pour stocker des données attachées à ses instances EC2 dans une seule zone de disponibilité (AZ) dans la région us-east-1. Pour améliorer la durabilité et la résilience des données, l'entreprise souhaite s'assurer que ses données sont en sécurité même en cas de défaillance d'une AZ.",
        "Question": "Quelle stratégie fournirait la meilleure résilience pour leurs données EBS ?",
        "Options": {
            "1": "Utiliser des instantanés EBS stockés dans Amazon S3 et les copier dans une autre région pour permettre la récupération après sinistre inter-régionale.",
            "2": "Attacher des volumes EBS à plusieurs instances EC2 dans différentes AZ au sein de la même région pour la redondance.",
            "3": "Configurer les volumes EBS pour se répliquer automatiquement à travers toutes les zones de disponibilité dans la région.",
            "4": "Utiliser S3 pour le stockage direct des données au lieu d'EBS, car cela offre une durabilité et une disponibilité supérieures à travers les AZ."
        },
        "Correct Answer": "Utiliser des instantanés EBS stockés dans Amazon S3 et les copier dans une autre région pour permettre la récupération après sinistre inter-régionale.",
        "Explanation": "Utiliser des instantanés EBS stockés dans Amazon S3 et les copier dans une autre région fournit la meilleure résilience pour les données EBS car cela garantit que les données sont non seulement sauvegardées mais également stockées dans un autre emplacement géographique. Cela protège contre la perte de données due à une défaillance complète d'une zone de disponibilité, car les instantanés peuvent être restaurés dans une autre région. Cette stratégie tire parti de la durabilité d'Amazon S3 et des capacités inter-régionales pour améliorer les options de récupération après sinistre.",
        "Other Options": [
            "Attacher des volumes EBS à plusieurs instances EC2 dans différentes AZ au sein de la même région ne fournit pas de résilience contre une défaillance d'AZ car les volumes EBS ne peuvent être attachés qu'à une seule instance à la fois. Bien que cela puisse offrir un certain niveau de redondance, cela ne protège pas contre la perte de l'ensemble de l'AZ.",
            "Configurer les volumes EBS pour se répliquer automatiquement à travers toutes les zones de disponibilité dans la région n'est pas une fonctionnalité offerte par EBS. Les volumes EBS sont liés à une AZ spécifique, et bien que vous puissiez créer des instantanés, il n'y a pas de réplication automatique entre les AZ. Ainsi, cette option n'améliore pas la résilience contre les défaillances d'AZ.",
            "Utiliser S3 pour le stockage direct des données au lieu d'EBS offre une durabilité et une disponibilité supérieures à travers les AZ, mais cela peut ne pas convenir à tous les cas d'utilisation, en particulier ceux nécessitant un stockage en bloc. De plus, cela ne répond pas directement au besoin de résilience des données EBS dans le contexte des instances EC2, car cela implique un paradigme de stockage différent."
        ]
    },
    {
        "Question Number": "52",
        "Situation": "Une entreprise de services financiers migre son entrepôt de données sur site vers AWS. L'entrepôt de données traite de grands volumes de données transactionnelles et nécessite un débit élevé pour les opérations ETL. L'entreprise vise à minimiser les coûts tout en garantissant évolutivité et performance.",
        "Question": "Quel service AWS le concepteur de solutions devrait-il recommander pour le stockage de l'entrepôt de données ?",
        "Options": {
            "1": "Amazon RDS for PostgreSQL",
            "2": "Amazon Redshift",
            "3": "Amazon DynamoDB",
            "4": "Amazon Aurora"
        },
        "Correct Answer": "Amazon Redshift",
        "Explanation": "Amazon Redshift est un service d'entrepôt de données entièrement géré, à l'échelle pétaoctet, conçu spécifiquement pour les charges de travail analytiques. Il est optimisé pour un débit élevé et peut gérer efficacement de grands volumes de données transactionnelles, ce qui le rend idéal pour les opérations ETL. Le stockage en colonnes de Redshift et ses capacités de traitement parallèle permettent d'obtenir des performances de requête rapides et une évolutivité, ce qui correspond aux exigences de l'entreprise en matière de performance et de rentabilité lors de la migration de son entrepôt de données vers AWS.",
        "Other Options": [
            "Amazon RDS for PostgreSQL est un service de base de données relationnelle adapté aux charges de travail transactionnelles, mais il n'est pas optimisé pour l'entreposage de données à grande échelle et l'analytique comme Redshift. Il peut ne pas offrir le même niveau de performance et d'évolutivité pour les opérations ETL sur de grands ensembles de données.",
            "Amazon DynamoDB est un service de base de données NoSQL conçu pour une haute disponibilité et un accès à faible latence aux données clé-valeur et document. Bien qu'il soit excellent pour certains types d'applications, il n'est pas adapté aux besoins traditionnels d'entreposage de données, en particulier pour des requêtes complexes et des analyses sur de grands ensembles de données.",
            "Amazon Aurora est un service de base de données relationnelle qui offre une haute performance et disponibilité. Cependant, comme RDS, il n'est pas spécifiquement conçu pour l'entreposage de données et peut ne pas fournir le même niveau de performance pour les requêtes analytiques et les opérations ETL que Amazon Redshift."
        ]
    },
    {
        "Question Number": "53",
        "Situation": "Une entreprise de production médiatique nécessite un stockage haute performance pour le montage vidéo mais souhaite garder les coûts bas. Elle a un mélange de charges de travail haute performance et basse performance et doit choisir des types de stockage en bloc appropriés.",
        "Question": "Quelle combinaison d'options de stockage en bloc l'entreprise devrait-elle utiliser pour optimiser les coûts tout en répondant aux exigences de performance ?",
        "Options": {
            "1": "Provisioned IOPS SSD (io2) pour tous les volumes",
            "2": "General Purpose SSD (gp3) pour les tâches haute performance et Throughput Optimized HDD (st1) pour les tâches de moindre performance",
            "3": "Cold HDD (sc1) pour tous les volumes",
            "4": "Utiliser Amazon S3 au lieu du stockage en bloc pour toutes les données"
        },
        "Correct Answer": "General Purpose SSD (gp3) pour les tâches haute performance et Throughput Optimized HDD (st1) pour les tâches de moindre performance",
        "Explanation": "Cette combinaison permet à l'entreprise de production médiatique d'équilibrer performance et coût de manière efficace. General Purpose SSD (gp3) offre un bon équilibre entre prix et performance pour les charges de travail haute performance, comme le montage vidéo, où la faible latence et le haut débit sont essentiels. D'autre part, Throughput Optimized HDD (st1) est plus rentable pour les tâches de moindre performance, comme le stockage de fichiers vidéo moins fréquemment accédés ou de sauvegardes. Cette approche hybride optimise les coûts tout en répondant aux exigences de performance pour les deux types de charges de travail.",
        "Other Options": [
            "Provisioned IOPS SSD (io2) pour tous les volumes serait inutilement coûteux pour les tâches de moindre performance, car il est conçu pour des charges de travail à haut IOPS et ne fournirait pas d'efficacité de coût pour des tâches qui ne nécessitent pas une telle performance.",
            "Cold HDD (sc1) pour tous les volumes ne répondrait pas aux exigences de performance pour des tâches haute performance comme le montage vidéo, car sc1 est conçu pour un accès peu fréquent et a des performances beaucoup plus faibles par rapport aux options SSD.",
            "Utiliser Amazon S3 au lieu du stockage en bloc pour toutes les données peut ne pas être adapté aux charges de travail de montage vidéo qui nécessitent une faible latence et un haut débit, car S3 est un stockage d'objets et n'est pas optimisé pour l'accès au niveau bloc nécessaire pour des applications haute performance."
        ]
    },
    {
        "Question Number": "54",
        "Situation": "Une entreprise souhaite mettre en place un accès sécurisé pour une équipe de développeurs travaillant sur un projet dans un compte AWS partagé. L'équipe nécessite un accès flexible à des ressources AWS spécifiques au sein du compte, et l'accès doit pouvoir être révoqué au niveau de chaque utilisateur.",
        "Question": "Quelle est l'approche la PLUS sécurisée et flexible pour accorder l'accès à ces ressources ?",
        "Options": {
            "1": "Créer des utilisateurs IAM pour chaque développeur avec des autorisations et des politiques spécifiques",
            "2": "Créer un seul utilisateur IAM avec des clés d'accès partagées entre les développeurs",
            "3": "Utiliser AWS IAM Identity Center (AWS Single Sign-On) pour attribuer des rôles à chaque développeur",
            "4": "Attribuer un rôle IAM aux ressources partagées et accorder des autorisations à un groupe IAM contenant les développeurs"
        },
        "Correct Answer": "Utiliser AWS IAM Identity Center (AWS Single Sign-On) pour attribuer des rôles à chaque développeur",
        "Explanation": "Utiliser AWS IAM Identity Center (AWS Single Sign-On) permet une gestion centralisée de l'accès des utilisateurs à travers les comptes et applications AWS. Cela offre une manière flexible et sécurisée d'attribuer des rôles à des développeurs individuels, leur permettant d'accéder uniquement aux ressources dont ils ont besoin. Cette approche permet également de révoquer facilement l'accès au niveau de chaque utilisateur, ce qui est essentiel pour maintenir la sécurité dans un environnement partagé. De plus, IAM Identity Center prend en charge l'intégration avec des fournisseurs d'identité existants, renforçant ainsi la sécurité et la gestion des utilisateurs.",
        "Other Options": [
            "Créer des utilisateurs IAM pour chaque développeur avec des autorisations et des politiques spécifiques est une approche valide, mais elle peut devenir lourde à gérer à mesure que l'équipe grandit. Chaque utilisateur devrait être géré individuellement, et révoquer l'accès nécessiterait de modifier les autorisations de chaque utilisateur, ce qui est moins efficace que d'utiliser IAM Identity Center.",
            "Créer un seul utilisateur IAM avec des clés d'accès partagées entre les développeurs est très peu sécurisé. Cette approche viole le principe du moindre privilège et rend difficile le suivi des actions individuelles des utilisateurs. Si les clés d'accès sont compromises, l'accès de tous les développeurs est en danger, et révoquer l'accès pour un utilisateur nécessiterait de changer les clés pour tout le monde.",
            "Attribuer un rôle IAM aux ressources partagées et accorder des autorisations à un groupe IAM contenant les développeurs est une approche raisonnable, mais elle manque de la flexibilité et de la facilité de gestion offertes par AWS IAM Identity Center. Bien qu'elle permette un certain niveau de contrôle d'accès, elle ne fournit pas le même niveau de gestion individuelle des utilisateurs et de capacités de révocation que IAM Identity Center."
        ]
    },
    {
        "Question Number": "55",
        "Situation": "Une entreprise de commerce électronique multinationale a des utilisateurs dans le monde entier qui ont besoin d'un accès rapide à leurs informations de commande. L'application nécessite une réplication de données multi-régions pour garantir une haute disponibilité et une faible latence pour les utilisateurs sur différents continents. De plus, le système doit gérer les conflits potentiels de manière élégante lorsque des mises à jour se produisent simultanément dans différentes régions.",
        "Question": "Quelle fonctionnalité de DynamoDB Global Tables répond le mieux à ces exigences ?",
        "Options": {
            "1": "Réplication multi-maître avec résolution de conflit \"dernier écrivain gagne\"",
            "2": "Réplication à maître unique pour garantir la cohérence des données",
            "3": "Cohérence forte globale pour toutes les lectures et écritures à travers les régions",
            "4": "Résolution de conflit FIFO (Premier arrivé, premier servi) stricte à travers les régions"
        },
        "Correct Answer": "Réplication multi-maître avec résolution de conflit 'dernier écrivain gagne'",
        "Explanation": "DynamoDB Global Tables utilise la réplication multi-maître, ce qui permet des mises à jour dans plusieurs régions simultanément. Cela est crucial pour une entreprise de commerce électronique multinationale qui doit fournir un accès rapide aux informations de commande à travers différents continents. La stratégie de résolution de conflit 'dernier écrivain gagne' garantit que lorsque des mises à jour se produisent dans différentes régions en même temps, la mise à jour la plus récente (basée sur un horodatage) est celle qui est conservée, permettant une gestion élégante des conflits potentiels. Cette fonctionnalité soutient une haute disponibilité et une faible latence, répondant efficacement aux exigences de l'application.",
        "Other Options": [
            "La réplication à maître unique ne répondrait pas à l'exigence de haute disponibilité et de faible latence à travers plusieurs régions, car elle limite les mises à jour à une seule région, ce qui pourrait entraîner des retards pour les utilisateurs dans d'autres régions.",
            "La cohérence forte globale pour toutes les lectures et écritures à travers les régions n'est pas prise en charge dans DynamoDB Global Tables, car cela nécessiterait une coordination qui pourrait introduire de la latence et réduire la disponibilité, ce qui contredit le besoin d'accès rapide et de faible latence.",
            "La résolution de conflit FIFO (Premier arrivé, premier servi) stricte n'est pas une fonctionnalité de DynamoDB Global Tables. Cette approche ne serait pas adaptée à une configuration multi-régions où des mises à jour peuvent se produire simultanément, car cela pourrait entraîner des retards et des incohérences dans la disponibilité des données."
        ]
    },
    {
        "Question Number": "56",
        "Situation": "Une entreprise met en place un nouvel environnement AWS et a besoin d'un réseau privé et isolé dans une région AWS spécifique. Elle souhaite contrôler la plage d'adresses IP pour ce réseau et disposer de plusieurs sous-réseaux, chacun dans une zone de disponibilité (AZ) différente pour garantir une haute disponibilité. L'entreprise souhaite également savoir si elle peut avoir plusieurs VPC dans la même région et quels paramètres par défaut sont appliqués si elle utilise le VPC par défaut.",
        "Question": "Quelle approche l'entreprise devrait-elle adopter pour configurer son réseau selon ces exigences ?",
        "Options": {
            "1": "Créer un VPC par défaut, qui fournit automatiquement des sous-réseaux dans chaque zone de disponibilité de la région. Le VPC par défaut a une plage CIDR fixe de 172.31.0.0/16, et des VPC personnalisés supplémentaires ne peuvent pas être créés dans la même région.",
            "2": "Créer un VPC personnalisé, ce qui permet à l'entreprise de spécifier sa propre plage CIDR et de créer plusieurs sous-réseaux dans chaque zone de disponibilité. Le VPC par défaut sera également disponible par défaut, et ils peuvent le supprimer ou le recréer si nécessaire.",
            "3": "Utiliser le VPC par défaut fourni par AWS, qui permet des plages CIDR personnalisées et offre un contrôle total sur les attributions d'adresses IP des sous-réseaux. Le VPC par défaut permet uniquement un sous-réseau par zone de disponibilité.",
            "4": "Mettre en place un seul VPC à travers plusieurs régions, car les VPC sont globaux par défaut. Cette configuration permet à l'entreprise d'avoir plusieurs zones de disponibilité dans un seul VPC à travers différentes régions, offrant redondance et haute disponibilité."
        },
        "Correct Answer": "Créer un VPC personnalisé, ce qui permet à l'entreprise de spécifier sa propre plage CIDR et de créer plusieurs sous-réseaux dans chaque zone de disponibilité. Le VPC par défaut sera également disponible par défaut, et ils peuvent le supprimer ou le recréer si nécessaire.",
        "Explanation": "Créer un VPC personnalisé permet à l'entreprise de définir sa propre plage d'adresses IP (bloc CIDR) et de créer plusieurs sous-réseaux dans différentes zones de disponibilité (AZ) pour garantir une haute disponibilité. Cette configuration répond à leur exigence d'un réseau privé et isolé avec contrôle sur la plage d'adresses IP. De plus, AWS permet de créer plusieurs VPC dans la même région, et le VPC par défaut est disponible par défaut, ce qui peut être supprimé ou recréé si nécessaire.",
        "Other Options": [
            "Créer un VPC par défaut ne permet pas à l'entreprise de spécifier sa propre plage CIDR, car il a une plage CIDR fixe de 172.31.0.0/16. De plus, plusieurs VPC personnalisés peuvent effectivement être créés dans la même région, donc cette option est incorrecte.",
            "Le VPC par défaut ne permet pas de plages CIDR personnalisées ; il a une plage CIDR fixe. De plus, bien que le VPC par défaut fournisse des sous-réseaux dans chaque AZ, il ne permet pas un contrôle total sur les attributions d'adresses IP des sous-réseaux comme le ferait un VPC personnalisé. Cette option est donc incorrecte.",
            "Les VPC ne sont pas globaux ; ils sont régionaux. Chaque VPC est confiné à une seule région, et bien qu'un VPC puisse s'étendre sur plusieurs AZ dans cette région, il ne peut pas s'étendre sur plusieurs régions. Cette option est incorrecte car elle déforme le fonctionnement des VPC dans AWS."
        ]
    },
    {
        "Question Number": "57",
        "Situation": "Vous mettez en place un système de distribution de contenu avec Amazon CloudFront pour servir du contenu sécurisé à partir d'un bucket S3 et d'un Application Load Balancer (ALB). Pour garantir une communication chiffrée, vous décidez de configurer des certificats SSL.",
        "Question": "En tenant compte des exigences SSL, laquelle des options suivantes est cruciale pour activer des connexions HTTPS sécurisées entre le visualiseur et votre distribution CloudFront ?",
        "Options": {
            "1": "Générer ou importer un certificat public valide dans ACM (Amazon Certificate Manager) dans la région us-east-1, en veillant à ce qu'il corresponde au nom DNS de votre domaine.",
            "2": "Utiliser des certificats auto-signés sur les origines (S3 et ALB) pour économiser des coûts, car CloudFront gérera la terminaison SSL.",
            "3": "Attribuer une IP dédiée pour le support SSL à chaque emplacement Edge de CloudFront, car cela est obligatoire pour que les navigateurs modernes établissent des connexions HTTPS.",
            "4": "Activer SSL uniquement sur la distribution CloudFront et non sur les serveurs d'origine, car CloudFront chiffre automatiquement tout le trafic avec les visualiseurs."
        },
        "Correct Answer": "Générer ou importer un certificat public valide dans ACM (Amazon Certificate Manager) dans la région us-east-1, en veillant à ce qu'il corresponde au nom DNS de votre domaine.",
        "Explanation": "Pour activer des connexions HTTPS sécurisées entre le visualiseur et votre distribution CloudFront, il est crucial d'avoir un certificat SSL valide. Amazon Certificate Manager (ACM) vous permet de générer ou d'importer des certificats SSL nécessaires à l'établissement de connexions sécurisées. Le certificat doit être dans la région us-east-1 car CloudFront exige que le certificat SSL soit émis depuis cette région pour être utilisé avec les distributions. De plus, le certificat doit correspondre au nom de domaine utilisé dans la distribution CloudFront pour garantir une validation correcte lors de la poignée de main SSL.",
        "Other Options": [
            "Utiliser des certificats auto-signés sur les origines (S3 et ALB) n'est pas recommandé pour les environnements de production car ils ne sont pas approuvés par les clients et peuvent entraîner des avertissements de sécurité. CloudFront ne gère pas la terminaison SSL pour les certificats auto-signés, et les clients ne pourront pas établir de connexions sécurisées sans un certificat de confiance.",
            "Attribuer une IP dédiée pour le support SSL à chaque emplacement Edge de CloudFront n'est pas nécessaire. CloudFront utilise une infrastructure partagée pour la terminaison SSL, et les navigateurs modernes ne nécessitent pas d'IP dédiées pour les connexions HTTPS. Au lieu de cela, ils s'appuient sur les certificats SSL pour établir des connexions sécurisées.",
            "Activer SSL uniquement sur la distribution CloudFront et non sur les serveurs d'origine n'est pas conseillé. Bien que CloudFront puisse chiffrer le trafic entre lui et les visualiseurs, il est essentiel de sécuriser également la connexion entre CloudFront et les serveurs d'origine (S3 et ALB) pour garantir un chiffrement de bout en bout. Cela empêche d'éventuelles vulnérabilités lors du transfert de données de CloudFront vers l'origine."
        ]
    },
    {
        "Question Number": "58",
        "Situation": "Une entreprise de machine learning exécute des simulations de calcul haute performance (HPC) qui nécessitent une latence réseau extrêmement faible et une performance élevée en paquets par seconde (PPS) entre les instances. Les simulations sont intensives en calcul et nécessitent que les instances communiquent directement entre elles avec un délai minimal.",
        "Question": "Quelle configuration de groupe de placement EC2 le concepteur de solutions devrait-il choisir pour répondre à ces exigences ?",
        "Options": {
            "1": "Groupe de placement étalé sur plusieurs zones de disponibilité",
            "2": "Groupe de placement en cluster au sein d'une seule zone de disponibilité",
            "3": "Groupe de placement par partition sur plusieurs racks",
            "4": "Hôte dédié"
        },
        "Correct Answer": "Groupe de placement en cluster au sein d'une seule zone de disponibilité",
        "Explanation": "Un groupe de placement en cluster est conçu pour fournir une faible latence et un haut débit entre les instances en les plaçant physiquement proches les unes des autres dans la même zone de disponibilité. Cette configuration est idéale pour les applications intensives en calcul qui nécessitent une communication rapide entre les instances, car elle minimise la latence réseau et maximise la performance en paquets par seconde. Étant donné que les simulations sont intensives en calcul et nécessitent une communication directe avec un délai minimal, le groupe de placement en cluster est le meilleur choix.",
        "Other Options": [
            "Le groupe de placement étalé sur plusieurs zones de disponibilité est conçu pour répartir les instances sur différents matériels physiques afin de réduire le risque de défaillance simultanée. Bien qu'il offre une haute disponibilité, il ne fournit pas la faible latence et la haute performance en PPS requises pour les simulations intensives en calcul, car les instances ne sont pas situées à proximité les unes des autres.",
            "Le groupe de placement par partition sur plusieurs racks est utile pour les applications qui nécessitent une haute disponibilité et une tolérance aux pannes, car il répartit les instances sur différents racks. Cependant, il ne garantit pas la faible latence et le haut débit nécessaires pour une communication directe entre les instances, ce qui le rend moins adapté au scénario donné.",
            "L'hôte dédié est un serveur physique dédié à votre utilisation, ce qui permet un meilleur contrôle sur le placement des instances et la gestion des licences. Cependant, il ne fournit pas intrinsèquement la faible latence et la haute performance en paquets par seconde qui sont critiques pour les simulations HPC décrites, car il se concentre davantage sur la conformité et le contrôle plutôt que sur la performance réseau."
        ]
    },
    {
        "Question Number": "59",
        "Situation": "Une organisation de santé doit établir une connexion sécurisée et fiable entre son centre de données sur site et son environnement AWS pour se conformer aux exigences réglementaires. La connexion doit prendre en charge une bande passante élevée et fournir une faible latence pour le traitement des données en temps réel.",
        "Question": "Quelle option de connexion réseau le concepteur de solutions devrait-il recommander ?",
        "Options": {
            "1": "AWS Site-to-Site VPN avec routage dynamique",
            "2": "AWS Direct Connect avec une connexion dédiée",
            "3": "AWS Transit Gateway avec peering VPC",
            "4": "AWS PrivateLink pour accéder aux services AWS de manière privée"
        },
        "Correct Answer": "AWS Direct Connect avec une connexion dédiée",
        "Explanation": "AWS Direct Connect fournit une connexion dédiée, à haute bande passante et à faible latence entre un centre de données sur site et AWS. Cette option est idéale pour les organisations qui nécessitent une connexion sécurisée et fiable pour répondre à la conformité réglementaire, en particulier pour le traitement des données en temps réel. Direct Connect contourne Internet public, réduisant la latence et améliorant la performance, ce qui le rend adapté aux applications à fort débit.",
        "Other Options": [
            "AWS Site-to-Site VPN avec routage dynamique utilise Internet public pour établir une connexion sécurisée, ce qui peut introduire de la variabilité dans la latence et la bande passante. Bien que ce soit une option sécurisée, elle peut ne pas répondre aux exigences de bande passante élevée et de faible latence nécessaires pour le traitement des données en temps réel.",
            "AWS Transit Gateway avec peering VPC est principalement utilisé pour connecter plusieurs VPC et réseaux sur site. Bien qu'il puisse faciliter la communication entre divers réseaux, il ne fournit pas de connexion dédiée et peut ne pas répondre aux exigences de bande passante élevée et de faible latence aussi efficacement que Direct Connect.",
            "AWS PrivateLink est conçu pour accéder aux services AWS de manière privée sans exposer le trafic à Internet public. Cependant, il n'établit pas de connexion directe entre un centre de données sur site et AWS, ce qui le rend inadapté à l'exigence spécifique d'une connexion sécurisée et fiable pour une bande passante élevée et une faible latence."
        ]
    },
    {
        "Question Number": "60",
        "Situation": "Une entreprise de services financiers souhaite suivre les coûts à travers différents départements en utilisant un seul compte AWS. Ils ont besoin d'une méthode pour catégoriser les ressources par département et générer des rapports de coûts détaillés.",
        "Question": "Quelle fonctionnalité de gestion des coûts AWS les aiderait le mieux à atteindre cet objectif ?",
        "Options": {
            "1": "Activer la facturation multi-comptes",
            "2": "Utiliser des balises d'allocation des coûts",
            "3": "Configurer des budgets AWS pour chaque département",
            "4": "Activer S3 Requester Pays pour le stockage spécifique aux départements"
        },
        "Correct Answer": "Utiliser des balises d'allocation des coûts",
        "Explanation": "Les balises d'allocation des coûts vous permettent de catégoriser les ressources AWS par département ou tout autre critère de votre choix. En appliquant ces balises aux ressources, l'entreprise de services financiers peut suivre les coûts associés à chaque département et générer des rapports de coûts détaillés basés sur ces balises. Cette fonctionnalité est spécifiquement conçue pour le suivi et le reporting des coûts, ce qui en fait la meilleure option pour leurs besoins.",
        "Other Options": [
            "Activer la facturation multi-comptes n'est pas adapté car cela implique d'utiliser plusieurs comptes AWS pour séparer les coûts, ce qui n'est pas ce que l'entreprise souhaite, car elle cherche à suivre les coûts au sein d'un seul compte AWS.",
            "Configurer des budgets AWS pour chaque département est utile pour surveiller les dépenses et définir des alertes, mais cela ne fournit pas la catégorisation des ressources nécessaire pour des rapports de coûts détaillés. Les budgets concernent davantage le suivi et le contrôle des coûts plutôt que leur catégorisation.",
            "Activer S3 Requester Pays pour le stockage spécifique aux départements n'est pas pertinent dans ce contexte. Cette fonctionnalité permet aux utilisateurs de facturer le demandeur d'accès aux données S3, mais elle n'aide pas à catégoriser les coûts entre les départements ou à générer des rapports de coûts détaillés."
        ]
    },
    {
        "Question Number": "61",
        "Situation": "Une entreprise de commerce électronique gère plusieurs comptes AWS à travers différentes unités commerciales, telles que le marketing, les ventes et le développement, et souhaite suivre et surveiller avec précision les coûts AWS par département. Elle a besoin d'une méthode pour allouer les ressources partagées comme les bases de données et les ressources de calcul au budget de chaque département et garantir un suivi transparent des coûts pour chaque unité commerciale.",
        "Question": "Quelle fonctionnalité de gestion des coûts AWS devraient-ils utiliser pour répondre à ces exigences ?",
        "Options": {
            "1": "Utiliser la facturation consolidée pour tous les comptes et appliquer des balises d'allocation des coûts pour attribuer les coûts à des départements spécifiques",
            "2": "Créer un seul compte AWS pour tous les départements et utiliser des pratiques de facturation internes pour allouer les coûts",
            "3": "Activer S3 Requester Pays pour les ressources de chaque département afin de transférer les coûts aux utilisateurs individuels au sein de chaque département",
            "4": "Mettre en place des alertes de facturation séparées pour chaque département afin de suivre les coûts de manière indépendante"
        },
        "Correct Answer": "Utiliser la facturation consolidée pour tous les comptes et appliquer des balises d'allocation des coûts pour attribuer les coûts à des départements spécifiques",
        "Explanation": "L'utilisation de la facturation consolidée permet à l'entreprise de commerce électronique de gérer plusieurs comptes AWS sous un seul compte de facturation, ce qui simplifie le processus de paiement. En appliquant des balises d'allocation des coûts, elle peut catégoriser et suivre les coûts associés à des ressources spécifiques utilisées par chaque département. Cette méthode offre une transparence dans l'allocation des coûts et permet un suivi précis du budget pour chaque unité commerciale, répondant ainsi à l'exigence de surveiller efficacement les coûts AWS.",
        "Other Options": [
            "Créer un seul compte AWS pour tous les départements compliquerait le suivi des coûts, car toutes les ressources seraient agrégées sous un seul compte. Cette approche manque de la granularité nécessaire pour allouer les coûts avec précision aux départements individuels, rendant difficile la gestion efficace des budgets.",
            "Activer S3 Requester Pays n'est pas adapté pour suivre les coûts entre les départements car cela ne s'applique qu'aux ressources Amazon S3. Cette fonctionnalité permet au demandeur des données de payer les coûts de transfert de données, mais ne fournit pas de solution complète pour suivre et allouer les coûts à travers divers services et départements AWS.",
            "Mettre en place des alertes de facturation séparées pour chaque département peut aider à surveiller les coûts, mais cela ne fournit pas de méthode pour allouer les ressources partagées ou suivre avec précision les coûts par rapport aux budgets départementaux. Les alertes sont réactives plutôt que proactives et ne facilitent pas la gestion ou l'allocation détaillées des coûts."
        ]
    },
    {
        "Question Number": "62",
        "Situation": "Une entreprise financière souhaite chiffrer les données en transit entre son environnement sur site et AWS. Les données doivent être chiffrées à l'aide d'un certificat TLS.",
        "Question": "Quel service AWS l'entreprise devrait-elle utiliser pour gérer et déployer le certificat TLS ?",
        "Options": {
            "1": "AWS Key Management Service (AWS KMS)",
            "2": "AWS Secrets Manager",
            "3": "AWS Certificate Manager (ACM)",
            "4": "Amazon S3"
        },
        "Correct Answer": "AWS Certificate Manager (ACM)",
        "Explanation": "AWS Certificate Manager (ACM) est spécifiquement conçu pour gérer et déployer des certificats TLS/SSL pour une utilisation avec les services et applications AWS. Il simplifie le processus de provisionnement, de gestion et de déploiement des certificats, permettant à l'entreprise financière de chiffrer facilement les données en transit entre son environnement sur site et AWS. ACM gère également le renouvellement des certificats automatiquement, garantissant que le chiffrement reste valide sans intervention manuelle.",
        "Other Options": [
            "AWS Key Management Service (AWS KMS) est principalement utilisé pour gérer les clés cryptographiques pour vos applications et services. Bien qu'il joue un rôle crucial dans les processus de chiffrement et de déchiffrement, il ne gère pas directement les certificats TLS.",
            "AWS Secrets Manager est utilisé pour gérer des secrets tels que les identifiants de base de données, les clés API et d'autres informations sensibles. Il ne fournit pas de fonctionnalité pour gérer les certificats TLS, ce qui le rend inadapté à cette exigence spécifique.",
            "Amazon S3 est un service de stockage qui vous permet de stocker et de récupérer n'importe quelle quantité de données à tout moment. Il n'a pas de capacités pour gérer ou déployer des certificats TLS, et n'est donc pas pertinent pour la tâche de chiffrer les données en transit."
        ]
    },
    {
        "Question Number": "63",
        "Situation": "Une entreprise développe une application web sur AWS qui nécessite une authentification sécurisée des utilisateurs et une protection contre les menaces externes, telles que les attaques DDoS et les injections SQL. L'application doit également garantir que les identifiants des utilisateurs sont gérés de manière sécurisée et que les utilisateurs ont un accès limité en fonction de leurs rôles.",
        "Question": "Quelle combinaison de services AWS l'entreprise devrait-elle utiliser pour répondre à ces exigences de sécurité ?",
        "Options": {
            "1": "Utiliser AWS Shield pour la protection DDoS, Amazon Cognito pour l'authentification des utilisateurs, et AWS WAF pour bloquer les attaques par injection SQL.",
            "2": "Utiliser Amazon GuardDuty pour la protection DDoS, des rôles IAM pour l'authentification des utilisateurs, et AWS CloudFront pour la protection contre les injections SQL.",
            "3": "Utiliser AWS Identity Center (AWS SSO) pour l'authentification des utilisateurs, AWS WAF pour la protection DDoS, et Amazon Macie pour la prévention des injections SQL.",
            "4": "Utiliser AWS Secrets Manager pour l'authentification des utilisateurs, AWS Shield pour la protection DDoS, et AWS Lambda pour la protection contre les injections SQL."
        },
        "Correct Answer": "Utiliser AWS Shield pour la protection DDoS, Amazon Cognito pour l'authentification des utilisateurs, et AWS WAF pour bloquer les attaques par injection SQL.",
        "Explanation": "Cette combinaison de services répond efficacement à toutes les exigences de sécurité décrites dans le scénario. AWS Shield fournit une protection DDoS robuste, essentielle pour protéger l'application web contre les menaces externes. Amazon Cognito est spécifiquement conçu pour l'authentification des utilisateurs, permettant une gestion sécurisée des identifiants des utilisateurs et un contrôle d'accès basé sur les rôles. AWS WAF (Web Application Firewall) est spécifiquement adapté pour protéger les applications web contre les exploits courants, y compris les attaques par injection SQL, en permettant de créer des règles qui bloquent de telles requêtes malveillantes.",
        "Other Options": [
            "Utiliser Amazon GuardDuty pour la protection DDoS est incorrect car GuardDuty est principalement un service de détection des menaces qui surveille les activités malveillantes et les comportements non autorisés, plutôt que de fournir une protection DDoS directe. Les rôles IAM ne sont pas un service d'authentification des utilisateurs ; ils sont utilisés pour accorder des permissions aux ressources AWS. AWS CloudFront est un réseau de distribution de contenu et ne fournit pas de protection directe contre les injections SQL.",
            "AWS Identity Center (AWS SSO) est un service pour le single sign-on et l'authentification des utilisateurs, mais AWS WAF n'est pas conçu pour la protection DDoS ; il est destiné à la sécurité des applications web. Amazon Macie est un service de sécurité des données et de protection de la vie privée qui aide à découvrir et protéger les données sensibles, mais ne prévient pas les attaques par injection SQL.",
            "AWS Secrets Manager est utilisé pour gérer des secrets tels que les clés API et les identifiants de base de données, mais ce n'est pas un service d'authentification. AWS Shield est approprié pour la protection DDoS, mais AWS Lambda ne fournit pas intrinsèquement de protection contre les injections SQL ; c'est un service de calcul qui peut exécuter du code en réponse à des événements et ne traite pas directement de la sécurité des applications web."
        ]
    },
    {
        "Question Number": "64",
        "Situation": "Une entreprise configure un Virtual Private Cloud (VPC) et doit concevoir plusieurs sous-réseaux pour une application qui sera déployée dans plusieurs Availability Zones (AZs). Elle souhaite s'assurer que les adresses IP au sein de chaque sous-réseau sont correctement attribuées et réservées pour des fonctions spécifiques au sein du réseau.",
        "Question": "Laquelle des affirmations suivantes décrit le mieux les règles pour la configuration des sous-réseaux VPC et la gestion des adresses IP réservées ?",
        "Options": {
            "1": "Un seul sous-réseau peut s'étendre sur plusieurs zones de disponibilité pour maximiser l'utilisation des adresses IP au sein du bloc CIDR du VPC.",
            "2": "Chaque sous-réseau a une plage d'adresses IP, avec cinq adresses IP spécifiques dans chaque sous-réseau automatiquement réservées par AWS pour des fonctions réseau, y compris les adresses pour DNS et le routage VPC.",
            "3": "Les blocs CIDR IPv4 attribués aux sous-réseaux peuvent se chevaucher pour optimiser l'utilisation de l'espace, en particulier lorsque les sous-réseaux se trouvent dans différentes AZs.",
            "4": "Les ensembles d'options DHCP dans AWS permettent d'éditer et de supprimer les adresses IP automatiquement attribuées au sein de chaque sous-réseau."
        },
        "Correct Answer": "Chaque sous-réseau a une plage d'adresses IP, avec cinq adresses IP spécifiques dans chaque sous-réseau automatiquement réservées par AWS pour des fonctions réseau, y compris les adresses pour DNS et le routage VPC.",
        "Explanation": "Dans AWS, chaque sous-réseau se voit attribuer une plage d'adresses IP à partir du bloc CIDR du VPC, et AWS réserve automatiquement cinq adresses IP dans chaque sous-réseau pour des fonctions réseau spécifiques. Ces adresses réservées sont utilisées pour le routeur VPC, DNS et d'autres services essentiels, garantissant qu'elles ne sont pas disponibles pour l'attribution aux instances. Cette règle est cruciale pour maintenir la fonctionnalité du VPC et de ses sous-réseaux.",
        "Other Options": [
            "Un seul sous-réseau ne peut pas s'étendre sur plusieurs zones de disponibilité ; chaque sous-réseau doit résider entièrement dans une seule zone de disponibilité. Cette conception garantit que les ressources dans différentes AZs sont isolées et peuvent fournir une haute disponibilité et une tolérance aux pannes.",
            "Les blocs CIDR IPv4 attribués aux sous-réseaux ne peuvent pas se chevaucher. Chaque sous-réseau doit avoir une plage unique d'adresses IP pour éviter les conflits et garantir un routage correct au sein du VPC. Des blocs CIDR qui se chevauchent entraîneraient des problèmes de routage et de connectivité.",
            "Les ensembles d'options DHCP dans AWS ne permettent pas d'éditer ou de supprimer les adresses IP automatiquement attribuées au sein de chaque sous-réseau. Les ensembles d'options DHCP sont utilisés pour configurer les paramètres DHCP pour les instances, tels que les serveurs de noms de domaine et les serveurs NTP, mais ils n'affectent pas les adresses IP réservées au sein du sous-réseau."
        ]
    },
    {
        "Question Number": "65",
        "Situation": "Une entreprise déploie une application web mondiale et souhaite garantir une haute disponibilité et un accès à faible latence pour les utilisateurs du monde entier. L'entreprise utilise Amazon Route 53 pour la gestion DNS et envisage de déployer l'application dans plusieurs Availability Zones (AZs) au sein de plusieurs régions AWS pour garantir la tolérance aux pannes.",
        "Question": "Laquelle des approches suivantes répondrait le mieux aux exigences de l'entreprise en matière de haute disponibilité et de récupération après sinistre ?",
        "Options": {
            "1": "Utiliser Route 53 avec le routage par géolocalisation pour diriger les utilisateurs vers la région la plus proche, et déployer l'application dans plusieurs Availability Zones à travers ces régions pour garantir une haute disponibilité.",
            "2": "Utiliser Route 53 avec une politique de routage de basculement pour s'assurer que le trafic est dirigé vers une région de secours en cas de défaillance de la région principale.",
            "3": "Déployer l'application dans une seule Availability Zone dans une région pour simplifier la gestion et réduire la complexité opérationnelle.",
            "4": "Utiliser Route 53 avec un routage pondéré pour diriger le trafic de manière égale vers toutes les régions, indépendamment de la disponibilité ou de la latence, pour une distribution de trafic plus équilibrée."
        },
        "Correct Answer": "Utiliser Route 53 avec le routage par géolocalisation pour diriger les utilisateurs vers la région la plus proche, et déployer l'application dans plusieurs Availability Zones à travers ces régions pour garantir une haute disponibilité.",
        "Explanation": "L'utilisation de Route 53 avec le routage par géolocalisation permet à l'entreprise de diriger les utilisateurs vers la région AWS la plus proche, ce qui minimise la latence et améliore l'expérience utilisateur. En déployant l'application dans plusieurs Availability Zones (AZs) au sein de ces régions, l'entreprise peut garantir une haute disponibilité, car le trafic peut être automatiquement dirigé vers des instances saines dans différentes AZs en cas de défaillance. Cette approche offre également des capacités de tolérance aux pannes et de récupération après sinistre, car elle tire parti de la redondance de plusieurs AZs et régions.",
        "Other Options": [
            "Utiliser Route 53 avec une politique de routage de basculement est bénéfique pour la récupération après sinistre, mais cela se concentre principalement sur le routage du trafic vers une région de secours uniquement lorsque la région principale échoue. Cela ne répond pas au besoin d'accès à faible latence pour les utilisateurs du monde entier, car cela peut ne pas diriger les utilisateurs vers la région la plus proche pour des performances optimales.",
            "Déployer l'application dans une seule Availability Zone dans une région augmente considérablement le risque de temps d'arrêt et ne fournit pas de haute disponibilité ni de tolérance aux pannes. Si cette unique AZ subit une panne, l'ensemble de l'application serait indisponible, ce qui contredit les exigences de l'entreprise en matière de haute disponibilité.",
            "Utiliser Route 53 avec un routage pondéré pour diriger le trafic de manière égale vers toutes les régions ignore la disponibilité et la latence de ces régions. Cela pourrait entraîner des performances sous-optimales pour les utilisateurs, car le trafic peut être envoyé vers une région plus éloignée ou rencontrant des problèmes, échouant ainsi à répondre aux objectifs de l'entreprise en matière d'accès à faible latence et de haute disponibilité."
        ]
    }
]