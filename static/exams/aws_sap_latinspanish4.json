[
    {
        "Question Number": "1",
        "Situation": "Una empresa global de comercio electrónico está experimentando problemas de latencia al atender a usuarios en diferentes regiones geográficas. Para mejorar la experiencia del usuario, la empresa desea implementar una solución DNS que dirija a los usuarios al punto final de aplicación más cercano, considerando también los patrones de tráfico. La arquitectura debe ser diseñada para manejar el tráfico de usuarios de manera eficiente y asegurar la máxima disponibilidad. (Seleccione Dos)",
        "Question": "¿Cuál de las siguientes opciones debería implementar el arquitecto de soluciones para optimizar el enrutamiento DNS para la aplicación de comercio electrónico?",
        "Options": {
            "1": "Crear una política de enrutamiento simple en Amazon Route 53 que apunte a todos los usuarios a un solo punto final de aplicación, sin importar su ubicación.",
            "2": "Implementar enrutamiento basado en latencia en Amazon Route 53 para dirigir a los usuarios a los puntos finales de aplicación con menor latencia según su ubicación geográfica.",
            "3": "Desplegar una política de enrutamiento de conmutación por error en Amazon Route 53 que dirija el tráfico a un punto final de aplicación de respaldo solo cuando el punto final primario no esté disponible.",
            "4": "Utilizar enrutamiento por geolocalización en Amazon Route 53 para dirigir a los usuarios según sus ubicaciones geográficas, asegurando que lleguen al punto final regional más cercano.",
            "5": "Configurar enrutamiento ponderado en Amazon Route 53 para distribuir el tráfico entre múltiples puntos finales de aplicación según pesos predefinidos."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Implementar enrutamiento basado en latencia en Amazon Route 53 para dirigir a los usuarios a los puntos finales de aplicación con menor latencia según su ubicación geográfica.",
            "Utilizar enrutamiento por geolocalización en Amazon Route 53 para dirigir a los usuarios según sus ubicaciones geográficas, asegurando que lleguen al punto final regional más cercano."
        ],
        "Explanation": "El enrutamiento basado en latencia y el enrutamiento por geolocalización en Amazon Route 53 son estrategias efectivas para mejorar el rendimiento de la aplicación al dirigir a los usuarios a los puntos finales más apropiados según su ubicación y condiciones de red. El enrutamiento basado en latencia asegura que los usuarios se conecten al punto final con la menor latencia, mientras que el enrutamiento por geolocalización permite dirigir a los usuarios al punto final regional más cercano, mejorando tanto la experiencia del usuario como la eficiencia de la aplicación.",
        "Other Options": [
            "El enrutamiento simple no toma en cuenta la ubicación geográfica de los usuarios ni su latencia, lo que puede llevar a un rendimiento subóptimo para los usuarios ubicados lejos del único punto final.",
            "El enrutamiento ponderado permite la distribución del tráfico según pesos, pero no optimiza para latencia o proximidad geográfica, lo cual es crítico para mejorar la experiencia del usuario en una aplicación global.",
            "El enrutamiento de conmutación por error está diseñado para alta disponibilidad más que para optimización del rendimiento; solo dirige el tráfico a un punto final de respaldo cuando el primario está fuera de servicio, lo que no aborda los problemas de latencia para los usuarios activos."
        ]
    },
    {
        "Question Number": "2",
        "Situation": "Una empresa está desplegando una nueva versión de una función Lambda que procesa datos entrantes. El arquitecto de soluciones necesita asegurarse de que la nueva versión sea probada en un entorno similar al de producción, minimizando el riesgo de impactar a los usuarios existentes. El arquitecto planea usar un alias para dirigir el tráfico entre la versión actual y la nueva versión. La configuración de enrutamiento debe permitir que la mayor parte del tráfico continúe hacia la versión existente mientras envía un pequeño porcentaje a la nueva versión para fines de prueba.",
        "Question": "¿Cuál de las siguientes configuraciones permitiría al arquitecto de soluciones implementar este enrutamiento de tráfico de manera efectiva mientras cumple con todos los requisitos necesarios?",
        "Options": {
            "1": "Crear un alias que apunte a la versión $LATEST y a la versión anterior de la función Lambda. Dirigir el 90% del tráfico a la versión $LATEST y el 10% a la versión anterior, asegurando que tengan diferentes roles de ejecución.",
            "2": "Crear dos alias: uno para la versión existente con 100% de tráfico y otro para la nueva versión con 0% de tráfico. Luego, ajustar el porcentaje a 90% y 10% respectivamente cuando esté listo para probar la nueva versión.",
            "3": "Crear un alias que apunte a la versión existente y a la nueva versión de la función Lambda, dirigiendo el 90% del tráfico a la versión existente y el 10% a la nueva versión. Asegurarse de que ambas versiones tengan el mismo rol de ejecución y ninguna configuración de cola de mensajes no entregados.",
            "4": "Crear un alias que apunte a la versión existente y a la nueva versión de la función Lambda, dirigiendo el 80% del tráfico a la versión existente y el 20% a la nueva versión. Asegurarse de que ambas versiones estén publicadas y tengan el mismo rol de ejecución."
        },
        "Correct Answer": "Crear un alias que apunte a la versión existente y a la nueva versión de la función Lambda, dirigiendo el 90% del tráfico a la versión existente y el 10% a la nueva versión. Asegurarse de que ambas versiones tengan el mismo rol de ejecución y ninguna configuración de cola de mensajes no entregados.",
        "Explanation": "Esta opción configura correctamente un alias para dirigir los porcentajes especificados de tráfico a las versiones existente y nueva de la función Lambda. Cumple con los requisitos de que ambas versiones deben estar publicadas, tener el mismo rol de ejecución y no utilizar una configuración de cola de mensajes no entregados.",
        "Other Options": [
            "Esta opción es incorrecta porque el alias no puede apuntar a la versión $LATEST, lo que no cumple con el requisito de apuntar solo a versiones publicadas.",
            "Esta opción es incorrecta ya que crear dos alias no proporciona la capacidad de dirigir el tráfico entre versiones de manera efectiva. No cumple con el requisito de tener ambas versiones en un solo alias.",
            "Esta opción es incorrecta porque dirige el 80% del tráfico a la versión existente y el 20% a la nueva versión, lo que no coincide con el requisito de dirigir el 90% a la versión existente y el 10% a la nueva versión."
        ]
    },
    {
        "Question Number": "3",
        "Situation": "Una empresa de transmisión de medios utiliza Amazon CloudFront para entregar contenido de video a nivel global. Desean personalizar el contenido basado en las preferencias y ubicación del usuario sin afectar el rendimiento. La empresa desea una solución que les permita modificar solicitudes y respuestas en el borde, asegurando que los cambios se ejecuten lo más cerca posible del espectador.",
        "Question": "¿Qué solución debería implementar el arquitecto de soluciones para personalizar el contenido entregado por CloudFront basado en las preferencias del usuario?",
        "Options": {
            "1": "Configurar un Amazon API Gateway frente a la distribución de CloudFront para manejar todas las modificaciones de solicitudes y respuestas basadas en los datos del usuario.",
            "2": "Usar Lambda@Edge para ejecutar una función Lambda en el evento de solicitud del espectador para modificar la solicitud según las preferencias del usuario antes de almacenar en caché las respuestas.",
            "3": "Implementar reglas de AWS WAF para filtrar y personalizar solicitudes y respuestas antes de que lleguen a la distribución de CloudFront.",
            "4": "Configurar una función AWS Lambda para que se ejecute en el evento de solicitud de origen en CloudFront para modificar solicitudes antes de que lleguen al servidor de origen."
        },
        "Correct Answer": "Usar Lambda@Edge para ejecutar una función Lambda en el evento de solicitud del espectador para modificar la solicitud según las preferencias del usuario antes de almacenar en caché las respuestas.",
        "Explanation": "Usar Lambda@Edge permite a la empresa personalizar la solicitud en la etapa de solicitud del espectador, asegurando que se realicen modificaciones específicas del usuario antes de que el contenido se almacene en caché en CloudFront, lo que lleva a una experiencia más personalizada sin comprometer el rendimiento.",
        "Other Options": [
            "Esta opción es incorrecta porque modificar solicitudes en el evento de solicitud de origen no permite la personalización basada en las preferencias del usuario antes de que la solicitud se envíe al servidor de origen, lo que podría llevar a una latencia innecesaria.",
            "Esta opción es incorrecta porque, aunque API Gateway puede gestionar modificaciones de solicitudes, introduciría latencia y complejidad adicionales en comparación con el uso directo de Lambda@Edge con CloudFront.",
            "Esta opción es incorrecta ya que AWS WAF está diseñado principalmente para propósitos de seguridad, como filtrar solicitudes maliciosas, y no está destinado a la personalización de contenido basada en las preferencias del usuario."
        ]
    },
    {
        "Question Number": "4",
        "Situation": "Una empresa ha desplegado una aplicación en AWS que experimenta fallos intermitentes debido a limitaciones de recursos. La aplicación se ejecuta en instancias de EC2, y el equipo ha implementado alarmas de CloudWatch para monitorear la utilización de CPU. Sin embargo, necesitan una estrategia de alertas y remediación automática más robusta para garantizar alta disponibilidad y minimizar la intervención manual.",
        "Question": "¿Cuál es la estrategia más efectiva para mejorar las alertas y la remediación automática de la aplicación?",
        "Options": {
            "1": "Configurar Auto Scaling para ajustar dinámicamente el número de instancias de EC2 según las métricas de CloudWatch, junto con la configuración de alarmas de CloudWatch para notificaciones proactivas.",
            "2": "Utilizar Amazon SNS para enviar notificaciones cuando se activan las alarmas de CloudWatch, permitiendo que el equipo de operaciones investigue y remedie manualmente el problema.",
            "3": "Crear un panel personalizado de CloudWatch que proporcione métricas en tiempo real y alerte al equipo por correo electrónico cuando el rendimiento de alguna instancia caiga por debajo de niveles aceptables.",
            "4": "Implementar funciones de AWS Lambda que se activen mediante alarmas de CloudWatch para reiniciar automáticamente las instancias de EC2 cuando la utilización de CPU supere un umbral definido."
        },
        "Correct Answer": "Configurar Auto Scaling para ajustar dinámicamente el número de instancias de EC2 según las métricas de CloudWatch, junto con la configuración de alarmas de CloudWatch para notificaciones proactivas.",
        "Explanation": "Utilizar Auto Scaling permite que la aplicación ajuste automáticamente su capacidad según la demanda, mejorando la confiabilidad y reduciendo la intervención manual. Acoplar esto con alarmas de CloudWatch asegura que el equipo sea notificado de cualquier cambio significativo, lo que permite una gestión proactiva de los recursos.",
        "Other Options": [
            "Este enfoque depende de la intervención manual, lo que no se alinea con el objetivo de la remediación automática. Si bien reiniciar instancias de EC2 puede resolver temporalmente problemas, no aborda de manera efectiva las limitaciones de recursos subyacentes.",
            "Esta opción implica investigación y remediación manual, lo que va en contra del propósito de la remediación automática. El equipo de operaciones puede no ser capaz de responder lo suficientemente rápido para prevenir el tiempo de inactividad.",
            "Si bien un panel personalizado de CloudWatch es útil para el monitoreo, no proporciona capacidades de remediación automática. Las alertas enviadas por correo electrónico requieren respuesta manual y no garantizan alta disponibilidad."
        ]
    },
    {
        "Question Number": "5",
        "Situation": "Una empresa de servicios financieros está desarrollando una nueva aplicación que requiere acceso rápido a datos utilizados con frecuencia mientras minimiza costos. Están considerando utilizar Amazon ElastiCache para implementar una estrategia de caché. El objetivo principal de la empresa es asegurar que la caché se mantenga efectiva sin abrumar sus recursos, especialmente en términos de almacenamiento de datos innecesarios.",
        "Question": "¿Qué estrategia de caché debería recomendar el arquitecto de soluciones para equilibrar la necesidad de datos actualizados con un uso eficiente de los recursos?",
        "Options": {
            "1": "Implementar una estrategia de caché de carga perezosa con un valor de tiempo de vida (TTL) para cada elemento en caché para optimizar el uso de recursos.",
            "2": "Utilizar una estrategia de caché de escritura directa sin un TTL, asegurando que todos los datos se mantengan frescos pero arriesgando un crecimiento innecesario de la caché.",
            "3": "Elegir una estrategia de caché de escritura directa con un TTL, asegurando la frescura de los datos mientras se previene el desorden de la caché por entradas no utilizadas.",
            "4": "Adoptar una estrategia de carga perezosa sin TTL, permitiendo datos potencialmente obsoletos y un uso ineficiente de los recursos en la caché."
        },
        "Correct Answer": "Implementar una estrategia de caché de carga perezosa con un valor de tiempo de vida (TTL) para cada elemento en caché para optimizar el uso de recursos.",
        "Explanation": "Una estrategia de caché de carga perezosa con un TTL permite que la aplicación solo almacene datos que son solicitados, junto con un TTL para eliminar automáticamente datos obsoletos. Esto equilibra la eficiencia y la frescura, asegurando un uso óptimo de los recursos.",
        "Other Options": [
            "Una estrategia de caché de escritura directa sin un TTL puede llevar a un crecimiento innecesario de la caché, ya que todos los datos se escriben continuamente en la caché sin considerar su relevancia a lo largo del tiempo.",
            "Adoptar una estrategia de carga perezosa sin un TTL puede resultar en datos obsoletos permaneciendo en la caché por más tiempo del necesario, lo que lleva a un uso ineficiente de los recursos y posiblemente a información desactualizada siendo servida.",
            "Elegir una estrategia de caché de escritura directa con un TTL puede asegurar la frescura de los datos, pero aún puede llenar la caché con entradas innecesarias a menos que se gestione cuidadosamente."
        ]
    },
    {
        "Question Number": "6",
        "Situation": "Una empresa está desplegando una aplicación web en una VPC que requiere acceso seguro a sus instancias de EC2 desde internet, mientras que también permite la comunicación interna entre instancias. El arquitecto de soluciones está configurando los ajustes de red para asegurar un control de acceso y enrutamiento adecuados.",
        "Question": "¿Cuál de las siguientes configuraciones asegurará que las instancias de EC2 sean accesibles desde internet y también permita comunicación sin restricciones entre instancias dentro de la misma subred?",
        "Options": {
            "1": "Implementar una subred pública con una ruta a una puerta de enlace de internet y usar grupos de seguridad para permitir tráfico interno.",
            "2": "Configurar un ACL de red que niegue todo el tráfico entrante mientras permite el tráfico saliente.",
            "3": "Configurar una ruta pública en la tabla de rutas y permitir todo el tráfico en el grupo de seguridad.",
            "4": "Crear una ruta privada en la tabla de rutas y restringir el acceso del grupo de seguridad a rangos de IP específicos."
        },
        "Correct Answer": "Implementar una subred pública con una ruta a una puerta de enlace de internet y usar grupos de seguridad para permitir tráfico interno.",
        "Explanation": "Esta configuración permite que las instancias de EC2 en la subred pública sean accesibles desde internet a través de la puerta de enlace de internet, mientras que también permite comunicación interna sin restricciones a través de grupos de seguridad configurados adecuadamente.",
        "Other Options": [
            "Esta opción permite el acceso a internet pero no especifica una ruta a una puerta de enlace de internet, lo cual es necesario para el acceso público.",
            "Esta opción bloquearía todo el tráfico entrante, impidiendo cualquier acceso externo a las instancias de EC2, lo cual no es deseable para una aplicación de cara al público.",
            "Esta opción establece la tabla de rutas como privada, lo que significa que las instancias no serían accesibles desde internet, contradiciendo el requisito de acceso público."
        ]
    },
    {
        "Question Number": "7",
        "Situation": "Una empresa de servicios financieros está buscando optimizar su uso de AWS y minimizar costos. La empresa ha estado utilizando múltiples cuentas de AWS para diferentes departamentos y ha notado altas facturas mensuales sin una comprensión clara de los factores que generan costos. La tarea del arquitecto de soluciones es implementar una estrategia que ayude a la empresa a monitorear y analizar su gasto en AWS de manera efectiva.",
        "Question": "¿Cuál de las siguientes herramientas sería la más efectiva para monitorear y gestionar los costos de AWS en múltiples cuentas en este escenario?",
        "Options": {
            "1": "AWS Budgets para establecer umbrales de costos y recibir alertas, junto con AWS Cost Explorer para un análisis detallado del gasto.",
            "2": "AWS Pricing Calculator para estimar costos de servicios futuros, y AWS CloudTrail para registrar llamadas a la API para auditoría.",
            "3": "Amazon QuickSight para visualizar tendencias de costos y AWS CloudFormation para gestionar la infraestructura como código.",
            "4": "AWS Trusted Advisor para acceder a recomendaciones de mejores prácticas, y AWS Config para monitorear configuraciones de recursos y cumplimiento."
        },
        "Correct Answer": "AWS Budgets para establecer umbrales de costos y recibir alertas, junto con AWS Cost Explorer para un análisis detallado del gasto.",
        "Explanation": "AWS Budgets permite a los usuarios establecer presupuestos personalizados de costos y uso, proporcionando alertas cuando se superan los umbrales. Junto con AWS Cost Explorer, que ofrece información detallada sobre patrones de gasto y factores de costo, esta combinación es la más efectiva para monitorear y gestionar costos en múltiples cuentas.",
        "Other Options": [
            "AWS Pricing Calculator se utiliza principalmente para estimar costos antes de la implementación en lugar de para el monitoreo y gestión continua de costos existentes. AWS CloudTrail se centra en registrar llamadas a la API y no proporciona información sobre la gestión de costos.",
            "AWS Trusted Advisor ofrece verificaciones de mejores prácticas pero no proporciona monitoreo de costos en tiempo real. AWS Config se utiliza para rastrear configuraciones de recursos y cumplimiento, no para análisis de costos.",
            "Amazon QuickSight es una herramienta de inteligencia empresarial para la visualización de datos, pero no se centra inherentemente en la gestión de costos. AWS CloudFormation se utiliza para la gestión de infraestructura y no proporciona capacidades de monitoreo de costos."
        ]
    },
    {
        "Question Number": "8",
        "Situation": "Una organización está implementando una nueva política de gestión de parches en su entorno de AWS para mantener el cumplimiento con los estándares de seguridad internos. La organización necesita asegurarse de que todas las instancias de EC2 estén parcheadas regularmente y cumplan con las últimas actualizaciones de seguridad.",
        "Question": "¿Cuál es la estrategia más efectiva para implementar una solución de gestión de parches que se alinee con los requisitos de cumplimiento de la organización?",
        "Options": {
            "1": "Desplegar una solución de gestión de parches de terceros en las instancias de EC2 para automatizar el proceso de parcheo y mantener el cumplimiento con los estándares organizacionales.",
            "2": "Iniciar sesión manualmente en cada instancia de EC2 y aplicar las actualizaciones necesarias a cada sistema operativo según sea necesario para garantizar el cumplimiento.",
            "3": "Utilizar AWS Systems Manager Patch Manager para automatizar el parcheo de las instancias de EC2, asegurando que estén actualizadas con la línea base de parches definida.",
            "4": "Configurar una alarma de Amazon CloudWatch para notificar a los administradores cuando un nuevo parche esté disponible para los sistemas operativos que se ejecutan en las instancias de EC2."
        },
        "Correct Answer": "Utilizar AWS Systems Manager Patch Manager para automatizar el parcheo de las instancias de EC2, asegurando que estén actualizadas con la línea base de parches definida.",
        "Explanation": "AWS Systems Manager Patch Manager permite la gestión automatizada de parches para sus instancias, ayudando a garantizar que permanezcan en cumplimiento con los estándares organizacionales mientras se reduce el esfuerzo manual y el error humano.",
        "Other Options": [
            "Iniciar sesión manualmente en cada instancia de EC2 para aplicar actualizaciones es ineficiente y puede llevar a parches perdidos, aumentando el riesgo de incumplimiento y vulnerabilidades de seguridad.",
            "Configurar una alarma de CloudWatch para nuevos parches no aborda el proceso real de parcheo, lo que significa que las instancias pueden permanecer sin parches a pesar de las notificaciones, lo que no garantiza el cumplimiento.",
            "Si bien desplegar una solución de gestión de parches de terceros puede funcionar, usar AWS Systems Manager Patch Manager es un enfoque más integrado y eficiente para gestionar parches en entornos de AWS."
        ]
    },
    {
        "Question Number": "9",
        "Situation": "Una gran empresa de comercio electrónico está analizando su utilización de recursos de AWS para optimizar costos. La empresa utiliza varios servicios, incluyendo Amazon EC2, Amazon EBS, AWS Fargate para aplicaciones en contenedores, y AWS Lambda para funciones sin servidor. El arquitecto de soluciones está considerando implementar AWS Compute Optimizer para mejorar la asignación de recursos basada en patrones de utilización. El arquitecto quiere asegurarse de recibir recomendaciones precisas que reflejen el verdadero uso de sus recursos.",
        "Question": "¿Qué debería hacer el arquitecto de soluciones para asegurarse de que AWS Compute Optimizer proporcione las mejores recomendaciones para las instancias de EC2 y los grupos de Auto Scaling?",
        "Options": {
            "1": "Configurar manualmente los tamaños de las instancias basándose en la carga de trabajo esperada sin utilizar ninguna recomendación automatizada.",
            "2": "Habilitar métricas de infraestructura mejoradas para las instancias de EC2 y los grupos de Auto Scaling para capturar datos detallados de utilización.",
            "3": "Revisar los tipos y tamaños de instancias actuales para asegurarse de que coincidan con los requisitos de las aplicaciones sin ninguna métrica.",
            "4": "Utilizar AWS Cost Explorer para analizar los datos de facturación de las instancias de EC2 y los grupos de Auto Scaling durante los últimos 12 meses."
        },
        "Correct Answer": "Habilitar métricas de infraestructura mejoradas para las instancias de EC2 y los grupos de Auto Scaling para capturar datos detallados de utilización.",
        "Explanation": "Habilitar métricas de infraestructura mejoradas permite a AWS Compute Optimizer recopilar datos detallados de utilización, lo cual es crucial para hacer recomendaciones precisas sobre tipos y tamaños de instancias, evitando así la sobreasignación y la subasignación.",
        "Other Options": [
            "Utilizar AWS Cost Explorer ayudará a entender las tendencias de costos, pero no proporciona los datos de utilización detallados necesarios para las recomendaciones de Compute Optimizer.",
            "Configurar manualmente los tamaños de las instancias sin recomendaciones automatizadas puede llevar a ineficiencias y no aprovecha las capacidades de AWS Compute Optimizer.",
            "Revisar los tipos y tamaños de instancias actuales sin métricas ignora los patrones de utilización reales, que son esenciales para tomar decisiones informadas de optimización."
        ]
    },
    {
        "Question Number": "10",
        "Situation": "Una empresa de servicios financieros está construyendo una nueva aplicación que procesa transacciones en tiempo real. La aplicación requiere entrega de mensajes confiable, desacoplamiento de componentes y la capacidad de escalar de manera independiente. El equipo está evaluando los servicios de AWS para asegurar que la aplicación permanezca altamente disponible y pueda manejar cargas variables sin tiempo de inactividad.",
        "Question": "¿Qué servicio de integración de AWS debería utilizar la empresa para cumplir con estos requisitos?",
        "Options": {
            "1": "Usar Amazon SQS para gestionar colas de mensajes entre los componentes de la aplicación, asegurando una entrega confiable y el desacoplamiento de los microservicios.",
            "2": "Utilizar Amazon EventBridge para responder a eventos de varios servicios de AWS y dirigirlos a los componentes necesarios de la aplicación.",
            "3": "Aprovechar AWS Step Functions para coordinar la ejecución de microservicios y gestionar el flujo de trabajo para el procesamiento de transacciones.",
            "4": "Implementar Amazon SNS para transmitir notificaciones a múltiples suscriptores, permitiendo actualizaciones en tiempo real a través de diferentes partes del sistema."
        },
        "Correct Answer": "Usar Amazon SQS para gestionar colas de mensajes entre los componentes de la aplicación, asegurando una entrega confiable y el desacoplamiento de los microservicios.",
        "Explanation": "Amazon SQS está diseñado específicamente para la cola de mensajes, proporcionando entrega confiable de mensajes y desacoplamiento de los componentes de la aplicación. Puede manejar cargas variables de manera eficiente y asegura que los mensajes se procesen incluso si el componente receptor está temporalmente no disponible.",
        "Other Options": [
            "Amazon SNS es principalmente para mensajería pub/sub y no es ideal para gestionar colas de mensajes o asegurar que los mensajes se procesen de manera confiable en el orden en que se reciben.",
            "AWS Step Functions se centra en orquestar flujos de trabajo entre servicios en lugar de gestionar la entrega de mensajes directamente, lo cual no es el requisito principal para este escenario.",
            "Amazon EventBridge es excelente para arquitecturas impulsadas por eventos, pero no proporcionaría el mismo nivel de cola de mensajes confiable que Amazon SQS, que es necesario para el procesamiento de transacciones."
        ]
    },
    {
        "Question Number": "11",
        "Situation": "Una empresa está ejecutando múltiples recursos de AWS como instancias de EC2, bases de datos de RDS y buckets de S3 en diferentes entornos. La dirección quiere identificar y eliminar cualquier recurso no utilizado para optimizar costos. El arquitecto de soluciones tiene la tarea de recomendar una solución de AWS que pueda automatizar este proceso y proporcionar información sobre el uso de recursos.",
        "Question": "¿Qué solución ayudaría mejor a la empresa a identificar recursos no utilizados en sus cuentas de AWS?",
        "Options": {
            "1": "Configurar alarmas de Amazon CloudWatch para cada tipo de recurso para alertar sobre inactividad, luego usar AWS Systems Manager para revisar las alarmas.",
            "2": "Implementar reglas de AWS Config para rastrear el uso de recursos y crear una función de AWS Lambda que se active según los cambios en el estado de los recursos.",
            "3": "Desplegar AWS Trusted Advisor para monitorear el uso de recursos y generar recomendaciones para recursos infrautilizados o inactivos.",
            "4": "Usar AWS Cost Explorer para analizar informes de costos y uso, filtrando recursos con cero uso durante un período específico."
        },
        "Correct Answer": "Usar AWS Trusted Advisor para monitorear el uso de recursos y generar recomendaciones para recursos infrautilizados o inactivos.",
        "Explanation": "AWS Trusted Advisor proporciona una vista integral del uso de cuentas de AWS y ofrece recomendaciones específicas para la optimización de costos, incluyendo la identificación de recursos no utilizados. Está diseñado para este propósito exacto, lo que lo convierte en una solución efectiva para las necesidades de la empresa.",
        "Other Options": [
            "Implementar reglas de AWS Config se centra en rastrear cambios de configuración en lugar de identificar directamente recursos no utilizados, lo que lo hace menos efectivo para el objetivo de la empresa.",
            "Usar AWS Cost Explorer puede ayudar a analizar costos, pero no indica directamente el estado de uso de los recursos, lo que puede llevar a información incompleta sobre recursos no utilizados.",
            "Configurar alarmas de Amazon CloudWatch para inactividad es un enfoque reactivo y no proporciona información integral para identificar recursos no utilizados de manera efectiva a través de diferentes servicios."
        ]
    },
    {
        "Question Number": "12",
        "Situation": "Una empresa ha desplegado un conjunto de APIs utilizando Amazon API Gateway para exponer sus servicios a clientes externos. Las APIs están experimentando un aumento en el tráfico, lo que lleva a una posible degradación del rendimiento. Para asegurar que las APIs permanezcan receptivas y disponibles, el arquitecto de soluciones necesita implementar limitaciones y cuotas de manera efectiva.",
        "Question": "¿Cuál de las siguientes configuraciones ayudaría mejor a la empresa a gestionar el tráfico de la API mientras previene interrupciones del servicio debido a solicitudes excesivas?",
        "Options": {
            "1": "Establecer una cuota estática de 10,000 solicitudes por día a nivel de cuenta para todas las APIs para evitar que una sola API abrume el sistema.",
            "2": "Implementar una capa de caché frente al API Gateway para reducir el número de solicitudes que llegan directamente a los servicios de backend.",
            "3": "Habilitar AWS WAF para restringir el acceso a las APIs según la dirección IP para limitar el número total de solicitudes.",
            "4": "Configurar un límite de tasa de 100 solicitudes por segundo y un límite de ráfaga de 500 solicitudes para cada API en la configuración del API Gateway."
        },
        "Correct Answer": "Configurar un límite de tasa de 100 solicitudes por segundo y un límite de ráfaga de 500 solicitudes para cada API en la configuración del API Gateway.",
        "Explanation": "Establecer un límite de tasa y un límite de ráfaga en el API Gateway ayuda a gestionar de manera efectiva las solicitudes entrantes, asegurando que las APIs puedan manejar picos repentinos en el tráfico mientras mantienen la capacidad de respuesta general. Este enfoque utiliza el algoritmo de cubo de tokens para controlar el flujo de solicitudes.",
        "Other Options": [
            "Establecer una cuota estática de 10,000 solicitudes por día a nivel de cuenta no proporciona flexibilidad en tiempo real y podría no prevenir una sobrecarga inmediata durante los momentos de uso máximo.",
            "Implementar una capa de caché puede reducir la carga, pero no aborda directamente la limitación de las solicitudes entrantes y puede no prevenir la degradación del servicio de backend durante un alto tráfico.",
            "Habilitar AWS WAF para restringir el acceso según la dirección IP limita el tráfico, pero puede no gestionar de manera efectiva la tasa total de solicitudes, lo que podría llevar a problemas de limitación."
        ]
    },
    {
        "Question Number": "13",
        "Situation": "Una empresa minorista quiere mejorar su plataforma de ventas en línea traduciendo los requisitos comerciales en métricas medibles. Se centran particularmente en mejorar la experiencia del cliente, optimizar la gestión de inventarios y aumentar las tasas de conversión a través de decisiones basadas en datos. El equipo de gestión busca una solución que capture métricas relevantes para informar su estrategia y medir el éxito.",
        "Question": "¿Cuál de las siguientes estrategias cumple mejor con los objetivos de la empresa para traducir los requisitos comerciales en métricas medibles?",
        "Options": {
            "1": "Configurar AWS IoT Core para recopilar datos de sensores y dispositivos minoristas, analizando las métricas de tráfico de clientes y niveles de inventario. Usar Amazon S3 para almacenar los datos para consultas históricas.",
            "2": "Implementar una solución de análisis utilizando Amazon QuickSight para crear paneles que rastreen métricas de compromiso del cliente, rotación de inventario y tasas de conversión. Integrar esto con Amazon Kinesis para analizar flujos de datos en tiempo real.",
            "3": "Usar AWS CloudTrail para monitorear y registrar llamadas a la API de la plataforma de comercio electrónico, extrayendo métricas relacionadas con la actividad del usuario y ajustes de inventario. Generar alertas para cambios significativos utilizando Amazon CloudWatch.",
            "4": "Desplegar un modelo de aprendizaje automático utilizando Amazon SageMaker para predecir patrones de compra de los clientes y generar informes. Aprovechar AWS Cost Explorer para analizar los costos asociados con la gestión de inventarios."
        },
        "Correct Answer": "Implementar una solución de análisis utilizando Amazon QuickSight para crear paneles que rastreen métricas de compromiso del cliente, rotación de inventario y tasas de conversión. Integrar esto con Amazon Kinesis para analizar flujos de datos en tiempo real.",
        "Explanation": "Esta opción aborda directamente la necesidad de traducir los requisitos comerciales en métricas medibles al implementar una solución de análisis integral que captura indicadores clave de rendimiento y proporciona información en tiempo real para la toma de decisiones.",
        "Other Options": [
            "Esta opción se centra en el análisis predictivo, pero no aborda directamente la necesidad de rastrear en tiempo real métricas clave como el compromiso del cliente y las tasas de conversión, que son esenciales para obtener información inmediata sobre el negocio.",
            "Esta opción se ocupa principalmente de registrar llamadas a la API, lo cual es útil para auditorías, pero no proporciona métricas o información procesable directamente relacionadas con los objetivos de la empresa.",
            "Esta opción implica recopilar datos de sensores minoristas, lo que puede no ser relevante para una plataforma de ventas en línea. El enfoque debería estar en métricas que impacten directamente el negocio en línea en lugar de datos minoristas físicos."
        ]
    },
    {
        "Question Number": "14",
        "Situation": "Una empresa tiene múltiples cuentas de AWS para diferentes departamentos y quiere compartir recursos de manera segura entre estas cuentas sin comprometer la seguridad o la capacidad de gestión.",
        "Question": "¿Cuál de las siguientes soluciones proporciona una forma segura y eficiente de compartir recursos entre múltiples cuentas de AWS?",
        "Options": {
            "1": "Usar AWS Organizations para consolidar las cuentas y compartir recursos utilizando roles de IAM.",
            "2": "Crear conexiones de emparejamiento de VPC entre todas las cuentas para permitir el acceso directo a los recursos compartidos.",
            "3": "Configurar AWS Resource Access Manager (RAM) para compartir recursos entre las cuentas y gestionar permisos de manera centralizada.",
            "4": "Implementar acceso entre cuentas creando manualmente roles de IAM en cada cuenta para compartir recursos."
        },
        "Correct Answer": "Configurar AWS Resource Access Manager (RAM) para compartir recursos entre las cuentas y gestionar permisos de manera centralizada.",
        "Explanation": "AWS Resource Access Manager (RAM) permite compartir recursos de AWS de manera segura y eficiente entre múltiples cuentas mientras gestiona permisos de forma centralizada, lo que lo convierte en la mejor opción para este escenario.",
        "Other Options": [
            "El emparejamiento de VPC está limitado a compartir recursos entre dos VPC y puede volverse complejo al gestionar múltiples cuentas, lo que lo hace menos eficiente para un intercambio de recursos más amplio.",
            "Si bien AWS Organizations ayuda con la gestión de cuentas, no facilita directamente el intercambio de recursos; se necesitarían configuraciones adicionales para compartir recursos de manera efectiva.",
            "Crear manualmente roles de IAM en cada cuenta para compartir recursos es engorroso y propenso a errores, lo que lo hace menos manejable en comparación con el uso de AWS RAM."
        ]
    },
    {
        "Question Number": "15",
        "Situation": "Una empresa está desplegando una aplicación web utilizando AWS OpsWorks Stacks. La aplicación requiere múltiples capas para diferentes componentes, incluyendo un balanceador de carga, servidores de aplicaciones y una capa de base de datos. El equipo de desarrollo necesita asegurarse de que cada capa esté correctamente configurada y que las instancias estén asociadas correctamente con sus respectivas capas. También quieren implementar las mejores prácticas para gestionar el ciclo de vida de los componentes de su aplicación.",
        "Question": "¿Cuál de las siguientes estrategias debería adoptar el equipo de desarrollo para gestionar eficazmente el despliegue de la aplicación utilizando AWS OpsWorks Stacks?",
        "Options": {
            "1": "Usar OpsWorks para desplegar la aplicación sin crear ninguna capa, confiando en scripts externos para gestionar la configuración y el despliegue de instancias.",
            "2": "Crear una pila que incluya todas las capas necesarias, asegurando que cada capa tenga los eventos de ciclo de vida correctos y las instancias asociadas. Usar recetas integradas para gestionar despliegues y configuraciones.",
            "3": "Configurar una sola capa para todos los componentes de la aplicación y agregar múltiples instancias a esta capa para manejar diferentes roles dentro de la aplicación.",
            "4": "Provisionar instancias directamente dentro de la pila sin definir capas y configurar manualmente cada instancia para las aplicaciones y servicios requeridos."
        },
        "Correct Answer": "Crear una pila que incluya todas las capas necesarias, asegurando que cada capa tenga los eventos de ciclo de vida correctos y las instancias asociadas. Usar recetas integradas para gestionar despliegues y configuraciones.",
        "Explanation": "Crear una pila con capas definidas asegura que cada componente de la aplicación esté correctamente organizado y gestionado. Este enfoque utiliza los eventos de ciclo de vida y recetas integradas de OpsWorks, permitiendo despliegues y configuraciones automatizadas, lo que se alinea con las mejores prácticas para usar OpsWorks.",
        "Other Options": [
            "Provisionar instancias directamente sin definir capas va en contra del diseño fundamental de OpsWorks, que está destinado a gestionar aplicaciones a través de capas. Este enfoque llevaría a dificultades en escalar y gestionar la aplicación de manera efectiva.",
            "Configurar una sola capa para todos los componentes socava el propósito de las capas en OpsWorks, que es separar preocupaciones y gestionar diferentes aspectos de la aplicación de manera independiente. Esto podría llevar a complicaciones en la gestión de despliegues y configuraciones.",
            "Usar OpsWorks sin crear ninguna capa ignora las capacidades de la plataforma para gestionar eficazmente los ciclos de vida de las aplicaciones. Confiar en scripts externos añadiría complejidad y reduciría los beneficios de usar un servicio gestionado como OpsWorks."
        ]
    },
    {
        "Question Number": "16",
        "Situation": "Una empresa busca mejorar su excelencia operativa en la gestión de su infraestructura de AWS mediante la automatización de tareas rutinarias y la mejora de la fiabilidad del sistema. El arquitecto de soluciones necesita identificar estrategias que no solo optimicen el rendimiento, sino que también reduzcan el potencial de error humano durante las operaciones.",
        "Question": "¿Cuál de las siguientes estrategias puede ayudar a mejorar la excelencia operativa en general? (Seleccione dos)",
        "Options": {
            "1": "Crear un equipo dedicado para actualizaciones manuales de servidores para asegurar que los sistemas siempre estén ejecutando los últimos parches.",
            "2": "Configurar manualmente cada servicio y recurso para asegurar un rendimiento adaptado a casos de uso específicos.",
            "3": "Implementar AWS Systems Manager Run Command para automatizar la gestión de instancias EC2.",
            "4": "Establecer una solución de registro centralizada utilizando Amazon CloudWatch Logs para monitorear el comportamiento de la aplicación.",
            "5": "Utilizar AWS CloudFormation para crear y gestionar infraestructura como código, promoviendo entornos consistentes."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Implementar AWS Systems Manager Run Command para automatizar la gestión de instancias EC2.",
            "Utilizar AWS CloudFormation para crear y gestionar infraestructura como código, promoviendo entornos consistentes."
        ],
        "Explanation": "Implementar AWS Systems Manager Run Command permite la automatización de tareas rutinarias en múltiples instancias EC2, reduciendo así la probabilidad de error humano y mejorando la eficiencia operativa. Además, utilizar AWS CloudFormation permite la gestión de infraestructura como código, asegurando que los entornos sean consistentes y fácilmente reproducibles, lo cual es clave para la excelencia operativa.",
        "Other Options": [
            "Configurar manualmente los servicios aumenta el riesgo de inconsistencias y errores humanos, lo que resta valor a la excelencia operativa. La automatización es esencial para mejorar la fiabilidad y la eficiencia.",
            "Si bien establecer un registro centralizado es beneficioso para el monitoreo, por sí solo no mejora directamente la excelencia operativa. Se trata más de los procesos y la automatización de tareas que conducen a la eficiencia operativa.",
            "Crear un equipo dedicado para actualizaciones manuales de servidores puede introducir retrasos y errores humanos, lo que va en contra de los principios de la excelencia operativa. La automatización debe ser priorizada para asegurar actualizaciones oportunas y consistentes."
        ]
    },
    {
        "Question Number": "17",
        "Situation": "Una empresa minorista está experimentando patrones de uso fluctuantes para su plataforma de compras en línea alojada en AWS. El arquitecto de soluciones de la empresa necesita desarrollar una estrategia de ajuste de tamaño que reduzca costos mientras asegura un rendimiento óptimo durante las temporadas de compras pico. La solución debe minimizar la sobreaprovisionamiento y adaptarse a las cargas de trabajo variables.",
        "Question": "¿Cuál de las siguientes estrategias debería implementar el arquitecto de soluciones para lograr el mejor resultado de ajuste de tamaño para la plataforma de compras en línea?",
        "Options": {
            "1": "Revisar manualmente los tamaños de las instancias cada mes y degradarlas según el uso actual sin ninguna automatización.",
            "2": "Configurar todas las instancias al tamaño más pequeño disponible para minimizar costos sin considerar las necesidades de rendimiento durante el uso pico.",
            "3": "Implementar Instancias Reservadas para todos los tipos de instancias para asegurar ahorros de costos sin considerar los patrones de uso reales.",
            "4": "Analizar patrones de uso históricos e implementar Auto Scaling para ajustar dinámicamente el número de instancias según la demanda."
        },
        "Correct Answer": "Analizar patrones de uso históricos e implementar Auto Scaling para ajustar dinámicamente el número de instancias según la demanda.",
        "Explanation": "Implementar Auto Scaling basado en patrones de uso históricos permite que la plataforma ajuste automáticamente los recursos en respuesta a las fluctuaciones de demanda en tiempo real. Esto asegura un rendimiento óptimo durante los momentos pico mientras minimiza costos durante los períodos de baja demanda.",
        "Other Options": [
            "Revisar manualmente los tamaños de las instancias cada mes carece de automatización y puede resultar en respuestas tardías a las cargas de trabajo cambiantes, lo que lleva a una posible sobreaprovisionamiento o subaprovisionamiento.",
            "Configurar todas las instancias al tamaño más pequeño puede degradar significativamente el rendimiento durante los momentos de uso pico, lo que lleva a una mala experiencia del cliente y ventas perdidas.",
            "Implementar Instancias Reservadas sin considerar los patrones de uso reales puede llevar a costos innecesarios si los recursos no se utilizan completamente, lo que anula el propósito del ajuste de tamaño."
        ]
    },
    {
        "Question Number": "18",
        "Situation": "Una empresa está aprovechando los servicios de AWS para sus requisitos de almacenamiento y respaldo de datos. Están utilizando Amazon S3 para almacenamiento de objetos y quieren asegurarse de que sus datos se respalden de manera eficiente y segura. La empresa también tiene requisitos de cumplimiento que requieren una estrategia de respaldo robusta. Están explorando diversas prácticas de respaldo para satisfacer estas necesidades.",
        "Question": "¿Cuál de las siguientes prácticas y métodos de respaldo puede implementar la empresa para asegurar la durabilidad de los datos y el cumplimiento? (Seleccione dos)",
        "Options": {
            "1": "Habilitar el versionado en el bucket de Amazon S3 y configurar políticas de ciclo de vida para trasladar versiones más antiguas a Amazon S3 Glacier.",
            "2": "Descargar manualmente objetos de S3 a almacenamiento local cada mes para asegurar el cumplimiento de las políticas de respaldo.",
            "3": "Utilizar AWS Backup para crear planes de respaldo que respalden automáticamente los datos de S3 a un vault de respaldo designado.",
            "4": "Configurar la replicación entre regiones en el bucket de S3 para replicar objetos a otro bucket de S3 en una región de AWS diferente.",
            "5": "Crear una función programada de AWS Lambda que copie regularmente los objetos de S3 a otro bucket de S3 en una región diferente."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Habilitar el versionado en el bucket de Amazon S3 y configurar políticas de ciclo de vida para trasladar versiones más antiguas a Amazon S3 Glacier.",
            "Configurar la replicación entre regiones en el bucket de S3 para replicar objetos a otro bucket de S3 en una región de AWS diferente."
        ],
        "Explanation": "Habilitar el versionado en el bucket de S3 asegura que todas las versiones de un objeto se conserven, lo cual es crucial para la recuperación de datos y el cumplimiento. Además, utilizar políticas de ciclo de vida para trasladar versiones más antiguas a Amazon S3 Glacier ayuda a optimizar costos mientras se asegura la durabilidad de los datos. Configurar la replicación entre regiones permite redundancia de datos y mejora la disponibilidad, lo que mejora aún más la estrategia de respaldo.",
        "Other Options": [
            "Crear una función programada de AWS Lambda para copiar objetos de S3 a otro bucket es una solución potencial, pero requiere gestión continua y no proporciona el mismo nivel de durabilidad que el versionado y las políticas de ciclo de vida.",
            "Utilizar AWS Backup para S3 no es actualmente compatible, ya que AWS Backup se dirige principalmente a servicios como EBS, RDS y DynamoDB, lo que hace que esta opción sea incorrecta.",
            "Descargar manualmente objetos de S3 a almacenamiento local no es una práctica de respaldo eficiente o confiable, ya que es propensa a errores humanos y no proporciona los beneficios de las características de durabilidad y redundancia integradas de AWS."
        ]
    },
    {
        "Question Number": "19",
        "Situation": "Una plataforma de comercio electrónico global ha experimentado un aumento en los errores de aplicación y problemas de latencia recientemente. El arquitecto de soluciones necesita implementar una solución de monitoreo robusta que permita al equipo detectar anomalías de rendimiento y solucionar problemas en tiempo real, así como registrar métricas detalladas de la aplicación para un análisis posterior. El equipo no tiene los recursos para gestionar una solución de registro compleja y prefiere un servicio completamente administrado que se integre bien con su infraestructura existente de AWS.",
        "Question": "¿Cuál de las siguientes opciones es la solución de monitoreo y registro más adecuada para los requisitos dados?",
        "Options": {
            "1": "Desplegar una herramienta de monitoreo de terceros en instancias de EC2 para capturar métricas de la aplicación.",
            "2": "Implementar AWS X-Ray para un seguimiento detallado de las solicitudes e integrarlo con CloudTrail para el registro.",
            "3": "Configurar un panel personalizado en Amazon QuickSight para visualizar métricas de rendimiento de la aplicación.",
            "4": "Usar Amazon CloudWatch para recopilar registros de la aplicación y configurar alarmas para anomalías de rendimiento."
        },
        "Correct Answer": "Usar Amazon CloudWatch para recopilar registros de la aplicación y configurar alarmas para anomalías de rendimiento.",
        "Explanation": "Amazon CloudWatch es un servicio completamente administrado que proporciona capacidades de monitoreo, registro y alarmas, lo que lo convierte en una opción ideal para el monitoreo de rendimiento en tiempo real y el registro de métricas de la aplicación sin necesidad de una gestión compleja.",
        "Other Options": [
            "Desplegar una herramienta de monitoreo de terceros en instancias de EC2 requeriría una carga adicional de gestión y no aprovecharía los servicios nativos de AWS, lo que podría complicar la arquitectura y aumentar los costos.",
            "Implementar AWS X-Ray sería beneficioso para el seguimiento de solicitudes, pero no aborda directamente la necesidad de registrar métricas de la aplicación y configurar alarmas, lo que lo hace menos adecuado como solución independiente.",
            "Configurar un panel personalizado en Amazon QuickSight no cumple con el requisito de monitoreo y registro en tiempo real, ya que QuickSight es principalmente una herramienta de inteligencia empresarial para la visualización de datos en lugar de una solución de monitoreo."
        ]
    },
    {
        "Question Number": "20",
        "Situation": "Una empresa de servicios financieros necesita monitorear el tráfico de red para mejorar su postura de seguridad. La empresa tiene una configuración existente de Amazon VPC y desea capturar y analizar patrones de tráfico por razones de cumplimiento y seguridad. Están considerando utilizar características de AWS para lograr este objetivo. La empresa quiere asegurarse de que puede analizar el tráfico de la Capa 7, que es crítico para su análisis de seguridad.",
        "Question": "¿Qué solución debería implementar la empresa para monitorear y analizar efectivamente el tráfico de red, incluyendo el análisis de la Capa 7?",
        "Options": {
            "1": "Habilitar los Registros de Flujo de VPC para capturar tráfico de la Capa 4 y publicar los registros en Amazon S3 para análisis utilizando AWS Athena.",
            "2": "Configurar Amazon CloudWatch Logs para monitorear los Registros de Flujo de VPC y crear alarmas basadas en el tráfico de la Capa 4 capturado.",
            "3": "Implementar AWS Traffic Mirroring para capturar y enviar todo el tráfico de red desde instancias de EC2 a dispositivos de seguridad para análisis de la Capa 7.",
            "4": "Usar AWS CloudTrail para registrar las llamadas a la API realizadas dentro de la VPC y analizar los registros para el cumplimiento de seguridad."
        },
        "Correct Answer": "Implementar AWS Traffic Mirroring para capturar y enviar todo el tráfico de red desde instancias de EC2 a dispositivos de seguridad para análisis de la Capa 7.",
        "Explanation": "AWS Traffic Mirroring permite a la empresa capturar y analizar todo el tráfico de red, incluidos los detalles de la Capa 7, enviándolo a dispositivos de seguridad y monitoreo fuera de banda. Esta solución proporciona visibilidad integral de los patrones de tráfico y es adecuada para el monitoreo de cumplimiento y seguridad.",
        "Other Options": [
            "Los Registros de Flujo de VPC solo capturan tráfico de la Capa 4, lo que no proporciona la información detallada necesaria para el análisis de la Capa 7. Aunque pueden publicarse en S3 para análisis, no cumplirán con el requisito de la empresa para una inspección más profunda del tráfico.",
            "AWS CloudTrail está diseñado para registrar las llamadas a la API realizadas dentro del entorno de AWS, no para monitorear el tráfico de red. No proporciona la información necesaria sobre los paquetes que fluyen a través de la VPC, lo que lo hace inadecuado para las necesidades de la empresa.",
            "Si bien Amazon CloudWatch Logs puede monitorear los Registros de Flujo de VPC, solo capturan tráfico de la Capa 4. Este enfoque no aborda el requisito de la empresa para el análisis del tráfico de la Capa 7, que es crítico para su postura de seguridad."
        ]
    },
    {
        "Question Number": "21",
        "Situation": "Una empresa de servicios financieros utiliza servicios de AWS para gestionar información sensible como claves de API, credenciales de bases de datos y tokens de servicios de terceros. Actualmente, las credenciales están codificadas en el código de la aplicación, lo que dificulta gestionarlas y rotarlas de manera segura. La empresa está buscando una solución robusta para gestionar estos secretos y credenciales de manera segura, asegurando que puedan ser rotados fácilmente y accesibles solo por aplicaciones autorizadas.",
        "Question": "¿Cuál de las siguientes opciones debería implementar el Arquitecto de Soluciones para gestionar de manera segura los secretos y credenciales?",
        "Options": {
            "1": "Utilizar AWS Systems Manager Parameter Store para almacenar los secretos como parámetros SecureString y gestionar el acceso con políticas de IAM.",
            "2": "Usar AWS Secrets Manager para almacenar los secretos y configurar la rotación automática de estos secretos. Conceder permisos a la aplicación utilizando roles de IAM para acceder a Secrets Manager.",
            "3": "Usar Amazon S3 para almacenar los secretos en archivos encriptados y gestionar el acceso utilizando políticas de bucket.",
            "4": "Almacenar secretos directamente en el repositorio de código de la aplicación y usar roles de IAM para controlar el acceso al repositorio."
        },
        "Correct Answer": "Usar AWS Secrets Manager para almacenar los secretos y configurar la rotación automática de estos secretos. Conceder permisos a la aplicación utilizando roles de IAM para acceder a Secrets Manager.",
        "Explanation": "Usar AWS Secrets Manager permite la gestión centralizada de secretos, rotación automática y control de acceso detallado utilizando políticas de IAM. Este enfoque mejora la seguridad al eliminar secretos codificados en el código de la aplicación y asegurando que la información sensible solo sea accesible por servicios autorizados.",
        "Other Options": [
            "Almacenar secretos directamente en el repositorio de código de la aplicación presenta riesgos de seguridad significativos, ya que aumenta la probabilidad de exponer información sensible a través de sistemas de control de versiones o divulgaciones accidentales de código.",
            "Si bien AWS Systems Manager Parameter Store puede almacenar secretos de manera segura, carece de algunas de las características avanzadas de AWS Secrets Manager, como la rotación automática integrada y capacidades de auditoría, lo que lo convierte en una opción menos óptima para gestionar credenciales.",
            "Usar Amazon S3 para almacenar secretos en archivos encriptados no es una buena práctica para gestionar información sensible. S3 no proporciona características integradas de gestión de secretos como la rotación automática o la gestión del ciclo de vida, lo que lo hace menos adecuado en comparación con AWS Secrets Manager."
        ]
    },
    {
        "Question Number": "22",
        "Situation": "Una empresa minorista está experimentando problemas de rendimiento con sus tablas de DynamoDB debido a patrones de acceso desiguales en sus datos. Algunos elementos se acceden significativamente más que otros, lo que lleva a particiones calientes y limitaciones. La empresa necesita reorganizar su estructura de datos para optimizar la utilización de la capacidad de lectura y escritura mientras minimiza costos.",
        "Question": "¿Cuál es la estrategia más efectiva para mejorar el rendimiento de las tablas de DynamoDB mientras se asegura una distribución eficiente de la capacidad de lectura y escritura?",
        "Options": {
            "1": "Aumentar la capacidad de lectura y escritura provisionada para toda la tabla para manejar cargas máximas sin limitaciones.",
            "2": "Utilizar índices secundarios globales para desviar el tráfico de lectura de la tabla principal, distribuyendo así la carga entre diferentes particiones.",
            "3": "Implementar claves compuestas para permitir una mejor distribución de los datos entre particiones, reduciendo la probabilidad de particiones calientes.",
            "4": "Particionamiento sin fragmentos creando múltiples tablas para diferentes categorías de datos, aislando los patrones de acceso para prevenir particiones calientes."
        },
        "Correct Answer": "Implementar claves compuestas para permitir una mejor distribución de los datos entre particiones, reduciendo la probabilidad de particiones calientes.",
        "Explanation": "El uso de claves compuestas ayuda a distribuir los datos de manera uniforme entre las particiones, lo que aborda directamente el problema de las particiones calientes y optimiza el uso de la capacidad de lectura y escritura provisionada.",
        "Other Options": [
            "Aumentar la capacidad provisionada para toda la tabla puede aliviar temporalmente las limitaciones, pero no aborda el problema subyacente de los patrones de acceso de datos desiguales y puede llevar a un aumento de costos.",
            "Si bien los índices secundarios globales pueden ayudar a desviar parte del tráfico de lectura, pueden no resolver completamente el problema de las particiones calientes si los patrones de acceso de datos subyacentes siguen siendo desbalanceados.",
            "Crear múltiples tablas para el particionamiento sin fragmentos puede complicar la gestión de datos y las consultas, haciéndolo menos eficiente que optimizar la estructura de la tabla existente con claves compuestas."
        ]
    },
    {
        "Question Number": "23",
        "Situation": "Una empresa de servicios financieros está migrando sus aplicaciones existentes a AWS para mejorar la escalabilidad y reducir la sobrecarga operativa. La empresa necesita implementar una arquitectura de microservicios y está considerando usar servicios de contenedores. Quieren asegurarse de que sus aplicaciones en contenedores puedan escalar automáticamente y que la gestión de la infraestructura subyacente sea mínima.",
        "Question": "¿Qué combinación de servicios de AWS satisface mejor los requisitos de la empresa para implementar y gestionar aplicaciones en contenedores con una gestión mínima de infraestructura?",
        "Options": {
            "1": "Desplegar contenedores en Amazon ECR y gestionarlos con AWS Lambda para ejecución sin servidor y escalado automático.",
            "2": "Configurar Amazon ECS con Fargate para ejecutar contenedores y usar Amazon RDS para la gestión de bases de datos.",
            "3": "Utilizar Amazon ECS con tipo de lanzamiento EC2 para la orquestación de contenedores, gestionando las instancias EC2 manualmente para el escalado.",
            "4": "Usar Amazon EKS para la orquestación y AWS Fargate para ejecutar los contenedores sin gestionar las instancias EC2 subyacentes."
        },
        "Correct Answer": "Usar Amazon EKS para la orquestación y AWS Fargate para ejecutar los contenedores sin gestionar las instancias EC2 subyacentes.",
        "Explanation": "Usar Amazon EKS para la orquestación combinado con AWS Fargate permite a la empresa de servicios financieros desplegar aplicaciones en contenedores sin tener que gestionar las instancias EC2 subyacentes. Esta configuración proporciona la escalabilidad y eficiencia operativa necesarias para una arquitectura de microservicios.",
        "Other Options": [
            "Utilizar Amazon ECS con tipo de lanzamiento EC2 requiere gestionar las instancias EC2, lo que va en contra del requisito de minimizar la gestión de infraestructura.",
            "Desplegar contenedores en Amazon ECR y gestionarlos con AWS Lambda no es adecuado ya que Lambda está diseñado para funciones efímeras y basadas en eventos, no para aplicaciones en contenedores de larga duración.",
            "Configurar Amazon ECS con Fargate para ejecutar contenedores y usar Amazon RDS para la gestión de bases de datos no proporciona capacidades de orquestación tan efectivas como Amazon EKS, que es más adecuado para arquitecturas de microservicios complejas."
        ]
    },
    {
        "Question Number": "24",
        "Situation": "Una empresa de servicios financieros está construyendo un sistema de procesamiento en tiempo real que necesita manejar millones de transacciones por segundo con una latencia mínima. El sistema debe asegurar que los mensajes no se pierdan y puedan ser procesados en orden. La empresa quiere incorporar una solución de mensajería que almacene mensajes y permita que los componentes de la aplicación se comuniquen de manera asíncrona.",
        "Question": "¿Qué servicio de AWS debería implementar la empresa para cumplir con los requisitos de alto rendimiento, durabilidad de mensajes y procesamiento de mensajes en orden?",
        "Options": {
            "1": "Amazon SNS con filtrado de mensajes",
            "2": "Amazon SQS con colas FIFO",
            "3": "AWS Step Functions con flujos de trabajo paralelos",
            "4": "Amazon EventBridge con eventos personalizados"
        },
        "Correct Answer": "Amazon SQS con colas FIFO",
        "Explanation": "Amazon SQS con colas FIFO está diseñado para permitir un procesamiento de mensajes de alto rendimiento y en orden, asegurando que los mensajes no se pierdan. Las colas FIFO proporcionan procesamiento exactamente una vez y mantienen el orden de los mensajes, lo que lo hace ideal para este caso de uso.",
        "Other Options": [
            "Amazon SNS con filtrado de mensajes es principalmente un servicio de mensajería pub/sub que no garantiza el orden de los mensajes y no proporciona durabilidad para los mensajes de la misma manera que lo hace SQS.",
            "Amazon EventBridge con eventos personalizados es adecuado para arquitecturas basadas en eventos, pero no ofrece el mismo nivel de durabilidad y orden de mensajes que proporcionan las colas FIFO de SQS.",
            "AWS Step Functions con flujos de trabajo paralelos se utiliza para orquestar microservicios, pero no es un servicio de mensajería y no proporciona las capacidades requeridas de durabilidad y procesamiento en orden."
        ]
    },
    {
        "Question Number": "25",
        "Situation": "Una empresa de servicios financieros necesita asegurar alta disponibilidad para su aplicación web alojada en AWS. La aplicación requiere acceso de baja latencia a una base de datos y debe ser resiliente ante fallos regionales. El arquitecto de soluciones tiene la tarea de diseñar una solución que utilice servicios administrados de AWS para un rendimiento y confiabilidad óptimos.",
        "Question": "¿Qué arquitectura cumplirá mejor con los requisitos de la empresa para alta disponibilidad y baja latencia?",
        "Options": {
            "1": "Implementar la aplicación utilizando AWS Lambda para el cómputo y Amazon S3 para contenido estático, con una base de datos Amazon Aurora Serverless en múltiples Regiones.",
            "2": "Crear un clúster de Amazon ECS con tipo de lanzamiento Fargate en una única Zona de Disponibilidad, utilizando Amazon DynamoDB para el almacenamiento de datos.",
            "3": "Usar AWS Elastic Beanstalk para desplegar la aplicación en múltiples Zonas de Disponibilidad, con Amazon RDS en una configuración Multi-AZ para la base de datos.",
            "4": "Desplegar la aplicación en instancias de Amazon EC2 en una única Zona de Disponibilidad con un despliegue Multi-AZ de Amazon RDS para la base de datos."
        },
        "Correct Answer": "Usar AWS Elastic Beanstalk para desplegar la aplicación en múltiples Zonas de Disponibilidad, con Amazon RDS en una configuración Multi-AZ para la base de datos.",
        "Explanation": "Usar AWS Elastic Beanstalk con despliegue en múltiples Zonas de Disponibilidad asegura que la aplicación pueda soportar la falla de una zona mientras proporciona acceso de baja latencia a través de balanceo de carga y escalado automáticos. Junto con Amazon RDS en una configuración Multi-AZ, esta arquitectura también proporciona alta disponibilidad para la base de datos.",
        "Other Options": [
            "Desplegar la aplicación en una única Zona de Disponibilidad puede llevar a un tiempo de inactividad potencial si esa zona falla, lo que no satisface el requisito de alta disponibilidad.",
            "Usar Amazon ECS en una única Zona de Disponibilidad limita la capacidad de la aplicación para permanecer disponible durante una falla de zona, y aunque DynamoDB ofrece alta disponibilidad, puede no proporcionar las características necesarias de base de datos relacional requeridas para la aplicación.",
            "Implementar la aplicación con AWS Lambda y Amazon S3 es adecuado para arquitecturas sin servidor, pero puede introducir problemas de latencia para el acceso a la base de datos, y depender de una única Región podría comprometer la disponibilidad si la Región experimenta problemas."
        ]
    },
    {
        "Question Number": "26",
        "Situation": "Una empresa emergente está desplegando una aplicación de aprendizaje automático en AWS que procesará grandes volúmenes de datos diariamente. La aplicación utilizará Amazon SageMaker para el entrenamiento e inferencia de modelos. La empresa espera escalar la aplicación rápidamente debido al crecimiento anticipado en la demanda de usuarios. El equipo está preocupado por alcanzar los límites de servicio de AWS, lo que podría afectar el rendimiento y la disponibilidad.",
        "Question": "¿Cuál es el mejor enfoque para gestionar las cuotas y límites de servicio en este escenario para asegurar que la aplicación se mantenga eficiente a medida que escala?",
        "Options": {
            "1": "Monitorear regularmente los límites de servicio utilizando AWS CloudTrail y solicitar aumentos de límite a través del Centro de Soporte de AWS según sea necesario.",
            "2": "Utilizar un servicio de AWS que escale automáticamente los recursos sin necesidad de monitorear cuotas, asegurando que nunca se alcancen límites de servicio.",
            "3": "Configurar Alarmas de CloudWatch para notificar al equipo cuando se acerquen a los límites de servicio, permitiendo ajustes reactivos a medida que se alcanzan los límites.",
            "4": "Establecer una estrategia proactiva creando un calendario para solicitar aumentos de límite basados en estimaciones de uso proyectadas antes de alcanzar los límites actuales."
        },
        "Correct Answer": "Establecer una estrategia proactiva creando un calendario para solicitar aumentos de límite basados en estimaciones de uso proyectadas antes de alcanzar los límites actuales.",
        "Explanation": "Este enfoque permite a la empresa anticipar el crecimiento y gestionar proactivamente los límites de servicio, asegurando que no haya interrupciones en el servicio a medida que aumenta la demanda. Al planificar con anticipación, la empresa puede enviar solicitudes de aumentos de límite de manera oportuna, manteniendo la aplicación eficiente y disponible.",
        "Other Options": [
            "Si bien monitorear los límites de servicio utilizando AWS CloudTrail es importante, depender únicamente de esto sin una gestión proactiva puede llevar a interrupciones inesperadas del servicio cuando se alcanzan los límites.",
            "Ningún servicio de AWS puede escalar automáticamente los recursos sin límites; todos los servicios tienen cuotas predefinidas que requieren monitoreo y gestión. Suponer lo contrario puede llevar a una sobreutilización y fallos en el servicio.",
            "Configurar Alarmas de CloudWatch puede proporcionar notificaciones cuando se alcanzan los límites, pero este es un enfoque reactivo. No previene que ocurran problemas cuando se superan los límites, lo que podría afectar el rendimiento de la aplicación."
        ]
    },
    {
        "Question Number": "27",
        "Situation": "Una organización está desplegando una arquitectura de microservicios utilizando Amazon ECS con Fargate. Cada microservicio requiere acceso a varios recursos de AWS, como obtener imágenes de Amazon ECR y leer secretos almacenados en AWS Secrets Manager. El equipo de DevOps necesita asegurarse de que las tareas de ECS tengan los permisos apropiados sin otorgar derechos excesivos a las instancias de EC2 subyacentes. El equipo está considerando la implementación de roles de ejecución de tareas para este propósito.",
        "Question": "¿Cuál de las siguientes configuraciones debería implementar el arquitecto de soluciones para asegurar las mejores prácticas para la ejecución de tareas de ECS? (Seleccione Dos)",
        "Options": {
            "1": "Adjuntar el rol de ejecución de tareas a las tareas de Fargate para permitirles obtener imágenes de Amazon ECR.",
            "2": "Definir roles de ejecución de tareas separados para diferentes microservicios para limitar el alcance de los permisos.",
            "3": "Usar un perfil de instancia de EC2 para otorgar permisos a las tareas de ECS para acceder a Secrets Manager.",
            "4": "Crear un único rol de ejecución de tareas con permisos para acceder a todos los recursos de AWS requeridos para todos los servicios.",
            "5": "Permitir que las tareas de ECS registren directamente en Amazon S3 en lugar de usar CloudWatch Logs."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Adjuntar el rol de ejecución de tareas a las tareas de Fargate para permitirles obtener imágenes de Amazon ECR.",
            "Definir roles de ejecución de tareas separados para diferentes microservicios para limitar el alcance de los permisos."
        ],
        "Explanation": "Adjuntar un rol de ejecución de tareas a las tareas de Fargate les permite realizar acciones específicas como obtener imágenes de contenedor de Amazon ECR mientras se adhiere al principio de menor privilegio. Definir roles separados para diferentes microservicios asegura que cada servicio solo tenga acceso a los permisos que necesita, mejorando aún más la seguridad y el cumplimiento.",
        "Other Options": [
            "Crear un único rol de ejecución de tareas con permisos amplios viola el principio de menor privilegio y puede exponer recursos innecesarios a un posible uso indebido.",
            "Usar un perfil de instancia de EC2 para tareas de ECS socava los beneficios de los roles de ejecución de tareas, ya que otorga permisos a la instancia de EC2 en lugar de a la tarea misma, lo que lleva a permisos excesivos.",
            "Registrar directamente en Amazon S3 en lugar de usar CloudWatch Logs no es una práctica recomendada, ya que complica la gestión y monitoreo de registros, que se simplifican utilizando CloudWatch Logs."
        ]
    },
    {
        "Question Number": "28",
        "Situation": "Una empresa de servicios financieros necesita gestionar su flota de instancias EC2 en múltiples entornos (desarrollo, pruebas, producción) mientras asegura el cumplimiento de las políticas de seguridad y automatiza las actualizaciones de software. La empresa requiere una solución centralizada para la gestión de configuraciones que ofrezca visibilidad sobre el estado de las instancias y pueda corregir automáticamente cualquier desviación del estado deseado.",
        "Question": "¿Qué herramienta de gestión de configuraciones debería recomendar el arquitecto de soluciones para cumplir con los requisitos de la empresa?",
        "Options": {
            "1": "Utilizar AWS Systems Manager para automatizar el despliegue de parches y gestionar el estado de las instancias EC2 en todos los entornos, asegurando el cumplimiento y la seguridad.",
            "2": "Implementar Ansible para la gestión de configuraciones, pero desplegarlo y gestionarlo en instancias EC2 para manejar el cumplimiento y las actualizaciones de software en los entornos.",
            "3": "Utilizar Chef en una configuración de servidor autogestionado para automatizar la configuración de las instancias EC2, proporcionando visibilidad y cumplimiento en todos los entornos.",
            "4": "Adoptar Puppet para la gestión de configuraciones, pero limitar su uso solo al entorno de producción para asegurar el cumplimiento de seguridad."
        },
        "Correct Answer": "Utilizar AWS Systems Manager para automatizar el despliegue de parches y gestionar el estado de las instancias EC2 en todos los entornos, asegurando el cumplimiento y la seguridad.",
        "Explanation": "AWS Systems Manager es un servicio completamente gestionado que proporciona visibilidad y control de su infraestructura en AWS. Permite automatizar tareas como la gestión de parches y las verificaciones de cumplimiento en diferentes entornos, lo que lo hace ideal para gestionar instancias EC2 de manera centralizada.",
        "Other Options": [
            "Ansible requiere una configuración de servidor de gestión, lo que añade complejidad y no proporciona el mismo nivel de integración con los servicios de AWS que Systems Manager.",
            "Utilizar Chef en una configuración de servidor autogestionado introduce una sobrecarga adicional en la gestión del servidor Chef y no aprovecha las características nativas de AWS para el cumplimiento y la automatización.",
            "Puppet es una herramienta de gestión de configuraciones capaz, pero limitar su uso solo al entorno de producción no cumple con el requisito de gestionar todos los entornos de manera consistente."
        ]
    },
    {
        "Question Number": "29",
        "Situation": "Una empresa de servicios financieros está migrando sus cargas de trabajo analíticas a AWS. Las cargas de trabajo implican procesar grandes volúmenes de datos estructurados y semi-estructurados de diversas fuentes, incluyendo bases de datos SQL y archivos JSON. La empresa requiere una solución que proporcione un alto rendimiento, baja latencia y la capacidad de consultar fácilmente los datos utilizando una sintaxis similar a SQL. Además, la solución debe ser altamente disponible y escalable para acomodar cargas de trabajo fluctuantes sin una complejidad de gestión.",
        "Question": "¿Cuál de los siguientes servicios de almacenamiento cumpliría mejor con los requisitos de la empresa para estas cargas de trabajo analíticas?",
        "Options": {
            "1": "Utilizar Amazon ElastiCache para Redis para almacenar en caché los datos en memoria y servirlos a aplicaciones analíticas para un acceso de baja latencia.",
            "2": "Desplegar Amazon Redshift como una solución de almacenamiento de datos, ingiriendo los datos de diversas fuentes para consultas y análisis complejos.",
            "3": "Implementar Amazon RDS con réplicas de lectura para manejar las consultas analíticas y almacenar los datos en un formato relacional.",
            "4": "Usar Amazon S3 para almacenar los datos y Amazon Athena para consultar los datos directamente desde S3 usando SQL."
        },
        "Correct Answer": "Usar Amazon S3 para almacenar los datos y Amazon Athena para consultar los datos directamente desde S3 usando SQL.",
        "Explanation": "Utilizar Amazon S3 junto con Amazon Athena permite a la empresa almacenar grandes volúmenes de datos estructurados y semi-estructurados de manera eficiente y consultarlos sin necesidad de aprovisionar o gestionar infraestructura. La capacidad de consulta similar a SQL de Athena cumple con el requisito de facilidad de uso, mientras que S3 proporciona alta durabilidad y disponibilidad.",
        "Other Options": [
            "Implementar Amazon RDS con réplicas de lectura puede proporcionar algo de escalabilidad, pero no es ideal para manejar grandes volúmenes de datos semi-estructurados y puede introducir una sobrecarga de gestión asociada con las instancias de base de datos.",
            "Utilizar Amazon ElastiCache para Redis está diseñado para almacenamiento en caché y no sería adecuado para almacenar grandes conjuntos de datos, ya que se utiliza principalmente para la recuperación de datos de baja latencia en lugar de procesamiento analítico.",
            "Desplegar Amazon Redshift es una buena opción para almacenamiento de datos, pero requiere aprovisionar y gestionar un almacén de datos, lo que puede no ser tan flexible o rentable como usar S3 y Athena para cargas de trabajo fluctuantes."
        ]
    },
    {
        "Question Number": "30",
        "Situation": "Una startup está desarrollando una aplicación de análisis en tiempo real que procesa grandes volúmenes de datos en streaming de diversas fuentes. La aplicación debe asegurar baja latencia y alto rendimiento mientras mantiene la capacidad de escalar a medida que aumenta el volumen de datos. La startup está considerando los servicios de AWS para un rendimiento óptimo.",
        "Question": "¿Qué arquitectura de servicio de AWS debería implementar la startup para lograr el mejor rendimiento para su aplicación de análisis en streaming?",
        "Options": {
            "1": "Implementar Amazon Kinesis Data Firehose para la ingesta, instancias de Amazon EC2 para el procesamiento y Amazon RDS para almacenar los resultados.",
            "2": "Aprovechar Amazon Kinesis Data Streams para la ingesta, AWS Glue para el procesamiento ETL y Amazon Redshift para consultas analíticas.",
            "3": "Utilizar Amazon Kinesis Data Analytics para el procesamiento en tiempo real, Amazon SQS para el almacenamiento en búfer y Amazon DynamoDB para el almacenamiento de datos.",
            "4": "Usar Amazon Kinesis Data Streams para la ingesta, AWS Lambda para el procesamiento y Amazon S3 para el almacenamiento de datos procesados."
        },
        "Correct Answer": "Aprovechar Amazon Kinesis Data Streams para la ingesta, AWS Glue para el procesamiento ETL y Amazon Redshift para consultas analíticas.",
        "Explanation": "Esta opción proporciona una arquitectura robusta para manejar datos en streaming en tiempo real con baja latencia. Kinesis Data Streams permite una ingesta de datos de alto rendimiento, mientras que AWS Glue proporciona capacidades ETL eficientes para transformar los datos. Amazon Redshift puede manejar consultas analíticas complejas sobre los datos procesados a gran escala, asegurando un rendimiento óptimo para cargas de trabajo analíticas.",
        "Other Options": [
            "Esta opción no es ideal ya que usar AWS Lambda para el procesamiento puede introducir problemas de latencia para el procesamiento de datos en tiempo real debido al problema de inicio en frío y límites en el tiempo de ejecución, lo que la hace menos adecuada para escenarios de alto rendimiento.",
            "Si bien esta opción permite la ingesta y el procesamiento de datos, usar Amazon EC2 para el procesamiento no proporciona el mismo nivel de escalabilidad y facilidad de uso que los servicios de streaming gestionados, lo que puede llevar a cuellos de botella en el rendimiento bajo alta carga.",
            "Esta opción es incorrecta porque usar Amazon SQS para el almacenamiento en búfer no está diseñado para el procesamiento de datos en tiempo real y puede introducir retrasos, mientras que Kinesis Data Analytics es más adecuado para los requisitos en tiempo real de la aplicación de análisis."
        ]
    },
    {
        "Question Number": "31",
        "Situation": "Una startup de atención médica está buscando alojar una aplicación de aprendizaje automático que requiere un poder computacional significativo para entrenar modelos. Se espera que la aplicación escale dinámicamente según la carga de trabajo, y el equipo quiere minimizar la sobrecarga operativa mientras mantiene flexibilidad en la gestión de la asignación de recursos. Están considerando varios servicios de computación de AWS para satisfacer estas necesidades.",
        "Question": "¿Cuál de los siguientes servicios de AWS proporciona la plataforma de computación más adecuada para la aplicación de aprendizaje automático de la startup, considerando la necesidad de escalabilidad y una mínima sobrecarga de gestión?",
        "Options": {
            "1": "AWS Lambda para ejecutar inferencias de aprendizaje automático en una arquitectura sin servidor.",
            "2": "Amazon Lightsail para desplegar un servidor privado virtual para ejecutar aplicaciones de aprendizaje automático.",
            "3": "Amazon ECS con Fargate para ejecutar cargas de trabajo de aprendizaje automático en contenedores sin gestionar servidores.",
            "4": "Amazon EC2 con grupos de Auto Scaling para gestionar la escalabilidad de instancias según la demanda."
        },
        "Correct Answer": "Amazon ECS con Fargate para ejecutar cargas de trabajo de aprendizaje automático en contenedores sin gestionar servidores.",
        "Explanation": "Amazon ECS con Fargate permite a la startup ejecutar aplicaciones en contenedores sin necesidad de gestionar las máquinas virtuales subyacentes, proporcionando la simplicidad operativa y escalabilidad deseadas para las cargas de trabajo de aprendizaje automático. Fargate aprovisiona y escala automáticamente los recursos de computación, lo que lo hace ideal para cargas de trabajo fluctuantes típicas en aplicaciones de aprendizaje automático.",
        "Other Options": [
            "Amazon EC2 con grupos de Auto Scaling requiere más esfuerzo de gestión para configurar y mantener las instancias de EC2, lo que podría aumentar la sobrecarga operativa en comparación con un servicio completamente gestionado como Fargate.",
            "AWS Lambda es adecuado para ejecutar tareas de corta duración, pero puede no ser ideal para procesos de entrenamiento de aprendizaje automático de larga duración, que requieren recursos de computación más consistentes durante períodos prolongados.",
            "Amazon Lightsail está diseñado para aplicaciones web y cargas de trabajo más simples y no proporciona el mismo nivel de escalabilidad y flexibilidad necesarios para aplicaciones complejas de aprendizaje automático en comparación con ECS con Fargate."
        ]
    },
    {
        "Question Number": "32",
        "Situation": "Una empresa de servicios financieros está planeando desplegar una nueva aplicación que se espera que experimente cargas de trabajo variables. La aplicación debe estar diseñada para escalar de manera eficiente para manejar tanto picos repentinos como aumentos sostenidos en el tráfico. El arquitecto de soluciones está evaluando opciones para escalar la aplicación y satisfacer estas demandas mientras optimiza costos y rendimiento. El arquitecto necesita elegir entre estrategias de escalado vertical (escalar hacia arriba) y escalado horizontal (escalar hacia afuera) para la arquitectura de la aplicación.",
        "Question": "¿Cuál de las siguientes estrategias debería recomendar el arquitecto de soluciones para asegurar que la aplicación pueda manejar cargas de trabajo variables de la manera más efectiva?",
        "Options": {
            "1": "Diseñar la aplicación con un enfoque de escalado horizontal distribuyendo la carga entre múltiples instancias, permitiendo la adición o eliminación de instancias según la demanda.",
            "2": "Elegir una arquitectura sin servidor que escale automáticamente según el volumen de solicitudes, eliminando la necesidad de gestionar tamaños o números de instancias.",
            "3": "Implementar una estrategia de escalado vertical utilizando instancias más grandes para los servidores de la aplicación, asegurando que tengan más recursos de CPU y memoria para acomodar cargas máximas.",
            "4": "Utilizar un enfoque híbrido que combine escalado vertical y horizontal, permitiendo el redimensionamiento de instancias y la adición de múltiples instancias según sea necesario."
        },
        "Correct Answer": "Diseñar la aplicación con un enfoque de escalado horizontal distribuyendo la carga entre múltiples instancias, permitiendo la adición o eliminación de instancias según la demanda.",
        "Explanation": "Diseñar la aplicación con un enfoque de escalado horizontal permite manejar de manera efectiva las cargas de trabajo variables al distribuir el tráfico entre múltiples instancias. Este método puede acomodar picos repentinos en la carga de manera más dinámica y rentable que simplemente aumentar el tamaño de una sola instancia.",
        "Other Options": [
            "Implementar una estrategia de escalado vertical puede limitar la flexibilidad de la aplicación y podría llevar a costos más altos si se utiliza una sola instancia para acomodar cargas máximas, lo que podría no ser necesario durante períodos de tráfico más bajo.",
            "Utilizar un enfoque híbrido puede introducir complejidad en la gestión y no necesariamente optimiza el método de escalado más efectivo dado los requisitos de carga de trabajo variable.",
            "Elegir una arquitectura sin servidor puede ser beneficioso, pero puede no ser adecuada para todos los tipos de aplicaciones, especialmente aquellas que requieren configuraciones específicas de instancias o servicios con estado que no están completamente gestionados en un modelo sin servidor."
        ]
    },
    {
        "Question Number": "33",
        "Situation": "Una plataforma de comercio electrónico global está planeando expandir sus servicios a múltiples regiones para mejorar la latencia y disponibilidad para sus clientes. Necesitan determinar la mejor estrategia para seleccionar las Regiones y Zonas de Disponibilidad de AWS que aseguren un rendimiento óptimo de la red, considerando los posibles problemas de latencia para los usuarios ubicados en América del Norte, Europa y Asia. La plataforma actualmente opera en una sola Región de AWS.",
        "Question": "¿Cuál es el mejor enfoque para seleccionar Regiones y Zonas de Disponibilidad de AWS para la expansión de la plataforma de comercio electrónico para minimizar la latencia y optimizar el rendimiento de la red?",
        "Options": {
            "1": "Seleccionar una sola Región de AWS y desplegar recursos en todas las Zonas de Disponibilidad disponibles dentro de esa Región para asegurar la máxima redundancia.",
            "2": "Elegir la Región de AWS más cercana a la sede de la empresa y replicar recursos en sus Zonas de Disponibilidad.",
            "3": "Desplegar recursos en múltiples Regiones de AWS que estén geográficamente cerca de los clientes en América del Norte, Europa y Asia.",
            "4": "Utilizar AWS Global Accelerator para dirigir el tráfico a la Región de AWS más cercana según la ubicación del usuario."
        },
        "Correct Answer": "Desplegar recursos en múltiples Regiones de AWS que estén geográficamente cerca de los clientes en América del Norte, Europa y Asia.",
        "Explanation": "Al desplegar recursos en múltiples Regiones de AWS que estén geográficamente cerca de los clientes, la plataforma de comercio electrónico puede reducir significativamente la latencia y mejorar el rendimiento de la red. Esta estrategia permite una arquitectura distribuida que atiende a usuarios en diferentes ubicaciones geográficas, asegurando una mejor experiencia de usuario.",
        "Other Options": [
            "Si bien seleccionar una sola Región de AWS y desplegar recursos en todas sus Zonas de Disponibilidad ofrece redundancia, no aborda las preocupaciones de latencia para los usuarios ubicados lejos de esa Región. Esto podría llevar a un rendimiento subóptimo para los usuarios en diferentes partes del mundo.",
            "Elegir la Región de AWS más cercana a la sede de la empresa puede no servir de manera efectiva a los clientes ubicados en otras regiones, lo que podría resultar en una mayor latencia para esos usuarios. Es crucial considerar la distribución geográfica en lugar de la proximidad a la sede.",
            "Utilizar AWS Global Accelerator puede mejorar la disponibilidad y el rendimiento de la aplicación al dirigir el tráfico, pero no resuelve la necesidad fundamental de desplegar recursos en múltiples Regiones para abordar directamente los problemas de latencia. Confiar únicamente en Global Accelerator puede no proporcionar la solución óptima para la distribución geográfica."
        ]
    },
    {
        "Question Number": "34",
        "Situation": "Una empresa está planeando migrar grandes volúmenes de datos a Amazon S3 desde diversas ubicaciones geográficas. Quieren asegurarse de que la transferencia de datos sea eficiente y minimice los tiempos de carga, especialmente para los clientes que están lejos de la región del bucket de S3. ¿Qué servicio de AWS puede ayudar a optimizar este proceso de transferencia de datos?",
        "Question": "¿Qué característica de Amazon S3 debería habilitar el arquitecto de soluciones para facilitar cargas de datos más rápidas a largas distancias?",
        "Options": {
            "1": "Clase de Almacenamiento Estándar de Amazon S3 para todos los objetos para mejorar la disponibilidad.",
            "2": "Políticas de Ciclo de Vida de Amazon S3 para gestionar la retención de datos y transiciones.",
            "3": "Versionado de Amazon S3 para asegurar que todas las cargas de datos sean retenidas y recuperables.",
            "4": "Aceleración de Transferencia de Amazon S3 para aprovechar las ubicaciones de borde de CloudFront para transferencias optimizadas."
        },
        "Correct Answer": "Aceleración de Transferencia de Amazon S3 para aprovechar las ubicaciones de borde de CloudFront para transferencias optimizadas.",
        "Explanation": "La Aceleración de Transferencia de Amazon S3 utiliza la red de borde de Amazon CloudFront para acelerar las cargas de datos a S3 desde largas distancias. Esta característica optimiza la ruta de la red para reducir la latencia y mejorar significativamente las velocidades de transferencia.",
        "Other Options": [
            "La Clase de Almacenamiento Estándar de Amazon S3 mejora la disponibilidad, pero no impacta la velocidad de transferencia de datos a largas distancias.",
            "El Versionado de Amazon S3 es útil para la recuperación y gestión de datos, pero no mejora la velocidad de las cargas de datos.",
            "Las Políticas de Ciclo de Vida de Amazon S3 gestionan la retención de datos y transiciones entre clases de almacenamiento, pero no influyen en la velocidad de las transferencias de datos."
        ]
    },
    {
        "Question Number": "35",
        "Situation": "Una empresa de servicios financieros está buscando automatizar el despliegue de su infraestructura en AWS. El equipo quiere asegurarse de que la infraestructura se aprovisione y gestione de manera consistente, con la capacidad de controlar versiones y reutilizar plantillas. Están considerando usar AWS CloudFormation para lograr este objetivo.",
        "Question": "¿Qué enfoque proporcionaría la mejor solución para automatizar el despliegue de la infraestructura mientras se asegura que sea mantenible y repetible?",
        "Options": {
            "1": "Implementar AWS CloudFormation para definir toda la infraestructura como código en formato JSON o YAML, incluyendo instancias de EC2, configuración de VPC y grupos de seguridad. Usar el Diseñador de CloudFormation para visualizar y gestionar las plantillas.",
            "2": "Utilizar AWS Elastic Beanstalk para gestionar el entorno de la aplicación mientras se confía en CloudFormation solo para configurar las bases de datos y componentes de red. Evitar usar control de versiones para las plantillas de CloudFormation.",
            "3": "Crear un conjunto de plantillas de AWS CloudFormation que incluyan pilas anidadas para gestionar diferentes componentes de la infraestructura. Usar AWS CodePipeline para desplegar las plantillas, asegurando control de versiones y actualizaciones automatizadas.",
            "4": "Provisionar manualmente la infraestructura utilizando la Consola de Administración de AWS para cada entorno mientras se documentan los ajustes en una wiki interna. Usar scripts para automatizar solo el despliegue del código de la aplicación."
        },
        "Correct Answer": "Crear un conjunto de plantillas de AWS CloudFormation que incluyan pilas anidadas para gestionar diferentes componentes de la infraestructura. Usar AWS CodePipeline para desplegar las plantillas, asegurando control de versiones y actualizaciones automatizadas.",
        "Explanation": "Al crear un conjunto de plantillas de AWS CloudFormation con pilas anidadas, la empresa puede descomponer la infraestructura en componentes manejables, facilitando su mantenimiento y actualización. Integrar AWS CodePipeline asegura que los despliegues sean automatizados, consistentes y controlados por versiones, alineándose con las mejores prácticas para infraestructura como código.",
        "Other Options": [
            "Esta opción depende de la provisión manual, lo que introduce el riesgo de inconsistencia y error humano. No aprovecha las capacidades completas de CloudFormation para gestionar infraestructura como código.",
            "Si bien Elastic Beanstalk simplifica la gestión de aplicaciones, confiar en CloudFormation solo para componentes específicos socava los beneficios de usar infraestructura como código. Además, no usar control de versiones puede llevar a desafíos en la gestión de cambios a lo largo del tiempo.",
            "Usar pilas anidadas es beneficioso, pero omitir CodePipeline significa que el proceso de despliegue carece de automatización y control de versiones, que son críticos para mantener una infraestructura consistente en todos los entornos."
        ]
    },
    {
        "Question Number": "36",
        "Situation": "Una empresa está migrando sus aplicaciones heredadas a AWS y necesita asegurarse de que las aplicaciones puedan escalar según la demanda sin intervención manual. Las aplicaciones son principalmente basadas en la web y requieren un entorno confiable para el despliegue. El arquitecto de soluciones necesita elegir un servicio que pueda manejar automáticamente el escalado, el balanceo de carga y la monitorización de la salud de la aplicación.",
        "Question": "¿Cuál de los siguientes servicios de AWS debería recomendar el arquitecto de soluciones para cumplir con los requisitos de la empresa para desplegar las aplicaciones?",
        "Options": {
            "1": "Utilizar funciones de AWS Lambda con Amazon API Gateway para ejecutar las aplicaciones web sin servidor y escalar automáticamente según la demanda.",
            "2": "Implementar Amazon ECS con Fargate para ejecutar contenedores Docker para las aplicaciones y gestionar el escalado y el balanceo de carga.",
            "3": "Usar grupos de Auto Scaling de Amazon EC2 con Elastic Load Balancing para gestionar el escalado y el balanceo de carga de las aplicaciones web.",
            "4": "Desplegar las aplicaciones en AWS Elastic Beanstalk, que maneja automáticamente el escalado, el balanceo de carga y la monitorización de la salud."
        },
        "Correct Answer": "Desplegar las aplicaciones en AWS Elastic Beanstalk, que maneja automáticamente el escalado, el balanceo de carga y la monitorización de la salud.",
        "Explanation": "AWS Elastic Beanstalk está diseñado para facilitar el despliegue y la gestión de aplicaciones web sin requerir una gestión extensa de infraestructura. Proporciona automáticamente los recursos necesarios, maneja el escalado según la demanda e incluye características integradas de balanceo de carga y monitorización de salud, lo que lo convierte en la mejor opción para los requisitos de la empresa.",
        "Other Options": [
            "Si bien usar grupos de Auto Scaling de Amazon EC2 con Elastic Load Balancing puede gestionar el escalado y el balanceo de carga de manera efectiva, requiere más configuración y gestión manual en comparación con Elastic Beanstalk, lo que lo hace menos ideal para las necesidades de la empresa.",
            "AWS Lambda con Amazon API Gateway es adecuado para aplicaciones sin servidor, pero puede no ser apropiado para aplicaciones web tradicionales que requieren conexiones con estado o configuraciones de servidor específicas, que Elastic Beanstalk puede manejar.",
            "Amazon ECS con Fargate permite que las aplicaciones en contenedores escalen automáticamente, pero puede requerir una arquitectura y gestión más complejas en comparación con las capacidades de despliegue directo de Elastic Beanstalk."
        ]
    },
    {
        "Question Number": "37",
        "Situation": "Una empresa de servicios financieros enfrenta vulnerabilidades de seguridad en su arquitectura de aplicaciones, lo que ha llevado a múltiples violaciones de datos. La empresa necesita evaluar soluciones de remediación potenciales para abordar estos problemas de seguridad mientras mantiene el cumplimiento con las regulaciones de la industria. Un equipo de evaluación de seguridad ha sido encargado de probar diferentes soluciones y hacer recomendaciones para mejorar la postura de seguridad general de la aplicación.",
        "Question": "¿Cuál de las siguientes opciones es la mejor recomendación para que la empresa implemente como solución de remediación para mejorar la seguridad de la aplicación?",
        "Options": {
            "1": "Implementar AWS WAF para proteger la aplicación de explotaciones web comunes y configurarlo para bloquear solicitudes maliciosas basadas en reglas predefinidas.",
            "2": "Habilitar AWS Shield Advanced para protección DDoS y configurar CloudTrail para monitorear el uso de la API en toda la aplicación.",
            "3": "Utilizar AWS Secrets Manager para almacenar y gestionar de manera segura información sensible, como claves API y credenciales de base de datos, utilizadas por la aplicación.",
            "4": "Desplegar Amazon Inspector para escanear la aplicación en busca de vulnerabilidades y generar informes detallados para auditorías de cumplimiento."
        },
        "Correct Answer": "Implementar AWS WAF para proteger la aplicación de explotaciones web comunes y configurarlo para bloquear solicitudes maliciosas basadas en reglas predefinidas.",
        "Explanation": "Implementar AWS WAF proporcionará protección inmediata contra vulnerabilidades web comunes, mejorando significativamente la seguridad de la aplicación. Configurarlo con reglas apropiadas puede ayudar a mitigar riesgos de ataques comunes como inyección SQL y scripting entre sitios.",
        "Other Options": [
            "Desplegar Amazon Inspector se centra principalmente en identificar vulnerabilidades, pero no proporciona protección en tiempo real contra ataques, lo que lo hace menos efectivo como solución de remediación independiente.",
            "Habilitar AWS Shield Advanced es útil para la protección DDoS, pero no aborda el rango más amplio de vulnerabilidades de aplicaciones web que AWS WAF puede mitigar.",
            "Utilizar AWS Secrets Manager es importante para gestionar credenciales sensibles, pero no protege directamente la aplicación de ataques externos, lo cual es un aspecto crítico de los requisitos de seguridad de la empresa."
        ]
    },
    {
        "Question Number": "38",
        "Situation": "Una empresa de servicios financieros está migrando sus aplicaciones a AWS. Manejan datos sensibles de clientes y requieren medidas de cifrado robustas tanto para datos en reposo como en tránsito. La empresa quiere asegurar el cumplimiento con las regulaciones de la industria mientras optimiza el rendimiento.",
        "Question": "¿Cuál de las siguientes estrategias debería implementar la empresa para asegurar un manejo seguro de los datos? (Seleccione Dos)",
        "Options": {
            "1": "Utilizar cifrado del lado del cliente para los datos antes de subirlos a Amazon S3.",
            "2": "Implementar cifrado SSL/TLS entre el cliente y el balanceador de carga para asegurar los datos en tránsito.",
            "3": "Usar AWS Key Management Service (KMS) para gestionar las claves de cifrado para datos en reposo en Amazon S3.",
            "4": "Almacenar datos sensibles en texto plano en Amazon RDS para optimizar el rendimiento de las consultas.",
            "5": "Configurar Amazon RDS para usar cifrado en reposo utilizando las claves gestionadas por AWS por defecto."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Usar AWS Key Management Service (KMS) para gestionar las claves de cifrado para datos en reposo en Amazon S3.",
            "Implementar cifrado SSL/TLS entre el cliente y el balanceador de carga para asegurar los datos en tránsito."
        ],
        "Explanation": "Utilizar AWS Key Management Service (KMS) permite a la empresa gestionar y controlar las claves de cifrado utilizadas para cifrar datos en reposo en Amazon S3, asegurando que los datos sensibles estén adecuadamente protegidos. Implementar cifrado SSL/TLS entre el cliente y el balanceador de carga asegura los datos en tránsito, protegiéndolos de la interceptación y asegurando el cumplimiento con las regulaciones de la industria.",
        "Other Options": [
            "Almacenar datos sensibles en texto plano en Amazon RDS es un riesgo de seguridad significativo y no cumple con los requisitos de cifrado. Esta opción no protege adecuadamente los datos de los clientes.",
            "El cifrado del lado del cliente añade complejidad y puede introducir una sobrecarga adicional para la gestión de datos. Si bien mejora la seguridad, no es necesario si se utilizan eficazmente las opciones de cifrado gestionadas por AWS.",
            "Usar las claves gestionadas por AWS por defecto para cifrado en reposo en Amazon RDS es seguro, pero no le da a la empresa control total sobre la gestión de claves en comparación con usar AWS KMS, que es una mejor solución para los requisitos de cumplimiento y auditoría."
        ]
    },
    {
        "Question Number": "39",
        "Situation": "Una empresa de medios opera una aplicación de múltiples capas en AWS que utiliza Amazon S3 para almacenamiento, instancias de Amazon EC2 para procesamiento y Amazon RDS para servicios de base de datos. La empresa necesita asegurar alta disponibilidad y recuperación automática de fallos para su aplicación. Además, la aplicación debe escalar según la demanda sin intervención manual. ¿Qué solución cumplirá mejor con estos requisitos?",
        "Question": "¿Qué arquitectura debería implementar la empresa para lograr conmutación por error automática, replicación de datos y elasticidad?",
        "Options": {
            "1": "Utilizar funciones de AWS Lambda para procesar los datos almacenados en S3 y activar las funciones usando Amazon CloudWatch Events, mientras almacena información de estado en una tabla de Amazon DynamoDB.",
            "2": "Crear una instancia de Amazon RDS con réplicas de lectura en múltiples regiones y conectar las instancias de EC2 a la instancia principal de RDS.",
            "3": "Configurar una única instancia de Amazon EC2 con Auto Scaling configurado para escalar según la utilización de CPU y usar Amazon S3 para la entrega de contenido estático.",
            "4": "Desplegar la aplicación a través de múltiples Zonas de Disponibilidad (AZs) con un Application Load Balancer (ALB) frente a las instancias de EC2, y configurar RDS Multi-AZ para la base de datos."
        },
        "Correct Answer": "Desplegar la aplicación a través de múltiples Zonas de Disponibilidad (AZs) con un Application Load Balancer (ALB) frente a las instancias de EC2, y configurar RDS Multi-AZ para la base de datos.",
        "Explanation": "Esta opción asegura alta disponibilidad al distribuir la aplicación a través de múltiples AZs, permitiendo la conmutación por error automática y capacidades de auto-reparación. El ALB equilibra el tráfico entre las instancias de EC2, y RDS Multi-AZ proporciona conmutación por error automatizada y replicación de datos, cumpliendo con los requisitos de elasticidad y confiabilidad.",
        "Other Options": [
            "Esta opción no proporciona alta disponibilidad ya que se basa únicamente en AWS Lambda y no aborda la conmutación por error o la replicación de datos para las instancias de EC2 o la base de datos RDS.",
            "Esta opción proporciona cierto nivel de elasticidad pero carece de características de conmutación por error automática y replicación de datos, lo que la hace menos adecuada para requisitos de alta disponibilidad.",
            "Si bien esta opción incluye réplicas de lectura, no asegura la conmutación por error automática y la auto-reparación para la capa de aplicación, lo cual es esencial para mantener alta disponibilidad."
        ]
    },
    {
        "Question Number": "40",
        "Situation": "Una empresa global de comercio electrónico está planeando desplegar su aplicación web en múltiples Regiones de AWS para asegurar baja latencia y alta disponibilidad para sus clientes en todo el mundo. La empresa necesita entender las implicaciones de la infraestructura global de AWS, incluyendo Regiones y Zonas de Disponibilidad, para tomar decisiones informadas sobre la estrategia de despliegue. Están particularmente interesados en cómo aprovechar la presencia global de AWS para mejorar el rendimiento de su aplicación.",
        "Question": "¿Cuál de las siguientes afirmaciones describe con precisión las Regiones y Zonas de Disponibilidad de AWS?",
        "Options": {
            "1": "Las Regiones de AWS consisten en múltiples Zonas de Disponibilidad que están geográficamente dispersas, pero cada Zona de Disponibilidad dentro de una Región depende de las demás para la replicación de datos.",
            "2": "Las Regiones de AWS están compuestas por Zonas de Disponibilidad independientes, que están diseñadas para estar completamente aisladas entre sí para prevenir cualquier pérdida de datos.",
            "3": "Las Zonas de Disponibilidad de AWS están diseñadas como ubicaciones aisladas dentro de una Región, pero todas están interconectadas con enlaces de alta latencia para mejorar la comunicación entre ellas.",
            "4": "Las Regiones de AWS están aisladas entre sí, y cada Región tiene múltiples Zonas de Disponibilidad que están interconectadas con enlaces de baja latencia."
        },
        "Correct Answer": "Las Regiones de AWS están aisladas entre sí, y cada Región tiene múltiples Zonas de Disponibilidad que están interconectadas con enlaces de baja latencia.",
        "Explanation": "Las Regiones de AWS están efectivamente aisladas entre sí para mejorar la tolerancia a fallos, y dentro de cada Región, hay múltiples Zonas de Disponibilidad diseñadas para proporcionar alta disponibilidad. Estas Zonas de Disponibilidad están interconectadas con enlaces de baja latencia, lo que permite una comunicación fluida y replicación de datos entre ellas, lo cual es esencial para aplicaciones que requieren redundancia y rendimiento.",
        "Other Options": [
            "Esta afirmación es incorrecta porque sugiere que las Zonas de Disponibilidad están interconectadas con enlaces de alta latencia, lo cual no es cierto. Están diseñadas con conexiones de baja latencia para facilitar la transferencia eficiente de datos.",
            "Esta afirmación es incorrecta ya que implica que las Zonas de Disponibilidad dependen entre sí para la replicación de datos. En realidad, están diseñadas para operar de manera independiente, permitiendo el aislamiento de fallos.",
            "Esta afirmación sugiere incorrectamente que las Zonas de Disponibilidad están completamente aisladas entre sí de una manera que previene cualquier pérdida de datos. Si bien están diseñadas para ser independientes para evitar fallos en cascada, todavía están interconectadas para la eficiencia operativa."
        ]
    },
    {
        "Question Number": "41",
        "Situation": "Una empresa de servicios financieros está construyendo una plataforma de análisis en tiempo real para procesar transacciones y detectar actividades fraudulentas. El sistema debe ser capaz de manejar un alto rendimiento con baja latencia para cumplir con los requisitos de procesamiento en tiempo real. La empresa está considerando usar Amazon Kinesis Data Streams para la ingestión de datos, pero necesita orientación sobre la mejor manera de implementar la solución.",
        "Question": "¿Cuál de los siguientes diseños proporcionaría el mejor rendimiento para la ingestión de datos en Amazon Kinesis Data Streams?",
        "Options": {
            "1": "Usar múltiples aplicaciones productoras individuales, cada una enviando datos a un flujo de datos Kinesis diferente para distribuir la carga.",
            "2": "Configurar un Kinesis Data Firehose para enrutar automáticamente los datos desde la aplicación productora al flujo de datos Kinesis.",
            "3": "Utilizar la Kinesis Producer Library (KPL) para agrupar múltiples registros y enviarlos en una sola llamada API al flujo de datos Kinesis.",
            "4": "Implementar una sola aplicación productora que envíe datos directamente a un flujo de datos Kinesis con un máximo de 1,000 registros por segundo."
        },
        "Correct Answer": "Utilizar la Kinesis Producer Library (KPL) para agrupar múltiples registros y enviarlos en una sola llamada API al flujo de datos Kinesis.",
        "Explanation": "Usar la Kinesis Producer Library (KPL) permite agrupar eficientemente múltiples registros y enviarlos en una sola llamada API, aumentando significativamente el rendimiento y reduciendo el número de solicitudes realizadas al flujo de datos Kinesis. Esta es la forma más efectiva de maximizar el rendimiento de la ingestión de datos.",
        "Other Options": [
            "Implementar una sola aplicación productora que envíe datos directamente a un flujo de datos Kinesis limita el rendimiento a 1,000 registros por segundo, lo cual puede no ser suficiente para aplicaciones de alto volumen.",
            "Usar múltiples aplicaciones productoras individuales puede llevar a una mayor complejidad en la gestión de aplicaciones y puede no utilizar efectivamente las capacidades máximas de rendimiento de Kinesis. Sería mejor optimizar el rendimiento de un solo productor.",
            "Configurar un Kinesis Data Firehose para este escenario puede no ser adecuado, ya que Firehose está diseñado para la entrega de datos en lugar de la ingestión de datos de alto rendimiento como Kinesis Data Streams, y añadiría latencia innecesaria."
        ]
    },
    {
        "Question Number": "42",
        "Situation": "Una empresa de medios se está preparando para subir grandes archivos de video a Amazon S3 para almacenamiento y distribución. Necesitan asegurarse de que las cargas sean eficientes y puedan ser gestionadas de manera flexible, especialmente dado que algunos archivos de video superan 1 GB de tamaño. Están considerando el mejor método para subir estos archivos.",
        "Question": "¿Cuál es la principal ventaja de usar cargas multipartes para almacenar grandes archivos de video en Amazon S3?",
        "Options": {
            "1": "Las cargas multipartes permiten el almacenamiento de objetos en múltiples buckets de S3 simultáneamente, facilitando una mejor gestión de datos.",
            "2": "Las cargas multipartes permiten cargas paralelas de partes de archivos, mejorando la velocidad de carga y permitiendo la recuperación de problemas de red sin afectar otras partes.",
            "3": "Las cargas multipartes aseguran que el objeto completo se suba como una sola transacción, previniendo cualquier carga parcial en caso de un fallo.",
            "4": "Las cargas multipartes encriptan automáticamente los archivos durante el proceso de carga, asegurando la seguridad de los datos sin pasos adicionales."
        },
        "Correct Answer": "Las cargas multipartes permiten cargas paralelas de partes de archivos, mejorando la velocidad de carga y permitiendo la recuperación de problemas de red sin afectar otras partes.",
        "Explanation": "Las cargas multipartes mejoran el proceso de carga al permitir que los archivos grandes se dividan en partes más pequeñas, que pueden ser subidas simultáneamente. Este método mejora el rendimiento general y proporciona flexibilidad para recuperarse de cualquier fallo sin necesidad de reiniciar toda la carga.",
        "Other Options": [
            "Las cargas multipartes no manejan automáticamente la encriptación; la encriptación debe ser gestionada por separado durante el proceso de carga.",
            "Las cargas multipartes no previenen cargas parciales; permiten la carga de partes de manera independiente, lo cual es una característica en lugar de una limitación.",
            "Las cargas multipartes no facilitan el almacenamiento de objetos en múltiples buckets de S3; se enfocan en subir un solo objeto en partes a un solo bucket."
        ]
    },
    {
        "Question Number": "43",
        "Situation": "Una plataforma de comercio electrónico global ha observado un aumento significativo en el tráfico de usuarios durante las temporadas de vacaciones, lo que ha llevado a una degradación del rendimiento de su aplicación alojada en AWS. El arquitecto de soluciones necesita asegurarse de que la aplicación pueda escalar para satisfacer la demanda mientras mantiene el rendimiento y minimiza los costos. Se le ha encomendado al arquitecto el diseño de una solución que pueda adaptarse automáticamente a los patrones de tráfico de usuarios fluctuantes.",
        "Question": "¿Cuál de las siguientes estrategias abordaría mejor la necesidad de escalado dinámico y eficiencia de costos en este escenario?",
        "Options": {
            "1": "Desplegar un servicio de contenedores administrado utilizando Amazon ECS con Fargate para escalar automáticamente los recursos según el tráfico entrante e implementar una capa de caché con Amazon ElastiCache.",
            "2": "Utilizar Amazon CloudFront como CDN para distribuir contenido globalmente mientras se ajustan manualmente los tamaños de las instancias EC2 según los aumentos de tráfico esperados.",
            "3": "Configurar funciones de AWS Lambda activadas por API Gateway para manejar las solicitudes entrantes y aprovechar Amazon S3 para la entrega de contenido estático, asegurando que no se requieran instancias EC2.",
            "4": "Implementar Amazon EC2 Auto Scaling con políticas de escalado programadas basadas en patrones de tráfico históricos, combinadas con réplicas de lectura de Amazon RDS para manejar la carga aumentada de la base de datos."
        },
        "Correct Answer": "Desplegar un servicio de contenedores administrado utilizando Amazon ECS con Fargate para escalar automáticamente los recursos según el tráfico entrante e implementar una capa de caché con Amazon ElastiCache.",
        "Explanation": "Utilizar Amazon ECS con Fargate permite el escalado automático de aplicaciones en contenedores en respuesta a cambios en el tráfico, proporcionando tanto elasticidad como rentabilidad. Acoplar esto con ElastiCache mejora el rendimiento al almacenar en caché datos de acceso frecuente, reduciendo la carga en los servicios de backend.",
        "Other Options": [
            "Implementar políticas de escalado programadas puede no responder rápidamente a picos de tráfico repentinos, lo que podría llevar a problemas de rendimiento durante momentos críticos. Además, las réplicas de lectura de RDS, aunque útiles, no abordan el escalado para los servidores de aplicaciones.",
            "Las funciones de AWS Lambda pueden manejar picos de tráfico de manera eficiente, pero este enfoque puede no ser adecuado para todos los tipos de cargas de trabajo, especialmente aquellas que requieren conexiones persistentes o transacciones complejas. Además, la entrega de contenido estático a través de S3 no aborda el escalado dinámico de la aplicación.",
            "Utilizar CloudFront es beneficioso para la entrega de contenido, pero no resuelve directamente el problema del escalado dinámico de instancias EC2. Ajustar manualmente los tamaños de las instancias no es eficiente ni responde a cambios repentinos en el tráfico, lo que puede llevar a cuellos de botella en el rendimiento."
        ]
    },
    {
        "Question Number": "44",
        "Situation": "Una empresa de servicios financieros está utilizando Amazon S3 para almacenar datos de clientes. Para cumplir con los requisitos regulatorios, la empresa necesita implementar políticas de bucket estrictas que impidan cualquier acceso público a los datos almacenados. El arquitecto de soluciones debe asegurarse de que las configuraciones estén configuradas correctamente para prevenir cualquier posibilidad de acceso público.",
        "Question": "¿Cuál de las siguientes configuraciones debería implementar el arquitecto de soluciones para asegurar que todo acceso público al bucket de S3 y sus objetos esté efectivamente bloqueado?",
        "Options": {
            "1": "Establecer IgnorePublicAcls en true y BlockPublicAcls en false para permitir acceso público específico.",
            "2": "Habilitar BlockPublicAcls e IgnorePublicAcls mientras se permite el acceso público a través de la política del bucket.",
            "3": "Usar la política del bucket para denegar todo acceso público, pero permitir que roles IAM específicos accedan a los datos.",
            "4": "Habilitar BlockPublicAcls y BlockPublicPolicy en el bucket de S3, y establecer RestrictPublicBuckets en true."
        },
        "Correct Answer": "Habilitar BlockPublicAcls y BlockPublicPolicy en el bucket de S3, y establecer RestrictPublicBuckets en true.",
        "Explanation": "Habilitar BlockPublicAcls y BlockPublicPolicy asegura que todos los controles de acceso público sean ignorados, y cualquier intento de establecer acceso público a través de políticas de bucket es bloqueado. Establecer RestrictPublicBuckets en true asegura aún más que solo la cuenta de AWS del propietario del bucket pueda acceder al contenido dentro del bucket, proporcionando un modelo de seguridad integral contra el acceso público.",
        "Other Options": [
            "Establecer IgnorePublicAcls en true y BlockPublicAcls en false permite la posibilidad de acceso público si se asignan ACLs públicas al bucket o a los objetos, lo que no cumple con el requisito de bloquear todo acceso público.",
            "Usar una política de bucket para denegar el acceso público no previene que se establezcan ACLs públicas. Por lo tanto, aún puede permitir el acceso público si se proporcionan ACLs, lo que es contrario a los requisitos de cumplimiento.",
            "Habilitar BlockPublicAcls mientras se permite el acceso público a través de la política del bucket contradice el objetivo de bloquear el acceso público, ya que la política podría anular la configuración de las ACL, lo que podría llevar a la exposición de datos sensibles."
        ]
    },
    {
        "Question Number": "45",
        "Situation": "Una empresa de servicios financieros depende en gran medida de su plataforma de comercio en línea. Para asegurar la continuidad del negocio, necesitan una estrategia de recuperación ante desastres robusta que les permita cambiar rápidamente a un sistema de respaldo en caso de falla del sitio principal. Actualmente utilizan una arquitectura multi-AZ dentro de AWS para su base de datos, pero quieren extender esto a sus servidores de aplicaciones y otros componentes críticos.",
        "Question": "¿Cuál de las siguientes soluciones proporcionaría el MEJOR diseño para la continuidad del negocio en este escenario?",
        "Options": {
            "1": "Configurar una réplica de lectura de la base de datos en otra región de AWS y usarla solo para conmutación por error.",
            "2": "Implementar una plantilla de AWS CloudFormation para automatizar el despliegue de servidores de aplicaciones en una región diferente en caso de falla.",
            "3": "Desplegar los servidores de aplicaciones en múltiples regiones de AWS y usar Route 53 para la conmutación por error de DNS.",
            "4": "Utilizar AWS Elastic Load Balancing para distribuir el tráfico entre múltiples instancias EC2 en una sola región."
        },
        "Correct Answer": "Desplegar los servidores de aplicaciones en múltiples regiones de AWS y usar Route 53 para la conmutación por error de DNS.",
        "Explanation": "Desplegar servidores de aplicaciones en múltiples regiones de AWS proporciona una solución robusta para la continuidad del negocio al asegurar que si una región se vuelve no disponible, la aplicación puede conmutar sin problemas a la otra región. Usar Route 53 para la conmutación por error de DNS ayuda a redirigir el tráfico a la región saludable, minimizando el tiempo de inactividad.",
        "Other Options": [
            "Configurar una réplica de lectura de la base de datos en otra región de AWS proporciona cierta redundancia, pero no aborda los servidores de aplicaciones, que también son críticos para la continuidad del negocio.",
            "Utilizar AWS Elastic Load Balancing dentro de una sola región no ofrece protección contra fallas regionales, lo cual es esencial para una estrategia de recuperación ante desastres robusta.",
            "Implementar una plantilla de AWS CloudFormation para automatizar el despliegue de servidores es útil para la provisión, pero no proporciona inherentemente la redundancia necesaria entre regiones para una continuidad efectiva del negocio."
        ]
    },
    {
        "Question Number": "46",
        "Situation": "Una empresa de servicios financieros está buscando modernizar su arquitectura de aplicaciones reduciendo la carga asociada con la gestión de infraestructura. La empresa tiene una aplicación heredada que requiere actualizaciones y parches frecuentes, lo que se ha vuelto engorroso. El arquitecto de soluciones tiene la tarea de hacer la transición a un modelo de servicio administrado para optimizar las operaciones y centrarse en el desarrollo de aplicaciones en lugar de la gestión de infraestructura.",
        "Question": "¿Cuál de las siguientes soluciones debería recomendar el arquitecto de soluciones para reducir efectivamente la carga de aprovisionamiento y parches de infraestructura?",
        "Options": {
            "1": "Migrar la aplicación a instancias de Amazon EC2 y usar un script de automatización personalizado para actualizaciones y parches.",
            "2": "Mover la aplicación a un clúster de Kubernetes en las instalaciones para gestionar la orquestación de contenedores y mantener la flexibilidad.",
            "3": "Desplegar la aplicación en Amazon ECS con Fargate para eliminar la gestión de servidores mientras se utilizan características de seguridad integradas.",
            "4": "Levantar y trasladar la aplicación a volúmenes de Amazon EBS adjuntos a instancias de EC2 para mantener el control sobre la infraestructura."
        },
        "Correct Answer": "Desplegar la aplicación en Amazon ECS con Fargate para eliminar la gestión de servidores mientras se utilizan características de seguridad integradas.",
        "Explanation": "Usar Amazon ECS con Fargate permite a la empresa ejecutar contenedores sin tener que gestionar servidores o clústeres. Esto reduce significativamente la carga de aprovisionamiento y parches de infraestructura, permitiendo al equipo centrarse en el desarrollo y despliegue de aplicaciones.",
        "Other Options": [
            "Migrar a instancias de Amazon EC2 aún requeriría que el equipo gestionara la infraestructura subyacente, incluyendo actualizaciones y parches, lo que no se alinea con el objetivo de reducir la carga.",
            "Levantar y trasladar la aplicación a volúmenes de Amazon EBS adjuntos a instancias de EC2 no eliminaría la necesidad de gestión de infraestructura, ya que la empresa seguiría siendo responsable de mantener y parchear las instancias de EC2.",
            "Mover la aplicación a un clúster de Kubernetes en las instalaciones no reduciría la carga de infraestructura, ya que la empresa aún necesitaría gestionar el hardware y software subyacentes, contradiciendo el objetivo de minimizar la gestión de infraestructura."
        ]
    },
    {
        "Question Number": "47",
        "Situation": "Una empresa de servicios financieros está desarrollando una nueva aplicación que requiere acceso a datos de configuración sensibles en múltiples entornos (desarrollo, pruebas y producción) en AWS. La aplicación debe recuperar estas configuraciones de manera segura sin codificarlas en el código fuente. El equipo ha decidido usar AWS CloudFormation para gestionar los recursos y configuraciones. También quieren asegurarse de que pueden gestionar y actualizar estas configuraciones fácilmente según sea necesario.",
        "Question": "¿Cómo puede el equipo de desarrollo utilizar AWS CloudFormation para gestionar de manera segura los datos de configuración sensibles para su aplicación?",
        "Options": {
            "1": "Definir Parámetros de Systems Manager en la sección de Parámetros de la plantilla de CloudFormation, utilizando claves de parámetros SSM para valores sensibles.",
            "2": "Usar AWS Secrets Manager para almacenar datos de configuración sensibles y referenciarlos directamente en la plantilla de CloudFormation.",
            "3": "Crear una función Lambda que recupere datos sensibles de S3 durante el proceso de creación de la pila de CloudFormation.",
            "4": "Almacenar datos de configuración sensibles directamente en la plantilla de CloudFormation como parámetros en texto plano para simplificar el acceso."
        },
        "Correct Answer": "Definir Parámetros de Systems Manager en la sección de Parámetros de la plantilla de CloudFormation, utilizando claves de parámetros SSM para valores sensibles.",
        "Explanation": "Usar Parámetros de Systems Manager en la plantilla de CloudFormation permite al equipo referenciar de manera segura los datos de configuración sensibles almacenados en AWS Systems Manager Parameter Store. Este enfoque asegura que los parámetros se recuperen de manera segura durante las operaciones de la pila sin exponer información sensible en la plantilla misma.",
        "Other Options": [
            "Almacenar datos de configuración sensibles directamente en la plantilla de CloudFormation como parámetros en texto plano representa un riesgo de seguridad significativo, ya que expone información sensible en el control de versiones y durante las operaciones de la pila.",
            "Si bien AWS Secrets Manager está diseñado para gestionar datos sensibles, no está integrado directamente en las plantillas de CloudFormation de la misma manera que los Parámetros de Systems Manager, lo que hace que este enfoque sea menos adecuado para la gestión segura de configuraciones en este contexto.",
            "Crear una función Lambda para recuperar datos sensibles de S3 añade complejidad innecesaria y posibles vulnerabilidades de seguridad, ya que requiere gestionar recursos y permisos adicionales que podrían exponer información sensible."
        ]
    },
    {
        "Question Number": "48",
        "Situation": "Una empresa emergente está lanzando una nueva aplicación móvil que requiere un servicio backend para procesar datos de usuarios y transacciones. La empresa está preocupada por la gestión de costos, ya que espera un tráfico de usuarios fluctuante. Quieren minimizar costos mientras aseguran que el servicio backend pueda escalar automáticamente según la demanda. La empresa está considerando varios servicios de AWS para implementar esta solución.",
        "Question": "¿Qué estrategia de optimización de costos debería recomendar el Arquitecto de Soluciones para gestionar eficientemente los recursos backend para la aplicación móvil?",
        "Options": {
            "1": "Implementar funciones de AWS Lambda para los servicios backend para escalar automáticamente según el tráfico, y usar Amazon API Gateway para gestionar el acceso a las funciones. Almacenar datos de usuarios en Amazon DynamoDB por su modelo de precios por solicitud.",
            "2": "Provisionar una flota de instancias de Amazon EC2 en un grupo de Auto Scaling para manejar los servicios backend, y usar Amazon RDS para la base de datos. Utilizar instancias reservadas para reducir costos a lo largo del tiempo.",
            "3": "Configurar una instancia de Amazon EC2 de tamaño fijo para ejecutar servicios backend y usar Amazon RDS con IOPS provisionados para un acceso rápido a la base de datos, aplicando un enfoque de escalado manual.",
            "4": "Desplegar Amazon ECS con Fargate para ejecutar servicios backend en contenedores. Usar Amazon S3 para almacenamiento estático y provisionar una instancia de Amazon RDS con precios bajo demanda para la base de datos."
        },
        "Correct Answer": "Implementar funciones de AWS Lambda para los servicios backend para escalar automáticamente según el tráfico, y usar Amazon API Gateway para gestionar el acceso a las funciones. Almacenar datos de usuarios en Amazon DynamoDB por su modelo de precios por solicitud.",
        "Explanation": "Usar AWS Lambda permite que el backend escale automáticamente en respuesta al tráfico entrante, asegurando que los costos se mantengan al mínimo al pagar solo por el tiempo de computación utilizado. Amazon API Gateway proporciona una interfaz segura y escalable para que la aplicación móvil interactúe con las funciones de Lambda. Además, el modelo de precios por solicitud de DynamoDB permite a la startup pagar solo por las solicitudes que realizan, optimizando aún más los costos.",
        "Other Options": [
            "Provisionar una flota de instancias de Amazon EC2 implica costos iniciales y puede llevar a un sobreaprovisionamiento durante períodos de bajo tráfico, lo que no se alinea con el objetivo de optimización de costos de la startup. Las instancias reservadas también requieren compromiso y no proporcionan la flexibilidad necesaria para el tráfico fluctuante.",
            "Desplegar Amazon ECS con Fargate es una solución más flexible, pero puede implicar costos más altos en comparación con Lambda cuando el tráfico es bajo. El uso de precios bajo demanda para RDS también podría llevar a costos incrementados si la base de datos está inactiva, lo que es menos óptimo para la gestión de costos.",
            "Configurar una instancia de Amazon EC2 de tamaño fijo no proporciona la escalabilidad necesaria para el tráfico variable y puede llevar a una subutilización durante los períodos de baja actividad. Los IOPS provisionados para Amazon RDS pueden añadir costos innecesarios, especialmente si la aplicación no requiere un alto rendimiento de manera constante."
        ]
    },
    {
        "Question Number": "49",
        "Situation": "Una empresa global de comercio electrónico está expandiendo sus servicios a múltiples regiones para mejorar la latencia y la confiabilidad. La empresa está considerando usar Amazon CloudFront para la entrega de contenido y AWS Regions para alojar su aplicación web. Quieren asegurarse de que su arquitectura esté optimizada para alta disponibilidad y recuperación ante desastres. Sin embargo, no están seguros sobre las mejores prácticas para desplegar recursos a través de la infraestructura global de AWS.",
        "Question": "¿Cuál de los siguientes enfoques apoyará la alta disponibilidad y la recuperación ante desastres a través de múltiples AWS Regions? (Seleccione dos)",
        "Options": {
            "1": "Desplegar la aplicación web a través de múltiples AWS Regions con políticas de enrutamiento de Route 53 para la gestión del tráfico.",
            "2": "Utilizar AWS Direct Connect para establecer una conexión privada entre el centro de datos local y una única AWS Region.",
            "3": "Usar Amazon S3 para el almacenamiento de contenido estático en una única AWS Region para simplificar la arquitectura.",
            "4": "Aprovechar AWS Global Accelerator para mejorar la disponibilidad y el rendimiento de la aplicación a través de múltiples AWS Regions.",
            "5": "Implementar Amazon RDS con réplicas de lectura entre regiones para asegurar la redundancia de datos y una rápida conmutación por error."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Desplegar la aplicación web a través de múltiples AWS Regions con políticas de enrutamiento de Route 53 para la gestión del tráfico.",
            "Aprovechar AWS Global Accelerator para mejorar la disponibilidad y el rendimiento de la aplicación a través de múltiples AWS Regions."
        ],
        "Explanation": "Desplegar la aplicación web a través de múltiples AWS Regions con políticas de enrutamiento de Route 53 permite una gestión efectiva del tráfico y asegura que los usuarios sean dirigidos al recurso disponible más cercano, mejorando la disponibilidad. AWS Global Accelerator puede enrutar el tráfico a puntos finales óptimos basados en salud, geografía y políticas de enrutamiento, lo que mejora tanto el rendimiento como la disponibilidad a través de las regiones.",
        "Other Options": [
            "Usar Amazon S3 para el almacenamiento de contenido estático en una única AWS Region no proporciona alta disponibilidad ni recuperación ante desastres a través de múltiples regiones, ya que crea un único punto de falla.",
            "Implementar Amazon RDS con réplicas de lectura entre regiones mejora la redundancia de datos, pero no asegura alta disponibilidad para la aplicación web en sí, ya que se centra principalmente en la disponibilidad de la base de datos en lugar de la arquitectura general de la aplicación.",
            "Utilizar AWS Direct Connect para establecer una conexión privada a una única AWS Region no apoya la alta disponibilidad a través de múltiples regiones, ya que limita la conectividad a un único punto, reduciendo la redundancia."
        ]
    },
    {
        "Question Number": "50",
        "Situation": "Una empresa está migrando sus aplicaciones a AWS y necesita implementar una estrategia de gestión de acceso seguro. El arquitecto de soluciones tiene la tarea de definir una política para los roles de IAM que permita que ciertos servicios de AWS interactúen entre sí mientras asegura que la información sensible permanezca protegida. La política debe permitir acciones en recursos específicos sin otorgar permisos excesivos.",
        "Question": "Dadas las necesidades de gestión de acceso seguro, ¿qué política de rol de IAM debería implementar el arquitecto de soluciones para satisfacer las necesidades de la empresa?",
        "Options": {
            "1": "Implementar un rol de IAM con acceso sin restricciones a recursos de EC2 y S3, permitiendo la eliminación de todos los roles y políticas de IAM para simplificar la gestión.",
            "2": "Crear un rol de IAM que permita acceso completo a todos los servicios y recursos de AWS, habilitando a los usuarios para gestionar usuarios y grupos de IAM según sea necesario.",
            "3": "Crear un rol de IAM que permita acceso solo a IAM y Organizations, impidiendo cualquier acceso a recursos de S3 o EC2 para mantener alta seguridad.",
            "4": "Definir un rol de IAM que permita acciones en recursos de S3 y EC2 mientras niega explícitamente acciones relacionadas con IAM y Organizations, asegurando que se puedan crear roles vinculados a servicios cuando sea necesario."
        },
        "Correct Answer": "Definir un rol de IAM que permita acciones en recursos de S3 y EC2 mientras niega explícitamente acciones relacionadas con IAM y Organizations, asegurando que se puedan crear roles vinculados a servicios cuando sea necesario.",
        "Explanation": "Esta opción se alinea con la necesidad de permitir acciones específicas en S3 y EC2 mientras restringe los permisos relacionados con IAM y Organizations, manteniendo un entorno seguro. También apoya la creación de roles vinculados a servicios según sea necesario.",
        "Other Options": [
            "Esta opción otorga permisos excesivos al permitir acceso completo a todos los servicios y recursos de AWS, lo que puede llevar a vulnerabilidades de seguridad y no cumple con el requisito de menor privilegio.",
            "Esta opción limita el acceso solo a IAM y Organizations, lo que contradice el requisito de permitir acciones en recursos de S3 y EC2, fallando así en satisfacer las necesidades de la aplicación.",
            "Esta opción presenta un gran riesgo de seguridad al permitir acceso sin restricciones a recursos de EC2 y S3 y habilitar la eliminación de roles y políticas de IAM, lo que puede comprometer la seguridad de la cuenta."
        ]
    },
    {
        "Question Number": "51",
        "Situation": "Una startup está ejecutando múltiples aplicaciones en AWS y está preocupada por su factura mensual de AWS, que ha estado aumentando constantemente. Quieren implementar una estrategia de optimización de costos mientras aseguran tener visibilidad sobre sus patrones de gasto. La startup tiene un pequeño equipo de DevOps y debe asegurar una mínima interrupción en sus servicios.",
        "Question": "¿Cuál de los siguientes enfoques debería tomar la startup para lograr la optimización de costos y visibilidad en su gasto en AWS?",
        "Options": {
            "1": "Configurar una solución de registro centralizada utilizando Amazon CloudTrail para monitorear llamadas a la API y AWS Config para rastrear cambios en los recursos. Revisar los registros mensualmente para entender las implicaciones de costos.",
            "2": "Usar Amazon CloudWatch para monitorear todos los servicios de AWS y crear alarmas para picos inusuales en el uso. Ajustar los límites de servicio en consecuencia para ayudar a controlar los costos.",
            "3": "Implementar AWS Budgets para establecer presupuestos de costos y uso personalizados para diferentes equipos. Habilitar etiquetas de asignación de costos para rastrear el gasto por aplicación y configurar alertas para los umbrales de presupuesto.",
            "4": "Migrar todas las aplicaciones a AWS Lambda para beneficiarse de un modelo de precios de pago por uso. Analizar datos de uso históricos para predecir costos futuros y ajustar en consecuencia."
        },
        "Correct Answer": "Implementar AWS Budgets para establecer presupuestos de costos y uso personalizados para diferentes equipos. Habilitar etiquetas de asignación de costos para rastrear el gasto por aplicación y configurar alertas para los umbrales de presupuesto.",
        "Explanation": "Implementar AWS Budgets permite a la startup establecer objetivos de costos específicos, monitorear el gasto y recibir alertas cuando se acerquen a los límites del presupuesto. Habilitar etiquetas de asignación de costos ayuda a proporcionar visibilidad sobre qué partes del negocio están generando costos, apoyando una gestión efectiva de costos.",
        "Other Options": [
            "Si bien monitorear con Amazon CloudWatch es beneficioso, se centra principalmente en métricas de rendimiento y no proporciona directamente visibilidad de costos o características de gestión de presupuesto necesarias para la optimización de costos.",
            "Migrar todas las aplicaciones a AWS Lambda puede reducir los costos asociados con recursos inactivos, pero no proporciona una estrategia integral para rastrear y gestionar el gasto total en AWS o visibilidad de costos por aplicación.",
            "Configurar registros centralizados con Amazon CloudTrail y AWS Config es útil para el cumplimiento y el rastreo de recursos, pero no aborda directamente la optimización de costos ni proporciona visibilidad en tiempo real sobre el gasto real."
        ]
    },
    {
        "Question Number": "52",
        "Situation": "Una institución financiera está planeando migrar sus aplicaciones heredadas locales a la nube de AWS. Las aplicaciones son altamente complejas y requieren modificaciones significativas para cumplir con los estándares de arquitectura en la nube. La institución busca evaluar diferentes estrategias de migración basadas en el marco de las 7Rs para determinar el mejor enfoque, minimizando riesgos y maximizando beneficios. El arquitecto de soluciones tiene la tarea de seleccionar las estrategias más apropiadas para las aplicaciones.",
        "Question": "¿Cuál de las siguientes estrategias de migración debería considerar el arquitecto de soluciones para las aplicaciones heredadas? (Seleccione Dos)",
        "Options": {
            "1": "Refactorizar las aplicaciones para aprovechar al máximo las características nativas de la nube, como microservicios y arquitectura sin servidor.",
            "2": "Replataformar las aplicaciones moviéndolas a instancias de Amazon EC2 con cambios mínimos en el código.",
            "3": "Reconstruir las aplicaciones desde cero utilizando un lenguaje de programación moderno y una arquitectura que se alinee con las mejores prácticas de AWS.",
            "4": "Recomprar las aplicaciones adquiriendo software comercial listo para usar que proporcione funcionalidad similar de manera más eficiente.",
            "5": "Retener las aplicaciones en las instalaciones y extender sus capacidades integrándolas con servicios de AWS a través de soluciones de nube híbrida."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Refactorizar las aplicaciones para aprovechar al máximo las características nativas de la nube, como microservicios y arquitectura sin servidor.",
            "Reconstruir las aplicaciones desde cero utilizando un lenguaje de programación moderno y una arquitectura que se alinee con las mejores prácticas de AWS."
        ],
        "Explanation": "Refactorizar las aplicaciones permite aprovechar las características nativas de la nube, mejorando la escalabilidad y mantenibilidad, mientras que reconstruir proporciona un nuevo comienzo para adoptar prácticas de desarrollo modernas, haciéndolas inherentemente más compatibles con la nube.",
        "Other Options": [
            "Replataformar puede no utilizar completamente las capacidades de la nube y podría no generar beneficios significativos en comparación con otras estrategias. Implica cambios mínimos que pueden no abordar efectivamente la complejidad de la aplicación.",
            "Retener las aplicaciones en las instalaciones contradice el objetivo de migrar a AWS y no aprovecha completamente la escalabilidad y flexibilidad de la nube.",
            "Recomprar software puede ser una opción viable, pero no aborda directamente la modernización de las aplicaciones heredadas y podría implicar costos de licencia más altos sin garantizar la alineación con los procesos comerciales existentes."
        ]
    },
    {
        "Question Number": "53",
        "Situation": "Una empresa de servicios financieros está buscando mover una parte de sus cargas de trabajo locales a AWS. Están preocupados por los costos asociados con la ejecución de sus aplicaciones en AWS y necesitan equilibrar los requisitos de rendimiento con las limitaciones presupuestarias. Las cargas de trabajo tienen patrones de uso variados, algunas se ejecutan continuamente mientras que otras solo se utilizan durante las horas pico de negocio. La empresa está considerando diferentes opciones de compra para optimizar sus costos.",
        "Question": "¿Cuál de las siguientes opciones de compra proporcionará a la empresa el mejor equilibrio entre costo y rendimiento para cargas de trabajo tanto estables como variables?",
        "Options": {
            "1": "Utilizar instancias bajo demanda exclusivamente para todas las cargas de trabajo para mantener flexibilidad sin importar las implicaciones de costo.",
            "2": "Desplegar hosts dedicados para todas las cargas de trabajo para obtener el mayor nivel de control sobre la colocación de instancias y la utilización de recursos.",
            "3": "Comprar instancias reservadas para cargas de trabajo en estado estable y usar instancias Spot para cargas de trabajo variables durante las horas pico para minimizar costos.",
            "4": "Optar por planes de ahorro para cubrir todas las cargas de trabajo, asegurando que la empresa se beneficie de ahorros sin estar atada a tipos de instancias específicos."
        },
        "Correct Answer": "Comprar instancias reservadas para cargas de trabajo en estado estable y usar instancias Spot para cargas de trabajo variables durante las horas pico para minimizar costos.",
        "Explanation": "Usar instancias reservadas para cargas de trabajo en estado estable proporciona un costo más bajo en comparación con los precios bajo demanda, mientras que aprovechar las instancias Spot para cargas de trabajo variables durante las horas pico permite a la empresa beneficiarse de precios más bajos en capacidad sobrante. Esta estrategia se alinea bien con la optimización de costos y las necesidades de rendimiento.",
        "Other Options": [
            "Usar instancias bajo demanda exclusivamente puede proporcionar flexibilidad, pero puede resultar en costos significativamente más altos, especialmente para cargas de trabajo estables que podrían optimizarse con instancias reservadas.",
            "Si bien los planes de ahorro ofrecen flexibilidad y ahorros de costos en varios tipos de instancias, pueden no proporcionar el mismo nivel de ahorros que una combinación de instancias reservadas y Spot adaptadas a los patrones de carga de trabajo específicos de la empresa.",
            "Desplegar hosts dedicados es generalmente más costoso y puede no ser necesario para todas las cargas de trabajo, lo que podría llevar a costos más altos sin los beneficios de rendimiento correspondientes para aplicaciones menos críticas."
        ]
    },
    {
        "Question Number": "54",
        "Situation": "Una empresa minorista utiliza varias aplicaciones de Software como Servicio (SaaS), incluyendo Salesforce para la gestión de relaciones con clientes y Google Analytics para rastrear el rendimiento del sitio web. La empresa necesita automatizar la transferencia de datos de clientes de Salesforce a Amazon S3 para fines de análisis y quiere asegurarse de que estos datos se actualicen regularmente sin intervención manual. Además, quieren asegurarse de que los datos sean transformados y preparados para el análisis. La empresa está buscando una solución que minimice la sobrecarga operativa y permita una fácil integración con los servicios de AWS.",
        "Question": "¿Cuál de las siguientes soluciones debería implementar el arquitecto de soluciones para automatizar el flujo de datos entre Salesforce y Amazon S3, asegurando que los datos sean transformados y preparados para el análisis?",
        "Options": {
            "1": "Configurar un Amazon Kinesis Data Firehose para transmitir datos de Salesforce a Amazon S3 en casi tiempo real.",
            "2": "Usar trabajos de AWS Glue para extraer datos de Salesforce y cargarlos en Amazon S3 en un horario predefinido.",
            "3": "Configurar Amazon AppFlow para transferir datos de Salesforce a Amazon S3, aplicando las transformaciones necesarias durante el proceso.",
            "4": "Desarrollar una aplicación personalizada usando AWS Lambda y la API de Salesforce para extraer y cargar datos en Amazon S3 según un horario."
        },
        "Correct Answer": "Configurar Amazon AppFlow para transferir datos de Salesforce a Amazon S3, aplicando las transformaciones necesarias durante el proceso.",
        "Explanation": "Amazon AppFlow es un servicio completamente gestionado que simplifica el proceso de transferencia de datos entre aplicaciones SaaS como Salesforce y servicios de AWS como Amazon S3. Permite una fácil configuración de flujos de datos, incluida la capacidad de aplicar transformaciones a los datos mientras se mueven, cumpliendo así con los requisitos de la empresa para la automatización y preparación de datos.",
        "Other Options": [
            "Desarrollar una aplicación personalizada agrega complejidad innecesaria y sobrecarga operativa, lo que va en contra del requisito de minimizar las cargas operativas. Requiere mantener el código y manejar manualmente los límites de tasa de la API.",
            "Usar Amazon Kinesis Data Firehose es más adecuado para aplicaciones de transmisión en tiempo real en lugar de transferencias de datos programadas. No proporciona capacidades de transformación integradas tan efectivamente como lo hace Amazon AppFlow.",
            "Los trabajos de AWS Glue se utilizan típicamente para procesos ETL y requieren configuración adicional para la programación y gestión de trabajos. Si bien puede lograr el objetivo, introduce más complejidad en comparación con la configuración directa de Amazon AppFlow."
        ]
    },
    {
        "Question Number": "55",
        "Situation": "Una empresa de comercio electrónico en crecimiento está evaluando el costo total de propiedad (TCO) de migrar su infraestructura local a AWS. Quieren entender no solo los costos directos, sino también los costos indirectos asociados con la migración, incluidos los gastos operativos y el posible tiempo de inactividad durante la transición. Han consultado con un Arquitecto de Soluciones para evaluar el impacto financiero general de este movimiento.",
        "Question": "¿Cuál de los siguientes enfoques es más efectivo para que la empresa calcule con precisión el costo total de propiedad (TCO) de su migración a AWS?",
        "Options": {
            "1": "Centrarse únicamente en el precio de los servicios de AWS que planean utilizar sin considerar otros factores.",
            "2": "Estimar costos basándose en datos históricos de migraciones similares realizadas por otras empresas en su industria.",
            "3": "Considerar solo los ahorros potenciales de no mantener su centro de datos local.",
            "4": "Utilizar el AWS TCO Calculator para incluir tanto los costos directos como los indirectos en su análisis."
        },
        "Correct Answer": "Utilizar el AWS TCO Calculator para incluir tanto los costos directos como los indirectos en su análisis.",
        "Explanation": "Utilizar el AWS TCO Calculator proporciona una visión integral de las implicaciones financieras de mudarse a AWS, teniendo en cuenta tanto los costos directos (como computación y almacenamiento) como los costos indirectos (como gastos operativos y posible tiempo de inactividad). Este enfoque holístico asegura que la empresa pueda tomar una decisión informada basada en proyecciones financieras precisas.",
        "Other Options": [
            "Centrarse únicamente en el precio de los servicios de AWS ignora la imagen financiera más amplia, incluidos los costos indirectos y los impactos operativos, lo que podría llevar a subestimar el verdadero TCO.",
            "Estimar costos basándose en datos históricos de otras empresas puede no reflejar con precisión la situación única de la empresa, incluidos sus cargas de trabajo específicas y requisitos operativos.",
            "Considerar solo los ahorros potenciales de eliminar el centro de datos local no toma en cuenta los costos continuos asociados con los servicios de AWS, los cambios operativos y los posibles gastos iniciales de migración."
        ]
    },
    {
        "Question Number": "56",
        "Situation": "Una empresa está ejecutando una arquitectura de microservicios utilizando Amazon ECS con tipo de lanzamiento EC2. Están considerando utilizar instancias Spot para reducir costos, mientras aseguran interrupciones mínimas del servicio durante la terminación de instancias. La empresa quiere entender cómo ECS gestiona la terminación de tareas en conjunto con las instancias EC2 subyacentes.",
        "Question": "¿Cómo mejora Amazon ECS el uso de instancias Spot en una arquitectura de microservicios para minimizar las interrupciones del servicio durante la terminación de instancias EC2?",
        "Options": {
            "1": "ECS gestiona el DRAINING de tareas, terminando conexiones de manera ordenada mientras programa tareas de reemplazo en nuevas instancias EC2.",
            "2": "ECS requiere intervención manual para manejar las terminaciones de instancias Spot, lo que lo hace menos eficiente para alta disponibilidad.",
            "3": "ECS utiliza instancias reservadas para reemplazar instancias Spot terminadas, asegurando la disponibilidad constante de las tareas.",
            "4": "ECS termina automáticamente las instancias Spot cuando las tareas ya no están en ejecución, asegurando una utilización eficiente de los recursos."
        },
        "Correct Answer": "ECS gestiona el DRAINING de tareas, terminando conexiones de manera ordenada mientras programa tareas de reemplazo en nuevas instancias EC2.",
        "Explanation": "Amazon ECS aprovecha la funcionalidad inherente de DRAINING durante la terminación de instancias Spot, permitiendo que las tareas se detengan de manera ordenada, las conexiones se terminen limpiamente y las tareas de reemplazo se programen de manera eficiente, lo que minimiza las interrupciones del servicio.",
        "Other Options": [
            "Esta opción es incorrecta porque ECS no termina automáticamente las instancias Spot basándose únicamente en el estado de la tarea. En cambio, gestiona la terminación ordenada de las tareas cuando una instancia subyacente está siendo terminada.",
            "Esta opción es incorrecta porque ECS no depende de instancias reservadas para reemplazar instancias Spot terminadas; utiliza la funcionalidad de DRAINING para gestionar las terminaciones de tareas y la programación de reemplazos en nuevas instancias.",
            "Esta opción es incorrecta porque, aunque ECS proporciona automatización para gestionar tareas, no requiere intervención manual para manejar las terminaciones de instancias Spot, ya que automatiza el proceso de DRAINING."
        ]
    },
    {
        "Question Number": "57",
        "Situation": "Una empresa minorista está construyendo una nueva aplicación que procesa pedidos de clientes en tiempo real. Se espera que la aplicación maneje cargas de trabajo variables durante las temporadas de compras pico y requiere una sobrecarga de gestión mínima. El arquitecto de soluciones está considerando opciones de computación sin servidor para cumplir con estos requisitos.",
        "Question": "¿Cuál servicio de computación sin servidor de AWS sería la mejor opción para manejar las cargas de trabajo variables mientras minimiza la sobrecarga de gestión?",
        "Options": {
            "1": "Amazon ECS con Fargate para ejecutar aplicaciones en contenedores",
            "2": "Amazon EC2 Auto Scaling para gestionar la escalabilidad de instancias",
            "3": "AWS Lambda para ejecutar código en respuesta a eventos",
            "4": "AWS Elastic Beanstalk para desplegar y gestionar aplicaciones"
        },
        "Correct Answer": "AWS Lambda para ejecutar código en respuesta a eventos",
        "Explanation": "AWS Lambda está diseñado para computación sin servidor y puede escalar automáticamente en respuesta a solicitudes entrantes, lo que lo hace ideal para manejar cargas de trabajo variables mientras requiere una sobrecarga de gestión mínima.",
        "Other Options": [
            "Amazon ECS con Fargate, aunque es sin servidor para aplicaciones en contenedores, requiere más gestión y configuración en comparación con AWS Lambda, que es impulsado por eventos y no tiene infraestructura de servidor que gestionar.",
            "Amazon EC2 Auto Scaling gestiona una flota de instancias EC2 y requiere intervención manual para la provisión y gestión de instancias, lo que contradice el requisito de una sobrecarga de gestión mínima.",
            "AWS Elastic Beanstalk simplifica el despliegue de aplicaciones, pero aún requiere cierta gestión de los recursos subyacentes, lo que lo hace menos adecuado para una arquitectura completamente sin servidor diseñada para manejar cargas de trabajo variables."
        ]
    },
    {
        "Question Number": "58",
        "Situation": "Una empresa global de comercio electrónico está enfrentando desafíos con la latencia y la consistencia de datos para su base de datos, que actualmente opera en una única Región de AWS. La dirección busca proporcionar lecturas de baja latencia para usuarios en diferentes regiones geográficas, así como asegurar capacidades de recuperación ante desastres. Están considerando usar Amazon Aurora para cumplir con estos requisitos.",
        "Question": "¿Cuál de las siguientes soluciones debería recomendar el arquitecto de soluciones para mejorar el rendimiento y la disponibilidad de la aplicación en múltiples regiones?",
        "Options": {
            "1": "Utilizar réplicas de lectura de Amazon RDS en cada Región de AWS para distribuir el tráfico de lectura, mientras se mantiene una única instancia de base de datos primaria para operaciones de escritura en una región.",
            "2": "Implementar Amazon Aurora Global Database para habilitar lecturas de baja latencia en múltiples Regiones de AWS mientras se asegura capacidades de recuperación ante desastres. Configurar la región primaria para escrituras y las regiones secundarias para réplicas de lectura.",
            "3": "Desplegar un clúster Multi-Master de Amazon Aurora para permitir múltiples instancias de lectura-escritura en diferentes Regiones de AWS, proporcionando alta disponibilidad y capacidades de conmutación por error.",
            "4": "Configurar una instancia separada de Amazon Aurora en cada Región de AWS y usar AWS Database Migration Service para la replicación continua de datos para asegurar la consistencia de datos y minimizar la latencia."
        },
        "Correct Answer": "Implementar Amazon Aurora Global Database para habilitar lecturas de baja latencia en múltiples Regiones de AWS mientras se asegura capacidades de recuperación ante desastres. Configurar la región primaria para escrituras y las regiones secundarias para réplicas de lectura.",
        "Explanation": "Amazon Aurora Global Database está diseñado específicamente para aplicaciones distribuidas globalmente, permitiendo lecturas de baja latencia y proporcionando recuperación ante desastres de interrupciones regionales. Esta solución cumple efectivamente con los requisitos de la empresa.",
        "Other Options": [
            "Amazon Aurora Multi-Master permite múltiples instancias de lectura-escritura, pero no soporta implementaciones entre regiones, lo que lo hace inadecuado para la necesidad de acceso de baja latencia en diferentes regiones.",
            "Configurar instancias separadas de Amazon Aurora en cada región complicaría la gestión y consistencia de datos, y no aprovecharía los beneficios de las características de base de datos global de Aurora.",
            "Usar réplicas de lectura de Amazon RDS podría distribuir el tráfico de lectura, pero no proporciona el mismo nivel de recuperación ante desastres y capacidades de baja latencia en múltiples regiones como lo hace Aurora Global Database."
        ]
    },
    {
        "Question Number": "59",
        "Situation": "Una empresa global de comercio electrónico opera un sitio web que atiende a clientes de diversas regiones del mundo. La empresa utiliza AWS Route 53 para gestionar sus registros DNS y desea optimizar el enrutamiento del tráfico para asegurar baja latencia y alta disponibilidad para sus usuarios. La empresa tiene múltiples servidores web desplegados en diferentes Regiones de AWS y desea implementar una estrategia de enrutamiento que equilibre mejor la experiencia del usuario y la utilización de recursos.",
        "Question": "¿Qué política de enrutamiento debería implementar la empresa para asegurar que los usuarios sean dirigidos a la Región de AWS que ofrezca la menor latencia para sus solicitudes?",
        "Options": {
            "1": "Política de enrutamiento por latencia para dirigir el tráfico a la región que proporciona el mejor tiempo de respuesta.",
            "2": "Política de enrutamiento ponderado para distribuir proporcionalmente el tráfico entre múltiples regiones.",
            "3": "Política de enrutamiento por geolocalización para dirigir a los usuarios según su ubicación geográfica.",
            "4": "Política de enrutamiento de conmutación por error para cambiar el tráfico a una región de respaldo en caso de falla de la región primaria."
        },
        "Correct Answer": "Política de enrutamiento por latencia para dirigir el tráfico a la región que proporciona el mejor tiempo de respuesta.",
        "Explanation": "La política de enrutamiento por latencia está diseñada específicamente para dirigir a los usuarios a la Región de AWS que ofrece la menor latencia, asegurando un rendimiento óptimo para las solicitudes de los usuarios. Esto minimiza los tiempos de respuesta y mejora la experiencia general del usuario.",
        "Other Options": [
            "La política de enrutamiento por geolocalización no es la mejor opción aquí, ya que dirige el tráfico según la ubicación del usuario en lugar de la latencia experimentada en diferentes regiones, lo que puede no proporcionar necesariamente la menor latencia para todos los usuarios.",
            "La política de enrutamiento ponderado permite distribuir el tráfico entre múltiples recursos, pero no toma en cuenta la latencia, lo que podría llevar a un rendimiento subóptimo para los usuarios si una región es significativamente más rápida que otras.",
            "La política de enrutamiento de conmutación por error está destinada a escenarios de recuperación ante desastres donde el tráfico se redirige a un recurso de respaldo solo cuando el primario falla; no optimiza activamente para baja latencia durante las operaciones normales."
        ]
    },
    {
        "Question Number": "60",
        "Situation": "Una empresa minorista está desarrollando una nueva aplicación para gestionar su inventario en múltiples tiendas. La aplicación utilizará Amazon DynamoDB como su servicio de base de datos. El equipo necesita optimizar las operaciones de lectura y escritura basándose en diferentes patrones de consulta, particularmente para consultar artículos de inventario por categoría y por ubicación de la tienda. Están considerando el uso de índices secundarios para lograr esto. El equipo es consciente de las diferencias entre los Índices Secundarios Globales (GSI) y los Índices Secundarios Locales (LSI), pero necesita orientación sobre qué índices implementar para un rendimiento óptimo.",
        "Question": "¿Qué enfoque debería recomendar el Arquitecto de Soluciones para asegurar la consulta eficiente de artículos de inventario por categoría y ubicación de la tienda mientras se adhiere a las mejores prácticas de DynamoDB?",
        "Options": {
            "1": "Crear dos Índices Secundarios Locales, uno con la categoría como la clave de ordenamiento y otro con la ubicación de la tienda como la clave de ordenamiento, ambos compartiendo la misma clave de partición que la tabla.",
            "2": "Crear un Índice Secundario Local utilizando la misma clave de partición que la tabla para la ubicación de la tienda, pero con la categoría como la clave de ordenamiento. Esto permitirá consultar por ubicación de la tienda y categoría.",
            "3": "Crear un Índice Secundario Global utilizando la ubicación de la tienda como la clave de partición y la categoría como la clave de ordenamiento. Luego crear otro Índice Secundario Global con la categoría como la clave de partición y una marca de tiempo como la clave de ordenamiento.",
            "4": "Crear un Índice Secundario Global con la ubicación de la tienda como la clave de partición y la categoría como la clave de ordenamiento. Crear otro Índice Secundario Global con la categoría como la clave de partición y una marca de tiempo como la clave de ordenamiento."
        },
        "Correct Answer": "Crear un Índice Secundario Global con la ubicación de la tienda como la clave de partición y la categoría como la clave de ordenamiento. Crear otro Índice Secundario Global con la categoría como la clave de partición y una marca de tiempo como la clave de ordenamiento.",
        "Explanation": "El uso de Índices Secundarios Globales permite diferentes claves de partición y ordenamiento, lo que hace posible consultar de manera eficiente tanto por ubicación de la tienda como por categoría sin estar limitado por la clave de partición de la tabla original. Esto coincide con el requisito de optimizar diferentes patrones de consulta.",
        "Other Options": [
            "Esta opción es incorrecta porque usar un Índice Secundario Local limita el tamaño total de los elementos indexados por clave de partición a 10 GB. Además, no puede proporcionar la flexibilidad requerida para consultar tanto por categoría como por ubicación de la tienda de manera eficiente.",
            "Esta opción es incorrecta ya que sugiere crear dos Índices Secundarios Locales. Los Índices Secundarios Locales comparten la misma clave de partición que la tabla y, por lo tanto, no pueden usarse para crear patrones de consulta separados basados en diferentes claves de partición de manera efectiva.",
            "Esta opción es incorrecta porque sugiere crear Índices Secundarios Globales, pero la combinación de claves propuestas no optimiza la consulta de artículos de inventario tanto por categoría como por ubicación de la tienda de manera efectiva. Es redundante tener ambos índices cuando uno puede estructurarse para manejar ambos patrones de consulta."
        ]
    },
    {
        "Question Number": "61",
        "Situation": "Una empresa de servicios financieros está evaluando varios modelos de precios de AWS para optimizar sus costos. La empresa tiene una carga de trabajo constante que requiere una cantidad significativa de potencia de cómputo, pero también experimenta picos predecibles en el uso durante ciertos momentos del mes debido a requisitos de informes. Quieren asegurarse de tomar la decisión más rentable mientras mantienen el rendimiento.",
        "Question": "¿Cuál de los siguientes modelos de precios se ajustaría mejor a las necesidades de la empresa mientras optimiza los costos para su carga de trabajo y picos de uso predecibles?",
        "Options": {
            "1": "Utilizar Instancias Bajo Demanda para satisfacer la carga de trabajo base y comprar Instancias Reservadas para los períodos de uso máximo para ahorrar costos.",
            "2": "Elegir Hosts Dedicados para asegurar el máximo rendimiento y cumplimiento para la carga de trabajo, sin importar el costo.",
            "3": "Desplegar Instancias Spot tanto para la carga de trabajo constante como para los picos, ya que es la opción más rentable disponible.",
            "4": "Implementar Planes de Ahorro para su uso de cómputo, permitiendo flexibilidad para adaptarse a cargas de trabajo cambiantes mientras se benefician de tarifas más bajas."
        },
        "Correct Answer": "Implementar Planes de Ahorro para su uso de cómputo, permitiendo flexibilidad para adaptarse a cargas de trabajo cambiantes mientras se benefician de tarifas más bajas.",
        "Explanation": "Los Planes de Ahorro ofrecen la capacidad de gestionar costos de manera efectiva mientras permiten flexibilidad en la carga de trabajo. Este modelo permitiría a la empresa adaptarse a sus picos predecibles sin estar atada a una estructura de precios rígida, optimizando así su gasto total.",
        "Other Options": [
            "Las Instancias Bajo Demanda pueden ser costosas para cargas de trabajo a largo plazo y no proporcionarían el mismo nivel de ahorro que las Instancias Reservadas o los Planes de Ahorro durante el uso máximo.",
            "Las Instancias Spot no son ideales para cargas de trabajo constantes y picos predecibles, ya que su disponibilidad puede fluctuar y puede que no garanticen la potencia de cómputo necesaria cuando se necesita.",
            "Los Hosts Dedicados son generalmente más caros y no son necesarios para las necesidades de la empresa, ya que requieren un compromiso con un tipo específico de instancia y no optimizan los costos de manera efectiva."
        ]
    },
    {
        "Question Number": "62",
        "Situation": "Una empresa minorista está experimentando problemas de rendimiento con su sistema de procesamiento de transacciones en línea alojado en Amazon RDS. La aplicación abre y cierra frecuentemente conexiones a la base de datos, lo que lleva a una alta latencia y agotamiento de recursos en la base de datos. Se ha encargado al arquitecto de soluciones mejorar la escalabilidad y la resiliencia, mientras se asegura un acceso seguro a la base de datos. La aplicación utiliza Amazon Aurora para sus necesidades de base de datos relacional.",
        "Question": "¿Qué solución optimizará las conexiones a la base de datos y mejorará el rendimiento de la aplicación?",
        "Options": {
            "1": "Usar Amazon Elasticache para almacenar en caché las respuestas de la base de datos y minimizar el número de consultas directas a la base de datos de Amazon Aurora.",
            "2": "Aumentar el tamaño de la instancia de la base de datos de Amazon Aurora para manejar más conexiones concurrentes y mejorar el rendimiento.",
            "3": "Migrar la base de datos a Amazon DynamoDB para eliminar la necesidad de gestión de conexiones y mejorar la escalabilidad.",
            "4": "Implementar Amazon RDS Proxy para agrupar y gestionar las conexiones a la base de datos, reduciendo el número de conexiones abiertas y cerradas por la aplicación."
        },
        "Correct Answer": "Implementar Amazon RDS Proxy para agrupar y gestionar las conexiones a la base de datos, reduciendo el número de conexiones abiertas y cerradas por la aplicación.",
        "Explanation": "Implementar Amazon RDS Proxy permite a la aplicación agrupar y compartir conexiones a la base de datos, lo que reduce la sobrecarga de establecer conexiones repetidamente. Esto lleva a una mejora en el rendimiento y la escalabilidad, así como a una mayor resiliencia ante fallos de la base de datos.",
        "Other Options": [
            "Aumentar el tamaño de la instancia puede mejorar el rendimiento, pero no aborda el problema subyacente de la gestión de conexiones y podría llevar a costos innecesarios.",
            "Migrar a Amazon DynamoDB requeriría cambios significativos en la arquitectura de la aplicación y puede que no se alinee con el modelo relacional actual, lo que lo convierte en una solución impráctica.",
            "Usar Amazon Elasticache puede ayudar a reducir las consultas directas a la base de datos, pero no aborda el problema de gestión de conexiones que está causando la degradación del rendimiento."
        ]
    },
    {
        "Question Number": "63",
        "Situation": "Una empresa de servicios financieros ha desplegado una aplicación en AWS que procesa datos sensibles de clientes. La dirección requiere que todos los datos en reposo estén cifrados y que el acceso a recursos sensibles esté estrictamente controlado. Como parte de su cumplimiento de seguridad, quieren implementar una solución que garantice la auditoría de todas las solicitudes de acceso y que pueda integrarse con su sistema de gestión de identidad existente.",
        "Question": "¿Cuál de las siguientes acciones se pueden tomar para mejorar la seguridad de la aplicación mientras se cumplen los requisitos de cumplimiento? (Seleccione Dos)",
        "Options": {
            "1": "Usar roles de AWS IAM para permitir un control de acceso granular a los recursos de AWS.",
            "2": "Utilizar AWS Directory Service para integrarse con el sistema de gestión de identidad existente.",
            "3": "Habilitar el Servicio de Gestión de Claves de AWS (KMS) para gestionar las claves de cifrado para los datos en reposo.",
            "4": "Desplegar AWS CloudTrail para registrar y monitorear todas las llamadas a la API con fines de auditoría.",
            "5": "Implementar Amazon CloudWatch Logs para rastrear solicitudes de acceso, pero no retener los registros."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Habilitar el Servicio de Gestión de Claves de AWS (KMS) para gestionar las claves de cifrado para los datos en reposo.",
            "Desplegar AWS CloudTrail para registrar y monitorear todas las llamadas a la API con fines de auditoría."
        ],
        "Explanation": "Habilitar el Servicio de Gestión de Claves de AWS (KMS) proporciona control centralizado sobre las claves de cifrado utilizadas para cifrar datos en reposo, lo cual es esencial para garantizar la confidencialidad de la información sensible. Desplegar AWS CloudTrail permite un registro completo de toda la actividad de la API relacionada con la aplicación, habilitando la auditoría y el monitoreo de solicitudes de acceso, lo cual es crucial para el cumplimiento.",
        "Other Options": [
            "Usar roles de IAM para un control de acceso granular es importante, pero no aborda directamente los requisitos específicos para el cifrado de datos y la auditoría tan efectivamente como KMS y CloudTrail.",
            "Si bien implementar CloudWatch Logs puede ayudar a rastrear solicitudes de acceso, simplemente rastrearlas sin retener los registros no cumple con los requisitos de auditoría que CloudTrail puede proporcionar.",
            "AWS Directory Service facilita la integración con sistemas de gestión de identidad existentes, pero no mejora inherentemente la seguridad o el cumplimiento en relación con el cifrado de datos y la auditoría de acceso."
        ]
    },
    {
        "Question Number": "64",
        "Situation": "Una empresa de servicios financieros está evaluando diferentes tipos de volúmenes de Amazon Elastic Block Store (EBS) para soportar su aplicación crítica que requiere un alto rendimiento y baja latencia. Necesitan seleccionar un tipo de volumen EBS que pueda manejar una carga de trabajo con I/O aleatorio y que requiera el más alto nivel de durabilidad y rendimiento. La aplicación es sensible a la latencia y requiere la capacidad de aprovisionar IOPS según las demandas de la carga de trabajo.",
        "Question": "¿Cuál de los siguientes tipos de volúmenes EBS es el MÁS apropiado para los requisitos de la empresa?",
        "Options": {
            "1": "sc1: Volumen HDD de costo más bajo diseñado para cargas de trabajo de acceso menos frecuente y almacenamiento en frío.",
            "2": "st1: Volumen HDD de bajo costo diseñado para cargas de trabajo de acceso frecuente y con alta intensidad de rendimiento.",
            "3": "gp2: Volumen SSD de propósito general con un precio y rendimiento equilibrados para diversas cargas de trabajo.",
            "4": "io1: Volumen SSD de más alto rendimiento para cargas de trabajo críticas de baja latencia o alto rendimiento."
        },
        "Correct Answer": "io1: Volumen SSD de más alto rendimiento para cargas de trabajo críticas de baja latencia o alto rendimiento.",
        "Explanation": "El tipo de volumen io1 ofrece el más alto rendimiento y puede aprovisionar hasta 64,000 IOPS, lo que lo hace ideal para aplicaciones críticas que requieren un rendimiento de baja latencia y alto rendimiento. Además, está diseñado específicamente para cargas de trabajo que dependen de I/O aleatorio, lo que se alinea perfectamente con los requisitos de la empresa.",
        "Other Options": [
            "El tipo de volumen gp2, aunque versátil, no ofrece el mismo nivel de aprovisionamiento de IOPS que io1 y puede no satisfacer las necesidades de baja latencia de las aplicaciones críticas.",
            "El tipo de volumen sc1 está destinado a cargas de trabajo de acceso menos frecuente y almacenamiento en frío, lo que no cumple con los requisitos de alto rendimiento de la aplicación.",
            "El tipo de volumen st1 está diseñado para cargas de trabajo intensivas en rendimiento, pero no es adecuado para aplicaciones de baja latencia y no puede igualar el rendimiento y la durabilidad de io1."
        ]
    },
    {
        "Question Number": "65",
        "Situation": "Una empresa global de comercio electrónico está utilizando AWS Backup para centralizar y automatizar la protección de datos en sus diversos servicios de AWS, incluyendo Amazon RDS, Amazon EFS y las instancias de EC2. La empresa tiene requisitos específicos para la frecuencia de copias de seguridad y los períodos de retención para diferentes tipos de datos debido a la conformidad regulatoria. La dirección quiere asegurarse de que las políticas de copia de seguridad sean fácilmente ajustables y que puedan monitorear las actividades de copia de seguridad desde un solo panel de control.",
        "Question": "¿Cuál de los siguientes enfoques satisface mejor los requisitos de la empresa para la gestión centralizada de copias de seguridad y cumplimiento?",
        "Options": {
            "1": "Implementar funciones de AWS Lambda para automatizar copias de seguridad para cada servicio y almacenar registros en CloudWatch para monitoreo.",
            "2": "Utilizar AWS Backup para crear planes de copia de seguridad centralizados que definan políticas para frecuencia y retención, y monitorear todas las actividades desde el panel de AWS Backup.",
            "3": "Crear planes de copia de seguridad individuales para cada servicio de AWS y monitorear manualmente su estado a través de la consola de cada servicio.",
            "4": "Programar documentos de automatización de AWS Systems Manager para realizar copias de seguridad para cada servicio y agregar los resultados en un bucket de S3."
        },
        "Correct Answer": "Utilizar AWS Backup para crear planes de copia de seguridad centralizados que definan políticas para frecuencia y retención, y monitorear todas las actividades desde el panel de AWS Backup.",
        "Explanation": "AWS Backup proporciona un servicio completamente gestionado que permite centralizar la gestión de copias de seguridad a través de múltiples servicios de AWS, automatizar tareas de copia de seguridad con políticas ajustables y monitorear la actividad de copia de seguridad en un panel integrado, lo que lo convierte en la mejor opción para el cumplimiento y la gestión.",
        "Other Options": [
            "Crear planes de copia de seguridad individuales para cada servicio de AWS complica la gestión y no proporciona una vista centralizada, lo que dificulta asegurar el cumplimiento en toda la organización.",
            "Si bien el uso de funciones de AWS Lambda podría automatizar las copias de seguridad, implica más complejidad y esfuerzo manual para monitorear y gestionar las copias de seguridad, lo que socava el objetivo de centralización.",
            "Programar documentos de automatización de AWS Systems Manager también requeriría una gestión separada para cada servicio, careciendo de las características centralizadas y automatizadas de AWS Backup, por lo que no cumpliría efectivamente con los requisitos de cumplimiento."
        ]
    },
    {
        "Question Number": "66",
        "Situation": "Un equipo de desarrollo se está preparando para implementar una nueva versión de su aplicación sin servidor que se ejecuta en AWS Lambda. La aplicación tiene una base de usuarios considerable, y el equipo quiere minimizar el riesgo durante el proceso de implementación. Necesitan elegir una configuración de implementación que les permita desviar gradualmente el tráfico a la nueva versión mientras monitorean su rendimiento.",
        "Question": "¿Cuál de las siguientes configuraciones de implementación es la más adecuada para desviar gradualmente el tráfico a la nueva versión de la función Lambda mientras permite el monitoreo del rendimiento?",
        "Options": {
            "1": "Lineal: Desviar el tráfico en incrementos iguales durante un período específico, permitiendo un monitoreo gradual.",
            "2": "Rolling: Desviar el tráfico de manera secuencial, una versión a la vez, para asegurar la estabilidad.",
            "3": "Canary: Desviar un pequeño porcentaje de tráfico a la nueva versión inicialmente, luego desviar el resto después de monitorear.",
            "4": "Todo de una vez: Desviar todo el tráfico a la nueva versión de inmediato sin ninguna transición gradual."
        },
        "Correct Answer": "Canary: Desviar un pequeño porcentaje de tráfico a la nueva versión inicialmente, luego desviar el resto después de monitorear.",
        "Explanation": "La configuración de implementación Canary permite un desvío gradual del tráfico a la nueva versión, lo que es ideal para monitorear el rendimiento y minimizar el riesgo. Este enfoque permite al equipo evaluar el comportamiento de la nueva versión con un subconjunto de usuarios antes de realizar la transición completa.",
        "Other Options": [
            "La implementación lineal no es la mejor opción para este escenario porque, aunque permite un desvío gradual del tráfico, no proporciona el mismo nivel de gestión de riesgos y monitoreo que el enfoque canary.",
            "La implementación todo de una vez no es recomendable en este caso porque desvía todo el tráfico a la nueva versión de inmediato, aumentando el riesgo de introducir problemas a toda la base de usuarios sin ninguna oportunidad de monitoreo.",
            "La implementación rolling no es una opción válida para AWS Lambda, ya que no existe como una estrategia de implementación definida para funciones Lambda. Lambda admite configuraciones canary, lineales y todo de una vez."
        ]
    },
    {
        "Question Number": "67",
        "Situation": "Una empresa de servicios financieros ha estado utilizando instancias de Amazon EC2 para ejecutar sus aplicaciones. Han notado que su factura mensual de AWS es más alta de lo anticipado. El equipo tiene la tarea de identificar oportunidades para optimizar costos sin comprometer el rendimiento.",
        "Question": "¿Qué dos estrategias podría implementar la empresa para reducir costos? (Seleccione Dos)",
        "Options": {
            "1": "Implementar Instancias Reservadas para cargas de trabajo predecibles.",
            "2": "Cambiar a Instancias Spot para cargas de trabajo no críticas.",
            "3": "Aumentar el tamaño de las instancias EC2 existentes para mejorar el rendimiento.",
            "4": "Utilizar Auto Scaling para ajustar el número de instancias EC2 según la demanda.",
            "5": "Migrar las aplicaciones a una sola instancia EC2 grande."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Cambiar a Instancias Spot para cargas de trabajo no críticas.",
            "Implementar Instancias Reservadas para cargas de trabajo predecibles."
        ],
        "Explanation": "Cambiar a Instancias Spot para cargas de trabajo no críticas permite a la empresa aprovechar precios más bajos por capacidad EC2 no utilizada, reduciendo significativamente los costos. Implementar Instancias Reservadas proporciona una solución rentable para cargas de trabajo que son predecibles, ofreciendo un descuento en comparación con los precios bajo demanda.",
        "Other Options": [
            "Migrar las aplicaciones a una sola instancia EC2 grande puede llevar a costos más altos y no aprovecha las estrategias de ahorro de costos disponibles en AWS. Este enfoque también podría crear cuellos de botella en el rendimiento.",
            "Utilizar Auto Scaling para ajustar el número de instancias EC2 según la demanda es una buena práctica para gestionar recursos de manera eficiente; sin embargo, no reduce directamente los costos a menos que se combine con tipos de instancias o modelos de precios que ahorren costos.",
            "Aumentar el tamaño de las instancias EC2 existentes probablemente aumente los costos en lugar de reducirlos, lo cual es contraproducente para el objetivo de optimizar gastos."
        ]
    },
    {
        "Question Number": "68",
        "Situation": "Una empresa de servicios financieros necesita asegurarse de que sus aplicaciones críticas sean resilientes y puedan recuperarse rápidamente de un desastre. La empresa tiene un requisito estricto de mínima pérdida de datos y tiempo de inactividad. Están considerando varias estrategias de recuperación ante desastres basadas en sus objetivos de tiempo de recuperación (RTO) y objetivos de punto de recuperación (RPO).",
        "Question": "¿Qué estrategia de recuperación ante desastres debería recomendar el arquitecto de soluciones para cumplir con los requisitos de la empresa de mínima pérdida de datos y tiempo de inactividad?",
        "Options": {
            "1": "Implementar una solución de espera cálida donde una versión reducida de la aplicación esté funcionando en una región secundaria, permitiendo un escalado rápido durante un desastre.",
            "2": "Utilizar una estrategia de respaldo y restauración con copias de seguridad en el tiempo tomadas cada hora para asegurar que los datos sean recuperables dentro de 24 horas.",
            "3": "Establecer una estrategia de luz piloto que mantenga componentes esenciales funcionando en la región secundaria, con el resto de la infraestructura provisionada rápidamente durante un desastre.",
            "4": "Desplegar una arquitectura activa-activa multi-región con tráfico en vivo siendo servido a través de múltiples regiones, asegurando cero pérdida de datos y capacidad de conmutación por error instantánea."
        },
        "Correct Answer": "Desplegar una arquitectura activa-activa multi-región con tráfico en vivo siendo servido a través de múltiples regiones, asegurando cero pérdida de datos y capacidad de conmutación por error instantánea.",
        "Explanation": "La arquitectura activa-activa multi-región cumple con los requisitos de la empresa de mínima pérdida de datos y tiempo de inactividad al servir activamente tráfico desde múltiples regiones, lo que proporciona un RPO casi cero y potencialmente un RTO cero. Este enfoque asegura que las aplicaciones permanezcan disponibles incluso durante cortes regionales.",
        "Other Options": [
            "La solución de espera cálida, aunque reduce el RTO, puede no proporcionar las garantías necesarias de pérdida de datos ya que opera con una versión reducida de la aplicación, lo que podría llevar a posibles retrasos en la recuperación.",
            "La estrategia de respaldo y restauración tiene un RTO y RPO mucho más largos, lo que no se alinea con el estricto requisito de la empresa de mínima inactividad y pérdida de datos.",
            "La estrategia de luz piloto tampoco cumple completamente con los requisitos, ya que depende de provisionar recursos adicionales durante un desastre, lo que puede introducir retrasos en la recuperación."
        ]
    },
    {
        "Question Number": "69",
        "Situation": "Una empresa de servicios financieros está preocupada por posibles ataques DDoS en sus aplicaciones web alojadas en AWS. Quieren implementar una solución que pueda detectar y mitigar automáticamente tales amenazas mientras asegura que el tráfico legítimo no se vea afectado. La empresa también requiere la capacidad de monitorear alertas de seguridad y tener una visión integral de su postura de seguridad a través de diferentes servicios de AWS.",
        "Question": "¿Qué servicio de seguridad administrado por AWS proporciona la protección más completa contra ataques DDoS mientras permite capacidades de monitoreo y alerta?",
        "Options": {
            "1": "AWS WAF con reglas personalizadas para filtrado de tráfico y AWS Security Hub para gestión de seguridad centralizada.",
            "2": "AWS Shield Standard para protección básica contra DDoS y AWS Config para monitoreo de cumplimiento.",
            "3": "Amazon Inspector para evaluación de vulnerabilidades y AWS Security Hub para respuesta a incidentes.",
            "4": "AWS Shield Advanced junto con Amazon GuardDuty para detección de amenazas y alertas."
        },
        "Correct Answer": "AWS Shield Advanced junto con Amazon GuardDuty para detección de amenazas y alertas.",
        "Explanation": "AWS Shield Advanced proporciona protección DDoS mejorada e incluye características para visibilidad y mitigación de ataques en tiempo real, lo que lo hace adecuado para proteger aplicaciones web. Cuando se utiliza junto con Amazon GuardDuty, que ofrece detección de amenazas inteligente, esta combinación asegura capacidades de seguridad y monitoreo completas.",
        "Other Options": [
            "AWS WAF con reglas personalizadas es efectivo para filtrar tráfico malicioso, pero no proporciona mitigación DDoS. AWS Security Hub es útil para la gestión de seguridad centralizada, pero no protege directamente contra ataques DDoS.",
            "AWS Shield Standard ofrece protección básica contra DDoS, pero carece de las características avanzadas y capacidades de respuesta proactiva de Shield Advanced. AWS Config se centra en el monitoreo de cumplimiento y no aborda directamente las amenazas DDoS.",
            "Amazon Inspector se utiliza principalmente para la evaluación de vulnerabilidades y no ofrece protección DDoS ni capacidades de monitoreo de tráfico. Aunque AWS Security Hub puede proporcionar información sobre incidentes de seguridad, no sirve como una solución de mitigación."
        ]
    },
    {
        "Question Number": "70",
        "Situation": "Una empresa de servicios financieros está buscando implementar una solución de registro centralizado para mejorar la seguridad y el cumplimiento en su infraestructura de AWS. La empresa necesita asegurarse de que todos los registros, incluidos los registros de aplicaciones, las llamadas a la API y los eventos del sistema, sean agregados y monitoreados en busca de cualquier actividad sospechosa. También desean recibir notificaciones de eventos para entradas de registro críticas que requieran atención inmediata.",
        "Question": "¿Qué combinación de opciones ayudará a lograr una estrategia de registro centralizado y notificación de eventos? (Seleccione Dos)",
        "Options": {
            "1": "Utilizar Amazon CloudWatch Logs para agregar registros de varios servicios y aplicaciones de AWS.",
            "2": "Usar AWS Config para monitorear cambios de configuración y enviar alertas para cualquier recurso no conforme.",
            "3": "Implementar Amazon S3 para almacenamiento de registros sin ningún procesamiento o mecanismo de alerta adicional.",
            "4": "Configurar funciones de AWS Lambda para procesar registros y activar notificaciones a un tema de Amazon SNS para eventos críticos.",
            "5": "Aprovechar Amazon Elasticsearch Service para analizar registros y configurar alertas para patrones específicos."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Utilizar Amazon CloudWatch Logs para agregar registros de varios servicios y aplicaciones de AWS.",
            "Configurar funciones de AWS Lambda para procesar registros y activar notificaciones a un tema de Amazon SNS para eventos críticos."
        ],
        "Explanation": "Utilizar Amazon CloudWatch Logs permite la agregación de registros de múltiples fuentes, lo cual es crucial para el registro centralizado. Configurar funciones de AWS Lambda para activar notificaciones asegura que los eventos críticos sean atendidos de manera oportuna, mejorando la postura de seguridad de la organización.",
        "Other Options": [
            "Implementar Amazon S3 para almacenamiento de registros sin procesamiento no cumple con el requisito de monitoreo y notificación en tiempo real.",
            "Usar AWS Config se trata más de monitoreo de cumplimiento y no se relaciona directamente con el registro centralizado de registros de aplicaciones y sistemas.",
            "Si bien aprovechar Amazon Elasticsearch Service puede ayudar a analizar registros, no proporciona inherentemente la función de agregación centralizada necesaria sin una configuración adicional."
        ]
    },
    {
        "Question Number": "71",
        "Situation": "Una empresa de servicios financieros está atravesando una transformación digital y desea implementar un modelo de gobernanza en la nube para gestionar sus recursos de AWS de manera efectiva. La empresa debe asegurarse de cumplir con los requisitos regulatorios mientras proporciona a sus equipos de desarrollo la flexibilidad para innovar. La dirección ha solicitado al arquitecto de soluciones que diseñe un modelo de gobernanza que equilibre el control y la agilidad para múltiples equipos que trabajan en varios proyectos.",
        "Question": "¿Cuál de los siguientes modelos de gobernanza es el más adecuado para que esta empresa mantenga el cumplimiento mientras permite la autonomía del equipo?",
        "Options": {
            "1": "Establecer un modelo de gobernanza descentralizado donde cada equipo opere de manera independiente sin supervisión, promoviendo la máxima agilidad.",
            "2": "Usar un modelo de gobernanza híbrido que combine enfoques centralizados y descentralizados, dando a los equipos cierta autonomía mientras se mantiene el control de cumplimiento general.",
            "3": "Implementar un modelo de gobernanza centralizado con políticas estrictas aplicadas a nivel de cuenta, limitando el acceso del equipo a los recursos.",
            "4": "Adoptar un modelo de gobernanza federado que permita a los equipos gestionar sus propias cuentas de AWS mientras se adhieren a un conjunto compartido de directrices de cumplimiento."
        },
        "Correct Answer": "Adoptar un modelo de gobernanza federado que permita a los equipos gestionar sus propias cuentas de AWS mientras se adhieren a un conjunto compartido de directrices de cumplimiento.",
        "Explanation": "El modelo de gobernanza federado es adecuado ya que permite a los equipos de desarrollo tener control sobre sus propias cuentas de AWS mientras se asegura que sigan un conjunto común de directrices de cumplimiento. Este enfoque equilibra la necesidad de cumplimiento con la necesidad de agilidad e innovación, lo que lo hace ideal para los requisitos de la empresa.",
        "Other Options": [
            "El modelo de gobernanza centralizado puede inhibir la autonomía del equipo y ralentizar la innovación, lo que contradice el objetivo de la empresa de permitir flexibilidad en el desarrollo.",
            "El modelo de gobernanza descentralizado presenta riesgos significativos para el cumplimiento, ya que permite a los equipos operar sin supervisión, dificultando la adherencia a los requisitos regulatorios.",
            "El modelo de gobernanza híbrido podría crear confusión respecto a las responsabilidades y el cumplimiento, ya que puede no definir claramente el alcance de la autonomía del equipo frente al control centralizado."
        ]
    },
    {
        "Question Number": "72",
        "Situation": "Una gran empresa de comercio electrónico está transitando su mecanismo de autenticación de usuarios para integrarse con proveedores de identidad de terceros. La empresa busca mejorar la seguridad y proporcionar una experiencia de usuario fluida para sus clientes. El arquitecto de soluciones necesita elegir el mejor enfoque para integrar estos proveedores de identidad en la arquitectura de la aplicación existente mientras asegura que los datos de los usuarios permanezcan seguros y sean fácilmente gestionables. (Seleccione Dos)",
        "Question": "¿Cuál de las siguientes opciones debería implementar el arquitecto de soluciones para lograr estos objetivos?",
        "Options": {
            "1": "Utilizar AWS Lambda para validar tokens de proveedores de identidad de terceros.",
            "2": "Configurar inicio de sesión único (SSO) basado en SAML para permitir que los usuarios se autentiquen con proveedores de identidad de terceros.",
            "3": "Implementar Amazon Cognito para federar identidades de usuarios de proveedores de identidad de terceros.",
            "4": "Aprovechar Amazon API Gateway para crear un flujo de autenticación personalizado para proveedores de identidad de terceros.",
            "5": "Usar roles de AWS IAM para gestionar directamente el acceso de usuarios de proveedores de identidad de terceros."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Implementar Amazon Cognito para federar identidades de usuarios de proveedores de identidad de terceros.",
            "Configurar inicio de sesión único (SSO) basado en SAML para permitir que los usuarios se autentiquen con proveedores de identidad de terceros."
        ],
        "Explanation": "Implementar Amazon Cognito permite que la aplicación gestione fácilmente las identidades de los usuarios y soporte la integración con múltiples proveedores de terceros. Además, configurar SSO basado en SAML proporciona una forma segura para que los usuarios se autentiquen sin necesidad de gestionar credenciales separadas, mejorando la experiencia general del usuario.",
        "Other Options": [
            "Usar roles de AWS IAM no es adecuado para la gestión de autenticación de usuarios con proveedores de terceros, ya que los roles de IAM están diseñados principalmente para permisos de servicios de AWS en lugar de federación de identidades de usuarios.",
            "Aprovechar Amazon API Gateway para un flujo de autenticación personalizado añade complejidad innecesaria y no proporciona las características de seguridad y gestión de usuarios integradas que ofrecen servicios como Cognito.",
            "Si bien utilizar AWS Lambda para validar tokens puede funcionar, requiere un desarrollo personalizado adicional y una carga de gestión en comparación con el uso de soluciones integradas como Cognito o SSO basado en SAML."
        ]
    },
    {
        "Question Number": "73",
        "Situation": "Una empresa de servicios financieros está utilizando actualmente una base de datos PostgreSQL autogestionada en instancias de Amazon EC2 para manejar datos transaccionales. La base de datos requiere escalado frecuente para acomodar cargas de trabajo variables, y el equipo está buscando una solución administrada que pueda proporcionar copias de seguridad automatizadas, escalado y alta disponibilidad sin cambios significativos en la arquitectura de la aplicación. Además, la empresa tiene estrictos requisitos de cumplimiento para la seguridad de los datos y la recuperación ante desastres.",
        "Question": "¿Cuál de las siguientes opciones satisface mejor los requisitos de la empresa para una solución de base de datos administrada en AWS?",
        "Options": {
            "1": "Migrar la base de datos PostgreSQL a Amazon RDS for PostgreSQL para aprovechar las características de copias de seguridad automatizadas, escalado y alta disponibilidad, asegurando al mismo tiempo el cumplimiento y la seguridad.",
            "2": "Cambiar a usar Amazon DynamoDB para el almacenamiento de datos transaccionales, aprovechando su rendimiento y capacidades de escalado sin requerir cambios significativos en la lógica de la aplicación.",
            "3": "Continuar usando la base de datos PostgreSQL autogestionada en Amazon EC2, implementando scripts manuales para copias de seguridad y escalado según sea necesario para evitar complejidades de migración.",
            "4": "Desplegar Amazon OpenSearch Service para indexar y consultar los datos transaccionales, permitiendo análisis en tiempo real mientras se mantiene la base de datos existente en EC2 para el almacenamiento de datos."
        },
        "Correct Answer": "Migrar la base de datos PostgreSQL a Amazon RDS for PostgreSQL para aprovechar las características de copias de seguridad automatizadas, escalado y alta disponibilidad, asegurando al mismo tiempo el cumplimiento y la seguridad.",
        "Explanation": "Migrar a Amazon RDS for PostgreSQL proporciona una solución de base de datos completamente administrada que incluye copias de seguridad automatizadas, escalado y alta disponibilidad, lo que se alinea con la necesidad de la empresa de un servicio administrado que cumpla con los estándares de cumplimiento y seguridad sin cambios importantes en la arquitectura de la aplicación.",
        "Other Options": [
            "Cambiar a Amazon DynamoDB requeriría cambios significativos en la lógica de la aplicación, ya que DynamoDB es una base de datos NoSQL y el caso de uso actual implica datos transaccionales que se adaptan mejor a una base de datos relacional.",
            "Desplegar Amazon OpenSearch Service no aborda directamente la necesidad de una solución de base de datos relacional administrada capaz de manejar cargas de trabajo transaccionales y cumplir con los requisitos de cumplimiento, ya que está diseñado principalmente para búsqueda y análisis en lugar de procesamiento transaccional.",
            "Continuar con una base de datos PostgreSQL autogestionada en EC2 no cumple con el requisito de una solución administrada con copias de seguridad automatizadas y escalado, lo que aumenta la carga operativa y el riesgo de incumplimiento con los estándares de seguridad de datos."
        ]
    },
    {
        "Question Number": "74",
        "Situation": "Una empresa de servicios financieros opera una aplicación crítica alojada en AWS, que requiere alta disponibilidad y recuperación rápida en caso de un desastre. La aplicación procesa transacciones financieras sensibles y debe cumplir con requisitos regulatorios. La empresa está evaluando su estrategia de recuperación ante desastres (DR) para asegurar un tiempo de inactividad y pérdida de datos mínimos.",
        "Question": "¿Qué dos estrategias debería considerar la empresa para mejorar su plan de recuperación ante desastres? (Seleccione Dos)",
        "Options": {
            "1": "Usar AWS Elastic Disaster Recovery para automatizar los procedimientos de conmutación por error.",
            "2": "Crear instantáneas regulares de las bases de datos de Amazon RDS y almacenarlas en Amazon S3.",
            "3": "Utilizar AWS Backup para copias de seguridad programadas de instancias de EC2 y volúmenes de EBS.",
            "4": "Implementar un despliegue multi-región con configuración activa-activa.",
            "5": "Desplegar una réplica de lectura en la misma región para una recuperación rápida."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Implementar un despliegue multi-región con configuración activa-activa.",
            "Usar AWS Elastic Disaster Recovery para automatizar los procedimientos de conmutación por error."
        ],
        "Explanation": "Implementar un despliegue multi-región con una configuración activa-activa permite que la aplicación mantenga disponibilidad en diferentes regiones, asegurando que si una región falla, la otra pueda continuar procesando transacciones con un tiempo de inactividad mínimo. Además, usar AWS Elastic Disaster Recovery proporciona opciones automatizadas de conmutación por error y recuperación, lo que reduce significativamente el objetivo de tiempo de recuperación (RTO) y asegura la consistencia de los datos durante un desastre.",
        "Other Options": [
            "Crear instantáneas regulares de las bases de datos de Amazon RDS y almacenarlas en Amazon S3 proporciona respaldo, pero no asegura alta disponibilidad o recuperación rápida durante un desastre, ya que puede llevar a la pérdida de datos dependiendo de la frecuencia de las instantáneas.",
            "Desplegar una réplica de lectura en la misma región puede mejorar el rendimiento de lectura, pero no proporciona una solución viable para la recuperación ante desastres en caso de una falla a nivel de región.",
            "Utilizar AWS Backup para copias de seguridad programadas de instancias de EC2 y volúmenes de EBS es una buena práctica para la protección de datos; sin embargo, no es una estrategia integral de recuperación ante desastres, ya que no aborda la conmutación por error o la alta disponibilidad."
        ]
    },
    {
        "Question Number": "75",
        "Situation": "Una empresa de servicios financieros necesita integrar su aplicación con varios servicios de AWS, asegurando una comunicación segura y eficiente entre los servicios. El arquitecto tiene la tarea de elegir los puntos finales de servicio apropiados para estas integraciones para mejorar el rendimiento y la seguridad. (Seleccione Dos)",
        "Question": "¿Cuáles de las siguientes son las acciones recomendadas para cumplir con el requisito anterior?",
        "Options": {
            "1": "Configurar puntos finales de servicio en una conexión directa a un centro de datos local.",
            "2": "Implementar AWS PrivateLink para acceso seguro a servicios alojados en VPCs.",
            "3": "Utilizar puntos finales de VPC para conectarse a servicios de AWS sin atravesar Internet público.",
            "4": "Usar puntos finales de Internet público para todas las integraciones de servicios de AWS para evitar costos de VPC.",
            "5": "Aprovechar AWS Global Accelerator para mejorar la disponibilidad y el rendimiento de los puntos finales de servicio."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Utilizar puntos finales de VPC para conectarse a servicios de AWS sin atravesar Internet público.",
            "Implementar AWS PrivateLink para acceso seguro a servicios alojados en VPCs."
        ],
        "Explanation": "Utilizar puntos finales de VPC permite conexiones privadas a los servicios de AWS mientras se mantiene el tráfico dentro de la red de Amazon, mejorando la seguridad y el rendimiento. Implementar AWS PrivateLink también proporciona acceso seguro a servicios alojados en VPCs, asegurando aún más que la comunicación no salga de la red de AWS, reduciendo así la exposición a amenazas potenciales.",
        "Other Options": [
            "Usar puntos finales de Internet público aumenta la exposición a riesgos de seguridad y podría llevar a problemas de latencia, lo cual no es ideal para datos financieros sensibles.",
            "Configurar puntos finales de servicio en una conexión directa a un centro de datos local no aprovecharía los beneficios de la infraestructura de AWS y podría introducir complejidades innecesarias.",
            "Si bien AWS Global Accelerator puede ayudar a mejorar el rendimiento, no está diseñado específicamente para integraciones de servicios seguras como los puntos finales de VPC y PrivateLink."
        ]
    }
]