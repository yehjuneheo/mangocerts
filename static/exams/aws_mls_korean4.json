[
    {
        "Question Number": "1",
        "Situation": "데이터 과학자는 크기, 위치 및 부동산의 연령과 같은 다양한 특성을 기반으로 주택 가격을 예측하는 임무를 맡았습니다. 팀은 예측 솔루션을 만들기 위해 선형 회귀 모델을 사용하기로 결정했습니다. 그들은 모델의 성능과 보지 못한 데이터에 대한 일반화 능력을 평가하고자 합니다.",
        "Question": "데이터 과학자가 주택 가격 예측을 위한 선형 회귀 모델의 정확성을 평가하기 위해 어떤 지표를 사용해야 합니까?",
        "Options": {
            "1": "R-제곱",
            "2": "평균 절대 오차",
            "3": "F1 점수",
            "4": "혼동 행렬"
        },
        "Correct Answer": "R-제곱",
        "Explanation": "R-제곱은 회귀 모델에서 독립 변수 또는 변수들이 설명하는 종속 변수의 분산 비율을 나타내는 통계적 측정입니다. 이는 모델의 적합도를 통찰하는 데 도움을 주어 선형 회귀 성능 평가에 적합한 지표입니다.",
        "Other Options": [
            "평균 절대 오차는 예측 집합에서 오류의 평균 크기를 측정하지만 방향은 고려하지 않습니다. 회귀에는 유용하지만 모델이 설명하는 분산 비율을 포착하지는 않습니다.",
            "혼동 행렬은 분류 문제에 사용되어 모델의 성능을 실제 분류와 예측 분류를 보여줌으로써 평가합니다. 회귀 작업에는 적용되지 않습니다.",
            "F1 점수는 이진 분류 작업에서 모델의 정확성을 측정하며, 정밀도와 재현율을 결합합니다. 숫자 예측이 이루어지는 회귀 모델에는 적용되지 않습니다."
        ]
    },
    {
        "Question Number": "2",
        "Situation": "머신 러닝 전문가가 고객 이탈과 관련된 비즈니스 문제에 대한 머신 러닝 솔루션을 구현할지 결정하고 있습니다. 전문가는 문제의 복잡성이 전통적인 방법보다 머신 러닝을 사용할 정당성을 제공하는지 판단해야 합니다.",
        "Question": "다음 시나리오 중 머신 러닝이 최선의 접근 방식이 아님을 시사하는 것은 무엇입니까?",
        "Options": {
            "1": "사용 가능한 비구조화 데이터의 양이 많다.",
            "2": "사용자 경험을 향상시키기 위해 실시간 예측이 필요하다.",
            "3": "입력과 출력 간의 관계가 매우 비선형적이다.",
            "4": "문제가 간단하고 기본적인 휴리스틱으로 해결할 수 있다."
        },
        "Correct Answer": "문제가 간단하고 기본적인 휴리스틱으로 해결할 수 있다.",
        "Explanation": "문제가 간단하고 기본적인 휴리스틱이나 규칙 기반 시스템을 사용하여 효과적으로 해결할 수 있는 경우, 머신 러닝 모델의 오버헤드와 복잡성은 일반적으로 불필요합니다. 전통적인 방법이 더 빠르고 효율적인 솔루션을 제공할 수 있습니다.",
        "Other Options": [
            "대량의 비구조화 데이터는 일반적으로 머신 러닝 기술을 필요로 하며, 이러한 데이터에서 효과적으로 통찰을 추출할 수 있습니다. 전통적인 방법은 이를 처리하는 데 어려움을 겪을 수 있습니다.",
            "실시간 예측은 머신 러닝을 사용해야 한다는 강력한 지표이며, 특정 알고리즘은 들어오는 데이터를 기반으로 빠른 예측을 위해 특별히 설계되었습니다.",
            "입력과 출력 간의 매우 비선형적인 관계는 종종 머신 러닝 모델의 사용을 필요로 하며, 이는 간단한 모델이 식별하지 못하는 복잡한 패턴을 포착할 수 있습니다."
        ]
    },
    {
        "Question Number": "3",
        "Situation": "데이터 과학자가 이미지 분류를 위한 신경망을 개발하고 있습니다. 역전파 알고리즘의 구현이 올바른지 확인하기 위해 과학자는 디버깅 기술을 사용하기로 결정했습니다.",
        "Question": "데이터 과학자가 신경망에서 기울기 계산의 정확성을 검증하기 위해 어떤 기술을 사용해야 합니까?",
        "Options": {
            "1": "모델을 더 큰 데이터셋으로 훈련시켜 일반화를 개선한다.",
            "2": "교차 검증을 사용하여 보지 못한 데이터에서 모델의 성능을 평가한다.",
            "3": "기울기 확인을 구현하여 분석적 기울기와 수치적 기울기를 비교한다.",
            "4": "훈련 중 드롭아웃을 적용하여 과적합을 방지한다."
        },
        "Correct Answer": "기울기 확인을 구현하여 분석적 기울기와 수치적 기울기를 비교한다.",
        "Explanation": "기울기 확인은 역전파 알고리즘에 의해 계산된 기울기의 정확성을 검증하기 위해 수치적으로 근사된 기울기와 비교하는 기술입니다. 이 방법은 신경망 코드가 정확하게 작동하고 있는지 확인하는 데 도움을 줍니다.",
        "Other Options": [
            "교차 검증은 데이터의 서로 다른 하위 집합에서 모델의 성능을 평가하는 데 사용되는 기술이지만, 기울기 계산을 검증하는 데는 도움이 되지 않습니다.",
            "드롭아웃을 적용하는 것은 과적합을 방지하기 위한 정규화 방법이지만, 기울기 계산의 정확성을 확인하는 데는 도움이 되지 않습니다.",
            "더 큰 데이터셋으로 훈련하는 것은 모델의 일반화를 개선할 수 있지만, 기울기 계산의 정확성을 검증하는 수단을 제공하지는 않습니다."
        ]
    },
    {
        "Question Number": "4",
        "Situation": "소매 회사가 과거 데이터를 기반으로 미래 판매를 예측하기 위한 예측 모델을 개발하고 있습니다. 데이터에는 계절적 트렌드, 프로모션 및 경제 지표가 포함됩니다. 데이터 과학자는 현재 모델이 기본 패턴을 효과적으로 포착하지 못하고 있어 부정확한 예측 결과를 초래하고 있음을 발견합니다. 데이터 과학자는 모델 성능을 개선하는 임무를 맡고 있습니다.",
        "Question": "데이터 과학자는 계절적 트렌드를 더 잘 포착하고 예측 정확도를 개선하기 위해 어떤 접근 방식을 취해야 합니까?",
        "Options": {
            "1": "데이터의 다양한 하위 집합에서 모델 성능을 평가하기 위해 교차 검증 기법을 사용합니다.",
            "2": "결과의 해석 가능성을 높이기 위해 더 간단한 모델을 선택합니다.",
            "3": "계절적 트렌드와 프로모션 효과를 나타내는 새로운 변수를 생성하기 위해 특성 공학을 구현합니다.",
            "4": "특성 선택 문제를 해결하지 않고 더 고급 알고리즘을 사용하여 모델의 복잡성을 증가시킵니다."
        },
        "Correct Answer": "계절적 트렌드와 프로모션 효과를 나타내는 새로운 변수를 생성하기 위해 특성 공학을 구현합니다.",
        "Explanation": "특성 공학은 데이터 과학자가 관련 정보를 추출하고 데이터의 기본 계절적 패턴과 프로모션 영향을 더 잘 나타내는 변수를 생성할 수 있게 하여 모델 정확도를 크게 향상시킬 수 있습니다.",
        "Other Options": [
            "모델의 복잡성을 증가시키는 것은 데이터에 존재하는 계절적 패턴에 대한 이해를 개선하지 않고 과적합으로 이어질 수 있습니다.",
            "교차 검증을 사용하는 것은 모델 평가에 중요하지만, 데이터의 계절적 트렌드를 포착하는 기본 문제를 직접적으로 해결하지는 않습니다.",
            "더 간단한 모델을 선택하는 것은 성능을 저하시킬 수 있으며, 데이터의 복잡성이 더 미세한 접근 방식을 요구하는 경우 반드시 더 나은 정확도로 이어지지는 않습니다."
        ]
    },
    {
        "Question Number": "5",
        "Situation": "데이터 과학자는 대규모 데이터 세트를 사용하여 이미지 분류를 위한 딥 러닝 모델을 훈련하는 임무를 맡고 있습니다. 모델 훈련은 비용 효율적이고 효율적이어야 하며, 과학자는 이를 위해 AWS Batch를 사용할 계획입니다. 과학자는 비용을 줄이기 위해 스팟 인스턴스 사용을 고려하고 있습니다.",
        "Question": "AWS Batch에서 딥 러닝 모델 훈련을 위해 스팟 인스턴스를 사용할 때 가장 관련이 깊은 이점은 무엇입니까?",
        "Options": {
            "1": "모든 인스턴스 유형에 대한 성능 증가",
            "2": "인스턴스 프로비저닝 관리의 단순화",
            "3": "온디맨드 인스턴스에 비해 상당히 낮은 비용",
            "4": "장기 실행 작업에 대한 보장된 가용성"
        },
        "Correct Answer": "온디맨드 인스턴스에 비해 상당히 낮은 비용",
        "Explanation": "스팟 인스턴스를 사용하면 종종 온디맨드 인스턴스 가격의 일부로 제공되기 때문에 비용을 극적으로 줄일 수 있습니다. 이는 중단을 견딜 수 있는 대규모 모델 훈련을 위한 비용 효율적인 옵션이 됩니다.",
        "Other Options": [
            "스팟 인스턴스는 가용성에 따라 달라지며 AWS에 의해 종료될 수 있으므로 장기 실행 작업에 대한 가용성을 보장하지 않습니다.",
            "일부 인스턴스 유형이 다른 인스턴스보다 성능이 더 좋을 수 있지만, 스팟 인스턴스는 모든 인스턴스 유형에 대한 성능 증가를 본질적으로 보장하지 않으며, 성능은 선택된 특정 인스턴스에 따라 달라집니다.",
            "AWS Batch는 일부 관리 기능을 제공하지만, 스팟 인스턴스를 사용하는 것이 다른 인스턴스 유형에 비해 인스턴스 프로비저닝 관리의 단순화를 보장하지는 않습니다."
        ]
    },
    {
        "Question Number": "6",
        "Situation": "데이터 과학자는 대규모 텍스트 문서 집합을 분석하여 각 문서의 내용을 특징짓는 가장 중요한 용어를 식별하는 임무를 맡고 있습니다. 과학자는 이 목표를 달성하기 위해 TF-IDF(용어 빈도-역 문서 빈도) 접근 방식을 적용하기로 결정합니다. 목표는 각 문서에서 용어의 관련성에 따라 순위를 매기고 의미 있는 통찰력을 제공하지 않을 수 있는 일반 용어를 필터링하는 것입니다.",
        "Question": "다음 중 TF-IDF 계산의 구성 요소를 올바르게 설명하는 문장은 무엇입니까?",
        "Options": {
            "1": "용어 빈도(TF)는 문서에서 용어가 나타나는 빈도를 해당 문서의 총 용어 수에 대해 측정합니다.",
            "2": "역 문서 빈도(IDF)는 총 문서 수를 해당 용어가 포함된 문서 수로 나누어 계산됩니다.",
            "3": "TF-IDF 점수는 TF와 DF를 곱하여 계산되며, 여기서 DF는 문서 빈도를 나타냅니다.",
            "4": "TF-IDF에서 유니그램은 단일 단어를 나타내고, 바이그램은 텍스트 내의 연속된 두 단어 쌍을 나타냅니다."
        },
        "Correct Answer": "용어 빈도(TF)는 문서에서 용어가 나타나는 빈도를 해당 문서의 총 용어 수에 대해 측정합니다.",
        "Explanation": "정답은 TF-IDF 프레임워크에서 용어 빈도(TF)가 어떻게 계산되는지를 정확하게 설명하며, 문서 내의 총 용어 수에 대한 용어의 빈도에 초점을 맞추고 있습니다.",
        "Other Options": [
            "이 옵션은 역 문서 빈도(IDF)를 잘못 정의하고 있습니다. IDF는 총 문서 수를 해당 용어가 포함된 문서 수로 나눈 로그로 계산되어야 하며, 단순히 총 문서 수를 문서 수로 나누는 것이 아닙니다.",
            "이 문장은 잘못되었습니다. TF-IDF는 용어 빈도(TF)와 역 문서 빈도(IDF)를 곱하여 계산되며, 문서 빈도(DF)는 다른 지표입니다.",
            "이 옵션은 유니그램과 바이그램을 올바르게 식별하지만, 바이그램이 연속된 두 단어 쌍을 나타낸다는 점을 언급하지 않아 TF-IDF 맥락에서 덜 정확하고 직접적으로 관련이 없습니다."
        ]
    },
    {
        "Question Number": "7",
        "Situation": "데이터 엔지니어가 전자상거래 애플리케이션의 실시간 사용자 활동 로그를 처리하기 위한 데이터 처리 파이프라인 설계를 맡았습니다. 요구 사항에는 라이브 대시보드 및 알림을 지원하기 위한 즉각적인 데이터 수집, 처리 및 분석이 포함됩니다. 엔지니어는 이 시나리오에 적합한 데이터 작업 스타일을 식별해야 합니다.",
        "Question": "실시간 사용자 활동 로그를 처리하는 데 가장 적합한 데이터 작업 스타일은 무엇입니까?",
        "Options": {
            "1": "예약 처리 작업",
            "2": "스트리밍 처리 작업",
            "3": "배치 처리 작업",
            "4": "마이크로 배치 처리 작업"
        },
        "Correct Answer": "스트리밍 처리 작업",
        "Explanation": "스트리밍 처리 작업은 실시간 데이터 수집 및 즉각적인 처리를 위해 설계되어 있으며, 시기적절한 통찰력이 중요한 사용자 활동 로그 처리와 같은 시나리오에 이상적입니다.",
        "Other Options": [
            "배치 처리 작업은 한 번에 대량의 데이터를 처리하도록 설계되어 있으며, 일반적으로 지연이 발생하므로 실시간 통찰력 요구 사항을 충족하지 않습니다.",
            "마이크로 배치 처리 작업은 중간 지점으로 볼 수 있지만, 여전히 작은 배치로 데이터를 처리하므로 지연을 초래하여 즉각적인 요구에 덜 최적입니다.",
            "예약 처리 작업은 일반적으로 미리 정의된 간격으로 실행되므로 사용자 활동 로그에 필요한 실시간 수집 및 처리를 지원하지 않기 때문에 이 맥락에서는 적절하지 않습니다."
        ]
    },
    {
        "Question Number": "8",
        "Situation": "머신 러닝 전문가가 Amazon SageMaker를 사용하여 중요한 애플리케이션을 위한 딥 러닝 모델을 조정하고 있습니다. 전문가는 모델의 성능과 훈련 효율성을 최적화하는 데 집중하고 있습니다. 그들은 훈련 과정이 시작되기 전에 조정할 수 있는 하이퍼파라미터를 검토하고 있습니다.",
        "Question": "모델이 훈련 중 얼마나 빨리 학습하고 가중치를 조정하는지를 결정하는 데 중요한 하이퍼파라미터는 무엇입니까?",
        "Options": {
            "1": "모델 아키텍처",
            "2": "학습률",
            "3": "배치 크기",
            "4": "에포크 수"
        },
        "Correct Answer": "학습률",
        "Explanation": "학습률은 모델 가중치가 업데이트될 때마다 추정된 오류에 따라 모델을 얼마나 변경할지를 제어하는 하이퍼파라미터입니다. 이는 훈련 중 수렴 속도와 안정성을 균형 있게 유지하는 데 중요합니다.",
        "Other Options": [
            "배치 크기는 모델의 내부 매개변수가 업데이트되기 전에 처리되는 샘플 수를 결정하지만, 모델이 얼마나 빨리 학습하는지에 직접적인 영향을 미치지 않습니다.",
            "에포크 수는 학습 알고리즘이 전체 훈련 데이터셋을 몇 번 반복할지를 나타내지만, 업데이트당 학습 속도를 결정하지는 않습니다.",
            "모델 아키텍처는 모델 자체의 설계, 즉 사용되는 레이어의 수와 유형을 포함하며, 학습 속도와 관련하여 훈련 전에 설정되는 하이퍼파라미터가 아닙니다."
        ]
    },
    {
        "Question Number": "9",
        "Situation": "데이터 과학자가 감정 분석 프로젝트를 위해 데이터셋을 준비하고 있습니다. 데이터셋을 검사한 결과, 여러 개의 결측값, 손상된 항목, 그리고 텍스트 데이터에서 많은 불용어가 발견되었습니다. 목표는 머신 러닝 모델 훈련 전에 데이터셋의 품질을 보장하는 것입니다.",
        "Question": "이 데이터셋에서 결측 데이터, 손상된 데이터 및 불용어를 처리하는 가장 좋은 방법은 무엇입니까?",
        "Options": {
            "1": "결측값이 있는 모든 행을 제거하고, 손상된 항목은 자리 표시자로 대체하며, 일반적인 불용어를 필터링합니다.",
            "2": "결측값을 무시하고, 손상된 항목을 제거하며, 불용어 목록을 사용하여 이를 제거합니다.",
            "3": "결측값을 평균으로 채우고, 손상된 항목은 그대로 두며, 모든 불용어를 유지합니다.",
            "4": "결측값에 대해 보간법을 사용하고, 손상된 항목을 임의의 데이터로 수정하며, 모든 불용어를 유지합니다."
        },
        "Correct Answer": "결측값이 있는 모든 행을 제거하고, 손상된 항목은 자리 표시자로 대체하며, 일반적인 불용어를 필터링합니다.",
        "Explanation": "결측 데이터를 처리하는 가장 좋은 방법은 데이터셋의 무결성을 유지하기 위해 결측값이 있는 행을 제거하는 것입니다. 손상된 항목은 편향을 도입하지 않도록 자리 표시자로 대체해야 하며, 불용어를 필터링하면 감정 분석에 가장 유용한 용어에 집중할 수 있습니다.",
        "Other Options": [
            "결측값을 평균으로 채우는 것은 편향을 초래할 수 있으며, 결측 데이터 문제를 적절히 해결하지 못합니다. 손상된 항목을 그대로 두면 모델의 부정확성을 초래할 수 있습니다.",
            "결측값에 대해 보간법을 사용하는 것은 모든 유형의 데이터에 적합하지 않을 수 있으며, 손상된 항목을 임의의 데이터로 수정하는 것은 손상의 근본 원인을 해결하지 않습니다. 불용어를 유지하면 텍스트 데이터의 중요성이 희석될 수 있습니다.",
            "결측값을 무시하면 상당한 데이터 손실이 발생할 수 있으며, 모델에 편향을 초래할 수 있습니다. 손상된 항목을 이해하지 않고 제거하면 데이터 손실로 이어질 수 있습니다. 모든 불용어를 유지하는 것은 감정 분석에 의미 있는 기여를 하지 않으므로 바람직하지 않습니다."
        ]
    },
    {
        "Question Number": "10",
        "Situation": "데이터 과학자는 기계 학습 모델을 위한 대규모 데이터셋을 전처리하는 임무를 맡았습니다. 그들은 특정 특성이 높은 상관관계를 가지고 있음을 깨닫고, 모델 성능을 개선하고 계산 시간을 줄이기 위해 데이터의 차원을 축소하기로 결정했습니다.",
        "Question": "데이터의 본질적인 패턴을 유지하면서 차원을 축소하기 위해 이 시나리오에 가장 적합한 기술은 무엇입니까?",
        "Options": {
            "1": "Principal Component Analysis",
            "2": "Binning",
            "3": "One-Hot Encoding",
            "4": "Tokenization"
        },
        "Correct Answer": "Principal Component Analysis",
        "Explanation": "주성분 분석(Principal Component Analysis, PCA)은 데이터를 새로운 좌표계로 변환하여 차원을 축소하는 강력한 기술입니다. 이때 어떤 투영에서도 가장 큰 분산이 첫 번째 좌표(주성분)에 위치하게 됩니다. 이는 특성의 수를 줄이면서 데이터의 본질적인 패턴을 유지하는 데 도움이 되어, 설명된 시나리오에 적합합니다.",
        "Other Options": [
            "One-Hot Encoding은 범주형 변수를 이진 행렬로 변환하는 데 사용되는 기술입니다. 이는 차원을 축소하지 않으며, 고유한 범주가 많을 경우 특성의 수를 증가시킬 수 있습니다.",
            "Binning은 연속 데이터를 이산 구간으로 그룹화하는 방법입니다. 모델을 단순화하고 이상치를 처리하는 데 도움이 될 수 있지만, 데이터셋의 차원을 효과적으로 축소하지는 않습니다.",
            "Tokenization은 주로 자연어 처리에서 텍스트를 개별 토큰이나 단어로 분해하는 데 사용됩니다. 이는 차원 축소를 위해 설계된 것이 아니며, 수치 특성 집합의 맥락에서는 관련이 없습니다."
        ]
    },
    {
        "Question Number": "11",
        "Situation": "소매 회사는 고객의 구매 행동에 따라 고객을 분류하기 위해 의사 결정 트리를 개발하고 있습니다. 데이터셋에는 나이, 소득 및 쇼핑 빈도와 같은 특성이 포함되어 있습니다.",
        "Question": "데이터 과학자는 의사 결정 트리에서 첫 번째 분할을 위한 최상의 특성을 결정하기 위해 어떤 방법을 사용해야 합니까?",
        "Options": {
            "1": "각 특성에 대해 Gini 불순도를 계산하고 가장 낮은 값을 가진 특성을 선택합니다.",
            "2": "첫 번째 분할을 위해 고유 값의 빈도가 가장 높은 특성을 사용합니다.",
            "3": "각 특성에 대해 평균 제곱 오차를 계산하고 가장 높은 오류를 가진 특성을 선택합니다.",
            "4": "첫 번째 분할을 위해 결측치가 가장 많은 특성을 선택합니다."
        },
        "Correct Answer": "각 특성에 대해 Gini 불순도를 계산하고 가장 낮은 값을 가진 특성을 선택합니다.",
        "Explanation": "Gini 불순도는 의사 결정 트리에서 분할의 품질을 평가하는 데 사용되는 척도입니다. 가중 평균을 계산한 후 가장 낮은 Gini 불순도를 초래하는 특성이 첫 번째 분할을 위한 최상의 선택입니다. 이는 클래스를 가장 효과적으로 분리합니다.",
        "Other Options": [
            "평균 제곱 오차를 계산하는 것은 분류 작업에 적용되지 않으며, 회귀 문제와 관련이 있습니다.",
            "고유 값의 빈도가 가장 높은 특성을 선택하는 것은 클래스 간의 최상의 분리를 보장하지 않습니다.",
            "결측치가 가장 많은 특성을 선택하는 것은 비효율적이며, 효과적인 클래스 분리에 기여하지 않습니다."
        ]
    },
    {
        "Question Number": "12",
        "Situation": "데이터 과학자는 고객 구매 이력이 포함된 데이터셋을 사용하여 분류 모델을 개발하고 있습니다. 모델이 잘 일반화되고 과적합을 피하기 위해, 과학자는 적절한 검증 전략을 구현해야 합니다. 그들은 단순한 훈련-테스트 분할을 사용하지 않기로 결정하고, 여러 번의 훈련 및 검증 반복을 허용하는 방법을 선택합니다.",
        "Question": "이 목표를 달성하기 위해 데이터 과학자는 어떤 교차 검증 기법을 사용해야 합니까?",
        "Options": {
            "1": "k-겹 교차 검증 방법을 구현하여 데이터를 k개의 하위 집합으로 나누고 각 하위 집합을 순차적으로 검증 세트로 사용합니다.",
            "2": "각 개별 레코드를 하나씩 검증을 위해 제외하는 leave-one-out 교차 검증을 적용합니다.",
            "3": "기록의 시간 순서에 따라 모델을 검증하기 위해 롤링 윈도우 접근 방식을 사용합니다.",
            "4": "각 반복에서 검증을 위해 고정 비율의 데이터를 선택하기 위해 층화 샘플링을 사용합니다."
        },
        "Correct Answer": "k-겹 교차 검증 방법을 구현하여 데이터를 k개의 하위 집합으로 나누고 각 하위 집합을 순차적으로 검증 세트로 사용합니다.",
        "Explanation": "k-겹 교차 검증은 모델이 데이터의 서로 다른 부분에 대해 여러 번 훈련되고 검증될 수 있도록 하는 강력한 기법입니다. 이를 통해 모든 데이터 포인트가 훈련 및 검증에 사용되며, 모델 성능을 정확하게 평가하고 과적합의 위험을 줄이는 데 도움이 됩니다.",
        "Other Options": [
            "층화 샘플링은 교차 검증 기법이 아니라 각 클래스가 검증 세트에 비례적으로 나타나도록 보장하는 샘플링 방법입니다. 이는 k-겹이 제공하는 여러 훈련 라운드를 제공하지 않습니다.",
            "leave-one-out 교차 검증은 대규모 데이터셋에서 계산 비용이 많이 들 수 있으며, 모델을 n번 훈련해야 하므로(k는 레코드 수) k-겹 교차 검증보다 비효율적입니다.",
            "롤링 윈도우 접근 방식은 시계열 데이터에 적합하지만 분류 작업에 필요한 포괄적인 검증을 제공하지 않습니다. 데이터가 독립적이고 동일하게 분포되지 않으면 편향이 발생할 수 있습니다."
        ]
    },
    {
        "Question Number": "13",
        "Situation": "머신 러닝 엔지니어가 MXNet 프레임워크를 사용하여 딥 러닝 모델을 개발하고 있습니다. 엔지니어는 PyTorch에서 제공하는 것과 유사하게 훈련 과정 중 유연성을 위해 동적 계산 그래프를 구현해야 합니다. 또한, 엔지니어는 모델 개발을 지원하기 위해 Scikit-learn을 사용하여 전처리 및 평가를 수행하고, 내장 데이터셋을 활용하고자 합니다.",
        "Question": "모델 훈련 중 자동 미분을 촉진하기 위해 엔지니어가 MXNet에서 활성화해야 하는 기능은 무엇입니까?",
        "Options": {
            "1": "MXNet의 Autograd 기능",
            "2": "MXNet의 정적 그래프 최적화",
            "3": "Pandas의 데이터 조작 기능",
            "4": "Scikit-learn의 내장 데이터셋"
        },
        "Correct Answer": "MXNet의 Autograd 기능",
        "Explanation": "MXNet의 Autograd 기능은 동적 계산과 자동 미분을 가능하게 하여, 특히 모델 아키텍처가 변경될 수 있는 상황에서 딥 러닝 모델의 훈련 중 역전파를 구현하는 데 필수적입니다.",
        "Other Options": [
            "MXNet의 정적 그래프 최적화는 사전 정의된 계산 그래프를 최적화하는 데 주로 사용되며, 즉석에서 그래프 생성을 지원하지 않습니다.",
            "Scikit-learn은 내장 데이터셋을 제공하지만, 딥 러닝 모델 훈련에 필요한 자동 미분이나 동적 그래프 기능을 제공하지 않습니다.",
            "Pandas의 데이터 조작 기능은 데이터 전처리에 유용하지만, 딥 러닝에서 동적 계산 그래프나 역전파 구현과는 관련이 없습니다."
        ]
    },
    {
        "Question Number": "14",
        "Situation": "개발자가 다국어 사용자 기반을 위한 텍스트를 음성으로 변환하는 애플리케이션을 만들고 있습니다. 이 애플리케이션은 다양한 발음과 음성 스타일을 지원해야 하며, 특정 발음 조정을 허용해야 합니다.",
        "Question": "Amazon Polly의 어떤 기능을 사용하여 음성 출력에서 특정 단어 또는 약어의 발음을 사용자 정의할 수 있습니까?",
        "Options": {
            "1": "내장 음성 선택을 사용하여 남성 및 여성 음성 중에서 선택합니다.",
            "2": "특정 단어 또는 약어의 발음을 사용자 정의하기 위해 어휘를 업로드합니다.",
            "3": "다른 언어를 선택하여 음성 합성 출력을 변경합니다.",
            "4": "SSML 태그를 구현하여 음성에 일시 정지 및 음조 변화를 추가합니다."
        },
        "Correct Answer": "특정 단어 또는 약어의 발음을 사용자 정의하기 위해 어휘를 업로드합니다.",
        "Explanation": "Amazon Polly는 사용자가 특정 단어 또는 구문이 어떻게 발음되는지를 정의하는 파일인 어휘를 업로드할 수 있도록 합니다. 이 기능은 약어 및 전문 용어의 발음을 사용자 정의하는 데 특히 유용하여 음성 출력의 명확성을 향상시킵니다.",
        "Other Options": [
            "남성 또는 여성 음성을 선택하는 것은 음성 특성을 변경할 수 있지만, 특정 단어 또는 약어의 발음을 사용자 정의하는 방법을 제공하지 않습니다.",
            "SSML 태그는 음성 출력에 일시 정지 및 강조와 같은 효과를 추가하는 데 사용되지만, 단어 발음 자체를 사용자 정의할 수는 없습니다.",
            "언어를 변경하면 전체 음성 출력에 영향을 미칠 수 있지만, 해당 언어 내에서 특정 용어의 발음을 사용자 정의하는 메커니즘을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "15",
        "Situation": "데이터 과학자가 Amazon SageMaker를 사용하여 머신 러닝 모델을 개발하고 있습니다. 모델의 성능이 견고하고 보지 못한 데이터에 잘 일반화되도록 하기 위해, 데이터 과학자는 효과적인 교차 검증 전략을 구현해야 합니다. 데이터셋이 상대적으로 작고, 과학자는 성능 평가에서 편향을 최소화하면서 사용되는 훈련 데이터를 최대화하고자 합니다. 이 시나리오에서 교차 검증을 위한 가장 적합한 접근 방식은 무엇입니까?",
        "Question": "데이터 과학자가 훈련 데이터 사용과 편향 없는 성능 평가 간의 최상의 균형을 달성하기 위해 사용해야 하는 교차 검증 방법은 무엇입니까?",
        "Options": {
            "1": "폴드 간 클래스 분포를 유지하기 위한 층화 k-겹 교차 검증.",
            "2": "모든 데이터 포인트를 훈련에 활용하기 위한 Leave-one-out 교차 검증 (LOOCV).",
            "3": "k 값을 5로 설정한 k-겹 교차 검증.",
            "4": "평가를 위한 다양한 훈련 세트를 생성하기 위한 대체 샘플링."
        },
        "Correct Answer": "폴드 간 클래스 분포를 유지하기 위한 층화 k-겹 교차 검증.",
        "Explanation": "층화 k-겹 교차 검증은 데이터셋의 각 폴드가 전체 데이터셋과 동일한 비율의 클래스를 유지하도록 보장하여, 특히 불균형 클래스 분포가 있는 데이터셋에서 균형 잡힌 평가에 중요합니다. 이 방법은 사용되는 훈련 데이터를 최대화하면서 모델 성능에 대한 편향 없는 추정치를 제공합니다.",
        "Other Options": [
            "k 값을 5로 설정한 k-겹 교차 검증은 불균형 데이터셋에서 클래스 분포를 적절히 유지하지 못할 수 있어, 편향된 성능 메트릭으로 이어질 수 있습니다.",
            "Leave-one-out 교차 검증 (LOOCV)은 거의 모든 데이터를 훈련에 사용하지만, 계산 비용이 많이 들고 특히 작은 데이터셋에서 성능 추정의 높은 분산을 초래할 수 있습니다.",
            "대체 샘플링은 훈련 세트에서 반복 샘플을 허용하므로 과적합을 초래할 수 있으며, 모델 성능에 대한 편향 없는 추정치를 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "16",
        "Situation": "데이터 과학자는 고차원 데이터셋을 다루고 있으며 모델 성능과 해석 가능성에 어려움을 겪고 있습니다. 이를 해결하기 위해 데이터 과학자는 데이터셋의 분산을 유지하면서 특징의 수를 줄이기를 원합니다. 그들은 비지도 학습 접근 방식의 일환으로 주성분 분석(Principal Component Analysis, PCA)과 K-평균 클러스터링을 사용할 것을 고려하고 있습니다.",
        "Question": "데이터셋에 K-평균 클러스터링을 적용하기 전에 PCA를 사용하는 주요 장점은 무엇인가요?",
        "Options": {
            "1": "PCA는 데이터셋의 노이즈를 줄여 K-평균 클러스터링의 전반적인 성능을 향상시킵니다.",
            "2": "PCA는 K-평균을 위한 데이터 포인트에 레이블을 붙이는 데 사용되어 클러스터링의 정확성을 향상시킵니다.",
            "3": "PCA는 특징의 수를 증가시켜 K-평균의 클러스터링 결과를 향상시킵니다.",
            "4": "PCA는 데이터를 저차원 공간에서 시각화하는 데 도움을 주어 클러스터를 식별하기 쉽게 만듭니다."
        },
        "Correct Answer": "PCA는 데이터셋의 노이즈를 줄여 K-평균 클러스터링의 전반적인 성능을 향상시킵니다.",
        "Explanation": "PCA를 사용하면 데이터셋의 차원을 줄이면서 대부분의 분산을 유지할 수 있어 노이즈와 관련 없는 특징을 제거하는 데 도움이 됩니다. 이는 K-평균이 적용될 때 더 효과적인 클러스터링 결과로 이어지며, 알고리즘이 데이터의 필수 패턴을 포착하는 축소된 특징 집합에서 더 효율적으로 작동할 수 있습니다.",
        "Other Options": [
            "PCA는 저차원에서 데이터를 시각화하는 데 도움을 주지만, 이 맥락에서의 주요 장점은 클러스터 식별을 위한 시각화가 아니라 노이즈 감소입니다.",
            "PCA는 특징의 수를 증가시키지 않고 오히려 줄입니다. 더 많은 특징은 과적합을 초래할 수 있으며 K-평균 클러스터링의 결과에 부정적인 영향을 미칠 수 있습니다.",
            "PCA는 데이터 포인트에 레이블을 붙이지 않고, 특징을 주성분으로 변환합니다. K-평균 클러스터링은 거리 메트릭에 의존하며 PCA의 레이블을 사용하지 않습니다."
        ]
    },
    {
        "Question Number": "17",
        "Situation": "데이터 과학자는 온라인 구독 서비스의 고객 이탈을 분류하는 모델을 개발하는 임무를 맡고 있습니다. 데이터셋에는 고객 인구 통계, 구독 세부 사항 및 사용 패턴을 포함한 많은 특징이 포함되어 있습니다. 데이터 과학자는 단일 결정 트리 모델보다 분류 정확도를 향상시키기 위해 랜덤 포레스트(Random Forest) 알고리즘을 사용하기로 결정했습니다. 데이터 과학자는 랜덤 포레스트 모델이 잘 최적화되고 해석 가능하도록 해야 합니다.",
        "Question": "이 분류 작업에 랜덤 포레스트 모델을 사용하는 주요 장점은 무엇인가요?",
        "Options": {
            "1": "랜덤 포레스트는 여러 결정 트리의 예측을 집계하여 과적합을 줄입니다.",
            "2": "랜덤 포레스트는 각 결정 트리를 생성하기 위해 모든 특징을 동등하게 사용합니다.",
            "3": "랜덤 포레스트는 결정 트리에 비해 훈련을 위한 데이터셋이 더 작아도 됩니다.",
            "4": "랜덤 포레스트는 쉽게 해석할 수 있도록 단일 결정 트리 출력을 제공합니다."
        },
        "Correct Answer": "랜덤 포레스트는 여러 결정 트리의 예측을 집계하여 과적합을 줄입니다.",
        "Explanation": "랜덤 포레스트는 데이터의 무작위 하위 집합에서 여러 결정 트리를 생성하고 그 예측을 평균화하여 예측의 정확성을 향상시키고 과적합 가능성을 줄입니다. 이 앙상블 접근 방식은 단일 결정 트리보다 데이터의 더 복잡한 패턴을 포착하는 데 도움이 됩니다.",
        "Other Options": [
            "이것은 잘못된 설명입니다. 랜덤 포레스트는 더 큰 데이터셋을 처리할 수 있으며, 종종 더 많은 데이터가 있는 것이 유리합니다.",
            "이 옵션은 잘못되었습니다. 랜덤 포레스트는 각 결정 트리를 생성할 때 무작위 특징의 하위 집합을 선택하여 트리 간의 상관관계를 줄이고 모델의 강건성을 향상시킵니다.",
            "이 옵션은 잘못되었습니다. 랜덤 포레스트는 여러 결정 트리를 생성하며, 최종 예측은 그 트리들 간의 다수결에 기반하므로 단일 결정 트리 출력을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "18",
        "Situation": "데이터 과학자는 소매 회사의 판매 예측을 위한 예측 모델을 개발하는 임무를 맡고 있습니다. 데이터셋은 계절성, 프로모션 및 경제 지표를 포함한 여러 특징으로 구성된 대규모입니다. 데이터 과학자는 사용자 정의 모델을 구현할지 아니면 Amazon SageMaker의 기존 알고리즘을 활용할지를 고려하고 있습니다.",
        "Question": "데이터 과학자가 Amazon SageMaker의 내장 알고리즘 대신 사용자 정의 모델을 구축하는 것을 고려해야 하는 시나리오는 어떤 경우인가요? (두 가지 선택)",
        "Options": {
            "1": "사용 사례는 기존 알고리즘으로 효과적으로 해결할 수 있습니다.",
            "2": "데이터 과학자는 머신러닝에 대한 경험이 제한적입니다.",
            "3": "문제가 매우 전문화된 특징과 도메인 지식을 요구합니다.",
            "4": "모델에서 고급 사용자 정의 및 유연성의 필요성이 높습니다.",
            "5": "데이터셋이 작고 특징이 적은 간단한 경우입니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "문제가 매우 전문화된 특징과 도메인 지식을 요구합니다.",
            "모델에서 고급 사용자 정의 및 유연성의 필요성이 높습니다."
        ],
        "Explanation": "문제가 내장 알고리즘이 충분히 해결하지 못할 수 있는 전문화된 특징을 포함할 때 사용자 정의 모델을 구축하는 것이 바람직합니다. 또한, 모델의 아키텍처나 기능에서 높은 수준의 사용자 정의 및 유연성이 요구되는 경우 사용자 정의 솔루션이 더 적합합니다.",
        "Other Options": [
            "이 시나리오는 복잡성이 부족하여 내장 알고리즘이 작은 데이터셋을 효율적으로 처리할 수 있는 경우에 더 적합합니다.",
            "제한된 머신러닝 경험은 일반적으로 내장 알고리즘의 사용을 선호하게 되며, 이는 최적화되어 있고 광범위한 지식 없이도 쉽게 구현할 수 있습니다.",
            "사용 사례가 기존 알고리즘으로 효과적으로 해결될 수 있다면, 사용자 정의 솔루션을 개발하기보다는 이를 활용하는 것이 더 효율적이고 비용 효과적입니다."
        ]
    },
    {
        "Question Number": "19",
        "Situation": "데이터 과학자가 제곱 피트, 침실 수, 위치와 같은 다양한 특성을 기반으로 주택 가격을 예측하기 위한 선형 회귀 모델을 개발하고 있습니다. 데이터셋에는 많은 수의 특성이 포함되어 있으며, 그 중 일부는 모델의 예측력에 크게 기여하지 않을 수 있습니다. 데이터 과학자는 과적합에 대해 우려하고 있으며 정규화 기법을 구현하고자 합니다.",
        "Question": "모델 일반화를 향상시키기 위해 데이터 과학자가 적용해야 할 정규화 기법은 무엇입니까?",
        "Options": {
            "1": "특성 집합의 희소성을 장려하기 위해 L1 정규화를 적용합니다.",
            "2": "두 방법의 장점을 활용하기 위해 L1 및 L2 정규화를 적용합니다.",
            "3": "큰 계수를 패널티를 부여하고 모델 복잡성을 줄이기 위해 L2 정규화를 적용합니다.",
            "4": "훈련 세트에서 더 나은 성능을 낼 수 있으므로 정규화를 적용하지 않습니다."
        },
        "Correct Answer": "두 방법의 장점을 활용하기 위해 L1 및 L2 정규화를 적용합니다.",
        "Explanation": "L1 및 L2 정규화(Elastic Net으로 알려짐)를 모두 적용하면 모델이 L1의 특성 선택과 L2의 계수 추정 안정성의 이점을 누릴 수 있어 보이지 않는 데이터에 대한 일반화가 향상됩니다.",
        "Other Options": [
            "L1 정규화만 적용하면 일부 특성이 완전히 제거될 수 있으며, 이는 유익할 수 있지만 남은 특성이 충분하지 않은 경우 중요한 정보를 잃을 수 있습니다.",
            "L2 정규화만 적용하면 과적합을 방지하는 데 도움이 되지만 특성 선택을 수행하지 않아 많은 관련 없는 특성을 가진 너무 복잡한 모델이 될 수 있습니다.",
            "정규화를 전혀 적용하지 않으면 많은 수의 특성이 있는 경우 심각한 과적합이 발생할 수 있습니다. 이 접근 방식은 보이지 않는 데이터에서 성능 저하의 위험이 있습니다."
        ]
    },
    {
        "Question Number": "20",
        "Situation": "머신 러닝 전문가가 테스트 데이터셋에서 생성된 혼동 행렬을 사용하여 여러 분류 모델의 성능을 평가하고 있습니다. 목표는 진짜 양성, 진짜 음성, 가짜 양성 및 가짜 음성을 기반으로 가장 효과적인 모델을 선택하는 것입니다.",
        "Question": "모델 성능을 비교할 때 전문가가 혼동 행렬에서 어떤 특성의 조합을 우선시해야 합니까? (두 가지 선택)",
        "Options": {
            "1": "모델 간 낮은 가짜 양성 비율",
            "2": "모델 간 높은 진짜 양성 비율",
            "3": "모델 간 균형 잡힌 정확도",
            "4": "모델 간 높은 진짜 음성 비율",
            "5": "모델 간 높은 가짜 음성 비율"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "모델 간 높은 진짜 양성 비율",
            "모델 간 낮은 가짜 양성 비율"
        ],
        "Explanation": "높은 진짜 양성 비율을 우선시하면 모델이 긍정적인 사례를 올바르게 식별하도록 보장하므로 성능에 매우 중요합니다. 또한 낮은 가짜 양성 비율은 모델이 잘못된 긍정 예측을 덜 하여 잠재적인 부정적인 결과를 줄인다는 것을 나타냅니다.",
        "Other Options": [
            "높은 가짜 음성 비율은 바람직하지 않으며, 이는 모델이 실제 긍정 사례를 식별하지 못해 기회를 놓치거나 중요한 오류를 초래할 수 있음을 의미합니다.",
            "균형 잡힌 정확도는 중요하지만, 모델이 긍정과 부정을 올바르게 식별하는 능력에 대한 구체적인 통찰력을 제공하지 않으므로 이 맥락에서는 덜 중요합니다.",
            "높은 진짜 음성 비율은 유익하지만, 그것만으로는 모델이 긍정 사례를 식별하는 효과성을 반영하지 않으므로 분류 작업에 필수적입니다."
        ]
    },
    {
        "Question Number": "21",
        "Situation": "데이터 과학 팀이 AWS에서 고객 이탈을 예측하기 위해 머신 러닝 모델을 배포하고 있습니다. 팀은 권한이 있는 사용자만 모델 및 관련 리소스에 접근할 수 있도록 해야 합니다. 그들은 권한을 안전하고 효율적으로 관리할 수 있는 솔루션을 구현하고자 합니다.",
        "Question": "팀이 머신 러닝 모델 및 리소스에 대한 접근을 관리하기 위해 어떤 AWS 서비스를 활용해야 합니까?",
        "Options": {
            "1": "AWS Lambda",
            "2": "Amazon Cognito",
            "3": "AWS CloudTrail",
            "4": "AWS Identity and Access Management (IAM)"
        },
        "Correct Answer": "AWS Identity and Access Management (IAM)",
        "Explanation": "AWS Identity and Access Management (IAM)는 AWS 사용자 및 그룹을 생성하고 관리하며 AWS 리소스에 대한 접근을 안전하게 허용하거나 거부하는 권한을 설정할 수 있도록 해주므로 올바른 선택입니다. 이는 머신 러닝 모델 및 리소스에 대한 접근을 제어하는 데 필수적입니다.",
        "Other Options": [
            "AWS CloudTrail은 주로 계정에서 수행된 API 호출을 기록하고 모니터링하는 데 사용됩니다. 사용자 접근이나 권한을 직접 관리하지 않습니다.",
            "Amazon Cognito는 웹 및 모바일 앱에 대한 인증, 권한 부여 및 사용자 관리를 제공하는 서비스이지만 AWS 리소스에 대한 권한 관리를 위해 특별히 설계되지 않았습니다.",
            "AWS Lambda는 이벤트에 응답하여 코드를 실행하고 필요한 컴퓨팅 리소스를 자동으로 관리하는 컴퓨팅 서비스입니다. 접근 관리 기능을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "22",
        "Situation": "한 금융 서비스 회사가 고객 이탈을 예측하는 기계 학습 모델을 AWS에 배포하고 있습니다. 그들은 모델 훈련 및 추론을 위해 Amazon SageMaker를 사용하고 있습니다. 이 회사는 추론 중 높은 대기 시간을 경험하고 있으며, 이는 고객 경험에 영향을 미치고 있습니다. 그들은 성능을 유지하면서 비용을 줄이기 위해 인프라를 최적화하고자 합니다.",
        "Question": "회사가 추론 작업에 맞게 리소스를 조정하기 위해 어떤 전략을 구현해야 합니까?",
        "Options": {
            "1": "여러 모델을 동시에 동일한 인스턴스에서 제공하기 위해 다중 변형 엔드포인트를 구현합니다.",
            "2": "비용이 낮은 인스턴스 유형으로 전환하고 동시 요청 수를 줄입니다.",
            "3": "CPU와 메모리가 더 많은 더 큰 인스턴스 유형으로 증가시킵니다.",
            "4": "Amazon SageMaker Endpoint Auto Scaling을 사용하여 트래픽에 따라 인스턴스 수를 조정합니다."
        },
        "Correct Answer": "Amazon SageMaker Endpoint Auto Scaling을 사용하여 트래픽에 따라 인스턴스 수를 조정합니다.",
        "Explanation": "Amazon SageMaker Endpoint Auto Scaling을 사용하면 회사는 실시간 트래픽에 따라 활성 인스턴스 수를 조정할 수 있어, 피크 시간 동안 충분한 리소스를 확보하고 저조한 트래픽 기간 동안 비용을 줄일 수 있습니다.",
        "Other Options": [
            "인스턴스 유형을 더 큰 크기로 증가시키면 대기 시간 문제를 반드시 해결하지 못하고 비용이 더 증가할 수 있으며, 문제는 인스턴스 성능이 아니라 동시 요청 수에서 발생할 수 있습니다.",
            "비용이 낮은 인스턴스 유형으로 전환하면 비용을 절감할 수 있지만, 작업 부하를 효과적으로 처리할 수 있는 리소스가 부족할 경우 성능이 더욱 저하될 수 있습니다.",
            "다중 변형 엔드포인트를 구현하는 것은 여러 모델을 관리하는 데 유용하지만, 트래픽 패턴에 따라 리소스를 동적으로 관리할 필요성을 직접적으로 해결하지 않으며, 이는 가변 부하 동안 성능을 유지하는 데 중요합니다."
        ]
    },
    {
        "Question Number": "23",
        "Situation": "기계 학습 전문가가 비지도 학습 접근 방식을 사용하여 대량의 텍스트 문서에서 숨겨진 주제를 발견하기 위해 주제 모델링을 수행하는 임무를 맡고 있습니다. 전문가는 이를 위해 잠재 디리클레 할당(LDA)을 사용할 것을 고려하고 있으며, 모델의 성능과 해석 가능성을 최적화하고자 합니다.",
        "Question": "전문가가 LDA 모델의 효과성을 개선하기 위해 고려해야 할 방법은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "주제의 품질을 평가하기 위해 일관된 지표를 사용합니다.",
            "2": "불용어를 제거하고 어간 추출을 통해 텍스트 데이터를 전처리합니다.",
            "3": "데이터셋의 자연 한계를 넘어 주제 수를 증가시킵니다.",
            "4": "알파 및 베타 매개변수에 대해 하이퍼파라미터 튜닝을 활용합니다.",
            "5": "전처리 없이 원시 텍스트에 LDA를 직접 적용합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "주제의 품질을 평가하기 위해 일관된 지표를 사용합니다.",
            "불용어를 제거하고 어간 추출을 통해 텍스트 데이터를 전처리합니다."
        ],
        "Explanation": "주제의 품질을 평가하기 위해 일관된 지표를 사용하는 것은 식별된 주제가 의미 있고 해석 가능하도록 보장하는 데 도움이 됩니다. 불용어를 제거하고 어간 추출과 같은 텍스트 데이터 전처리는 데이터의 노이즈를 줄여 LDA 모델의 품질을 향상시켜 모델이 가장 관련성 높은 용어에 집중할 수 있도록 합니다.",
        "Other Options": [
            "주제 수를 자연 한계를 넘어 증가시키면 과적합과 해석이 어려운 결과를 초래할 수 있어, 모델에서 의미 있는 통찰을 추출하기 어려워질 수 있습니다.",
            "전처리 없이 원시 텍스트에 LDA를 직접 적용하면 주제 발견에 기여하지 않는 무관하거나 고빈도 용어의 존재로 인해 일반적으로 성능이 저하됩니다.",
            "하이퍼파라미터 튜닝이 유익할 수 있지만, 입력 텍스트 데이터가 잘 준비되어 있고 주제 품질을 평가하기 위한 관련 지표가 마련되어 있는 것이 더 중요합니다."
        ]
    },
    {
        "Question Number": "24",
        "Situation": "데이터 과학자가 고객 정보와 구매 행동을 포함하는 데이터셋을 분석하여 판매에 영향을 미치는 요인을 이해하고 있습니다. 데이터셋에는 나이, 소득, 구매 금액 등 다양한 특성이 포함되어 있습니다. 데이터 과학자는 탐색적 데이터 분석(EDA)을 수행하고 평균, 중앙값, 상관 계수와 같은 기술 통계를 계산합니다. 또한 특성 간의 관계의 유의성을 평가하기 위해 p-값도 계산합니다.",
        "Question": "데이터 과학자가 특성 관계를 이해하기 위해 집중해야 할 통찰의 조합은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "유의성을 확립하기 위해 p-값이 0.05 이하인 특성에만 집중합니다.",
            "2": "특성 간의 관계 강도를 평가하기 위해 p-값을 검토합니다.",
            "3": "분석 전에 데이터 품질을 보장하기 위해 데이터셋에서 이상치를 찾습니다.",
            "4": "각 특성의 중심 경향을 요약하기 위해 평균과 중앙값을 사용합니다.",
            "5": "다중공선성을 확인하기 위해 상관 계수가 높은 특성을 식별합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "다중공선성을 확인하기 위해 상관 계수가 높은 특성을 식별합니다.",
            "특성 간의 관계 강도를 평가하기 위해 p-값을 검토합니다."
        ],
        "Explanation": "상관 계수가 높은 특성을 식별하는 것은 모델 성능에 영향을 미칠 수 있는 잠재적인 다중공선성 문제를 파악하는 데 도움이 됩니다. p-값을 검토하면 관계의 통계적 유의성에 대한 통찰을 제공하여 데이터 과학자가 이러한 관계의 강도에 따라 정보에 기반한 결정을 내릴 수 있도록 합니다.",
        "Other Options": [
            "평균과 중앙값만 사용하면 EDA에서 특성 간의 관계에 대한 통찰을 제공하지 않으며, 이는 매우 중요합니다.",
            "p-값이 0.05 이하인 특성에만 집중하면 이 임계값보다 약간 높은 p-값을 가진 중요한 관계를 제외할 수 있어 분석을 지나치게 단순화할 수 있습니다.",
            "이상치를 찾는 것은 데이터 품질에 중요하지만, 분석의 주요 목표인 특성 관계를 이해하는 데 직접적으로 도움이 되지 않습니다."
        ]
    },
    {
        "Question Number": "25",
        "Situation": "데이터 엔지니어링 팀은 Amazon S3에 저장된 대규모 데이터셋을 분석하는 임무를 맡고 있습니다. 그들은 서버를 프로비저닝할 필요 없이 데이터에 대해 직접 SQL 쿼리를 실행할 수 있는 솔루션이 필요합니다. 또한, 쿼리 결과를 S3에 다시 저장하여 추가 처리 및 머신 러닝 작업을 수행할 수 있는 기능을 원합니다.",
        "Question": "S3 데이터를 SQL로 쿼리하고 결과를 S3에 다시 저장하는 팀의 요구 사항을 가장 잘 충족하는 AWS 서비스는 무엇입니까?",
        "Options": {
            "1": "Amazon Redshift",
            "2": "AWS Glue",
            "3": "Amazon Athena",
            "4": "Amazon RDS"
        },
        "Correct Answer": "Amazon Athena",
        "Explanation": "Amazon Athena는 S3의 데이터를 표준 SQL을 사용하여 분석할 수 있는 서버리스 대화형 쿼리 서비스입니다. CSV, JSON 및 Parquet와 같은 다양한 형식을 쿼리할 수 있으며, 결과를 S3에 다시 저장할 수 있어 팀의 요구에 완벽하게 부합합니다.",
        "Other Options": [
            "Amazon Redshift는 서버를 프로비저닝해야 하는 데이터 웨어하우스 솔루션으로, 추가 설정 없이 S3 데이터에 대한 직접 쿼리에 적합하지 않습니다.",
            "AWS Glue는 주로 ETL(추출, 변환, 적재) 서비스이며, Athena와 같은 직접 SQL 쿼리 인터페이스를 제공하지 않아 즉석 쿼리에 덜 이상적입니다.",
            "Amazon RDS는 데이터베이스를 프로비저닝해야 하는 관리형 관계형 데이터베이스 서비스로, 추가 구성 없이 S3에 저장된 데이터를 직접 쿼리할 수 없습니다."
        ]
    },
    {
        "Question Number": "26",
        "Situation": "머신 러닝 엔지니어가 머신 러닝 모델의 훈련 데이터를 저장하기 위해 Amazon S3 버킷을 설정하고 있습니다. 엔지니어는 특정 서비스인 Amazon SageMaker가 훈련 목적으로 버킷에서 읽을 수 있도록 하면서, 권한이 있는 인원만 데이터에 접근할 수 있도록 보장하고자 합니다.",
        "Question": "이 요구 사항을 충족하기 위해 S3 버킷 정책을 구성하는 가장 효과적인 방법은 무엇입니까?",
        "Options": {
            "1": "특정 IAM 역할에 읽기 접근을 허용하는 버킷 정책을 구현하되, 객체 쓰기를 위한 공개 접근을 허용합니다.",
            "2": "모든 AWS 계정에 접근을 허용하되, 쓰기 작업에 MFA를 요구하는 S3 버킷 정책을 사용합니다.",
            "3": "기본적으로 모든 접근을 거부하고 특정 IAM 역할 및 SageMaker와 같은 서비스만 객체를 읽을 수 있도록 허용하는 버킷 정책을 설정합니다.",
            "4": "모든 객체에 대한 공개 읽기 접근을 허용하고 특정 IAM 역할에 쓰기 접근을 제한하는 버킷 정책을 생성합니다."
        },
        "Correct Answer": "기본적으로 모든 접근을 거부하고 특정 IAM 역할 및 SageMaker와 같은 서비스만 객체를 읽을 수 있도록 허용하는 버킷 정책을 설정합니다.",
        "Explanation": "기본적으로 모든 접근을 거부하고 특정 IAM 역할 및 SageMaker와 같은 서비스만 읽을 수 있도록 하는 버킷 정책을 설정하면, 권한이 있는 사용자와 서비스만 데이터에 접근할 수 있어 훈련 데이터에 대한 보안과 통제를 유지할 수 있습니다.",
        "Other Options": [
            "공개 읽기 접근을 허용하는 버킷 정책을 생성하는 것은 데이터를 인터넷의 누구에게나 노출시켜 민감한 훈련 데이터에는 적합하지 않습니다.",
            "모든 AWS 계정에 접근을 허용하는 것은 MFA가 있더라도 지나치게 관대하여 민감한 데이터에 대한 무단 접근을 초래할 수 있습니다.",
            "쓰기 작업에 대한 공개 접근을 구현하는 것은 보안을 저해하며, 누구나 버킷에 객체를 업로드할 수 있게 되어 데이터 손상이나 노출로 이어질 수 있습니다."
        ]
    },
    {
        "Question Number": "27",
        "Situation": "데이터 과학자가 최적화를 위해 경량 하강법을 사용하는 머신 러닝 모델을 훈련시키고 있습니다. 모델의 훈련 데이터에 대한 성능은 향상되고 있지만, 과학자는 지역 최소값에 갇힐 위험에 대해 우려하고 있습니다. 또한, 과학자는 수렴 속도와 안정성 간의 최적의 균형을 찾기 위해 다양한 학습률을 실험하고 있습니다.",
        "Question": "이 시나리오에서 최적화 알고리즘으로 경량 하강법을 사용할 때의 주요 우려 사항은 무엇입니까?",
        "Options": {
            "1": "모델이 더 나은 성능을 달성하기 위해 더 많은 특성이 필요할 수 있습니다.",
            "2": "모델이 전역 최소값 대신 지역 최소값에 수렴할 수 있습니다.",
            "3": "모델이 학습률이 너무 높게 설정되면 훈련 데이터에 과적합할 수 있습니다.",
            "4": "모델이 학습률이 너무 낮게 설정되면 수렴하는 데 너무 오랜 시간이 걸릴 수 있습니다."
        },
        "Correct Answer": "모델이 전역 최소값 대신 지역 최소값에 수렴할 수 있습니다.",
        "Explanation": "경량 하강법을 사용할 때의 주요 위험은 전역 최소값 대신 지역 최소값에 수렴하는 것입니다. 이는 최적화 과정이 최상의 가능한 솔루션이 아닌 낮은 오류 지점에 갇힐 수 있기 때문입니다.",
        "Other Options": [
            "낮은 학습률이 실제로 수렴 속도를 늦출 수 있지만, 이는 지역 최소값이 특정 문제로 다루어지고 있는 이 맥락에서 주요 우려 사항이 아닙니다.",
            "과적합은 일반적으로 모델 복잡성과 훈련 기간과 관련이 있으며, 경량 하강법 최적화의 맥락에서 학습률에 의해 직접적으로 발생하지 않습니다.",
            "더 많은 특성이 모델 성능을 향상시킬 수 있지만, 이는 지역 최소값이나 경량 하강법 최적화의 구체적인 우려 사항과 직접적으로 관련이 없습니다."
        ]
    },
    {
        "Question Number": "28",
        "Situation": "데이터 과학자가 고객의 사용 패턴을 기반으로 고객 이탈 여부를 예측하는 분류 모델을 작업하고 있습니다. 모델이 보지 못한 데이터에 잘 일반화되도록 하기 위해 데이터 과학자는 훈련 과정에서 교차 검증을 구현하기로 결정했습니다. 그들은 교차 검증을 효과적으로 수행하기 위한 다양한 전략을 고려하고 있습니다.",
        "Question": "이 불균형 데이터셋을 가진 분류 문제에 가장 적합한 교차 검증 전략은 무엇인가요?",
        "Options": {
            "1": "빠른 결과를 위한 간단한 홀드아웃 검증.",
            "2": "최대 데이터 사용을 위한 Leave-One-Out 교차 검증.",
            "3": "클래스 비율을 유지하기 위한 계층화 K-겹 교차 검증.",
            "4": "데이터의 무작위 셔플을 포함한 K-겹 교차 검증."
        },
        "Correct Answer": "클래스 비율을 유지하기 위한 계층화 K-겹 교차 검증.",
        "Explanation": "계층화 K-겹 교차 검증은 불균형 데이터셋에 이상적입니다. 각 겹이 전체 데이터셋과 동일한 클래스 비율을 유지하도록 보장하여, 모델이 다수 클래스에 편향되지 않고 두 클래스 모두에서 효과적으로 학습할 수 있게 합니다.",
        "Other Options": [
            "데이터의 무작위 셔플을 포함한 K-겹 교차 검증은 소수 클래스를 적절히 대표하지 않는 겹을 초래할 수 있어, 해당 클래스에서 성능이 저조한 편향된 모델이 될 수 있습니다.",
            "Leave-One-Out 교차 검증은 최대한 많은 데이터를 훈련에 사용하지만, 높은 분산을 초래할 수 있으며 계산 비용이 많이 들어 대규모 데이터셋, 특히 클래스 불균형이 있는 경우에는 실용적이지 않습니다.",
            "간단한 홀드아웃 검증은 불균형 시나리오에서 모델의 성능에 대한 충분한 통찰력을 제공하지 않으며, 단일 분할이 모델의 일반화 능력을 정확하게 반영하지 않을 수 있습니다."
        ]
    },
    {
        "Question Number": "29",
        "Situation": "연구팀이 새로운 문헌 리뷰를 위한 기본 주제를 식별하기 위해 대규모 학술 논문 코퍼스를 분석하고 있습니다. 그들은 사전 레이블이 없는 데이터로 문서를 효과적으로 분류하고자 합니다. 팀은 이를 위해 Latent Dirichlet Allocation (LDA)를 사용하는 것을 고려하고 있습니다.",
        "Question": "LDA를 주제 모델링에 적용하기 전에 텍스트 데이터를 준비하는 데 필수적인 단계는 무엇인가요?",
        "Options": {
            "1": "주제 추출 과정을 단순화하기 위해 전체 코퍼스를 단일 문서로 변환합니다.",
            "2": "토큰화 전에 불용어를 제거하고 어간 추출을 적용하여 단어를 기본 형태로 줄입니다.",
            "3": "모든 단어를 포착하기 위해 전처리 없이 원시 텍스트 데이터에 LDA를 직접 사용합니다.",
            "4": "텍스트를 문장으로 토큰화하고 각 문장의 구조를 분석하기 위해 LDA를 적용합니다."
        },
        "Correct Answer": "토큰화 전에 불용어를 제거하고 어간 추출을 적용하여 단어를 기본 형태로 줄입니다.",
        "Explanation": "LDA를 적용하기 전에 텍스트 데이터를 전처리하는 것은 주제 모델링의 품질을 향상시키기 위해 매우 중요합니다. 불용어를 제거하고 어간 추출을 통해 주제 발견에 기여하는 가장 관련성 높은 단어에 집중할 수 있어 모델의 성능이 향상됩니다.",
        "Other Options": [
            "전처리 없이 원시 텍스트 데이터에 LDA를 직접 사용하는 것은 관련 없는 단어가 특징 공간을 지배하게 되어 의미 있는 주제를 식별하기 어렵게 만들기 때문에 좋지 않은 결과를 초래할 수 있습니다.",
            "텍스트를 문장으로 토큰화하는 것은 LDA에 적합하지 않습니다. 모델은 각 문서를 단어의 집합으로 처리하는 문서-단어 행렬을 기대합니다.",
            "전체 코퍼스를 단일 문서로 변환하는 것은 LDA의 목적을 무색하게 하며, LDA는 여러 문서에 걸쳐 단어의 분포를 기반으로 독특한 주제를 식별합니다."
        ]
    },
    {
        "Question Number": "30",
        "Situation": "데이터 엔지니어가 소셜 미디어 피드와 IoT 센서를 포함한 여러 출처에서 실시간 스트리밍 데이터를 처리하기 위한 솔루션을 설계하고 있습니다. 목표는 이 데이터를 효율적으로 저장하여 추가 분석 및 보고를 위한 것입니다.",
        "Question": "이 요구 사항에 가장 적합한 AWS 서비스 조합은 무엇인가요?",
        "Options": {
            "1": "변환을 위한 Glue ETL과 저장을 위한 RDS",
            "2": "수집을 위한 Kinesis Data Streams와 저장을 위한 S3",
            "3": "저장을 위한 DynamoDB와 처리를 위한 Batch",
            "4": "저장을 위한 Redshift와 캐싱을 위한 ElastiCache"
        },
        "Correct Answer": "수집을 위한 Kinesis Data Streams와 저장을 위한 S3",
        "Explanation": "Kinesis Data Streams는 실시간 스트리밍 데이터의 수집을 가능하게 하며, 이는 설명된 시나리오에 매우 중요합니다. Amazon S3에 데이터를 저장하는 것은 장기 데이터 저장을 위한 비용 효율적이고 확장 가능한 솔루션을 제공하여 추가 분석 및 보고에 적합합니다.",
        "Other Options": [
            "DynamoDB는 고속 데이터에 적합한 NoSQL 데이터베이스이지만 Kinesis와 같은 실시간 스트리밍 수집에 최적화되어 있지 않습니다. 배치 처리는 실시간 데이터 처리를 위해 설계되지 않았습니다.",
            "Redshift는 주로 데이터 웨어하우징 솔루션이며 실시간 수집에 최적화되어 있지 않습니다. ElastiCache는 캐싱 솔루션으로 스트리밍 데이터의 기본 저장 계층으로 사용되지 않습니다.",
            "Glue ETL은 데이터 변환에 사용되며 실시간 데이터 수집을 위한 것이 아닙니다. RDS는 OLTP에 적합한 관계형 데이터베이스이지만 실시간 스트리밍 데이터를 효율적으로 처리하지 않습니다."
        ]
    },
    {
        "Question Number": "31",
        "Situation": "머신 러닝 엔지니어가 대규모 이미지 데이터셋을 처리하는 딥 러닝 모델을 훈련하는 임무를 맡았습니다. 엔지니어는 훈련 시간과 비용을 최적화하기 위해 적절한 컴퓨팅 자원을 선택해야 합니다.",
        "Question": "이 딥 러닝 모델 훈련을 위해 엔지니어가 선택해야 할 컴퓨팅 자원의 유형은 무엇입니까?",
        "Options": {
            "1": "효율적인 데이터 처리를 위한 CPU 인스턴스.",
            "2": "균형 잡힌 성능을 위한 CPU와 GPU 인스턴스의 조합.",
            "3": "고용량 메모리를 갖춘 로컬 머신.",
            "4": "모델 훈련을 가속화하기 위한 GPU 인스턴스."
        },
        "Correct Answer": "모델 훈련을 가속화하기 위한 GPU 인스턴스.",
        "Explanation": "GPU 인스턴스는 병렬 처리 작업을 처리하도록 특별히 설계되어 있어, 상당한 계산 능력이 필요한 딥 러닝 모델 훈련에 이상적입니다. CPU 인스턴스에 비해 훈련 시간을 크게 단축시킵니다.",
        "Other Options": [
            "CPU 인스턴스는 딥 러닝 작업에 비효율적이며, GPU만큼 효과적으로 병렬 계산을 수행할 수 없어 훈련 시간이 길어집니다.",
            "CPU와 GPU 인스턴스의 조합이 유용할 수 있지만, 딥 러닝 모델을 효율적으로 훈련하는 특정 작업에는 GPU 인스턴스만으로도 더 효과적입니다.",
            "고용량 메모리를 갖춘 로컬 머신은 딥 러닝 작업에 필요한 계산 능력을 제공하지 못할 수 있으며, 특히 GPU의 병렬 처리 능력이 부족할 경우 더욱 그렇습니다."
        ]
    },
    {
        "Question Number": "32",
        "Situation": "데이터 과학자가 머신 러닝 모델의 하이퍼파라미터를 조정하여 최적의 성능을 달성하고 있습니다. 고려 중인 중요한 하이퍼파라미터 중 하나는 학습률로, 이는 모델이 훈련 중 수렴하는 속도에 영향을 미칩니다.",
        "Question": "모델 훈련 중 학습률을 너무 높게 설정할 경우의 잠재적 결과는 무엇입니까?",
        "Options": {
            "1": "모델이 너무 빨리 수렴하여 과소적합이 발생합니다.",
            "2": "모델이 훈련 데이터에 무감각해집니다.",
            "3": "모델이 수렴하는 데 너무 오랜 시간이 걸려 훈련 시간이 증가합니다.",
            "4": "모델이 최적의 솔루션을 초과하여 효과적으로 수렴하지 못할 수 있습니다."
        },
        "Correct Answer": "모델이 최적의 솔루션을 초과하여 효과적으로 수렴하지 못할 수 있습니다.",
        "Explanation": "높은 학습률은 모델이 손실 함수의 최소값을 넘어서게 하여 최적의 지점에 정착하지 못하게 할 수 있습니다. 이로 인해 훈련 행동이 불규칙해지고 수렴하지 못할 수 있습니다.",
        "Other Options": [
            "너무 높은 학습률은 모델이 수렴하는 데 오랜 시간이 걸리게 하지 않으며, 오히려 수렴을 방해할 수 있습니다.",
            "매우 높은 학습률은 초과 수렴을 초래할 수 있지만, 모델이 너무 빨리 수렴한다는 것을 의미하지는 않으며, 오히려 아예 수렴하지 않을 수도 있습니다.",
            "높은 학습률은 훈련 데이터에 대한 무감각을 초래하지 않으며, 대신 학습의 불안정을 초래할 수 있습니다."
        ]
    },
    {
        "Question Number": "33",
        "Situation": "데이터 과학자가 Amazon S3에 저장된 민감한 데이터를 사용하여 Amazon SageMaker로 머신 러닝 모델을 훈련하고 있습니다. 그들은 SageMaker 노트북 인스턴스가 과도한 권한을 부여하지 않으면서 올바른 IAM 정책을 갖추도록 해야 합니다. 데이터 과학자는 또한 SageMaker 노트북 인스턴스를 생성할 때 라이프사이클 구성 및 기본 설정의 의미를 이해하고 싶어합니다.",
        "Question": "SageMaker 노트북 인스턴스를 생성할 때 IAM 정책 및 라이프사이클 구성에 대한 다음 설명 중 어떤 것이 TRUE입니까?",
        "Options": {
            "1": "SageMaker는 노트북 인스턴스에 연결된 S3 버킷에 대한 리소스 기반 정책을 지원합니다.",
            "2": "라이프사이클 스크립트는 루트 대신 특정 IAM 역할로 실행되도록 구성할 수 있습니다.",
            "3": "기본 설정은 라이프사이클 스크립트가 루트 권한으로 실행되도록 허용합니다.",
            "4": "SageMaker 노트북 인스턴스는 기본적으로 제한된 권한으로 라이프사이클 스크립트를 실행합니다."
        },
        "Correct Answer": "기본 설정은 라이프사이클 스크립트가 루트 권한으로 실행되도록 허용합니다.",
        "Explanation": "기본적으로 Amazon SageMaker 노트북 인스턴스의 라이프사이클 구성은 루트 사용자로 실행되며, 이는 기본 리소스에 대한 전체 액세스 권한을 갖는 것을 의미합니다. 이는 특정 작업에 중요하지만, 적절히 관리되지 않으면 보안 문제를 일으킬 수 있습니다.",
        "Other Options": [
            "SageMaker 노트북 인스턴스는 제한된 권한으로 라이프사이클 스크립트를 실행하지 않으며, 명시적으로 구성하지 않는 한 루트로 실행됩니다.",
            "노트북 인스턴스에 대해 IAM 역할을 지정하는 것은 가능하지만, 라이프사이클 스크립트 자체는 루트로 실행되며 다른 IAM 역할로 실행되도록 구성할 수 없습니다.",
            "SageMaker는 노트북 인스턴스에 대한 S3 버킷 정책과 같은 리소스 기반 정책을 지원하지 않으므로, 권한은 오직 IAM 역할을 통해 관리해야 합니다."
        ]
    },
    {
        "Question Number": "34",
        "Situation": "데이터 과학 팀이 Amazon SageMaker를 사용하여 머신 러닝 모델을 개발하고 있습니다. 그들은 훈련을 위해 사용자 정의 Docker 이미지를 활용해야 하며, 효율적인 데이터 관리와 자원 할당을 보장하고자 합니다. 팀은 훈련 및 검증을 위한 다양한 데이터 채널을 지정할 수 있는 능력이 필요하며, 훈련 중 발생할 수 있는 중단을 처리하기 위해 체크포인팅을 구현하고자 합니다. 그들은 훈련 아키텍처에 대한 다양한 옵션을 고려하고 있습니다.",
        "Question": "사용자 정의 Docker 이미지를 사용하고, 데이터 채널을 정의하며, Amazon SageMaker에서 체크포인팅을 구현하기 위한 팀의 요구 사항을 가장 잘 충족하는 아키텍처 설정은 무엇입니까?",
        "Options": {
            "1": "훈련을 위해 미리 구축된 SageMaker 컨테이너를 활용하고, 채널을 정의하지 않고 EFS를 데이터 소스로 지정하며, 체크포인팅은 필요하지 않으므로 무시합니다.",
            "2": "Docker를 사용하여 로컬 환경에서 훈련 스크립트를 배포하고, 훈련이 완료된 후 모델 아티팩트를 S3에 수동으로 업로드합니다.",
            "3": "/opt/ml/code에 훈련 스크립트를 포함하는 사용자 정의 Docker 이미지를 생성하고, 훈련 및 검증을 위한 정의된 채널로 S3를 훈련 데이터 소스로 구성합니다.",
            "4": "사용자 정의 Docker 이미지 없이 SageMaker 내장 알고리즘을 사용하여 훈련하고, FSx for Lustre에 데이터를 저장하며 기본 채널 구성에 의존합니다."
        },
        "Correct Answer": "사용자 정의 Docker 이미지를 생성하고 /opt/ml/code에 훈련 스크립트를 포함하며, 훈련 및 검증을 위한 정의된 채널로 S3를 훈련 데이터 소스로 구성합니다.",
        "Explanation": "이 옵션은 SageMaker에서 사용자 정의 Docker 이미지를 올바르게 활용하며, 필요한 디렉토리 구조를 준수하고, 다양한 유형의 데이터에 대한 채널을 지정하며, 데이터 저장을 위해 S3를 활용하여 훈련 프로세스에 최적화되어 있습니다.",
        "Other Options": [
            "이 옵션은 미리 구축된 컨테이너를 잘못 사용하고 채널을 정의하거나 체크포인팅을 구현하지 않아 효율적인 훈련과 데이터 관리에 필수적인 요소를 놓치고 있습니다.",
            "이 옵션은 로컬 Docker 환경에 의존하며, SageMaker의 기능과 통합되지 않고 자동 체크포인팅과 같은 관리 인프라의 이점을 누리지 못합니다.",
            "이 옵션은 팀이 요구하는 사용자 정의 Docker 이미지를 사용하지 않으며, 훈련 및 검증 데이터에 대한 특정 요구 사항과 일치하지 않을 수 있는 기본 구성을 가정합니다."
        ]
    },
    {
        "Question Number": "35",
        "Situation": "데이터 과학자가 소매점의 월별 판매를 예측하기 위한 시계열 예측 모델을 개발하는 임무를 맡았습니다. 이 모델은 역사적 판매 데이터와 함께 휴일 시즌 및 프로모션과 같은 외부 요인을 활용할 것입니다. 데이터 과학자는 예측을 용이하게 하기 위해 다양한 Amazon Web Services (AWS) 도구를 고려하고 있습니다.",
        "Question": "데이터 과학자가 예측 요구 사항을 충족하기 위해 사용해야 할 AWS 서비스 조합은 무엇입니까? (두 개 선택)",
        "Options": {
            "1": "Amazon Redshift를 데이터 웨어하우징에 사용",
            "2": "AWS Glue를 ETL 프로세스에 사용",
            "3": "Amazon Forecast를 시계열 예측에 사용",
            "4": "Amazon SageMaker를 사용하여 사용자 정의 모델 구축",
            "5": "Amazon S3를 데이터 저장소로 사용"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon Forecast를 시계열 예측에 사용",
            "Amazon SageMaker를 사용하여 사용자 정의 모델 구축"
        ],
        "Explanation": "Amazon Forecast는 시계열 예측을 위해 특별히 설계되었으며, 역사적 데이터를 기반으로 정확한 예측을 제공하기 위해 머신 러닝을 활용합니다. Amazon SageMaker는 머신 러닝 모델을 구축, 훈련 및 배포할 수 있는 기능을 제공하여 필요에 따라 예측 접근 방식을 사용자 정의하는 데 적합합니다.",
        "Other Options": [
            "Amazon S3는 주로 저장 솔루션이며 예측을 위한 특정 기능을 제공하지 않으므로 예측 작업의 주요 도구로 선택할 수 없습니다.",
            "Amazon Redshift는 데이터 웨어하우징 솔루션으로 시계열 예측과 직접적인 관련이 없으며, 예측보다는 대규모 데이터 세트에 대한 분석 및 쿼리에 더 중점을 둡니다.",
            "AWS Glue는 데이터를 분석을 위해 준비하는 ETL(추출, 변환, 로드) 서비스입니다. 데이터 준비에는 유용하지만 특정 예측 기능을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "36",
        "Situation": "데이터 과학 팀이 Amazon SageMaker에서 문서 이미지를 분석하기 위한 다단계 추론 파이프라인을 개발하고 있습니다. 첫 번째 모델은 광학 문자 인식(OCR)을 수행하여 텍스트를 추출하고, 두 번째 모델은 추출된 텍스트를 분석하여 감정 분석을 수행합니다. 팀은 OCR 모델의 출력이 감정 분석 모델의 입력으로 원활하게 전달될 수 있도록 해야 합니다.",
        "Question": "Amazon SageMaker에서 이 추론 파이프라인을 구현하는 가장 효과적인 방법은 무엇입니까?",
        "Options": {
            "1": "첫 번째 모델을 실행하도록 지정하고, 그 다음 두 번째 모델을 실행하도록 하는 SageMaker 파이프라인을 정의하여 출력을 자동으로 입력으로 전달합니다.",
            "2": "각 개별 단계에 대해 SageMaker 모델을 생성하고 Lambda 함수를 사용하여 데이터 흐름을 조정합니다.",
            "3": "SageMaker의 내장 다중 모델 엔드포인트를 사용하여 두 모델을 함께 호스팅하고 데이터를 직접 공유할 수 있도록 합니다.",
            "4": "모델을 별도로 배포하고 S3 버킷을 사용하여 중간 결과를 저장하여 데이터 전송을 수동으로 처리합니다."
        },
        "Correct Answer": "첫 번째 모델을 실행하도록 지정하고, 그 다음 두 번째 모델을 실행하도록 하는 SageMaker 파이프라인을 정의하여 출력을 자동으로 입력으로 전달합니다.",
        "Explanation": "SageMaker 파이프라인을 사용하는 것은 한 모델의 출력이 추가적인 수동 개입 없이 자동으로 다음 모델에 공급될 수 있는 단계의 순서를 정의하는 가장 효율적인 방법으로, 워크플로우를 단순화하고 잠재적인 오류를 줄입니다.",
        "Other Options": [
            "Lambda 함수를 사용하여 조정하는 것은 불필요한 복잡성과 지연을 추가하며, 모델 간 데이터 전송 및 오류 처리를 위한 추가 코드를 요구합니다.",
            "다중 모델 엔드포인트는 여러 모델을 호스팅할 수 있지만, 한 모델의 출력이 다른 모델의 입력으로 필요할 때의 순차 실행을 위해 설계되지 않았으며, 개별적으로 모델을 제공하는 데 더 적합합니다.",
            "모델을 별도로 배포하고 S3를 사용하여 데이터 전송을 처리하는 것은 더 많은 단계와 잠재적인 실패 지점을 도입하여 정의된 파이프라인을 사용하는 것보다 효율성이 떨어집니다."
        ]
    },
    {
        "Question Number": "37",
        "Situation": "머신 러닝 엔지니어가 순환 신경망(RNN)을 사용하여 시계열 예측 모델을 개발하고 있습니다. 엔지니어는 이 작업을 위해 장기 단기 메모리(LSTM) 네트워크와 게이티드 순환 유닛(GRU)의 성능과 계산 효율성을 평가하고 있습니다.",
        "Question": "LSTM 및 GRU 아키텍처에 대해 어떤 특성이 사실인가요? (두 가지 선택)",
        "Options": {
            "1": "LSTM은 GRU보다 계산 집약도가 낮습니다.",
            "2": "LSTM과 GRU 네트워크 모두 과거 입력을 시간에 따라 기억할 수 있습니다.",
            "3": "GRU는 훈련 중 LSTM보다 더 많은 메모리를 요구합니다.",
            "4": "GRU는 일반적으로 더 간단한 아키텍처 덕분에 더 빠르게 훈련됩니다.",
            "5": "LSTM 네트워크는 장기 의존성을 효과적으로 관리합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "LSTM 네트워크는 장기 의존성을 효과적으로 관리합니다.",
            "GRU는 일반적으로 더 간단한 아키텍처 덕분에 더 빠르게 훈련됩니다."
        ],
        "Explanation": "LSTM 네트워크는 소실 기울기 문제를 해결하기 위해 특별히 설계되어, 시퀀스에서 장기 의존성을 효과적으로 포착할 수 있습니다. GRU는 구조가 더 간단하여 일반적으로 LSTM보다 더 빠르게 훈련되지만 경쟁력 있는 성능을 유지합니다.",
        "Other Options": [
            "이 옵션은 GRU가 구조가 더 간단하기 때문에 일반적으로 LSTM보다 메모리 집약도가 낮기 때문에 잘못된 것입니다.",
            "이 옵션은 LSTM이 복잡성 때문에 GRU보다 더 계산 집약적이기 때문에 잘못된 것입니다.",
            "이 옵션은 두 아키텍처 모두 과거 입력을 기억하는 메커니즘을 가지고 있지만, 이 진술은 그들을 구별하는 특성으로 간주하기에는 너무 모호합니다."
        ]
    },
    {
        "Question Number": "38",
        "Situation": "데이터 분석가는 조직 내 여러 부서가 특정 요구에 맞는 데이터를 접근하고 해석할 수 있도록 시각화 및 대시보드 시리즈를 만드는 임무를 맡고 있습니다. 분석가는 최종 사용자가 대시보드에 접근할 때 원활한 경험을 보장하면서 다양한 AWS 데이터 소스에 안전하게 연결할 수 있는 서비스를 활용하고자 합니다.",
        "Question": "분석가는 최종 사용자에게 연합 인증을 제공하고 여러 AWS 데이터 소스에 연결할 수 있는 대화형 대시보드를 만들기 위해 어떤 AWS 서비스를 사용해야 하나요?",
        "Options": {
            "1": "Amazon Redshift",
            "2": "AWS Glue",
            "3": "Amazon QuickSight",
            "4": "Amazon Athena"
        },
        "Correct Answer": "Amazon QuickSight",
        "Explanation": "Amazon QuickSight는 대화형 대시보드 및 시각화를 생성하기 위해 특별히 설계되었습니다. 연합 인증을 지원하여 최종 사용자가 안전하게 접근할 수 있도록 하며, 다양한 AWS 데이터 소스에 네이티브로 연결할 수 있어 분석가의 요구에 이상적인 선택입니다.",
        "Other Options": [
            "Amazon Athena는 주로 SQL을 사용하여 Amazon S3의 데이터를 분석하는 쿼리 서비스입니다. 데이터 분석에 사용할 수 있지만, 대시보드 기능이나 최종 사용자를 위한 연합 인증을 제공하지 않습니다.",
            "AWS Glue는 분석을 위해 데이터를 준비하는 완전 관리형 ETL 서비스입니다. 시각화 기능이나 대시보드를 제공하지 않기 때문에 이 작업에 적합하지 않습니다.",
            "Amazon Redshift는 복잡한 쿼리 및 분석을 허용하는 데이터 웨어하우징 서비스입니다. 보고를 위한 데이터를 저장할 수 있지만, 시각화 도구나 대시보드 생성 기능을 직접 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "39",
        "Situation": "머신 러닝 엔지니어가 제조 시설을 위한 예측 유지보수 솔루션을 배포하는 임무를 맡고 있습니다. 이 솔루션은 견고하고 확장 가능하며, 다양한 기계에 설치된 IoT 센서로부터 실시간 데이터를 처리할 수 있어야 합니다. 엔지니어는 클라우드 환경에서 머신 러닝 모델을 운영화할 수 있는 옵션을 탐색하고 있습니다.",
        "Question": "엔지니어는 높은 가용성과 자동 확장을 보장하면서 실시간 추론을 위해 머신 러닝 모델을 배포하기 위해 어떤 AWS 서비스를 사용해야 하나요?",
        "Options": {
            "1": "AWS Lambda와 API Gateway",
            "2": "자동 확장 그룹이 있는 Amazon EC2",
            "3": "Fargate가 있는 Amazon ECS",
            "4": "Amazon SageMaker Endpoints"
        },
        "Correct Answer": "Amazon SageMaker Endpoints",
        "Explanation": "Amazon SageMaker Endpoints는 실시간 추론을 위해 머신 러닝 모델을 배포하기 위해 특별히 설계되었습니다. 자동 확장 및 높은 가용성을 위한 내장 기능을 제공하여 이 시나리오에 가장 적합한 선택입니다.",
        "Other Options": [
            "자동 확장 그룹이 있는 Amazon EC2는 인프라 관리가 더 많이 필요하며, SageMaker Endpoints에 비해 머신 러닝 모델 배포에 최적화되어 있지 않습니다.",
            "AWS Lambda와 API Gateway는 실행 시간에 제한이 있으며, 더 긴 처리 기간이나 더 큰 메모리를 요구하는 복잡한 머신 러닝 모델을 지원하지 않을 수 있어, 무거운 모델의 실시간 추론에 덜 적합합니다.",
            "Fargate가 있는 Amazon ECS는 머신 러닝 모델을 실행할 수 있는 컨테이너 오케스트레이션 서비스이지만, SageMaker Endpoints의 간소화된 배포 기능에 비해 추가 구성 및 관리가 필요합니다."
        ]
    },
    {
        "Question Number": "40",
        "Situation": "금융 기관이 대출 채무 불이행을 예측하기 위한 머신 러닝 모델을 개발하고 있습니다. 데이터 과학자는 과적합과 과소적합의 위험을 인식하고 있으며, 모델이 보지 못한 데이터에 잘 일반화되도록 보장하고자 합니다. 이 균형을 달성하기 위한 다양한 전략을 고려하고 있습니다.",
        "Question": "다음 접근 방식 중 데이터 과학자가 과적합을 피하고 모델의 성능을 보지 못한 데이터에서 보장하는 데 가장 도움이 될 방법은 무엇입니까?",
        "Options": {
            "1": "모델의 성능을 데이터의 다양한 하위 집합에서 평가하기 위해 교차 검증 기법을 구현합니다.",
            "2": "별도의 데이터셋에서 검증하지 않고 훈련 데이터만 사용하여 모델을 훈련합니다.",
            "3": "데이터의 복잡한 패턴을 포착하기 위해 더 많은 수의 특성을 가진 복잡한 모델을 사용합니다.",
            "4": "모델이 너무 많은 세부 사항을 학습하지 않도록 훈련 데이터셋의 크기를 줄입니다."
        },
        "Correct Answer": "모델의 성능을 데이터의 다양한 하위 집합에서 평가하기 위해 교차 검증 기법을 구현합니다.",
        "Explanation": "교차 검증 기법을 구현하면 데이터 과학자는 모델이 데이터의 다양한 하위 집합에서 어떻게 수행되는지를 평가할 수 있으며, 이는 과적합을 식별하는 데 도움이 됩니다. 모델이 다양한 데이터 분할에서 잘 일반화되도록 보장함으로써 과적합의 위험이 크게 줄어듭니다.",
        "Other Options": [
            "더 많은 수의 특성을 가진 복잡한 모델을 사용하는 것은 모델이 기본 패턴 대신 훈련 데이터의 노이즈를 학습할 수 있어 과적합을 초래할 수 있습니다.",
            "훈련 데이터셋의 크기를 줄이면 모델이 효과적으로 학습할 수 있는 충분한 데이터가 부족해져 과소적합의 위험이 증가할 수 있습니다.",
            "별도의 검증 없이 훈련 데이터만 사용하여 모델을 훈련하는 것은 모델 성능 평가의 목적을 무색하게 하며, 보지 못한 데이터에 대한 평가가 없기 때문에 과적합의 위험을 증가시킵니다."
        ]
    },
    {
        "Question Number": "41",
        "Situation": "소매 회사가 고객 상호작용, 구매 이력 및 제품 메타데이터를 포함한 다양한 데이터 소스를 통합하여 추천 엔진을 향상시키고자 합니다. 데이터는 웹사이트에서 사용자에게 실시간 추천을 제공하기 위해 효율적으로 수집되고 처리되어야 합니다. 회사는 머신 러닝 모델의 최적 성능을 위해 데이터 소스가 잘 정의되고 구조화되도록 하고자 합니다.",
        "Question": "추천 엔진 구축을 위해 머신 러닝 전문가가 어떤 데이터 소스를 식별해야 합니까?",
        "Options": {
            "1": "웹사이트 트래픽 로그 및 설문조사에서 수집한 고객 인구 통계 데이터.",
            "2": "소셜 미디어의 사용자 생성 콘텐츠 및 외부 웹사이트의 제품 리뷰.",
            "3": "매장 내 장치의 센서 데이터 및 제3자 결제 처리업체의 거래 데이터.",
            "4": "전자상거래 플랫폼의 고객 구매 이력 및 재고 데이터베이스의 제품 세부정보."
        },
        "Correct Answer": "전자상거래 플랫폼의 고객 구매 이력 및 재고 데이터베이스의 제품 세부정보.",
        "Explanation": "이 옵션은 추천 엔진과 직접적으로 관련된 주요 데이터 소스를 식별합니다. 고객 구매 이력은 구매 패턴에 대한 통찰력을 제공하고, 제품 세부정보는 추천되는 항목에 대한 맥락을 제공합니다. 두 소스 모두 과거 행동 및 제품 특성에 기반한 개인화된 추천을 생성하는 데 필수적입니다.",
        "Other Options": [
            "소셜 미디어의 사용자 생성 콘텐츠 및 외부 웹사이트의 제품 리뷰는 일부 통찰력을 제공할 수 있지만, 소매업체의 자체 거래와 직접적으로 연결된 주요 데이터 소스가 아니므로 추천 시스템에 중요합니다.",
            "매장 내 장치의 센서 데이터 및 제3자 결제 처리업체의 거래 데이터는 전자상거래 플랫폼에서 사용자 상호작용 및 선호도에 중점을 둔 온라인 추천 엔진에 직접 적용되지 않습니다.",
            "웹사이트 트래픽 로그 및 설문조사에서 수집한 고객 인구 통계 데이터는 사용자에 대한 일부 맥락을 제공할 수 있지만, 효과적인 추천 생성을 위해 필수적인 고객 구매 행동이나 제품 세부정보에 대한 직접적인 통찰력을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "42",
        "Situation": "회사가 실시간 IoT 센서 데이터를 수집하고 있으며, 이 데이터를 효율적으로 처리하고 저장해야 합니다. 그들은 데이터를 변환, 압축 및 Amazon S3에 저장하여 향후 분석에 사용할 수 있도록 보장하고자 합니다. 솔루션은 최소한의 운영 오버헤드로 지속적인 데이터 스트림을 처리해야 합니다.",
        "Question": "IoT 센서 데이터를 실시간으로 수집, 변환 및 저장하기 위한 최상의 AWS 서비스 조합은 무엇입니까?",
        "Options": {
            "1": "Amazon S3를 사용하여 IoT 센서에서 데이터를 직접 수집한 다음 AWS Glue 작업을 실행하여 데이터를 변환하고 저장합니다.",
            "2": "Kinesis Data Streams를 사용하여 데이터를 수집하고 AWS Lambda 함수를 사용하여 변환한 후 결과를 Amazon S3에 저장합니다.",
            "3": "Kinesis Data Firehose를 사용하여 IoT 센서에서 데이터를 직접 Amazon S3로 수집하여 Parquet 형식으로 자동 변환합니다.",
            "4": "Kinesis Data Analytics를 사용하여 데이터를 실시간으로 처리한 다음 출력을 Amazon Redshift에 직접 저장합니다."
        },
        "Correct Answer": "Kinesis Data Firehose를 사용하여 IoT 센서에서 데이터를 직접 Amazon S3로 수집하여 Parquet 형식으로 자동 변환합니다.",
        "Explanation": "Kinesis Data Firehose는 스트리밍 데이터의 원활한 수집을 위해 특별히 설계되었으며, Amazon S3에 저장하기 전에 데이터를 자동으로 변환하고 압축할 수 있어 이 시나리오에 가장 효율적인 선택입니다.",
        "Other Options": [
            "Kinesis Data Streams를 사용하는 것은 샤드 및 데이터 변환을 위한 Lambda 함수에 대한 추가 설정이 필요하므로 Firehose를 사용하는 것보다 운영 복잡성이 증가합니다.",
            "IoT 센서에서 Amazon S3로 직접 데이터를 수집하는 것은 Kinesis 서비스의 실시간 수집 기능을 우회하며 변환을 위해 수동 개입이 필요합니다.",
            "Kinesis Data Analytics는 데이터를 실시간으로 처리할 수 있지만 IoT 센서에서 데이터 수집을 직접 처리하지 않으며, 이 사용 사례에 필수적인 데이터 저장도 하지 않습니다."
        ]
    },
    {
        "Question Number": "43",
        "Situation": "머신 러닝 엔지니어가 예측 분석 프로젝트를 위해 다양한 모델을 평가하고 있습니다. 엔지니어는 모델 품질과 엔지니어링 자원 및 모델 훈련에 소요되는 시간 측면에서 비용 효율성을 모두 최적화해야 합니다.",
        "Question": "엔지니어가 모델을 비교하기 위해 고려해야 할 지표의 조합은 무엇입니까? (두 개 선택)",
        "Options": {
            "1": "각 모델이 수렴하는 데 걸린 훈련 시간.",
            "2": "모델에 사용된 특징의 수.",
            "3": "훈련에 사용된 기본 인프라의 비용.",
            "4": "모델 개발에 필요한 총 엔지니어링 시간.",
            "5": "정확도 및 F1 점수와 같은 평가 지표."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "모델 개발에 필요한 총 엔지니어링 시간.",
            "각 모델이 수렴하는 데 걸린 훈련 시간."
        ],
        "Explanation": "모델 개발에 필요한 총 엔지니어링 시간과 각 모델이 수렴하는 데 걸린 훈련 시간은 모델을 비교하는 데 중요한 지표입니다. 이들은 모델 훈련 및 배포에 관련된 효율성과 자원 할당에 대한 통찰력을 제공합니다.",
        "Other Options": [
            "정확도 및 F1 점수와 같은 평가 지표는 모델 성능을 평가하는 데 중요하지만, 이 시나리오에서 필수적인 엔지니어링 비용이나 훈련 효율성을 직접 비교하지는 않습니다.",
            "모델에 사용된 특징의 수는 모델 복잡성과 성능과 더 관련이 있으며, 엔지니어링 자원 사용이나 훈련 시간을 직접 측정하는 것과는 관련이 없습니다.",
            "기본 인프라의 비용은 관련이 있지만, 엔지니어링 노력이나 훈련 효율성에 대한 전체적인 그림을 제공하지 않으므로 이 특정 비교에는 덜 효과적입니다."
        ]
    },
    {
        "Question Number": "44",
        "Situation": "머신 러닝 전문가가 대규모 데이터 세트를 사용하여 예측 모델을 개발하고 있습니다. 모델이 보지 못한 데이터에 잘 일반화되도록 하기 위해 전문가가 교차 검증을 구현하기로 결정했습니다. 데이터 세트가 크고, 전문가는 검증 프로세스의 무결성을 유지하면서 훈련 시간을 최적화하고자 합니다.",
        "Question": "전문가가 계산 오버헤드를 최소화하면서 모델을 효율적으로 검증하기 위해 선택해야 할 교차 검증 기법은 무엇입니까?",
        "Options": {
            "1": "계층화된 k-겹 교차 검증을 구현하여 클래스 분포가 유지되도록 합니다.",
            "2": "훈련 시간을 줄이기 위해 작은 k 값을 가진 k-겹 교차 검증을 사용합니다.",
            "3": "과적합을 피하기 위해 검증을 위해 데이터 세트의 단일 무작위 분할을 선택합니다.",
            "4": "모든 데이터 포인트를 훈련에 활용하기 위해 leave-one-out 교차 검증을 적용합니다."
        },
        "Correct Answer": "훈련 시간을 줄이기 위해 작은 k 값을 가진 k-겹 교차 검증을 사용합니다.",
        "Explanation": "k-겹 교차 검증은 데이터 세트를 k개의 하위 집합으로 나누어 모델 성능을 검증하는 강력한 방법입니다. k의 작은 값(예: 5 또는 10)을 사용하면 전문가는 훈련 시간을 관리 가능하게 유지하면서 모델을 여러 번 훈련할 수 있습니다. 이 접근 방식은 정확성과 효율성을 잘 균형 잡습니다.",
        "Other Options": [
            "계층화된 k-겹 교차 검증은 각 겹이 유사한 클래스 분포를 가지도록 보장하는 좋은 기법이지만, k가 클 경우 여전히 계산 비용이 많이 들 수 있습니다. 이 경우 전문가는 훈련 시간을 최소화할 방법을 찾고 있습니다.",
            "leave-one-out 교차 검증은 거의 전체 데이터 세트를 훈련에 사용하므로 매우 정확하지만, 대규모 데이터 세트에서는 계산 집약적입니다. 이는 n번 모델을 훈련해야 하며, 여기서 n은 관측치의 수입니다.",
            "검증을 위해 데이터 세트의 단일 무작위 분할을 선택하면 과적합으로 이어질 수 있으며, 이는 다양한 하위 집합에서 모델 성능에 대한 포괄적인 관점을 제공하지 않기 때문입니다. 이 방법은 신뢰할 수 있는 검증에 필요한 강건성이 부족합니다."
        ]
    },
    {
        "Question Number": "45",
        "Situation": "소매 회사가 고객 이탈을 예측하는 다양한 머신 러닝 모델의 성능을 평가하고자 합니다. 그들은 로지스틱 회귀, 랜덤 포레스트 및 그래디언트 부스팅을 포함하여 여러 모델을 배포했습니다. 그들은 예측 성능과 해석 가능성을 기준으로 최상의 모델을 선택하고자 합니다.",
        "Question": "회사가 정밀도와 재현율의 균형을 맞추기 위해 모델을 평가하는 데 주로 사용해야 할 지표는 무엇입니까?",
        "Options": {
            "1": "평균 절대 오차",
            "2": "F1 점수",
            "3": "제곱근 평균 제곱 오차",
            "4": "수신자 조작 특성 (ROC) 곡선"
        },
        "Correct Answer": "F1 점수",
        "Explanation": "F1 점수는 정밀도와 재현율의 조화 평균으로, 고객 이탈 예측과 같은 이진 분류 작업에서 거짓 긍정과 거짓 부정을 균형 있게 맞추는 것이 중요한 시나리오에 적합한 지표입니다.",
        "Other Options": [
            "평균 절대 오차는 주로 회귀 문제에 사용되며, 정밀도와 재현율 간의 균형에 대한 통찰력을 제공하지 않습니다.",
            "수신자 조작 특성 (ROC) 곡선은 성능을 시각화하는 데 유용하지만, 정밀도와 재현율을 균형 있게 맞추는 단일 지표를 제공하지 않습니다.",
            "제곱근 평균 제곱 오차는 회귀 작업에 사용되며, 정밀도와 재현율에 대한 분류 모델 평가에는 적용되지 않습니다."
        ]
    },
    {
        "Question Number": "46",
        "Situation": "한 금융 서비스 회사는 대출 신청에 대한 고객 문의 처리를 자동화하고자 합니다. 문의의 복잡성은 다양할 수 있으며, 회사는 원활한 경험을 제공하기 위해 여러 AWS 서비스를 활용하고자 합니다. 그들은 AWS Step Functions를 사용하여 문의를 번역하고, 감정을 분석하며, 백엔드 시스템에서 신청 상태를 가져오는 일련의 AWS Lambda 함수를 조율하기로 결정했습니다. 외부 서비스에서 대기할 수 있는 솔루션이 필요하며, 실행 논리가 효과적으로 유지되도록 해야 합니다.",
        "Question": "이러한 프로세스의 오케스트레이션을 구현하기 위해 가장 적합한 AWS 서비스는 무엇이며 그 이유는 무엇인가요?",
        "Options": {
            "1": "AWS Lambda는 오케스트레이션 없이 서버리스 방식으로 함수를 실행할 수 있습니다.",
            "2": "Amazon Comprehend는 텍스트를 분석할 수 있지만 여러 서비스의 오케스트레이션을 지원하지 않습니다.",
            "3": "Amazon S3는 저장을 위해 설계되었으며 Lambda 함수를 직접 트리거할 수 있습니다.",
            "4": "AWS Step Functions는 여러 AWS 서비스를 조정하고 상태를 통해 실행 흐름을 관리할 수 있습니다."
        },
        "Correct Answer": "AWS Step Functions는 여러 AWS 서비스를 조정하고 상태를 통해 실행 흐름을 관리할 수 있습니다.",
        "Explanation": "AWS Step Functions는 여러 AWS 서비스를 조정하여 복잡한 실행 논리를 구현할 수 있도록 설계되었습니다. 비동기 작업에서 대기할 수 있으며 상태 관리를 처리할 수 있어 이 시나리오에 이상적인 선택입니다.",
        "Other Options": [
            "AWS Lambda는 오케스트레이션을 위한 단독 솔루션으로 적합하지 않으며, 주로 여러 서비스 간의 워크플로우를 관리하지 않고 코드를 실행하는 컴퓨팅 서비스입니다.",
            "Amazon S3는 주로 저장 서비스이며 오케스트레이션 기능을 제공하지 않습니다. Lambda 함수를 트리거할 수 있지만 여러 서비스의 실행 흐름을 관리할 수는 없습니다.",
            "Amazon Comprehend는 텍스트를 분석하고 통찰력을 제공하는 NLP 서비스이지만, 워크플로우에서 여러 AWS 서비스의 오케스트레이션이나 조정을 촉진하지 않습니다."
        ]
    },
    {
        "Question Number": "47",
        "Situation": "데이터 엔지니어링 팀은 실시간 IoT 애플리케이션의 스트리밍 데이터를 분석에 적합한 구조화된 형식으로 변환하는 작업을 맡고 있습니다. 데이터 처리 중 낮은 지연 시간과 높은 처리량을 보장해야 합니다. 팀은 이 요구 사항을 효율적으로 처리하기 위해 다양한 AWS 서비스를 고려하고 있습니다.",
        "Question": "팀이 최소한의 지연 시간과 높은 확장성으로 전송 중인 데이터를 변환하기 위해 어떤 솔루션을 구현해야 하나요?",
        "Options": {
            "1": "Kinesis Data Streams에 의해 트리거되는 Lambda 함수를 생성하여 들어오는 데이터를 실시간으로 처리하고 변환합니다.",
            "2": "AWS Batch 작업을 설정하여 일정 기간 동안 수집된 데이터를 배치로 처리합니다.",
            "3": "Amazon EMR과 Apache Spark Streaming을 활용하여 스트리밍 데이터를 실시간으로 처리하고 변환합니다.",
            "4": "AWS Glue를 활용하여 데이터를 Amazon S3에 로드하기 전에 변환하는 ETL 작업을 생성합니다."
        },
        "Correct Answer": "Amazon EMR과 Apache Spark Streaming을 활용하여 스트리밍 데이터를 실시간으로 처리하고 변환합니다.",
        "Explanation": "Amazon EMR과 Apache Spark Streaming을 사용하면 스트리밍 데이터를 강력하고 확장 가능하며 낮은 지연 시간으로 처리할 수 있습니다. 이 설정은 실시간 분석을 위해 설계되어 데이터가 도착하는 즉시 변환할 수 있어 IoT 애플리케이션의 요구 사항에 이상적입니다.",
        "Other Options": [
            "AWS Glue를 ETL 작업에 사용하는 것은 실시간 스트리밍 데이터보다는 배치 처리에 더 적합하여 낮은 지연 시간 요구 사항을 충족하지 않습니다.",
            "AWS Batch는 배치 처리를 위해 설계되었으며, 데이터가 그룹으로 수집되고 처리되기 때문에 지연 시간을 초래하여 변환을 지연시킵니다.",
            "Kinesis Data Streams에 의해 트리거되는 Lambda 함수를 생성하는 것은 가능하지만, 실행 시간과 메모리에 대한 제한으로 인해 EMR과 Spark Streaming만큼 대규모 처리를 효율적으로 처리하지 못할 수 있습니다."
        ]
    },
    {
        "Question Number": "48",
        "Situation": "한 금융 서비스 회사는 신용 위험을 예측하기 위한 머신 러닝 모델을 배포하고 있습니다. 이 모델은 특히 월말과 같은 피크 시간 동안 변동하는 사용자 요청을 처리할 수 있도록 높은 가용성과 확장성이 필요합니다. 머신 러닝 전문가는 배포가 요구되는 성능 지표를 충족하면서 잠재적인 실패에 대한 복원력을 보장해야 합니다.",
        "Question": "전문가가 머신 러닝 모델의 높은 가용성, 확장성 및 내결함성을 보장하기 위해 어떤 아키텍처를 구현해야 하나요?",
        "Options": {
            "1": "로드 스파이크를 처리하기 위해 단일 EC2 인스턴스에 모델을 배포하고 자동 확장 그룹을 설정합니다.",
            "2": "성능 지표에 따라 수동으로 확장하는 Elastic Load Balancer 뒤의 EC2 인스턴스에 모델을 호스팅합니다.",
            "3": "Amazon SageMaker를 사용하여 다중 AZ 배포와 자동 확장을 활성화한 엔드포인트를 생성합니다.",
            "4": "모델 추론을 위해 AWS Lambda를 사용하여 서버리스 아키텍처를 생성하고 결과를 DynamoDB에 저장합니다."
        },
        "Correct Answer": "Amazon SageMaker를 사용하여 다중 AZ 배포와 자동 확장을 활성화한 엔드포인트를 생성합니다.",
        "Explanation": "Amazon SageMaker를 사용하면 높은 가용성과 자동 확장 기능이 내장되어 있어 모델이 다양한 부하를 효율적으로 처리할 수 있습니다. 다중 AZ 배포는 실패 시 건강한 엔드포인트로 요청을 라우팅하여 내결함성을 보장합니다.",
        "Other Options": [
            "단일 EC2 인스턴스에 모델을 배포하는 것은 높은 가용성을 제공하지 않으며, 단일 실패 지점을 생성합니다. 자동 확장은 부하를 처리하는 데 도움이 될 수 있지만 인스턴스가 실패할 경우 내결함성을 보장할 수 없습니다.",
            "Elastic Load Balancer 뒤의 EC2 인스턴스에 모델을 호스팅하는 것은 변동하는 작업 부하에 대해 최적이 아니며, 수동 개입이 필요합니다. 또한 이 설정은 장애 조치를 위한 추가 구성 없이는 높은 가용성을 보장하지 않습니다.",
            "AWS Lambda를 사용하여 서버리스 아키텍처를 생성하는 것은 콜드 스타트 문제를 일으킬 수 있으며, 일관된 낮은 지연 시간이 필요한 모델에는 적합하지 않을 수 있습니다. 또한, SageMaker 엔드포인트와 같은 수준의 성능과 확장성을 보장하지 않을 수 있습니다."
        ]
    },
    {
        "Question Number": "49",
        "Situation": "기계 학습 전문가가 역사적인 고객 데이터를 사용하여 구독 기반 서비스의 고객 이탈을 예측하는 임무를 맡았습니다. 데이터 세트에는 고객 인구 통계, 사용 패턴 및 참여 지표와 같은 특성이 포함되어 있습니다.",
        "Question": "고객 이탈 예측에서 가장 높은 정확도를 달성하기 위해 전문가는 어떤 알고리즘을 사용해야 합니까?",
        "Options": {
            "1": "K-Nearest Neighbors (KNN) algorithm",
            "2": "Random Forest algorithm",
            "3": "Linear Regression algorithm",
            "4": "Support Vector Machine (SVM) algorithm"
        },
        "Correct Answer": "Random Forest algorithm",
        "Explanation": "Random Forest 알고리즘은 훈련 중에 여러 개의 결정 트리를 구성하고 그들의 예측 모드를 출력하는 앙상블 학습 방법입니다. 이 알고리즘은 고차원 대규모 데이터 세트를 처리하고 특성 간의 복잡한 상호작용을 모델링할 수 있는 능력 덕분에 고객 이탈 예측과 같은 분류 작업에 특히 효과적입니다.",
        "Other Options": [
            "K-Nearest Neighbors (KNN) 알고리즘은 거리 측정 기준의 선택에 민감하며 고차원 데이터에서 어려움을 겪을 수 있어 이 맥락에서 이탈 예측에 대한 신뢰성이 떨어집니다.",
            "Support Vector Machine (SVM) 알고리즘은 이진 분류 문제에 효과적일 수 있지만, 매개변수의 세심한 조정이 필요할 수 있으며 대규모 데이터 세트에 대해 Random Forest만큼 강력하지 않습니다.",
            "Linear Regression은 연속 값을 예측하도록 설계되었기 때문에 이 문제에 적합하지 않으며, 고객 이탈 예측은 본질적으로 분류 문제입니다."
        ]
    },
    {
        "Question Number": "50",
        "Situation": "데이터 엔지니어링 팀이 웹 서버에서 생성된 대량의 로그 데이터를 처리하는 임무를 맡았습니다. 이 데이터는 기계 학습 애플리케이션에 사용되기 전에 정리되고, 정규화되며, 변환되어야 합니다. 팀은 운영 복잡성을 최소화하면서 이 데이터를 효율적으로 처리하기 위해 AWS 서비스를 활용하고자 합니다.",
        "Question": "최소한의 관리 오버헤드로 로그 데이터 처리를 가장 잘 지원하는 AWS 서비스 조합은 무엇입니까?",
        "Options": {
            "1": "Amazon EMR과 Spark를 사용하여 S3에 저장된 로그 데이터를 처리합니다. 분산 처리를 위해 코어 및 작업 노드에서 Spark 작업을 실행하고, 추가 분석을 위해 출력을 다시 S3에 저장합니다.",
            "2": "AWS Glue를 활용하여 S3의 로그 데이터에 대해 ETL 작업을 수행한 후, 정리된 데이터를 Amazon SageMaker로 내보내 모델 훈련을 진행합니다.",
            "3": "AWS Lambda 함수를 구현하여 S3에 도착하는 로그 데이터를 처리합니다. 처리된 데이터를 Amazon SageMaker로 푸시하여 기계 학습 작업을 수행합니다.",
            "4": "온프레미스 Hadoop 클러스터를 설정하여 MapReduce를 사용해 로그 데이터를 처리합니다. 처리 후 데이터를 Amazon S3로 전송하여 기계 학습 훈련을 진행합니다."
        },
        "Correct Answer": "Amazon EMR과 Spark를 사용하여 S3에 저장된 로그 데이터를 처리합니다. 분산 처리를 위해 코어 및 작업 노드에서 Spark 작업을 실행하고, 추가 분석을 위해 출력을 다시 S3에 저장합니다.",
        "Explanation": "Amazon EMR과 Spark를 사용하면 S3에 저장된 대규모 데이터 세트를 효율적으로 처리할 수 있으며, 기본 인프라를 관리할 필요 없이 분산 컴퓨팅 기능을 활용할 수 있습니다. 이 솔루션은 기계 학습을 위한 데이터 준비 작업의 워크플로우를 간소화합니다.",
        "Other Options": [
            "온프레미스 Hadoop 클러스터를 설정하면 상당한 관리 오버헤드와 복잡성이 발생합니다. 또한 AWS의 확장 가능하고 완전 관리되는 서비스를 활용하지 않으므로 EMR을 사용하는 것보다 효율성이 떨어집니다.",
            "AWS Glue는 좋은 ETL 서비스이지만, EMR의 Spark처럼 대규모 데이터 세트나 복잡한 변환에 대해 효과적이지 않을 수 있습니다.",
            "AWS Lambda를 사용하여 로그 데이터를 처리하는 것은 작은 데이터 세트에는 효과적일 수 있지만, Lambda는 실행 시간 제한이 있으며 EMR의 분산 처리 기능에 비해 대규모 데이터 처리를 효율적으로 처리하지 못할 수 있습니다."
        ]
    },
    {
        "Question Number": "51",
        "Situation": "기계 학습 전문가가 다양한 알고리즘을 사용하여 금융 데이터 세트에 대한 예측 모델을 구축하는 임무를 맡았습니다. 여러 옵션을 평가한 후, 전문가는 효율성과 예측 능력 덕분에 XGBoost를 구현하기로 결정했습니다. 그러나 그는 모델의 하이퍼파라미터와 성능에 미치는 영향에 대해 확신이 없습니다.",
        "Question": "표 형 데이터 예측을 위해 XGBoost를 사용하는 주요 장점은 무엇이며, 전문가는 하이퍼파라미터를 어떻게 고려해야 합니까?",
        "Options": {
            "1": "XGBoost는 주로 비정형 데이터에 뛰어난 딥 러닝 알고리즘으로, 최소한의 조정이 필요합니다.",
            "2": "XGBoost는 단일 결정 트리에 한정되어 있으며 더 나은 정확도를 위한 앙상블 방법을 활용할 수 없습니다.",
            "3": "XGBoost는 결정 트리를 최적화하는 그래디언트 부스팅 프레임워크를 활용하여 성능을 향상시키기 위해 광범위한 하이퍼파라미터 조정을 허용합니다.",
            "4": "XGBoost는 표 형 데이터에 적합하지 않으며 고정된 수의 하이퍼파라미터로만 이미지 기반 예측에 사용해야 합니다."
        },
        "Correct Answer": "XGBoost는 결정 트리를 최적화하는 그래디언트 부스팅 프레임워크를 활용하여 성능을 향상시키기 위해 광범위한 하이퍼파라미터 조정을 허용합니다.",
        "Explanation": "XGBoost는 효율성과 높은 성능을 위해 설계된 강력한 그래디언트 부스팅 알고리즘으로, 특히 표 형 데이터에 적합합니다. 이 아키텍처는 여러 하이퍼파라미터를 조정할 수 있게 하여 모델 정확도를 크게 향상시키고 과적합을 줄일 수 있습니다.",
        "Other Options": [
            "XGBoost는 딥 러닝 알고리즘이 아니며 구조화된 데이터에 최적화되어 있으므로 이 옵션은 잘못되었습니다.",
            "XGBoost는 표 형 데이터에 대해 매우 효과적이지만, 이 유형의 데이터에 적합하지 않거나 고정된 하이퍼파라미터에 한정된다고 말하는 것은 올바르지 않습니다.",
            "XGBoost는 여러 결정 트리를 구축하는 앙상블 방법이므로 단일 결정 트리에 한정된다고 주장하는 것은 근본적으로 잘못된 것입니다."
        ]
    },
    {
        "Question Number": "52",
        "Situation": "한 회사가 민감한 데이터를 처리하는 머신 러닝 모델을 실행하기 위해 AWS 서비스를 활용하고 있습니다. 규정 준수를 보장하고 보안을 강화하기 위해, 머신 러닝 워크플로우와 관련된 API 호출을 포함하여 AWS 리소스에 대한 모든 API 호출을 기록하고 모니터링해야 합니다. 이 회사는 리소스에서 수행된 작업을 신뢰할 수 있고 확장 가능한 방식으로 가시성을 제공하는 솔루션을 원합니다.",
        "Question": "회사가 Amazon SageMaker와 Amazon S3를 포함하여 AWS 리소스에 대한 API 호출을 기록하기 위해 어떤 AWS 서비스를 사용해야 합니까?",
        "Options": {
            "1": "AWS CloudFormation을 사용하여 리소스 프로비저닝을 자동화하고 인프라를 코드로 관리합니다.",
            "2": "API 호출을 기록하기 위해 AWS CloudTrail을 사용하고, 메트릭 및 로그 모니터링을 위해 Amazon CloudWatch를 사용합니다.",
            "3": "AWS Config를 사용하여 리소스 구성 및 변경 사항을 시간에 따라 추적하여 규정 준수를 보장합니다.",
            "4": "추가 서비스를 사용하지 않고 Amazon SageMaker에서 직접 로그 파일을 수집하기 위해 Amazon CloudWatch를 사용합니다."
        },
        "Correct Answer": "API 호출을 기록하기 위해 AWS CloudTrail을 사용하고, 메트릭 및 로그 모니터링을 위해 Amazon CloudWatch를 사용합니다.",
        "Explanation": "AWS CloudTrail은 AWS 계정에서 수행된 API 호출을 포괄적으로 기록하며, Amazon SageMaker와 Amazon S3와 같은 서비스에 대한 호출도 포함됩니다. 이를 통해 회사는 사용자 활동 및 API 사용을 추적할 수 있으며, 이는 보안 및 규정 준수에 필수적입니다. Amazon CloudWatch는 로그 및 메트릭을 모니터링하고 시각화하는 데 사용되어 운영 가시성을 향상시킵니다.",
        "Other Options": [
            "Amazon CloudWatch는 API 호출을 기록하지 않으며, AWS 서비스에서 생성된 메트릭 및 로그 모니터링에 주로 집중하므로 API 활동의 완전한 기록을 위해서는 불충분합니다.",
            "AWS Config는 시간에 따라 AWS 리소스의 구성을 추적하도록 설계되었지만, AWS 환경에서 누가 무엇을 했는지를 이해하는 데 필요한 API 호출을 기록하지 않습니다.",
            "AWS CloudFormation은 주로 AWS 리소스를 코드로 프로비저닝하고 관리하는 서비스입니다. API 호출에 대한 기록 기능을 제공하지 않으므로 리소스에서의 작업 모니터링 요구를 충족하지 못합니다."
        ]
    },
    {
        "Question Number": "53",
        "Situation": "한 머신 러닝 엔지니어가 Amazon SageMaker를 사용하여 대규모 데이터 세트에서 딥 러닝 모델을 훈련하고 있습니다. 평가 단계에서 모델은 검증 데이터 세트에 비해 훈련 데이터 세트에서 훨씬 더 나은 성능을 보이며, 이는 과적합을 나타냅니다. 엔지니어는 이 문제를 완화할 방법을 고려하고 있습니다.",
        "Question": "이 시나리오에서 과적합을 줄이는 데 가장 효과적인 전략은 무엇입니까?",
        "Options": {
            "1": "훈련 에포크 수를 늘립니다.",
            "2": "모델 아키텍처에 드롭아웃 레이어를 추가합니다.",
            "3": "더 큰 배치 크기로 모델을 훈련합니다.",
            "4": "추가 매개변수가 있는 더 복잡한 모델을 사용합니다."
        },
        "Correct Answer": "모델 아키텍처에 드롭아웃 레이어를 추가합니다.",
        "Explanation": "드롭아웃 레이어를 추가하면 훈련 중에 일부 뉴런을 무작위로 비활성화하여 모델이 더 강력한 특징을 학습하도록 유도하고 특정 뉴런에 대한 의존성을 줄입니다. 이는 모델이 훈련 데이터에 너무 특화되는 것을 방지하여 과적합을 효과적으로 방지합니다.",
        "Other Options": [
            "훈련 에포크 수를 늘리면 모델이 정규화 없이 훈련 데이터에서 계속 학습하게 되어 과적합 문제가 악화될 가능성이 높아지며, 검증 세트에서의 일반화 성능이 더욱 저하됩니다.",
            "추가 매개변수가 있는 더 복잡한 모델을 사용하면 과적합 문제가 심화될 수 있으며, 더 복잡한 모델은 훈련 데이터를 암기할 가능성이 높아져 보지 못한 데이터에 효과적으로 일반화하지 못합니다.",
            "더 큰 배치 크기로 모델을 훈련하면 일반화 성능이 저하될 수 있으며, 큰 배치는 덜 노이즈가 있는 그래디언트 업데이트를 초래할 수 있어 모델이 잘 일반화되지 않는 날카로운 최소값으로 수렴할 수 있습니다."
        ]
    },
    {
        "Question Number": "54",
        "Situation": "한 게임 회사가 복잡한 비디오 게임에서 플레이어 경험을 개선하기 위해 AI 에이전트를 개발하고 있습니다. 그들은 에이전트가 게임 환경과 상호작용하여 최적의 전략을 학습하고, 성공적인 행동에 대한 보상과 실패에 대한 패널티를 받기를 원합니다. 회사는 이를 구현하기 위한 최상의 머신 러닝 접근 방식을 식별해야 합니다.",
        "Question": "회사가 동적 환경에서 시행착오를 통해 학습하는 AI 에이전트를 개발하기 위해 어떤 머신 러닝 패러다임을 사용해야 합니까?",
        "Options": {
            "1": "라벨이 있는 데이터와 라벨이 없는 데이터를 결합하여 에이전트를 훈련하기 위한 반지도 학습.",
            "2": "과거 게임 플레이를 기반으로 플레이어 행동을 예측하기 위한 라벨이 있는 데이터를 사용하는 지도 학습.",
            "3": "에이전트가 자신의 행동에 따라 보상과 패널티를 통해 학습할 수 있도록 하는 강화 학습.",
            "4": "사전 정의된 라벨 없이 다양한 플레이어 행동을 클러스터링하기 위한 비지도 학습."
        },
        "Correct Answer": "에이전트가 자신의 행동에 따라 보상과 패널티를 통해 학습할 수 있도록 하는 강화 학습.",
        "Explanation": "강화 학습은 에이전트가 환경과의 상호작용을 통해 시행착오로 학습하고, 행동에 대한 보상에 따라 전략을 조정할 수 있도록 하는 가장 적합한 접근 방식입니다. 이는 비디오 게임의 동적 특성과 완벽하게 일치합니다.",
        "Other Options": [
            "지도 학습은 라벨이 있는 데이터 세트를 필요로 하며, 에이전트가 상호작용을 통해 최적의 행동을 발견해야 하는 시나리오에는 적합하지 않아 게임 AI 맥락에서 비효율적입니다.",
            "비지도 학습은 라벨 없이 데이터에서 패턴과 그룹을 찾는 데 중점을 두며, 에이전트가 게임에서 자신의 행동에 대한 피드백을 통해 학습해야 하는 상황에는 적용되지 않습니다.",
            "반지도 학습은 라벨이 있는 데이터와 라벨이 없는 데이터를 결합하지만 여전히 지도 접근 방식에 의존하므로 동적 환경에서 직접 상호작용과 피드백을 통해 학습해야 하는 요구 사항에 맞지 않습니다."
        ]
    },
    {
        "Question Number": "55",
        "Situation": "데이터 과학자가 의사 결정 트리 모델을 사용하여 이진 분류 문제를 해결하고 있습니다. 그녀는 트리가 효율적으로 구축되도록 하여 목표 변수에 대한 예측력을 가장 많이 제공하는 특성에 집중하고자 합니다.",
        "Question": "이진 분류를 위한 의사 결정 트리 알고리즘에서 루트 노드를 선택하는 주요 기준은 무엇인가요?",
        "Options": {
            "1": "결측치가 가장 적은 특성.",
            "2": "데이터셋의 특성 중 분산이 가장 높은 특성.",
            "3": "데이터셋의 레이블과 가장 높은 상관관계를 가진 특성.",
            "4": "지니 불순도를 최소화하거나 정보 이득을 극대화하는 특성."
        },
        "Correct Answer": "지니 불순도를 최소화하거나 정보 이득을 극대화하는 특성.",
        "Explanation": "의사 결정 트리에서는 루트 노드가 목표 변수에 따라 데이터를 가장 잘 분리하는 특성을 기준으로 선택됩니다. 이는 일반적으로 지니 불순도를 최소화하거나 정보 이득을 극대화함으로써 결정되며, 이는 데이터셋에서 가장 효과적인 분할을 생성하는 데 도움이 됩니다.",
        "Other Options": [
            "레이블과의 상관관계는 중요하지만, 루트 노드를 선택하는 주요 기준은 아닙니다. 의사 결정 트리는 불순도 감소와 정보 이득에 중점을 두며, 이는 상관관계만으로는 포착할 수 없는 특성 간의 상호작용을 고려할 수 있습니다.",
            "분산만으로는 특성이 분류 문제에서 클래스들을 얼마나 잘 분리하는지를 나타내지 않습니다. 특성이 높은 분산을 가질 수 있지만, 목표 변수에 대한 중요한 구별력을 제공하지 않을 수 있습니다.",
            "결측치는 처리해야 하지만, 루트 노드를 선택하는 것은 결측치의 수에 기반하지 않습니다. 대신, 데이터셋에서 특성이 클래스를 얼마나 잘 분리할 수 있는지에 중점을 둡니다."
        ]
    },
    {
        "Question Number": "56",
        "Situation": "머신러닝 전문가가 AWS에서 머신러닝 모델을 배포하기 위한 표준화된 환경을 만드는 임무를 맡았습니다. 배포 간 일관성을 보장하기 위해, 전문가는 필요한 구성과 종속성을 캡슐화하는 Amazon Machine Images (AMIs)와 골든 이미지를 만들고자 합니다.",
        "Question": "전문가는 AMIs와 골든 이미지를 만들기 위해 어떤 방법을 사용할 수 있나요? (두 가지 선택)",
        "Options": {
            "1": "AWS Systems Manager를 사용하여 AMI 생성 프로세스를 자동화하기",
            "2": "EC2 CLI를 사용하여 프로그래밍 방식으로 AMIs 생성하기",
            "3": "사전 설치된 패키지가 있는 기존 EC2 인스턴스에서 AMI 생성하기",
            "4": "AWS CloudFormation을 사용하여 인프라를 코드로 정의하기",
            "5": "AWS CodeDeploy를 활용하여 머신러닝 모델을 직접 배포하기"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "AWS Systems Manager를 사용하여 AMI 생성 프로세스를 자동화하기",
            "사전 설치된 패키지가 있는 기존 EC2 인스턴스에서 AMI 생성하기"
        ],
        "Explanation": "AWS Systems Manager를 사용하면 전문가는 AMI 생성 프로세스를 자동화하고 간소화하여 필요한 모든 구성이 캡처되도록 할 수 있습니다. 또한, 사전 설치된 패키지가 있는 기존 EC2 인스턴스에서 AMI를 생성하면 환경이 일관되고 생산 사용을 위한 준비가 완료됩니다.",
        "Other Options": [
            "AWS CloudFormation은 주로 인프라 프로비저닝에 사용되며 AMIs나 골든 이미지를 생성하는 데 사용되지 않습니다. 자원을 정의할 수는 있지만, AMIs를 직접 생성하지는 않습니다.",
            "AWS CodeDeploy는 애플리케이션 배포를 위한 서비스로, AMIs나 골든 이미지를 생성할 수 있는 기능이 없습니다. 그 초점은 이미지 생성이 아닌 애플리케이션 배포에 있습니다.",
            "EC2 CLI는 실제로 AMIs를 프로그래밍 방식으로 생성할 수 있지만, AWS Systems Manager를 사용하는 것만큼 포괄적이거나 자동화되어 있지 않으며, 추가 관리 기능을 제공합니다."
        ]
    },
    {
        "Question Number": "57",
        "Situation": "데이터 과학자가 대규모 데이터셋을 사용하여 분류 모델을 구축했습니다. 훈련 후, 모델은 훈련 세트에서 F1 점수 0.85를 보였지만 검증 세트에서는 F1 점수 0.60만 보였습니다. 모델의 성능에 대해 우려한 데이터 과학자는 일반화 능력을 개선하고자 합니다.",
        "Question": "데이터 과학자는 모델의 성능 차이를 해결하기 위해 무엇을 해야 하나요?",
        "Options": {
            "1": "모델의 복잡성을 줄여 과적합을 방지하고 재훈련하기.",
            "2": "모델의 복잡성을 증가시켜 훈련 데이터에서 더 많은 패턴을 포착하기.",
            "3": "같은 훈련 데이터셋을 다시 사용하되, 모델 초기화를 위한 랜덤 시드를 변경하기.",
            "4": "데이터셋에 더 많은 특성을 추가하여 모델에 추가 정보를 제공하기."
        },
        "Correct Answer": "모델의 복잡성을 줄여 과적합을 방지하고 재훈련하기.",
        "Explanation": "모델의 복잡성을 줄이면 과적합을 완화하는 데 도움이 될 수 있으며, 이는 훈련에서 검증으로의 F1 점수의 급격한 하락으로 나타납니다. 이 접근 방식은 모델이 보지 못한 데이터에 대해 더 잘 일반화할 수 있도록 합니다.",
        "Other Options": [
            "모델의 복잡성을 증가시키는 것은 과적합을 악화시킬 가능성이 높아 검증 데이터에서 성능이 더욱 나빠질 수 있습니다.",
            "더 많은 특성을 추가하면 때때로 노이즈를 유발하고 모델을 더욱 복잡하게 만들 수 있으며, 이는 과적합 문제를 해결하지 못할 수 있습니다.",
            "다른 랜덤 시드를 사용하여 같은 훈련 데이터셋을 사용하는 것은 과적합의 근본적인 문제를 해결하지 않으며, 검증 성능을 개선하지 않을 것입니다."
        ]
    },
    {
        "Question Number": "58",
        "Situation": "머신러닝 엔지니어가 고객 이탈 예측을 위한 여러 모델을 평가하고 있습니다. 엔지니어는 각 모델의 정확도, 정밀도, F1 점수 등 다양한 지표를 계산했으며, 각 모델의 훈련에 소요된 시간도 고려하고 있습니다.",
        "Question": "다양한 머신러닝 모델을 비교할 때, 어떤 접근 방식이 성능에 대한 가장 포괄적인 시각을 제공합니까?",
        "Options": {
            "1": "훈련 시간이 가장 짧은 모델만 우선시합니다.",
            "2": "모델 간의 정확도 지표에만 집중합니다.",
            "3": "다른 요소와 관계없이 복잡성이 가장 높은 모델을 선택합니다.",
            "4": "정확도, 정밀도, 재현율 및 훈련 시간을 포함한 여러 지표를 고려합니다."
        },
        "Correct Answer": "정확도, 정밀도, 재현율 및 훈련 시간을 포함한 여러 지표를 고려합니다.",
        "Explanation": "포괄적인 평가는 여러 성능 지표를 분석하여 선택된 모델이 정확도 측면에서 잘 수행될 뿐만 아니라 정밀도, 재현율 및 훈련 효율성과 같은 다른 측면도 균형을 이루도록 합니다. 이러한 전체적인 관점은 더 나은 정보에 기반한 결정을 내리는 데 도움이 됩니다.",
        "Other Options": [
            "정확도에만 집중하면 정밀도와 재현율과 같은 다른 중요한 요소를 간과하게 되어 실제 응용에서 성능이 저조한 모델이 될 수 있습니다.",
            "훈련 시간이 가장 짧은 모델을 우선시하면 정확도 및 기타 중요한 지표에서 성능이 저조할 수 있는 모델을 선택하게 되어 최적이 아닌 결정을 초래할 수 있습니다.",
            "성능 지표를 고려하지 않고 복잡성이 가장 높은 모델을 선택하면 과적합이 발생할 수 있으며, 보지 못한 데이터에 잘 일반화되지 않을 수 있습니다."
        ]
    },
    {
        "Question Number": "59",
        "Situation": "머신러닝 전문가는 회귀 작업을 위한 신경망 모델을 개발하고 있습니다. 모델의 일반화를 개선하고 과적합을 방지하기 위해 전문가는 훈련 중 다양한 기법을 고려합니다.",
        "Question": "전문가는 과적합을 줄이고 훈련 시간을 최적화하기 위해 어떤 방법을 구현해야 합니까?",
        "Options": {
            "1": "데이터 증강을 통해 데이터셋 크기를 늘립니다.",
            "2": "드롭아웃 레이어를 사용하여 뉴런을 무작위로 비활성화합니다.",
            "3": "배치 정규화를 통해 입력을 표준화합니다.",
            "4": "검증 손실에 기반한 조기 중단을 구현합니다."
        },
        "Correct Answer": "검증 손실에 기반한 조기 중단을 구현합니다.",
        "Explanation": "조기 중단은 모델의 검증 데이터셋에서 성능이 저하되기 시작할 때 훈련을 중단하는 기법으로, 과적합을 방지하고 훈련 시간을 최적화합니다. 이 방법은 성능이 저하되기 전에 최적의 에폭에서 모델이 중단되도록 합니다.",
        "Other Options": [
            "드롭아웃 레이어는 훈련 중 뉴런을 무작위로 비활성화하여 과적합을 줄이는 데 도움이 되지만, 조기 중단처럼 훈련 시간에 직접적인 영향을 미치지는 않습니다.",
            "배치 정규화는 각 레이어의 입력을 표준화하여 수렴 속도를 개선하고 때때로 일반화를 향상시킬 수 있지만, 조기 중단처럼 과적합을 명시적으로 관리하지는 않습니다.",
            "데이터 증강은 데이터셋 크기를 늘려 더 강력한 모델을 훈련하는 데 도움이 될 수 있지만, 훈련 과정에서 과적합 문제를 해결하지 않으며 실제로 훈련 시간을 늘릴 수 있습니다."
        ]
    },
    {
        "Question Number": "60",
        "Situation": "금융 서비스 회사가 생산 환경에 배포된 사기 탐지를 위한 머신러닝 모델을 개발했습니다. 모델의 성능을 평가하기 위해 회사는 새로운 모델과 기존 모델을 비교하기 위해 A/B 테스트를 수행하고자 합니다. 목표는 새로운 모델이 사용자 경험에 부정적인 영향을 미치지 않으면서 주요 성능 지표를 개선하는 것입니다.",
        "Question": "회사가 사기 탐지 모델에 대해 A/B 테스트를 효과적으로 수행하기 위해 어떤 접근 방식을 취해야 합니까?",
        "Options": {
            "1": "모델 훈련 단계에서 사용되지 않은 홀드아웃 데이터셋을 사용하여 배포 전에 새로운 모델의 정확도를 평가합니다.",
            "2": "사용자를 무작위로 새로운 모델 또는 기존 모델에 할당하고 두 그룹 간의 사기 탐지 비율을 정의된 기간 동안 비교합니다.",
            "3": "새로운 모델의 롤링 배포를 구현하여 점진적으로 노출을 늘리면서 사용자 피드백을 모니터링합니다.",
            "4": "새로운 모델의 성능을 지속적으로 모니터링하고 성능이 특정 임계값 이하로 떨어지면 이전 모델로 전환합니다."
        },
        "Correct Answer": "사용자를 무작위로 새로운 모델 또는 기존 모델에 할당하고 두 그룹 간의 사기 탐지 비율을 정의된 기간 동안 비교합니다.",
        "Explanation": "이 접근 방식은 두 모델 간의 통제된 비교를 가능하게 하여 외부 요인을 최소화하고 성능 지표를 모델 변경에 직접 귀속시킬 수 있도록 합니다. 이러한 방식의 A/B 테스트는 새로운 모델이 기존 모델에 비해 어떻게 수행되는지를 통계적으로 유효한 결과를 제공합니다.",
        "Other Options": [
            "이 옵션은 적절한 A/B 테스트보다는 그림자 배포에 더 가깝습니다. 성능 모니터링이 중요하지만, 유사한 조건에서 두 모델 간의 직접적인 비교를 제공하지 않습니다.",
            "홀드아웃 데이터셋을 평가에 사용하는 것은 배포 전 모델 성능을 평가하는 좋은 방법이지만, A/B 테스트는 라이브 환경에서 동시에 비교해야 합니다.",
            "롤링 배포는 위험을 완화하는 데 도움이 될 수 있지만, A/B 테스트에서 새로운 모델의 개선이나 문제를 검증하는 데 필수적인 명확한 나란히 성능 비교를 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "61",
        "Situation": "소매 회사가 K-Means 클러스터링을 사용하여 고객 기반을 세분화하고 타겟 마케팅을 진행하고 있습니다. 데이터 과학자는 분석에 사용할 최적의 클러스터 수(K)를 결정하는 임무를 맡고 있습니다. 다양한 K 값으로 K-Means 알고리즘을 실행한 후, 데이터 과학자는 총 클러스터 내 변동성을 클러스터 수에 대해 플로팅하여 엘보우 플롯을 생성합니다. 목표는 더 많은 클러스터를 추가해도 변동성이 크게 줄어들지 않는 K 값을 식별하는 것입니다.",
        "Question": "엘보우 플롯을 기반으로 K-Means 클러스터링에서 최적의 K 값을 선택하는 가장 효과적인 방법은 무엇입니까?",
        "Options": {
            "1": "가능한 최대 클러스터 수를 선택합니다.",
            "2": "엘보우 플롯의 변곡점에서 K 값을 선택합니다.",
            "3": "클러스터 중심으로부터의 평균 거리를 기준으로 K를 결정합니다.",
            "4": "분산 증가가 가장 적은 K 값을 사용합니다."
        },
        "Correct Answer": "엘보우 플롯의 변곡점에서 K 값을 선택합니다.",
        "Explanation": "K-Means 클러스터링에서 최적의 K 값은 일반적으로 플롯의 엘보우가 발생하는 지점에서 선택됩니다. 이 지점은 클러스터 수와 클러스터 내 변동성 감소 간의 균형을 나타내며, 더 많은 클러스터를 추가하는 것에 대한 수익 감소를 시사합니다.",
        "Other Options": [
            "최대 클러스터 수를 선택하는 것은 복잡성과 클러스터 품질 간의 균형을 고려하지 않으며, 이는 과적합 및 데이터의 잘못된 해석으로 이어질 수 있습니다.",
            "분산 증가가 가장 적은 K 값을 선택하는 것은 표준 관행이 아니며, 변동성 감소가 평준화되기 시작하는 지점을 식별하는 것이 목표이므로 잘못된 결론으로 이어질 수 있습니다.",
            "클러스터 중심으로부터의 평균 거리를 기준으로 K를 결정하는 것은 체계적인 접근 방식이 부족하며, 가장 적절한 클러스터 수를 식별하기 위해 엘보우 플롯을 효과적으로 활용하지 않습니다."
        ]
    },
    {
        "Question Number": "62",
        "Situation": "소매 회사는 고객 구매 행동을 예측하기 위해 머신러닝 솔루션을 구현하고자 합니다. 이 솔루션이 확장 가능하고, 성수기 동안 변동하는 트래픽을 처리할 수 있도록 해야 합니다. 회사는 AWS 서비스를 사용하여 ML 모델을 배포하고 인프라를 효과적으로 관리할 계획입니다.",
        "Question": "회사가 성능과 내결함성을 보장하는 머신러닝 솔루션을 어떻게 구축할 수 있습니까? (두 가지 선택)",
        "Options": {
            "1": "Amazon SageMaker를 사용하여 모델을 배포하고 수요에 따라 자동 확장을 활성화합니다.",
            "2": "더 나은 자원 활용을 위해 Amazon SageMaker 엔드포인트를 사용하여 모델을 배포합니다.",
            "3": "AWS Lambda를 활용하여 모델 추론을 트리거하고 들어오는 요청을 자동으로 관리합니다.",
            "4": "모델 예측을 캐시하기 위해 Amazon CloudFront를 콘텐츠 전송 네트워크로 구현합니다.",
            "5": "훈련된 모델을 Amazon S3 버킷에 저장하고 EC2 인스턴스에서 직접 호출합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon SageMaker를 사용하여 모델을 배포하고 수요에 따라 자동 확장을 활성화합니다.",
            "더 나은 자원 활용을 위해 Amazon SageMaker 엔드포인트를 사용하여 모델을 배포합니다."
        ],
        "Explanation": "Amazon SageMaker를 사용하면 회사가 자동 확장을 위한 내장 기능으로 모델을 효율적으로 배포할 수 있습니다. 이는 모델이 성수기 동안 다양한 부하를 처리할 수 있도록 보장합니다. 또한 Multi-Model Endpoints를 사용하면 여러 모델이 동일한 엔드포인트를 공유할 수 있어 자원 활용을 극대화하고 성능을 향상시키며 비용을 절감합니다.",
        "Other Options": [
            "훈련된 모델을 Amazon S3 버킷에 저장하고 EC2 인스턴스에서 직접 호출하는 것은 SageMaker가 제공하는 확장성과 운영 능력이 부족합니다. 이 방법은 지연 시간 증가와 관리 복잡성을 초래할 수 있습니다.",
            "모델 추론을 위해 AWS Lambda를 활용하는 것은 대규모 ML 모델에는 이상적이지 않으며, Lambda는 실행 시간과 메모리에 제한이 있어 특히 높은 트래픽에서 성능을 저해할 수 있습니다.",
            "Amazon CloudFront를 콘텐츠 전송 네트워크로 구현하는 것은 ML 모델 자체의 내결함성이나 확장성을 보장하는 것과 직접적인 관련이 없습니다. 캐싱에 도움이 될 수 있지만 모델 배포를 위한 기본 인프라 요구 사항을 해결하지는 않습니다."
        ]
    },
    {
        "Question Number": "63",
        "Situation": "데이터 엔지니어는 머신러닝 애플리케이션을 위한 스트리밍 데이터를 처리하기 위해 실시간 데이터 수집 파이프라인을 생성하는 임무를 맡고 있습니다. 목표는 AWS 서비스를 활용하여 낮은 지연 시간과 높은 확장성을 보장하는 것입니다.",
        "Question": "데이터 엔지니어가 스트리밍 데이터를 효율적으로 조정하고 처리하기 위해 주로 사용해야 하는 AWS 서비스는 무엇입니까?",
        "Options": {
            "1": "Amazon Kinesis Data Firehose",
            "2": "Amazon Redshift",
            "3": "AWS Glue",
            "4": "Amazon Managed Service for Apache Flink"
        },
        "Correct Answer": "Amazon Managed Service for Apache Flink",
        "Explanation": "Amazon Managed Service for Apache Flink는 낮은 지연 시간과 높은 처리량으로 스트리밍 데이터를 처리하기 위해 특별히 설계되어, 머신러닝 애플리케이션에 필요한 실시간 데이터 수집 파이프라인에 이상적입니다.",
        "Other Options": [
            "AWS Glue는 ETL 프로세스를 위한 데이터 준비 서비스로 주로 사용되며, 낮은 지연 시간의 스트리밍 데이터 처리를 위해 최적화되어 있지 않아 실시간 애플리케이션에 덜 적합합니다.",
            "Amazon Kinesis Data Firehose는 스트리밍 데이터를 데이터 레이크, 데이터 저장소 및 분석 서비스로 로드하는 서비스이지만, 복잡한 이벤트 처리를 위한 Flink와 같은 수준의 처리 능력을 제공하지 않습니다.",
            "Amazon Redshift는 대규모 데이터 세트의 배치 처리를 위해 최적화된 데이터 웨어하우징 서비스로, 실시간 스트리밍 데이터 수집을 위해 설계되지 않았습니다."
        ]
    },
    {
        "Question Number": "64",
        "Situation": "데이터 과학자는 Amazon Comprehend를 사용하여 고객 피드백을 분석하는 임무를 맡았습니다. 그들은 텍스트 데이터에서 감정 및 주요 구문과 같은 통찰력을 추출하고, 이름 및 날짜와 같은 엔티티를 식별하고자 합니다. 그들은 프로젝트를 위해 Amazon Comprehend의 기능을 고려하고 있습니다.",
        "Question": "데이터 과학자가 텍스트 분석을 위해 사용할 수 있는 Amazon Comprehend의 기능은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "감정 분석",
            "2": "주요 구문 추출",
            "3": "시계열 예측",
            "4": "이미지 분류",
            "5": "엔티티 인식"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "주요 구문 추출",
            "감정 분석"
        ],
        "Explanation": "주요 구문 추출과 감정 분석은 Amazon Comprehend의 핵심 기능으로, 사용자가 텍스트 데이터에서 의미 있는 통찰력을 도출할 수 있도록 합니다. 주요 구문 추출은 텍스트에서 중요한 구문을 식별하고, 감정 분석은 감정을 긍정적, 부정적, 중립적 또는 혼합으로 분류합니다.",
        "Other Options": [
            "이미지 분류는 Amazon Comprehend의 기능이 아니며, 일반적으로 Amazon Rekognition과 같은 컴퓨터 비전 서비스와 관련이 있습니다.",
            "시계열 예측은 텍스트 분석과 관련이 없으며 Amazon Comprehend의 기능이 아닙니다; 일반적으로 Amazon Forecast와 같은 다른 서비스에서 처리됩니다.",
            "엔티티 인식은 실제로 Amazon Comprehend의 기능이지만, 이 시나리오에서 선택된 두 가지 답변 중 하나는 아닙니다."
        ]
    },
    {
        "Question Number": "65",
        "Situation": "데이터 과학자는 Amazon SageMaker를 사용하여 이미지 분류 모델을 작업하고 있습니다. 모델의 정확도를 향상시키기 위해 여러 하이퍼파라미터를 조정해야 합니다. 데이터 과학자는 최상의 하이퍼파라미터 조합을 효율적으로 찾기 위해 자동 하이퍼파라미터 최적화를 사용하고자 합니다.",
        "Question": "데이터 과학자가 Amazon SageMaker에서 하이퍼파라미터 최적화를 수행하기 위해 어떤 접근 방식을 사용해야 합니까?",
        "Options": {
            "1": "여러 훈련 작업을 수동으로 실행하고, 한 번에 하나의 하이퍼파라미터를 변경하여 모델 성능에 미치는 영향을 관찰합니다.",
            "2": "모델 훈련 후 SageMaker Batch Transform을 사용하여 다양한 하이퍼파라미터 조합을 평가합니다.",
            "3": "SageMaker Python SDK를 사용하여 사용자 정의 최적화 알고리즘을 구현하고 훈련 작업 구성에서 하이퍼파라미터를 정의합니다.",
            "4": "하이퍼파라미터를 JSON 파일에 지정하고 내장된 튜닝 알고리즘을 사용하여 SageMaker 하이퍼파라미터 튜닝 작업을 활용합니다."
        },
        "Correct Answer": "하이퍼파라미터를 JSON 파일에 지정하고 내장된 튜닝 알고리즘을 사용하여 SageMaker 하이퍼파라미터 튜닝 작업을 활용합니다.",
        "Explanation": "SageMaker 하이퍼파라미터 튜닝 작업은 내장 알고리즘을 활용하여 최상의 하이퍼파라미터를 자동으로 검색하는 효율적인 방법을 제공합니다. 이 방법은 훈련 과정을 최적화하고 수동 개입 없이 모델 성능을 향상시킵니다.",
        "Other Options": [
            "사용자 정의 최적화 알고리즘을 구현하는 것은 SageMaker의 기능을 효율적으로 활용하는 방법이 아닙니다. 가능하지만, 이 목적을 위해 특별히 설계된 내장 하이퍼파라미터 튜닝 기능을 활용하지 않습니다.",
            "여러 훈련 작업을 수동으로 실행하는 것은 시간 소모적이고 비효율적입니다. 이 방법은 SageMaker의 하이퍼파라미터 튜닝이 제공하는 체계적인 접근 방식이 부족하여 조합을 지능적으로 최적화하지 않습니다.",
            "SageMaker Batch Transform을 사용하는 것은 하이퍼파라미터 최적화에 적용되지 않습니다. Batch Transform은 훈련된 모델에 대한 예측을 수행하기 위한 것이지, 훈련 단계에서 하이퍼파라미터를 조정하기 위한 것이 아닙니다."
        ]
    }
]