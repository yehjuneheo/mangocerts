[
    {
        "Question Number": "1",
        "Situation": "Una empresa está ejecutando una aplicación web en una flota de instancias de Amazon EC2 en un grupo de Auto Scaling. La aplicación experimenta patrones de tráfico variables a lo largo del día, con cargas máximas durante el horario laboral. La empresa necesita asegurarse de que la aplicación pueda escalar adecuadamente para manejar la carga aumentada mientras minimiza costos durante las horas de menor actividad. El arquitecto de soluciones necesita implementar una política de Auto Scaling que responda a los cambios en la demanda de manera efectiva.",
        "Question": "¿Qué política de Auto Scaling debería implementar el arquitecto de soluciones para optimizar el escalado de las instancias de EC2 según la carga de la aplicación mientras asegura la eficiencia de costos?",
        "Options": {
            "1": "Implementar una política de escalado de seguimiento de objetivos que ajuste el número de instancias según la métrica de utilización promedio de CPU.",
            "2": "Configurar una política de escalado programado que agregue instancias a una hora específica cada día sin tener en cuenta la demanda real.",
            "3": "Utilizar una política de escalado por pasos que aumente el número de instancias según umbrales específicos de métricas de tráfico de red.",
            "4": "Configurar una política de escalado simple que solo reduzca el número de instancias cuando la utilización de CPU cae por debajo de un nivel base."
        },
        "Correct Answer": "Implementar una política de escalado de seguimiento de objetivos que ajuste el número de instancias según la métrica de utilización promedio de CPU.",
        "Explanation": "Una política de escalado de seguimiento de objetivos ajusta automáticamente el número de instancias de EC2 para mantener un nivel especificado de utilización de CPU, lo que permite un escalado dinámico en respuesta a la carga real. Este enfoque optimiza el rendimiento mientras controla los costos al reducir el número de instancias durante los períodos de baja demanda.",
        "Other Options": [
            "Una política de escalado programado no tiene en cuenta las fluctuaciones de demanda real y puede llevar a una sobreaprovisionamiento o subaprovisionamiento de recursos, resultando en costos innecesarios o problemas de rendimiento.",
            "Si bien una política de escalado por pasos basada en el tráfico de red puede funcionar, puede no correlacionarse directamente con el rendimiento de la aplicación y puede llevar a retrasos en las acciones de escalado, especialmente si los patrones de tráfico son impredecibles.",
            "Una política de escalado simple que solo reduce el número de instancias según la utilización de CPU no permite un escalado proactivo durante la demanda máxima, lo que puede resultar en un rendimiento degradado y una mala experiencia para el usuario."
        ]
    },
    {
        "Question Number": "2",
        "Situation": "Una empresa minorista quiere mejorar su experiencia del cliente utilizando Amazon Rekognition para analizar las transmisiones de video de sus tiendas. El objetivo es identificar la demografía de los clientes, rastrear el tráfico peatonal y detectar cualquier contenido inapropiado en tiempo real. La empresa necesita asegurarse de que la solución sea eficiente y rentable.",
        "Question": "¿Cuál de los siguientes enfoques debería tomar la empresa para implementar el análisis de video en tiempo real utilizando Amazon Rekognition mientras se adhiere a las mejores prácticas?",
        "Options": {
            "1": "La empresa debería usar Amazon Rekognition Video para analizar segmentos de video almacenados en S3 y consultar periódicamente los resultados para evaluar la demografía de los clientes y el tráfico peatonal.",
            "2": "La empresa debería configurar un Amazon Kinesis Data Stream para ingerir transmisiones de video en tiempo real y activar Amazon Rekognition Video para analizar las transmisiones en busca de información y contenido inapropiado.",
            "3": "La empresa debería implementar una aplicación de procesamiento de video personalizada que use FFmpeg para analizar las transmisiones de video y extraer información antes de enviar los datos a Amazon Rekognition para validación.",
            "4": "La empresa debería ejecutar Amazon Rekognition en las instalaciones utilizando el dispositivo AWS Snowball Edge para analizar las transmisiones de video localmente, luego cargar los resultados a AWS para un procesamiento adicional."
        },
        "Correct Answer": "La empresa debería configurar un Amazon Kinesis Data Stream para ingerir transmisiones de video en tiempo real y activar Amazon Rekognition Video para analizar las transmisiones en busca de información y contenido inapropiado.",
        "Explanation": "Utilizar Amazon Kinesis Data Streams permite a la empresa procesar transmisiones de video en tiempo real de manera eficiente. Al integrar Kinesis con Amazon Rekognition Video, la empresa puede analizar el contenido de video inmediatamente a medida que se ingiere, proporcionando información oportuna y asegurando la detección de contenido inapropiado en tiempo real.",
        "Other Options": [
            "Analizar segmentos de video almacenados en S3 no proporciona información en tiempo real, ya que habría un retraso entre la grabación y el análisis, lo que lo hace inadecuado para mejoras inmediatas en la experiencia del cliente.",
            "Usar una solución en las instalaciones con AWS Snowball Edge puede no aprovechar todas las capacidades de Amazon Rekognition, y también complica la arquitectura al introducir pasos adicionales para el procesamiento y la carga de resultados.",
            "Implementar una aplicación de procesamiento de video personalizada podría llevar a una mayor complejidad y carga de mantenimiento, además de no utilizar las capacidades especializadas de Amazon Rekognition, que está diseñado específicamente para el análisis de imágenes y videos."
        ]
    },
    {
        "Question Number": "3",
        "Situation": "Una empresa de transmisión de medios está utilizando Amazon CloudFront para entregar contenido almacenado en Amazon S3. Han estado usando Origin Access Identity (OAI) para asegurar su bucket de S3, pero enfrentan desafíos con las configuraciones de políticas y métodos HTTP. Para mejorar su seguridad y expandir la funcionalidad, deciden explorar Origin Access Control (OAC) para sus distribuciones de CloudFront. El arquitecto de soluciones necesita determinar las principales ventajas de la transición a OAC sobre OAI para su caso de uso.",
        "Question": "¿Cuál de los siguientes describe un beneficio principal de usar Origin Access Control (OAC) sobre Origin Access Identity (OAI) en Amazon CloudFront?",
        "Options": {
            "1": "OAI proporciona mejores prácticas de seguridad con credenciales a corto plazo y rotaciones frecuentes de credenciales en comparación con OAC.",
            "2": "OAC restringe el acceso a los orígenes de S3 permitiendo que solo las distribuciones designadas de CloudFront accedan al contenido.",
            "3": "OAC solo admite objetos de S3 que no están encriptados, asegurando compatibilidad con todas las regiones de AWS.",
            "4": "OAC permite configuraciones de políticas granulares y admite todos los métodos HTTP, incluidos PUT y DELETE."
        },
        "Correct Answer": "OAC restringe el acceso a los orígenes de S3 permitiendo que solo las distribuciones designadas de CloudFront accedan al contenido.",
        "Explanation": "Origin Access Control (OAC) mejora la seguridad al permitir el acceso a los orígenes de S3 exclusivamente para distribuciones específicas de CloudFront, limitando así la exposición y mejorando el modelo de seguridad en comparación con OAI.",
        "Other Options": [
            "Si bien OAC permite el soporte de todos los métodos HTTP, incluidos PUT y DELETE, no proporciona específicamente configuraciones de políticas granulares, lo que hace que esta afirmación sea engañosa.",
            "OAC admite objetos de S3 que están encriptados y permite el acceso a todas las regiones de AWS, por lo que esta opción es incorrecta ya que tergiversa las capacidades de OAC.",
            "OAC está diseñado para incorporar mejores prácticas de seguridad que OAI, incluidas las credenciales a corto plazo, por lo que esta opción afirma incorrectamente lo contrario."
        ]
    },
    {
        "Question Number": "4",
        "Situation": "Una aplicación de salud desplegada en la nube de AWS necesita asegurar que los datos sensibles de los pacientes estén seguros mientras permite que los usuarios autorizados accedan al sistema. La aplicación utiliza una Nube Privada Virtual (VPC) con múltiples subredes en diferentes Zonas de Disponibilidad. Como Arquitecto de Soluciones, se te ha encomendado la tarea de configurar la red para cumplir con los requisitos de cumplimiento y seguridad de manera efectiva.",
        "Question": "¿Qué configuraciones de red deberías implementar para asegurar el acceso seguro a la aplicación mientras proteges los datos sensibles? (Selecciona Dos)",
        "Options": {
            "1": "Configura un grupo de seguridad para permitir tráfico entrante solo desde direcciones IP específicas utilizadas por usuarios autorizados.",
            "2": "Crea una tabla de rutas que solo permita tráfico desde las subredes privadas a las subredes públicas.",
            "3": "Usa un ACL de red para permitir tráfico entrante desde rangos CIDR específicos a las subredes de la aplicación.",
            "4": "Implementa un ACL de red que niegue todo el tráfico entrante, bloqueando así todo acceso.",
            "5": "Configura grupos de seguridad que permitan tráfico a la aplicación desde todas las direcciones IP en el puerto 80."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Configura un grupo de seguridad para permitir tráfico entrante solo desde direcciones IP específicas utilizadas por usuarios autorizados.",
            "Usa un ACL de red para permitir tráfico entrante desde rangos CIDR específicos a las subredes de la aplicación."
        ],
        "Explanation": "Usar un grupo de seguridad para permitir tráfico entrante solo desde direcciones IP específicas asegura que solo los usuarios autorizados puedan acceder a la aplicación de salud, mejorando así la seguridad. Además, implementar un ACL de red para permitir tráfico desde rangos CIDR específicos proporciona una capa adicional de seguridad a nivel de subred, permitiendo que solo fuentes confiables accedan a los recursos.",
        "Other Options": [
            "Crear una tabla de rutas que solo permita tráfico desde subredes privadas a subredes públicas no proporciona ninguna seguridad para los datos sensibles, ya que no controla quién puede acceder a la aplicación.",
            "Implementar un ACL de red que niegue todo el tráfico entrante bloquearía todo acceso, incluyendo el de usuarios autorizados, haciendo que la aplicación sea inaccesible.",
            "Configurar grupos de seguridad que permitan tráfico desde todas las direcciones IP en el puerto 80 expondría la aplicación a ataques potenciales, ya que permitiría acceso sin restricciones a cualquier persona en internet."
        ]
    },
    {
        "Question Number": "5",
        "Situation": "Una empresa de tecnología de salud está desarrollando una aplicación móvil que permite a los usuarios rastrear sus actividades físicas y métricas de salud. La aplicación requiere actualizaciones en tiempo real sobre los datos del usuario y debe proporcionar capacidades fuera de línea para asegurar una experiencia fluida. El equipo de desarrollo está considerando usar AWS AppSync para facilitar la gestión de datos de diversas fuentes, incluyendo una base de datos NoSQL para perfiles de usuario y funciones de AWS Lambda para el procesamiento de datos personalizado. Quieren asegurarse de que cuando los usuarios estén fuera de línea, sus datos sigan siendo accesibles, y cualquier cambio realizado mientras están fuera de línea se sincronice una vez que se reconecten. El equipo también está preocupado por manejar conflictos que puedan surgir durante la sincronización de datos.",
        "Question": "¿Cuál es la forma más efectiva de implementar AWS AppSync para cumplir con los requisitos de la aplicación para acceso a datos en tiempo real, capacidades fuera de línea y resolución de conflictos?",
        "Options": {
            "1": "Integra AWS AppSync con una base de datos Amazon RDS e implementa una API personalizada para manejar actualizaciones en tiempo real, acceso fuera de línea y resolución de conflictos manualmente.",
            "2": "Configura AWS AppSync con un modelo de suscripción para proporcionar actualizaciones en tiempo real y habilitar la resolución de conflictos utilizando los mecanismos integrados de AppSync mientras aseguras el acceso local a los datos para uso fuera de línea.",
            "3": "Usa AWS AppSync con un mecanismo de sondeo para obtener actualizaciones a intervalos regulares e implementa una solución personalizada para almacenamiento y sincronización fuera de línea sin resolución de conflictos integrada.",
            "4": "Despliega AWS AppSync junto con Amazon S3 para almacenar todos los datos de los usuarios y depender de Amazon CloudFront para entregar datos a los usuarios, lo que no soporta actualizaciones en tiempo real ni acceso fuera de línea."
        },
        "Correct Answer": "Configura AWS AppSync con un modelo de suscripción para proporcionar actualizaciones en tiempo real y habilitar la resolución de conflictos utilizando los mecanismos integrados de AppSync mientras aseguras el acceso local a los datos para uso fuera de línea.",
        "Explanation": "Usar AWS AppSync con un modelo de suscripción permite que las actualizaciones en tiempo real se envíen a los clientes, asegurando que los usuarios siempre tengan acceso a los datos más recientes. Además, el soporte integrado de AppSync para capacidades fuera de línea y resolución de conflictos simplifica la implementación, permitiendo que la aplicación maneje cambios en los datos sin problemas cuando se restaura la conectividad.",
        "Other Options": [
            "Usar un mecanismo de sondeo no proporcionaría actualizaciones en tiempo real, que es un requisito crítico para la aplicación. Además, las soluciones personalizadas para almacenamiento y sincronización fuera de línea pueden ser complejas y propensas a errores en comparación con aprovechar las características integradas de AppSync.",
            "Desplegar AWS AppSync únicamente con Amazon S3 no se alinea con la necesidad de actualizaciones en tiempo real, ya que S3 no está diseñado para interacciones de datos dinámicas. Además, CloudFront sirve principalmente contenido estático y no facilita la comunicación en tiempo real.",
            "Integrar AWS AppSync con una base de datos Amazon RDS mientras se manejan manualmente las actualizaciones y la resolución de conflictos añade complejidad innecesaria y podría llevar a problemas potenciales. Este enfoque no aprovecha las capacidades completas de AppSync, que está diseñado para simplificar estas tareas."
        ]
    },
    {
        "Question Number": "6",
        "Situation": "Una empresa de servicios financieros opera una aplicación crítica que procesa transacciones en tiempo real. Para asegurar alta disponibilidad y minimizar el tiempo de inactividad, la empresa implementa monitoreo centralizado utilizando AWS CloudWatch y AWS CloudTrail. La aplicación está diseñada para recuperarse automáticamente de fallos utilizando servicios de AWS. (Selecciona Dos)",
        "Question": "¿Cuál de las siguientes estrategias debería implementar la empresa para recuperarse proactivamente de fallos del sistema?",
        "Options": {
            "1": "Implementar reglas de AWS Config para monitorear el cumplimiento y activar la remediación.",
            "2": "Configurar eventos de CloudWatch para detectar cambios en el estado del sistema e invocar procesos de recuperación.",
            "3": "Habilitar alarmas de CloudWatch para activar funciones de Lambda para acciones de auto-reparación.",
            "4": "Integrar registros de CloudWatch con Amazon SNS para enviar notificaciones por errores críticos.",
            "5": "Usar AWS CloudTrail para registrar todas las llamadas a la API solo con fines de auditoría."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Habilitar alarmas de CloudWatch para activar funciones de Lambda para acciones de auto-reparación.",
            "Configurar eventos de CloudWatch para detectar cambios en el estado del sistema e invocar procesos de recuperación."
        ],
        "Explanation": "Habilitar alarmas de CloudWatch para activar funciones de Lambda permite acciones de auto-reparación automatizadas cuando se superan umbrales específicos, asegurando una recuperación proactiva. Configurar eventos de CloudWatch para detectar cambios en el estado del sistema también puede invocar procesos de recuperación, permitiendo que el sistema reaccione a fallos a medida que ocurren.",
        "Other Options": [
            "Usar AWS CloudTrail solo para auditoría no contribuye a la recuperación proactiva, ya que se centra principalmente en registrar llamadas a la API y no activa ninguna acción.",
            "Integrar registros de CloudWatch con Amazon SNS para notificaciones es útil para alertar, pero no contribuye directamente a procesos de recuperación automatizados.",
            "Implementar reglas de AWS Config ayuda a mantener el cumplimiento, pero no activa automáticamente acciones de recuperación en respuesta a fallos."
        ]
    },
    {
        "Question Number": "7",
        "Situation": "Una empresa de servicios financieros está experimentando problemas de rendimiento con su solución de base de datos actual, que se utiliza principalmente para el procesamiento transaccional. Están buscando mejorar el rendimiento de su aplicación mientras aseguran el cumplimiento de los estándares de la industria. La empresa tiene patrones de acceso a datos diversos, incluyendo análisis en tiempo real, procesamiento de transacciones y almacenamiento de documentos. Quieren identificar oportunidades para aprovechar bases de datos diseñadas específicamente para sus cargas de trabajo.",
        "Question": "¿Cuál de las siguientes estrategias debería implementar la empresa para optimizar su arquitectura de base de datos para las cargas de trabajo específicas mencionadas?",
        "Options": {
            "1": "Desplegar un único clúster de Amazon ElastiCache para manejar todos los patrones de acceso a datos y mejorar el rendimiento.",
            "2": "Utilizar Amazon Aurora para el procesamiento transaccional, Amazon DynamoDB para análisis en tiempo real y Amazon DocumentDB para almacenamiento de documentos.",
            "3": "Migrar todos los datos existentes a una única instancia de Amazon RDS para simplificar la gestión y el mantenimiento.",
            "4": "Implementar Amazon S3 con Athena para todas las necesidades de almacenamiento y consulta de datos para reducir costos."
        },
        "Correct Answer": "Utilizar Amazon Aurora para el procesamiento transaccional, Amazon DynamoDB para análisis en tiempo real y Amazon DocumentDB para almacenamiento de documentos.",
        "Explanation": "Este enfoque aprovecha bases de datos diseñadas específicamente para los casos de uso, asegurando un rendimiento y escalabilidad óptimos. Amazon Aurora proporciona un alto rendimiento para cargas de trabajo transaccionales, DynamoDB ofrece acceso de baja latencia para análisis en tiempo real, y DocumentDB está diseñado para gestionar datos basados en documentos, cumpliendo así con los diversos requisitos de la empresa de manera eficiente.",
        "Other Options": [
            "Migrar todos los datos a una única instancia de Amazon RDS puede simplificar la gestión, pero puede llevar a cuellos de botella de rendimiento ya que no se adapta a los diferentes patrones de acceso y requisitos de las cargas de trabajo.",
            "Desplegar un único clúster de Amazon ElastiCache no es adecuado ya que se utiliza principalmente para almacenamiento en caché y no proporciona un almacenamiento de datos persistente requerido para el procesamiento transaccional y el almacenamiento de documentos.",
            "Implementar Amazon S3 con Athena no es óptimo para cargas de trabajo transaccionales, ya que S3 es un servicio de almacenamiento y Athena es un servicio de consulta. Esta combinación carece de las capacidades transaccionales necesarias y el rendimiento requerido para los casos de uso específicos de la empresa."
        ]
    },
    {
        "Question Number": "8",
        "Situation": "Una organización de salud necesita asegurar la disponibilidad continua de su aplicación de gestión de pacientes alojada en AWS. La aplicación es crítica para las operaciones diarias y debe seguir funcionando durante cortes o interrupciones regionales. La organización busca diseñar una arquitectura que proporcione alta disponibilidad y tolerancia a fallos.",
        "Question": "¿Cuál de las siguientes estrategias de diseño ayudaría a lograr la disponibilidad de la aplicación e infraestructura durante una interrupción? (Seleccione Dos)",
        "Options": {
            "1": "Aprovechar Amazon RDS con un despliegue Multi-AZ para la capa de base de datos para mejorar la disponibilidad.",
            "2": "Desplegar la aplicación en múltiples regiones de AWS con Route 53 para la conmutación por error de DNS.",
            "3": "Implementar un único Elastic Load Balancer (ELB) en una única Zona de Disponibilidad para gestionar el tráfico.",
            "4": "Utilizar funciones de AWS Lambda con un bucket de S3 para almacenar datos de la aplicación y gestionar el almacenamiento.",
            "5": "Usar instancias de Amazon EC2 en un grupo de Auto Scaling en múltiples Zonas de Disponibilidad dentro de una única región."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Desplegar la aplicación en múltiples regiones de AWS con Route 53 para la conmutación por error de DNS.",
            "Aprovechar Amazon RDS con un despliegue Multi-AZ para la capa de base de datos para mejorar la disponibilidad."
        ],
        "Explanation": "Desplegar la aplicación en múltiples regiones de AWS con Route 53 para la conmutación por error de DNS permite la redundancia geográfica, asegurando que si una región falla, el tráfico puede ser redirigido automáticamente a otra región. Además, utilizar Amazon RDS con un despliegue Multi-AZ proporciona conmutación por error automática a una instancia de reserva en otra Zona de Disponibilidad, mejorando la disponibilidad de la base de datos y su resistencia a fallos de infraestructura.",
        "Other Options": [
            "Usar instancias de EC2 en un grupo de Auto Scaling en múltiples Zonas de Disponibilidad dentro de una única región proporciona cierto nivel de disponibilidad, pero no protege contra interrupciones regionales. Una falla en toda la región aún podría llevar a tiempo de inactividad de la aplicación.",
            "Implementar un único Elastic Load Balancer en una única Zona de Disponibilidad limita la redundancia. Si esa Zona de Disponibilidad experimenta una interrupción, la aplicación se volverá no disponible, contradiciendo los objetivos de alta disponibilidad y tolerancia a fallos.",
            "Utilizar funciones de AWS Lambda con un bucket de S3 para la gestión de datos de la aplicación no aborda la disponibilidad de la aplicación de manera integral. Si bien este enfoque puede ser parte de una solución, no mejora específicamente la disponibilidad de la aplicación misma durante interrupciones."
        ]
    },
    {
        "Question Number": "9",
        "Situation": "Una startup está desarrollando una aplicación basada en microservicios que se ejecutará en contenedores. El equipo de desarrollo está buscando una solución que les permita desplegar, gestionar y escalar sus aplicaciones en contenedores con un mínimo de sobrecarga operativa. Quieren centrarse en desarrollar su aplicación sin preocuparse por la infraestructura subyacente.",
        "Question": "¿Cuál de las siguientes opciones es la mejor elección para gestionar las necesidades de orquestación de contenedores de la startup?",
        "Options": {
            "1": "Utilizar Amazon EKS con instancias spot para ahorrar costos mientras ejecutan un servicio de Kubernetes gestionado.",
            "2": "Configurar un clúster de Docker Swarm autogestionado en instancias de EC2 para orquestar los contenedores.",
            "3": "Desplegar Kubernetes en instancias de Amazon EC2 y gestionar el clúster manualmente para la orquestación de contenedores.",
            "4": "Usar Amazon ECS con Fargate para ejecutar contenedores sin gestionar las instancias de EC2 subyacentes."
        },
        "Correct Answer": "Usar Amazon ECS con Fargate para ejecutar contenedores sin gestionar las instancias de EC2 subyacentes.",
        "Explanation": "Amazon ECS con Fargate permite a la startup ejecutar contenedores sin tener que gestionar la infraestructura subyacente. Este enfoque sin servidor proporciona al equipo la flexibilidad para centrarse en el desarrollo de su aplicación mientras AWS maneja la escalabilidad y gestión del entorno de contenedores.",
        "Other Options": [
            "Desplegar Kubernetes en instancias de Amazon EC2 requiere una sobrecarga operativa significativa para gestionar el clúster, incluyendo actualizaciones, escalado y configuración, lo que contradice el requisito de la startup de minimizar la gestión operativa.",
            "Usar Amazon EKS con instancias spot puede ahorrar costos, pero aún requiere que el equipo gestione la configuración y configuración de Kubernetes, lo que añade complejidad innecesaria dado su deseo de minimizar la sobrecarga operativa.",
            "Configurar un clúster de Docker Swarm autogestionado en instancias de EC2 implica considerables responsabilidades de gestión y mantenimiento, lo que va en contra del objetivo de la startup de centrarse en el desarrollo de la aplicación sin la carga de la gestión de infraestructura."
        ]
    },
    {
        "Question Number": "10",
        "Situation": "Un equipo de desarrollo de software está trabajando en una aplicación de microservicios alojada en AWS. El equipo utiliza AWS CodeCommit para gestionar su código fuente y AWS CodeBuild para automatizar el proceso de construcción y pruebas. La aplicación requiere acceso a una base de datos alojada dentro de una Nube Privada Virtual (VPC), y el proyecto de CodeBuild necesita ser configurado para este acceso. El equipo ha identificado el ID de la VPC, los IDs de subred y los IDs de grupos de seguridad necesarios para la configuración del proyecto de CodeBuild. Sin embargo, no están seguros sobre las opciones de configuración necesarias para permitir que CodeBuild acceda a los recursos de la VPC con éxito.",
        "Question": "¿Qué debe hacer el equipo para asegurarse de que AWS CodeBuild pueda acceder a los recursos en la VPC especificada?",
        "Options": {
            "1": "Agregar una variable de entorno en el proyecto de CodeBuild para especificar la configuración de la VPC.",
            "2": "Configurar el proyecto de CodeBuild para usar el ID de la VPC, los IDs de subred y los IDs de grupos de seguridad en la configuración del entorno de construcción.",
            "3": "Crear un nuevo rol de IAM para CodeBuild que otorgue acceso a los recursos de la VPC y adjuntarlo al proyecto de CodeBuild.",
            "4": "Asegurarse de que el proyecto de CodeBuild se ejecute en la misma región que los recursos de la VPC para permitir el acceso."
        },
        "Correct Answer": "Configurar el proyecto de CodeBuild para usar el ID de la VPC, los IDs de subred y los IDs de grupos de seguridad en la configuración del entorno de construcción.",
        "Explanation": "Para habilitar que AWS CodeBuild acceda a recursos dentro de una VPC, debes proporcionar el ID de la VPC, los IDs de subred y los IDs de grupos de seguridad en la configuración del proyecto de CodeBuild. Esta configuración permite a CodeBuild establecer un entorno de construcción habilitado para VPC, que puede interactuar con recursos dentro de la VPC.",
        "Other Options": [
            "Crear un nuevo rol de IAM no es necesario porque CodeBuild requiere configuraciones específicas de VPC en lugar de solo un rol de IAM para acceder a los recursos de la VPC.",
            "Si bien ejecutar en la misma región que la VPC es un requisito, no garantiza el acceso; aún deben configurarse configuraciones específicas de VPC en el proyecto de CodeBuild.",
            "Las variables de entorno no configuran el acceso a la VPC; los ajustes de la VPC deben definirse explícitamente en la configuración del entorno de construcción."
        ]
    },
    {
        "Question Number": "11",
        "Situation": "Una empresa de servicios financieros está planeando migrar su aplicación de gestión de relaciones con clientes (CRM) heredada a AWS. La aplicación es crítica para las interacciones en tiempo real con los clientes y debe mantener alta disponibilidad y rendimiento durante el proceso de migración. La empresa quiere asegurar un tiempo de inactividad mínimo y una transición fluida para sus usuarios. Para mejorar las capacidades de la aplicación después de la migración, también consideran modernizar la aplicación utilizando una arquitectura de microservicios. ¿Cuál de los siguientes enfoques se debe tomar para acelerar la migración de la carga de trabajo y la modernización, asegurando al mismo tiempo rendimiento y disponibilidad?",
        "Question": "¿Qué estrategia de migración debería adoptar la empresa para asegurar una transición exitosa de su aplicación CRM a AWS con mínima interrupción y con miras a la modernización futura?",
        "Options": {
            "1": "Levantar y trasladar toda la aplicación a instancias de EC2 en una VPC dedicada mientras se mantiene la arquitectura existente. Usar Amazon Route 53 para la gestión de DNS y el enrutamiento del tráfico.",
            "2": "Reestructurar la aplicación a computación sin servidor utilizando AWS Lambda y Amazon API Gateway para reducir la sobrecarga operativa y mejorar la escalabilidad después de la migración.",
            "3": "Utilizar AWS Database Migration Service para replicar la base de datos CRM a una instancia de Amazon RDS. Migrar la aplicación en fases utilizando funciones de AWS Lambda para manejar microservicios específicos.",
            "4": "Refactorizar la aplicación en microservicios antes de migrar a AWS, desplegando cada microservicio como un contenedor en Amazon ECS. Usar AWS App Mesh para el descubrimiento y la comunicación de servicios."
        },
        "Correct Answer": "Refactorizar la aplicación en microservicios antes de migrar a AWS, desplegando cada microservicio como un contenedor en Amazon ECS. Usar AWS App Mesh para el descubrimiento y la comunicación de servicios.",
        "Explanation": "Refactorizar la aplicación en microservicios antes de migrar permite a la empresa aprovechar al máximo las características de AWS y mejorar la escalabilidad y el rendimiento después de la migración. Desplegar cada microservicio como un contenedor en Amazon ECS facilita una mejor gestión de recursos y flexibilidad en el despliegue, mientras que AWS App Mesh simplifica el descubrimiento de servicios y la comunicación entre microservicios.",
        "Other Options": [
            "Utilizar AWS Database Migration Service es útil para transiciones de bases de datos, pero migrar toda la aplicación en fases puede no abordar efectivamente la necesidad de modernización y podría llevar a un tiempo de inactividad prolongado.",
            "Un enfoque de levantar y trasladar no aprovecha las capacidades de AWS para la modernización y podría resultar en costos operativos más altos y escalabilidad limitada, lo cual no está alineado con los objetivos futuros de la empresa.",
            "Reestructurar la aplicación a computación sin servidor utilizando AWS Lambda y API Gateway es un enfoque válido, pero puede introducir complejidad y podría requerir cambios significativos en la arquitectura existente de la aplicación antes de la migración."
        ]
    },
    {
        "Question Number": "12",
        "Situation": "Una empresa de servicios financieros está procesando datos de transacciones en vivo para detectar actividades fraudulentas en tiempo real. Están utilizando Amazon Kinesis Data Streams (KDS) para recopilar y analizar estos datos. Sin embargo, han notado que durante los períodos de transacciones pico, algunos registros están siendo limitados debido a las restricciones de fragmentos. La gerencia quiere mejorar el rendimiento de su configuración de KDS para manejar la carga de datos aumentada sin perder ningún registro.",
        "Question": "¿Cuál de las siguientes opciones es la solución más efectiva para aumentar la capacidad de ingestión de datos para el Kinesis Data Stream mientras se asegura una alta disponibilidad?",
        "Options": {
            "1": "Implementar la Kinesis Producer Library (KPL) para agrupar los registros antes de enviarlos al Kinesis Data Stream, maximizando así la utilización de los fragmentos existentes.",
            "2": "Aumentar el número de fragmentos en el Kinesis Data Stream existente para acomodar un mayor rendimiento de escritura y prevenir la limitación durante los períodos pico.",
            "3": "Utilizar Amazon S3 para almacenar temporalmente los datos de transacciones y configurar una función de AWS Lambda para cargar periódicamente los datos en el Kinesis Data Stream para manejar cargas pico.",
            "4": "Crear un nuevo Kinesis Data Stream y configurar la aplicación para dividir los datos de transacciones equitativamente entre los flujos original y nuevo para equilibrar la carga."
        },
        "Correct Answer": "Aumentar el número de fragmentos en el Kinesis Data Stream existente para acomodar un mayor rendimiento de escritura y prevenir la limitación durante los períodos pico.",
        "Explanation": "Aumentar el número de fragmentos en el Kinesis Data Stream mejora directamente la capacidad de ingestión de datos. Cada fragmento puede manejar una cantidad específica de datos, por lo que agregar más fragmentos permite que el flujo gestione volúmenes más grandes de datos entrantes, reduciendo así el riesgo de limitación y pérdida de datos durante los períodos pico.",
        "Other Options": [
            "Implementar la Kinesis Producer Library (KPL) es beneficioso para agrupar registros, pero no aumenta inherentemente el rendimiento máximo del flujo en sí. Si el flujo ya está siendo limitado debido a restricciones de fragmentos, solo agrupar no resolverá el problema.",
            "Utilizar Amazon S3 para almacenamiento temporal introduce latencia adicional y complejidad al flujo de trabajo. Puede no abordar la necesidad inmediata de aumentar la capacidad de ingestión, ya que requiere procesamiento adicional para mover datos de S3 a Kinesis.",
            "Crear un nuevo Kinesis Data Stream y equilibrar la carga podría funcionar, pero este enfoque agrega complejidad en la gestión de múltiples flujos y no resuelve el problema de limitación existente en el flujo original."
        ]
    },
    {
        "Question Number": "13",
        "Situation": "Una empresa está experimentando problemas de latencia con su aplicación web que depende en gran medida de una base de datos backend. La aplicación atiende a un gran número de usuarios simultáneamente, y el acceso directo a la base de datos está ralentizando el rendimiento. El arquitecto de soluciones tiene la tarea de mejorar el rendimiento mientras asegura la consistencia de los datos.",
        "Question": "¿Qué patrón de diseño debería implementar el arquitecto de soluciones para mejorar el rendimiento a través de la caché y reducir la carga en la base de datos?",
        "Options": {
            "1": "Desplegar réplicas de lectura de la base de datos para manejar el aumento del tráfico de lectura.",
            "2": "Incorporar Amazon SQS para encolar solicitudes a la base de datos.",
            "3": "Implementar una capa de caché utilizando Amazon ElastiCache para datos de acceso frecuente.",
            "4": "Usar AWS Lambda para procesar solicitudes de manera sin servidor."
        },
        "Correct Answer": "Implementar una capa de caché utilizando Amazon ElastiCache para datos de acceso frecuente.",
        "Explanation": "Implementar una capa de caché utilizando Amazon ElastiCache permite almacenar datos de acceso frecuente en memoria, reduciendo significativamente la latencia experimentada por los usuarios y disminuyendo la carga en la base de datos. Este patrón es efectivo para mejorar el rendimiento de la aplicación.",
        "Other Options": [
            "Desplegar réplicas de lectura de la base de datos puede ayudar a distribuir el tráfico de lectura, pero no aborda la latencia causada por la alta carga en la base de datos principal. Es más una solución de escalado que una estrategia de caché.",
            "Usar AWS Lambda para procesar solicitudes puede mejorar la escalabilidad, pero no aborda específicamente los problemas de rendimiento directo asociados con el acceso a la base de datos. Las funciones de Lambda aún requieren acceso a la base de datos, lo que podría seguir siendo un cuello de botella.",
            "Incorporar Amazon SQS puede ayudar a gestionar el flujo de solicitudes y mejorar la confiabilidad, pero no mejora directamente el rendimiento a través de la caché. Es más adecuado para desacoplar componentes que para reducir la latencia de las consultas a la base de datos."
        ]
    },
    {
        "Question Number": "14",
        "Situation": "Una empresa de medios está migrando su servicio de transmisión de video a AWS. El servicio experimenta patrones de tráfico fluctuantes, lo que lleva a costos de transferencia de datos impredecibles. El arquitecto de soluciones necesita diseñar una forma rentable de transferir datos desde el almacenamiento local a AWS mientras minimiza las tarifas de salida.",
        "Question": "¿Cuál de las siguientes estrategias debería implementar el arquitecto de soluciones para optimizar los costos de transferencia de datos para el servicio de transmisión de video?",
        "Options": {
            "1": "Usar Amazon S3 Transfer Acceleration para cargar videos rápidamente a S3 y reducir la latencia mientras incurre en costos adicionales de transferencia.",
            "2": "Implementar AWS Snowball para transferir grandes volúmenes de datos de video a AWS, beneficiándose de costos de envío reducidos y sin tarifas de salida durante la transferencia inicial de datos.",
            "3": "Utilizar Amazon CloudFront para almacenar en caché el contenido de video más cerca de los usuarios y reducir los costos de transferencia de datos minimizando las solicitudes de origen desde S3.",
            "4": "Aprovechar AWS Direct Connect para establecer una conexión de red dedicada, reduciendo así los costos de transferencia de datos para archivos de video grandes."
        },
        "Correct Answer": "Implementar AWS Snowball para transferir grandes volúmenes de datos de video a AWS, beneficiándose de costos de envío reducidos y sin tarifas de salida durante la transferencia inicial de datos.",
        "Explanation": "AWS Snowball está diseñado para transferir grandes cantidades de datos a AWS de manera eficiente. Elimina los cargos de salida durante el proceso de transferencia inicial, lo que lo convierte en una solución rentable para las necesidades de la empresa de medios.",
        "Other Options": [
            "Amazon S3 Transfer Acceleration aumenta la velocidad de transferencia pero incurre en costos adicionales por el uso del servicio, lo que puede no ser ideal para la optimización de costos.",
            "Si bien AWS Direct Connect proporciona una conexión confiable y de baja latencia a AWS, es más beneficioso para la transferencia de datos continua que para transferencias iniciales masivas y puede no reducir significativamente los costos para tráfico esporádico.",
            "Amazon CloudFront mejora la entrega de contenido pero no aborda la transferencia inicial de archivos de video grandes a AWS, y aún podría incurrir en tarifas de salida desde S3."
        ]
    },
    {
        "Question Number": "15",
        "Situation": "Una empresa de comercio electrónico global ha desplegado su aplicación en múltiples regiones de AWS para asegurar alta disponibilidad y baja latencia para sus clientes. La arquitectura de la aplicación utiliza Amazon RDS para sus necesidades de base de datos, con instancias ubicadas en cada región. Sin embargo, durante un incidente reciente, la empresa experimentó una interrupción regional que causó una disrupción en el servicio. Para mejorar la resiliencia y minimizar el tiempo de inactividad, se le ha encomendado al arquitecto de soluciones diseñar una arquitectura más robusta que aproveche los despliegues Multi-AZ y multi-región.",
        "Question": "¿Cuál de las siguientes soluciones mejora mejor la disponibilidad y resiliencia de la aplicación mientras minimiza el tiempo de inactividad durante interrupciones regionales?",
        "Options": {
            "1": "Desplegar instancias de Amazon RDS en configuración Multi-AZ dentro de cada región y habilitar réplicas de lectura entre regiones para atender el tráfico de lectura.",
            "2": "Desplegar instancias de Amazon RDS en una sola región con configuración Multi-AZ y usar Amazon ElastiCache para caché y reducir la carga de la base de datos.",
            "3": "Desplegar instancias de Amazon RDS en configuración Multi-AZ en todas las regiones y usar DynamoDB Global Tables para la sincronización de datos entre regiones.",
            "4": "Desplegar instancias de Amazon RDS en una sola región con configuración Multi-AZ solamente, e implementar políticas de enrutamiento de conmutación por error de Route 53 para dirigir el tráfico a una región de respaldo."
        },
        "Correct Answer": "Desplegar instancias de Amazon RDS en configuración Multi-AZ dentro de cada región y habilitar réplicas de lectura entre regiones para atender el tráfico de lectura.",
        "Explanation": "Esta opción proporciona tanto alta disponibilidad como la capacidad de atender el tráfico de lectura desde otra región durante una interrupción, mejorando así la resiliencia y minimizando efectivamente el tiempo de inactividad.",
        "Other Options": [
            "Esta opción solo proporciona alta disponibilidad dentro de una sola región. Carece de la replicación entre regiones necesaria, que es crucial para minimizar el tiempo de inactividad durante una falla regional.",
            "Esta opción no aprovecha completamente las configuraciones Multi-AZ entre regiones, y aunque utiliza Route 53 para la conmutación por error, podría resultar en inconsistencia de datos debido a la falta de replicación en tiempo real entre regiones.",
            "Si bien usar Multi-AZ entre regiones mejora la disponibilidad, depender únicamente de DynamoDB Global Tables para la sincronización puede introducir complejidad y posibles problemas de latencia que pueden afectar el rendimiento de la aplicación."
        ]
    },
    {
        "Question Number": "16",
        "Situation": "Una empresa está planeando implementar una aplicación global que requiere acceso de baja latencia para usuarios de todo el mundo. La aplicación consiste en múltiples microservicios que deben ser desplegados en múltiples Regiones de AWS, asegurando la consistencia de los datos y alta disponibilidad. La empresa quiere utilizar un servicio de AWS que proporcione una capa de caché global para mejorar el rendimiento y reducir la latencia para los usuarios finales. ¿Cuál de las siguientes soluciones es la MÁS adecuada para este requisito?",
        "Question": "¿Qué servicio de AWS debería utilizar la empresa para proporcionar una capa de caché global para su aplicación?",
        "Options": {
            "1": "Amazon CloudFront con conmutación por error de origen a un bucket de S3 en cada región que aloje los activos de la aplicación.",
            "2": "Amazon CloudFront con Lambda@Edge para personalizar la entrega de contenido y reducir la latencia a nivel global.",
            "3": "Amazon ElastiCache con grupos de replicación para mantener la consistencia de la caché a través de diferentes Regiones de AWS.",
            "4": "AWS Global Accelerator para enrutar el tráfico al punto de aplicación más cercano mientras se utiliza Amazon Route 53 para la gestión de DNS."
        },
        "Correct Answer": "Amazon CloudFront con Lambda@Edge para personalizar la entrega de contenido y reducir la latencia a nivel global.",
        "Explanation": "Amazon CloudFront es una red de entrega de contenido (CDN) que almacena contenido en ubicaciones de borde alrededor del mundo, proporcionando acceso de baja latencia a los usuarios. Lambda@Edge permite la personalización de la entrega de contenido, lo que permite que la aplicación ajuste dinámicamente el contenido según las solicitudes de los usuarios, optimizando aún más el rendimiento.",
        "Other Options": [
            "Amazon CloudFront con conmutación por error de origen a un bucket de S3 no proporciona una capa de caché para contenido dinámico y no está optimizado para microservicios que requieren baja latencia.",
            "Amazon ElastiCache está diseñado para la caché dentro de una sola región y no soporta la caché global de forma predeterminada, lo cual es crucial para una aplicación global.",
            "AWS Global Accelerator mejora la disponibilidad y el rendimiento de la aplicación al enrutar el tráfico al punto más cercano, pero no proporciona capacidades de caché, que son necesarias para reducir la latencia."
        ]
    },
    {
        "Question Number": "17",
        "Situation": "Una empresa de servicios financieros está planeando migrar su aplicación local a AWS. La aplicación es crítica y requiere alta disponibilidad y baja latencia. La empresa necesita evaluar la aplicación para entender su arquitectura, dependencias y los mejores servicios de AWS a utilizar. Quieren asegurarse de que la migración no interrumpa las operaciones existentes y que el nuevo entorno cumpla con los requisitos de cumplimiento. El equipo está buscando recopilar información sobre la arquitectura de la aplicación, los requisitos de red y las métricas de rendimiento. También necesitan identificar cualquier dependencia de base de datos y posibles cuellos de botella.",
        "Question": "¿Cuál de los siguientes enfoques debería adoptar la empresa para completar una evaluación de migración integral para su aplicación?",
        "Options": {
            "1": "Utilizar AWS Application Discovery Service para recopilar información detallada sobre la aplicación local, incluyendo su arquitectura, métricas de rendimiento y dependencias de red.",
            "2": "Contratar a una firma de consultoría externa para analizar la aplicación y recomendar servicios de AWS basados en su experiencia en migraciones a la nube.",
            "3": "Realizar una revisión manual del código de la aplicación y la documentación de arquitectura para identificar dependencias y cuellos de botella de rendimiento antes de migrar a AWS.",
            "4": "Implementar un proyecto piloto en AWS con un subconjunto limitado de la aplicación para probar el rendimiento e identificar posibles desafíos de migración antes de una migración completa."
        },
        "Correct Answer": "Utilizar AWS Application Discovery Service para recopilar información detallada sobre la aplicación local, incluyendo su arquitectura, métricas de rendimiento y dependencias de red.",
        "Explanation": "El AWS Application Discovery Service está diseñado específicamente para ayudar a las organizaciones a recopilar información sobre sus aplicaciones locales, incluyendo arquitectura, dependencias y métricas de rendimiento. Estos datos son cruciales para planificar una migración a AWS y asegurar que todos los aspectos de la aplicación sean considerados, lo que ayuda a minimizar la interrupción y cumplir con los requisitos de cumplimiento.",
        "Other Options": [
            "Si bien realizar una revisión manual puede proporcionar algunas ideas, es propensa a errores humanos y puede pasar por alto dependencias críticas o métricas de rendimiento que las herramientas automatizadas pueden capturar fácilmente.",
            "Implementar un proyecto piloto puede ayudar a identificar desafíos, pero no proporciona una visión completa de la arquitectura y dependencias de la aplicación, que son esenciales para una evaluación de migración integral.",
            "Contratar a una firma de consultoría externa puede proporcionar información valiosa, pero depender únicamente de la experiencia externa puede pasar por alto detalles específicos que el equipo interno podría evaluar utilizando herramientas de AWS personalizadas."
        ]
    },
    {
        "Question Number": "18",
        "Situation": "Una empresa de servicios financieros está expandiendo su infraestructura para soportar una nueva aplicación de banca móvil. Necesitan asegurarse de que pueden monitorear el tráfico de red de manera efectiva para detectar cualquier actividad sospechosa y mantener el cumplimiento con los estándares regulatorios. La empresa está utilizando actualmente Amazon VPC y AWS CloudTrail, pero quiere mejorar sus capacidades de monitoreo.",
        "Question": "¿Cuál de las siguientes soluciones ayudaría mejor a la empresa a monitorear el tráfico de red de manera efectiva y asegurar el cumplimiento con los estándares regulatorios?",
        "Options": {
            "1": "Usar Amazon Inspector para realizar evaluaciones de seguridad en la aplicación y generar informes de cumplimiento.",
            "2": "Desplegar un AWS WAF para filtrar las solicitudes entrantes y bloquear el tráfico malicioso antes de que llegue a la aplicación.",
            "3": "Configurar AWS CloudTrail para registrar todas las llamadas a la API realizadas en la cuenta y revisar los registros periódicamente en busca de actividad sospechosa.",
            "4": "Implementar AWS VPC Flow Logs para capturar y analizar el tráfico dentro de la VPC y configurar alertas para patrones inusuales."
        },
        "Correct Answer": "Implementar AWS VPC Flow Logs para capturar y analizar el tráfico dentro de la VPC y configurar alertas para patrones inusuales.",
        "Explanation": "AWS VPC Flow Logs proporcionan visibilidad detallada del tráfico de red que fluye hacia y desde las interfaces de red en su VPC. Esto permite a la empresa analizar patrones de tráfico, detectar anomalías y asegurar el cumplimiento con los estándares regulatorios de manera efectiva.",
        "Other Options": [
            "Si bien AWS CloudTrail es útil para registrar llamadas a la API, no proporciona visibilidad detallada del tráfico de red real, que es esencial para monitorear actividades sospechosas.",
            "Amazon Inspector se centra principalmente en evaluar la seguridad de la aplicación en lugar de monitorear el tráfico de red en tiempo real, lo que lo hace menos adecuado para las necesidades de la empresa.",
            "AWS WAF se utiliza para proteger aplicaciones de exploits web comunes, pero no proporciona capacidades de monitoreo de tráfico integrales necesarias para analizar y detectar patrones de red sospechosos."
        ]
    },
    {
        "Question Number": "19",
        "Situation": "Una empresa está implementando una nueva aplicación web que requiere protección contra vulnerabilidades web comunes como inyección SQL y scripting entre sitios. Quieren usar AWS WAF para filtrar el tráfico antes de que llegue a su distribución de CloudFront. El equipo está considerando usar AWS Managed Rules para simplificar la configuración y el mantenimiento del WAF. También quieren implementar limitación de tasa para prevenir abusos de direcciones IP específicas. (Seleccione Dos)",
        "Question": "¿Qué acciones se deben tomar para implementar efectivamente AWS WAF en este escenario?",
        "Options": {
            "1": "Seleccionar uno o más grupos de AWS Managed Rule para agregar a su WebACL que proporcionen protección contra vulnerabilidades comunes.",
            "2": "Implementar una regla basada en tasa en su WebACL para bloquear direcciones IP que superen un umbral de solicitudes especificado.",
            "3": "Crear una regla personalizada que permita todo el tráfico a la distribución de CloudFront sin importar las condiciones.",
            "4": "Configurar su WebACL para permitir tráfico solo de una ubicación geográfica específica para mejorar la seguridad.",
            "5": "Modificar la acción predeterminada del WebACL para contar solicitudes en lugar de bloquearlas."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Seleccionar uno o más grupos de AWS Managed Rule para agregar a su WebACL que proporcionen protección contra vulnerabilidades comunes.",
            "Implementar una regla basada en tasa en su WebACL para bloquear direcciones IP que superen un umbral de solicitudes especificado."
        ],
        "Explanation": "Al seleccionar grupos de AWS Managed Rule, puede aprovechar reglas predefinidas que protegen automáticamente su aplicación de vulnerabilidades comunes sin necesidad de una configuración extensa. Implementar una regla basada en tasa le permite limitar el número de solicitudes de direcciones IP individuales, previniendo efectivamente abusos y asegurando un uso justo de los recursos.",
        "Other Options": [
            "Crear una regla personalizada que permita todo el tráfico anula el propósito de implementar un WAF, ya que expondría la aplicación a todo tipo de ataques sin filtrar.",
            "Configurar el WebACL para permitir tráfico solo de una ubicación geográfica específica podría bloquear inadvertidamente a usuarios legítimos de otras regiones, reduciendo la accesibilidad.",
            "Modificar la acción predeterminada para contar solicitudes no proporcionaría ninguna medida de protección; simplemente registra el tráfico sin hacer cumplir políticas de seguridad."
        ]
    },
    {
        "Question Number": "20",
        "Situation": "Una organización está implementando un entorno AWS de múltiples cuentas donde diferentes equipos necesitan acceder a recursos compartidos de manera segura. El equipo de seguridad ha aconsejado usar roles de IAM con IDs externos para mitigar el riesgo de acceso no autorizado. La organización quiere asegurarse de que las partes externas puedan asumir roles de manera segura sin exponer permisos sensibles.",
        "Question": "¿Qué enfoque debe tomar la organización para habilitar de manera segura a las partes externas para asumir roles dentro de sus cuentas de AWS?",
        "Options": {
            "1": "Definir un rol vinculado a un servicio que permita a los servicios externos acceder a recursos en su cuenta sin usar un ID externo.",
            "2": "Configurar un rol con una política de confianza que requiera que la parte externa proporcione un ID externo al asumir el rol.",
            "3": "Configurar una política de IAM que otorgue acceso a la parte externa y adjuntarla directamente a los recursos que necesitan.",
            "4": "Crear un nuevo usuario de IAM para cada parte externa con claves de acceso a largo plazo y proporcionarles los permisos necesarios."
        },
        "Correct Answer": "Configurar un rol con una política de confianza que requiera que la parte externa proporcione un ID externo al asumir el rol.",
        "Explanation": "Usar una política de confianza que requiera un ID externo mejora la seguridad al garantizar que la parte externa solo pueda asumir el rol cuando proporcione el ID externo correcto. Esto mitiga el riesgo de que el rol sea asumido por usuarios no autorizados.",
        "Other Options": [
            "Crear usuarios de IAM con claves de acceso a largo plazo aumenta el riesgo de filtración de credenciales y no sigue las mejores prácticas para acceso temporal.",
            "Los roles vinculados a un servicio son predefinidos por los servicios de AWS y no son adecuados para otorgar acceso a partes externas, ya que no permiten IDs externos ni permisos personalizados.",
            "Adjuntar una política de IAM directamente a recursos para partes externas no proporciona los controles de seguridad necesarios que ofrecen los IDs externos, y podría exponer permisos sensibles sin verificar la identidad de la parte externa."
        ]
    },
    {
        "Question Number": "21",
        "Situation": "Una empresa de servicios financieros está implementando una aplicación que procesa transacciones en tiempo real. Dada la naturaleza crítica de estas transacciones, la empresa necesita asegurar el cumplimiento de estrictos Acuerdos de Nivel de Servicio (SLAs) y establecer Indicadores Clave de Desempeño (KPIs) relevantes para monitorear efectivamente el rendimiento de la aplicación.",
        "Question": "¿Cuál de los siguientes enfoques asegura mejor que la aplicación cumpla con sus SLAs y KPIs mientras mantiene alta confiabilidad y rendimiento?",
        "Options": {
            "1": "Definir SLAs que especifiquen tiempos máximos de respuesta y tiempo de inactividad máximo, e implementar una arquitectura altamente disponible en múltiples regiones.",
            "2": "Establecer un equipo dedicado para verificar manualmente el rendimiento de la aplicación semanalmente para asegurar el cumplimiento de los SLAs.",
            "3": "Utilizar una única instancia de EC2 para alojar la aplicación mientras se implementan copias de seguridad diarias para recuperarse de cualquier falla.",
            "4": "Implementar una solución de monitoreo que rastree métricas de rendimiento de la aplicación y alerte al equipo de operaciones cuando no se cumplan los KPIs."
        },
        "Correct Answer": "Definir SLAs que especifiquen tiempos máximos de respuesta y tiempo de inactividad máximo, e implementar una arquitectura altamente disponible en múltiples regiones.",
        "Explanation": "Este enfoque asegura que la aplicación esté diseñada con los SLAs en mente, estableciendo expectativas de rendimiento claras mientras proporciona redundancia a través de una arquitectura de múltiples regiones. Esta configuración mejora significativamente la disponibilidad y la resiliencia, alineándose con la naturaleza crítica de los servicios que se están proporcionando.",
        "Other Options": [
            "Si bien monitorear las métricas de rendimiento de la aplicación es esencial, depender únicamente de alertas no asegura proactivamente que se cumplan los SLAs y KPIs. Carece de las garantías estructurales requeridas para una alta confiabilidad.",
            "Utilizar una única instancia de EC2 introduce un único punto de falla y no cumple con los requisitos de alta disponibilidad necesarios para procesar transacciones críticas. Las copias de seguridad diarias no sustituyen la disponibilidad en tiempo real.",
            "Un proceso de verificación manual no es una forma escalable o efectiva de monitorear el rendimiento de la aplicación. Este método es propenso a retrasos y errores humanos, fallando en proporcionar información en tiempo real sobre el cumplimiento de los SLAs."
        ]
    },
    {
        "Question Number": "22",
        "Situation": "Una empresa utiliza un bucket de Amazon S3 para almacenar documentos importantes. Recientemente han habilitado el versionado para asegurarse de que los cambios en estos documentos sean rastreados. Después de habilitar el versionado, están preocupados por cómo se verán afectados los documentos existentes y las futuras cargas, y si podrán revertir a versiones anteriores si es necesario.",
        "Question": "¿Cuáles son las implicaciones de habilitar el versionado en un bucket de S3? (Seleccione Dos)",
        "Options": {
            "1": "Una vez que se habilita el versionado, no se puede desactivar sin eliminar el bucket.",
            "2": "Los objetos existentes en el bucket mantendrán su ID de versión nulo y no se verán afectados.",
            "3": "Los objetos que se eliminan aún conservarán sus versiones anteriores en el bucket.",
            "4": "Todos los nuevos objetos cargados en el bucket recibirán un ID de versión único.",
            "5": "Habilitar el versionado asigna retroactivamente un ID de versión único a todos los objetos existentes."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Los objetos existentes en el bucket mantendrán su ID de versión nulo y no se verán afectados.",
            "Todos los nuevos objetos cargados en el bucket recibirán un ID de versión único."
        ],
        "Explanation": "Cuando se habilita el versionado en un bucket de S3, los objetos existentes permanecen sin cambios con su ID de versión establecido en nulo. Sin embargo, cualquier nuevo objeto cargado en el bucket recibirá un ID de versión único, lo que permite un mejor seguimiento y gestión de las versiones de los objetos.",
        "Other Options": [
            "Esta opción es incorrecta porque habilitar el versionado no asigna retroactivamente IDs de versión únicos a los objetos existentes; ellos mantendrán su ID de versión nulo.",
            "Esta opción es incorrecta porque el versionado puede ser suspendido, pero el bucket en sí no necesita ser eliminado para detener el versionado.",
            "Esta opción es incorrecta porque los objetos eliminados no se eliminan permanentemente; en cambio, se marcan como eliminados, y sus versiones anteriores aún pueden ser accedidas."
        ]
    },
    {
        "Question Number": "23",
        "Situation": "Una empresa está buscando implementar una solución que permita a sus dispositivos de borde procesar datos localmente y comunicarse con los servicios de AWS IoT para gestión y análisis. La arquitectura debe asegurar que los dispositivos puedan operar de manera independiente incluso durante la conectividad intermitente. El arquitecto de soluciones necesita elegir el enfoque más adecuado utilizando los servicios de AWS.",
        "Question": "¿Cuál de las siguientes configuraciones que utilizan servicios de AWS proporciona la mejor solución para extender las capacidades de la nube a los dispositivos de borde mientras se asegura que puedan actuar sobre los datos que generan localmente?",
        "Options": {
            "1": "Usar AWS Lambda@Edge para ejecutar funciones que modifican solicitudes y respuestas en CloudFront, permitiendo el procesamiento de datos más cerca de los usuarios pero dependiendo de una conectividad a internet constante.",
            "2": "Desplegar AWS IoT Greengrass en los dispositivos de borde para habilitar la ejecución local de funciones de AWS Lambda y comunicación segura con los servicios de AWS incluso sin conectividad a internet.",
            "3": "Implementar una instancia de Amazon EC2 en el borde para ejecutar aplicaciones que procesen datos localmente, asegurando conectividad con AWS para gestión y análisis.",
            "4": "Utilizar AWS IoT Core para conectar dispositivos directamente a la nube, realizando todo el procesamiento de datos en la nube sin ejecución local."
        },
        "Correct Answer": "Desplegar AWS IoT Greengrass en los dispositivos de borde para habilitar la ejecución local de funciones de AWS Lambda y comunicación segura con los servicios de AWS incluso sin conectividad a internet.",
        "Explanation": "AWS IoT Greengrass permite a los dispositivos de borde ejecutar funciones de AWS Lambda y realizar acciones locales basadas en los datos que generan. Esta capacidad asegura que los dispositivos puedan funcionar de manera independiente durante cortes de energía mientras mantienen una comunicación segura con los servicios de AWS cuando la conectividad está disponible.",
        "Other Options": [
            "AWS Lambda@Edge está diseñado para ejecutar funciones en el borde de la red de AWS, principalmente para modificar solicitudes y respuestas en conjunto con CloudFront. Esta solución depende en gran medida de la conectividad a internet y no permite la ejecución local de funciones en los propios dispositivos.",
            "Usar una instancia de Amazon EC2 en el borde puede proporcionar capacidades de procesamiento local, pero no se adapta específicamente a la gestión de dispositivos de borde o comunicación segura con los servicios de AWS en un estado desconectado. También introduce sobrecarga y complejidad que pueden no ser necesarias.",
            "Si bien AWS IoT Core permite la comunicación directa con los servicios en la nube, no proporciona capacidades de procesamiento local para los dispositivos de borde. Esta opción requeriría una conexión a internet constante, lo que la hace inadecuada para escenarios donde se necesita acción local durante problemas de conectividad."
        ]
    },
    {
        "Question Number": "24",
        "Situation": "Un equipo de desarrollo de software está implementando un pipeline de CI/CD utilizando servicios de AWS para automatizar el despliegue de sus aplicaciones. Quieren asegurarse de que los cambios de código se construyan, prueben y desplieguen automáticamente en múltiples entornos sin intervención manual. El equipo está considerando varias herramientas de AWS para lograr este objetivo.",
        "Question": "¿Cuál de las siguientes opciones es la forma MÁS efectiva de implementar un pipeline de CI/CD en AWS para este escenario?",
        "Options": {
            "1": "Configurar un servidor Jenkins en una instancia de EC2 para gestionar el proceso de construcción y despliegue de la aplicación.",
            "2": "Implementar un proceso de despliegue manual utilizando AWS Elastic Beanstalk para desplegar la aplicación en el entorno de staging.",
            "3": "Utilizar funciones de AWS Lambda para manejar los disparadores de despliegue y gestionar el proceso de CI/CD sin un pipeline dedicado.",
            "4": "Usar AWS CodePipeline para orquestar el flujo de trabajo de CI/CD e integrarlo con AWS CodeBuild y AWS CodeDeploy."
        },
        "Correct Answer": "Usar AWS CodePipeline para orquestar el flujo de trabajo de CI/CD e integrarlo con AWS CodeBuild y AWS CodeDeploy.",
        "Explanation": "Usar AWS CodePipeline proporciona un servicio completamente gestionado que permite definir fácilmente las etapas de su pipeline de CI/CD, integrarse con otros servicios de AWS como CodeBuild para construir código y CodeDeploy para el despliegue, y automatizar todo el proceso desde el commit del código hasta el despliegue. Este enfoque minimiza la intervención manual y maximiza la eficiencia.",
        "Other Options": [
            "Implementar un proceso de despliegue manual utilizando AWS Elastic Beanstalk no proporciona la automatización y las características de integración continua que ofrece un pipeline de CI/CD adecuado, lo que llevaría a un mayor riesgo de error humano y ciclos de lanzamiento más lentos.",
            "Utilizar funciones de AWS Lambda para disparadores de despliegue carece de las características integrales de un pipeline de CI/CD, como la gestión de construcciones y la orquestación de despliegues, lo que lo convierte en una solución menos efectiva para automatizar todo el ciclo de vida del desarrollo.",
            "Configurar un servidor Jenkins en una instancia de EC2 añade complejidad innecesaria y sobrecarga de mantenimiento en comparación con el uso de servicios gestionados por AWS como CodePipeline, que están diseñados específicamente para flujos de trabajo de CI/CD."
        ]
    },
    {
        "Question Number": "25",
        "Situation": "Una empresa emergente está buscando optimizar sus costos de AWS mientras asegura que tiene suficiente capacidad para su creciente aplicación web. Están considerando diferentes opciones de compra ofrecidas por AWS. La carga de trabajo de la empresa es predecible, con patrones de uso consistentes durante el horario laboral y un uso mínimo durante las horas fuera de pico. ¿Cuál es la opción de compra MÁS rentable para este escenario?",
        "Question": "¿Qué opción de compra de AWS debería recomendar el Arquitecto de Soluciones para optimizar los costos de la carga de trabajo predecible de la startup?",
        "Options": {
            "1": "Comprar Instancias Reservadas con un término de un año para cubrir la carga de trabajo consistente durante el horario laboral.",
            "2": "Implementar Planes de Ahorro para proporcionar flexibilidad mientras se reducen los costos basados en los patrones de uso.",
            "3": "Utilizar Instancias Spot para toda la carga de trabajo para aprovechar los precios más bajos.",
            "4": "Aprovechar Instancias Bajo Demanda para mantener flexibilidad sin ningún compromiso inicial."
        },
        "Correct Answer": "Comprar Instancias Reservadas con un término de un año para cubrir la carga de trabajo consistente durante el horario laboral.",
        "Explanation": "Comprar Instancias Reservadas con un término de un año es la opción más rentable para cargas de trabajo predecibles, ya que ofrece ahorros significativos en comparación con los precios de Instancias Bajo Demanda, asegurando al mismo tiempo que se reserve capacidad para el uso consistente durante el horario laboral.",
        "Other Options": [
            "Usar Instancias Spot puede llevar a interrupciones y no es adecuado para cargas de trabajo predecibles que requieren tiempo de actividad consistente, ya que estas instancias pueden ser reclamadas por AWS en cualquier momento.",
            "Implementar Planes de Ahorro proporcionaría cierta flexibilidad, pero para una carga de trabajo altamente predecible, las Instancias Reservadas generalmente ofrecerían mayores ahorros dado el compromiso con el uso.",
            "Aprovechar Instancias Bajo Demanda permite flexibilidad y sin costos iniciales, pero es la opción más cara para cargas de trabajo predecibles en comparación con las Instancias Reservadas."
        ]
    },
    {
        "Question Number": "26",
        "Situation": "Una empresa de servicios financieros depende de un conjunto de instancias EC2 y una base de datos Amazon RDS para PostgreSQL para gestionar datos sensibles de transacciones de clientes. Requieren una estrategia robusta de respaldo y restauración para asegurar la integridad de los datos y el cumplimiento de los requisitos regulatorios. La empresa exige que los respaldos se realicen sin afectar el rendimiento de la aplicación, y el RTO debe ser inferior a 2 horas, mientras que el RPO no debe exceder los 10 minutos. Además, los datos sensibles deben estar encriptados tanto en tránsito como en reposo.",
        "Question": "Como Arquitecto de Soluciones, ¿qué estrategia de respaldo y restauración cumpliría mejor con los requisitos de RTO, RPO y encriptación de datos mientras minimiza el impacto en el rendimiento de la aplicación?",
        "Options": {
            "1": "Habilitar respaldos automáticos de RDS con un intervalo de instantáneas de 15 minutos. Usar Amazon S3 para almacenar respaldos y configurar encriptación del lado del servidor con claves gestionadas por S3, asegurando que los datos estén encriptados en tránsito con TLS.",
            "2": "Programar respaldos manuales de la instancia RDS cada 30 minutos y almacenar registros de transacciones en un bucket de S3 cada 5 minutos. Usar AWS Secrets Manager para gestionar claves de encriptación y asegurar que los datos estén encriptados en tránsito con HTTPS.",
            "3": "Implementar AWS Backup para crear respaldos diarios de la instancia RDS y habilitar respaldos automáticos con una frecuencia de instantáneas de 5 minutos. Usar AWS Key Management Service (KMS) para gestionar claves de encriptación para datos en reposo y asegurar que SSL esté habilitado para datos en tránsito.",
            "4": "Usar AWS Data Pipeline para programar respaldos de la instancia RDS cada hora y transferirlos a Amazon S3. Configurar encriptación para los respaldos usando AWS CloudHSM y asegurar que los datos estén encriptados en tránsito usando IPsec."
        },
        "Correct Answer": "Implementar AWS Backup para crear respaldos diarios de la instancia RDS y habilitar respaldos automáticos con una frecuencia de instantáneas de 5 minutos. Usar AWS Key Management Service (KMS) para gestionar claves de encriptación para datos en reposo y asegurar que SSL esté habilitado para datos en tránsito.",
        "Explanation": "Esta opción asegura que se creen respaldos automáticos con un impacto mínimo en el rendimiento y proporciona un RPO de 5 minutos, que cumple con el requisito. También aprovecha AWS KMS para la encriptación en reposo y SSL para la encriptación en tránsito, asegurando el cumplimiento de las políticas de seguridad de la empresa.",
        "Other Options": [
            "Esta opción no cumple con el requisito de RPO de 10 minutos, ya que los respaldos manuales cada 30 minutos podrían llevar a la pérdida de datos. Además, AWS Secrets Manager no está diseñado principalmente para gestionar claves de encriptación para datos en reposo.",
            "Si bien los respaldos automáticos de RDS son una buena característica, un intervalo de instantáneas de 15 minutos no cumple con el requisito de RPO de 10 minutos. Además, usar claves gestionadas por S3 no proporciona el mismo nivel de control que AWS KMS para la gestión de claves de encriptación.",
            "Usar AWS Data Pipeline para programar respaldos puede introducir complejidad innecesaria, y los respaldos horarios no cumplen con el requisito de RPO de 10 minutos. Si bien CloudHSM proporciona una gestión de claves sólida, su integración con RDS para la encriptación de respaldos podría no ser sencilla."
        ]
    },
    {
        "Question Number": "27",
        "Situation": "Una empresa está planeando migrar una gran aplicación local a AWS. La aplicación se alojará en múltiples Zonas de Disponibilidad dentro de una sola región. Como parte de la estrategia de migración, la empresa quiere asegurarse de minimizar los costos de transferencia de datos mientras mantiene alta disponibilidad y rendimiento. Están particularmente preocupados por los costos asociados con la transferencia de datos entre los servicios de AWS y el centro de datos local.",
        "Question": "¿Cuál de las siguientes estrategias ayudaría mejor a la empresa a minimizar los costos de transferencia de datos mientras asegura alta disponibilidad y rendimiento para su aplicación migrada?",
        "Options": {
            "1": "Implementar emparejamiento de VPC entre múltiples Nubes Privadas Virtuales (VPC) para facilitar la transferencia de datos sin costo dentro de las regiones de AWS.",
            "2": "Usar AWS Direct Connect para establecer una conexión dedicada desde el centro de datos local a AWS, asegurando baja latencia y reducción de costos de transferencia de datos.",
            "3": "Utilizar Amazon CloudFront como una red de entrega de contenido para almacenar en caché datos en ubicaciones de borde, reduciendo la cantidad de datos transferidos desde el origen en AWS.",
            "4": "Aprovechar AWS Global Accelerator para optimizar la ruta hacia la región de AWS desde el centro de datos local, reduciendo la latencia y mejorando el rendimiento."
        },
        "Correct Answer": "Usar AWS Direct Connect para establecer una conexión dedicada desde el centro de datos local a AWS, asegurando baja latencia y reducción de costos de transferencia de datos.",
        "Explanation": "Usar AWS Direct Connect proporciona una conexión dedicada y de alto ancho de banda desde el centro de datos local a AWS, lo que reduce significativamente los costos de transferencia de datos en comparación con el uso de internet. Este método también asegura baja latencia y alta confiabilidad, lo que lo hace ideal para aplicaciones de alto rendimiento.",
        "Other Options": [
            "Utilizar Amazon CloudFront ayuda principalmente a reducir la latencia y proporciona beneficios de almacenamiento en caché para la distribución de contenido, pero no aborda directamente los costos de transferencia de datos asociados con el movimiento de grandes volúmenes de datos entre el local y AWS.",
            "Implementar emparejamiento de VPC permite la transferencia gratuita de datos entre VPC en la misma región, pero no se aplica a las transferencias de datos entre el local y AWS, por lo que no ayuda a minimizar costos en este escenario específico.",
            "Aprovechar AWS Global Accelerator optimiza el enrutamiento del tráfico hacia los servicios de AWS, pero no impacta directamente en el costo de transferencia de datos entre el centro de datos local y los servicios de AWS."
        ]
    },
    {
        "Question Number": "28",
        "Situation": "Una organización de servicios financieros está buscando mejorar su postura de seguridad implementando un sistema robusto de gestión de credenciales en AWS. El arquitecto de soluciones necesita identificar servicios efectivos que puedan gestionar, almacenar y recuperar de manera segura información sensible como claves API, contraseñas y credenciales de bases de datos. La organización requiere una solución que se pueda integrar fácilmente en sus servicios existentes de AWS y que proporcione un control de acceso detallado para sus usuarios. (Seleccione Dos)",
        "Question": "¿Qué combinación de servicios de AWS debería recomendar el arquitecto de soluciones para la gestión de credenciales?",
        "Options": {
            "1": "Implementar AWS Systems Manager Parameter Store para gestionar datos de configuración y secretos con cifrado incorporado.",
            "2": "Usar AWS Secrets Manager para almacenar y recuperar credenciales sensibles y rotarlas automáticamente.",
            "3": "Aprovechar AWS Lambda para crear una solución personalizada de gestión de credenciales utilizando variables de entorno.",
            "4": "Adoptar Amazon Cognito para gestionar la autenticación de usuarios y el control de acceso para el almacenamiento de credenciales.",
            "5": "Utilizar roles de AWS Identity and Access Management (IAM) para almacenar directamente las contraseñas de los usuarios de manera segura."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Usar AWS Secrets Manager para almacenar y recuperar credenciales sensibles y rotarlas automáticamente.",
            "Implementar AWS Systems Manager Parameter Store para gestionar datos de configuración y secretos con cifrado incorporado."
        ],
        "Explanation": "AWS Secrets Manager está diseñado específicamente para gestionar información sensible como credenciales, proporcionando rotación automática y control de acceso detallado. AWS Systems Manager Parameter Store también ofrece una forma segura de almacenar datos de configuración, incluidos secretos, con cifrado, lo que lo hace adecuado para la gestión de credenciales.",
        "Other Options": [
            "Los roles de AWS Identity and Access Management (IAM) se utilizan para gestionar permisos y acceso a recursos de AWS, pero no proporcionan un mecanismo para almacenar de manera segura las contraseñas de los usuarios, lo que hace que esta opción no sea adecuada para la gestión de credenciales.",
            "Usar AWS Lambda para una solución personalizada de gestión de credenciales aumenta la complejidad y puede introducir riesgos de seguridad, ya que requiere gestionar toda la solución en lugar de aprovechar los servicios existentes de AWS diseñados para la gestión de credenciales.",
            "Amazon Cognito se centra principalmente en la autenticación de usuarios y el control de acceso, y aunque puede gestionar credenciales de usuarios, no está diseñado específicamente para almacenar y recuperar de manera segura credenciales sensibles de aplicaciones como claves API o contraseñas de bases de datos."
        ]
    },
    {
        "Question Number": "29",
        "Situation": "Una empresa global de comercio minorista en línea está buscando mejorar su estrategia de recuperación ante desastres para asegurar un tiempo de inactividad y pérdida de datos mínimos. La empresa utiliza servicios de AWS de manera extensiva, pero aún no ha implementado un plan formal de recuperación ante desastres. El arquitecto de soluciones tiene la tarea de identificar metodologías y herramientas de recuperación ante desastres apropiadas para satisfacer los requisitos de la empresa de manera efectiva. (Seleccione Dos)",
        "Question": "¿Cuál de los siguientes métodos y herramientas de recuperación ante desastres debería recomendar el arquitecto de soluciones?",
        "Options": {
            "1": "Utilizar Amazon S3 para copias de seguridad y restauración solo durante el horario laboral.",
            "2": "Adoptar un enfoque de espera cálida con instancias de Amazon EC2 en una región diferente.",
            "3": "Aprovechar AWS Backup para automatizar procesos de copia de seguridad a través de los servicios.",
            "4": "Implementar AWS Elastic Disaster Recovery para replicación continua.",
            "5": "Confiar únicamente en copias de seguridad en cinta locales para la restauración de datos."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Implementar AWS Elastic Disaster Recovery para replicación continua.",
            "Aprovechar AWS Backup para automatizar procesos de copia de seguridad a través de los servicios."
        ],
        "Explanation": "AWS Elastic Disaster Recovery permite la replicación continua de recursos de AWS, lo que permite una recuperación rápida en caso de un desastre. AWS Backup automatiza y centraliza las tareas de copia de seguridad a través de múltiples servicios de AWS, asegurando que los datos se respalden regularmente y estén disponibles para su recuperación. Ambas opciones abordan la necesidad de soluciones efectivas de recuperación ante desastres adaptadas a la infraestructura en la nube de la empresa.",
        "Other Options": [
            "Utilizar Amazon S3 para copias de seguridad y restauración solo durante el horario laboral no es ideal, ya que no garantiza una protección continua de los datos y puede llevar a la pérdida de datos si ocurre un desastre fuera de ese horario.",
            "Adoptar un enfoque de espera cálida con instancias de Amazon EC2 en una región diferente puede ser efectivo, pero puede no proporcionar el mismo nivel de automatización y facilidad de gestión que AWS Elastic Disaster Recovery y AWS Backup ofrecen.",
            "Confiar únicamente en copias de seguridad en cinta locales para la restauración de datos es inadecuado, ya que no aprovecha las ventajas de las soluciones basadas en la nube y puede llevar a tiempos de recuperación más largos y posible pérdida de datos."
        ]
    },
    {
        "Question Number": "30",
        "Situation": "Una empresa de servicios financieros está realizando una auditoría de su entorno de AWS para asegurarse de que los usuarios tengan solo los permisos que necesitan para realizar sus funciones laborales, de acuerdo con el principio de menor privilegio. La empresa tiene múltiples equipos con diferentes responsabilidades y necesidades de acceso. Están utilizando AWS Identity and Access Management (IAM) para la gestión de permisos de usuarios.",
        "Question": "¿Cuál es la estrategia más efectiva para auditar el entorno de AWS y asegurar el acceso de menor privilegio para todos los usuarios?",
        "Options": {
            "1": "Implementar una solución de registro centralizada que rastree todas las llamadas API realizadas por los usuarios para identificar permisos excesivos y patrones de uso.",
            "2": "Configurar un script automatizado que elimine regularmente cualquier permiso que no se haya utilizado en los últimos 30 días para todos los usuarios.",
            "3": "Usar AWS IAM Access Analyzer para identificar permisos que no se están utilizando y ajustar los roles y políticas de IAM en consecuencia.",
            "4": "Realizar una revisión manual de todas las políticas y roles de IAM para asegurarse de que los usuarios tengan los permisos mínimos necesarios para sus tareas."
        },
        "Correct Answer": "Usar AWS IAM Access Analyzer para identificar permisos que no se están utilizando y ajustar los roles y políticas de IAM en consecuencia.",
        "Explanation": "Usar AWS IAM Access Analyzer es la forma más efectiva de auditar los permisos de los usuarios, ya que analiza automáticamente las políticas e identifica accesos excesivamente permisivos, lo que permite ajustes sistemáticos para mantener el acceso de menor privilegio en todo el entorno.",
        "Other Options": [
            "Realizar una revisión manual es laborioso y propenso a errores, lo que lo hace menos efectivo en comparación con herramientas automatizadas como IAM Access Analyzer.",
            "Si bien el registro centralizado puede proporcionar información sobre patrones de llamadas API, no identifica directamente permisos que sean excesivos o innecesarios, lo cual es esencial para hacer cumplir el menor privilegio.",
            "Un script automatizado que elimina permisos no utilizados puede revocar inadvertidamente el acceso necesario para los usuarios, lo que podría llevar a interrupciones en su capacidad para realizar tareas requeridas."
        ]
    },
    {
        "Question Number": "31",
        "Situation": "Una empresa de servicios financieros necesita procesar regularmente datos de transacciones almacenados en Amazon S3 y luego cargar los datos transformados en una base de datos Amazon RDS para fines de informes. La empresa requiere una solución que pueda automatizar este proceso y garantizar la integridad de los datos mientras minimiza costos.",
        "Question": "¿Qué servicio de AWS debería usar la empresa para orquestar el movimiento y la transformación de datos de Amazon S3 a Amazon RDS?",
        "Options": {
            "1": "AWS Step Functions para gestionar el flujo de trabajo y AWS Lambda para la transformación de datos.",
            "2": "Amazon Kinesis Data Firehose para transmitir datos de S3 a RDS.",
            "3": "AWS Batch para procesar datos en S3 y cargarlos en RDS.",
            "4": "AWS Glue para crear trabajos ETL y automatizar la transferencia y transformación de datos."
        },
        "Correct Answer": "AWS Glue para crear trabajos ETL y automatizar la transferencia y transformación de datos.",
        "Explanation": "AWS Glue está diseñado específicamente para procesos ETL (Extraer, Transformar, Cargar), lo que lo hace ideal para mover y transformar datos de Amazon S3 a Amazon RDS. Proporciona una arquitectura sin servidor que automatiza la programación y ejecución de flujos de trabajo de datos, garantizando la integridad de los datos y minimizando la sobrecarga operativa.",
        "Other Options": [
            "AWS Step Functions se utiliza para gestionar flujos de trabajo complejos, pero no proporciona capacidades ETL nativas, lo que requiere servicios adicionales para la transformación de datos.",
            "Amazon Kinesis Data Firehose se utiliza principalmente para transmitir datos y puede no ser adecuado para el procesamiento por lotes y la transformación de los datos existentes en S3 antes de cargarlos en RDS.",
            "AWS Batch está diseñado para trabajos de procesamiento por lotes, pero no proporciona una forma sencilla de orquestar procesos ETL o gestionar el flujo de datos entre S3 y RDS."
        ]
    },
    {
        "Question Number": "32",
        "Situation": "Una empresa de transmisión de medios está experimentando problemas de rendimiento con su servicio de entrega de video, que está alojado en AWS. Los usuarios han informado de buffering y retrasos durante la reproducción de video, especialmente durante las horas pico. Como arquitecto de soluciones, necesitas mejorar el rendimiento del servicio de transmisión de video para garantizar una experiencia de usuario fluida. (Selecciona Dos)",
        "Question": "¿Cuál de las siguientes estrategias deberías implementar para optimizar el rendimiento del servicio de entrega de video?",
        "Options": {
            "1": "Configurar Amazon Simple Storage Service (S3) para alojar tus archivos de video sin ningún mecanismo de caché frente a él.",
            "2": "Implementar Amazon CloudFront como una red de entrega de contenido (CDN) para almacenar en caché el contenido de video más cerca de los usuarios y reducir la latencia.",
            "3": "Usar AWS Global Accelerator para mejorar la disponibilidad y el rendimiento de tus aplicaciones con usuarios en múltiples regiones geográficas.",
            "4": "Desplegar una configuración de múltiples regiones para tu aplicación de procesamiento de medios para garantizar alta disponibilidad y baja latencia a nivel global.",
            "5": "Habilitar Amazon Elastic Transcoder para convertir automáticamente archivos de video a varios formatos y resoluciones para una entrega optimizada."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Implementar Amazon CloudFront como una red de entrega de contenido (CDN) para almacenar en caché el contenido de video más cerca de los usuarios y reducir la latencia.",
            "Usar AWS Global Accelerator para mejorar la disponibilidad y el rendimiento de tus aplicaciones con usuarios en múltiples regiones geográficas."
        ],
        "Explanation": "Implementar Amazon CloudFront almacenará en caché el contenido de video en ubicaciones de borde, reduciendo significativamente la latencia para los usuarios. Además, usar AWS Global Accelerator optimiza la ruta hacia tu aplicación, mejorando el rendimiento para los usuarios distribuidos en diferentes regiones.",
        "Other Options": [
            "Habilitar Amazon Elastic Transcoder es beneficioso para el procesamiento de medios, pero no aborda directamente los problemas de rendimiento relacionados con la entrega. Se centra en el formato y la calidad del contenido en lugar de reducir la latencia.",
            "Desplegar una configuración de múltiples regiones puede mejorar la disponibilidad, pero puede no abordar directamente los problemas de rendimiento a menos que se combine con una CDN. Agrega complejidad y costo sin garantizar una mejora en el rendimiento por sí solo.",
            "Configurar S3 sin mecanismos de caché probablemente agravará los problemas de rendimiento, ya que los usuarios tendrían que recuperar el contenido de video directamente de S3 sin los beneficios de la caché en el borde, lo que llevaría a una mayor latencia."
        ]
    },
    {
        "Question Number": "33",
        "Situation": "Un arquitecto de la nube está diseñando una solución que requiere el despliegue de múltiples instancias de Amazon EC2 en varias regiones para garantizar alta disponibilidad y tolerancia a fallos. El arquitecto necesita asegurarse de que se pueda aprovisionar el número máximo de instancias de EC2 sin alcanzar los límites de servicio.",
        "Question": "¿Qué combinaciones de acciones debería tomar el arquitecto para gestionar eficazmente las cuotas del servicio EC2? (Selecciona Dos)",
        "Options": {
            "1": "Solicitar un aumento de límite para las instancias de EC2 a través del Centro de Soporte de AWS si se alcanzan los límites.",
            "2": "Configurar Amazon EC2 Auto Scaling para ajustar dinámicamente el número de instancias según el tráfico.",
            "3": "Usar AWS CloudFormation para automatizar el despliegue de instancias de EC2 sin considerar las cuotas.",
            "4": "Implementar una función de AWS Lambda para monitorear el uso de instancias de EC2 y alertar cuando los límites estén cerca.",
            "5": "Revisar los límites predeterminados de instancias de EC2 para cada región en la Consola de Administración de AWS."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Revisar los límites predeterminados de instancias de EC2 para cada región en la Consola de Administración de AWS.",
            "Solicitar un aumento de límite para las instancias de EC2 a través del Centro de Soporte de AWS si se alcanzan los límites."
        ],
        "Explanation": "Para gestionar eficazmente las cuotas del servicio EC2, el arquitecto debería primero revisar los límites predeterminados para entender la capacidad disponible en cada región. Si las demandas del proyecto superan estos límites, solicitar un aumento de límite a través del Centro de Soporte de AWS es esencial para aprovisionar recursos adicionales.",
        "Other Options": [
            "Usar AWS CloudFormation no considera las cuotas de servicio y puede llevar a despliegues fallidos si se superan los límites, lo que hace que esta sea una acción ineficaz para gestionar las cuotas.",
            "Si bien monitorear el uso de EC2 es beneficioso, simplemente implementar una función de Lambda para alertar cuando los límites estén cerca no aborda directamente la gestión de las cuotas de servicio y no garantiza la capacidad de aprovisionamiento.",
            "Configurar EC2 Auto Scaling es útil para gestionar la capacidad de instancias según la demanda, pero no aborda inherentemente la necesidad de entender o solicitar aumentos en las cuotas de servicio."
        ]
    },
    {
        "Question Number": "34",
        "Situation": "Una empresa de comercio electrónico de tamaño mediano quiere mejorar sus prácticas de gestión de costos en AWS. La empresa actualmente utiliza múltiples servicios de AWS, incluyendo EC2, S3 y RDS. Quieren establecer un sistema de alertas automatizado para notificar al equipo de finanzas cuando su gasto mensual supere un umbral predefinido. Además, el equipo de finanzas requiere un informe mensual detallado que proporcione información sobre el uso de los servicios y los costos asociados. ¿Cuál es la forma más efectiva de lograr estos requisitos?",
        "Question": "¿Cuál de las siguientes opciones satisface mejor las necesidades de la empresa en cuanto a gestión de costos, alertas e informes en AWS?",
        "Options": {
            "1": "Utilizar AWS CloudTrail para el registro y configurar alarmas de Amazon CloudWatch para monitorear el gasto en todos los servicios.",
            "2": "Configurar AWS Budgets para enviar alertas cuando se alcance el umbral de costo y usar AWS Cost Explorer para informes detallados.",
            "3": "Implementar AWS Trusted Advisor para revisar el uso de servicios y configurar scripts personalizados para informes de costos.",
            "4": "Habilitar AWS Config para rastrear cambios en los recursos y utilizar Amazon SNS para alertas sobre umbrales de costo."
        },
        "Correct Answer": "Configurar AWS Budgets para enviar alertas cuando se alcance el umbral de costo y usar AWS Cost Explorer para informes detallados.",
        "Explanation": "AWS Budgets está diseñado específicamente para establecer presupuestos de costos y uso, con la capacidad de enviar alertas cuando se superan los umbrales. AWS Cost Explorer proporciona información detallada sobre el uso de servicios y costos, lo que hace que esta opción sea la más efectiva para los requisitos de la empresa.",
        "Other Options": [
            "AWS CloudTrail se utiliza principalmente para auditar llamadas a la API y no proporciona directamente capacidades de monitoreo de costos o alertas, lo que lo hace insuficiente para las necesidades de la empresa.",
            "AWS Trusted Advisor ofrece recomendaciones para optimizar los recursos de AWS, pero no proporciona un mecanismo dedicado para alertas sobre umbrales de costo o informes detallados.",
            "AWS Config se utiliza para rastrear configuraciones de recursos y cumplimiento; no proporciona monitoreo de costos y carece de las capacidades de alerta necesarias para los umbrales de gasto."
        ]
    },
    {
        "Question Number": "35",
        "Situation": "Una gran empresa de medios necesita transferir terabytes de datos de video a Amazon S3 para archivar y procesar. La empresa tiene un ancho de banda de internet limitado y está preocupada por el tiempo requerido para cargar un volumen tan grande de datos. Están evaluando qué dispositivo AWS Snowball utilizar para la migración, considerando las diversas opciones disponibles según sus necesidades de almacenamiento y computación.",
        "Question": "¿Qué opción de AWS Snowball debería elegir la empresa para transferir eficientemente sus datos de video mientras permite algún preprocesamiento en el dispositivo?",
        "Options": {
            "1": "Seleccionar la opción Standard Snowball con 50 TB de almacenamiento para transferir los datos directamente a S3 sin capacidades de computación.",
            "2": "Elegir la opción Snowball Edge Storage Optimized para utilizar la capacidad de almacenamiento de 100 TB y 24 vCPUs para preprocesar los datos de video antes de transferirlos a S3.",
            "3": "Optar por el servicio Snowmobile, que proporciona 100 PB de almacenamiento, para transferir todos los datos de video a S3 en un solo viaje.",
            "4": "Seleccionar la opción Snowball Edge Compute Optimized para ejecutar algoritmos avanzados de aprendizaje automático en los datos de video antes de transferirlos a S3."
        },
        "Correct Answer": "Elegir la opción Snowball Edge Storage Optimized para utilizar la capacidad de almacenamiento de 100 TB y 24 vCPUs para preprocesar los datos de video antes de transferirlos a S3.",
        "Explanation": "La opción Snowball Edge Storage Optimized proporciona la capacidad de almacenamiento y los recursos de computación necesarios para realizar el preprocesamiento de los datos de video, lo que la hace ideal para las necesidades de la empresa de transferir grandes volúmenes de datos mientras utiliza capacidades de computación.",
        "Other Options": [
            "La opción Standard Snowball carece de capacidades de computación y no permitiría ningún preprocesamiento de los datos de video, lo que la hace inadecuada para los requisitos de la empresa.",
            "El servicio Snowmobile está diseñado para migraciones de datos extremadamente grandes, pero sería excesivo para terabytes de datos de video y no ofrece capacidades de preprocesamiento.",
            "La opción Snowball Edge Compute Optimized está más orientada a ejecutar cargas de trabajo avanzadas de aprendizaje automático y puede no proporcionar suficiente capacidad de almacenamiento para las necesidades de la empresa en comparación con la opción Storage Optimized."
        ]
    },
    {
        "Question Number": "36",
        "Situation": "Una gran empresa está migrando a AWS y necesita una solución centralizada para gestionar identidades de usuario y acceso a través de múltiples cuentas y aplicaciones de AWS. La empresa actualmente utiliza Microsoft Active Directory para su gestión de identidades y quiere implementar una solución de autenticación para la fuerza laboral que soporte capacidades de inicio de sesión único.",
        "Question": "¿Cuál de las siguientes soluciones debería implementar la empresa para satisfacer mejor sus requisitos de gestión centralizada de identidades y acceso de inicio de sesión único?",
        "Options": {
            "1": "Configurar múltiples cuentas de AWS con usuarios IAM individuales en cada cuenta para manejar la gestión de usuarios y el control de acceso.",
            "2": "Desplegar AWS Directory Service para crear un almacén de identidades separado y gestionar el acceso de usuarios directamente dentro de cada cuenta de AWS.",
            "3": "Implementar AWS IAM Identity Center para conectarse al Microsoft Active Directory existente y gestionar el acceso de usuarios a través de las cuentas de AWS.",
            "4": "Usar Amazon Cognito para crear identidades de usuario y gestionar la autenticación a través de todos los servicios y aplicaciones de AWS."
        },
        "Correct Answer": "Implementar AWS IAM Identity Center para conectarse al Microsoft Active Directory existente y gestionar el acceso de usuarios a través de las cuentas de AWS.",
        "Explanation": "AWS IAM Identity Center está diseñado para la gestión centralizada de identidades, permitiendo a las organizaciones conectar sus fuentes de identidad existentes como Microsoft Active Directory. Proporciona capacidades de inicio de sesión único a través de múltiples cuentas y aplicaciones de AWS, lo que se alinea perfectamente con los requisitos de la empresa.",
        "Other Options": [
            "AWS Directory Service requeriría un almacén de identidades separado y no proporcionaría la gestión centralizada necesaria a través de múltiples cuentas, lo que no se alinea con el objetivo de la empresa.",
            "Amazon Cognito está más enfocado en la autenticación de usuarios a nivel de aplicación y no es ideal para gestionar el acceso a través de múltiples cuentas de AWS en un entorno corporativo.",
            "Configurar usuarios IAM individuales en cada cuenta llevaría a una gestión de identidades fragmentada, dificultando la gestión del acceso y creando una experiencia de inicio de sesión único sin interrupciones."
        ]
    },
    {
        "Question Number": "37",
        "Situation": "Una plataforma de comercio electrónico global está planeando mejorar su estrategia de recuperación ante desastres. La empresa opera en múltiples regiones y necesita asegurarse de que su aplicación pueda recuperarse rápidamente de las interrupciones mientras minimiza el tiempo de inactividad y la pérdida de datos. Se ha encargado al arquitecto de soluciones identificar las estrategias de recuperación ante desastres apropiadas que equilibren el costo y los objetivos de tiempo de recuperación.",
        "Question": "¿Cuál de las siguientes estrategias de recuperación ante desastres debería considerar implementar el arquitecto de soluciones? (Seleccione Dos)",
        "Options": {
            "1": "Estrategia de espera fría sin componentes activos durante las operaciones normales",
            "2": "Estrategia de Pilot Light con componentes esenciales funcionando en modo de espera",
            "3": "Estrategia de respaldo y restauración con datos almacenados en una sola región",
            "4": "Estrategia de espera tibia con una versión reducida de un entorno completamente funcional",
            "5": "Estrategia multi-sitio con implementaciones activas en múltiples regiones"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Estrategia de Pilot Light con componentes esenciales funcionando en modo de espera",
            "Estrategia de espera tibia con una versión reducida de un entorno completamente funcional"
        ],
        "Explanation": "La estrategia de Pilot Light permite que los componentes críticos estén listos para escalar rápidamente cuando sea necesario, mientras que la estrategia de espera tibia mantiene un entorno parcialmente operativo que puede ser llevado rápidamente a plena capacidad en caso de una falla. Ambas estrategias proporcionan un equilibrio efectivo entre costo y velocidad de recuperación para escenarios de recuperación ante desastres.",
        "Other Options": [
            "La estrategia de respaldo y restauración generalmente implica tiempos de recuperación más largos y puede llevar a la pérdida de datos si no se gestiona cuidadosamente, ya que depende de que las copias de seguridad se restauren desde una sola ubicación.",
            "La estrategia multi-sitio, aunque proporciona los tiempos de recuperación más rápidos, puede ser significativamente más costosa debido al mantenimiento de entornos completamente operativos en múltiples regiones, lo que puede no estar justificado para todas las aplicaciones.",
            "La estrategia de espera fría no es ideal para una recuperación rápida, ya que implica activar recursos desde un estado inactivo, lo que lleva a tiempos de inactividad más largos y potencial pérdida de datos."
        ]
    },
    {
        "Question Number": "38",
        "Situation": "Una empresa alberga una aplicación crítica que procesa datos en tiempo real en una instancia de Amazon EC2. La aplicación está experimentando interrupciones ocasionales debido a fallos de instancia, lo que impacta las operaciones comerciales. El arquitecto de soluciones necesita implementar una arquitectura altamente disponible y resiliente que pueda manejar fallos de instancia con mínima interrupción a la aplicación y asegurar que los datos se procesen continuamente.",
        "Question": "¿Cuál de las siguientes soluciones cumple con los requisitos de alta disponibilidad y resiliencia mientras minimiza la interrupción a la aplicación?",
        "Options": {
            "1": "Crear un snapshot de la instancia de EC2 y programarlo para que se ejecute cada hora. En caso de un fallo de instancia, lanzar manualmente una nueva instancia de EC2 utilizando el último snapshot para restaurar la aplicación.",
            "2": "Usar Amazon ECS con Fargate para ejecutar la aplicación de manera sin servidor. Configurar un servicio con múltiples tareas distribuidas en múltiples Zonas de Disponibilidad. Implementar un Application Load Balancer para dirigir el tráfico a las tareas.",
            "3": "Desplegar la aplicación en una sola instancia de EC2 con un volumen de Amazon Elastic Block Store (EBS) adjunto para el almacenamiento de datos. Crear una copia de seguridad del volumen de EBS utilizando Amazon Data Lifecycle Manager para restaurar en caso de fallo.",
            "4": "Crear un grupo de Auto Scaling con múltiples instancias de EC2 en múltiples Zonas de Disponibilidad. Usar un Application Load Balancer (ALB) para distribuir el tráfico entrante a las instancias en el grupo de Auto Scaling. Configurar verificaciones de salud para el ALB para asegurar que el tráfico solo se envíe a instancias saludables."
        },
        "Correct Answer": "Crear un grupo de Auto Scaling con múltiples instancias de EC2 en múltiples Zonas de Disponibilidad. Usar un Application Load Balancer (ALB) para distribuir el tráfico entrante a las instancias en el grupo de Auto Scaling. Configurar verificaciones de salud para el ALB para asegurar que el tráfico solo se envíe a instancias saludables.",
        "Explanation": "Esta solución proporciona alta disponibilidad y resiliencia al utilizar un grupo de Auto Scaling con instancias distribuidas en múltiples Zonas de Disponibilidad. El Application Load Balancer asegura que el tráfico solo se envíe a instancias saludables, lo que minimiza el tiempo de inactividad y la interrupción para los usuarios.",
        "Other Options": [
            "Desplegar la aplicación en una sola instancia de EC2 no proporciona alta disponibilidad, ya que la falla de esa instancia resultaría en tiempo de inactividad. Si bien las copias de seguridad son útiles, no garantizan la operación continua durante las fallas.",
            "Usar Amazon ECS con Fargate ofrece un enfoque sin servidor, pero si no se configura correctamente, puede no proporcionar alta disponibilidad. Sin embargo, es una opción válida para la resiliencia; carece de la mención explícita de verificaciones de salud y distribución equilibrada del tráfico en comparación con la respuesta correcta.",
            "Crear un snapshot de la instancia de EC2 no proporciona capacidades de conmutación por error inmediatas. Este enfoque depende de la intervención manual y no asegura la operación continua, lo que lo hace menos adecuado para los requisitos de alta disponibilidad."
        ]
    },
    {
        "Question Number": "39",
        "Situation": "Una empresa de servicios financieros tiene la tarea de asegurar que los datos de transacciones de sus clientes estén protegidos contra la pérdida de datos y las interrupciones del servicio. Requieren un Objetivo de Tiempo de Recuperación (RTO) de 30 minutos y un Objetivo de Punto de Recuperación (RPO) de 15 minutos. La arquitectura debe seguir operativa incluso en caso de una falla completa de la región de AWS.",
        "Question": "¿Cuál de las siguientes soluciones cumple mejor con los requisitos de RTO y RPO para este escenario?",
        "Options": {
            "1": "Configurar una arquitectura activa-pasiva con replicación de datos cada 15 minutos a una región secundaria, y un proceso de conmutación por error que se puede ejecutar dentro de 30 minutos.",
            "2": "Implementar una configuración de espera tibia que realice copias de seguridad cada hora a otra región, permitiendo una intervención manual para restaurar los servicios.",
            "3": "Usar Amazon S3 para el almacenamiento de datos y configurar políticas de ciclo de vida para replicar datos a otra región cada hora, proporcionando un proceso de conmutación por error manual.",
            "4": "Implementar una arquitectura activa-activa en múltiples regiones de AWS con replicación de datos sincrónica para asegurar que no haya pérdida de datos."
        },
        "Correct Answer": "Configurar una arquitectura activa-pasiva con replicación de datos cada 15 minutos a una región secundaria, y un proceso de conmutación por error que se puede ejecutar dentro de 30 minutos.",
        "Explanation": "Esta opción proporciona el RPO requerido de 15 minutos a través de replicación frecuente de datos y cumple con el RTO de 30 minutos con un proceso de conmutación por error automático, asegurando un tiempo de inactividad y pérdida de datos mínimos.",
        "Other Options": [
            "Si bien una arquitectura activa-activa proporcionaría baja latencia y alta disponibilidad, puede introducir complejidad y potencialmente costos más altos sin garantizar el RTO y RPO requeridos para este escenario específico.",
            "Usar Amazon S3 con replicación horaria no cumple con el RPO de 15 minutos, ya que permite una pérdida de datos máxima de una hora, lo que excede el requisito.",
            "Una configuración de espera tibia con copias de seguridad horarias no satisface el RTO de 30 minutos porque requeriría más tiempo para poner los servicios en línea en comparación con los requisitos especificados."
        ]
    },
    {
        "Question Number": "40",
        "Situation": "Una empresa de servicios financieros está expandiendo sus operaciones a múltiples cuentas de AWS para mejorar la gestión de recursos y el cumplimiento. Quieren implementar un marco de gobernanza que permita la gestión centralizada de políticas y controles de seguridad en todas sus cuentas de AWS. Están considerando utilizar AWS Control Tower y AWS Organizations como parte de su estrategia de gobernanza.",
        "Question": "¿Cuál de las siguientes configuraciones proporcionará la gestión de gobernanza y cumplimiento MÁS efectiva para la configuración de múltiples cuentas de la empresa?",
        "Options": {
            "1": "Configurar AWS Control Tower para crear cuentas con guardrails preconfigurados. Usar AWS Organizations para gestionar las cuentas, pero no aplicar ningún SCP, confiando únicamente en roles de IAM para gestionar permisos y cumplimiento.",
            "2": "Crear una cuenta central de AWS y vincular todas las demás cuentas utilizando AWS Organizations. Implementar reglas de AWS Config para verificaciones de cumplimiento, pero no usar AWS Control Tower ni ningún guardrail para simplificar la gestión.",
            "3": "Usar AWS Organizations para crear una estructura de múltiples cuentas y aplicar manualmente políticas de IAM en todas las cuentas. Configurar registros individuales de CloudTrail para cada cuenta para monitorear actividades y asegurar el cumplimiento de políticas internas.",
            "4": "Implementar AWS Control Tower para establecer un nuevo entorno de múltiples cuentas y aplicar los guardrails proporcionados. Usar AWS Organizations para gestionar la creación de cuentas y aplicar SCPs para controles de cumplimiento adicionales. Auditar regularmente las cuentas utilizando AWS Config."
        },
        "Correct Answer": "Implementar AWS Control Tower para establecer un nuevo entorno de múltiples cuentas y aplicar los guardrails proporcionados. Usar AWS Organizations para gestionar la creación de cuentas y aplicar SCPs para controles de cumplimiento adicionales. Auditar regularmente las cuentas utilizando AWS Config.",
        "Explanation": "Usar AWS Control Tower permite a la empresa configurar rápidamente un entorno seguro de múltiples cuentas con guardrails de cumplimiento integrados. Combinar esto con AWS Organizations permite la gestión centralizada y la aplicación de Políticas de Control de Servicio (SCPs) para una mejor gobernanza. Auditorías regulares con AWS Config aseguran el cumplimiento continuo.",
        "Other Options": [
            "Usar solo AWS Organizations para políticas de IAM puede llevar a inconsistencias y aumentar el esfuerzo manual. Sin la automatización y los guardrails de AWS Control Tower, el cumplimiento puede ser más desafiante y menos efectivo.",
            "Configurar AWS Control Tower sin aplicar SCPs limita las capacidades de gobernanza. Confiar únicamente en roles de IAM para permisos podría exponer las cuentas a riesgos debido a la falta de control y supervisión centralizados.",
            "Crear una cuenta central y confiar en las reglas de AWS Config sin usar AWS Control Tower o guardrails deja el entorno vulnerable a configuraciones incorrectas y no aprovecha las capacidades completas de las herramientas de gobernanza de AWS."
        ]
    },
    {
        "Question Number": "41",
        "Situation": "Una empresa de servicios financieros opera una aplicación crítica que procesa transacciones en tiempo real. La aplicación está alojada en instancias de Amazon EC2 dentro de un grupo de Auto Scaling en múltiples Zonas de Disponibilidad. El arquitecto tiene la tarea de asegurar que la aplicación pueda soportar fallos y recuperarse sin problemas sin pérdida de datos. La aplicación escribe datos de transacciones en una base de datos de Amazon RDS. La empresa requiere una solución que minimice el tiempo de inactividad y asegure la integridad de los datos.",
        "Question": "¿Cuál de las siguientes estrategias debería implementar el arquitecto de soluciones para diseñar para fallos y asegurar una recuperación sin problemas?",
        "Options": {
            "1": "Implementar instantáneas de Amazon RDS para crear copias de seguridad antes de cada transacción. Usar AWS Lambda para automatizar procedimientos de conmutación por error y recuperación.",
            "2": "Desplegar una réplica de lectura de la instancia de Amazon RDS en otra región. Usar Amazon Route 53 para la conmutación por error de DNS para redirigir el tráfico en caso de fallo.",
            "3": "Implementar despliegues Multi-AZ de Amazon RDS para asegurar alta disponibilidad y conmutación por error automática para la base de datos. Usar un bucket de Amazon S3 para copias de seguridad y habilitar la recuperación a un punto en el tiempo.",
            "4": "Desplegar la aplicación en Amazon ECS con una configuración de malla de servicios. Almacenar registros de transacciones en una tabla de Amazon DynamoDB para una recuperación rápida."
        },
        "Correct Answer": "Implementar despliegues Multi-AZ de Amazon RDS para asegurar alta disponibilidad y conmutación por error automática para la base de datos. Usar un bucket de Amazon S3 para copias de seguridad y habilitar la recuperación a un punto en el tiempo.",
        "Explanation": "Implementar despliegues Multi-AZ de Amazon RDS proporciona alta disponibilidad y conmutación por error automática para la base de datos, lo cual es esencial para una aplicación crítica que maneja transacciones en tiempo real. Usar Amazon S3 para copias de seguridad y habilitar la recuperación a un punto en el tiempo asegura la integridad de los datos y la recuperabilidad en caso de fallos.",
        "Other Options": [
            "Desplegar una réplica de lectura en otra región no proporciona conmutación por error automática para la base de datos primaria y puede introducir latencia adicional para las operaciones de escritura. Esta opción no es adecuada para una aplicación crítica que requiere recuperación inmediata.",
            "Usar instantáneas de RDS antes de cada transacción no es una estrategia factible para asegurar cero pérdida de datos, ya que las instantáneas tardan tiempo en crearse y pueden no capturar datos en tiempo real, arriesgando así la pérdida de transacciones recientes en caso de un fallo.",
            "Desplegar la aplicación en Amazon ECS con una malla de servicios no aborda directamente la alta disponibilidad y recuperabilidad de la base de datos. Almacenar registros de transacciones en DynamoDB puede no asegurar la integridad de los datos transaccionales requeridos para la aplicación."
        ]
    },
    {
        "Question Number": "42",
        "Situation": "Una empresa de servicios financieros ha implementado recientemente una herramienta de escaneo de vulnerabilidades que se ejecuta todas las noches en su entorno de AWS. La herramienta identifica varias vulnerabilidades, pero el equipo tiene dificultades para responder de manera rápida y efectiva a estos hallazgos. Quieren priorizar respuestas automatizadas para mejorar su postura de seguridad y reducir la intervención manual. (Seleccione Dos)",
        "Question": "¿Cuáles de las siguientes respuestas automatizadas deberían ser priorizadas para abordar las vulnerabilidades detectadas?",
        "Options": {
            "1": "Programar revisiones manuales regulares de los hallazgos de vulnerabilidades para discutir con el equipo de seguridad.",
            "2": "Configurar alarmas de CloudWatch para notificar al equipo cada vez que se detecte una vulnerabilidad sin remediación automatizada.",
            "3": "Utilizar reglas de AWS Config para asegurar el cumplimiento de las mejores prácticas de seguridad y remediar automáticamente los recursos no conformes.",
            "4": "Implementar funciones de AWS Lambda para remediar automáticamente vulnerabilidades comunes según su gravedad.",
            "5": "Integrar documentos de automatización de AWS Systems Manager para ejecutar acciones de remediación predefinidas para vulnerabilidades."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Implementar funciones de AWS Lambda para remediar automáticamente vulnerabilidades comunes según su gravedad.",
            "Integrar documentos de automatización de AWS Systems Manager para ejecutar acciones de remediación predefinidas para vulnerabilidades."
        ],
        "Explanation": "Implementar funciones de AWS Lambda para la remediación automática permite una respuesta inmediata a las vulnerabilidades según su gravedad, minimizando la ventana de exposición. Además, integrar documentos de automatización de AWS Systems Manager permite ejecutar acciones predefinidas, agilizando el proceso de remediación y asegurando consistencia en el manejo de vulnerabilidades.",
        "Other Options": [
            "Programar revisiones manuales regulares no proporciona una respuesta automatizada y puede retrasar el proceso de remediación, dejando vulnerabilidades sin abordar durante períodos más largos.",
            "Configurar alarmas de CloudWatch para notificaciones sin remediación automatizada no resuelve las vulnerabilidades; solo alerta al equipo, lo que puede llevar a tiempos de respuesta más lentos.",
            "Usar reglas de AWS Config se centra en el cumplimiento en lugar de la remediación directa de vulnerabilidades, y aunque ayuda a mantener la postura de seguridad general, no aborda la necesidad inmediata de respuestas automatizadas a las vulnerabilidades detectadas."
        ]
    },
    {
        "Question Number": "43",
        "Situation": "Una empresa de servicios financieros está migrando su almacenamiento de datos a AWS. Requieren una solución que pueda proporcionar un alto rendimiento y baja latencia para sus aplicaciones de procesamiento de datos. La empresa también necesita una solución que pueda escalar fácilmente para acomodar cargas de trabajo fluctuantes y ofrezca características para la replicación automática de datos entre regiones para recuperación ante desastres. Además, quieren asegurarse de que los datos sean accesibles desde múltiples máquinas virtuales sin problemas.",
        "Question": "¿Qué combinación de servicios de almacenamiento de AWS cumpliría mejor con los requisitos de la empresa para alto rendimiento, baja latencia, escalabilidad y replicación entre regiones?",
        "Options": {
            "1": "Amazon EFS con rendimiento provisionado y replicación entre regiones habilitada.",
            "2": "Amazon S3 con políticas de ciclo de vida para la gestión de datos y versionado habilitadas.",
            "3": "Amazon FSx for Lustre con replicación de datos entre múltiples Zonas de Disponibilidad.",
            "4": "Amazon S3 con S3 Transfer Acceleration y replicación entre regiones habilitada."
        },
        "Correct Answer": "Amazon FSx for Lustre con replicación de datos entre múltiples Zonas de Disponibilidad.",
        "Explanation": "Amazon FSx for Lustre está optimizado para alto rendimiento y baja latencia, lo que lo hace adecuado para aplicaciones de procesamiento de datos. Soporta la replicación de datos, lo que mejora la durabilidad y disponibilidad entre múltiples Zonas de Disponibilidad.",
        "Other Options": [
            "Amazon S3 con S3 Transfer Acceleration y replicación entre regiones habilitada no es la mejor opción, ya que es principalmente almacenamiento de objetos y puede no proporcionar la baja latencia requerida para aplicaciones de procesamiento de datos.",
            "Amazon EFS con rendimiento provisionado y replicación entre regiones habilitada es más adecuado para almacenamiento de archivos, pero puede no ofrecer el alto rendimiento necesario para cargas de trabajo intensivas de procesamiento de datos.",
            "Amazon S3 con políticas de ciclo de vida para la gestión de datos y versionado habilitadas no cumple con los requisitos de rendimiento de alto rendimiento y baja latencia para aplicaciones de procesamiento de datos."
        ]
    },
    {
        "Question Number": "44",
        "Situation": "Una empresa tiene una aplicación de procesamiento de datos en tiempo real que ingiere y procesa datos de eventos de varios dispositivos IoT. La arquitectura actual consiste en múltiples instancias de Amazon EC2 que ejecutan un marco de procesamiento de datos, pero la empresa quiere reducir costos y simplificar operaciones al migrar a una arquitectura sin servidor.",
        "Question": "¿Cuál es el enfoque más efectivo para transitar esta aplicación a una arquitectura sin servidor mientras se mantienen las capacidades de procesamiento en tiempo real?",
        "Options": {
            "1": "Migrar el procesamiento de datos a AWS Batch con instancias EC2 Spot para manejar los eventos de datos entrantes. Usar Amazon SNS para notificar a los trabajos de Batch sobre nuevos eventos.",
            "2": "Implementar un clúster de Amazon Elastic MapReduce (EMR) con capacidades sin servidor para manejar el procesamiento de datos de eventos. Usar Amazon DynamoDB para almacenar los resultados.",
            "3": "Usar funciones de AWS Lambda con Amazon Kinesis Data Streams para procesar los datos de eventos en tiempo real. Configurar el flujo de Kinesis para activar las funciones de Lambda para cada evento de datos.",
            "4": "Utilizar Amazon SQS para almacenar en búfer los datos de eventos y configurar una flota de instancias de AWS EC2 para sondear la cola SQS para su procesamiento. Usar Auto Scaling para gestionar las instancias EC2."
        },
        "Correct Answer": "Usar funciones de AWS Lambda con Amazon Kinesis Data Streams para procesar los datos de eventos en tiempo real. Configurar el flujo de Kinesis para activar las funciones de Lambda para cada evento de datos.",
        "Explanation": "Usar AWS Lambda con Amazon Kinesis Data Streams proporciona una arquitectura sin servidor completamente gestionada que puede escalar fácilmente para manejar el procesamiento de datos en tiempo real. Este enfoque minimiza la sobrecarga operativa mientras asegura baja latencia y respuesta inmediata a los eventos entrantes.",
        "Other Options": [
            "Migrar a AWS Batch con instancias EC2 Spot aún requeriría gestionar instancias EC2, lo que no cumple con el objetivo de adoptar una arquitectura sin servidor.",
            "Usar Amazon SQS con una flota de instancias EC2 requiere gestión continua de esas instancias y no aprovecha los beneficios de un enfoque verdaderamente sin servidor, lo que lleva a mayores costos y complejidad operativa.",
            "Implementar un clúster de Amazon EMR, aunque puede procesar grandes conjuntos de datos, no es inherentemente sin servidor y requeriría gestión y configuración adicionales, lo que va en contra del objetivo de simplificar las operaciones."
        ]
    },
    {
        "Question Number": "45",
        "Situation": "Una empresa de servicios financieros está desarrollando una aplicación sin servidor para procesar transacciones en tiempo real. El arquitecto de soluciones ha decidido usar el AWS Serverless Application Model (AWS SAM) para la implementación. La aplicación requiere múltiples funciones de AWS Lambda, un API Gateway y permisos de IAM para acceder a los recursos de AWS. El arquitecto quiere asegurarse de que el proceso de implementación sea eficiente y manejable.",
        "Question": "¿Cuál de los siguientes enfoques permitirá al arquitecto definir e implementar la aplicación sin servidor usando AWS SAM mientras mantiene una estructura limpia y comprensible en la plantilla?",
        "Options": {
            "1": "Definir cada función de AWS Lambda y sus recursos asociados en plantillas separadas de AWS SAM, y luego implementar manualmente cada plantilla para crear la aplicación.",
            "2": "Usar AWS SAM para crear un único stack de AWS CloudFormation que incluya todos los recursos requeridos para la aplicación, definiendo cada recurso en el mismo archivo de plantilla.",
            "3": "Utilizar AWS SAM para crear un stack de CloudFormation separado para cada función Lambda y sus recursos, vinculándolos juntos con salidas e importaciones.",
            "4": "Aprovechar las capacidades integradas de AWS SAM para definir la aplicación sin servidor en una sola plantilla utilizando la sección 'Resources' para funciones Lambda, API Gateway y roles de IAM necesarios."
        },
        "Correct Answer": "Aprovechar las capacidades integradas de AWS SAM para definir la aplicación sin servidor en una sola plantilla utilizando la sección 'Resources' para funciones Lambda, API Gateway y roles de IAM necesarios.",
        "Explanation": "Este enfoque utiliza efectivamente AWS SAM para gestionar toda la aplicación sin servidor dentro de una sola plantilla, proporcionando una estructura clara y simplificando el proceso de implementación a través del uso de recursos de SAM como funciones Lambda e integración con API Gateway.",
        "Other Options": [
            "Esta opción podría llevar a un proceso de implementación complicado y dificultar la gestión de dependencias y configuraciones entre múltiples recursos, negando los beneficios de usar AWS SAM.",
            "Implementar plantillas separadas para cada función puede complicar el proceso de implementación y aumentar la sobrecarga, lo cual no es ideal para una arquitectura sin servidor que AWS SAM busca simplificar.",
            "Si bien crear stacks separados puede ser útil en algunos escenarios, añade complejidad en la gestión de las interacciones entre diferentes recursos y puede llevar a una experiencia de implementación más fragmentada."
        ]
    },
    {
        "Question Number": "46",
        "Situation": "Una empresa global de comercio electrónico ha desplegado su aplicación web en múltiples Regiones de AWS para garantizar alta disponibilidad y baja latencia para los usuarios de todo el mundo. Han implementado AWS Global Accelerator para dirigir el tráfico entrante a sus Application Load Balancers en cada Región. Sin embargo, notan un rendimiento inconsistente durante los picos de tráfico y buscan soluciones para optimizar su configuración. (Seleccione Dos)",
        "Question": "¿Cuál de las siguientes configuraciones ayudará a mejorar el rendimiento y la disponibilidad de la aplicación? (Seleccione Dos)",
        "Options": {
            "1": "Implementar AWS Shield Advanced para proporcionar protección DDoS mejorada para sus puntos finales de Global Accelerator.",
            "2": "Configurar Global Accelerator con dos direcciones IP estáticas y habilitar la función Anycast para enrutar el tráfico a la Región más cercana.",
            "3": "Utilizar Amazon CloudFront como una capa de caché frente a la aplicación para reducir la latencia para los usuarios globales.",
            "4": "Configurar verificaciones de salud en Global Accelerator para asegurar que el tráfico solo se envíe a puntos finales saludables en todas las Regiones.",
            "5": "Desplegar Application Load Balancers adicionales en cada Región para manejar el aumento de tráfico durante los picos."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Configurar Global Accelerator con dos direcciones IP estáticas y habilitar la función Anycast para enrutar el tráfico a la Región más cercana.",
            "Configurar verificaciones de salud en Global Accelerator para asegurar que el tráfico solo se envíe a puntos finales saludables en todas las Regiones."
        ],
        "Explanation": "Configurar Global Accelerator con Anycast permite que el tráfico se enrute al punto final saludable más cercano, mejorando el rendimiento y la disponibilidad. Además, configurar verificaciones de salud asegura que los usuarios no sean dirigidos a puntos finales no saludables, mejorando aún más la confiabilidad de la aplicación.",
        "Other Options": [
            "Si bien desplegar Application Load Balancers adicionales puede ayudar a manejar el aumento de tráfico, no aborda directamente los beneficios de enrutamiento y rendimiento que proporciona Global Accelerator.",
            "Implementar AWS Shield Advanced proporciona protección DDoS, pero no optimiza el enrutamiento del tráfico o el rendimiento directamente a través de Global Accelerator.",
            "Utilizar Amazon CloudFront puede reducir la latencia, pero es un servicio separado y no aprovecha los beneficios de las capacidades de enrutamiento de Global Accelerator."
        ]
    },
    {
        "Question Number": "47",
        "Situation": "Una empresa de servicios financieros opera múltiples VPCs en diferentes regiones para gestionar datos sensibles de clientes. La empresa necesita establecer conectividad segura y eficiente entre estas VPCs para la comunicación de aplicaciones, minimizando la latencia y el costo. El arquitecto de soluciones tiene la tarea de evaluar las mejores opciones de conectividad para cumplir con estos requisitos.",
        "Question": "¿Cuál de las siguientes soluciones aborda mejor las necesidades de conectividad entre múltiples VPCs mientras asegura seguridad y baja latencia?",
        "Options": {
            "1": "Configurar conexiones VPN entre cada par de VPCs, asegurando comunicación encriptada, pero resultando en una gestión compleja y posibles problemas de rendimiento.",
            "2": "Utilizar AWS Direct Connect para establecer una conexión dedicada a cada VPC, proporcionando baja latencia pero requiriendo una inversión significativa en infraestructura y gestión.",
            "3": "Crear conexiones de emparejamiento de VPC entre todas las VPCs, configurando manualmente las tablas de enrutamiento para cada conexión para asegurar un flujo de tráfico adecuado mientras se mantiene la seguridad.",
            "4": "Usar AWS Transit Gateway para interconectar las VPCs, permitiendo la gestión centralizada de las conexiones y permitiendo una comunicación escalable y segura entre todas las VPCs."
        },
        "Correct Answer": "Usar AWS Transit Gateway para interconectar las VPCs, permitiendo la gestión centralizada de las conexiones y permitiendo una comunicación escalable y segura entre todas las VPCs.",
        "Explanation": "AWS Transit Gateway simplifica el proceso de interconectar múltiples VPCs al proporcionar un hub central que permite un enrutamiento y gestión eficientes. Soporta miles de VPCs y permite una comunicación escalable y segura, lo que lo convierte en la mejor opción para este escenario.",
        "Other Options": [
            "Crear conexiones de emparejamiento de VPC puede volverse complejo y engorroso a medida que aumenta el número de VPCs, lo que lleva a una sobrecarga de gestión y posibles problemas de enrutamiento.",
            "Configurar conexiones VPN entre cada par de VPCs añade una complejidad significativa y posibles cuellos de botella de rendimiento, ya que cada conexión debe ser gestionada individualmente.",
            "Utilizar AWS Direct Connect requiere una inversión sustancial en infraestructura y gestión continua, lo que lo hace menos adecuado para escenarios donde la flexibilidad y los costos más bajos son prioridades."
        ]
    },
    {
        "Question Number": "48",
        "Situation": "Una empresa global está migrando sus aplicaciones a AWS y quiere implementar una estrategia de múltiples cuentas utilizando AWS Organizations. El objetivo es mejorar la seguridad, simplificar la facturación y gestionar los recursos de manera efectiva entre varios equipos y departamentos.",
        "Question": "¿Cuál de las siguientes estrategias debería recomendar el arquitecto de soluciones para crear un entorno AWS de múltiples cuentas seguro y eficiente que satisfaga las necesidades de la organización?",
        "Options": {
            "1": "Crear una cuenta separada para cada equipo de aplicación y aplicar etiquetado de recursos para la gestión de costos.",
            "2": "Consolidar todas las cuentas en una sola cuenta para simplificar la facturación y la gestión de recursos.",
            "3": "Usar un solo rol de IAM para todas las cuentas para gestionar permisos de manera uniforme en toda la organización.",
            "4": "Implementar Políticas de Control de Servicio (SCPs) en AWS Organizations para hacer cumplir la gobernanza entre cuentas."
        },
        "Correct Answer": "Implementar Políticas de Control de Servicio (SCPs) en AWS Organizations para hacer cumplir la gobernanza entre cuentas.",
        "Explanation": "Implementar Políticas de Control de Servicio (SCPs) permite a la organización definir límites de permisos a través de múltiples cuentas, asegurando que las cuentas solo puedan acceder a los servicios de AWS que son necesarios para sus funciones específicas. Esto mejora la seguridad y el cumplimiento mientras permite una gestión centralizada.",
        "Other Options": [
            "Consolidar todas las cuentas en una sola cuenta elimina los beneficios de aislamiento y seguridad que provienen de una estrategia de múltiples cuentas, como limitar el radio de explosión y controles de acceso más granulares.",
            "Usar un solo rol de IAM para todas las cuentas no es una buena práctica porque puede llevar a un acceso excesivamente permisivo y no aprovecha los beneficios de la separación de cuentas y políticas de IAM distintas adaptadas a roles o equipos específicos.",
            "Crear una cuenta separada para cada equipo de aplicación y aplicar etiquetado de recursos por sí solo no hace cumplir políticas de gobernanza o seguridad de manera efectiva. Si bien el etiquetado es útil para la gestión de costos, no proporciona los controles necesarios que ofrecen las SCPs."
        ]
    },
    {
        "Question Number": "49",
        "Situation": "Una firma de servicios financieros ha desplegado una aplicación crítica en AWS que está experimentando interrupciones intermitentes. Se ha encargado al arquitecto de soluciones mejorar la confiabilidad de la aplicación para asegurar un rendimiento y disponibilidad consistentes. La arquitectura actual incluye instancias de EC2 en un Grupo de Auto Scaling a través de múltiples Zonas de Disponibilidad. El arquitecto necesita recomendar estrategias para mejorar la confiabilidad.",
        "Question": "¿Cuál de las siguientes estrategias debería implementar el arquitecto para mejorar la confiabilidad? (Seleccione Dos)",
        "Options": {
            "1": "Usar funciones de AWS Lambda para manejar tareas asíncronas y reducir la carga en la aplicación principal.",
            "2": "Desplegar Amazon RDS en una configuración Multi-AZ para proporcionar alta disponibilidad para la capa de base de datos.",
            "3": "Implementar AWS Global Accelerator para enrutar el tráfico y mejorar la disponibilidad entre regiones.",
            "4": "Configurar una verificación de salud de Amazon Route 53 para monitorear los puntos finales de la aplicación y activar la conmutación por error.",
            "5": "Configurar Amazon CloudFront para almacenar en caché contenido estático y reducir la carga en los servidores de origen."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Desplegar Amazon RDS en una configuración Multi-AZ para proporcionar alta disponibilidad para la capa de base de datos.",
            "Configurar una verificación de salud de Amazon Route 53 para monitorear los puntos finales de la aplicación y activar la conmutación por error."
        ],
        "Explanation": "Desplegar Amazon RDS en una configuración Multi-AZ asegura que haya una instancia de respaldo disponible en caso de falla de la instancia principal, mejorando así la confiabilidad de la base de datos. Además, configurar una verificación de salud de Amazon Route 53 permite el monitoreo automatizado de los puntos finales de la aplicación y puede facilitar la conmutación por error a instancias saludables en caso de interrupciones, mejorando aún más la confiabilidad.",
        "Other Options": [
            "Implementar AWS Global Accelerator puede mejorar el rendimiento y reducir la latencia, pero no mejora directamente la confiabilidad de la aplicación en sí.",
            "Configurar Amazon CloudFront es beneficioso para el almacenamiento en caché y puede mejorar el rendimiento, pero no aborda las preocupaciones centrales de confiabilidad relacionadas con la aplicación y la base de datos.",
            "Usar funciones de AWS Lambda puede ayudar a descargar tareas, pero no mejora inherentemente la confiabilidad de la aplicación principal, ya que es un servicio separado."
        ]
    },
    {
        "Question Number": "50",
        "Situation": "Una empresa de servicios financieros está migrando sus aplicaciones a AWS y necesita una forma confiable de gestionar información sensible como credenciales de bases de datos, claves de API y otros secretos. La empresa requiere una solución que se integre sin problemas con sus servicios existentes de AWS, proporcione control de acceso y asegure el almacenamiento y recuperación seguros de secretos sin codificarlos en el código de la aplicación. (Seleccione Dos)",
        "Question": "¿Cuál de las siguientes soluciones debería implementar el arquitecto de soluciones para cumplir con los requisitos de la empresa para la gestión de secretos?",
        "Options": {
            "1": "Implementar AWS Systems Manager Parameter Store con cifrado para almacenar secretos y parámetros.",
            "2": "Almacenar información sensible en Amazon S3 con cifrado del lado del servidor habilitado.",
            "3": "Usar AWS Secrets Manager para almacenar y gestionar toda la información sensible de manera segura.",
            "4": "Usar roles de IAM para incrustar credenciales directamente en el código de la aplicación para facilitar el acceso.",
            "5": "Desplegar una solución de bóveda autohospedada en instancias de EC2 para la gestión de secretos."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Usar AWS Secrets Manager para almacenar y gestionar toda la información sensible de manera segura.",
            "Implementar AWS Systems Manager Parameter Store con cifrado para almacenar secretos y parámetros."
        ],
        "Explanation": "AWS Secrets Manager permite el almacenamiento y gestión seguros de información sensible con integración incorporada para varios servicios de AWS, mientras que AWS Systems Manager Parameter Store proporciona una solución escalable para almacenar datos de configuración y secretos, con la opción de cifrado. Ambos servicios cumplen con los requisitos de la empresa para el acceso seguro y la gestión de información sensible.",
        "Other Options": [
            "Almacenar información sensible en Amazon S3, incluso con cifrado, no proporciona el mismo nivel de control de acceso y características de gestión que Secrets Manager o Parameter Store, lo que lo hace menos adecuado para la gestión de secretos.",
            "Incrustar credenciales directamente en el código de la aplicación compromete la seguridad y no permite una fácil rotación o gestión de secretos, lo cual va en contra de las mejores prácticas.",
            "Una solución de bóveda autohospedada añade sobrecarga operativa y complejidad, lo que puede no ser necesario cuando los servicios gestionados de AWS proporcionan capacidades robustas de gestión de secretos."
        ]
    },
    {
        "Question Number": "51",
        "Situation": "Una empresa de servicios financieros depende de una aplicación heredada alojada en las instalaciones que maneja transacciones de clientes. La aplicación es crítica para las operaciones diarias, pero carece de escalabilidad y agilidad. La dirección ha decidido migrar la aplicación a AWS para mejorar el rendimiento y reducir los costos operativos. Buscan una solución que permita la modernización de la aplicación mientras se minimiza la interrupción de los servicios existentes.",
        "Question": "¿Cuál de las siguientes estrategias debería recomendar el Arquitecto de Soluciones para modernizar la aplicación de manera efectiva mientras se asegura una transición suave?",
        "Options": {
            "1": "Levantar y trasladar toda la aplicación a instancias de Amazon EC2 y refactorizar gradualmente la aplicación según sea necesario para aprovechar los servicios de AWS.",
            "2": "Recrear toda la aplicación utilizando AWS Lambda y arquitectura de microservicios para aprovechar completamente las capacidades sin servidor desde el principio.",
            "3": "Migrar la base de datos a Amazon RDS y mantener la aplicación heredada en las instalaciones mientras se transiciona gradualmente a una solución nativa de la nube.",
            "4": "Contenerizar la aplicación y desplegarla en Amazon ECS, luego refactorizar la aplicación en microservicios con el tiempo para mejorar la escalabilidad."
        },
        "Correct Answer": "Contenerizar la aplicación y desplegarla en Amazon ECS, luego refactorizar la aplicación en microservicios con el tiempo para mejorar la escalabilidad.",
        "Explanation": "Contenerizar la aplicación permite una mejor utilización de recursos y una gestión más fácil de las dependencias. Usar Amazon ECS permite a la empresa orquestar contenedores de manera efectiva, y la refactorización gradual en microservicios permite una modernización incremental sin una revisión completa, minimizando la interrupción.",
        "Other Options": [
            "Levantar y trasladar puede no proporcionar los mejores beneficios de las características nativas de la nube, y a menudo conduce a continuar con ineficiencias existentes sin modernizar la aplicación.",
            "Recrear toda la aplicación desde cero es un enfoque arriesgado y que consume recursos que podría llevar a tiempos de inactividad prolongados y mayores costos sin garantizar beneficios inmediatos.",
            "Mantener la aplicación heredada en las instalaciones mientras se migra la base de datos no aprovecha efectivamente las capacidades de la nube y puede complicar el proceso de modernización al mantener dependencias heredadas."
        ]
    },
    {
        "Question Number": "52",
        "Situation": "Una empresa de servicios financieros está diseñando una arquitectura de microservicios en AWS. El arquitecto de soluciones necesita asegurarse de que los diversos servicios puedan comunicarse de manera segura y eficiente utilizando puntos finales de servicio. La empresa tiene estrictos requisitos de cumplimiento que dictan el uso de conectividad privada a los servicios internos.",
        "Question": "¿Cuál de las siguientes configuraciones debería implementar el arquitecto de soluciones para habilitar integraciones de servicio seguras mientras cumple con los requisitos de cumplimiento? (Seleccione Dos)",
        "Options": {
            "1": "Configurar VPC Peering entre sus servicios para permitir conectividad directa dentro de sus VPCs mientras se mantiene el cumplimiento.",
            "2": "Configurar AWS Transit Gateway para conectar múltiples VPCs y redes locales, facilitando la comunicación segura para sus microservicios.",
            "3": "Utilizar AWS PrivateLink para crear puntos finales privados para sus servicios, asegurando que el tráfico no atraviese Internet público.",
            "4": "Utilizar Amazon API Gateway con una interfaz web para exponer sus servicios públicamente, permitiendo un fácil acceso por parte de clientes externos.",
            "5": "Implementar AWS Direct Connect para establecer una conexión de red dedicada desde su centro de datos local a AWS."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Utilizar AWS PrivateLink para crear puntos finales privados para sus servicios, asegurando que el tráfico no atraviese Internet público.",
            "Configurar AWS Transit Gateway para conectar múltiples VPCs y redes locales, facilitando la comunicación segura para sus microservicios."
        ],
        "Explanation": "AWS PrivateLink proporciona conectividad privada entre VPCs y servicios, asegurando que los datos no salgan de la red de AWS, cumpliendo así con los requisitos de cumplimiento. AWS Transit Gateway simplifica el proceso de conectar múltiples VPCs y redes locales de manera segura, facilitando la gestión de las comunicaciones entre servicios en una arquitectura de microservicios.",
        "Other Options": [
            "VPC Peering es una opción válida para conectividad directa; sin embargo, puede volverse complejo de gestionar a medida que aumenta el número de VPCs y no aborda inherentemente el cumplimiento tan bien como PrivateLink.",
            "Amazon API Gateway está diseñado para acceso público a los servicios, lo que contradice el requisito de conectividad privada y cumplimiento en este escenario.",
            "AWS Direct Connect es útil para conexiones dedicadas, pero no aborda las integraciones de servicio a servicio dentro de una arquitectura de VPC tan eficazmente como PrivateLink y Transit Gateway."
        ]
    },
    {
        "Question Number": "53",
        "Situation": "Una empresa de servicios financieros utiliza Amazon RDS para PostgreSQL para gestionar su base de datos transaccional. La base de datos contiene información sensible de clientes y es crítica para las operaciones diarias. La empresa necesita asegurarse de que los datos se repliquen en múltiples regiones para recuperación ante desastres y cumplimiento. Requieren un RTO de 1 hora y un RPO de 10 minutos.",
        "Question": "¿Cuál de las siguientes opciones debería implementar el Arquitecto de Soluciones para cumplir con los requisitos de la empresa de manera efectiva? (Seleccione Dos)",
        "Options": {
            "1": "Crear una réplica de lectura de la instancia RDS en la misma región para permitir una recuperación rápida.",
            "2": "Programar copias de seguridad automatizadas de la instancia RDS a un bucket de S3 en otra región cada 10 minutos.",
            "3": "Implementar AWS Database Migration Service (DMS) para replicar continuamente datos a una base de datos de destino en otra región.",
            "4": "Utilizar instantáneas de Amazon RDS para realizar copias de seguridad manuales y copiarlas a otra región una vez cada hora.",
            "5": "Habilitar la replicación entre regiones de Amazon RDS para replicar cambios en la base de datos a otra región."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Habilitar la replicación entre regiones de Amazon RDS para replicar cambios en la base de datos a otra región.",
            "Implementar AWS Database Migration Service (DMS) para replicar continuamente datos a una base de datos de destino en otra región."
        ],
        "Explanation": "Habilitar la replicación entre regiones de Amazon RDS permite la replicación casi en tiempo real de los cambios a otra región, cumpliendo con el requisito de RPO de 10 minutos. Además, utilizar AWS DMS para la replicación continua proporciona una forma efectiva de asegurar que los datos estén siempre actualizados en la región de destino, lo cual es esencial para la planificación de recuperación ante desastres.",
        "Other Options": [
            "Crear una réplica de lectura en la misma región no proporciona recuperación ante desastres entre regiones y no cumple con el requisito de replicación de datos a otra región.",
            "Las copias de seguridad automatizadas a S3 cada 10 minutos podrían cumplir con el RPO, pero no permiten una conmutación por error inmediata ya que requieren un proceso de restauración manual que no cumpliría con el requisito de RTO.",
            "Utilizar instantáneas de Amazon RDS para copias de seguridad manuales una vez por hora no cumpliría con el requisito de RPO de 10 minutos, ya que los cambios de datos podrían perderse entre las instantáneas."
        ]
    },
    {
        "Question Number": "54",
        "Situation": "Una empresa está ejecutando una aplicación crítica en AWS que requiere alta disponibilidad. Actualmente tienen una base de datos primaria en una región de AWS y quieren implementar una estrategia para la conmutación por error automática a una base de datos secundaria en otra región en caso de una falla.",
        "Question": "¿Qué enfoque proporcionará la conmutación por error automática más confiable para la base de datos mientras minimiza el tiempo de inactividad?",
        "Options": {
            "1": "Utilizar Amazon Aurora Global Database para capacidades de conmutación por error entre regiones.",
            "2": "Usar Amazon RDS con implementaciones Multi-AZ para conmutación por error automática.",
            "3": "Implementar una réplica de lectura en otra región y promoverla durante una falla.",
            "4": "Configurar un servicio de migración de base de datos para replicar continuamente datos a otra región."
        },
        "Correct Answer": "Utilizar Amazon Aurora Global Database para capacidades de conmutación por error entre regiones.",
        "Explanation": "Amazon Aurora Global Database está diseñado para replicación entre regiones y proporciona lecturas de baja latencia y capacidades de conmutación por error automática. Esto lo convierte en la opción más confiable para minimizar el tiempo de inactividad y asegurar alta disponibilidad a través de las regiones.",
        "Other Options": [
            "Amazon RDS con implementaciones Multi-AZ proporciona conmutación por error automática dentro de una sola región, pero no admite la conmutación por error a otra región, lo que lo hace inadecuado para alta disponibilidad entre regiones.",
            "Implementar una réplica de lectura en otra región requiere intervención manual para promoverla a primaria, lo que puede resultar en tiempo de inactividad adicional durante el proceso de conmutación por error.",
            "Configurar un servicio de migración de base de datos para replicación continua es una opción viable, pero introduce complejidad y posibles retrasos en la conmutación por error, lo que puede no cumplir con los requisitos de alta disponibilidad."
        ]
    },
    {
        "Question Number": "55",
        "Situation": "Una empresa de servicios financieros ejecuta varias aplicaciones críticas en AWS. Necesitan asegurarse de que sus aplicaciones estén funcionando de manera óptima y que cualquier problema potencial sea detectado y resuelto de manera rápida. La empresa tiene estrictos requisitos de cumplimiento, lo que requiere mecanismos de registro y alerta detallados para todas las operaciones. El equipo de TI quiere implementar una estrategia de monitoreo que minimice la intervención manual mientras asegura una visibilidad completa del rendimiento y la salud del sistema.",
        "Question": "¿Cuál de las siguientes soluciones proporciona el sistema de monitoreo y alerta más efectivo para las aplicaciones de la empresa con la menor supervisión manual?",
        "Options": {
            "1": "Utilizar AWS CloudTrail para rastrear llamadas a la API y registrarlas en Amazon S3. Configurar funciones de AWS Lambda para analizar los registros y enviar alertas basadas en criterios predefinidos.",
            "2": "Aprovechar Amazon CloudWatch Service Lens para monitorear el rendimiento de la aplicación, detectar automáticamente anomalías e integrarse con AWS Config para asegurar el cumplimiento y alertar sobre cambios de configuración.",
            "3": "Implementar AWS X-Ray para rastrear solicitudes en las aplicaciones para visualizar cuellos de botella en el rendimiento y configurar Amazon SNS para enviar notificaciones basadas en las anomalías de X-Ray.",
            "4": "Configurar Amazon CloudWatch para rastrear métricas personalizadas y crear alarmas para umbrales de rendimiento. Usar CloudWatch Logs para agregar registros de la aplicación y configurar alertas para patrones de registro específicos."
        },
        "Correct Answer": "Aprovechar Amazon CloudWatch Service Lens para monitorear el rendimiento de la aplicación, detectar automáticamente anomalías e integrarse con AWS Config para asegurar el cumplimiento y alertar sobre cambios de configuración.",
        "Explanation": "Amazon CloudWatch Service Lens proporciona una solución de monitoreo integral que monitorea el rendimiento de la aplicación, detecta anomalías automáticamente e integra con AWS Config para la gestión del cumplimiento, lo que lo convierte en la opción más eficiente para minimizar la supervisión manual.",
        "Other Options": [
            "Configurar Amazon CloudWatch para métricas personalizadas y alarmas requiere cierta configuración y mantenimiento manual, lo que lo hace menos eficiente que una solución completamente integrada como Service Lens.",
            "AWS X-Ray es excelente para rastrear problemas de rendimiento, pero no proporciona un monitoreo y alerta integral para los requisitos de cumplimiento, que la empresa necesita.",
            "Usar AWS CloudTrail se centra principalmente en rastrear llamadas a la API en lugar del rendimiento de la aplicación, y aunque Lambda puede procesar registros, requiere configuración adicional y no ofrece capacidades de monitoreo directo."
        ]
    },
    {
        "Question Number": "56",
        "Situation": "Una organización de servicios financieros utiliza AWS IAM para gestionar el acceso de sus empleados y proveedores externos. La organización requiere una estricta adherencia a las políticas de seguridad y necesita asegurarse de que los usuarios solo tengan acceso a los recursos que requieren para sus roles específicos. Además, la organización quiere implementar acceso temporal para contratistas que expirará automáticamente después de que se complete su proyecto.",
        "Question": "¿Cuál de las siguientes soluciones de IAM debería implementar el Arquitecto de Soluciones para cumplir con los requisitos de la organización?",
        "Options": {
            "1": "Utilizar grupos de IAM para gestionar los permisos de los usuarios agrupando a empleados y contratistas según sus requisitos de acceso. Crear claves de acceso para contratistas que les permitan acceder a los recursos solo durante el horario laboral.",
            "2": "Crear cuentas de usuario de IAM para cada empleado y contratista, asignando a cada usuario una contraseña única y adjuntando políticas para permitir el acceso a recursos específicos. Usar una función Lambda programada para desactivar cuentas de contratistas después de la finalización del proyecto.",
            "3": "Crear roles de IAM para cada función laboral específica con políticas correspondientes. Asignar usuarios a estos roles según sus requisitos laborales. Para contratistas, crear un rol con una relación de confianza que les permita asumir el rol temporalmente, asegurando que el rol tenga una duración máxima de sesión que se alinee con el cronograma del proyecto.",
            "4": "Implementar políticas de IAM que estén adjuntas a un grupo de usuarios central para empleados y contratistas. Establecer permisos basados en etiquetas asignadas a los recursos, asegurando que los contratistas solo puedan acceder a recursos con las etiquetas apropiadas."
        },
        "Correct Answer": "Crear roles de IAM para cada función laboral específica con políticas correspondientes. Asignar usuarios a estos roles según sus requisitos laborales. Para contratistas, crear un rol con una relación de confianza que les permita asumir el rol temporalmente, asegurando que el rol tenga una duración máxima de sesión que se alinee con el cronograma del proyecto.",
        "Explanation": "Crear roles de IAM para cada función laboral permite un control preciso sobre los permisos. Al permitir que los contratistas asuman un rol temporalmente, se puede asegurar que el acceso se adapte a sus necesidades mientras se adhiere a las mejores prácticas de seguridad. Además, establecer una duración máxima de sesión para los roles de contratistas asegura que su acceso esté automáticamente limitado al cronograma del proyecto.",
        "Other Options": [
            "Esta opción es incorrecta porque usar cuentas de usuario de IAM para contratistas sin un proceso de desactivación automatizado puede llevar a riesgos de seguridad si las cuentas no se gestionan adecuadamente. Una función Lambda programada agrega complejidad y podría dejar brechas en la seguridad.",
            "Esta opción es incorrecta ya que usar grupos de IAM no proporciona el control granular necesario para el acceso temporal. Las claves de acceso para contratistas también son menos seguras que el acceso basado en roles, ya que podrían no expirar automáticamente o podrían ser mal utilizadas.",
            "Esta opción es incorrecta porque usar políticas de IAM basadas en etiquetas no restringe inherentemente el acceso de manera sensible al tiempo. No proporciona el mecanismo necesario para asegurar que el acceso de los contratistas sea temporal."
        ]
    },
    {
        "Question Number": "57",
        "Situation": "Una aplicación de atención médica está alojada en AWS que almacena datos sensibles de pacientes en Amazon S3 y utiliza un API Gateway para acceder a servicios de backend. La aplicación debe cumplir con las regulaciones de HIPAA, que incluyen acceso seguro a los servicios de AWS mientras se mantiene la privacidad de los datos. El equipo quiere minimizar la exposición al acceso a Internet público y asegurar que todas las comunicaciones con los servicios de AWS sean seguras y privadas. La arquitectura ya incluye una Nube Privada Virtual (VPC) con múltiples subredes configuradas para alta disponibilidad.",
        "Question": "¿Cuál sería la configuración de servicio de AWS más efectiva para asegurar conectividad privada a Amazon S3 mientras se adhiere al cumplimiento de HIPAA para esta aplicación de atención médica?",
        "Options": {
            "1": "Configurar una conexión VPN entre la VPC y una red local, enroutando todo el tráfico de S3 a través de la VPN para mayor seguridad.",
            "2": "Desplegar un NAT Gateway en una subred pública y enrutar todo el tráfico de S3 a través de él para mantener la arquitectura de la aplicación privada.",
            "3": "Crear un punto de enlace de puerta de enlace para Amazon S3 y actualizar la tabla de rutas asociada con las subredes privadas para dirigir el tráfico destinado a S3 a través del punto de enlace.",
            "4": "Configurar un punto de enlace de interfaz para Amazon S3 y vincularlo al grupo de seguridad que controla el acceso a las instancias de la aplicación en las subredes privadas."
        },
        "Correct Answer": "Crear un punto de enlace de puerta de enlace para Amazon S3 y actualizar la tabla de rutas asociada con las subredes privadas para dirigir el tráfico destinado a S3 a través del punto de enlace.",
        "Explanation": "Crear un punto de enlace de puerta de enlace para Amazon S3 permite conectividad privada a S3 desde dentro de la VPC sin atravesar Internet público, lo cual es crítico para el cumplimiento de HIPAA. Esta configuración también simplifica el enrutamiento y mejora la seguridad al eliminar la necesidad de acceso público a S3.",
        "Other Options": [
            "Desplegar un NAT Gateway en una subred pública no proporcionaría la conectividad privada requerida a Amazon S3 y aún expondría el tráfico a Internet público, lo que no es conforme a las regulaciones de HIPAA.",
            "Configurar un punto de enlace de interfaz para Amazon S3 no es válido, ya que S3 solo admite puntos de enlace de puerta de enlace, que están diseñados específicamente para este servicio y proporcionan la conectividad privada necesaria.",
            "Configurar una conexión VPN no es la mejor solución para acceder a S3, ya que introduce complejidad y latencia innecesarias. Un punto de enlace de puerta de enlace es un método más eficiente y conforme para conectarse a S3 desde dentro de la VPC."
        ]
    },
    {
        "Question Number": "58",
        "Situation": "Un equipo de seguridad es responsable de garantizar la seguridad de sus cargas de trabajo en AWS. Quieren aprovechar Amazon Inspector para monitorear continuamente sus recursos en busca de vulnerabilidades y exposiciones no intencionadas. El equipo está particularmente enfocado en las instancias de Amazon EC2 y las funciones de AWS Lambda.",
        "Question": "¿Qué configuraciones debería implementar el equipo de seguridad para maximizar la efectividad de Amazon Inspector? (Seleccione dos)",
        "Options": {
            "1": "Desactivar el escaneo automático para las funciones de AWS Lambda para reducir la sobrecarga.",
            "2": "Instalar el agente de Amazon Inspector en todas las instancias de Amazon EC2 en ejecución.",
            "3": "Vincular Amazon Inspector con AWS CloudTrail para obtener registros detallados de todos los hallazgos.",
            "4": "Programar evaluaciones regulares de las instancias de Amazon EC2 utilizando Amazon Inspector.",
            "5": "Configurar Amazon Inspector para enviar automáticamente los hallazgos a AWS Security Hub."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Instalar el agente de Amazon Inspector en todas las instancias de Amazon EC2 en ejecución.",
            "Programar evaluaciones regulares de las instancias de Amazon EC2 utilizando Amazon Inspector."
        ],
        "Explanation": "Para evaluar completamente la seguridad de las instancias de Amazon EC2, es esencial instalar el agente de Amazon Inspector. Esto permite un análisis exhaustivo de las posibles vulnerabilidades. Además, programar evaluaciones regulares asegura que el equipo se mantenga alerta sobre la postura de seguridad de sus recursos y pueda abordar rápidamente cualquier problema identificado.",
        "Other Options": [
            "Desactivar el escaneo automático para las funciones de AWS Lambda reduciría la efectividad de la detección de vulnerabilidades, lo cual es contrario al objetivo de mantener un entorno seguro.",
            "Si bien vincular Amazon Inspector con AWS CloudTrail puede proporcionar algunos beneficios de registro, no mejora directamente el proceso de escaneo ni la efectividad de la gestión de vulnerabilidades.",
            "Configurar Amazon Inspector para enviar hallazgos a AWS Security Hub es beneficioso, pero no contribuye directamente a la evaluación inicial y el monitoreo de vulnerabilidades en las funciones de EC2 y Lambda."
        ]
    },
    {
        "Question Number": "59",
        "Situation": "Una empresa de servicios financieros está experimentando una mayor demanda para su aplicación web que procesa transacciones. La aplicación está actualmente desplegada en una sola instancia de Amazon EC2 y está teniendo dificultades para manejar la carga durante los picos de transacciones. La empresa quiere asegurar alta disponibilidad y rendimiento con cambios mínimos en la arquitectura existente.",
        "Question": "¿Cuál de las siguientes estrategias debería implementar un Arquitecto de Soluciones para mejorar la escalabilidad y confiabilidad de la aplicación?",
        "Options": {
            "1": "Migrar la aplicación a AWS Lambda para manejar el procesamiento de transacciones y usar Amazon API Gateway para el enrutamiento de solicitudes.",
            "2": "Actualizar la instancia de EC2 a un tipo de instancia más grande y configurar una Réplica de Lectura de Amazon RDS para descargar consultas de lectura de la base de datos principal.",
            "3": "Desplegar una instancia adicional de EC2 para compartir la carga y configurar Route 53 para la distribución de tráfico basada en DNS.",
            "4": "Implementar un grupo de Auto Scaling para las instancias de EC2 y usar un Elastic Load Balancer para distribuir el tráfico entrante de manera uniforme entre las instancias."
        },
        "Correct Answer": "Implementar un grupo de Auto Scaling para las instancias de EC2 y usar un Elastic Load Balancer para distribuir el tráfico entrante de manera uniforme entre las instancias.",
        "Explanation": "Usar un grupo de Auto Scaling combinado con un Elastic Load Balancer permite que la aplicación ajuste automáticamente su capacidad según la demanda, asegurando tanto escalabilidad como alta disponibilidad. Esta configuración garantiza que la aplicación pueda manejar cargas variables de manera eficiente.",
        "Other Options": [
            "Migrar a AWS Lambda requeriría cambios significativos en la arquitectura de la aplicación y puede no ser adecuado para todos los escenarios de procesamiento de transacciones, especialmente si la aplicación es con estado o requiere conexiones persistentes.",
            "Actualizar a una instancia de EC2 más grande puede proporcionar un alivio temporal, pero no aborda la preocupación de escalabilidad durante los picos, ya que una sola instancia aún puede convertirse en un cuello de botella y no proporciona redundancia.",
            "Desplegar una instancia adicional de EC2 mejoraría la distribución de carga hasta cierto punto, pero carece de las capacidades de escalado dinámico de un grupo de Auto Scaling y no asegura alta disponibilidad, ya que ambas instancias aún podrían fallar."
        ]
    },
    {
        "Question Number": "60",
        "Situation": "Una empresa tiene un grupo de Auto Scaling que gestiona múltiples instancias de EC2 para manejar cargas de trabajo variables. Quieren desacoplar una instancia del grupo de Auto Scaling para mantenimiento, asegurándose de que las instancias restantes continúen cumpliendo con la capacidad deseada. También quieren asegurarse de que la instancia se elimine correctamente de cualquier balanceador de carga asociado.",
        "Question": "¿Cuál es el enfoque correcto para desacoplar una instancia del grupo de Auto Scaling mientras se asegura que se desregistre de sus balanceadores de carga?",
        "Options": {
            "1": "Usar la API DetachInstances para eliminar la instancia del grupo de Auto Scaling y asegurarse de que el balanceador de carga también se desacople.",
            "2": "Desacoplar la instancia del grupo de Auto Scaling utilizando la API DetachLoadBalancers para asegurarse de que se elimine del balanceador de carga.",
            "3": "Suspender los procesos de escalado, desacoplar manualmente la instancia del grupo de Auto Scaling y luego desregistrarla del balanceador de carga.",
            "4": "Desacoplar la instancia utilizando la API DetachInstances, que manejará automáticamente la desregistración del balanceador de carga."
        },
        "Correct Answer": "Desacoplar la instancia utilizando la API DetachInstances, que manejará automáticamente la desregistración del balanceador de carga.",
        "Explanation": "Al usar la API DetachInstances, la instancia se elimina del grupo de Auto Scaling y se desregistrará de cualquier balanceador de carga asociado, asegurando que el grupo de escalado mantenga su capacidad deseada.",
        "Other Options": [
            "Esta opción sugiere incorrectamente usar la API DetachInstances mientras menciona la necesidad de asegurarse de que el balanceador de carga esté desacoplado, lo cual ya es manejado automáticamente por la API.",
            "Si bien suspender los procesos de escalado podría prevenir el reemplazo de instancias, no aborda la desregistración automática de los balanceadores de carga, lo que hace que este enfoque sea menos eficiente.",
            "La API DetachLoadBalancers solo desacopla Classic Load Balancers y no aborda el desacoplamiento de instancias del grupo de Auto Scaling, lo que hace que esta opción sea inválida."
        ]
    },
    {
        "Question Number": "61",
        "Situation": "Una empresa de servicios financieros está utilizando Amazon Redshift para sus necesidades de almacenamiento de datos. Experimentan problemas de rendimiento durante las horas pico cuando múltiples usuarios ejecutan consultas analíticas complejas. Los analistas de datos de la empresa a menudo se quejan de los largos tiempos de espera para que sus consultas se ejecuten. El equipo de arquitectura está explorando opciones para optimizar el rendimiento de las consultas mientras asegura que las consultas cortas puedan ejecutarse sin retrasos significativos.",
        "Question": "¿Cuál es la forma más efectiva de optimizar el rendimiento de las consultas en Amazon Redshift mientras se gestiona la concurrencia?",
        "Options": {
            "1": "Deshabilitar la gestión de carga de trabajo en Amazon Redshift para permitir que todas las consultas se ejecuten sin restricciones.",
            "2": "Aumentar el wlm_query_slot_count para permitir más consultas concurrentes y establecer clases de servicio apropiadas para diferentes tipos de consultas.",
            "3": "Implementar un sistema de programación de consultas para asegurar que las consultas de larga duración no afecten la ejecución de consultas cortas durante las horas pico.",
            "4": "Reducir el número de nodos en el clúster de Redshift para disminuir la contención de recursos entre consultas concurrentes."
        },
        "Correct Answer": "Aumentar el wlm_query_slot_count para permitir más consultas concurrentes y establecer clases de servicio apropiadas para diferentes tipos de consultas.",
        "Explanation": "Aumentar el wlm_query_slot_count permite que más consultas se ejecuten de manera concurrente, mejorando así el rendimiento general durante los momentos pico. Configurar adecuadamente las clases de servicio puede optimizar aún más las prioridades de ejecución, asegurando que las consultas cortas tengan prioridad sobre las de larga duración.",
        "Other Options": [
            "Reducir el número de nodos en el clúster de Redshift limitaría los recursos disponibles, lo que podría agravar los problemas de rendimiento en lugar de mejorarlos.",
            "Implementar un sistema de programación de consultas no es una característica directa de Amazon Redshift y puede introducir complejidad innecesaria sin abordar la causa raíz de los problemas de concurrencia.",
            "Deshabilitar la gestión de carga de trabajo significaría que no hay controles para gestionar la ejecución de consultas, lo que probablemente resultaría en tiempos de espera más largos para todas las consultas, especialmente durante el uso pico."
        ]
    },
    {
        "Question Number": "62",
        "Situation": "Un equipo de análisis de datos está procesando actualmente grandes conjuntos de datos utilizando Amazon EMR con Apache Spark. Quieren optimizar sus flujos de trabajo de procesamiento para reducir costos mientras mantienen un alto rendimiento. El equipo recupera datos frecuentemente de Amazon S3 y también necesita almacenar resultados intermedios para un análisis posterior. Están explorando opciones para mejorar la eficiencia de su clúster de EMR mientras gestionan costos.",
        "Question": "¿Cuál de las siguientes estrategias debería recomendar el arquitecto de soluciones para optimizar los costos de procesamiento de datos para el equipo que utiliza Amazon EMR?",
        "Options": {
            "1": "Lanzar el clúster de EMR solo con instancias bajo demanda para asegurar disponibilidad y confiabilidad, independientemente de las fluctuaciones de costos, y usar una instancia reservada para el nodo maestro.",
            "2": "Utilizar Amazon S3 para todas las necesidades de almacenamiento intermedio y configurar el trabajo de EMR para procesar datos en una sola etapa sin ningún intercambio de datos para minimizar los costos de transferencia de datos.",
            "3": "Programar clústeres de EMR para que se ejecuten solo durante horas no pico, aprovechando las instancias reservadas para gestionar costos de manera efectiva mientras se asegura que los datos estén disponibles para el procesamiento.",
            "4": "Usar instancias spot para el clúster de EMR para aprovechar los precios más bajos para cargas de trabajo no críticas y configurar el clúster para escalar automáticamente hacia adentro y hacia afuera según la demanda de carga de trabajo."
        },
        "Correct Answer": "Usar instancias spot para el clúster de EMR para aprovechar los precios más bajos para cargas de trabajo no críticas y configurar el clúster para escalar automáticamente hacia adentro y hacia afuera según la demanda de carga de trabajo.",
        "Explanation": "Usar instancias spot permite al equipo reducir significativamente los costos asociados con el clúster de EMR mientras mantiene la capacidad de escalar según los requisitos de carga de trabajo. Este enfoque es ideal para cargas de trabajo no críticas donde se pueden tolerar interrupciones. Escalar automáticamente el clúster según la demanda optimiza aún más los costos.",
        "Other Options": [
            "Lanzar el clúster de EMR solo con instancias bajo demanda asegurará confiabilidad, pero no optimizará los costos de manera efectiva, ya que las instancias bajo demanda son más caras que las instancias spot.",
            "Utilizar Amazon S3 para todo el almacenamiento intermedio es una buena práctica; sin embargo, procesar datos en una sola etapa sin intercambio puede no ser siempre factible para flujos de trabajo complejos, y puede llevar a una utilización ineficiente de los recursos.",
            "Programar clústeres de EMR para que se ejecuten durante horas no pico puede ayudar a gestionar costos, pero puede no ser práctico para todas las cargas de trabajo, especialmente si el procesamiento de datos necesita ocurrir en tiempo real o casi en tiempo real."
        ]
    },
    {
        "Question Number": "63",
        "Situation": "Una empresa de servicios financieros está migrando su almacenamiento de datos a AWS para mejorar la escalabilidad y reducir costos. Requieren una solución que les permita almacenar grandes volúmenes de datos no estructurados mientras asegura durabilidad y facilidad de acceso. Además, planean implementar una estrategia de respaldo que se integre sin problemas con su flujo de trabajo existente. Se le ha pedido al arquitecto de soluciones que recomiende servicios de almacenamiento de AWS que cumplan con estos requisitos. (Seleccione Dos)",
        "Question": "¿Cuáles de las siguientes soluciones de almacenamiento de AWS debería recomendar el arquitecto de soluciones para las necesidades de la empresa?",
        "Options": {
            "1": "Amazon S3 para almacenamiento de objetos duraderos y soluciones de respaldo, con políticas de ciclo de vida para gestionar datos.",
            "2": "Amazon FSx for Windows File Server para alojar aplicaciones basadas en Windows que requieren soporte para el protocolo SMB.",
            "3": "Amazon EBS para almacenamiento en bloque para proporcionar almacenamiento de alto rendimiento para instancias de EC2.",
            "4": "Amazon Elastic File System (EFS) para almacenamiento de archivos compartidos, permitiendo que múltiples instancias accedan a archivos simultáneamente.",
            "5": "AWS Storage Gateway para integrar entornos locales con almacenamiento en la nube para respaldo."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon S3 para almacenamiento de objetos duraderos y soluciones de respaldo, con políticas de ciclo de vida para gestionar datos.",
            "AWS Storage Gateway para integrar entornos locales con almacenamiento en la nube para respaldo."
        ],
        "Explanation": "Amazon S3 ofrece alta durabilidad, escalabilidad y gestión de ciclo de vida para datos no estructurados, lo que lo hace ideal para las necesidades de almacenamiento de la empresa. AWS Storage Gateway permite la integración sin problemas de entornos locales con almacenamiento en la nube, proporcionando una solución de respaldo que se alinea con los flujos de trabajo existentes de la empresa.",
        "Other Options": [
            "Amazon Elastic File System (EFS) es más adecuado para almacenamiento de archivos compartidos y puede no ser óptimo para grandes volúmenes de datos no estructurados que requieren una durabilidad extensa.",
            "Amazon FSx for Windows File Server está diseñado para aplicaciones de Windows que necesitan el protocolo SMB, lo cual puede no ser necesario para los requisitos de la empresa para el almacenamiento de datos no estructurados.",
            "Amazon EBS es efectivo para almacenamiento en bloque pero no está diseñado para el almacenamiento de datos no estructurados a gran escala como lo necesita la empresa."
        ]
    },
    {
        "Question Number": "64",
        "Situation": "Una empresa de servicios financieros está cambiando su estrategia de archivo de datos a AWS. La empresa maneja datos financieros sensibles y necesita una solución para almacenamiento a largo plazo que minimice costos mientras asegura el cumplimiento y un acceso rápido a los datos cuando sea necesario. El arquitecto de soluciones tiene la tarea de seleccionar una clase de almacenamiento de Amazon S3 adecuada para el archivo. Los datos se accederán con poca frecuencia, pero deben ser recuperables en minutos si es necesario.",
        "Question": "¿Cuál de las siguientes opciones es la solución más adecuada que cumple con los requisitos de la empresa?",
        "Options": {
            "1": "Utilizar S3 Glacier Flexible Retrieval para un ahorro óptimo de costos, permitiendo tiempos de recuperación de varias horas para datos menos críticos.",
            "2": "Almacenar los datos en S3 Standard para acceso frecuente y luego transferir a S3 Glacier cuando se vuelva menos relevante.",
            "3": "Usar S3 Glacier Instant Retrieval para acceso inmediato mientras se minimizan los costos de almacenamiento debido a la necesidad de acceso poco frecuente.",
            "4": "Implementar S3 Standard-IA para acceso poco frecuente y depender de procesos manuales para la recuperación de datos."
        },
        "Correct Answer": "Usar S3 Glacier Instant Retrieval para acceso inmediato mientras se minimizan los costos de almacenamiento debido a la necesidad de acceso poco frecuente.",
        "Explanation": "S3 Glacier Instant Retrieval está diseñado para datos que se acceden con poca frecuencia pero requieren recuperación inmediata. Esto se alinea perfectamente con la necesidad de la empresa de acceso rápido a los datos mientras mantiene bajos los costos de almacenamiento, lo que lo convierte en la opción óptima para su estrategia de archivo.",
        "Other Options": [
            "S3 Standard no es rentable para el archivo a largo plazo de datos a los que se accede con poca frecuencia, ya que incurre en costos de almacenamiento más altos que las opciones Glacier.",
            "S3 Glacier Flexible Retrieval es adecuado para el ahorro de costos, pero no cumple con el requisito de acceso inmediato, ya que puede tardar horas en recuperar datos.",
            "S3 Standard-IA está destinado para acceso poco frecuente, pero no proporciona el mismo nivel de ahorro de costos que las opciones Glacier para necesidades de almacenamiento a largo plazo."
        ]
    },
    {
        "Question Number": "65",
        "Situation": "Una empresa está utilizando AWS Lambda para procesar registros de un flujo de Amazon Kinesis. El arquitecto de soluciones necesita optimizar el procesamiento de datos para asegurar que la función Lambda se invoque con la configuración de agrupamiento más eficiente. La empresa requiere que la función Lambda pueda manejar el número máximo de registros en un lote sin exceder los límites de tamaño de carga útil.",
        "Question": "¿Cuál es el número máximo de registros que se pueden procesar en un solo lote por una función AWS Lambda al leer de un flujo de Amazon Kinesis?",
        "Options": {
            "1": "1,000 registros por lote",
            "2": "10,000 registros por lote",
            "3": "6 MB de tamaño de carga útil",
            "4": "2,000 registros por lote"
        },
        "Correct Answer": "1,000 registros por lote",
        "Explanation": "El tamaño máximo del lote para las funciones Lambda que procesan registros de un flujo de Amazon Kinesis es de 1,000 registros. Este límite asegura que la función no exceda el tamaño máximo de carga útil de 6 MB.",
        "Other Options": [
            "10,000 registros por lote es incorrecto porque el tamaño máximo del lote para Kinesis está limitado a 1,000 registros independientemente del tamaño de la carga útil.",
            "6 MB de tamaño de carga útil es incorrecto ya que se refiere al límite total de tamaño para la carga útil, pero no especifica el número máximo de registros procesados en un lote.",
            "2,000 registros por lote es incorrecto porque el tamaño máximo del lote para Kinesis está limitado a 1,000 registros, no 2,000."
        ]
    },
    {
        "Question Number": "66",
        "Situation": "Una empresa de servicios financieros está migrando sus aplicaciones a AWS. Han desplegado una mezcla de instancias EC2 para diferentes cargas de trabajo, incluyendo servidores web, servidores de aplicaciones y bases de datos. Después de monitorear el rendimiento y costo de sus instancias EC2 actuales, se dan cuenta de que algunas instancias están subutilizadas mientras que otras están sobreutilizadas. La empresa quiere optimizar sus recursos de AWS ajustando el tamaño de sus instancias EC2 para que se adapten mejor a sus cargas de trabajo. (Seleccionar Dos)",
        "Question": "¿Cuáles de las siguientes acciones ayudarán a la empresa a lograr un mejor ajuste de tamaño de sus instancias EC2?",
        "Options": {
            "1": "Implementar AWS Compute Optimizer para recibir recomendaciones para el ajuste de tamaño de instancias basado en patrones de utilización.",
            "2": "Realizar un análisis de costos de cada tipo de instancia y seleccionar la instancia más barata para todas las cargas de trabajo sin importar los requisitos de rendimiento.",
            "3": "Usar una función AWS Lambda para terminar automáticamente instancias que están funcionando por debajo de un umbral de utilización de CPU especificado.",
            "4": "Revisar los tipos de instancias EC2 utilizados para la capa de base de datos y migrar a un solo tipo de instancia para simplificar la gestión.",
            "5": "Analizar métricas de CloudWatch para identificar instancias EC2 subutilizadas y reducir su tamaño a tipos de instancia más pequeños."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Analizar métricas de CloudWatch para identificar instancias EC2 subutilizadas y reducir su tamaño a tipos de instancia más pequeños.",
            "Implementar AWS Compute Optimizer para recibir recomendaciones para el ajuste de tamaño de instancias basado en patrones de utilización."
        ],
        "Explanation": "Analizar métricas de CloudWatch permite a la empresa tomar decisiones basadas en datos para identificar instancias subutilizadas, que luego pueden ser reducidas de tamaño para ahorrar costos. Además, AWS Compute Optimizer proporciona recomendaciones automatizadas basadas en patrones de uso históricos, facilitando la identificación de oportunidades de ajuste de tamaño.",
        "Other Options": [
            "Si bien revisar los tipos de instancias puede ayudar, migrar a un solo tipo de instancia no aborda necesariamente la eficiencia de rendimiento o costo para cargas de trabajo diversas, lo que lo convierte en un enfoque ineficaz para el ajuste de tamaño.",
            "Usar una función Lambda para terminar instancias basándose únicamente en la utilización de CPU puede llevar a tiempos de inactividad no deseados para aplicaciones críticas, ya que no considera el rendimiento general o la naturaleza de las cargas de trabajo.",
            "Seleccionar el tipo de instancia más barato sin considerar requisitos de rendimiento específicos puede resultar en un rendimiento degradado de la aplicación, llevando a la insatisfacción del usuario y potencial pérdida de negocio."
        ]
    },
    {
        "Question Number": "67",
        "Situation": "Una empresa de servicios financieros ha desplegado varias aplicaciones en AWS que manejan datos sensibles de clientes. Para mejorar la seguridad y el cumplimiento, la empresa ha decidido implementar herramientas de seguridad de AWS que pueden ayudar a monitorear y evaluar sus entornos de AWS. El arquitecto de soluciones tiene la tarea de seleccionar las herramientas adecuadas que puedan proporcionar información sobre vulnerabilidades de seguridad, estado de cumplimiento y configuraciones de control de acceso. Necesitan una vista consolidada de alertas de seguridad y hallazgos a través de múltiples cuentas de AWS.",
        "Question": "¿Qué combinación de servicios de AWS satisfaría mejor los requisitos de la empresa para el monitoreo de seguridad y cumplimiento?",
        "Options": {
            "1": "AWS Security Hub, AWS CloudTrail, Amazon Inspector, AWS IAM Access Analyzer",
            "2": "Amazon CloudWatch, AWS Config, AWS Shield, AWS Firewall Manager",
            "3": "AWS Lambda, AWS Budgets, Amazon S3, AWS CloudFormation",
            "4": "AWS Trusted Advisor, Amazon GuardDuty, AWS WAF, AWS Systems Manager"
        },
        "Correct Answer": "AWS Security Hub, AWS CloudTrail, Amazon Inspector, AWS IAM Access Analyzer",
        "Explanation": "La combinación de AWS Security Hub, AWS CloudTrail, Amazon Inspector y AWS IAM Access Analyzer proporciona un enfoque integral para el monitoreo de seguridad y cumplimiento. AWS Security Hub agrega y prioriza alertas de seguridad, mientras que AWS CloudTrail permite visibilidad sobre la actividad de la cuenta. Amazon Inspector evalúa aplicaciones en busca de vulnerabilidades, y AWS IAM Access Analyzer ayuda a identificar accesos no intencionados a recursos, asegurando el cumplimiento de las políticas de seguridad.",
        "Other Options": [
            "Esta opción incluye servicios que se centran principalmente en el monitoreo y gestión de recursos, pero carece de herramientas dedicadas para evaluaciones de seguridad y monitoreo de cumplimiento.",
            "Esta opción presenta servicios que brindan protección contra ataques DDoS y gestionan reglas de seguridad, pero no ofrece una vista integral de alertas de seguridad o verificaciones de cumplimiento.",
            "Esta opción incluye servicios que ofrecen optimización de costos y monitoreo de rendimiento, pero no aborda vulnerabilidades de seguridad ni requisitos de cumplimiento."
        ]
    },
    {
        "Question Number": "68",
        "Situation": "Una empresa está planeando migrar su aplicación existente en las instalaciones a AWS. Quieren aprovechar los nuevos servicios y características de AWS para mejorar el rendimiento y la confiabilidad. El arquitecto de soluciones necesita desarrollar una estrategia de migración que incluya la modernización de la arquitectura de la aplicación mientras minimiza el tiempo de inactividad durante la transición. La arquitectura también debe soportar la escalabilidad y mantenibilidad futuras.",
        "Question": "¿Cuál de las siguientes opciones es el enfoque más adecuado para que la empresa adopte en este escenario?",
        "Options": {
            "1": "Migrar la aplicación a una instancia de Amazon RDS y refactorizarla para utilizar las características de la base de datos, mientras se mantiene la aplicación alojada en las instalaciones.",
            "2": "Contenerizar la aplicación utilizando Amazon ECS y desplegarla en instancias de Amazon EC2, lo que permite una gestión y despliegue más fáciles de microservicios.",
            "3": "Rearquitectar la aplicación para usar AWS Lambda y Amazon API Gateway, asegurando una arquitectura sin servidor que escale automáticamente y minimice la sobrecarga operativa.",
            "4": "Levantar y trasladar la aplicación a instancias de Amazon EC2 sin cambios, y planear modernizarla después de que la migración esté completa."
        },
        "Correct Answer": "Rearquitectar la aplicación para usar AWS Lambda y Amazon API Gateway, asegurando una arquitectura sin servidor que escale automáticamente y minimice la sobrecarga operativa.",
        "Explanation": "Esta opción proporciona el mejor enfoque para modernizar la aplicación al utilizar una arquitectura sin servidor. AWS Lambda y API Gateway permiten el escalado automático, reduciendo la necesidad de gestión de servidores y mejorando el rendimiento y la confiabilidad general.",
        "Other Options": [
            "Este enfoque no aprovecha los servicios de AWS para modernizar la aplicación. Puede llevar a costos operativos más altos y no soporta mejoras en escalabilidad o rendimiento.",
            "Si bien la contenerización puede mejorar la gestión y el despliegue, esta opción aún depende de EC2, que requiere gestionar la infraestructura subyacente y no abraza completamente los beneficios de una arquitectura sin servidor.",
            "Esta opción se centra únicamente en la migración de la base de datos y no aborda la capa de la aplicación. Mantiene la aplicación en las instalaciones, lo que limita la escalabilidad y no aprovecha las capacidades completas de los servicios de AWS."
        ]
    },
    {
        "Question Number": "69",
        "Situation": "Una empresa global de juegos en línea atiende a millones de jugadores en todo el mundo y necesita optimizar su experiencia de juego reduciendo la latencia y mejorando la entrega de contenido. La empresa ha desplegado sus servidores de juegos en múltiples regiones de AWS y busca una solución que pueda proporcionar una entrega de contenido rápida y experiencias de jugador sin interrupciones a través de geografías. Además, la empresa quiere asegurar alta disponibilidad y conmutación por error automática en caso de interrupciones regionales.",
        "Question": "¿Cuál de las siguientes soluciones satisfaría mejor los requisitos de la empresa para la entrega de contenido de baja latencia y alta disponibilidad?",
        "Options": {
            "1": "Implementar AWS Lambda@Edge con Amazon CloudFront para almacenar en caché los datos del juego más cerca de los jugadores mientras se utiliza Amazon Route 53 para gestionar la conmutación por error de DNS para alta disponibilidad.",
            "2": "Desplegar Amazon S3 para el almacenamiento de contenido del juego y usar AWS Direct Connect para proporcionar una línea dedicada para la transferencia de datos a los servidores de juegos. Esto mejorará la latencia y el rendimiento.",
            "3": "Usar Amazon CloudFront para distribuir contenido del juego a nivel global. Implementar AWS Global Accelerator para dirigir a los jugadores al servidor de juegos más cercano y mejorar la disponibilidad con conmutación por error automática.",
            "4": "Utilizar Amazon Elastic Load Balancing en múltiples regiones para distribuir el tráfico de manera uniforme entre los servidores de juegos, mientras se configura Amazon RDS con Multi-AZ para redundancia de base de datos."
        },
        "Correct Answer": "Usar Amazon CloudFront para distribuir contenido del juego a nivel global. Implementar AWS Global Accelerator para dirigir a los jugadores al servidor de juegos más cercano y mejorar la disponibilidad con conmutación por error automática.",
        "Explanation": "Usar Amazon CloudFront permite una distribución eficiente del contenido del juego con latencia reducida, ya que almacena en caché el contenido en ubicaciones de borde cercanas a los jugadores. AWS Global Accelerator mejora aún más la disponibilidad al dirigir el tráfico de manera inteligente al servidor de juegos óptimo, asegurando que los jugadores tengan un retraso mínimo y una experiencia sin interrupciones.",
        "Other Options": [
            "Desplegar Amazon S3 para el almacenamiento de contenido del juego y usar AWS Direct Connect mejora el rendimiento de la transferencia de datos, pero no aborda directamente la entrega de contenido de baja latencia o los mecanismos de conmutación por error automática para los servidores de juegos.",
            "Implementar AWS Lambda@Edge con Amazon CloudFront para almacenamiento en caché y usar Amazon Route 53 para la conmutación por error de DNS ofrece algunos beneficios, pero puede no proporcionar el mismo nivel de conmutación por error automática y optimización de enrutamiento que AWS Global Accelerator.",
            "Utilizar Amazon Elastic Load Balancing para la distribución de tráfico y Amazon RDS con Multi-AZ para redundancia de base de datos es una buena estrategia de alta disponibilidad, pero no aborda específicamente la entrega de contenido global y la reducción de latencia para una base de jugadores mundial."
        ]
    },
    {
        "Question Number": "70",
        "Situation": "Una empresa de servicios financieros está migrando sus aplicaciones web a AWS. La empresa necesita asegurar sus APIs y servicios internos con certificados SSL/TLS. El equipo de seguridad prefiere usar certificados que sean automáticamente confiables por las aplicaciones cliente y los navegadores sin configuración adicional. Están considerando usar AWS Certificate Manager para este propósito.",
        "Question": "¿Qué tipo de certificado debería provisionar la empresa usando AWS Certificate Manager para asegurar una confianza sin interrupciones con las aplicaciones cliente y los navegadores?",
        "Options": {
            "1": "Usar una autoridad de certificación de terceros para certificados públicos.",
            "2": "Usar certificados autofirmados para todas las aplicaciones internas.",
            "3": "Provisionar un certificado SSL/TLS privado para servicios internos.",
            "4": "Provisionar un certificado SSL/TLS público para servicios externos."
        },
        "Correct Answer": "Provisionar un certificado SSL/TLS público para servicios externos.",
        "Explanation": "Provisionar un certificado SSL/TLS público a través de AWS Certificate Manager asegura que el certificado sea automáticamente confiable por los navegadores y las aplicaciones cliente, cumpliendo con el requisito de la empresa para una confianza sin interrupciones sin configuración adicional.",
        "Other Options": [
            "Provisionar un certificado SSL/TLS privado requeriría configuración explícita en las aplicaciones cliente para confiar en el certificado, lo que no cumple con el requisito de confianza sin interrupciones.",
            "Usar certificados autofirmados no se recomienda para entornos de producción ya que no son confiables por defecto, requiriendo configuración adicional para cada cliente, lo que contradice el requisito.",
            "Usar una autoridad de certificación de terceros puede introducir complejidad y costos innecesarios, ya que AWS Certificate Manager proporciona certificados públicos gratuitos que son automáticamente confiables."
        ]
    },
    {
        "Question Number": "71",
        "Situation": "Una empresa multinacional está desplegando una aplicación distribuida globalmente en AWS que necesita enrutar el tráfico de los usuarios de manera eficiente y proporcionar alta disponibilidad. La aplicación será accesible desde varias ubicaciones geográficas, y la empresa busca minimizar la latencia mientras asegura que los usuarios sean dirigidos a los recursos disponibles más cercanos. Están considerando varias políticas de enrutamiento proporcionadas por AWS Route 53 para lograr este objetivo.",
        "Question": "¿Cuál de las siguientes políticas de enrutamiento en AWS Route 53 sería la MÁS efectiva para dirigir a los usuarios al punto final de la aplicación más cercano basado en su ubicación geográfica?",
        "Options": {
            "1": "Política de enrutamiento ponderado",
            "2": "Política de enrutamiento por geolocalización",
            "3": "Política de enrutamiento por conmutación por error",
            "4": "Política de enrutamiento por latencia"
        },
        "Correct Answer": "Política de enrutamiento por geolocalización",
        "Explanation": "La política de enrutamiento por geolocalización permite a Route 53 dirigir el tráfico basado en la ubicación geográfica del usuario. Esto significa que los usuarios serán dirigidos al punto final de la aplicación más cercano, reduciendo la latencia y mejorando el rendimiento. Está específicamente diseñada para escenarios donde la proximidad geográfica es crucial para optimizar la experiencia del usuario.",
        "Other Options": [
            "La política de enrutamiento por latencia dirige a los usuarios al punto final que proporciona la menor latencia basada en verificaciones de salud, pero no considera específicamente la ubicación geográfica del usuario. Esto puede no resultar siempre en dirigir a los usuarios al recurso más cercano, que es el requisito principal en este escenario.",
            "La política de enrutamiento ponderado permite distribuir el tráfico entre múltiples puntos finales basados en pesos asignados, pero no toma en cuenta la ubicación geográfica. Esto podría llevar a un enrutamiento ineficiente en términos de latencia, ya que los usuarios pueden no ser dirigidos al recurso más cercano.",
            "La política de enrutamiento por conmutación por error se utiliza para dirigir el tráfico a un punto final primario y conmutar a un punto final secundario en caso de falla. Esta política está destinada a alta disponibilidad en lugar de optimizar la proximidad del usuario o la latencia, lo que la hace inadecuada para el requisito de dirigir a los usuarios al punto final de la aplicación más cercano."
        ]
    },
    {
        "Question Number": "72",
        "Situation": "Una empresa está migrando su arquitectura de on-premises a AWS. Requieren una solución que permita a las instancias en una subred privada acceder a internet para actualizaciones y parches, asegurando que las instancias no estén expuestas directamente al tráfico de internet entrante. El equipo está evaluando el mejor uso de NAT para lograr este requisito.",
        "Question": "¿Cuál afirmación describe correctamente el comportamiento de las instancias NAT y las puertas de enlace NAT en el contexto de los tiempos de espera de conexión?",
        "Options": {
            "1": "Las instancias NAT envían un paquete FIN para cerrar conexiones en tiempos de espera, mientras que las puertas de enlace NAT envían un paquete RST para terminarlas.",
            "2": "Tanto las instancias NAT como las puertas de enlace envían paquetes RST para terminar conexiones en tiempos de espera.",
            "3": "Tanto las instancias NAT como las puertas de enlace envían paquetes FIN para terminar conexiones en tiempos de espera.",
            "4": "Las puertas de enlace NAT envían un paquete FIN para cerrar conexiones en tiempos de espera, mientras que las instancias NAT envían un paquete RST para terminarlas."
        },
        "Correct Answer": "Las instancias NAT envían un paquete FIN para cerrar conexiones en tiempos de espera, mientras que las puertas de enlace NAT envían un paquete RST para terminarlas.",
        "Explanation": "Las instancias NAT y las puertas de enlace NAT manejan los tiempos de espera de conexión de manera diferente. Las instancias NAT enviarán un paquete FIN a los recursos privados para cerrar la conexión de manera ordenada, mientras que las puertas de enlace NAT enviarán un paquete RST, que termina la conexión de manera forzada sin una secuencia de apagado adecuada.",
        "Other Options": [
            "Es incorrecto que las puertas de enlace NAT envíen un paquete FIN; en realidad, envían un paquete RST en los tiempos de espera de conexión.",
            "Esto es incorrecto porque solo las instancias NAT envían paquetes FIN, mientras que las puertas de enlace NAT envían paquetes RST.",
            "Esto es incorrecto; las instancias NAT y las puertas de enlace no envían ambos paquetes FIN en los tiempos de espera, ya que utilizan diferentes mecanismos para la terminación de conexiones."
        ]
    },
    {
        "Question Number": "73",
        "Situation": "Una empresa de servicios financieros está migrando sus aplicaciones a AWS y necesita elegir una plataforma de alojamiento de contenedores. La empresa requiere una solución que permita una fácil escalabilidad, alta disponibilidad e integración con las tuberías de CI/CD existentes. Las aplicaciones están basadas en microservicios y deben soportar capacidades de despliegue rápido y reversión, asegurando al mismo tiempo que se cumplan los requisitos de seguridad y cumplimiento.",
        "Question": "¿Cuál de las siguientes plataformas de alojamiento de contenedores sería la opción más adecuada para los requisitos de la empresa?",
        "Options": {
            "1": "Amazon EC2 con Docker instalado para ejecutar contenedores directamente en máquinas virtuales, ofreciendo control total pero complicando la escalabilidad y gestión.",
            "2": "Amazon ECS con AWS Fargate para gestionar los contenedores y habilitar computación sin servidor, simplificando la escalabilidad y el despliegue.",
            "3": "AWS Lambda para ejecutar aplicaciones en contenedores de manera sin servidor, eliminando la necesidad de gestión de contenedores pero limitando el control.",
            "4": "Amazon EKS con Kubernetes para gestionar los contenedores, proporcionando características avanzadas de orquestación pero requiriendo más carga operativa."
        },
        "Correct Answer": "Amazon ECS con AWS Fargate para gestionar los contenedores y habilitar computación sin servidor, simplificando la escalabilidad y el despliegue.",
        "Explanation": "Amazon ECS con AWS Fargate proporciona una opción de alojamiento de contenedores sin servidor que abstrae la infraestructura subyacente, permitiendo a la empresa centrarse en desplegar y gestionar aplicaciones sin preocuparse por el mantenimiento del servidor. Soporta una fácil escalabilidad e integra bien con las tuberías de CI/CD, cumpliendo con los requisitos de la empresa.",
        "Other Options": [
            "Amazon EKS con Kubernetes requiere gestionar el plano de control de Kubernetes, lo que añade complejidad y carga operativa, haciéndolo menos adecuado para un equipo que busca simplicidad y facilidad de uso.",
            "AWS Lambda está diseñado para ejecutar código en una arquitectura sin servidor, pero no proporciona el mismo nivel de control sobre las aplicaciones en contenedores como ECS o EKS, limitando la capacidad de la empresa para gestionar microservicios de manera efectiva.",
            "Amazon EC2 con Docker instalado ofrece control total sobre el entorno, pero complica la escalabilidad y gestión, lo que va en contra de la necesidad de la empresa de una solución simplificada y manejable."
        ]
    },
    {
        "Question Number": "74",
        "Situation": "Una empresa está diseñando una nueva aplicación sin servidor utilizando Amazon DynamoDB como su base de datos principal. La aplicación manejará cargas de trabajo variables, y el equipo de desarrollo se centra en optimizar los patrones de acceso a datos y minimizar costos. Necesitan decidir sobre el uso apropiado de claves primarias para asegurar una recuperación y almacenamiento de datos eficientes. (Seleccione Dos)",
        "Question": "¿Cuáles dos configuraciones asegurarán un rendimiento óptimo y eficiencia de costos en DynamoDB? (Seleccione Dos)",
        "Options": {
            "1": "Configurar capacidad adaptativa para ajustar automáticamente el rendimiento de las particiones que experimentan alto tráfico sin exceder la capacidad total provisionada.",
            "2": "Usar una clave primaria simple con solo una clave de partición para asegurar que los elementos se distribuyan uniformemente entre las particiones.",
            "3": "Usar índices secundarios globales para permitir consultas basadas en atributos distintos a la clave primaria.",
            "4": "Usar una clave primaria compuesta con una clave de partición y una clave de orden para habilitar consultas eficientes de elementos relacionados.",
            "5": "Implementar un diseño de tabla única para consolidar todos los datos relacionados en una sola tabla de DynamoDB para un mejor rendimiento."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Usar una clave primaria compuesta con una clave de partición y una clave de orden para habilitar consultas eficientes de elementos relacionados.",
            "Configurar capacidad adaptativa para ajustar automáticamente el rendimiento de las particiones que experimentan alto tráfico sin exceder la capacidad total provisionada."
        ],
        "Explanation": "Usar una clave primaria compuesta permite consultas y recuperación eficientes de elementos relacionados, lo cual es crucial para aplicaciones con patrones de acceso complejos. Además, configurar capacidad adaptativa asegura que la aplicación pueda manejar cargas de trabajo variables sin incurrir en costos innecesarios debido a la limitación o sobreaprovisionamiento.",
        "Other Options": [
            "Usar una clave primaria simple puede no proporcionar la flexibilidad requerida para una recuperación eficiente de datos al tratar con elementos relacionados, lo que puede llevar a consultas ineficientes y posibles problemas de rendimiento.",
            "Si bien los índices secundarios globales pueden ser útiles, no abordan directamente el diseño de la clave primaria para un rendimiento óptimo; sirven como un patrón de acceso secundario y pueden incurrir en costos adicionales.",
            "Implementar un diseño de tabla única podría ser beneficioso en algunos escenarios, pero no aborda directamente la necesidad de una configuración óptima de la clave primaria y puede complicar los patrones de acceso a datos."
        ]
    },
    {
        "Question Number": "75",
        "Situation": "Una empresa de servicios financieros está desarrollando una nueva aplicación sin servidor utilizando AWS Lambda para manejar transacciones en tiempo real. Se espera que la aplicación tenga niveles de tráfico variables a lo largo del día, con un uso máximo durante las horas laborales. El arquitecto de soluciones es responsable de asegurar que la aplicación pueda manejar picos repentinos de tráfico mientras minimiza costos.",
        "Question": "¿Qué método de control de concurrencia debería implementar el arquitecto de soluciones para asegurar que la aplicación pueda manejar picos de tráfico repentinos de manera eficiente?",
        "Options": {
            "1": "Usar una combinación de concurrencia provisionada y reservada para gestionar el tráfico de manera efectiva y optimizar costos.",
            "2": "Establecer concurrencia reservada para limitar el número máximo de ejecuciones concurrentes en todas las funciones de Lambda para evitar la limitación.",
            "3": "Aumentar el límite total de concurrencia para la cuenta de AWS para permitir más ejecuciones concurrentes en todas las funciones.",
            "4": "Configurar concurrencia provisionada para precalentar un número específico de instancias de Lambda para disponibilidad inmediata durante picos de tráfico."
        },
        "Correct Answer": "Configurar concurrencia provisionada para precalentar un número específico de instancias de Lambda para disponibilidad inmediata durante picos de tráfico.",
        "Explanation": "La concurrencia provisionada permite al arquitecto pre-inicializar un número establecido de instancias de Lambda, asegurando que estén listas para manejar solicitudes de inmediato, lo cual es crucial para aplicaciones que experimentan picos repentinos de tráfico.",
        "Other Options": [
            "Establecer concurrencia reservada solo limita las ejecuciones concurrentes máximas sin asegurar tiempos de respuesta inmediatos, lo que puede llevar a retrasos durante cargas máximas.",
            "Si bien una combinación de concurrencia provisionada y reservada puede proporcionar algunos beneficios, complica la arquitectura y podría no ser necesaria para gestionar picos repentinos de manera efectiva.",
            "Aumentar el límite total de concurrencia para la cuenta de AWS puede no abordar la necesidad de disponibilidad inmediata de las instancias de Lambda durante picos de tráfico y podría llevar a costos adicionales."
        ]
    }
]