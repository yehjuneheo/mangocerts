[
    {
        "Question Number": "1",
        "Situation": "한 회사가 Auto Scaling 그룹의 Amazon EC2 인스턴스 집합에서 웹 애플리케이션을 운영하고 있습니다. 이 애플리케이션은 하루 동안 변동하는 트래픽 패턴을 경험하며, 업무 시간 동안 피크 로드가 발생합니다. 회사는 애플리케이션이 증가하는 로드를 처리할 수 있도록 적절하게 확장할 수 있도록 하면서 비피크 시간 동안 비용을 최소화해야 합니다. 솔루션 아키텍트는 수요 변화에 효과적으로 대응하는 Auto Scaling 정책을 구현해야 합니다.",
        "Question": "솔루션 아키텍트가 애플리케이션 로드에 따라 EC2 인스턴스의 확장을 최적화하면서 비용 효율성을 보장하기 위해 어떤 Auto Scaling 정책을 구현해야 합니까?",
        "Options": {
            "1": "평균 CPU 사용률 메트릭에 따라 인스턴스 수를 조정하는 타겟 추적 스케일링 정책을 구현합니다.",
            "2": "실제 수요와 관계없이 매일 특정 시간에 인스턴스를 추가하는 예약 스케일링 정책을 구성합니다.",
            "3": "특정 네트워크 트래픽 메트릭의 임계값에 따라 인스턴스 수를 증가시키는 단계적 스케일링 정책을 사용합니다.",
            "4": "CPU 사용률이 기준 수준 이하로 떨어질 때만 축소하는 단순 스케일링 정책을 설정합니다."
        },
        "Correct Answer": "평균 CPU 사용률 메트릭에 따라 인스턴스 수를 조정하는 타겟 추적 스케일링 정책을 구현합니다.",
        "Explanation": "타겟 추적 스케일링 정책은 지정된 CPU 사용률 수준을 유지하기 위해 EC2 인스턴스 수를 자동으로 조정하여 실제 로드에 따라 동적으로 확장할 수 있게 합니다. 이 접근 방식은 낮은 수요 기간 동안 축소하여 비용을 통제하면서 성능을 최적화합니다.",
        "Other Options": [
            "예약 스케일링 정책은 실제 수요 변동을 고려하지 않으며, 자원의 과잉 제공 또는 부족 제공으로 이어져 불필요한 비용이나 성능 문제를 초래할 수 있습니다.",
            "네트워크 트래픽 기반의 단계적 스케일링 정책이 작동할 수 있지만, 애플리케이션 성능과 직접적으로 연관되지 않을 수 있으며, 특히 트래픽 패턴이 예측 불가능할 경우 스케일링 작업에 지연을 초래할 수 있습니다.",
            "CPU 사용률에 따라 축소만 하는 단순 스케일링 정책은 피크 수요 동안 사전 확장을 허용하지 않아 성능 저하 및 사용자 경험 악화를 초래할 수 있습니다."
        ]
    },
    {
        "Question Number": "2",
        "Situation": "한 소매 회사가 Amazon Rekognition을 사용하여 매장 비디오 피드를 분석하여 고객 경험을 향상시키고자 합니다. 목표는 고객 인구 통계를 식별하고, 발길 수를 추적하며, 실시간으로 부적절한 콘텐츠를 감지하는 것입니다. 회사는 솔루션이 효율적이고 비용 효과적이어야 함을 보장해야 합니다.",
        "Question": "회사가 Amazon Rekognition을 사용하여 실시간 비디오 분석을 구현하기 위해 어떤 접근 방식을 취해야 합니까?",
        "Options": {
            "1": "회사는 Amazon Rekognition Video를 사용하여 S3에 저장된 비디오 세그먼트를 분석하고, 고객 인구 통계 및 발길 수를 평가하기 위해 주기적으로 결과를 쿼리해야 합니다.",
            "2": "회사는 Amazon Kinesis Data Stream을 설정하여 실시간 비디오 피드를 수집하고, Amazon Rekognition Video를 트리거하여 스트림을 분석하여 통찰력과 부적절한 콘텐츠를 감지해야 합니다.",
            "3": "회사는 FFmpeg를 사용하여 비디오 피드를 분석하고 통찰력을 추출한 후 Amazon Rekognition에 데이터를 검증하도록 보내는 맞춤형 비디오 처리 애플리케이션을 구현해야 합니다.",
            "4": "회사는 AWS Snowball Edge 장치를 사용하여 온프레미스에서 Amazon Rekognition을 실행하여 비디오 피드를 로컬에서 분석한 후 결과를 AWS에 업로드해야 합니다."
        },
        "Correct Answer": "회사는 Amazon Kinesis Data Stream을 설정하여 실시간 비디오 피드를 수집하고, Amazon Rekognition Video를 트리거하여 스트림을 분석하여 통찰력과 부적절한 콘텐츠를 감지해야 합니다.",
        "Explanation": "Amazon Kinesis Data Streams를 사용하면 회사가 실시간 비디오 피드를 효율적으로 처리할 수 있습니다. Kinesis와 Amazon Rekognition Video를 통합함으로써 회사는 비디오 콘텐츠를 수집 즉시 분석할 수 있어 적시의 통찰력을 제공하고 실시간으로 부적절한 콘텐츠를 감지할 수 있습니다.",
        "Other Options": [
            "S3에 저장된 비디오 세그먼트를 분석하는 것은 실시간 통찰력을 제공하지 않으며, 기록과 분석 사이에 지연이 발생하여 즉각적인 고객 경험 향상에 적합하지 않습니다.",
            "AWS Snowball Edge를 사용하는 온프레미스 솔루션은 Amazon Rekognition의 모든 기능을 활용하지 못할 수 있으며, 결과 처리 및 업로드를 위한 추가 단계를 도입하여 아키텍처를 복잡하게 만듭니다.",
            "맞춤형 비디오 처리 애플리케이션을 구현하면 복잡성과 유지 관리 오버헤드가 증가할 수 있으며, 이미지 및 비디오 분석을 위해 특별히 설계된 Amazon Rekognition의 전문 기능을 활용하지 못할 수 있습니다."
        ]
    },
    {
        "Question Number": "3",
        "Situation": "한 미디어 스트리밍 회사가 Amazon S3에 저장된 콘텐츠를 제공하기 위해 Amazon CloudFront를 활용하고 있습니다. 이들은 S3 버킷을 보호하기 위해 Origin Access Identity (OAI)를 사용해 왔지만 정책 구성 및 HTTP 방법에 대한 문제에 직면하고 있습니다. 보안을 강화하고 기능을 확장하기 위해 CloudFront 배포에 대해 Origin Access Control (OAC)을 탐색하기로 결정했습니다. 솔루션 아키텍트는 OAI에서 OAC로 전환하는 주요 이점을 결정해야 합니다.",
        "Question": "Amazon CloudFront에서 Origin Access Control (OAC)을 사용함으로써 Origin Access Identity (OAI)보다 주된 이점은 무엇입니까?",
        "Options": {
            "1": "OAI는 OAC에 비해 단기 자격 증명 및 빈번한 자격 증명 회전을 통해 더 나은 보안 관행을 제공합니다.",
            "2": "OAC는 지정된 CloudFront 배포만 콘텐츠에 접근할 수 있도록 하여 S3 원본에 대한 접근을 제한합니다.",
            "3": "OAC는 암호화되지 않은 S3 객체만 지원하여 모든 AWS 리전과의 호환성을 보장합니다.",
            "4": "OAC는 세분화된 정책 구성을 허용하고 PUT 및 DELETE를 포함한 모든 HTTP 방법을 지원합니다."
        },
        "Correct Answer": "OAC는 지정된 CloudFront 배포만 콘텐츠에 접근할 수 있도록 하여 S3 원본에 대한 접근을 제한합니다.",
        "Explanation": "Origin Access Control (OAC)은 특정 CloudFront 배포에 대해서만 S3 원본에 대한 접근을 허용함으로써 보안을 강화하고 OAI에 비해 노출을 제한하여 보안 모델을 개선합니다.",
        "Other Options": [
            "OAC는 PUT 및 DELETE를 포함한 모든 HTTP 방법을 지원하지만, 세분화된 정책 구성을 특별히 제공하지 않으므로 이 진술은 오해의 소지가 있습니다.",
            "OAC는 암호화된 S3 객체를 지원하며 모든 AWS 리전에 대한 접근을 허용하므로 이 옵션은 OAC의 기능을 잘못 표현하고 있습니다.",
            "OAC는 OAI보다 더 나은 보안 관행을 통합하도록 설계되었으며, 단기 자격 증명을 포함하므로 이 옵션은 반대의 주장을 잘못하고 있습니다."
        ]
    },
    {
        "Question Number": "4",
        "Situation": "AWS Cloud에 배포된 의료 애플리케이션은 민감한 환자 데이터를 안전하게 보호하면서 인증된 사용자가 시스템에 접근할 수 있도록 해야 합니다. 이 애플리케이션은 여러 가용 영역에 있는 여러 서브넷을 사용하는 가상 사설 클라우드(VPC)를 사용합니다. 솔루션 아키텍트로서, 귀하는 규정 준수 및 보안 요구 사항을 효과적으로 충족하기 위해 네트워크를 구성하는 임무를 맡고 있습니다.",
        "Question": "민감한 데이터를 보호하면서 애플리케이션에 대한 안전한 접근을 보장하기 위해 어떤 네트워크 구성을 구현해야 합니까? (두 가지 선택)",
        "Options": {
            "1": "인증된 사용자가 사용하는 특정 IP 주소에서만 수신 트래픽을 허용하도록 보안 그룹을 구성합니다.",
            "2": "사설 서브넷에서 공용 서브넷으로의 트래픽만 허용하는 라우트 테이블을 생성합니다.",
            "3": "특정 CIDR 범위에서 애플리케이션 서브넷으로의 수신 트래픽을 허용하도록 네트워크 ACL을 사용합니다.",
            "4": "모든 수신 트래픽을 거부하는 네트워크 ACL을 구현하여 모든 접근을 차단합니다.",
            "5": "모든 IP 주소에서 포트 80으로 애플리케이션으로의 트래픽을 허용하는 보안 그룹을 설정합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "인증된 사용자가 사용하는 특정 IP 주소에서만 수신 트래픽을 허용하도록 보안 그룹을 구성합니다.",
            "특정 CIDR 범위에서 애플리케이션 서브넷으로의 수신 트래픽을 허용하도록 네트워크 ACL을 사용합니다."
        ],
        "Explanation": "특정 IP 주소에서만 수신 트래픽을 허용하도록 보안 그룹을 사용하는 것은 인증된 사용자만 의료 애플리케이션에 접근할 수 있도록 보장하여 보안을 강화합니다. 또한, 특정 CIDR 범위에서의 트래픽을 허용하는 네트워크 ACL을 구현하면 서브넷 수준에서 추가적인 보안 계층을 제공하여 신뢰할 수 있는 소스만 리소스에 접근할 수 있게 합니다.",
        "Other Options": [
            "사설 서브넷에서 공용 서브넷으로의 트래픽만 허용하는 라우트 테이블을 생성하는 것은 애플리케이션에 접근할 수 있는 사용자를 제어하지 않기 때문에 민감한 데이터에 대한 보안을 제공하지 않습니다.",
            "모든 수신 트래픽을 거부하는 네트워크 ACL을 구현하면 인증된 사용자로부터의 접근도 차단되어 애플리케이션에 접근할 수 없게 됩니다.",
            "모든 IP 주소에서 포트 80으로 애플리케이션으로의 트래픽을 허용하는 보안 그룹을 설정하면 인터넷의 누구에게나 무제한 접근을 허용하게 되어 애플리케이션이 잠재적인 공격에 노출됩니다."
        ]
    },
    {
        "Question Number": "5",
        "Situation": "한 헬스 테크 회사가 사용자가 자신의 피트니스 활동과 건강 지표를 추적할 수 있는 모바일 애플리케이션을 개발하고 있습니다. 이 애플리케이션은 사용자 데이터에 대한 실시간 업데이트가 필요하며, 원활한 경험을 보장하기 위해 오프라인 기능을 제공해야 합니다. 개발 팀은 사용자 프로필을 위한 NoSQL 데이터베이스와 사용자 정의 데이터 처리를 위한 AWS Lambda 기능을 포함한 다양한 소스에서 데이터 관리를 용이하게 하기 위해 AWS AppSync를 사용하는 것을 고려하고 있습니다. 그들은 사용자가 오프라인 상태일 때도 데이터에 접근할 수 있도록 하고, 오프라인 중에 이루어진 변경 사항이 재연결 시 동기화되도록 하기를 원합니다. 팀은 데이터 동기화 중 발생할 수 있는 충돌 처리에 대해서도 우려하고 있습니다.",
        "Question": "실시간 데이터 접근, 오프라인 기능 및 충돌 해결을 위한 애플리케이션의 요구 사항을 충족하기 위해 AWS AppSync를 구현하는 가장 효과적인 방법은 무엇입니까?",
        "Options": {
            "1": "AWS AppSync를 Amazon RDS 데이터베이스와 통합하고 실시간 업데이트, 오프라인 접근 및 충돌 해결을 수동으로 처리하는 사용자 정의 API를 구현합니다.",
            "2": "AWS AppSync를 구독 모델로 구성하여 실시간 업데이트를 제공하고 AppSync 내장 메커니즘을 사용하여 충돌 해결을 가능하게 하며 오프라인 사용을 위한 로컬 데이터 접근을 보장합니다.",
            "3": "AWS AppSync를 사용하여 정기적으로 업데이트를 가져오는 폴링 메커니즘을 사용하고 내장된 충돌 해결 없이 오프라인 저장 및 동기화를 위한 사용자 정의 솔루션을 구현합니다.",
            "4": "모든 사용자 데이터를 저장하기 위해 AWS AppSync를 Amazon S3와 함께 배포하고 Amazon CloudFront에 의존하여 사용자에게 데이터를 제공하는데, 이는 실시간 업데이트나 오프라인 접근을 지원하지 않습니다."
        },
        "Correct Answer": "AWS AppSync를 구독 모델로 구성하여 실시간 업데이트를 제공하고 AppSync 내장 메커니즘을 사용하여 충돌 해결을 가능하게 하며 오프라인 사용을 위한 로컬 데이터 접근을 보장합니다.",
        "Explanation": "AWS AppSync를 구독 모델로 사용하면 실시간 업데이트가 클라이언트에 푸시되어 사용자가 항상 최신 데이터에 접근할 수 있도록 보장합니다. 또한, AppSync의 오프라인 기능 및 충돌 해결에 대한 내장 지원은 구현을 단순화하여 연결이 복원될 때 데이터 변경을 원활하게 처리할 수 있게 합니다.",
        "Other Options": [
            "폴링 메커니즘을 사용하는 것은 실시간 업데이트를 제공하지 않기 때문에 애플리케이션의 중요한 요구 사항을 충족하지 못합니다. 또한, 오프라인 저장 및 동기화를 위한 사용자 정의 솔루션은 AppSync의 내장 기능을 활용하는 것보다 복잡하고 오류가 발생할 가능성이 높습니다.",
            "AWS AppSync를 Amazon S3와 함께 배포하는 것은 실시간 업데이트의 필요성과 일치하지 않으며, S3는 동적 데이터 상호작용을 위해 설계되지 않았습니다. 또한, CloudFront는 주로 정적 콘텐츠를 제공하며 실시간 통신을 촉진하지 않습니다.",
            "AWS AppSync를 Amazon RDS 데이터베이스와 통합하면서 업데이트 및 충돌 해결을 수동으로 처리하는 것은 불필요한 복잡성을 추가하고 잠재적인 문제를 초래할 수 있습니다. 이 접근 방식은 이러한 작업을 단순화하도록 설계된 AppSync의 전체 기능을 활용하지 않습니다."
        ]
    },
    {
        "Question Number": "6",
        "Situation": "한 금융 서비스 회사가 실시간으로 거래를 처리하는 중요한 애플리케이션을 운영하고 있습니다. 높은 가용성을 보장하고 다운타임을 최소화하기 위해 이 회사는 AWS CloudWatch 및 AWS CloudTrail을 사용하여 중앙 집중식 모니터링을 구현합니다. 이 애플리케이션은 AWS 서비스를 사용하여 자동으로 실패에서 복구되도록 설계되었습니다. (두 가지 선택)",
        "Question": "회사가 시스템 실패에서 능동적으로 복구하기 위해 구현해야 할 전략은 무엇입니까?",
        "Options": {
            "1": "AWS Config 규칙을 구현하여 준수를 모니터링하고 수정 작업을 트리거합니다.",
            "2": "CloudWatch Events를 설정하여 시스템 상태의 변화를 감지하고 복구 프로세스를 호출합니다.",
            "3": "CloudWatch Alarms를 활성화하여 자가 치유 작업을 위한 Lambda 함수를 트리거합니다.",
            "4": "CloudWatch Logs를 Amazon SNS와 통합하여 중요한 오류에 대한 알림을 보냅니다.",
            "5": "AWS CloudTrail을 사용하여 감사 목적으로 모든 API 호출을 기록합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "CloudWatch Alarms를 활성화하여 자가 치유 작업을 위한 Lambda 함수를 트리거합니다.",
            "CloudWatch Events를 설정하여 시스템 상태의 변화를 감지하고 복구 프로세스를 호출합니다."
        ],
        "Explanation": "CloudWatch Alarms를 활성화하여 Lambda 함수를 트리거하면 특정 임계값이 초과될 때 자동화된 자가 치유 작업이 가능해져 능동적인 복구를 보장합니다. CloudWatch Events를 설정하여 시스템 상태의 변화를 감지하면 복구 프로세스를 호출할 수 있어 시스템이 실패 발생 시 즉시 반응할 수 있습니다.",
        "Other Options": [
            "AWS CloudTrail을 감사 목적으로만 사용하는 것은 능동적인 복구에 기여하지 않으며, 주로 API 호출을 기록하는 데 집중하고 있어 어떤 작업도 트리거하지 않습니다.",
            "CloudWatch Logs를 Amazon SNS와 통합하여 알림을 보내는 것은 유용하지만 자동화된 복구 프로세스에 직접적으로 기여하지 않습니다.",
            "AWS Config 규칙을 구현하는 것은 준수를 유지하는 데 도움이 되지만 실패에 대한 복구 작업을 자동으로 트리거하지는 않습니다."
        ]
    },
    {
        "Question Number": "7",
        "Situation": "한 금융 서비스 회사가 현재의 데이터베이스 솔루션에서 성능 문제를 겪고 있으며, 이 솔루션은 주로 트랜잭션 처리를 위해 사용됩니다. 이들은 애플리케이션의 성능을 향상시키면서 산업 표준을 준수하고자 합니다. 회사는 실시간 분석, 트랜잭션 처리 및 문서 저장을 포함한 다양한 데이터 접근 패턴을 가지고 있습니다. 그들은 특정 작업 부하에 맞춘 목적별 데이터베이스를 활용할 기회를 찾고 있습니다.",
        "Question": "회사가 언급된 특정 작업 부하에 맞춰 데이터베이스 아키텍처를 최적화하기 위해 어떤 전략을 구현해야 합니까?",
        "Options": {
            "1": "모든 데이터 접근 패턴을 처리하기 위해 단일 Amazon ElastiCache 클러스터를 배포하여 성능을 향상시킵니다.",
            "2": "트랜잭션 처리를 위해 Amazon Aurora를, 실시간 분석을 위해 Amazon DynamoDB를, 문서 저장을 위해 Amazon DocumentDB를 활용합니다.",
            "3": "모든 기존 데이터를 단일 Amazon RDS 인스턴스로 마이그레이션하여 관리 및 유지 관리를 단순화합니다.",
            "4": "비용 절감을 위해 모든 데이터 저장 및 쿼리 요구 사항에 대해 Amazon S3와 Athena를 구현합니다."
        },
        "Correct Answer": "트랜잭션 처리를 위해 Amazon Aurora를, 실시간 분석을 위해 Amazon DynamoDB를, 문서 저장을 위해 Amazon DocumentDB를 활용합니다.",
        "Explanation": "이 접근 방식은 특정 사용 사례에 맞춘 목적별 데이터베이스를 활용하여 최적의 성능과 확장성을 보장합니다. Amazon Aurora는 트랜잭션 작업 부하에 대해 높은 처리량을 제공하고, DynamoDB는 실시간 분석을 위한 저지연 접근을 제공하며, DocumentDB는 문서 기반 데이터를 관리하도록 설계되어 회사의 다양한 요구 사항을 효율적으로 충족합니다.",
        "Other Options": [
            "모든 데이터를 단일 Amazon RDS 인스턴스로 마이그레이션하는 것은 관리 단순화에 도움이 될 수 있지만, 다양한 접근 패턴과 작업 부하의 요구 사항을 충족하지 못해 성능 병목 현상을 초래할 수 있습니다.",
            "단일 Amazon ElastiCache 클러스터를 배포하는 것은 주로 캐싱에 사용되므로 트랜잭션 처리 및 문서 저장에 필요한 지속적인 데이터 저장소를 제공하지 않기 때문에 적합하지 않습니다.",
            "Amazon S3와 Athena를 구현하는 것은 트랜잭션 작업 부하에 최적이 아닙니다. S3는 저장 서비스이고 Athena는 쿼리 서비스이므로 이 조합은 회사의 특정 사용 사례에 필요한 트랜잭션 기능과 성능이 부족합니다."
        ]
    },
    {
        "Question Number": "8",
        "Situation": "한 의료 기관이 AWS에 호스팅된 환자 관리 애플리케이션의 지속적인 가용성을 보장해야 합니다. 이 애플리케이션은 일상 운영에 필수적이며 지역적인 중단이나 장애 동안에도 기능을 유지해야 합니다. 기관은 높은 가용성과 내결함성을 제공하는 아키텍처를 설계하고자 합니다.",
        "Question": "중단 동안 애플리케이션 및 인프라 가용성을 달성하는 데 도움이 될 수 있는 설계 전략은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "가용성을 높이기 위해 데이터베이스 계층에 대해 Multi-AZ 배포가 있는 Amazon RDS를 활용합니다.",
            "2": "DNS 장애 조치를 위해 Route 53과 함께 여러 AWS 리전에서 애플리케이션을 배포합니다.",
            "3": "트래픽 관리를 위해 단일 가용 영역에 단일 Elastic Load Balancer (ELB)를 구현합니다.",
            "4": "애플리케이션 데이터를 저장하고 관리를 위해 AWS Lambda 함수를 S3 버킷과 함께 사용합니다.",
            "5": "단일 리전 내 여러 가용 영역에서 Auto Scaling 그룹의 Amazon EC2 인스턴스를 사용합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "DNS 장애 조치를 위해 Route 53과 함께 여러 AWS 리전에서 애플리케이션을 배포합니다.",
            "가용성을 높이기 위해 데이터베이스 계층에 대해 Multi-AZ 배포가 있는 Amazon RDS를 활용합니다."
        ],
        "Explanation": "여러 AWS 리전에서 애플리케이션을 배포하고 Route 53을 통해 DNS 장애 조치를 구현하면 지리적 중복성이 확보되어 한 리전이 다운되면 트래픽이 자동으로 다른 리전으로 리라우팅될 수 있습니다. 또한, Amazon RDS의 Multi-AZ 배포를 사용하면 다른 가용 영역의 대기 인스턴스로 자동 장애 조치가 이루어져 데이터베이스의 가용성과 인프라 장애에 대한 회복력을 높입니다.",
        "Other Options": [
            "단일 리전 내 여러 가용 영역에서 Auto Scaling 그룹의 EC2 인스턴스를 사용하는 것은 어느 정도의 가용성을 제공하지만 지역적인 중단에 대한 보호를 제공하지 않습니다. 전체 리전의 장애는 여전히 애플리케이션 다운타임으로 이어질 수 있습니다.",
            "단일 가용 영역에 단일 Elastic Load Balancer를 구현하는 것은 중복성을 제한합니다. 해당 가용 영역에서 장애가 발생하면 애플리케이션이 사용할 수 없게 되어 높은 가용성과 내결함성의 목표에 반합니다.",
            "애플리케이션 데이터 관리를 위해 AWS Lambda 함수를 S3 버킷과 함께 사용하는 것은 애플리케이션 가용성을 포괄적으로 해결하지 않습니다. 이 접근 방식은 솔루션의 일부가 될 수 있지만 중단 동안 애플리케이션 자체의 가용성을 특별히 향상시키지 않습니다."
        ]
    },
    {
        "Question Number": "9",
        "Situation": "한 스타트업이 컨테이너에서 실행될 마이크로서비스 기반 애플리케이션을 개발하고 있습니다. 개발 팀은 최소한의 운영 오버헤드로 컨테이너화된 애플리케이션을 배포, 관리 및 확장할 수 있는 솔루션을 찾고 있습니다. 그들은 기본 인프라에 대한 걱정 없이 애플리케이션 개발에 집중하고 싶어합니다.",
        "Question": "스타트업의 컨테이너 오케스트레이션 요구 사항을 관리하기 위한 최선의 선택은 무엇입니까?",
        "Options": {
            "1": "관리형 Kubernetes 서비스를 실행하기 위해 스팟 인스턴스와 함께 Amazon EKS를 활용합니다.",
            "2": "EC2 인스턴스에서 자체 관리 Docker Swarm 클러스터를 설정하여 컨테이너를 오케스트레이션합니다.",
            "3": "Amazon EC2 인스턴스에서 Kubernetes를 배포하고 클러스터를 수동으로 관리하여 컨테이너 오케스트레이션을 수행합니다.",
            "4": "기본 EC2 인스턴스를 관리하지 않고 Amazon ECS와 Fargate를 사용하여 컨테이너를 실행합니다."
        },
        "Correct Answer": "기본 EC2 인스턴스를 관리하지 않고 Amazon ECS와 Fargate를 사용하여 컨테이너를 실행합니다.",
        "Explanation": "Amazon ECS와 Fargate를 사용하면 스타트업이 기본 인프라를 관리하지 않고도 컨테이너를 실행할 수 있습니다. 이 서버리스 접근 방식은 팀이 애플리케이션 개발에 집중할 수 있는 유연성을 제공하며, AWS가 컨테이너 환경의 확장성과 관리를 처리합니다.",
        "Other Options": [
            "Amazon EC2 인스턴스에서 Kubernetes를 배포하는 것은 클러스터 관리, 업데이트, 확장 및 구성에 대한 상당한 운영 오버헤드를 요구하므로 스타트업의 최소한의 운영 관리를 요구하는 것과 모순됩니다.",
            "Amazon EKS와 스팟 인스턴스를 사용하는 것은 비용을 절감할 수 있지만 여전히 팀이 Kubernetes 구성 및 설정을 관리해야 하므로 불필요한 복잡성을 추가합니다.",
            "EC2 인스턴스에서 자체 관리 Docker Swarm 클러스터를 설정하는 것은 상당한 관리 및 유지 관리 책임이 따르므로 스타트업이 인프라 관리의 부담 없이 애플리케이션 개발에 집중하려는 목표에 반합니다."
        ]
    },
    {
        "Question Number": "10",
        "Situation": "소프트웨어 개발 팀이 AWS에서 호스팅되는 마이크로서비스 애플리케이션을 개발하고 있습니다. 팀은 AWS CodeCommit을 사용하여 소스 코드를 관리하고 AWS CodeBuild를 사용하여 빌드 및 테스트 프로세스를 자동화합니다. 애플리케이션은 가상 사설 클라우드(VPC) 내에 호스팅된 데이터베이스에 접근해야 하며, CodeBuild 프로젝트는 이 접근을 위해 구성되어야 합니다. 팀은 CodeBuild 프로젝트 설정에 필요한 VPC ID, 서브넷 ID 및 보안 그룹 ID를 확인했습니다. 그러나 CodeBuild가 VPC 리소스에 성공적으로 접근할 수 있도록 필요한 구성 옵션에 대해서는 확신이 없습니다.",
        "Question": "AWS CodeBuild가 지정된 VPC의 리소스에 접근할 수 있도록 하려면 팀은 무엇을 해야 합니까?",
        "Options": {
            "1": "CodeBuild 프로젝트에 환경 변수를 추가하여 VPC 설정을 지정합니다.",
            "2": "CodeBuild 프로젝트를 구성하여 빌드 환경 설정에서 VPC ID, 서브넷 ID 및 보안 그룹 ID를 사용합니다.",
            "3": "VPC 리소스에 대한 접근 권한을 부여하는 CodeBuild용 새로운 IAM 역할을 생성하고 이를 CodeBuild 프로젝트에 연결합니다.",
            "4": "CodeBuild 프로젝트가 VPC 리소스와 동일한 리전에서 실행되도록 하여 접근을 허용합니다."
        },
        "Correct Answer": "CodeBuild 프로젝트를 구성하여 빌드 환경 설정에서 VPC ID, 서브넷 ID 및 보안 그룹 ID를 사용합니다.",
        "Explanation": "AWS CodeBuild가 VPC 내의 리소스에 접근할 수 있도록 하려면 CodeBuild 프로젝트 구성에서 VPC ID, 서브넷 ID 및 보안 그룹 ID를 제공해야 합니다. 이 구성은 CodeBuild가 VPC 지원 빌드 환경을 설정할 수 있게 하여 VPC 내부의 리소스와 상호작용할 수 있도록 합니다.",
        "Other Options": [
            "새로운 IAM 역할을 생성할 필요는 없습니다. CodeBuild는 VPC 리소스에 접근하기 위해 단순히 IAM 역할이 아닌 특정 VPC 설정이 필요합니다.",
            "VPC와 동일한 리전에서 실행되는 것은 요구 사항이지만, 접근을 보장하지는 않습니다. CodeBuild 프로젝트에서 특정 VPC 구성이 여전히 설정되어야 합니다.",
            "환경 변수는 VPC 접근을 구성하지 않습니다. VPC 설정은 빌드 환경 설정에서 명시적으로 정의되어야 합니다."
        ]
    },
    {
        "Question Number": "11",
        "Situation": "한 금융 서비스 회사가 기존의 고객 관계 관리(CRM) 애플리케이션을 AWS로 마이그레이션할 계획을 세우고 있습니다. 이 애플리케이션은 실시간 고객 상호작용에 필수적이며, 마이그레이션 과정 동안 높은 가용성과 성능을 유지해야 합니다. 회사는 최소한의 다운타임과 사용자에게 원활한 전환을 보장하고자 합니다. 마이그레이션 후 애플리케이션의 기능을 향상시키기 위해 마이크로서비스 아키텍처를 사용하여 애플리케이션을 현대화하는 것도 고려하고 있습니다. 다음 중 작업 부하 마이그레이션과 현대화를 가속화하면서 성능과 가용성을 보장하기 위해 어떤 접근 방식을 취해야 할까요?",
        "Question": "회사가 최소한의 중단으로 CRM 애플리케이션을 AWS로 성공적으로 전환하고 향후 현대화를 염두에 두기 위해 어떤 마이그레이션 전략을 채택해야 합니까?",
        "Options": {
            "1": "기존 아키텍처를 유지하면서 전체 애플리케이션을 전용 VPC의 EC2 인스턴스로 리프트 앤 시프트합니다. DNS 관리 및 트래픽 라우팅을 위해 Amazon Route 53을 사용합니다.",
            "2": "AWS Lambda와 Amazon API Gateway를 사용하여 서버리스 컴퓨팅으로 애플리케이션을 재구성하여 운영 오버헤드를 줄이고 마이그레이션 후 확장성을 개선합니다.",
            "3": "AWS Database Migration Service를 사용하여 CRM 데이터베이스를 Amazon RDS 인스턴스로 복제합니다. 특정 마이크로서비스를 처리하기 위해 AWS Lambda 함수를 사용하여 애플리케이션을 단계적으로 마이그레이션합니다.",
            "4": "AWS로 마이그레이션하기 전에 애플리케이션을 마이크로서비스로 리팩토링하고 각 마이크로서비스를 Amazon ECS의 컨테이너로 배포합니다. 서비스 검색 및 통신을 위해 AWS App Mesh를 사용합니다."
        },
        "Correct Answer": "AWS로 마이그레이션하기 전에 애플리케이션을 마이크로서비스로 리팩토링하고 각 마이크로서비스를 Amazon ECS의 컨테이너로 배포합니다. 서비스 검색 및 통신을 위해 AWS App Mesh를 사용합니다.",
        "Explanation": "애플리케이션을 마이그레이션하기 전에 마이크로서비스로 리팩토링하면 회사가 AWS 기능을 최대한 활용하고 마이그레이션 후 확장성과 성능을 향상시킬 수 있습니다. 각 마이크로서비스를 Amazon ECS의 컨테이너로 배포하면 자원 관리 및 배포 유연성이 향상되며, AWS App Mesh는 마이크로서비스 간의 서비스 검색 및 통신을 간소화합니다.",
        "Other Options": [
            "AWS Database Migration Service를 사용하는 것은 데이터베이스 전환에 유용하지만, 전체 애플리케이션을 단계적으로 마이그레이션하는 것은 현대화의 필요를 효과적으로 해결하지 못할 수 있으며, 장기적인 다운타임을 초래할 수 있습니다.",
            "리프트 앤 시프트 접근 방식은 AWS의 현대화 기능을 활용하지 않으며, 운영 비용이 증가하고 확장성이 제한될 수 있어 회사의 미래 목표와 일치하지 않습니다.",
            "AWS Lambda와 API Gateway를 사용하여 서버리스 컴퓨팅으로 애플리케이션을 재구성하는 것은 유효한 접근 방식이지만, 복잡성을 초래할 수 있으며 마이그레이션 전에 기존 애플리케이션 아키텍처에 상당한 변경이 필요할 수 있습니다."
        ]
    },
    {
        "Question Number": "12",
        "Situation": "한 금융 서비스 회사가 실시간으로 사기 활동을 감지하기 위해 라이브 거래 데이터를 처리하고 있습니다. 그들은 Amazon Kinesis Data Streams(KDS)를 사용하여 이 데이터를 수집하고 분석하고 있습니다. 그러나 피크 거래 기간 동안 일부 레코드가 샤드 제한으로 인해 제한되고 있음을 발견했습니다. 경영진은 KDS 설정의 처리량을 향상시켜 증가된 데이터 부하를 처리하면서 레코드 손실이 없도록 하고자 합니다.",
        "Question": "Kinesis Data Stream의 데이터 수집 용량을 증가시키면서 높은 가용성을 보장하기 위한 가장 효과적인 솔루션은 무엇입니까?",
        "Options": {
            "1": "Kinesis Producer Library(KPL)를 구현하여 레코드를 Kinesis Data Stream에 전송하기 전에 배치하여 기존 샤드의 활용도를 극대화합니다.",
            "2": "기존 Kinesis Data Stream의 샤드 수를 늘려 더 높은 쓰기 처리량을 수용하고 피크 기간 동안 제한을 방지합니다.",
            "3": "Amazon S3를 사용하여 거래 데이터를 임시로 저장하고 AWS Lambda 함수를 설정하여 주기적으로 Kinesis Data Stream에 데이터를 로드하여 피크 부하를 처리합니다.",
            "4": "새로운 Kinesis Data Stream을 생성하고 애플리케이션을 구성하여 원래 스트림과 새로운 스트림 간에 거래 데이터를 고르게 분할하여 부하를 균형 있게 합니다."
        },
        "Correct Answer": "기존 Kinesis Data Stream의 샤드 수를 늘려 더 높은 쓰기 처리량을 수용하고 피크 기간 동안 제한을 방지합니다.",
        "Explanation": "Kinesis Data Stream의 샤드 수를 늘리면 데이터 수집 용량이 직접적으로 향상됩니다. 각 샤드는 특정 양의 데이터를 처리할 수 있으므로, 더 많은 샤드를 추가하면 스트림이 더 많은 양의 수신 데이터를 관리할 수 있게 되어 피크 기간 동안 제한 및 데이터 손실의 위험을 줄일 수 있습니다.",
        "Other Options": [
            "Kinesis Producer Library(KPL)를 구현하는 것은 레코드를 배치하는 데 유용하지만, 스트림 자체의 최대 처리량을 본질적으로 증가시키지는 않습니다. 스트림이 이미 샤드 제한으로 인해 제한되고 있다면, 단순히 배치하는 것만으로는 문제를 해결할 수 없습니다.",
            "Amazon S3를 임시 저장소로 사용하는 것은 워크플로우에 추가적인 지연과 복잡성을 초래합니다. S3에서 Kinesis로 데이터를 이동하는 추가 처리가 필요하므로 즉각적인 데이터 수집 용량 증가의 필요를 해결하지 못할 수 있습니다.",
            "새로운 Kinesis Data Stream을 생성하고 부하를 균형 있게 하는 것은 가능하지만, 이 접근 방식은 여러 스트림을 관리하는 복잡성을 추가하며 원래 스트림에서의 기존 제한 문제를 해결하지 않습니다."
        ]
    },
    {
        "Question Number": "13",
        "Situation": "한 회사가 백엔드 데이터베이스에 크게 의존하는 웹 애플리케이션에서 지연 문제를 겪고 있습니다. 이 애플리케이션은 동시에 많은 사용자에게 서비스를 제공하며, 직접 데이터베이스 접근이 성능을 저하시킵니다. 솔루션 아키텍트는 데이터 일관성을 보장하면서 성능을 개선하는 임무를 맡고 있습니다.",
        "Question": "솔루션 아키텍트가 캐싱을 통해 성능을 향상시키고 데이터베이스의 부하를 줄이기 위해 어떤 디자인 패턴을 구현해야 합니까?",
        "Options": {
            "1": "읽기 트래픽 증가를 처리하기 위해 데이터베이스의 읽기 복제본을 배포합니다.",
            "2": "데이터베이스 요청을 큐에 넣기 위해 Amazon SQS를 통합합니다.",
            "3": "자주 접근하는 데이터를 위해 Amazon ElastiCache를 사용하여 캐싱 레이어를 구현합니다.",
            "4": "서버리스 방식으로 요청을 처리하기 위해 AWS Lambda를 사용합니다."
        },
        "Correct Answer": "자주 접근하는 데이터를 위해 Amazon ElastiCache를 사용하여 캐싱 레이어를 구현합니다.",
        "Explanation": "Amazon ElastiCache를 사용하여 캐싱 레이어를 구현하면 자주 접근하는 데이터를 메모리에 저장할 수 있어 사용자가 경험하는 지연을 크게 줄이고 데이터베이스의 부하를 낮출 수 있습니다. 이 패턴은 애플리케이션 성능을 개선하는 데 효과적입니다.",
        "Other Options": [
            "데이터베이스의 읽기 복제본을 배포하면 읽기 트래픽을 분산하는 데 도움이 되지만, 기본 데이터베이스의 높은 부하로 인한 지연 문제를 해결하지는 않습니다. 이는 캐싱 전략이라기보다는 확장 솔루션에 가깝습니다.",
            "요청 처리를 위해 AWS Lambda를 사용하는 것은 확장성을 개선할 수 있지만, 데이터베이스 접근과 관련된 직접적인 성능 문제를 해결하지는 않습니다. Lambda 함수는 여전히 데이터베이스 접근이 필요하므로 병목 현상이 발생할 수 있습니다.",
            "Amazon SQS를 통합하면 요청 흐름을 관리하고 신뢰성을 향상시킬 수 있지만, 캐싱을 통해 성능을 직접적으로 향상시키지는 않습니다. 이는 데이터베이스 쿼리로 인한 지연을 줄이기보다는 구성 요소의 분리를 더 적합하게 합니다."
        ]
    },
    {
        "Question Number": "14",
        "Situation": "한 미디어 회사가 비디오 스트리밍 서비스를 AWS로 마이그레이션하고 있습니다. 이 서비스는 변동하는 트래픽 패턴을 경험하여 예측할 수 없는 데이터 전송 비용이 발생합니다. 솔루션 아키텍트는 온프레미스 스토리지에서 AWS로 데이터를 전송하는 비용 효율적인 방법을 설계해야 하며, 이 과정에서 이그레스 요금을 최소화해야 합니다.",
        "Question": "비디오 스트리밍 서비스의 데이터 전송 비용을 최적화하기 위해 솔루션 아키텍트가 구현해야 할 전략은 무엇입니까?",
        "Options": {
            "1": "Amazon S3 Transfer Acceleration을 사용하여 비디오를 S3에 빠르게 업로드하고 지연을 줄이면서 추가 전송 비용을 발생시킵니다.",
            "2": "AWS Snowball을 구현하여 대량의 비디오 데이터를 AWS로 전송하고, 초기 데이터 전송 시 배송 비용을 줄이고 이그레스 요금을 면제받습니다.",
            "3": "Amazon CloudFront를 활용하여 사용자 가까이에 비디오 콘텐츠를 캐시하고 S3에서의 원본 요청을 최소화하여 데이터 전송 비용을 줄입니다.",
            "4": "AWS Direct Connect를 활용하여 전용 네트워크 연결을 설정하여 대형 비디오 파일의 데이터 전송 비용을 줄입니다."
        },
        "Correct Answer": "AWS Snowball을 구현하여 대량의 비디오 데이터를 AWS로 전송하고, 초기 데이터 전송 시 배송 비용을 줄이고 이그레스 요금을 면제받습니다.",
        "Explanation": "AWS Snowball은 대량의 데이터를 AWS로 효율적으로 전송하기 위해 설계되었습니다. 초기 전송 과정에서 이그레스 요금을 없애주어 미디어 회사의 요구에 비용 효율적인 솔루션이 됩니다.",
        "Other Options": [
            "Amazon S3 Transfer Acceleration은 전송 속도를 높이지만 서비스를 사용하는 데 추가 비용이 발생하므로 비용 최적화에는 이상적이지 않을 수 있습니다.",
            "AWS Direct Connect는 AWS에 대한 신뢰할 수 있고 저지연 연결을 제공하지만, 초기 대량 전송보다는 지속적인 데이터 전송에 더 유리하며, 간헐적인 트래픽에 대한 비용을 크게 줄이지는 않을 수 있습니다.",
            "Amazon CloudFront는 콘텐츠 제공을 개선하지만, 대량 비디오 파일을 AWS로 초기 전송하는 문제를 해결하지 않으며, 여전히 S3에서 이그레스 요금이 발생할 수 있습니다."
        ]
    },
    {
        "Question Number": "15",
        "Situation": "한 글로벌 전자상거래 회사가 고객에게 높은 가용성과 낮은 지연을 보장하기 위해 여러 AWS 리전에서 애플리케이션을 배포했습니다. 애플리케이션 아키텍처는 데이터베이스 요구를 위해 Amazon RDS를 사용하며, 각 리전에 인스턴스가 위치해 있습니다. 그러나 최근 사건에서 회사는 서비스 중단을 초래한 리전 장애를 경험했습니다. 복원력을 강화하고 다운타임을 최소화하기 위해 솔루션 아키텍트는 Multi-AZ 및 다중 리전 배포를 활용한 보다 견고한 아키텍처를 설계해야 합니다.",
        "Question": "리전 장애 동안 다운타임을 최소화하면서 애플리케이션의 가용성과 복원력을 가장 잘 개선하는 솔루션은 무엇입니까?",
        "Options": {
            "1": "각 리전 내에서 Multi-AZ 구성으로 Amazon RDS 인스턴스를 배포하고, 읽기 트래픽을 처리하기 위해 교차 리전 읽기 복제본을 활성화합니다.",
            "2": "단일 리전 내에서 Multi-AZ 구성으로 Amazon RDS 인스턴스를 배포하고, 데이터베이스 부하를 줄이기 위해 Amazon ElastiCache를 사용합니다.",
            "3": "모든 리전에서 Multi-AZ 구성으로 Amazon RDS 인스턴스를 배포하고, 리전 간 데이터 동기화를 위해 DynamoDB Global Tables를 사용합니다.",
            "4": "단일 리전 내에서 Multi-AZ 구성으로만 Amazon RDS 인스턴스를 배포하고, Route 53 장애 조치 라우팅 정책을 구현하여 트래픽을 대기 리전으로 유도합니다."
        },
        "Correct Answer": "각 리전 내에서 Multi-AZ 구성으로 Amazon RDS 인스턴스를 배포하고, 읽기 트래픽을 처리하기 위해 교차 리전 읽기 복제본을 활성화합니다.",
        "Explanation": "이 옵션은 높은 가용성을 제공하며, 장애 발생 시 다른 리전에서 읽기 트래픽을 처리할 수 있는 능력을 제공하여 복원력을 개선하고 다운타임을 효과적으로 최소화합니다.",
        "Other Options": [
            "이 옵션은 단일 리전 내에서만 높은 가용성을 제공합니다. 리전 장애 동안 다운타임을 최소화하는 데 필수적인 교차 리전 복제를 결여하고 있습니다.",
            "이 옵션은 리전 간 Multi-AZ 구성을 최대한 활용하지 않으며, Route 53을 사용하여 장애 조치를 수행하더라도 리전 간 실시간 복제 부족으로 인해 데이터 불일치가 발생할 수 있습니다.",
            "리전 간 Multi-AZ를 사용하는 것은 가용성을 향상시키지만, 동기화를 위해 DynamoDB Global Tables에만 의존하는 것은 복잡성과 잠재적인 지연 문제를 초래할 수 있으며, 이는 애플리케이션 성능에 영향을 미칠 수 있습니다."
        ]
    },
    {
        "Question Number": "16",
        "Situation": "한 회사가 전 세계 사용자에게 저지연 액세스를 제공하는 글로벌 애플리케이션을 배포할 계획입니다. 이 애플리케이션은 여러 마이크로서비스로 구성되어 있으며, 데이터 일관성과 높은 가용성을 보장하면서 여러 AWS 리전에서 배포되어야 합니다. 회사는 최종 사용자에 대한 성능을 개선하고 지연 시간을 줄이기 위해 글로벌 캐시 레이어를 제공하는 AWS 서비스를 사용하고 싶어합니다. 다음 솔루션 중 이 요구 사항에 가장 적합한 것은 무엇입니까?",
        "Question": "회사가 애플리케이션에 대한 글로벌 캐시 레이어를 제공하기 위해 어떤 AWS 서비스를 사용해야 합니까?",
        "Options": {
            "1": "Amazon CloudFront와 각 리전에서 애플리케이션 자산을 호스팅하는 S3 버킷으로의 오리진 페일오버.",
            "2": "Amazon CloudFront와 Lambda@Edge를 사용하여 콘텐츠 전송을 사용자 정의하고 전 세계적으로 지연 시간을 줄입니다.",
            "3": "Amazon ElastiCache와 복제 그룹을 사용하여 서로 다른 AWS 리전 간의 캐시 일관성을 유지합니다.",
            "4": "AWS Global Accelerator를 사용하여 Amazon Route 53을 DNS 관리에 사용하면서 가장 가까운 애플리케이션 엔드포인트로 트래픽을 라우팅합니다."
        },
        "Correct Answer": "Amazon CloudFront와 Lambda@Edge를 사용하여 콘텐츠 전송을 사용자 정의하고 전 세계적으로 지연 시간을 줄입니다.",
        "Explanation": "Amazon CloudFront는 전 세계 엣지 위치에서 콘텐츠를 캐시하여 사용자에게 저지연 액세스를 제공하는 콘텐츠 전송 네트워크(CDN)입니다. Lambda@Edge는 콘텐츠 전송을 사용자 정의할 수 있게 하여 애플리케이션이 사용자 요청에 따라 콘텐츠를 동적으로 조정하고 성능을 더욱 최적화할 수 있도록 합니다.",
        "Other Options": [
            "Amazon CloudFront와 오리진 페일오버를 S3 버킷으로 설정하면 동적 콘텐츠에 대한 캐시 레이어를 제공하지 않으며 저지연이 필요한 마이크로서비스에 최적화되어 있지 않습니다.",
            "Amazon ElastiCache는 단일 리전 내에서 캐싱을 위해 설계되었으며, 글로벌 애플리케이션에 필수적인 글로벌 캐싱을 기본적으로 지원하지 않습니다.",
            "AWS Global Accelerator는 가장 가까운 엔드포인트로 트래픽을 라우팅하여 애플리케이션의 가용성과 성능을 개선하지만, 지연 시간을 줄이는 데 필요한 캐싱 기능은 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "17",
        "Situation": "한 금융 서비스 회사가 온프레미스 애플리케이션을 AWS로 마이그레이션할 계획입니다. 이 애플리케이션은 중요하며 높은 가용성과 저지연이 필요합니다. 회사는 애플리케이션의 아키텍처, 종속성 및 사용할 최상의 AWS 서비스를 이해하기 위해 평가해야 합니다. 그들은 마이그레이션이 기존 운영을 방해하지 않고 새로운 환경이 규정 준수 요구 사항을 충족하는지 확인하고 싶어합니다. 팀은 애플리케이션의 아키텍처, 네트워크 요구 사항 및 성능 메트릭에 대한 정보를 수집하려고 합니다. 또한 데이터베이스 종속성과 잠재적인 병목 현상을 식별해야 합니다.",
        "Question": "회사가 애플리케이션에 대한 포괄적인 마이그레이션 평가를 완료하기 위해 어떤 접근 방식을 취해야 합니까?",
        "Options": {
            "1": "AWS Application Discovery Service를 활용하여 온프레미스 애플리케이션에 대한 아키텍처, 성능 메트릭 및 네트워크 종속성을 포함한 자세한 정보를 수집합니다.",
            "2": "제3자 컨설팅 회사를 참여시켜 애플리케이션을 분석하고 클라우드 마이그레이션에 대한 전문 지식을 바탕으로 AWS 서비스를 추천합니다.",
            "3": "AWS로 마이그레이션하기 전에 애플리케이션 코드 및 아키텍처 문서를 수동으로 검토하여 종속성과 성능 병목 현상을 식별합니다.",
            "4": "AWS에서 애플리케이션의 제한된 하위 집합으로 파일럿 프로젝트를 구현하여 성능을 테스트하고 전체 마이그레이션 전에 잠재적인 마이그레이션 문제를 식별합니다."
        },
        "Correct Answer": "AWS Application Discovery Service를 활용하여 온프레미스 애플리케이션에 대한 아키텍처, 성능 메트릭 및 네트워크 종속성을 포함한 자세한 정보를 수집합니다.",
        "Explanation": "AWS Application Discovery Service는 조직이 온프레미스 애플리케이션에 대한 정보, 즉 아키텍처, 종속성 및 성능 메트릭을 수집하는 데 특별히 설계되었습니다. 이 데이터는 AWS로의 마이그레이션 계획 및 애플리케이션의 모든 측면을 고려하는 데 중요하며, 이는 중단을 최소화하고 규정 준수 요구 사항을 충족하는 데 도움이 됩니다.",
        "Other Options": [
            "수동 검토를 수행하면 일부 통찰력을 제공할 수 있지만, 이는 인간 오류에 취약하며 자동화 도구가 쉽게 캡처할 수 있는 중요한 종속성이나 성능 메트릭을 놓칠 수 있습니다.",
            "파일럿 프로젝트를 구현하면 문제를 식별하는 데 도움이 될 수 있지만, 포괄적인 마이그레이션 평가에 필수적인 애플리케이션의 아키텍처 및 종속성에 대한 완전한 시각을 제공하지 않습니다.",
            "제3자 컨설팅 회사를 참여시키면 귀중한 통찰력을 제공할 수 있지만, 외부 전문 지식에만 의존하면 내부 팀이 맞춤형 AWS 도구를 사용하여 평가할 수 있는 특정 세부 사항을 간과할 수 있습니다."
        ]
    },
    {
        "Question Number": "18",
        "Situation": "한 금융 서비스 회사가 새로운 모바일 뱅킹 애플리케이션을 지원하기 위해 인프라를 확장하고 있습니다. 그들은 네트워크 트래픽을 효과적으로 모니터링하여 의심스러운 활동을 감지하고 규제 기준을 준수할 수 있도록 해야 합니다. 회사는 현재 Amazon VPC와 AWS CloudTrail을 사용하고 있지만 모니터링 기능을 강화하고 싶어합니다.",
        "Question": "다음 솔루션 중 회사가 네트워크 트래픽을 효과적으로 모니터링하고 규제 기준을 준수하는 데 가장 도움이 될 것인가요?",
        "Options": {
            "1": "Amazon Inspector를 사용하여 애플리케이션에 대한 보안 평가를 수행하고 규정 준수 보고서를 생성합니다.",
            "2": "AWS WAF를 배포하여 들어오는 요청을 필터링하고 애플리케이션에 도달하기 전에 악성 트래픽을 차단합니다.",
            "3": "AWS CloudTrail을 설정하여 계정에서 수행된 모든 API 호출을 기록하고 의심스러운 활동을 위해 로그를 주기적으로 검토합니다.",
            "4": "AWS VPC Flow Logs를 구현하여 VPC 내의 트래픽을 캡처하고 분석하며 비정상적인 패턴에 대한 경고를 구성합니다."
        },
        "Correct Answer": "AWS VPC Flow Logs를 구현하여 VPC 내의 트래픽을 캡처하고 분석하며 비정상적인 패턴에 대한 경고를 구성합니다.",
        "Explanation": "AWS VPC Flow Logs는 VPC의 네트워크 인터페이스로 흐르는 네트워크 트래픽에 대한 자세한 가시성을 제공합니다. 이를 통해 회사는 트래픽 패턴을 분석하고 이상 징후를 감지하며 규제 기준을 효과적으로 준수할 수 있습니다.",
        "Other Options": [
            "AWS CloudTrail은 API 호출을 기록하는 데 유용하지만, 의심스러운 활동을 모니터링하는 데 필수적인 실제 네트워크 트래픽에 대한 자세한 가시성을 제공하지 않습니다.",
            "Amazon Inspector는 애플리케이션 보안 평가에 주로 초점을 맞추고 있어 실시간 네트워크 트래픽 모니터링에는 적합하지 않습니다.",
            "AWS WAF는 일반적인 웹 공격으로부터 애플리케이션을 보호하는 데 사용되지만, 의심스러운 네트워크 패턴을 분석하고 감지하는 데 필요한 포괄적인 트래픽 모니터링 기능을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "19",
        "Situation": "한 회사가 SQL 인젝션 및 크로스 사이트 스크립팅과 같은 일반적인 웹 취약점으로부터 보호가 필요한 새로운 웹 애플리케이션을 배포하고 있습니다. 그들은 AWS WAF를 사용하여 트래픽이 CloudFront 배포에 도달하기 전에 필터링하고자 합니다. 팀은 WAF의 구성 및 유지 관리를 간소화하기 위해 AWS Managed Rules를 사용하는 것을 고려하고 있습니다. 또한 특정 IP 주소에서의 남용을 방지하기 위해 속도 제한을 구현하고자 합니다. (두 가지 선택)",
        "Question": "이 시나리오에 대해 AWS WAF를 효과적으로 구현하기 위해 어떤 조치를 취해야 합니까?",
        "Options": {
            "1": "일반적인 취약점으로부터 보호를 제공하는 WebACL에 추가할 하나 이상의 AWS Managed Rule 그룹을 선택합니다.",
            "2": "지정된 요청 임계값을 초과하는 IP 주소를 차단하기 위해 WebACL에 속도 기반 규칙을 구현합니다.",
            "3": "조건에 관계없이 CloudFront 배포로의 모든 트래픽을 허용하는 사용자 정의 규칙을 생성합니다.",
            "4": "보안을 강화하기 위해 특정 지리적 위치에서만 트래픽을 허용하도록 WebACL을 구성합니다.",
            "5": "WebACL의 기본 동작을 차단하는 대신 요청을 계산하도록 수정합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "일반적인 취약점으로부터 보호를 제공하는 WebACL에 추가할 하나 이상의 AWS Managed Rule 그룹을 선택합니다.",
            "지정된 요청 임계값을 초과하는 IP 주소를 차단하기 위해 WebACL에 속도 기반 규칙을 구현합니다."
        ],
        "Explanation": "AWS Managed Rule 그룹을 선택함으로써, 광범위한 구성 없이도 일반적인 취약점으로부터 애플리케이션을 자동으로 보호하는 미리 정의된 규칙을 활용할 수 있습니다. 속도 기반 규칙을 구현하면 개별 IP 주소로부터의 요청 수를 제한하여 남용을 효과적으로 방지하고 자원의 공정한 사용을 보장할 수 있습니다.",
        "Other Options": [
            "모든 트래픽을 허용하는 사용자 정의 규칙을 생성하는 것은 WAF를 구현하는 목적을 무효화하며, 필터링 없이 모든 유형의 공격에 애플리케이션을 노출시킵니다.",
            "WebACL을 특정 지리적 위치에서만 트래픽을 허용하도록 구성하면 다른 지역의 합법적인 사용자가 차단될 수 있어 접근성이 감소할 수 있습니다.",
            "기본 동작을 요청을 계산하도록 수정하는 것은 보호 조치를 제공하지 않으며, 보안 정책을 시행하지 않고 단순히 트래픽을 기록합니다."
        ]
    },
    {
        "Question Number": "20",
        "Situation": "한 조직이 서로 다른 팀이 안전하게 공유 리소스에 접근할 수 있는 다중 계정 AWS 환경을 구현하고 있습니다. 보안 팀은 무단 접근의 위험을 완화하기 위해 외부 ID가 포함된 IAM 역할 사용을 권장했습니다. 조직은 외부 당사자가 민감한 권한을 노출하지 않고 안전하게 역할을 맡을 수 있도록 보장하고자 합니다.",
        "Question": "조직이 외부 당사자가 AWS 계정 내에서 역할을 안전하게 맡을 수 있도록 하려면 어떤 접근 방식을 취해야 합니까?",
        "Options": {
            "1": "외부 ID를 사용하지 않고 외부 서비스가 귀하의 계정의 리소스에 접근할 수 있도록 하는 서비스 연결 역할을 정의합니다.",
            "2": "외부 당사자가 역할을 맡을 때 외부 ID를 제공하도록 요구하는 신뢰 정책이 포함된 역할을 구성합니다.",
            "3": "외부 당사자에게 접근을 부여하는 IAM 정책을 설정하고 그들이 필요로 하는 리소스에 직접 연결합니다.",
            "4": "각 외부 당사자에 대해 장기 액세스 키가 있는 새로운 IAM 사용자를 생성하고 필요한 권한을 제공합니다."
        },
        "Correct Answer": "외부 당사자가 역할을 맡을 때 외부 ID를 제공하도록 요구하는 신뢰 정책이 포함된 역할을 구성합니다.",
        "Explanation": "외부 ID를 요구하는 신뢰 정책을 사용하면 외부 당사자가 올바른 외부 ID를 제공할 때만 역할을 맡을 수 있도록 보장하여 보안을 강화합니다. 이는 무단 사용자가 역할을 맡는 위험을 완화합니다.",
        "Other Options": [
            "장기 액세스 키가 있는 IAM 사용자를 생성하는 것은 자격 증명 유출의 위험을 증가시키며, 임시 접근에 대한 모범 사례를 따르지 않습니다.",
            "서비스 연결 역할은 AWS 서비스에 의해 미리 정의되며 외부 ID나 사용자 정의 권한을 허용하지 않기 때문에 외부 당사자에게 접근을 부여하는 데 적합하지 않습니다.",
            "외부 당사자를 위한 IAM 정책을 리소스에 직접 연결하는 것은 외부 ID가 제공하는 필요한 보안 통제를 제공하지 않으며, 외부 당사자의 신원을 확인하지 않고 민감한 권한을 노출할 수 있습니다."
        ]
    },
    {
        "Question Number": "21",
        "Situation": "한 금융 서비스 회사가 실시간으로 거래를 처리하는 애플리케이션을 구현하고 있습니다. 이러한 거래의 중요성을 고려할 때, 회사는 엄격한 서비스 수준 계약(SLA)을 준수하고 애플리케이션 성능을 효과적으로 모니터링하기 위해 관련 핵심 성과 지표(KPI)를 설정해야 합니다.",
        "Question": "다음 접근 방식 중 어떤 것이 애플리케이션이 SLA 및 KPI를 충족하면서 높은 신뢰성과 성능을 유지하도록 가장 잘 보장합니까?",
        "Options": {
            "1": "최대 응답 시간 및 최대 다운타임을 지정하는 SLA를 정의하고, 여러 지역에 걸쳐 고가용성 아키텍처를 구현합니다.",
            "2": "SLA 준수를 보장하기 위해 애플리케이션 성능을 매주 수동으로 검증하는 전담 팀을 구성합니다.",
            "3": "애플리케이션을 호스팅하기 위해 단일 EC2 인스턴스를 사용하고, 모든 실패로부터 복구하기 위해 매일 백업을 구현합니다.",
            "4": "애플리케이션 성능 메트릭을 추적하고 KPI가 충족되지 않을 때 운영 팀에 경고하는 모니터링 솔루션을 구현합니다."
        },
        "Correct Answer": "최대 응답 시간 및 최대 다운타임을 지정하는 SLA를 정의하고, 여러 지역에 걸쳐 고가용성 아키텍처를 구현합니다.",
        "Explanation": "이 접근 방식은 SLA를 염두에 두고 애플리케이션을 설계하여 명확한 성능 기대치를 설정하고, 다중 지역 아키텍처를 통해 중복성을 제공합니다. 이 설정은 제공되는 서비스의 중요성에 부합하여 가용성과 복원력을 크게 향상시킵니다.",
        "Other Options": [
            "애플리케이션 성능 메트릭을 모니터링하는 것은 필수적이지만, 경고에만 의존하는 것은 SLA 및 KPI가 충족되도록 사전 예방적으로 보장하지 않습니다. 이는 높은 신뢰성을 위한 구조적 보장이 부족합니다.",
            "단일 EC2 인스턴스를 사용하는 것은 단일 실패 지점을 도입하며, 중요한 거래를 처리하는 데 필요한 높은 가용성 요구 사항을 충족하지 않습니다. 매일 백업은 실시간 가용성을 대체하지 않습니다.",
            "수동 검증 프로세스는 애플리케이션 성능을 모니터링하는 확장 가능하거나 효과적인 방법이 아닙니다. 이 방법은 지연 및 인적 오류에 취약하여 SLA 준수에 대한 실시간 통찰력을 제공하지 못합니다."
        ]
    },
    {
        "Question Number": "22",
        "Situation": "한 회사가 중요한 문서를 저장하기 위해 Amazon S3 버킷을 사용하고 있습니다. 최근에 이러한 문서의 변경 사항을 추적하기 위해 버전 관리를 활성화했습니다. 버전 관리를 활성화한 후, 기존 문서와 향후 업로드가 어떻게 영향을 받을지, 필요할 경우 이전 버전으로 되돌릴 수 있는지에 대해 우려하고 있습니다.",
        "Question": "S3 버킷에서 버전 관리를 활성화하는 것의 의미는 무엇인가요? (두 가지 선택)",
        "Options": {
            "1": "버전 관리가 활성화되면 버킷을 삭제하지 않고는 비활성화할 수 없습니다.",
            "2": "버킷의 기존 객체는 null 버전 ID를 유지하며 영향을 받지 않습니다.",
            "3": "삭제된 객체는 여전히 버킷에 이전 버전을 유지합니다.",
            "4": "버킷에 업로드된 모든 새로운 객체는 고유한 버전 ID를 받습니다.",
            "5": "버전 관리를 활성화하면 기존 객체에 고유한 버전 ID가 소급적으로 할당됩니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "버킷의 기존 객체는 null 버전 ID를 유지하며 영향을 받지 않습니다.",
            "버킷에 업로드된 모든 새로운 객체는 고유한 버전 ID를 받습니다."
        ],
        "Explanation": "S3 버킷에서 버전 관리가 활성화되면 기존 객체는 변경되지 않고 버전 ID가 null로 설정됩니다. 그러나 버킷에 업로드된 새로운 객체는 고유한 버전 ID를 받아 객체 버전의 추적 및 관리를 개선할 수 있습니다.",
        "Other Options": [
            "이 옵션은 잘못된 것입니다. 버전 관리를 활성화하면 기존 객체에 고유한 버전 ID가 소급적으로 할당되지 않으며, 그들은 null 버전 ID를 유지합니다.",
            "이 옵션은 잘못된 것입니다. 버전 관리는 중단할 수 있지만, 버전 관리를 중지하기 위해 버킷 자체를 삭제할 필요는 없습니다.",
            "이 옵션은 잘못된 것입니다. 삭제된 객체는 영구적으로 제거되지 않으며, 대신 삭제된 것으로 표시되고 이전 버전은 여전히 접근할 수 있습니다."
        ]
    },
    {
        "Question Number": "23",
        "Situation": "한 회사가 엣지 장치가 데이터를 로컬에서 처리하고 AWS IoT 서비스와 통신하여 관리 및 분석을 수행할 수 있는 솔루션을 구현하려고 합니다. 아키텍처는 장치가 간헐적인 연결 중에도 독립적으로 작동할 수 있도록 해야 합니다. 솔루션 아키텍트는 AWS 서비스를 사용하여 가장 적합한 접근 방식을 선택해야 합니다.",
        "Question": "AWS 서비스를 활용한 다음 구성 중 엣지 장치에 클라우드 기능을 확장하면서 생성한 데이터를 로컬에서 처리할 수 있도록 하는 최상의 솔루션은 무엇인가요?",
        "Options": {
            "1": "AWS Lambda@Edge를 사용하여 CloudFront에서 요청 및 응답을 수정하는 함수를 실행하여 사용자에게 더 가까운 데이터 처리를 가능하게 하지만 일관된 인터넷 연결에 의존합니다.",
            "2": "엣지 장치에 AWS IoT Greengrass를 배포하여 AWS Lambda 함수를 로컬에서 실행하고 인터넷 연결 없이도 AWS 서비스와 안전하게 통신할 수 있도록 합니다.",
            "3": "엣지에서 Amazon EC2 인스턴스를 구현하여 로컬에서 데이터를 처리하는 애플리케이션을 실행하고 관리 및 분석을 위해 AWS에 연결합니다.",
            "4": "AWS IoT Core를 활용하여 장치를 클라우드에 직접 연결하고 로컬 실행 없이 모든 데이터 처리를 클라우드에서 수행합니다."
        },
        "Correct Answer": "엣지 장치에 AWS IoT Greengrass를 배포하여 AWS Lambda 함수를 로컬에서 실행하고 인터넷 연결 없이도 AWS 서비스와 안전하게 통신할 수 있도록 합니다.",
        "Explanation": "AWS IoT Greengrass는 엣지 장치가 AWS Lambda 함수를 실행하고 생성한 데이터를 기반으로 로컬 작업을 수행할 수 있도록 합니다. 이 기능은 장치가 연결이 끊겼을 때도 독립적으로 작동할 수 있도록 하며, 연결이 가능할 때 AWS 서비스와 안전하게 통신할 수 있도록 합니다.",
        "Other Options": [
            "AWS Lambda@Edge는 AWS 네트워크의 엣지에서 함수를 실행하도록 설계되었으며, 주로 CloudFront와 함께 요청 및 응답을 수정하는 데 사용됩니다. 이 솔루션은 인터넷 연결에 크게 의존하며 장치 자체에서 함수를 로컬로 실행할 수 없습니다.",
            "엣지에서 Amazon EC2 인스턴스를 사용하는 것은 로컬 처리 기능을 제공할 수 있지만, 엣지 장치 관리나 연결이 끊긴 상태에서 AWS 서비스와의 안전한 통신을 특별히 고려하지 않습니다. 또한 불필요한 오버헤드와 복잡성을 도입할 수 있습니다.",
            "AWS IoT Core는 클라우드 서비스와의 직접 통신을 허용하지만, 엣지 장치에 대한 로컬 처리 기능을 제공하지 않습니다. 이 옵션은 지속적인 인터넷 연결이 필요하므로 연결 문제 발생 시 로컬 작업이 필요한 시나리오에는 적합하지 않습니다."
        ]
    },
    {
        "Question Number": "24",
        "Situation": "소프트웨어 개발 팀이 AWS 서비스를 사용하여 애플리케이션 배포를 자동화하는 CI/CD 파이프라인을 구현하고 있습니다. 그들은 코드 변경 사항이 수동 개입 없이 자동으로 빌드, 테스트 및 여러 환경에 배포되도록 하기를 원합니다. 팀은 이 목표를 달성하기 위해 다양한 AWS 도구를 고려하고 있습니다.",
        "Question": "이 시나리오에서 AWS에서 CI/CD 파이프라인을 구현하는 가장 효과적인 방법은 무엇인가요?",
        "Options": {
            "1": "EC2 인스턴스에서 Jenkins 서버를 설정하여 애플리케이션의 빌드 및 배포 프로세스를 관리합니다.",
            "2": "AWS Elastic Beanstalk를 사용하여 수동 배포 프로세스를 구현하고 애플리케이션을 스테이징 환경에 배포합니다.",
            "3": "AWS Lambda 함수를 활용하여 배포 트리거를 처리하고 전용 파이프라인 없이 CI/CD 프로세스를 관리합니다.",
            "4": "AWS CodePipeline을 사용하여 CI/CD 워크플로를 조정하고 AWS CodeBuild 및 AWS CodeDeploy와 통합합니다."
        },
        "Correct Answer": "AWS CodePipeline을 사용하여 CI/CD 워크플로를 조정하고 AWS CodeBuild 및 AWS CodeDeploy와 통합합니다.",
        "Explanation": "AWS CodePipeline을 사용하면 CI/CD 파이프라인의 단계를 쉽게 정의하고, CodeBuild와 같은 다른 AWS 서비스와 통합하여 코드를 빌드하고 CodeDeploy를 통해 배포하며, 코드 커밋부터 배포까지 전체 프로세스를 자동화할 수 있는 완전 관리형 서비스를 제공합니다. 이 접근 방식은 수동 개입을 최소화하고 효율성을 극대화합니다.",
        "Other Options": [
            "AWS Elastic Beanstalk를 사용하여 수동 배포 프로세스를 구현하는 것은 적절한 CI/CD 파이프라인이 제공하는 자동화 및 지속적인 통합 기능을 제공하지 않으므로 인적 오류의 위험이 증가하고 릴리스 주기가 느려질 수 있습니다.",
            "배포 트리거를 위해 AWS Lambda 함수를 활용하는 것은 빌드 관리 및 배포 조정과 같은 CI/CD 파이프라인의 포괄적인 기능이 부족하여 전체 개발 생애 주기를 자동화하는 데 덜 효과적인 솔루션이 됩니다.",
            "EC2 인스턴스에서 Jenkins 서버를 설정하는 것은 AWS 관리 서비스인 CodePipeline을 사용하는 것에 비해 불필요한 복잡성과 유지 관리 오버헤드를 추가합니다. CodePipeline은 CI/CD 워크플로를 위해 특별히 설계되었습니다."
        ]
    },
    {
        "Question Number": "25",
        "Situation": "스타트업 회사가 AWS 비용을 최적화하면서 성장하는 웹 애플리케이션에 충분한 용량을 확보하려고 합니다. 이들은 AWS에서 제공하는 다양한 구매 옵션을 고려하고 있습니다. 회사의 작업 부하는 예측 가능하며, 업무 시간 동안 일관된 사용 패턴을 보이고 비업무 시간 동안에는 최소한의 사용이 이루어집니다. 이 시나리오에 가장 비용 효율적인 구매 옵션은 무엇인가요?",
        "Question": "솔루션 아키텍트가 스타트업의 예측 가능한 작업 부하에 대한 비용 최적화를 위해 추천해야 할 AWS 구매 옵션은 무엇인가요?",
        "Options": {
            "1": "업무 시간 동안 일관된 작업 부하를 커버하기 위해 1년 기간의 예약 인스턴스를 구매합니다.",
            "2": "사용 패턴에 따라 비용을 줄이면서 유연성을 제공하기 위해 세이빙 플랜을 구현합니다.",
            "3": "더 낮은 가격을 활용하기 위해 전체 작업 부하에 대해 스팟 인스턴스를 사용합니다.",
            "4": "사전 약정 없이 유연성을 유지하기 위해 온디맨드 인스턴스를 활용합니다."
        },
        "Correct Answer": "업무 시간 동안 일관된 작업 부하를 커버하기 위해 1년 기간의 예약 인스턴스를 구매합니다.",
        "Explanation": "1년 기간의 예약 인스턴스를 구매하는 것은 예측 가능한 작업 부하에 가장 비용 효율적인 옵션으로, 온디맨드 가격에 비해 상당한 절약을 제공하며, 업무 시간 동안 일관된 사용을 위해 용량이 예약됩니다.",
        "Other Options": [
            "스팟 인스턴스를 사용하면 중단이 발생할 수 있으며, 이러한 인스턴스는 언제든지 AWS에 의해 회수될 수 있으므로 일관된 가동 시간이 필요한 예측 가능한 작업 부하에는 적합하지 않습니다.",
            "세이빙 플랜을 구현하면 어느 정도의 유연성을 제공하지만, 매우 예측 가능한 작업 부하의 경우 예약 인스턴스가 사용에 대한 약정으로 인해 일반적으로 더 큰 절약을 제공합니다.",
            "온디맨드 인스턴스를 활용하면 유연성과 사전 비용 없이 운영할 수 있지만, 예약 인스턴스에 비해 예측 가능한 작업 부하에 가장 비싼 옵션입니다."
        ]
    },
    {
        "Question Number": "26",
        "Situation": "금융 서비스 회사는 민감한 고객 거래 데이터를 관리하기 위해 EC2 인스턴스 세트와 Amazon RDS for PostgreSQL 데이터베이스에 의존하고 있습니다. 이들은 데이터 무결성과 규제 요구 사항 준수를 보장하기 위해 강력한 백업 및 복원 전략이 필요합니다. 회사는 애플리케이션 성능에 영향을 주지 않고 백업을 수행해야 하며, RTO는 2시간 미만, RPO는 10분을 초과하지 않아야 합니다. 또한, 민감한 데이터는 전송 중과 저장 중 모두 암호화되어야 합니다.",
        "Question": "솔루션 아키텍트로서 RTO, RPO 및 데이터 암호화 요구 사항을 충족하면서 애플리케이션에 대한 성능 영향을 최소화할 수 있는 백업 및 복원 전략은 무엇인가요?",
        "Options": {
            "1": "15분 스냅샷 간격으로 RDS 자동 백업을 활성화합니다. Amazon S3를 사용하여 백업을 저장하고, S3 관리 키로 서버 측 암호화를 구성하며, TLS로 전송 중 데이터가 암호화되도록 합니다.",
            "2": "RDS 인스턴스의 수동 백업을 30분마다 예약하고, 거래 로그를 5분마다 S3 버킷에 저장합니다. AWS Secrets Manager를 사용하여 암호화 키를 관리하고, HTTPS로 전송 중 데이터가 암호화되도록 합니다.",
            "3": "AWS Backup을 구현하여 RDS 인스턴스의 일일 백업을 생성하고 5분 스냅샷 빈도로 자동 백업을 활성화합니다. AWS Key Management Service (KMS)를 사용하여 저장 중 데이터의 암호화 키를 관리하고, 전송 중 데이터에 대해 SSL이 활성화되도록 합니다.",
            "4": "AWS Data Pipeline을 사용하여 RDS 인스턴스의 백업을 매시간 예약하고 Amazon S3로 전송합니다. AWS CloudHSM을 사용하여 백업의 암호화를 구성하고, IPsec을 사용하여 전송 중 데이터가 암호화되도록 합니다."
        },
        "Correct Answer": "AWS Backup을 구현하여 RDS 인스턴스의 일일 백업을 생성하고 5분 스냅샷 빈도로 자동 백업을 활성화합니다. AWS Key Management Service (KMS)를 사용하여 저장 중 데이터의 암호화 키를 관리하고, 전송 중 데이터에 대해 SSL이 활성화되도록 합니다.",
        "Explanation": "이 옵션은 최소한의 성능 영향을 주면서 자동 백업이 생성되도록 보장하며, 5분 RPO를 제공하여 요구 사항을 충족합니다. 또한, AWS KMS를 활용하여 저장 중 암호화와 전송 중 SSL 암호화를 보장하여 회사의 보안 정책을 준수합니다.",
        "Other Options": [
            "이 옵션은 30분마다 수동 백업을 수행하므로 10분 RPO 요구 사항을 충족하지 못하며, 데이터 손실이 발생할 수 있습니다. 또한, AWS Secrets Manager는 저장 중 데이터의 암호화 키를 관리하기 위해 주로 설계되지 않았습니다.",
            "RDS 자동 백업은 좋은 기능이지만, 15분 스냅샷 간격은 10분 RPO 요구 사항을 충족하지 못합니다. 또한, S3 관리 키를 사용하는 것은 AWS KMS의 암호화 키 관리와 동일한 수준의 제어를 제공하지 않습니다.",
            "AWS Data Pipeline을 사용하여 백업을 예약하면 불필요한 복잡성이 발생할 수 있으며, 매시간 백업은 10분 RPO 요구 사항을 충족하지 못합니다. CloudHSM은 강력한 키 관리를 제공하지만, 백업 암호화를 위한 RDS와의 통합이 간단하지 않을 수 있습니다."
        ]
    },
    {
        "Question Number": "27",
        "Situation": "한 회사가 대규모 온프레미스 애플리케이션을 AWS로 마이그레이션할 계획입니다. 애플리케이션은 단일 리전 내 여러 가용 영역에 호스팅될 것입니다. 마이그레이션 전략의 일환으로, 회사는 높은 가용성과 성능을 유지하면서 데이터 전송 비용을 최소화하려고 합니다. 특히 AWS 서비스와 온프레미스 데이터 센터 간의 데이터 전송과 관련된 비용에 대해 우려하고 있습니다.",
        "Question": "다음 전략 중 어떤 것이 회사가 마이그레이션된 애플리케이션의 높은 가용성과 성능을 보장하면서 데이터 전송 비용을 최소화하는 데 가장 도움이 될까요?",
        "Options": {
            "1": "여러 가상 사설 클라우드(VPC) 간에 VPC 피어링을 구현하여 AWS 리전 내에서 비용 없이 데이터 전송을 용이하게 합니다.",
            "2": "AWS Direct Connect를 사용하여 온프레미스 데이터 센터와 AWS 간에 전용 연결을 설정하여 낮은 대기 시간과 데이터 전송 비용 절감을 보장합니다.",
            "3": "Amazon CloudFront를 콘텐츠 전송 네트워크로 활용하여 엣지 위치에서 데이터를 캐시하여 AWS의 원본에서 전송되는 데이터 양을 줄입니다.",
            "4": "AWS Global Accelerator를 활용하여 온프레미스 데이터 센터에서 AWS 리전으로의 경로를 최적화하여 대기 시간을 줄이고 성능을 향상시킵니다."
        },
        "Correct Answer": "AWS Direct Connect를 사용하여 온프레미스 데이터 센터와 AWS 간에 전용 연결을 설정하여 낮은 대기 시간과 데이터 전송 비용 절감을 보장합니다.",
        "Explanation": "AWS Direct Connect를 사용하면 온프레미스 데이터 센터와 AWS 간에 전용 고대역폭 연결이 제공되어 인터넷을 사용하는 것에 비해 데이터 전송 비용이 크게 줄어듭니다. 이 방법은 또한 낮은 대기 시간과 높은 신뢰성을 보장하여 고성능 애플리케이션에 이상적입니다.",
        "Other Options": [
            "Amazon CloudFront를 활용하면 주로 대기 시간을 줄이고 콘텐츠 배포를 위한 캐싱 이점을 제공하지만, 온프레미스와 AWS 간의 대량 데이터 이동과 관련된 데이터 전송 비용을 직접적으로 해결하지는 않습니다.",
            "VPC 피어링을 구현하면 동일 리전 내 VPC 간의 무료 데이터 전송이 가능하지만, 온프레미스와 AWS 간의 데이터 전송에는 적용되지 않으므로 이 특정 시나리오에서 비용을 최소화하는 데 도움이 되지 않습니다.",
            "AWS Global Accelerator를 활용하면 AWS 서비스로의 트래픽 라우팅을 최적화하지만, 온프레미스 데이터 센터와 AWS 서비스 간의 데이터 전송 비용에 직접적인 영향을 미치지 않습니다."
        ]
    },
    {
        "Question Number": "28",
        "Situation": "금융 서비스 조직이 AWS에서 강력한 자격 증명 관리 시스템을 구현하여 보안 태세를 강화하려고 합니다. 솔루션 아키텍트는 API 키, 비밀번호 및 데이터베이스 자격 증명과 같은 민감한 정보를 안전하게 관리, 저장 및 검색할 수 있는 효과적인 서비스를 식별해야 합니다. 조직은 기존 AWS 서비스에 쉽게 통합할 수 있고 사용자에 대한 세분화된 액세스 제어를 제공하는 솔루션을 요구합니다. (두 가지 선택)",
        "Question": "솔루션 아키텍트가 자격 증명 관리를 위해 추천해야 할 AWS 서비스 조합은 무엇입니까?",
        "Options": {
            "1": "AWS Systems Manager Parameter Store를 구현하여 구성 데이터와 비밀을 내장된 암호화로 관리합니다.",
            "2": "AWS Secrets Manager를 사용하여 민감한 자격 증명을 저장하고 검색하며 자동으로 회전합니다.",
            "3": "AWS Lambda를 활용하여 환경 변수를 사용한 맞춤형 자격 증명 관리 솔루션을 만듭니다.",
            "4": "Amazon Cognito를 채택하여 자격 증명 저장을 위한 사용자 인증 및 액세스 제어를 관리합니다.",
            "5": "AWS Identity and Access Management (IAM) 역할을 활용하여 사용자 비밀번호를 안전하게 직접 저장합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "AWS Secrets Manager를 사용하여 민감한 자격 증명을 저장하고 검색하며 자동으로 회전합니다.",
            "AWS Systems Manager Parameter Store를 구현하여 구성 데이터와 비밀을 내장된 암호화로 관리합니다."
        ],
        "Explanation": "AWS Secrets Manager는 자격 증명과 같은 민감한 정보를 관리하기 위해 특별히 설계되었으며, 자동 회전 및 세분화된 액세스 제어를 제공합니다. AWS Systems Manager Parameter Store는 비밀을 포함한 구성 데이터를 안전하게 저장할 수 있는 방법을 제공하며, 암호화를 통해 자격 증명 관리에 적합합니다.",
        "Other Options": [
            "AWS Identity and Access Management (IAM) 역할은 AWS 리소스에 대한 권한 및 액세스를 관리하는 데 사용되지만, 사용자 비밀번호를 안전하게 저장하는 메커니즘을 제공하지 않으므로 자격 증명 관리에는 부적합합니다.",
            "AWS Lambda를 사용하여 맞춤형 자격 증명 관리 솔루션을 만드는 것은 복잡성을 증가시키고 보안 위험을 초래할 수 있으며, 자격 증명 관리를 위해 설계된 기존 AWS 서비스를 활용하는 대신 전체 솔루션을 관리해야 합니다.",
            "Amazon Cognito는 주로 사용자 인증 및 액세스 제어에 중점을 두고 있으며, 사용자 자격 증명을 관리할 수 있지만 API 키나 데이터베이스 비밀번호와 같은 민감한 애플리케이션 자격 증명을 안전하게 저장하고 검색하기 위해 특별히 설계되지 않았습니다."
        ]
    },
    {
        "Question Number": "29",
        "Situation": "글로벌 온라인 소매 회사가 최소한의 다운타임과 데이터 손실을 보장하기 위해 재해 복구 전략을 강화하려고 합니다. 이 회사는 AWS 서비스를 광범위하게 사용하고 있지만 아직 공식적인 재해 복구 계획을 구현하지 않았습니다. 솔루션 아키텍트는 회사의 요구 사항을 효과적으로 충족할 수 있는 적절한 재해 복구 방법론과 도구를 식별하는 임무를 맡고 있습니다. (두 가지 선택)",
        "Question": "솔루션 아키텍트가 추천해야 할 재해 복구 방법 및 도구는 무엇입니까?",
        "Options": {
            "1": "업무 시간 동안만 백업 및 복원을 위해 Amazon S3를 활용합니다.",
            "2": "다른 지역에 있는 Amazon EC2 인스턴스를 사용하여 따뜻한 대기 접근 방식을 채택합니다.",
            "3": "AWS Backup을 활용하여 서비스 간 백업 프로세스를 자동화합니다.",
            "4": "AWS Elastic Disaster Recovery를 구현하여 지속적인 복제를 수행합니다.",
            "5": "데이터 복원을 위해 온프레미스 테이프 백업에만 의존합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "AWS Elastic Disaster Recovery를 구현하여 지속적인 복제를 수행합니다.",
            "AWS Backup을 활용하여 서비스 간 백업 프로세스를 자동화합니다."
        ],
        "Explanation": "AWS Elastic Disaster Recovery는 AWS 리소스의 지속적인 복제를 가능하게 하여 재해 발생 시 신속한 복구를 지원합니다. AWS Backup은 여러 AWS 서비스 간의 백업 작업을 자동화하고 중앙 집중화하여 데이터가 정기적으로 백업되고 복구를 위해 쉽게 사용할 수 있도록 보장합니다. 두 옵션 모두 회사의 클라우드 인프라에 맞춘 효과적인 재해 복구 솔루션의 필요성을 충족합니다.",
        "Other Options": [
            "업무 시간 동안만 Amazon S3를 사용하여 백업 및 복원하는 것은 이상적이지 않으며, 이는 지속적인 데이터 보호를 보장하지 않으며 해당 시간 외에 재해가 발생할 경우 데이터 손실로 이어질 수 있습니다.",
            "다른 지역에 있는 Amazon EC2 인스턴스를 사용하여 따뜻한 대기 접근 방식을 채택하는 것은 효과적일 수 있지만, AWS Elastic Disaster Recovery 및 AWS Backup이 제공하는 자동화 및 관리 용이성과 동일한 수준을 제공하지 않을 수 있습니다.",
            "데이터 복원을 위해 온프레미스 테이프 백업에만 의존하는 것은 불충분하며, 클라우드 기반 솔루션의 이점을 활용하지 못하고 복구 시간이 길어지고 잠재적인 데이터 손실로 이어질 수 있습니다."
        ]
    },
    {
        "Question Number": "30",
        "Situation": "금융 서비스 회사가 AWS 환경을 감사하여 사용자가 최소 권한 원칙에 따라 작업 기능을 수행하는 데 필요한 권한만 갖도록 보장하고 있습니다. 이 회사는 서로 다른 책임과 액세스 요구 사항을 가진 여러 팀이 있습니다. 그들은 사용자 권한 관리를 위해 AWS Identity and Access Management (IAM)를 사용하고 있습니다.",
        "Question": "모든 사용자에 대해 최소 권한 액세스를 보장하기 위해 AWS 환경을 감사하는 가장 효과적인 전략은 무엇입니까?",
        "Options": {
            "1": "모든 사용자가 수행한 API 호출을 추적하여 과도한 권한 및 사용 패턴을 식별하는 중앙 집중식 로깅 솔루션을 구현합니다.",
            "2": "모든 사용자에 대해 지난 30일 동안 사용되지 않은 권한을 정기적으로 제거하는 자동화된 스크립트를 설정합니다.",
            "3": "AWS IAM Access Analyzer를 사용하여 사용되지 않는 권한을 식별하고 IAM 역할 및 정책을 조정합니다.",
            "4": "모든 IAM 정책 및 역할을 수동으로 검토하여 사용자가 작업에 필요한 최소 권한만 갖도록 합니다."
        },
        "Correct Answer": "AWS IAM Access Analyzer를 사용하여 사용되지 않는 권한을 식별하고 IAM 역할 및 정책을 조정합니다.",
        "Explanation": "AWS IAM Access Analyzer를 사용하는 것은 사용자 권한을 감사하는 가장 효과적인 방법으로, 정책을 자동으로 분석하고 과도한 액세스를 식별하여 환경 전반에 걸쳐 최소 권한 액세스를 유지하기 위한 체계적인 조정을 가능하게 합니다.",
        "Other Options": [
            "수동 검토는 시간이 많이 걸리고 오류가 발생하기 쉬워 IAM Access Analyzer와 같은 자동화 도구에 비해 효과적이지 않습니다.",
            "중앙 집중식 로깅은 API 호출 패턴에 대한 통찰력을 제공할 수 있지만, 과도하거나 불필요한 권한을 직접 식별하지 않으므로 최소 권한을 시행하는 데 필수적입니다.",
            "사용되지 않는 권한을 제거하는 자동화된 스크립트는 사용자에게 필요한 액세스를 실수로 취소할 수 있어 필요한 작업을 수행하는 데 잠재적인 중단을 초래할 수 있습니다."
        ]
    },
    {
        "Question Number": "31",
        "Situation": "금융 서비스 회사는 Amazon S3에 저장된 거래 데이터를 정기적으로 처리한 후, 변환된 데이터를 보고 목적으로 Amazon RDS 데이터베이스에 로드해야 합니다. 이 회사는 이 프로세스를 자동화하고 데이터 무결성을 보장하며 비용을 최소화할 수 있는 솔루션이 필요합니다.",
        "Question": "회사가 Amazon S3에서 Amazon RDS로 데이터의 이동 및 변환을 조정하기 위해 어떤 AWS 서비스를 사용해야 합니까?",
        "Options": {
            "1": "워크플로우를 관리하기 위해 AWS Step Functions를 사용하고 데이터 변환을 위해 AWS Lambda를 사용합니다.",
            "2": "S3에서 RDS로 데이터를 스트리밍하기 위해 Amazon Kinesis Data Firehose를 사용합니다.",
            "3": "S3의 데이터를 처리하고 RDS에 로드하기 위해 AWS Batch를 사용합니다.",
            "4": "ETL 작업을 생성하고 데이터 전송 및 변환을 자동화하기 위해 AWS Glue를 사용합니다."
        },
        "Correct Answer": "ETL 작업을 생성하고 데이터 전송 및 변환을 자동화하기 위해 AWS Glue를 사용합니다.",
        "Explanation": "AWS Glue는 ETL(추출, 변환, 로드) 프로세스를 위해 특별히 설계되어 Amazon S3에서 Amazon RDS로 데이터를 이동하고 변환하는 데 이상적입니다. 데이터 워크플로우의 스케줄링 및 실행을 자동화하는 서버리스 아키텍처를 제공하여 데이터 무결성을 보장하고 운영 오버헤드를 최소화합니다.",
        "Other Options": [
            "AWS Step Functions는 복잡한 워크플로우를 관리하는 데 사용되지만, 기본 ETL 기능을 제공하지 않아 데이터 변환을 위해 추가 서비스가 필요합니다.",
            "Amazon Kinesis Data Firehose는 주로 데이터 스트리밍에 사용되며, RDS에 로드하기 전에 S3의 기존 데이터를 배치 처리 및 변환하는 데 적합하지 않을 수 있습니다.",
            "AWS Batch는 배치 처리 작업을 위해 설계되었지만, ETL 프로세스를 조정하거나 S3와 RDS 간의 데이터 흐름을 관리하는 간단한 방법을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "32",
        "Situation": "미디어 스트리밍 회사가 AWS에 호스팅된 비디오 전송 서비스에서 성능 문제를 겪고 있습니다. 사용자는 특히 피크 시간대에 비디오 재생 중 버퍼링 및 지연을 보고했습니다. 솔루션 아키텍트로서, 원활한 사용자 경험을 보장하기 위해 비디오 스트리밍 서비스의 성능을 향상시켜야 합니다. (두 가지 선택)",
        "Question": "비디오 전송 서비스의 성능을 최적화하기 위해 어떤 전략을 구현해야 합니까?",
        "Options": {
            "1": "Amazon Simple Storage Service(S3)를 구성하여 비디오 파일을 캐싱 메커니즘 없이 호스팅합니다.",
            "2": "Amazon CloudFront를 콘텐츠 전송 네트워크(CDN)로 구현하여 사용자 가까이에 비디오 콘텐츠를 캐시하고 지연을 줄입니다.",
            "3": "AWS Global Accelerator를 사용하여 여러 지리적 지역의 사용자와 함께 애플리케이션의 가용성과 성능을 향상시킵니다.",
            "4": "미디어 처리 애플리케이션을 위한 다중 지역 설정을 배포하여 전 세계적으로 높은 가용성과 낮은 지연을 보장합니다.",
            "5": "Amazon Elastic Transcoder를 활성화하여 비디오 파일을 다양한 형식과 해상도로 자동 변환하여 최적화된 전송을 제공합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon CloudFront를 콘텐츠 전송 네트워크(CDN)로 구현하여 사용자 가까이에 비디오 콘텐츠를 캐시하고 지연을 줄입니다.",
            "AWS Global Accelerator를 사용하여 여러 지리적 지역의 사용자와 함께 애플리케이션의 가용성과 성능을 향상시킵니다."
        ],
        "Explanation": "Amazon CloudFront를 구현하면 엣지 위치에서 비디오 콘텐츠를 캐시하여 사용자에게 지연을 크게 줄입니다. 또한 AWS Global Accelerator를 사용하면 애플리케이션으로의 경로를 최적화하여 서로 다른 지역에 분산된 사용자에게 성능을 향상시킵니다.",
        "Other Options": [
            "Amazon Elastic Transcoder를 활성화하는 것은 미디어 처리에 유용하지만 전송과 관련된 성능 문제를 직접적으로 해결하지 않습니다. 이는 콘텐츠의 형식과 품질에 중점을 두며 지연을 줄이는 데는 초점을 맞추지 않습니다.",
            "다중 지역 설정을 배포하면 가용성을 향상시킬 수 있지만 CDN과 결합되지 않는 한 성능 문제를 직접적으로 해결하지 않을 수 있습니다. 이는 복잡성과 비용을 추가하며 성능 향상을 보장하지 않습니다.",
            "캐싱 메커니즘 없이 S3를 구성하면 성능 문제가 악화될 가능성이 높습니다. 사용자는 엣지 캐싱의 이점 없이 S3에서 직접 비디오 콘텐츠를 검색해야 하므로 지연이 증가할 수 있습니다."
        ]
    },
    {
        "Question Number": "33",
        "Situation": "클라우드 아키텍트가 높은 가용성과 내결함성을 보장하기 위해 다양한 지역에 여러 Amazon EC2 인스턴스를 배포해야 하는 솔루션을 설계하고 있습니다. 아키텍트는 서비스 한도에 도달하지 않고 최대한 많은 EC2 인스턴스를 프로비저닝할 수 있도록 해야 합니다.",
        "Question": "아키텍트가 EC2 서비스 쿼터를 효과적으로 관리하기 위해 어떤 조치를 취해야 합니까? (두 가지 선택)",
        "Options": {
            "1": "한도에 도달하면 AWS Support Center를 통해 EC2 인스턴스의 한도 증가를 요청합니다.",
            "2": "트래픽에 따라 인스턴스 수를 동적으로 조정하기 위해 Amazon EC2 Auto Scaling을 구성합니다.",
            "3": "쿼터를 고려하지 않고 EC2 인스턴스의 배포를 자동화하기 위해 AWS CloudFormation을 사용합니다.",
            "4": "EC2 인스턴스 사용량을 모니터링하고 한도에 근접할 때 경고하는 AWS Lambda 함수를 구현합니다.",
            "5": "AWS Management Console에서 각 지역의 기본 EC2 인스턴스 한도를 검토합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "AWS Management Console에서 각 지역의 기본 EC2 인스턴스 한도를 검토합니다.",
            "한도에 도달하면 AWS Support Center를 통해 EC2 인스턴스의 한도 증가를 요청합니다."
        ],
        "Explanation": "EC2 서비스 쿼터를 효과적으로 관리하기 위해 아키텍트는 먼저 기본 한도를 검토하여 각 지역에서 사용 가능한 용량을 이해해야 합니다. 프로젝트 요구 사항이 이러한 한도를 초과하는 경우, AWS Support Center를 통해 한도 증가를 요청하는 것이 필수적입니다.",
        "Other Options": [
            "AWS CloudFormation을 사용하는 것은 서비스 쿼터를 고려하지 않으며, 한도를 초과할 경우 배포 실패를 초래할 수 있어 쿼터 관리를 위한 비효율적인 조치입니다.",
            "EC2 사용량을 모니터링하는 것은 유익하지만, 한도에 근접할 때 경고하는 Lambda 함수를 구현하는 것만으로는 서비스 쿼터 관리를 직접적으로 해결하지 않으며 프로비저닝 용량을 보장하지 않습니다.",
            "EC2 Auto Scaling을 구성하는 것은 수요에 따라 인스턴스 용량을 관리하는 데 유용하지만, 서비스 쿼터의 이해나 증가 요청의 필요성을 본질적으로 해결하지 않습니다."
        ]
    },
    {
        "Question Number": "34",
        "Situation": "중간 규모의 전자상거래 회사가 AWS에서 비용 관리 관행을 개선하고자 합니다. 이 회사는 현재 EC2, S3 및 RDS를 포함한 여러 AWS 서비스를 사용하고 있습니다. 그들은 월간 지출이 미리 정의된 임계값을 초과할 때 재무 팀에 알림을 보내는 자동화된 경고 시스템을 설정하고자 합니다. 또한, 재무 팀은 서비스 사용 및 관련 비용에 대한 통찰력을 제공하는 상세한 월간 보고서를 요구합니다. 이러한 요구 사항을 충족하는 가장 효과적인 방법은 무엇입니까?",
        "Question": "다음 옵션 중 회사의 AWS에서 비용 관리, 경고 및 보고 요구 사항을 가장 잘 충족하는 것은 무엇입니까?",
        "Options": {
            "1": "AWS CloudTrail을 활용하여 로그를 기록하고 모든 서비스의 지출을 모니터링하기 위해 Amazon CloudWatch 경고를 설정합니다.",
            "2": "AWS Budgets를 설정하여 비용 임계값에 도달할 때 경고를 보내고 AWS Cost Explorer를 사용하여 상세 보고서를 작성합니다.",
            "3": "AWS Trusted Advisor를 구현하여 서비스 사용을 검토하고 비용 보고를 위한 사용자 정의 스크립트를 설정합니다.",
            "4": "AWS Config를 활성화하여 리소스 변경 사항을 추적하고 비용 임계값에 대한 경고를 위해 Amazon SNS를 활용합니다."
        },
        "Correct Answer": "AWS Budgets를 설정하여 비용 임계값에 도달할 때 경고를 보내고 AWS Cost Explorer를 사용하여 상세 보고서를 작성합니다.",
        "Explanation": "AWS Budgets는 비용 및 사용 예산을 설정하기 위해 특별히 설계되었으며, 임계값이 초과될 때 경고를 보낼 수 있는 기능을 제공합니다. AWS Cost Explorer는 서비스 사용 및 비용에 대한 상세한 통찰력을 제공하므로 이 옵션이 회사의 요구 사항에 가장 효과적입니다.",
        "Other Options": [
            "AWS CloudTrail은 주로 API 호출 감사에 사용되며 비용 모니터링이나 경고 기능을 직접 제공하지 않으므로 회사의 요구에 불충분합니다.",
            "AWS Trusted Advisor는 AWS 리소스를 최적화하기 위한 권장 사항을 제공하지만 비용 임계값에 대한 경고나 상세 보고를 위한 전용 메커니즘을 제공하지 않습니다.",
            "AWS Config는 리소스 구성 및 준수를 추적하는 데 사용되며, 비용 모니터링을 제공하지 않으며 지출 임계값에 대한 필요한 경고 기능이 부족합니다."
        ]
    },
    {
        "Question Number": "35",
        "Situation": "대형 미디어 회사가 아카이빙 및 처리를 위해 테라바이트의 비디오 데이터를 Amazon S3로 전송해야 합니다. 이 회사는 제한된 인터넷 대역폭을 가지고 있으며, 이렇게 큰 양의 데이터를 업로드하는 데 필요한 시간에 대해 우려하고 있습니다. 그들은 저장 및 컴퓨팅 요구 사항에 따라 다양한 옵션을 고려하여 마이그레이션에 사용할 AWS Snowball 장치를 평가하고 있습니다.",
        "Question": "회사가 비디오 데이터를 효율적으로 전송하면서 장치에서 일부 전처리를 허용하기 위해 선택해야 할 AWS Snowball 옵션은 무엇입니까?",
        "Options": {
            "1": "50 TB 저장 용량을 가진 Standard Snowball 옵션을 선택하여 컴퓨팅 기능 없이 데이터를 S3로 직접 전송합니다.",
            "2": "100 TB 저장 용량과 24 vCPU를 활용하여 비디오 데이터를 S3로 전송하기 전에 전처리할 수 있는 Snowball Edge Storage Optimized 옵션을 선택합니다.",
            "3": "100 PB의 저장 용량을 제공하는 Snowmobile 서비스를 선택하여 모든 비디오 데이터를 한 번에 S3로 전송합니다.",
            "4": "S3로 전송하기 전에 비디오 데이터에서 고급 기계 학습 알고리즘을 실행할 수 있는 Snowball Edge Compute Optimized 옵션을 선택합니다."
        },
        "Correct Answer": "100 TB 저장 용량과 24 vCPU를 활용하여 비디오 데이터를 S3로 전송하기 전에 전처리할 수 있는 Snowball Edge Storage Optimized 옵션을 선택합니다.",
        "Explanation": "Snowball Edge Storage Optimized 옵션은 비디오 데이터의 전처리를 수행하는 데 필요한 저장 용량과 컴퓨팅 리소스를 제공하므로 대량의 데이터를 전송하면서 컴퓨팅 기능을 활용해야 하는 회사의 요구에 적합합니다.",
        "Other Options": [
            "Standard Snowball 옵션은 컴퓨팅 기능이 부족하여 비디오 데이터의 전처리를 허용하지 않으므로 회사의 요구에 적합하지 않습니다.",
            "Snowmobile 서비스는 매우 대규모 데이터 마이그레이션을 위해 설계되었지만, 테라바이트의 비디오 데이터에는 과도하며 전처리 기능을 제공하지 않습니다.",
            "Snowball Edge Compute Optimized 옵션은 고급 기계 학습 작업을 실행하는 데 더 적합하며, Storage Optimized 옵션에 비해 회사의 요구에 충분한 저장 용량을 제공하지 않을 수 있습니다."
        ]
    },
    {
        "Question Number": "36",
        "Situation": "대기업이 AWS로 마이그레이션하고 있으며 여러 AWS 계정 및 애플리케이션에서 사용자 신원 및 액세스를 관리하기 위한 중앙 집중식 솔루션이 필요합니다. 이 기업은 현재 Microsoft Active Directory를 사용하여 신원 관리를 하고 있으며, 단일 로그인 기능을 지원하는 인력 인증 솔루션을 구현하고자 합니다.",
        "Question": "중앙 집중식 신원 관리 및 단일 로그인 액세스 요구 사항을 가장 잘 충족하기 위해 기업이 구현해야 할 솔루션은 무엇입니까?",
        "Options": {
            "1": "각 계정에 개별 IAM 사용자를 설정하여 사용자 관리 및 액세스 제어를 처리하기 위해 여러 AWS 계정을 설정합니다.",
            "2": "AWS Directory Service를 배포하여 별도의 신원 저장소를 만들고 각 AWS 계정 내에서 사용자 액세스를 직접 관리합니다.",
            "3": "AWS IAM Identity Center를 구현하여 기존 Microsoft Active Directory에 연결하고 AWS 계정 간 사용자 액세스를 관리합니다.",
            "4": "Amazon Cognito를 사용하여 사용자 신원을 생성하고 모든 AWS 서비스 및 애플리케이션에서 인증을 관리합니다."
        },
        "Correct Answer": "AWS IAM Identity Center를 구현하여 기존 Microsoft Active Directory에 연결하고 AWS 계정 간 사용자 액세스를 관리합니다.",
        "Explanation": "AWS IAM Identity Center는 중앙 집중식 신원 관리를 위해 설계되었으며, 조직이 기존 신원 소스인 Microsoft Active Directory에 연결할 수 있도록 합니다. 이는 여러 AWS 계정 및 애플리케이션에서 단일 로그인 기능을 제공하므로 기업의 요구 사항과 완벽하게 일치합니다.",
        "Other Options": [
            "AWS Directory Service는 별도의 신원 저장소가 필요하며 여러 계정 간에 필요한 중앙 집중식 관리를 제공하지 않으므로 기업의 목표와 일치하지 않습니다.",
            "Amazon Cognito는 애플리케이션 수준의 사용자 인증에 더 중점을 두고 있으며, 기업 환경에서 여러 AWS 계정 간의 액세스를 관리하는 데 이상적이지 않습니다.",
            "각 계정에 개별 IAM 사용자를 설정하면 신원 관리가 분산되어 액세스를 관리하고 원활한 단일 로그인 경험을 만드는 데 어려움을 겪게 됩니다."
        ]
    },
    {
        "Question Number": "37",
        "Situation": "글로벌 전자상거래 플랫폼이 재해 복구 전략을 강화할 계획입니다. 이 회사는 여러 지역에서 운영되며, 애플리케이션이 중단으로부터 신속하게 복구되고 다운타임과 데이터 손실을 최소화할 수 있도록 해야 합니다. 솔루션 아키텍트는 비용과 복구 시간 목표를 균형 있게 고려한 적절한 재해 복구 전략을 식별하는 임무를 맡았습니다.",
        "Question": "다음 중 솔루션 아키텍트가 구현을 고려해야 할 재해 복구 전략은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "정상 운영 중 활성 구성 요소가 없는 콜드 스탠바이 전략",
            "2": "필수 구성 요소가 대기 모드로 실행되는 파일럿 라이트 전략",
            "3": "단일 지역에 데이터가 저장된 백업 및 복원 전략",
            "4": "완전한 기능 환경의 축소 버전이 있는 웜 스탠바이 전략",
            "5": "여러 지역에 걸쳐 활성-활성 배포가 있는 다중 사이트 전략"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "필수 구성 요소가 대기 모드로 실행되는 파일럿 라이트 전략",
            "완전한 기능 환경의 축소 버전이 있는 웜 스탠바이 전략"
        ],
        "Explanation": "파일럿 라이트 전략은 필요할 때 중요한 구성 요소가 신속하게 확장될 준비가 되어 있도록 하며, 웜 스탠바이 전략은 실패 시 신속하게 전체 용량으로 복구할 수 있는 부분적으로 실행 중인 환경을 유지합니다. 두 전략 모두 재해 복구 시나리오에서 비용과 복구 속도 간의 효과적인 균형을 제공합니다.",
        "Other Options": [
            "백업 및 복원 전략은 일반적으로 더 긴 복구 시간을 수반하며, 단일 위치에서 백업을 복원하는 데 의존하기 때문에 신중하게 관리하지 않으면 데이터 손실로 이어질 수 있습니다.",
            "다중 사이트 전략은 가장 빠른 복구 시간을 제공하지만, 여러 지역에서 완전 운영 환경을 유지해야 하므로 비용이 상당히 더 비쌀 수 있으며, 이는 모든 애플리케이션에 정당화되지 않을 수 있습니다.",
            "콜드 스탠바이 전략은 비활성 상태에서 리소스를 활성화해야 하므로 신속한 복구에 적합하지 않으며, 이는 더 긴 다운타임과 잠재적인 데이터 손실로 이어질 수 있습니다."
        ]
    },
    {
        "Question Number": "38",
        "Situation": "한 회사가 Amazon EC2 인스턴스에서 실시간 데이터를 처리하는 중요한 애플리케이션을 호스팅하고 있습니다. 이 애플리케이션은 인스턴스 실패로 인해 가끔 다운타임을 경험하고 있으며, 이는 비즈니스 운영에 영향을 미칩니다. 솔루션 아키텍트는 인스턴스 실패를 최소한의 중단으로 처리할 수 있는 고가용성 및 복원력이 뛰어난 아키텍처를 구현해야 합니다.",
        "Question": "다음 중 애플리케이션에 대한 중단을 최소화하면서 고가용성과 복원력 요구 사항을 충족하는 솔루션은 무엇입니까?",
        "Options": {
            "1": "EC2 인스턴스의 스냅샷을 생성하고 매시간 실행되도록 예약합니다. 인스턴스 실패 시 최신 스냅샷을 사용하여 새 EC2 인스턴스를 수동으로 시작하여 애플리케이션을 복원합니다.",
            "2": "Amazon ECS와 Fargate를 사용하여 서버리스 방식으로 애플리케이션을 실행합니다. 여러 가용 영역에 분산된 여러 작업으로 서비스를 구성합니다. 애플리케이션 로드 밸런서를 구현하여 트래픽을 작업으로 라우팅합니다.",
            "3": "데이터 저장을 위해 Amazon Elastic Block Store (EBS) 볼륨이 연결된 단일 EC2 인스턴스에 애플리케이션을 배포합니다. 실패 시 복원을 위해 Amazon Data Lifecycle Manager를 사용하여 EBS 볼륨의 백업을 생성합니다.",
            "4": "여러 가용 영역에 걸쳐 여러 EC2 인스턴스를 가진 Auto Scaling 그룹을 생성합니다. 애플리케이션 로드 밸런서(ALB)를 사용하여 Auto Scaling 그룹의 인스턴스에 수신 트래픽을 분산합니다. ALB의 헬스 체크를 구성하여 트래픽이 건강한 인스턴스에만 전송되도록 합니다."
        },
        "Correct Answer": "여러 가용 영역에 걸쳐 여러 EC2 인스턴스를 가진 Auto Scaling 그룹을 생성합니다. 애플리케이션 로드 밸런서(ALB)를 사용하여 Auto Scaling 그룹의 인스턴스에 수신 트래픽을 분산합니다. ALB의 헬스 체크를 구성하여 트래픽이 건강한 인스턴스에만 전송되도록 합니다.",
        "Explanation": "이 솔루션은 여러 가용 영역에 분산된 인스턴스를 가진 Auto Scaling 그룹을 활용하여 고가용성과 복원력을 제공합니다. 애플리케이션 로드 밸런서는 트래픽이 건강한 인스턴스에만 전송되도록 하여 다운타임과 사용자에 대한 중단을 최소화합니다.",
        "Other Options": [
            "단일 EC2 인스턴스에 애플리케이션을 배포하는 것은 고가용성을 제공하지 않으며, 해당 인스턴스의 실패는 다운타임을 초래합니다. 백업은 유용하지만 실패 중 지속적인 운영을 보장하지 않습니다.",
            "Amazon ECS와 Fargate를 사용하는 것은 서버리스 접근 방식을 제공하지만, 올바르게 구성되지 않으면 고가용성을 제공하지 않을 수 있습니다. 그러나 복원력에 대한 유효한 옵션이며, 올바른 답변에 비해 헬스 체크 및 균형 잡힌 트래픽 분배에 대한 명시적인 언급이 부족합니다.",
            "EC2 인스턴스의 스냅샷을 생성하는 것은 즉각적인 장애 조치 기능을 제공하지 않습니다. 이 접근 방식은 수동 개입에 의존하며 지속적인 운영을 보장하지 않으므로 고가용성 요구 사항에 덜 적합합니다."
        ]
    },
    {
        "Question Number": "39",
        "Situation": "금융 서비스 회사는 고객 거래 데이터가 데이터 손실 및 서비스 중단으로부터 보호되도록 해야 합니다. 그들은 30분의 복구 시간 목표(RTO)와 15분의 복구 지점 목표(RPO)를 요구합니다. 아키텍처는 AWS 리전이 완전히 실패하더라도 운영을 유지해야 합니다.",
        "Question": "다음 중 이 시나리오의 RTO 및 RPO 요구 사항을 가장 잘 충족하는 솔루션은 무엇입니까?",
        "Options": {
            "1": "데이터를 15분마다 보조 리전으로 복제하는 활성-수동 아키텍처를 설정하고, 30분 이내에 실행할 수 있는 장애 조치 프로세스를 설정합니다.",
            "2": "다른 리전으로 매시간 백업을 수행하는 웜 스탠바이 설정을 구현하여 서비스를 복원하기 위한 수동 개입을 허용합니다.",
            "3": "데이터 저장을 위해 Amazon S3를 사용하고, 데이터를 매시간 다른 리전으로 복제하는 라이프사이클 정책을 구성하여 수동 장애 조치 프로세스를 제공합니다.",
            "4": "데이터 손실을 방지하기 위해 여러 AWS 리전 간에 동기식 데이터 복제를 통해 활성-활성 아키텍처를 구현합니다."
        },
        "Correct Answer": "데이터를 15분마다 보조 리전으로 복제하는 활성-수동 아키텍처를 설정하고, 30분 이내에 실행할 수 있는 장애 조치 프로세스를 설정합니다.",
        "Explanation": "이 옵션은 빈번한 데이터 복제를 통해 15분의 RPO를 제공하고, 자동 장애 조치 프로세스를 통해 30분의 RTO를 충족하여 다운타임과 데이터 손실을 최소화합니다.",
        "Other Options": [
            "활성-활성 아키텍처는 낮은 지연 시간과 높은 가용성을 제공하지만, 이 특정 시나리오에 필요한 RTO 및 RPO를 보장하지 않으면서 복잡성과 잠재적으로 더 높은 비용을 초래할 수 있습니다.",
            "Amazon S3를 사용하여 매시간 복제하는 것은 15분의 RPO를 충족하지 않으며, 최대 1시간의 데이터 손실을 허용하므로 요구 사항을 초과합니다.",
            "매시간 백업을 수행하는 웜 스탠바이 설정은 지정된 요구 사항에 비해 서비스를 온라인으로 복구하는 데 더 많은 시간이 필요하므로 30분의 RTO를 충족하지 않습니다."
        ]
    },
    {
        "Question Number": "40",
        "Situation": "한 금융 서비스 회사가 자원 관리 및 규정 준수를 개선하기 위해 여러 AWS 계정으로 운영을 확장하고 있습니다. 이들은 모든 AWS 계정에서 정책 및 보안 통제를 중앙 집중적으로 관리할 수 있는 거버넌스 프레임워크를 구현하고자 합니다. 이들은 거버넌스 전략의 일환으로 AWS Control Tower와 AWS Organizations를 사용하는 것을 고려하고 있습니다.",
        "Question": "다음 구성 중 회사의 다중 계정 설정에 대해 가장 효과적인 거버넌스 및 규정 준수 관리를 제공하는 것은 무엇입니까?",
        "Options": {
            "1": "AWS Control Tower를 설정하여 미리 구성된 가드레일로 계정을 생성합니다. AWS Organizations를 사용하여 계정을 관리하되, IAM 역할만으로 권한 및 규정 준수를 관리하며 SCP는 적용하지 않습니다.",
            "2": "중앙 AWS 계정을 생성하고 AWS Organizations를 사용하여 모든 다른 계정을 연결합니다. 규정 준수 검사를 위해 AWS Config 규칙을 구현하되, 관리 단순화를 위해 AWS Control Tower나 가드레일은 사용하지 않습니다.",
            "3": "AWS Organizations를 사용하여 다중 계정 구조를 만들고 계정 간에 IAM 정책을 수동으로 적용합니다. 각 계정에 대해 개별 CloudTrail 로그를 설정하여 활동을 모니터링하고 내부 정책 준수를 보장합니다.",
            "4": "AWS Control Tower를 구현하여 새로운 다중 계정 환경을 설정하고 제공된 가드레일을 적용합니다. AWS Organizations를 사용하여 계정 생성을 관리하고 추가 규정 준수 통제를 위해 SCP를 적용합니다. AWS Config를 사용하여 정기적으로 계정을 감사합니다."
        },
        "Correct Answer": "AWS Control Tower를 구현하여 새로운 다중 계정 환경을 설정하고 제공된 가드레일을 적용합니다. AWS Organizations를 사용하여 계정 생성을 관리하고 추가 규정 준수 통제를 위해 SCP를 적용합니다. AWS Config를 사용하여 정기적으로 계정을 감사합니다.",
        "Explanation": "AWS Control Tower를 사용하면 회사가 내장된 규정 준수 가드레일로 안전한 다중 계정 환경을 신속하게 설정할 수 있습니다. 이를 AWS Organizations와 결합하면 중앙 집중식 관리와 서비스 제어 정책(SCP)의 적용이 가능해져 거버넌스가 향상됩니다. AWS Config를 통한 정기 감사는 지속적인 규정 준수를 보장합니다.",
        "Other Options": [
            "AWS Organizations만을 사용하여 IAM 정책을 적용하면 불일치가 발생하고 수동 작업이 증가할 수 있습니다. AWS Control Tower의 자동화 및 가드레일이 없으면 규정 준수가 더 어려워지고 효과적이지 않을 수 있습니다.",
            "SCP를 적용하지 않고 AWS Control Tower를 설정하면 거버넌스 기능이 제한됩니다. 권한을 위해 IAM 역할만을 의존하면 중앙 집중식 제어 및 감독 부족으로 인해 계정이 위험에 노출될 수 있습니다.",
            "중앙 계정을 생성하고 AWS Control Tower나 가드레일을 사용하지 않고 AWS Config 규칙에 의존하면 환경이 잘못 구성될 위험에 처하고 AWS 거버넌스 도구의 전체 기능을 활용하지 못합니다."
        ]
    },
    {
        "Question Number": "41",
        "Situation": "한 금융 서비스 회사가 실시간으로 거래를 처리하는 중요한 애플리케이션을 운영하고 있습니다. 이 애플리케이션은 여러 가용 영역에 걸쳐 Auto Scaling 그룹 내의 Amazon EC2 인스턴스에서 호스팅됩니다. 아키텍트는 애플리케이션이 실패를 견디고 데이터 손실 없이 원활하게 복구될 수 있도록 보장하는 임무를 맡고 있습니다. 애플리케이션은 거래 데이터를 Amazon RDS 데이터베이스에 기록합니다. 회사는 다운타임을 최소화하고 데이터 무결성을 보장하는 솔루션을 요구합니다.",
        "Question": "실패를 대비하고 원활한 복구를 보장하기 위해 솔루션 아키텍트가 구현해야 할 전략은 무엇입니까?",
        "Options": {
            "1": "각 거래 전에 Amazon RDS 스냅샷을 구현하여 백업을 생성합니다. AWS Lambda를 사용하여 장애 조치 및 복구 절차를 자동화합니다.",
            "2": "다른 리전에서 Amazon RDS 인스턴스의 읽기 복제본을 배포합니다. 장애 발생 시 트래픽을 리디렉션하기 위해 Amazon Route 53을 사용합니다.",
            "3": "Amazon RDS Multi-AZ 배포를 구현하여 데이터베이스의 고가용성과 자동 장애 조치를 보장합니다. 백업을 위해 Amazon S3 버킷을 사용하고 시점 복구를 활성화합니다.",
            "4": "Amazon ECS에 애플리케이션을 배포하고 서비스 메쉬 구성을 사용합니다. 빠른 복구를 위해 거래 로그를 Amazon DynamoDB 테이블에 저장합니다."
        },
        "Correct Answer": "Amazon RDS Multi-AZ 배포를 구현하여 데이터베이스의 고가용성과 자동 장애 조치를 보장합니다. 백업을 위해 Amazon S3 버킷을 사용하고 시점 복구를 활성화합니다.",
        "Explanation": "Amazon RDS Multi-AZ 배포를 구현하면 실시간 거래를 처리하는 중요한 애플리케이션에 필수적인 데이터베이스의 고가용성과 자동 장애 조치를 제공합니다. Amazon S3를 백업에 사용하고 시점 복구를 활성화하면 실패 시 데이터 무결성과 복구 가능성을 보장합니다.",
        "Other Options": [
            "다른 리전에서 읽기 복제본을 배포하는 것은 기본 데이터베이스에 대한 자동 장애 조치를 제공하지 않으며, 쓰기 작업에 추가 지연을 초래할 수 있습니다. 이 옵션은 즉각적인 복구가 필요한 중요한 애플리케이션에 적합하지 않습니다.",
            "각 거래 전에 RDS 스냅샷을 사용하는 것은 데이터 손실을 방지하기 위한 실행 가능한 전략이 아니며, 스냅샷 생성에는 시간이 걸리고 실시간으로 데이터를 캡처하지 못할 수 있어 실패 시 최근 거래 손실의 위험이 있습니다.",
            "Amazon ECS에 애플리케이션을 배포하고 서비스 메쉬를 사용하는 것은 데이터베이스의 고가용성과 복구 가능성을 직접적으로 해결하지 않습니다. DynamoDB에 거래 로그를 저장하는 것은 애플리케이션에 필요한 거래 데이터의 무결성을 보장하지 않을 수 있습니다."
        ]
    },
    {
        "Question Number": "42",
        "Situation": "한 금융 서비스 회사가 최근에 AWS 환경에서 매일 밤 실행되는 취약점 스캔 도구를 구현했습니다. 이 도구는 여러 취약점을 식별하지만 팀은 이러한 발견에 신속하고 효과적으로 대응하는 데 어려움을 겪고 있습니다. 이들은 보안 태세를 강화하고 수동 개입을 줄이기 위해 자동화된 응답을 우선시하고자 합니다. (두 가지 선택)",
        "Question": "감지된 취약점을 해결하기 위해 우선적으로 고려해야 할 자동화된 응답은 무엇입니까?",
        "Options": {
            "1": "취약점 발견 사항에 대해 보안 팀과 논의하기 위해 정기적인 수동 검토를 예약합니다.",
            "2": "취약점이 감지될 때마다 팀에 알리기 위해 CloudWatch 경고를 설정하되 자동화된 수정은 하지 않습니다.",
            "3": "AWS Config 규칙을 활용하여 보안 모범 사례 준수를 보장하고 비준수 리소스를 자동으로 수정합니다.",
            "4": "심각도에 따라 일반적인 취약점을 자동으로 수정하기 위해 AWS Lambda 함수를 구현합니다.",
            "5": "취약점에 대한 사전 정의된 수정 작업을 실행하기 위해 AWS Systems Manager Automation 문서를 통합합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "심각도에 따라 일반적인 취약점을 자동으로 수정하기 위해 AWS Lambda 함수를 구현합니다.",
            "취약점에 대한 사전 정의된 수정 작업을 실행하기 위해 AWS Systems Manager Automation 문서를 통합합니다."
        ],
        "Explanation": "AWS Lambda 함수를 통한 자동 수정 구현은 심각도에 따라 취약점에 즉각적으로 대응할 수 있게 하여 노출 시간을 최소화합니다. 또한 AWS Systems Manager Automation 문서를 통합하면 사전 정의된 작업을 실행하여 수정 프로세스를 간소화하고 취약점 처리의 일관성을 보장합니다.",
        "Other Options": [
            "정기적인 수동 검토를 예약하는 것은 자동화된 응답을 제공하지 않으며 수정 프로세스를 지연시켜 취약점이 오랜 기간 동안 해결되지 않을 수 있습니다.",
            "자동화된 수정 없이 알림을 위한 CloudWatch 경고를 설정하는 것은 취약점을 해결하지 않으며, 팀에 알림만 제공하여 응답 시간을 느리게 할 수 있습니다.",
            "AWS Config 규칙을 사용하는 것은 준수에 중점을 두며 취약점의 직접적인 수정을 다루지 않으며, 전반적인 보안 태세를 유지하는 데 도움이 되지만 감지된 취약점에 대한 자동화된 응답의 즉각적인 필요를 해결하지 않습니다."
        ]
    },
    {
        "Question Number": "43",
        "Situation": "한 금융 서비스 회사가 데이터 저장소를 AWS로 이전하고 있습니다. 그들은 데이터 처리 애플리케이션을 위한 높은 처리량과 낮은 대기 시간을 제공할 수 있는 솔루션이 필요합니다. 또한, 회사는 변동하는 작업 부하를 수용할 수 있도록 쉽게 확장할 수 있는 솔루션과 재해 복구를 위한 지역 간 자동 데이터 복제를 제공하는 기능이 필요합니다. 추가로, 여러 가상 머신에서 데이터에 원활하게 접근할 수 있도록 보장하고자 합니다.",
        "Question": "어떤 AWS 스토리지 서비스 조합이 회사의 높은 처리량, 낮은 대기 시간, 확장성 및 지역 간 복제 요구 사항을 가장 잘 충족할 수 있을까요?",
        "Options": {
            "1": "Amazon EFS와 프로비저닝된 처리량 및 지역 간 복제 활성화.",
            "2": "Amazon S3와 데이터 관리 및 버전 관리를 위한 라이프사이클 정책 활성화.",
            "3": "Amazon FSx for Lustre와 여러 가용 영역 간 데이터 복제.",
            "4": "Amazon S3와 S3 전송 가속 및 지역 간 복제 활성화."
        },
        "Correct Answer": "Amazon FSx for Lustre와 여러 가용 영역 간 데이터 복제.",
        "Explanation": "Amazon FSx for Lustre는 높은 처리량과 낮은 대기 시간에 최적화되어 있어 데이터 처리 애플리케이션에 적합합니다. 이는 여러 가용 영역 간의 내구성과 가용성을 향상시키는 데이터 복제를 지원합니다.",
        "Other Options": [
            "Amazon S3와 S3 전송 가속 및 지역 간 복제 활성화는 주로 객체 저장소이기 때문에 데이터 처리 애플리케이션에 필요한 낮은 대기 시간을 제공하지 않을 수 있습니다.",
            "Amazon EFS와 프로비저닝된 처리량 및 지역 간 복제 활성화는 파일 저장소에 더 적합하지만, 집약적인 데이터 처리 작업 부하에 필요한 높은 처리량을 제공하지 않을 수 있습니다.",
            "Amazon S3와 데이터 관리 및 버전 관리를 위한 라이프사이클 정책 활성화는 데이터 처리 애플리케이션에 대한 높은 처리량과 낮은 대기 시간의 성능 요구 사항을 충족하지 않습니다."
        ]
    },
    {
        "Question Number": "44",
        "Situation": "한 회사가 다양한 IoT 장치로부터 이벤트 데이터를 수집하고 처리하는 실시간 데이터 처리 애플리케이션을 운영하고 있습니다. 현재 아키텍처는 데이터 처리 프레임워크를 실행하는 여러 Amazon EC2 인스턴스로 구성되어 있지만, 회사는 비용을 줄이고 서버리스 아키텍처로 전환하여 운영을 간소화하고자 합니다.",
        "Question": "실시간 처리 기능을 유지하면서 이 애플리케이션을 서버리스 아키텍처로 전환하기 위한 가장 효과적인 접근 방식은 무엇인가요?",
        "Options": {
            "1": "AWS Batch로 데이터 처리로 마이그레이션하고 EC2 스팟 인스턴스를 사용하여 들어오는 데이터 이벤트를 처리합니다. Amazon SNS를 사용하여 배치 작업에 새로운 이벤트를 알립니다.",
            "2": "이벤트 데이터 처리를 위해 서버리스 기능을 갖춘 Amazon Elastic MapReduce (EMR) 클러스터를 구현합니다. 결과를 저장하기 위해 Amazon DynamoDB를 사용합니다.",
            "3": "AWS Lambda 함수를 사용하여 Amazon Kinesis Data Streams로 이벤트 데이터를 실시간으로 처리합니다. Kinesis 스트림을 구성하여 각 데이터 이벤트에 대해 Lambda 함수를 트리거합니다.",
            "4": "Amazon SQS를 사용하여 이벤트 데이터를 버퍼링하고 AWS EC2 인스턴스의 집합을 설정하여 SQS 큐를 폴링하여 처리합니다. Auto Scaling을 사용하여 EC2 인스턴스를 관리합니다."
        },
        "Correct Answer": "AWS Lambda 함수를 사용하여 Amazon Kinesis Data Streams로 이벤트 데이터를 실시간으로 처리합니다. Kinesis 스트림을 구성하여 각 데이터 이벤트에 대해 Lambda 함수를 트리거합니다.",
        "Explanation": "AWS Lambda와 Amazon Kinesis Data Streams를 사용하면 실시간 데이터 처리를 처리할 수 있는 완전 관리형 서버리스 아키텍처를 제공합니다. 이 접근 방식은 운영 오버헤드를 최소화하면서 낮은 대기 시간과 들어오는 이벤트에 대한 즉각적인 응답을 보장합니다.",
        "Other Options": [
            "AWS Batch로 EC2 스팟 인스턴스를 사용하여 마이그레이션하는 것은 여전히 EC2 인스턴스를 관리해야 하므로 서버리스 아키텍처를 채택하는 목표를 충족하지 않습니다.",
            "Amazon SQS와 EC2 인스턴스 집합을 사용하는 것은 이러한 인스턴스를 지속적으로 관리해야 하며, 진정한 서버리스 접근 방식의 이점을 활용하지 못해 더 높은 비용과 운영 복잡성을 초래합니다.",
            "Amazon EMR 클러스터를 구현하는 것은 대량의 데이터 세트를 처리할 수 있지만 본질적으로 서버리스가 아니며 추가 관리 및 구성이 필요하므로 운영을 간소화하려는 목표에 반합니다."
        ]
    },
    {
        "Question Number": "45",
        "Situation": "한 금융 서비스 회사가 실시간으로 거래를 처리하기 위한 서버리스 애플리케이션을 개발하고 있습니다. 솔루션 아키텍트는 배포를 위해 AWS Serverless Application Model (AWS SAM)을 사용하기로 결정했습니다. 이 애플리케이션은 여러 AWS Lambda 함수, API Gateway 및 AWS 리소스에 접근하기 위한 IAM 권한이 필요합니다. 아키텍트는 배포 프로세스가 효율적이고 관리 가능하도록 보장하고자 합니다.",
        "Question": "다음 중 어떤 접근 방식이 아키텍트가 AWS SAM을 사용하여 서버리스 애플리케이션을 정의하고 배포하면서 템플릿에서 깔끔하고 이해하기 쉬운 구조를 유지할 수 있도록 할까요?",
        "Options": {
            "1": "각 AWS Lambda 함수와 관련 리소스를 별도의 AWS SAM 템플릿에 정의한 다음, 각 템플릿을 수동으로 배포하여 애플리케이션을 생성합니다.",
            "2": "AWS SAM을 사용하여 애플리케이션에 필요한 모든 리소스를 포함하는 단일 AWS CloudFormation 스택을 생성하고, 동일한 템플릿 파일에서 각 리소스를 정의합니다.",
            "3": "AWS SAM을 사용하여 각 Lambda 함수와 해당 리소스에 대해 별도의 CloudFormation 스택을 생성하고, 출력 및 가져오기를 통해 서로 연결합니다.",
            "4": "AWS SAM의 내장 기능을 활용하여 Lambda 함수, API Gateway 및 필요한 IAM 역할을 위한 'Resources' 섹션을 사용하여 서버리스 애플리케이션을 단일 템플릿으로 정의합니다."
        },
        "Correct Answer": "AWS SAM의 내장 기능을 활용하여 Lambda 함수, API Gateway 및 필요한 IAM 역할을 위한 'Resources' 섹션을 사용하여 서버리스 애플리케이션을 단일 템플릿으로 정의합니다.",
        "Explanation": "이 접근 방식은 AWS SAM을 사용하여 단일 템플릿 내에서 전체 서버리스 애플리케이션을 관리할 수 있도록 하여 명확한 구조를 제공하고 Lambda 함수 및 API Gateway 통합과 같은 SAM의 리소스를 통해 배포 프로세스를 간소화합니다.",
        "Other Options": [
            "이 옵션은 복잡한 배포 프로세스를 초래하고 여러 리소스 간의 종속성과 구성을 관리하기 어렵게 만들어 AWS SAM을 사용하는 이점을 무효화할 수 있습니다.",
            "각 함수를 위한 별도의 템플릿을 배포하는 것은 배포 프로세스를 복잡하게 만들고 오버헤드를 증가시킬 수 있으며, 이는 AWS SAM이 간소화하려는 서버리스 아키텍처에 적합하지 않습니다.",
            "별도의 스택을 생성하는 것은 일부 시나리오에서 유용할 수 있지만, 서로 다른 리소스 간의 상호작용을 관리하는 데 복잡성을 추가하고 더 단편화된 배포 경험을 초래할 수 있습니다."
        ]
    },
    {
        "Question Number": "46",
        "Situation": "글로벌 전자상거래 회사가 전 세계 사용자에게 높은 가용성과 낮은 대기 시간을 보장하기 위해 여러 AWS 리전에서 웹 애플리케이션을 배포했습니다. 그들은 AWS Global Accelerator를 구현하여 각 리전의 애플리케이션 로드 밸런서로 들어오는 트래픽을 유도하고 있습니다. 그러나 피크 트래픽 시간 동안 일관되지 않은 성능을 발견하고 설정을 최적화할 솔루션을 찾고 있습니다. (두 가지 선택)",
        "Question": "다음 구성 중 애플리케이션의 성능과 가용성을 개선하는 데 도움이 되는 것은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "AWS Shield Advanced를 구현하여 Global Accelerator 엔드포인트에 대한 향상된 DDoS 보호를 제공합니다.",
            "2": "Global Accelerator를 두 개의 정적 IP 주소로 구성하고 Anycast 기능을 활성화하여 트래픽을 가장 가까운 리전으로 라우팅합니다.",
            "3": "Amazon CloudFront를 애플리케이션 앞의 캐싱 레이어로 활용하여 전 세계 사용자에 대한 대기 시간을 줄입니다.",
            "4": "Global Accelerator에서 헬스 체크를 설정하여 모든 리전에서 건강한 엔드포인트로만 트래픽이 전송되도록 합니다.",
            "5": "각 리전에서 추가 애플리케이션 로드 밸런서를 배포하여 피크 시간 동안 증가한 트래픽을 처리합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Global Accelerator를 두 개의 정적 IP 주소로 구성하고 Anycast 기능을 활성화하여 트래픽을 가장 가까운 리전으로 라우팅합니다.",
            "Global Accelerator에서 헬스 체크를 설정하여 모든 리전에서 건강한 엔드포인트로만 트래픽이 전송되도록 합니다."
        ],
        "Explanation": "Anycast로 Global Accelerator를 구성하면 트래픽이 가장 가까운 건강한 엔드포인트로 라우팅되어 성능과 가용성이 향상됩니다. 또한 헬스 체크를 설정하면 사용자가 건강하지 않은 엔드포인트로 안내되지 않도록 하여 애플리케이션의 신뢰성을 더욱 향상시킵니다.",
        "Other Options": [
            "추가 애플리케이션 로드 밸런서를 배포하면 증가한 트래픽을 처리하는 데 도움이 될 수 있지만, Global Accelerator가 제공하는 라우팅 및 성능 이점을 직접적으로 해결하지는 않습니다.",
            "AWS Shield Advanced를 구현하면 DDoS 보호를 제공하지만 Global Accelerator를 통한 트래픽 라우팅이나 성능을 직접적으로 최적화하지는 않습니다.",
            "Amazon CloudFront를 활용하면 대기 시간을 줄일 수 있지만, 이는 별도의 서비스이며 Global Accelerator의 라우팅 기능의 이점을 활용하지 않습니다."
        ]
    },
    {
        "Question Number": "47",
        "Situation": "금융 서비스 회사가 민감한 고객 데이터를 관리하기 위해 서로 다른 리전에서 여러 VPC를 운영하고 있습니다. 회사는 이러한 VPC 간에 애플리케이션 통신을 위한 안전하고 효율적인 연결을 구축하면서 대기 시간과 비용을 최소화해야 합니다. 솔루션 아키텍트는 이러한 요구 사항을 충족하기 위한 최상의 연결 옵션을 평가하는 임무를 맡고 있습니다.",
        "Question": "다음 솔루션 중 여러 VPC 간의 연결 요구 사항을 가장 잘 해결하면서 보안과 낮은 대기 시간을 보장하는 것은 무엇입니까?",
        "Options": {
            "1": "각 VPC 쌍 간에 VPN 연결을 설정하여 암호화된 통신을 보장하지만 복잡한 관리와 잠재적인 성능 문제를 초래합니다.",
            "2": "AWS Direct Connect를 활용하여 각 VPC에 전용 연결을 설정하여 낮은 대기 시간을 제공하지만 상당한 인프라 투자와 관리가 필요합니다.",
            "3": "모든 VPC 간에 VPC 피어링 연결을 생성하고 각 연결에 대한 라우팅 테이블을 수동으로 구성하여 적절한 트래픽 흐름을 보장하면서 보안을 유지합니다.",
            "4": "AWS Transit Gateway를 사용하여 VPC를 상호 연결하고 연결의 중앙 집중식 관리를 가능하게 하여 모든 VPC 간의 확장 가능하고 안전한 통신을 허용합니다."
        },
        "Correct Answer": "AWS Transit Gateway를 사용하여 VPC를 상호 연결하고 연결의 중앙 집중식 관리를 가능하게 하여 모든 VPC 간의 확장 가능하고 안전한 통신을 허용합니다.",
        "Explanation": "AWS Transit Gateway는 여러 VPC를 상호 연결하는 프로세스를 단순화하여 효율적인 라우팅 및 관리를 가능하게 하는 중앙 허브를 제공합니다. 수천 개의 VPC를 지원하며 확장 가능하고 안전한 통신을 허용하므로 이 시나리오에 가장 적합한 선택입니다.",
        "Other Options": [
            "VPC 피어링 연결을 생성하면 VPC 수가 증가함에 따라 복잡하고 번거로워져 관리 오버헤드와 잠재적인 라우팅 문제를 초래할 수 있습니다.",
            "각 VPC 쌍 간에 VPN 연결을 설정하면 상당한 복잡성과 잠재적인 성능 병목 현상이 추가되며, 각 연결을 개별적으로 관리해야 합니다.",
            "AWS Direct Connect를 활용하려면 인프라에 대한 상당한 투자와 지속적인 관리가 필요하므로 유연성과 낮은 비용이 우선인 시나리오에는 적합하지 않습니다."
        ]
    },
    {
        "Question Number": "48",
        "Situation": "글로벌 기업이 애플리케이션을 AWS로 마이그레이션하고 AWS Organizations를 사용하여 다중 계정 전략을 구현하고자 합니다. 목표는 보안을 강화하고 청구를 간소화하며 다양한 팀과 부서 간에 자원을 효과적으로 관리하는 것입니다.",
        "Question": "조직의 요구 사항을 충족하는 안전하고 효율적인 다중 계정 AWS 환경을 만들기 위해 솔루션 아키텍트가 추천해야 할 전략은 무엇입니까?",
        "Options": {
            "1": "각 애플리케이션 팀에 대해 별도의 계정을 생성하고 비용 관리를 위해 리소스 태깅을 적용합니다.",
            "2": "모든 계정을 단일 계정으로 통합하여 청구 및 리소스 관리를 간소화합니다.",
            "3": "모든 계정에 대해 단일 IAM 역할을 사용하여 조직 전반에 걸쳐 권한을 균일하게 관리합니다.",
            "4": "AWS Organizations에서 서비스 제어 정책(SCP)을 구현하여 계정 간 거버넌스를 강화합니다."
        },
        "Correct Answer": "AWS Organizations에서 서비스 제어 정책(SCP)을 구현하여 계정 간 거버넌스를 강화합니다.",
        "Explanation": "서비스 제어 정책(SCP)을 구현하면 조직이 여러 계정 간에 권한 가드레일을 정의할 수 있어 계정이 특정 기능에 필요한 AWS 서비스에만 접근할 수 있도록 보장합니다. 이는 보안과 규정 준수를 강화하면서 중앙 집중식 관리를 가능하게 합니다.",
        "Other Options": [
            "모든 계정을 단일 계정으로 통합하면 폭발 반경 제한 및 보다 세분화된 접근 제어와 같은 다중 계정 전략의 이점을 제거합니다.",
            "모든 계정에 대해 단일 IAM 역할을 사용하는 것은 최선의 관행이 아니며, 이는 지나치게 허용적인 접근을 초래할 수 있고 계정 분리 및 특정 역할이나 팀에 맞춘 개별 IAM 정책의 이점을 활용하지 않습니다.",
            "각 애플리케이션 팀에 대해 별도의 계정을 생성하고 리소스 태깅을 적용하는 것만으로는 효과적으로 거버넌스나 보안 정책을 시행하지 않습니다. 태깅은 비용 관리에 도움이 되지만 SCP가 제공하는 필요한 제어를 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "49",
        "Situation": "한 금융 서비스 회사가 AWS에 중요한 애플리케이션을 배포했으나 간헐적인 중단이 발생하고 있습니다. 솔루션 아키텍트는 일관된 성능과 가용성을 보장하기 위해 애플리케이션의 신뢰성을 향상시키는 임무를 맡았습니다. 현재 아키텍처는 여러 가용 영역에 걸쳐 Auto Scaling Group의 EC2 인스턴스를 포함하고 있습니다. 아키텍트는 신뢰성을 향상시키기 위한 전략을 추천해야 합니다.",
        "Question": "신뢰성을 향상시키기 위해 아키텍트가 구현해야 할 전략은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "AWS Lambda 함수를 사용하여 비동기 작업을 처리하고 주요 애플리케이션의 부하를 줄입니다.",
            "2": "Amazon RDS를 Multi-AZ 구성으로 배포하여 데이터베이스 계층의 고가용성을 제공합니다.",
            "3": "AWS Global Accelerator를 구현하여 트래픽을 라우팅하고 지역 간 가용성을 향상시킵니다.",
            "4": "Amazon Route 53 헬스 체크를 설정하여 애플리케이션의 엔드포인트를 모니터링하고 장애 조치를 트리거합니다.",
            "5": "Amazon CloudFront를 구성하여 정적 콘텐츠를 캐시하고 원본 서버의 부하를 줄입니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon RDS를 Multi-AZ 구성으로 배포하여 데이터베이스 계층의 고가용성을 제공합니다.",
            "Amazon Route 53 헬스 체크를 설정하여 애플리케이션의 엔드포인트를 모니터링하고 장애 조치를 트리거합니다."
        ],
        "Explanation": "Amazon RDS를 Multi-AZ 구성으로 배포하면 기본 인스턴스가 실패할 경우 대기 인스턴스가 제공되어 데이터베이스 신뢰성이 향상됩니다. 또한 Amazon Route 53 헬스 체크를 설정하면 애플리케이션 엔드포인트를 자동으로 모니터링하고 중단 시 건강한 인스턴스로 장애 조치를 촉진할 수 있어 신뢰성이 더욱 향상됩니다.",
        "Other Options": [
            "AWS Global Accelerator를 구현하면 성능이 향상되고 지연 시간이 줄어들 수 있지만, 애플리케이션 자체의 신뢰성을 직접적으로 향상시키지는 않습니다.",
            "Amazon CloudFront를 구성하는 것은 캐싱에 유익하며 성능을 향상시킬 수 있지만, 애플리케이션 및 데이터베이스와 관련된 핵심 신뢰성 문제를 해결하지는 않습니다.",
            "AWS Lambda 함수를 사용하는 것은 작업을 분산하는 데 도움이 될 수 있지만, 이는 별도의 서비스이므로 주요 애플리케이션의 신뢰성을 본질적으로 향상시키지는 않습니다."
        ]
    },
    {
        "Question Number": "50",
        "Situation": "한 금융 서비스 회사가 애플리케이션을 AWS로 마이그레이션하고 있으며 데이터베이스 자격 증명, API 키 및 기타 비밀과 같은 민감한 정보를 관리할 수 있는 신뢰할 수 있는 방법이 필요합니다. 이 회사는 기존 AWS 서비스와 원활하게 통합되고, 접근 제어를 제공하며, 비밀을 애플리케이션 코드에 하드코딩하지 않고 안전하게 저장하고 검색할 수 있는 솔루션을 요구합니다. (두 가지 선택)",
        "Question": "비밀 관리에 대한 회사의 요구 사항을 충족하기 위해 솔루션 아키텍트가 구현해야 할 솔루션은 무엇입니까?",
        "Options": {
            "1": "AWS Systems Manager Parameter Store를 암호화와 함께 구현하여 비밀과 매개변수를 저장합니다.",
            "2": "서버 측 암호화가 활성화된 Amazon S3에 민감한 정보를 저장합니다.",
            "3": "AWS Secrets Manager를 사용하여 모든 민감한 정보를 안전하게 저장하고 관리합니다.",
            "4": "IAM 역할을 사용하여 자격 증명을 애플리케이션 코드에 직접 삽입하여 접근을 용이하게 합니다.",
            "5": "EC2 인스턴스에 자가 호스팅된 금고 솔루션을 배포하여 비밀 관리를 수행합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "AWS Secrets Manager를 사용하여 모든 민감한 정보를 안전하게 저장하고 관리합니다.",
            "AWS Systems Manager Parameter Store를 암호화와 함께 구현하여 비밀과 매개변수를 저장합니다."
        ],
        "Explanation": "AWS Secrets Manager는 다양한 AWS 서비스와의 통합이 내장된 민감한 정보를 안전하게 저장하고 관리할 수 있게 해주며, AWS Systems Manager Parameter Store는 구성 데이터와 비밀을 저장하기 위한 확장 가능한 솔루션을 제공하며 암호화 옵션도 있습니다. 두 서비스 모두 민감한 정보의 안전한 접근 및 관리 요구 사항을 충족합니다.",
        "Other Options": [
            "Amazon S3에 민감한 정보를 저장하는 것은 암호화가 있더라도 Secrets Manager나 Parameter Store와 같은 접근 제어 및 관리 기능을 제공하지 않으므로 비밀 관리에 덜 적합합니다.",
            "자격 증명을 애플리케이션 코드에 직접 삽입하는 것은 보안을 저해하며 비밀의 용이한 회전이나 관리가 불가능하게 되어 모범 사례에 위배됩니다.",
            "자가 호스팅된 금고 솔루션은 운영 오버헤드와 복잡성을 추가하며, 관리되는 AWS 서비스가 강력한 비밀 관리 기능을 제공할 때는 필요하지 않을 수 있습니다."
        ]
    },
    {
        "Question Number": "51",
        "Situation": "한 금융 서비스 회사가 고객 거래를 처리하는 온프레미스에 호스팅된 레거시 애플리케이션에 의존하고 있습니다. 이 애플리케이션은 일상적인 운영에 필수적이지만 확장성과 민첩성이 부족합니다. 경영진은 성능을 개선하고 운영 비용을 줄이기 위해 애플리케이션을 AWS로 마이그레이션하기로 결정했습니다. 그들은 기존 서비스에 대한 중단을 최소화하면서 애플리케이션의 현대화를 허용하는 솔루션을 찾고 있습니다.",
        "Question": "솔루션 아키텍트가 애플리케이션을 효과적으로 현대화하면서 원활한 전환을 보장하기 위해 추천해야 할 전략은 무엇입니까?",
        "Options": {
            "1": "전체 애플리케이션을 Amazon EC2 인스턴스로 리프트 앤 시프트하고 필요에 따라 AWS 서비스를 활용하기 위해 애플리케이션을 점진적으로 리팩토링합니다.",
            "2": "AWS Lambda와 마이크로서비스 아키텍처를 사용하여 전체 애플리케이션을 처음부터 완전히 재구축합니다.",
            "3": "데이터베이스를 Amazon RDS로 마이그레이션하고 레거시 애플리케이션을 온프레미스에 유지하면서 점진적으로 클라우드 네이티브 솔루션으로 전환합니다.",
            "4": "애플리케이션을 컨테이너화하고 Amazon ECS에 배포한 후, 시간이 지남에 따라 애플리케이션을 마이크로서비스로 리팩토링하여 확장성을 향상시킵니다."
        },
        "Correct Answer": "애플리케이션을 컨테이너화하고 Amazon ECS에 배포한 후, 시간이 지남에 따라 애플리케이션을 마이크로서비스로 리팩토링하여 확장성을 향상시킵니다.",
        "Explanation": "애플리케이션을 컨테이너화하면 자원 활용이 개선되고 종속성 관리가 용이해집니다. Amazon ECS를 사용하면 회사를 효과적으로 컨테이너를 조정할 수 있으며, 점진적인 마이크로서비스로의 리팩토링은 완전한 개편 없이 점진적인 현대화를 가능하게 하여 중단을 최소화합니다.",
        "Other Options": [
            "리프트 앤 시프트는 클라우드 네이티브 기능의 최상의 이점을 제공하지 않을 수 있으며, 종종 애플리케이션을 현대화하지 않고 기존 비효율성을 지속하게 됩니다.",
            "전체 애플리케이션을 처음부터 재구축하는 것은 위험하고 자원 집약적인 접근 방식으로, 장기적인 다운타임과 높은 비용을 초래할 수 있으며 즉각적인 이점을 보장하지 않습니다.",
            "레거시 애플리케이션을 온프레미스에 유지하면서 데이터베이스를 마이그레이션하는 것은 클라우드 기능을 효과적으로 활용하지 못하며 레거시 종속성을 유지함으로써 현대화 프로세스를 복잡하게 만들 수 있습니다."
        ]
    },
    {
        "Question Number": "52",
        "Situation": "한 금융 서비스 회사가 AWS에서 마이크로서비스 아키텍처를 설계하고 있습니다. 솔루션 아키텍트는 다양한 서비스가 서비스 엔드포인트를 사용하여 안전하고 효율적으로 통신할 수 있도록 해야 합니다. 이 회사는 내부 서비스에 대한 개인 연결 사용을 규정하는 엄격한 규정 준수 요구 사항이 있습니다.",
        "Question": "솔루션 아키텍트가 규정 준수 요구 사항을 준수하면서 안전한 서비스 통합을 가능하게 하기 위해 어떤 구성을 구현해야 합니까? (두 가지 선택)",
        "Options": {
            "1": "서비스 간의 직접 연결을 가능하게 하기 위해 VPC 피어링을 구성하여 규정 준수를 유지합니다.",
            "2": "AWS Transit Gateway를 설정하여 여러 VPC와 온프레미스 네트워크를 연결하고 마이크로서비스의 안전한 통신을 촉진합니다.",
            "3": "AWS PrivateLink를 사용하여 서비스에 대한 개인 엔드포인트를 생성하여 트래픽이 공용 인터넷을 통과하지 않도록 합니다.",
            "4": "Amazon API Gateway를 사용하여 웹 인터페이스로 서비스를 공개적으로 노출하여 외부 클라이언트가 쉽게 접근할 수 있도록 합니다.",
            "5": "AWS Direct Connect를 구현하여 온프레미스 데이터 센터에서 AWS로 전용 네트워크 연결을 설정합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "AWS PrivateLink를 사용하여 서비스에 대한 개인 엔드포인트를 생성하여 트래픽이 공용 인터넷을 통과하지 않도록 합니다.",
            "AWS Transit Gateway를 설정하여 여러 VPC와 온프레미스 네트워크를 연결하고 마이크로서비스의 안전한 통신을 촉진합니다."
        ],
        "Explanation": "AWS PrivateLink는 VPC와 서비스 간의 개인 연결을 제공하여 데이터가 AWS 네트워크를 떠나지 않도록 하여 규정 준수 요구 사항을 충족합니다. AWS Transit Gateway는 여러 VPC와 온프레미스 네트워크를 안전하게 연결하는 과정을 단순화하여 마이크로서비스 아키텍처에서 서비스 간 통신을 관리하기 쉽게 만듭니다.",
        "Other Options": [
            "VPC 피어링은 직접 연결을 위한 유효한 옵션이지만, VPC 수가 증가함에 따라 관리가 복잡해질 수 있으며 PrivateLink만큼 규정 준수를 효과적으로 해결하지는 않습니다.",
            "Amazon API Gateway는 서비스에 대한 공개 접근을 위해 설계되었으며, 이 시나리오에서 개인 연결 및 규정 준수 요구 사항과 모순됩니다.",
            "AWS Direct Connect는 전용 연결에 유용하지만, VPC 아키텍처 내에서 서비스 간 통합을 PrivateLink 및 Transit Gateway만큼 효과적으로 해결하지는 않습니다."
        ]
    },
    {
        "Question Number": "53",
        "Situation": "한 금융 서비스 회사가 Amazon RDS for PostgreSQL을 사용하여 거래 데이터베이스를 관리하고 있습니다. 이 데이터베이스에는 민감한 고객 정보가 포함되어 있으며 일상적인 운영에 필수적입니다. 회사는 재해 복구 및 규정 준수를 위해 데이터가 여러 지역에 복제되도록 해야 합니다. 그들은 1시간의 RTO와 10분의 RPO를 요구합니다.",
        "Question": "솔루션 아키텍트가 회사의 요구 사항을 효과적으로 충족하기 위해 어떤 옵션을 구현해야 합니까? (두 가지 선택)",
        "Options": {
            "1": "빠른 복구를 위해 동일한 지역에 RDS 인스턴스의 읽기 복제본을 생성합니다.",
            "2": "10분마다 다른 지역의 S3 버킷에 RDS 인스턴스의 자동 백업을 예약합니다.",
            "3": "AWS Database Migration Service (DMS)를 구현하여 다른 지역의 대상 데이터베이스로 데이터를 지속적으로 복제합니다.",
            "4": "Amazon RDS 스냅샷을 사용하여 수동 백업을 수행하고 매시간 다른 지역으로 복사합니다.",
            "5": "Amazon RDS 교차 지역 복제를 활성화하여 데이터베이스 변경 사항을 다른 지역으로 복제합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon RDS 교차 지역 복제를 활성화하여 데이터베이스 변경 사항을 다른 지역으로 복제합니다.",
            "AWS Database Migration Service (DMS)를 구현하여 다른 지역의 대상 데이터베이스로 데이터를 지속적으로 복제합니다."
        ],
        "Explanation": "Amazon RDS 교차 지역 복제를 활성화하면 변경 사항을 다른 지역으로 거의 실시간으로 복제할 수 있어 10분의 RPO 요구 사항을 충족합니다. 또한, AWS DMS를 사용하여 지속적으로 복제하면 대상 지역의 데이터가 항상 최신 상태로 유지되도록 보장하는 효과적인 방법이 됩니다. 이는 재해 복구 계획에 필수적입니다.",
        "Other Options": [
            "동일한 지역에 읽기 복제본을 생성하는 것은 교차 지역 재해 복구를 제공하지 않으며, 다른 지역으로 데이터 복제를 위한 요구 사항을 충족하지 않습니다.",
            "10분마다 S3로 자동 백업을 수행하면 RPO를 충족할 수 있지만, 수동 복원 프로세스가 필요하므로 즉각적인 장애 조치를 허용하지 않아 RTO 요구 사항을 충족하지 않습니다.",
            "Amazon RDS 스냅샷을 사용하여 매시간 수동 백업을 수행하는 것은 10분의 RPO 요구 사항을 충족하지 않으며, 스냅샷 간에 데이터 변경 사항이 손실될 수 있습니다."
        ]
    },
    {
        "Question Number": "54",
        "Situation": "한 회사가 AWS에서 높은 가용성을 요구하는 중요한 애플리케이션을 운영하고 있습니다. 현재 하나의 AWS 지역에 기본 데이터베이스가 있으며, 장애 발생 시 다른 지역의 보조 데이터베이스로 자동 장애 조치 전략을 구현하고자 합니다.",
        "Question": "가장 신뢰할 수 있는 자동 장애 조치를 제공하면서 다운타임을 최소화하는 접근 방식은 무엇입니까?",
        "Options": {
            "1": "교차 지역 장애 조치 기능을 위해 Amazon Aurora Global Database를 활용합니다.",
            "2": "자동 장애 조치를 위해 Amazon RDS를 Multi-AZ 배포로 사용합니다.",
            "3": "다른 지역에 읽기 복제본을 구현하고 장애 발생 시 이를 승격합니다.",
            "4": "데이터를 다른 지역으로 지속적으로 복제하기 위해 데이터베이스 마이그레이션 서비스를 설정합니다."
        },
        "Correct Answer": "교차 지역 장애 조치 기능을 위해 Amazon Aurora Global Database를 활용합니다.",
        "Explanation": "Amazon Aurora Global Database는 교차 지역 복제를 위해 설계되었으며, 낮은 대기 시간의 읽기 및 자동 장애 조치 기능을 제공합니다. 이는 다운타임을 최소화하고 지역 간 높은 가용성을 보장하는 가장 신뢰할 수 있는 옵션입니다.",
        "Other Options": [
            "Amazon RDS의 Multi-AZ 배포는 단일 지역 내에서 자동 장애 조치를 제공하지만, 다른 지역으로의 장애 조치를 지원하지 않아 교차 지역 높은 가용성에는 적합하지 않습니다.",
            "다른 지역에 읽기 복제본을 구현하는 것은 이를 기본으로 승격하기 위해 수동 개입이 필요하며, 이로 인해 장애 조치 과정에서 추가적인 다운타임이 발생할 수 있습니다.",
            "지속적인 복제를 위한 데이터베이스 마이그레이션 서비스를 설정하는 것은 실행 가능한 옵션이지만, 복잡성과 장애 조치 지연을 초래할 수 있어 높은 가용성 요구 사항을 충족하지 못할 수 있습니다."
        ]
    },
    {
        "Question Number": "55",
        "Situation": "한 금융 서비스 회사가 AWS에서 여러 중요한 애플리케이션을 운영하고 있습니다. 이들은 애플리케이션이 최적의 성능을 발휘하고 있으며, 잠재적인 문제가 신속하게 감지되고 해결되도록 해야 합니다. 이 회사는 엄격한 규정 준수 요구 사항이 있어 모든 작업에 대한 상세한 로깅 및 경고 메커니즘이 필요합니다. IT 팀은 수동 개입을 최소화하면서 시스템 성능과 건강에 대한 포괄적인 가시성을 보장하는 모니터링 전략을 구현하고자 합니다.",
        "Question": "다음 솔루션 중에서 회사의 애플리케이션에 대해 최소한의 수동 감독으로 가장 효과적인 모니터링 및 경고 시스템을 제공하는 것은 무엇입니까?",
        "Options": {
            "1": "AWS CloudTrail을 사용하여 API 호출을 추적하고 Amazon S3에 기록합니다. AWS Lambda 함수를 설정하여 로그를 분석하고 미리 정의된 기준에 따라 경고를 보냅니다.",
            "2": "Amazon CloudWatch Service Lens를 활용하여 애플리케이션 성능을 모니터링하고, 자동으로 이상을 감지하며, AWS Config와 통합하여 규정 준수를 보장하고 구성 변경에 대한 경고를 설정합니다.",
            "3": "AWS X-Ray를 구현하여 애플리케이션의 요청을 추적하고 성능 병목 현상을 시각화하며, Amazon SNS를 구성하여 X-Ray 이상에 따라 알림을 보냅니다.",
            "4": "Amazon CloudWatch를 설정하여 사용자 정의 메트릭을 추적하고 성능 임계값에 대한 경고를 생성합니다. CloudWatch Logs를 사용하여 애플리케이션 로그를 집계하고 특정 로그 패턴에 대한 경고를 구성합니다."
        },
        "Correct Answer": "Amazon CloudWatch Service Lens를 활용하여 애플리케이션 성능을 모니터링하고, 자동으로 이상을 감지하며, AWS Config와 통합하여 규정 준수를 보장하고 구성 변경에 대한 경고를 설정합니다.",
        "Explanation": "Amazon CloudWatch Service Lens는 애플리케이션 성능을 모니터링하고, 이상을 자동으로 감지하며, 규정 준수 관리를 위해 AWS Config와 통합하는 포괄적인 모니터링 솔루션을 제공합니다. 이는 수동 감독을 최소화하는 데 가장 효율적인 선택입니다.",
        "Other Options": [
            "Amazon CloudWatch를 사용자 정의 메트릭 및 경고를 위해 설정하는 것은 일부 수동 구성 및 유지 관리가 필요하여 Service Lens와 같은 완전 통합 솔루션보다 효율성이 떨어집니다.",
            "AWS X-Ray는 성능 문제를 추적하는 데 탁월하지만, 회사가 필요로 하는 규정 준수 요구 사항에 대한 포괄적인 모니터링 및 경고를 제공하지 않습니다.",
            "AWS CloudTrail을 사용하는 것은 주로 API 호출을 추적하는 데 중점을 두며, 애플리케이션 성능을 모니터링하는 직접적인 기능을 제공하지 않고, Lambda가 로그를 처리할 수 있지만 추가 설정이 필요합니다."
        ]
    },
    {
        "Question Number": "56",
        "Situation": "한 금융 서비스 조직이 AWS IAM을 사용하여 직원 및 제3자 공급업체의 접근을 관리하고 있습니다. 이 조직은 보안 정책을 엄격히 준수해야 하며, 사용자가 특정 역할에 필요한 리소스에만 접근할 수 있도록 해야 합니다. 또한, 조직은 계약자에게 프로젝트가 완료된 후 자동으로 만료되는 임시 접근을 구현하고자 합니다.",
        "Question": "조직의 요구 사항을 충족하기 위해 솔루션 아키텍트가 구현해야 할 IAM 솔루션은 무엇입니까?",
        "Options": {
            "1": "IAM 그룹을 활용하여 직원과 계약자를 접근 요구 사항에 따라 그룹화하여 사용자 권한을 관리합니다. 계약자가 근무 시간 동안만 리소스에 접근할 수 있도록 접근 키를 생성합니다.",
            "2": "각 직원과 계약자에 대해 IAM 사용자 계정을 생성하고, 각 사용자에게 고유한 비밀번호를 할당하며, 특정 리소스에 대한 접근을 허용하는 정책을 부착합니다. 프로젝트 완료 후 계약자 계정을 비활성화하기 위해 예약된 Lambda 함수를 사용합니다.",
            "3": "각 특정 직무 기능에 대해 해당 정책이 포함된 IAM 역할을 생성합니다. 사용자를 직무 요구 사항에 따라 이러한 역할에 할당합니다. 계약자의 경우, 역할을 임시로 맡을 수 있도록 신뢰 관계가 있는 역할을 생성하여, 역할의 최대 세션 기간이 프로젝트 일정에 맞도록 설정합니다.",
            "4": "직원과 계약자를 위한 중앙 사용자 그룹에 부착된 IAM 정책을 구현합니다. 리소스에 할당된 태그에 따라 권한을 설정하여 계약자가 적절한 태그가 있는 리소스에만 접근할 수 있도록 합니다."
        },
        "Correct Answer": "각 특정 직무 기능에 대해 해당 정책이 포함된 IAM 역할을 생성합니다. 사용자를 직무 요구 사항에 따라 이러한 역할에 할당합니다. 계약자의 경우, 역할을 임시로 맡을 수 있도록 신뢰 관계가 있는 역할을 생성하여, 역할의 최대 세션 기간이 프로젝트 일정에 맞도록 설정합니다.",
        "Explanation": "각 직무 기능에 대해 IAM 역할을 생성하면 권한에 대한 정밀한 제어가 가능합니다. 계약자가 역할을 임시로 맡을 수 있도록 함으로써, 보안 모범 사례를 준수하면서 접근이 그들의 필요에 맞게 조정되도록 할 수 있습니다. 또한, 계약자 역할에 대한 최대 세션 기간을 설정하면 그들의 접근이 자동으로 프로젝트 일정에 맞게 제한됩니다.",
        "Other Options": [
            "이 옵션은 계약자에 대해 자동 비활성화 프로세스 없이 IAM 사용자 계정을 사용하는 것은 보안 위험을 초래할 수 있으므로 잘못된 것입니다. 예약된 Lambda 함수는 복잡성을 추가하고 여전히 보안의 공백을 남길 수 있습니다.",
            "이 옵션은 IAM 그룹을 사용하는 것이 임시 접근에 필요한 세밀한 제어를 제공하지 않기 때문에 잘못된 것입니다. 계약자를 위한 접근 키는 역할 기반 접근보다 덜 안전하며, 자동으로 만료되지 않거나 악용될 수 있습니다.",
            "이 옵션은 태그 기반 IAM 정책을 사용하는 것이 시간에 민감한 방식으로 접근을 본질적으로 제한하지 않기 때문에 잘못된 것입니다. 계약자 접근이 임시적임을 보장하는 데 필요한 메커니즘을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "57",
        "Situation": "민감한 환자 데이터를 Amazon S3에 저장하고 백엔드 서비스에 접근하기 위해 API Gateway를 사용하는 헬스케어 애플리케이션이 AWS에 호스팅되고 있습니다. 이 애플리케이션은 HIPAA 규정을 준수해야 하며, AWS 서비스에 대한 안전한 접근을 보장하면서 데이터를 비공개로 유지해야 합니다. 팀은 공용 인터넷 접근 노출을 최소화하고 AWS 서비스에 대한 모든 통신이 안전하고 비공식적이도록 하기를 원합니다. 아키텍처에는 이미 고가용성을 위해 구성된 여러 서브넷이 있는 가상 사설 클라우드(VPC)가 포함되어 있습니다.",
        "Question": "이 헬스케어 애플리케이션의 HIPAA 준수를 준수하면서 Amazon S3에 대한 비공식 연결을 보장하기 위한 가장 효과적인 AWS 서비스 구성은 무엇입니까?",
        "Options": {
            "1": "VPC와 온프레미스 네트워크 간에 VPN 연결을 설정하고 모든 S3 트래픽을 VPN을 통해 라우팅하여 보안을 강화합니다.",
            "2": "공용 서브넷에 NAT Gateway를 배포하고 모든 S3 트래픽을 이를 통해 라우팅하여 애플리케이션 아키텍처를 비공식적으로 유지합니다.",
            "3": "Amazon S3에 대한 게이트웨이 엔드포인트를 생성하고, S3로 향하는 트래픽을 엔드포인트를 통해 라우팅하도록 개인 서브넷과 연결된 라우트 테이블을 업데이트합니다.",
            "4": "Amazon S3에 대한 인터페이스 엔드포인트를 구성하고 이를 개인 서브넷의 애플리케이션 인스턴스에 대한 접근을 제어하는 보안 그룹에 연결합니다."
        },
        "Correct Answer": "Amazon S3에 대한 게이트웨이 엔드포인트를 생성하고, S3로 향하는 트래픽을 엔드포인트를 통해 라우팅하도록 개인 서브넷과 연결된 라우트 테이블을 업데이트합니다.",
        "Explanation": "Amazon S3에 대한 게이트웨이 엔드포인트를 생성하면 공용 인터넷을 통과하지 않고 VPC 내에서 S3에 대한 비공식 연결을 허용하여 HIPAA 준수에 필수적입니다. 이 구성은 라우팅을 단순화하고 S3에 대한 공용 접근 필요성을 제거하여 보안을 강화합니다.",
        "Other Options": [
            "공용 서브넷에 NAT Gateway를 배포하는 것은 Amazon S3에 대한 필요한 비공식 연결을 제공하지 않으며, 여전히 트래픽을 공용 인터넷에 노출시켜 HIPAA 규정을 준수하지 않습니다.",
            "Amazon S3에 대한 인터페이스 엔드포인트를 구성하는 것은 유효하지 않으며, S3는 이 서비스에 대해 특별히 설계된 게이트웨이 엔드포인트만 지원하여 필요한 비공식 연결을 제공합니다.",
            "VPN 연결을 설정하는 것은 S3에 접근하기 위한 최선의 솔루션이 아니며, 불필요한 복잡성과 지연을 초래합니다. 게이트웨이 엔드포인트는 VPC 내에서 S3에 연결하는 보다 효율적이고 규정을 준수하는 방법입니다."
        ]
    },
    {
        "Question Number": "58",
        "Situation": "보안 팀은 AWS 워크로드의 안전을 보장할 책임이 있습니다. 그들은 Amazon Inspector를 활용하여 자원을 지속적으로 모니터링하고 취약점 및 의도치 않은 노출을 확인하고자 합니다. 팀은 특히 Amazon EC2 인스턴스와 AWS Lambda 함수에 집중하고 있습니다.",
        "Question": "보안 팀이 Amazon Inspector의 효과를 극대화하기 위해 어떤 구성을 구현해야 합니까? (두 가지 선택)",
        "Options": {
            "1": "오버헤드를 줄이기 위해 Amazon Lambda 함수에 대한 자동 스캔을 비활성화합니다.",
            "2": "모든 실행 중인 Amazon EC2 인스턴스에 Amazon Inspector 에이전트를 설치합니다.",
            "3": "Amazon Inspector를 AWS CloudTrail과 연결하여 모든 발견 사항에 대한 자세한 로그를 얻습니다.",
            "4": "Amazon Inspector를 사용하여 Amazon EC2 인스턴스에 대한 정기적인 평가를 예약합니다.",
            "5": "Amazon Inspector를 구성하여 발견 사항을 AWS Security Hub에 자동으로 전송합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "모든 실행 중인 Amazon EC2 인스턴스에 Amazon Inspector 에이전트를 설치합니다.",
            "Amazon Inspector를 사용하여 Amazon EC2 인스턴스에 대한 정기적인 평가를 예약합니다."
        ],
        "Explanation": "Amazon EC2 인스턴스의 보안을 완전히 평가하기 위해 Amazon Inspector 에이전트를 설치하는 것이 필수적입니다. 이는 잠재적인 취약점에 대한 포괄적인 분석을 가능하게 합니다. 또한 정기적인 평가를 예약하면 팀이 자원의 보안 상태에 대해 경계를 유지하고 식별된 문제를 신속하게 해결할 수 있습니다.",
        "Other Options": [
            "AWS Lambda 함수에 대한 자동 스캔을 비활성화하면 취약점 탐지의 효과가 감소하여 안전한 환경을 유지하려는 목표에 반합니다.",
            "Amazon Inspector를 AWS CloudTrail과 연결하면 일부 로깅 이점을 제공할 수 있지만, 스캔 프로세스나 취약점 관리의 효과를 직접적으로 향상시키지는 않습니다.",
            "Amazon Inspector를 구성하여 발견 사항을 AWS Security Hub에 전송하는 것은 유익하지만, EC2 및 Lambda 함수의 초기 평가 및 모니터링에 직접적으로 기여하지는 않습니다."
        ]
    },
    {
        "Question Number": "59",
        "Situation": "한 금융 서비스 회사는 거래를 처리하는 웹 애플리케이션에 대한 수요가 증가하고 있습니다. 현재 애플리케이션은 단일 Amazon EC2 인스턴스에 배포되어 있으며, 피크 거래 시간 동안 부하를 처리하는 데 어려움을 겪고 있습니다. 회사는 기존 아키텍처에 최소한의 변경으로 높은 가용성과 성능을 보장하고자 합니다.",
        "Question": "애플리케이션의 확장성과 신뢰성을 개선하기 위해 솔루션 아키텍트가 구현해야 할 전략은 무엇입니까?",
        "Options": {
            "1": "애플리케이션을 AWS Lambda로 마이그레이션하여 거래 처리를 수행하고 Amazon API Gateway를 요청 라우팅에 사용합니다.",
            "2": "EC2 인스턴스를 더 큰 인스턴스 유형으로 업그레이드하고 Amazon RDS 읽기 복제를 구성하여 기본 데이터베이스에서 읽기 쿼리를 오프로드합니다.",
            "3": "부하를 분산하기 위해 단일 추가 EC2 인스턴스를 배포하고 Route 53을 구성하여 DNS 기반 트래픽 분배를 수행합니다.",
            "4": "EC2 인스턴스에 대해 Auto Scaling 그룹을 구현하고 Elastic Load Balancer를 사용하여 들어오는 트래픽을 인스턴스에 고르게 분산합니다."
        },
        "Correct Answer": "EC2 인스턴스에 대해 Auto Scaling 그룹을 구현하고 Elastic Load Balancer를 사용하여 들어오는 트래픽을 인스턴스에 고르게 분산합니다.",
        "Explanation": "Auto Scaling 그룹과 Elastic Load Balancer를 결합하여 사용하면 애플리케이션이 수요에 따라 용량을 자동으로 조정할 수 있어 확장성과 높은 가용성을 보장합니다. 이 구성은 애플리케이션이 다양한 부하를 효율적으로 처리할 수 있도록 합니다.",
        "Other Options": [
            "AWS Lambda로 마이그레이션하면 애플리케이션 아키텍처에 상당한 변경이 필요하며, 애플리케이션이 상태를 유지하거나 지속적인 연결이 필요한 경우 모든 거래 처리 시나리오에 적합하지 않을 수 있습니다.",
            "더 큰 EC2 인스턴스로 업그레이드하면 일시적인 완화가 가능하지만, 피크 시간 동안 확장성 문제를 해결하지 못하며, 단일 인스턴스는 여전히 병목 현상이 발생할 수 있고 중복성을 제공하지 않습니다.",
            "단일 추가 EC2 인스턴스를 배포하면 부하 분산이 어느 정도 개선되지만, Auto Scaling 그룹의 동적 확장 기능이 부족하고 두 인스턴스 모두 실패할 수 있으므로 높은 가용성을 보장하지 않습니다."
        ]
    },
    {
        "Question Number": "60",
        "Situation": "한 회사는 다양한 워크로드를 처리하기 위해 여러 EC2 인스턴스를 관리하는 Auto Scaling 그룹을 운영하고 있습니다. 그들은 유지 관리를 위해 인스턴스를 Auto Scaling 그룹에서 분리하고 나머지 인스턴스가 원하는 용량을 계속 충족하도록 하기를 원합니다. 또한 인스턴스가 관련된 로드 밸런서에서 적절하게 제거되도록 하기를 원합니다.",
        "Question": "로드 밸런서에서 적절히 등록 해제되도록 하면서 Auto Scaling 그룹에서 인스턴스를 분리하는 올바른 접근 방식은 무엇입니까?",
        "Options": {
            "1": "DetachInstances API를 사용하여 인스턴스를 Auto Scaling 그룹에서 제거하고 로드 밸런서도 분리되도록 합니다.",
            "2": "DetachLoadBalancers API를 사용하여 Auto Scaling 그룹에서 인스턴스를 분리하여 로드 밸런서에서 제거되도록 합니다.",
            "3": "스케일링 프로세스를 일시 중지하고, 인스턴스를 Auto Scaling 그룹에서 수동으로 분리한 다음 로드 밸런서에서 등록 해제합니다.",
            "4": "DetachInstances API를 사용하여 인스턴스를 분리하면 로드 밸런서 등록 해제가 자동으로 처리됩니다."
        },
        "Correct Answer": "DetachInstances API를 사용하여 인스턴스를 분리하면 로드 밸런서 등록 해제가 자동으로 처리됩니다.",
        "Explanation": "DetachInstances API를 사용하면 인스턴스가 Auto Scaling 그룹에서 제거되고 관련된 로드 밸런서에서 등록 해제되어 스케일링 그룹이 원하는 용량을 유지하도록 보장합니다.",
        "Other Options": [
            "이 옵션은 DetachInstances API를 사용하라고 잘못 제안하면서 로드 밸런서가 분리되도록 해야 한다고 언급하지만, 이는 API에 의해 자동으로 처리됩니다.",
            "스케일링 프로세스를 일시 중지하면 인스턴스 교체를 방지할 수 있지만, 로드 밸런서에서의 자동 등록 해제를 해결하지 않으므로 이 접근 방식은 비효율적입니다.",
            "DetachLoadBalancers API는 Classic Load Balancer만 분리하며, Auto Scaling 그룹에서 인스턴스를 분리하는 것을 다루지 않으므로 이 옵션은 유효하지 않습니다."
        ]
    },
    {
        "Question Number": "61",
        "Situation": "한 금융 서비스 회사가 데이터 웨어하우징 요구를 위해 Amazon Redshift를 사용하고 있습니다. 여러 사용자가 복잡한 분석 쿼리를 실행할 때 피크 시간 동안 성능 문제가 발생합니다. 회사의 데이터 분석가들은 쿼리 실행 대기 시간이 길다고 자주 불평합니다. 아키텍처 팀은 짧은 쿼리가 큰 지연 없이 실행될 수 있도록 하면서 쿼리 성능을 최적화할 수 있는 옵션을 탐색하고 있습니다.",
        "Question": "동시성을 관리하면서 Amazon Redshift에서 쿼리 성능을 최적화하는 가장 효과적인 방법은 무엇입니까?",
        "Options": {
            "1": "Amazon Redshift에서 작업 부하 관리를 비활성화하여 모든 쿼리가 제한 없이 실행되도록 합니다.",
            "2": "wlm_query_slot_count를 증가시켜 더 많은 동시 쿼리를 허용하고 다양한 쿼리 유형에 적절한 서비스 클래스를 설정합니다.",
            "3": "장기 실행 쿼리가 피크 시간 동안 짧은 쿼리의 실행에 영향을 미치지 않도록 쿼리 스케줄링 시스템을 구현합니다.",
            "4": "Redshift 클러스터의 노드 수를 줄여 동시 쿼리 간의 자원 경쟁을 감소시킵니다."
        },
        "Correct Answer": "wlm_query_slot_count를 증가시켜 더 많은 동시 쿼리를 허용하고 다양한 쿼리 유형에 적절한 서비스 클래스를 설정합니다.",
        "Explanation": "wlm_query_slot_count를 증가시키면 더 많은 쿼리를 동시에 실행할 수 있어 피크 시간 동안 전체 성능이 향상됩니다. 적절한 서비스 클래스를 설정하면 실행 우선 순위를 추가로 최적화하여 짧은 쿼리가 장기 실행 쿼리보다 우선시되도록 할 수 있습니다.",
        "Other Options": [
            "Redshift 클러스터의 노드 수를 줄이면 사용 가능한 자원이 제한되어 성능 문제가 악화될 수 있습니다.",
            "쿼리 스케줄링 시스템을 구현하는 것은 Amazon Redshift의 직접적인 기능이 아니며, 동시성 문제의 근본 원인을 해결하지 않고 불필요한 복잡성을 초래할 수 있습니다.",
            "작업 부하 관리를 비활성화하면 쿼리 실행을 관리할 수 있는 제어가 없게 되어 모든 쿼리, 특히 피크 사용 시 대기 시간이 길어질 가능성이 높습니다."
        ]
    },
    {
        "Question Number": "62",
        "Situation": "데이터 분석 팀이 현재 Amazon EMR과 Apache Spark를 사용하여 대규모 데이터 세트를 처리하고 있습니다. 그들은 높은 성능을 유지하면서 비용을 줄이기 위해 처리 워크플로를 최적화하고자 합니다. 팀은 자주 Amazon S3에서 데이터를 검색하고 추가 분석을 위해 중간 결과를 저장해야 합니다. 그들은 비용을 관리하면서 EMR 클러스터의 효율성을 개선할 수 있는 옵션을 탐색하고 있습니다.",
        "Question": "Amazon EMR을 사용하는 팀의 데이터 처리 비용을 최적화하기 위해 솔루션 아키텍트가 추천해야 할 전략은 무엇입니까?",
        "Options": {
            "1": "비용 변동에 관계없이 가용성과 신뢰성을 보장하기 위해 온디맨드 인스턴스만으로 EMR 클러스터를 시작하고 마스터 노드에 예약 인스턴스를 사용합니다.",
            "2": "모든 중간 저장 요구에 Amazon S3를 활용하고 데이터 전송 비용을 최소화하기 위해 데이터 셔플링 없이 단일 단계에서 데이터를 처리하도록 EMR 작업을 구성합니다.",
            "3": "비용을 효과적으로 관리하면서 데이터가 처리할 수 있도록 보장하기 위해 EMR 클러스터를 비피크 시간에만 실행되도록 예약합니다.",
            "4": "EMR 클러스터에 스팟 인스턴스를 사용하여 비핵심 워크로드에 대한 낮은 가격을 활용하고 클러스터가 워크로드 수요에 따라 자동으로 확장 및 축소되도록 구성합니다."
        },
        "Correct Answer": "EMR 클러스터에 스팟 인스턴스를 사용하여 비핵심 워크로드에 대한 낮은 가격을 활용하고 클러스터가 워크로드 수요에 따라 자동으로 확장 및 축소되도록 구성합니다.",
        "Explanation": "스팟 인스턴스를 사용하면 팀이 EMR 클러스터와 관련된 비용을 크게 줄이면서 워크로드 요구 사항에 따라 확장할 수 있는 능력을 유지할 수 있습니다. 이 접근 방식은 중단을 감내할 수 있는 비핵심 워크로드에 이상적입니다. 수요에 따라 클러스터를 자동으로 확장하는 것은 비용을 추가로 최적화합니다.",
        "Other Options": [
            "온디맨드 인스턴스만으로 EMR 클러스터를 시작하면 신뢰성을 보장하지만 비용을 효과적으로 최적화하지 못합니다. 온디맨드 인스턴스는 스팟 인스턴스보다 비쌉니다.",
            "모든 중간 저장에 Amazon S3를 활용하는 것은 좋은 관행이지만, 데이터 셔플링 없이 단일 단계에서 데이터를 처리하는 것은 복잡한 워크플로에 항상 가능하지 않으며 비효율적인 자원 활용을 초래할 수 있습니다.",
            "EMR 클러스터를 비피크 시간에만 실행하도록 예약하는 것은 비용 관리에 도움이 될 수 있지만, 데이터 처리가 실시간 또는 거의 실시간으로 발생해야 하는 경우 모든 워크로드에 실용적이지 않을 수 있습니다."
        ]
    },
    {
        "Question Number": "63",
        "Situation": "한 금융 서비스 회사가 확장성을 개선하고 비용을 줄이기 위해 데이터 저장소를 AWS로 마이그레이션하고 있습니다. 그들은 내구성과 접근 용이성을 보장하면서 대량의 비구조적 데이터를 저장할 수 있는 솔루션이 필요합니다. 또한, 기존 워크플로와 원활하게 통합되는 백업 전략을 구현할 계획입니다. 솔루션 아키텍트는 이러한 요구 사항을 충족하는 AWS 스토리지 서비스를 추천해 달라는 요청을 받았습니다. (두 개 선택)",
        "Question": "회사의 요구 사항에 대해 솔루션 아키텍트가 추천해야 할 AWS 스토리지 솔루션은 무엇입니까?",
        "Options": {
            "1": "내구성 있는 객체 저장 및 백업 솔루션을 위한 Amazon S3, 데이터 관리를 위한 라이프사이클 정책 포함.",
            "2": "SMB 프로토콜 지원이 필요한 Windows 기반 애플리케이션 호스팅을 위한 Amazon FSx for Windows File Server.",
            "3": "EC2 인스턴스를 위한 고성능 블록 저장을 제공하는 Amazon EBS.",
            "4": "여러 인스턴스가 동시에 파일에 접근할 수 있도록 하는 공유 파일 저장을 위한 Amazon Elastic File System (EFS).",
            "5": "온프레미스 환경과 클라우드 저장소를 통합하여 백업을 위한 AWS Storage Gateway."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "내구성 있는 객체 저장 및 백업 솔루션을 위한 Amazon S3, 데이터 관리를 위한 라이프사이클 정책 포함.",
            "온프레미스 환경과 클라우드 저장소를 통합하여 백업을 위한 AWS Storage Gateway."
        ],
        "Explanation": "Amazon S3는 비구조적 데이터에 대한 높은 내구성, 확장성 및 라이프사이클 관리를 제공하여 회사의 저장 요구에 이상적입니다. AWS Storage Gateway는 온프레미스 환경과 클라우드 저장소의 원활한 통합을 가능하게 하여 회사의 기존 워크플로와 일치하는 백업 솔루션을 제공합니다.",
        "Other Options": [
            "Amazon Elastic File System (EFS)는 공유 파일 저장에 더 적합하며, 광범위한 내구성이 필요한 대량의 비구조적 데이터에는 최적이 아닐 수 있습니다.",
            "Amazon FSx for Windows File Server는 SMB 프로토콜이 필요한 Windows 애플리케이션에 맞춰져 있으며, 회사의 비구조적 데이터 저장 요구에는 필요하지 않을 수 있습니다.",
            "Amazon EBS는 블록 저장에 효과적이지만 회사가 필요로 하는 대규모 비구조적 데이터 저장을 위해 설계되지 않았습니다."
        ]
    },
    {
        "Question Number": "64",
        "Situation": "한 금융 서비스 회사가 데이터 아카이빙 전략을 AWS로 전환하고 있습니다. 이 회사는 민감한 금융 데이터를 처리하며, 비용을 최소화하면서 규정을 준수하고 필요할 때 데이터에 빠르게 접근할 수 있는 장기 저장 솔루션이 필요합니다. 솔루션 아키텍트는 아카이빙을 위한 적절한 Amazon S3 저장 클래스를 선택하는 임무를 맡고 있습니다. 데이터는 드물게 접근되지만 필요할 경우 몇 분 내에 검색할 수 있어야 합니다.",
        "Question": "다음 옵션 중 회사의 요구 사항을 가장 잘 충족하는 솔루션은 무엇입니까?",
        "Options": {
            "1": "S3 Glacier Flexible Retrieval을 활용하여 최적의 비용 절감을 이루고, 덜 중요한 데이터에 대해 몇 시간의 검색 시간을 허용합니다.",
            "2": "데이터를 S3 Standard에 저장한 후 덜 관련성이 높아지면 S3 Glacier로 전송합니다.",
            "3": "S3 Glacier Instant Retrieval을 사용하여 즉시 접근할 수 있도록 하면서 드물게 접근해야 하는 요구로 인해 저장 비용을 최소화합니다.",
            "4": "S3 Standard-IA를 구현하여 드물게 접근하고 데이터 검색을 위해 수동 프로세스에 의존합니다."
        },
        "Correct Answer": "S3 Glacier Instant Retrieval을 사용하여 즉시 접근할 수 있도록 하면서 드물게 접근해야 하는 요구로 인해 저장 비용을 최소화합니다.",
        "Explanation": "S3 Glacier Instant Retrieval은 드물게 접근되지만 즉시 검색이 필요한 데이터에 맞춰 설계되었습니다. 이는 데이터에 대한 빠른 접근이 필요하면서 저장 비용을 낮게 유지해야 하는 회사의 요구와 완벽하게 일치하여 아카이빙 전략에 최적의 선택이 됩니다.",
        "Other Options": [
            "S3 Standard는 드물게 접근되는 데이터의 장기 아카이빙에 비용 효율적이지 않으며, Glacier 옵션보다 더 높은 저장 비용이 발생합니다.",
            "S3 Glacier Flexible Retrieval은 비용 절감에 적합하지만 즉시 접근 요구를 충족하지 않으며, 데이터 검색에 몇 시간이 걸릴 수 있습니다.",
            "S3 Standard-IA는 드물게 접근하기 위해 설계되었지만 장기 저장 요구에 대해 Glacier 옵션만큼의 비용 절감을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "65",
        "Situation": "한 회사가 AWS Lambda를 사용하여 Amazon Kinesis 스트림의 레코드를 처리하고 있습니다. 솔루션 아키텍트는 Lambda 함수가 가장 효율적인 배치 구성으로 호출되도록 데이터 처리를 최적화해야 합니다. 회사는 Lambda 함수가 페이로드 크기 제한을 초과하지 않으면서 배치에서 최대 레코드 수를 처리할 수 있어야 합니다.",
        "Question": "Amazon Kinesis 스트림에서 읽을 때 AWS Lambda 함수가 단일 배치에서 처리할 수 있는 최대 레코드 수는 얼마입니까?",
        "Options": {
            "1": "배치당 1,000 레코드",
            "2": "배치당 10,000 레코드",
            "3": "6 MB 페이로드 크기",
            "4": "배치당 2,000 레코드"
        },
        "Correct Answer": "배치당 1,000 레코드",
        "Explanation": "Amazon Kinesis 스트림에서 레코드를 처리하는 Lambda 함수의 최대 배치 크기는 1,000 레코드입니다. 이 제한은 함수가 6 MB의 최대 페이로드 크기를 초과하지 않도록 보장합니다.",
        "Other Options": [
            "배치당 10,000 레코드는 잘못된 정보입니다. Kinesis의 최대 배치 크기는 페이로드 크기와 관계없이 1,000 레코드로 제한됩니다.",
            "6 MB 페이로드 크기는 잘못된 정보입니다. 이는 페이로드의 총 크기 제한을 나타내지만 배치에서 처리되는 최대 레코드 수를 명시하지 않습니다.",
            "배치당 2,000 레코드는 잘못된 정보입니다. Kinesis의 최대 배치 크기는 1,000 레코드로 제한되며, 2,000이 아닙니다."
        ]
    },
    {
        "Question Number": "66",
        "Situation": "한 금융 서비스 회사가 애플리케이션을 AWS로 마이그레이션하고 있습니다. 그들은 웹 서버, 애플리케이션 서버 및 데이터베이스를 포함한 다양한 워크로드를 위해 EC2 인스턴스를 혼합하여 배포했습니다. 현재 EC2 인스턴스의 성능과 비용을 모니터링한 결과 일부 인스턴스는 과소 활용되고 있고 다른 인스턴스는 과다 활용되고 있음을 깨달았습니다. 회사는 워크로드에 더 잘 맞도록 EC2 인스턴스를 적절한 크기로 조정하여 AWS 리소스를 최적화하고자 합니다. (두 가지 선택)",
        "Question": "다음 중 회사가 EC2 인스턴스의 적절한 크기 조정을 달성하는 데 도움이 되는 조치는 무엇입니까?",
        "Options": {
            "1": "AWS Compute Optimizer를 구현하여 활용 패턴에 따라 인스턴스 크기 조정에 대한 권장 사항을 받습니다.",
            "2": "각 인스턴스 유형에 대한 비용 분석을 수행하고 성능 요구 사항에 관계없이 모든 워크로드에 대해 가장 저렴한 인스턴스를 선택합니다.",
            "3": "AWS Lambda 함수를 사용하여 지정된 CPU 활용도 임계값 이하로 실행 중인 인스턴스를 자동으로 종료합니다.",
            "4": "데이터베이스 계층에 사용되는 EC2 인스턴스 유형을 검토하고 관리 단순화를 위해 단일 인스턴스 유형으로 마이그레이션합니다.",
            "5": "CloudWatch 메트릭을 분석하여 과소 활용된 EC2 인스턴스를 식별하고 이를 더 작은 인스턴스 유형으로 축소합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "CloudWatch 메트릭을 분석하여 과소 활용된 EC2 인스턴스를 식별하고 이를 더 작은 인스턴스 유형으로 축소합니다.",
            "AWS Compute Optimizer를 구현하여 활용 패턴에 따라 인스턴스 크기 조정에 대한 권장 사항을 받습니다."
        ],
        "Explanation": "CloudWatch 메트릭을 분석하면 회사가 과소 활용된 인스턴스를 식별하여 비용을 절감하기 위해 축소할 수 있는 데이터 기반 결정을 내릴 수 있습니다. 또한 AWS Compute Optimizer는 과거 사용 패턴에 따라 자동화된 권장 사항을 제공하여 적절한 크기 조정 기회를 식별하는 데 도움을 줍니다.",
        "Other Options": [
            "인스턴스 유형을 검토하는 것이 도움이 될 수 있지만 단일 인스턴스 유형으로 마이그레이션하는 것은 다양한 워크로드에 대한 성능이나 비용 효율성을 반드시 해결하지 않으므로 적절한 크기 조정에 비효율적입니다.",
            "CPU 활용도만을 기준으로 인스턴스를 종료하는 Lambda 함수를 사용하는 것은 전체 성능이나 워크로드의 특성을 고려하지 않기 때문에 중요한 애플리케이션의 의도치 않은 다운타임을 초래할 수 있습니다.",
            "특정 성능 요구 사항을 고려하지 않고 가장 저렴한 인스턴스 유형을 선택하면 애플리케이션 성능이 저하되어 사용자 불만과 잠재적인 비즈니스 손실로 이어질 수 있습니다."
        ]
    },
    {
        "Question Number": "67",
        "Situation": "한 금융 서비스 회사가 민감한 고객 데이터를 처리하는 여러 애플리케이션을 AWS에 배포했습니다. 보안 및 규정 준수를 강화하기 위해 회사는 AWS 환경을 모니터링하고 평가하는 데 도움이 되는 AWS 보안 도구를 구현하기로 결정했습니다. 솔루션 아키텍트는 보안 취약점, 규정 준수 상태 및 접근 제어 구성에 대한 통찰력을 제공할 수 있는 적절한 도구를 선택하는 임무를 맡았습니다. 그들은 여러 AWS 계정에 걸쳐 보안 경고 및 결과에 대한 통합된 뷰가 필요합니다.",
        "Question": "회사의 보안 모니터링 및 규정 준수 요구 사항을 가장 잘 충족하는 AWS 서비스 조합은 무엇입니까?",
        "Options": {
            "1": "AWS Security Hub, AWS CloudTrail, Amazon Inspector, AWS IAM Access Analyzer",
            "2": "Amazon CloudWatch, AWS Config, AWS Shield, AWS Firewall Manager",
            "3": "AWS Lambda, AWS Budgets, Amazon S3, AWS CloudFormation",
            "4": "AWS Trusted Advisor, Amazon GuardDuty, AWS WAF, AWS Systems Manager"
        },
        "Correct Answer": "AWS Security Hub, AWS CloudTrail, Amazon Inspector, AWS IAM Access Analyzer",
        "Explanation": "AWS Security Hub, AWS CloudTrail, Amazon Inspector 및 AWS IAM Access Analyzer의 조합은 보안 모니터링 및 규정 준수에 대한 포괄적인 접근 방식을 제공합니다. AWS Security Hub는 보안 경고를 집계하고 우선 순위를 지정하며, AWS CloudTrail은 계정 활동에 대한 가시성을 제공합니다. Amazon Inspector는 애플리케이션의 취약점을 평가하고, AWS IAM Access Analyzer는 리소스에 대한 의도하지 않은 접근을 식별하여 보안 정책 준수를 보장합니다.",
        "Other Options": [
            "이 옵션은 주로 리소스 모니터링 및 관리에 중점을 둔 서비스가 포함되어 있지만, 보안 평가 및 규정 준수 모니터링을 위한 전용 도구가 부족합니다.",
            "이 옵션은 DDoS 공격으로부터 보호하고 보안 규칙을 관리하는 서비스를 특징으로 하지만, 보안 경고 또는 규정 준수 검사의 포괄적인 뷰를 제공하지 않습니다.",
            "이 옵션은 비용 최적화 및 성능 모니터링을 제공하는 서비스를 포함하지만, 보안 취약점이나 규정 준수 요구 사항을 다루지 않습니다."
        ]
    },
    {
        "Question Number": "68",
        "Situation": "한 회사가 기존 온프레미스 애플리케이션을 AWS로 마이그레이션할 계획입니다. 그들은 성능과 신뢰성을 향상시키기 위해 새로운 AWS 서비스와 기능을 활용하고자 합니다. 솔루션 아키텍트는 애플리케이션 아키텍처를 현대화하면서 전환 중 다운타임을 최소화하는 마이그레이션 전략을 개발해야 합니다. 아키텍처는 또한 미래의 확장성과 유지 관리성을 지원해야 합니다.",
        "Question": "이 시나리오에서 회사가 취할 수 있는 가장 적합한 접근 방식은 무엇입니까?",
        "Options": {
            "1": "애플리케이션을 Amazon RDS 인스턴스로 마이그레이션하고 데이터베이스 기능을 활용하도록 리팩토링하되, 애플리케이션은 온프레미스에서 호스팅합니다.",
            "2": "Amazon ECS를 사용하여 애플리케이션을 컨테이너화하고 Amazon EC2 인스턴스에 배포하여 마이크로서비스의 관리 및 배포를 용이하게 합니다.",
            "3": "애플리케이션을 AWS Lambda 및 Amazon API Gateway를 사용하도록 재설계하여 자동으로 확장되고 운영 오버헤드를 최소화하는 서버리스 아키텍처를 보장합니다.",
            "4": "애플리케이션을 Amazon EC2 인스턴스로 변경 없이 리프트 앤 시프트하고, 마이그레이션이 완료된 후 현대화할 계획을 세웁니다."
        },
        "Correct Answer": "애플리케이션을 AWS Lambda 및 Amazon API Gateway를 사용하도록 재설계하여 자동으로 확장되고 운영 오버헤드를 최소화하는 서버리스 아키텍처를 보장합니다.",
        "Explanation": "이 옵션은 서버리스 아키텍처를 활용하여 애플리케이션을 현대화하는 가장 좋은 접근 방식을 제공합니다. AWS Lambda 및 API Gateway는 자동 확장을 허용하여 서버 관리의 필요성을 줄이고 전반적인 성능과 신뢰성을 향상시킵니다.",
        "Other Options": [
            "이 접근 방식은 AWS 서비스를 활용하여 애플리케이션을 현대화하지 않습니다. 이는 운영 비용을 증가시킬 수 있으며 확장성이나 성능 개선을 지원하지 않습니다.",
            "컨테이너화가 관리 및 배포를 향상시킬 수 있지만, 이 옵션은 여전히 EC2에 의존하여 기본 인프라를 관리해야 하며 서버리스 아키텍처의 이점을 완전히 활용하지 않습니다.",
            "이 옵션은 데이터베이스 마이그레이션에만 초점을 맞추고 애플리케이션 계층을 다루지 않습니다. 애플리케이션을 온프레미스에 유지하여 확장성을 제한하고 AWS 서비스의 전체 기능을 활용하지 않습니다."
        ]
    },
    {
        "Question Number": "69",
        "Situation": "전 세계 수백만 명의 플레이어에게 서비스를 제공하는 글로벌 온라인 게임 회사가 지연 시간을 줄이고 콘텐츠 전달을 개선하여 게임 경험을 최적화할 필요가 있습니다. 이 회사는 여러 AWS 리전에서 게임 서버를 배포했으며, 지리적으로 빠른 콘텐츠 전달과 원활한 플레이어 경험을 제공할 수 있는 솔루션을 찾고 있습니다. 또한, 이 회사는 지역 장애 발생 시 높은 가용성과 자동 장애 조치를 보장하고자 합니다.",
        "Question": "회사의 저지연 콘텐츠 전달 및 높은 가용성 요구 사항을 가장 잘 충족하는 솔루션은 무엇입니까?",
        "Options": {
            "1": "AWS Lambda@Edge와 Amazon CloudFront를 구현하여 게임 데이터를 플레이어 가까이에 캐시하고, Amazon Route 53을 사용하여 높은 가용성을 위한 DNS 장애 조치를 관리합니다.",
            "2": "게임 콘텐츠 저장을 위해 Amazon S3를 배포하고 AWS Direct Connect를 사용하여 게임 서버로의 데이터 전송을 위한 전용 회선을 제공합니다. 이는 지연 시간과 성능을 개선합니다.",
            "3": "Amazon CloudFront를 사용하여 게임 콘텐츠를 전 세계에 배포합니다. AWS Global Accelerator를 구현하여 플레이어를 가장 가까운 게임 서버로 라우팅하고 자동 장애 조치로 가용성을 향상시킵니다.",
            "4": "여러 리전에서 Amazon Elastic Load Balancing을 활용하여 게임 서버 간에 트래픽을 고르게 분산하고, 데이터베이스 중복성을 위해 Amazon RDS를 Multi-AZ로 설정합니다."
        },
        "Correct Answer": "Amazon CloudFront를 사용하여 게임 콘텐츠를 전 세계에 배포합니다. AWS Global Accelerator를 구현하여 플레이어를 가장 가까운 게임 서버로 라우팅하고 자동 장애 조치로 가용성을 향상시킵니다.",
        "Explanation": "Amazon CloudFront를 사용하면 플레이어 가까운 엣지 위치에서 콘텐츠를 캐시하여 지연 시간을 줄이면서 게임 콘텐츠를 효율적으로 배포할 수 있습니다. AWS Global Accelerator는 트래픽을 최적의 게임 서버로 지능적으로 라우팅하여 가용성을 더욱 향상시켜 플레이어가 최소한의 지연으로 원활한 경험을 할 수 있도록 보장합니다.",
        "Other Options": [
            "게임 콘텐츠 저장을 위해 Amazon S3를 배포하고 AWS Direct Connect를 사용하는 것은 데이터 전송 성능을 개선하지만, 저지연 콘텐츠 전달이나 게임 서버의 자동 장애 조치 메커니즘을 직접적으로 다루지 않습니다.",
            "AWS Lambda@Edge와 Amazon CloudFront를 캐싱에 구현하고 Amazon Route 53을 DNS 장애 조치에 사용하는 것은 일부 이점을 제공하지만, AWS Global Accelerator만큼의 자동 장애 조치 및 라우팅 최적화를 제공하지 않을 수 있습니다.",
            "Amazon Elastic Load Balancing을 트래픽 분산에 활용하고 Amazon RDS를 Multi-AZ로 설정하여 데이터베이스 중복성을 확보하는 것은 좋은 높은 가용성 전략이지만, 전 세계 플레이어 기반을 위한 글로벌 콘텐츠 전달 및 지연 시간 감소를 구체적으로 다루지 않습니다."
        ]
    },
    {
        "Question Number": "70",
        "Situation": "한 금융 서비스 회사가 웹 애플리케이션을 AWS로 마이그레이션하고 있습니다. 이 회사는 내부 API와 서비스를 SSL/TLS 인증서로 보호해야 합니다. 보안 팀은 추가 구성 없이 클라이언트 애플리케이션과 브라우저에서 자동으로 신뢰되는 인증서를 사용하는 것을 선호합니다. 이 목적을 위해 AWS Certificate Manager를 사용할 것을 고려하고 있습니다.",
        "Question": "회사가 클라이언트 애플리케이션과 브라우저와의 원활한 신뢰를 보장하기 위해 AWS Certificate Manager를 사용하여 어떤 유형의 인증서를 발급해야 합니까?",
        "Options": {
            "1": "공개 인증서에 대해 제3자 인증 기관을 사용합니다.",
            "2": "모든 내부 애플리케이션에 대해 자체 서명된 인증서를 사용합니다.",
            "3": "내부 서비스에 대해 개인 SSL/TLS 인증서를 발급합니다.",
            "4": "외부 서비스에 대해 공개 SSL/TLS 인증서를 발급합니다."
        },
        "Correct Answer": "외부 서비스에 대해 공개 SSL/TLS 인증서를 발급합니다.",
        "Explanation": "AWS Certificate Manager를 통해 공개 SSL/TLS 인증서를 발급하면 인증서가 브라우저와 클라이언트 애플리케이션에서 자동으로 신뢰되므로 추가 구성 없이 원활한 신뢰를 요구하는 회사의 요구 사항을 충족합니다.",
        "Other Options": [
            "개인 SSL/TLS 인증서를 발급하면 클라이언트 애플리케이션에서 인증서를 신뢰하도록 명시적인 구성이 필요하므로 원활한 신뢰 요구 사항을 충족하지 않습니다.",
            "자체 서명된 인증서를 사용하는 것은 기본적으로 신뢰되지 않기 때문에 프로덕션 환경에서는 권장되지 않으며, 각 클라이언트에 대해 추가 구성이 필요하므로 요구 사항과 모순됩니다.",
            "제3자 인증 기관을 사용하는 것은 불필요한 복잡성과 비용을 초래할 수 있으며, AWS Certificate Manager는 자동으로 신뢰되는 무료 공개 인증서를 제공합니다."
        ]
    },
    {
        "Question Number": "71",
        "Situation": "한 다국적 기업이 AWS에서 전 세계적으로 분산된 애플리케이션을 배포하고 있으며, 사용자 트래픽을 효율적으로 라우팅하고 높은 가용성을 제공해야 합니다. 이 애플리케이션은 다양한 지리적 위치에서 접근될 것이며, 회사는 지연 시간을 최소화하면서 사용자가 가장 가까운 가용 리소스로 안내되도록 하는 것을 목표로 하고 있습니다. 이를 위해 AWS Route 53에서 제공하는 다양한 라우팅 정책을 고려하고 있습니다.",
        "Question": "사용자의 지리적 위치에 따라 가장 가까운 애플리케이션 엔드포인트로 사용자를 안내하는 데 가장 효과적인 AWS Route 53의 라우팅 정책은 무엇입니까?",
        "Options": {
            "1": "가중 라우팅 정책",
            "2": "지리적 위치 라우팅 정책",
            "3": "장애 조치 라우팅 정책",
            "4": "지연 시간 라우팅 정책"
        },
        "Correct Answer": "지리적 위치 라우팅 정책",
        "Explanation": "지리적 위치 라우팅 정책을 사용하면 Route 53이 사용자의 지리적 위치에 따라 트래픽을 안내할 수 있습니다. 이는 사용자가 가장 가까운 애플리케이션 엔드포인트로 라우팅되어 지연 시간을 줄이고 성능을 향상시킵니다. 이는 지리적 근접성이 사용자 경험 최적화에 중요한 시나리오를 위해 특별히 설계되었습니다.",
        "Other Options": [
            "지연 시간 라우팅 정책은 건강 검사를 기반으로 가장 낮은 지연 시간을 제공하는 엔드포인트로 사용자를 안내하지만, 사용자의 지리적 위치를 특별히 고려하지 않습니다. 이는 항상 사용자를 가장 가까운 리소스로 안내하지 않을 수 있으며, 이는 이 시나리오의 주요 요구 사항입니다.",
            "가중 라우팅 정책은 할당된 가중치에 따라 여러 엔드포인트에 트래픽을 분배할 수 있지만, 지리적 위치를 고려하지 않습니다. 이로 인해 지연 시간 측면에서 비효율적인 라우팅이 발생할 수 있으며, 사용자가 가장 가까운 리소스로 안내되지 않을 수 있습니다.",
            "장애 조치 라우팅 정책은 트래픽을 기본 엔드포인트로 라우팅하고 실패 시 보조 엔드포인트로 장애 조치하는 데 사용됩니다. 이 정책은 사용자 근접성이나 지연 시간을 최적화하기보다는 높은 가용성을 위해 설계되었으므로 사용자를 가장 가까운 애플리케이션 엔드포인트로 안내하는 요구 사항에 적합하지 않습니다."
        ]
    },
    {
        "Question Number": "72",
        "Situation": "한 회사가 온프레미스에서 AWS로 아키텍처를 마이그레이션하고 있습니다. 이들은 개인 서브넷의 인스턴스가 업데이트 및 패치를 위해 인터넷에 접근할 수 있도록 하면서 인스턴스가 직접적으로 들어오는 인터넷 트래픽에 노출되지 않도록 하는 솔루션이 필요합니다. 팀은 이 요구 사항을 달성하기 위해 NAT의 최적 사용을 평가하고 있습니다.",
        "Question": "연결 시간 초과와 관련하여 NAT 인스턴스와 NAT 게이트웨이의 동작을 올바르게 설명하는 문장은 무엇입니까?",
        "Options": {
            "1": "NAT 인스턴스는 시간 초과 시 연결을 닫기 위해 FIN 패킷을 보내고, NAT 게이트웨이는 연결을 종료하기 위해 RST 패킷을 보냅니다.",
            "2": "NAT 인스턴스와 게이트웨이 모두 시간 초과 시 연결을 종료하기 위해 RST 패킷을 보냅니다.",
            "3": "NAT 인스턴스와 게이트웨이 모두 시간 초과 시 연결을 종료하기 위해 FIN 패킷을 보냅니다.",
            "4": "NAT 게이트웨이는 시간 초과 시 연결을 닫기 위해 FIN 패킷을 보내고, NAT 인스턴스는 연결을 종료하기 위해 RST 패킷을 보냅니다."
        },
        "Correct Answer": "NAT 인스턴스는 시간 초과 시 연결을 닫기 위해 FIN 패킷을 보내고, NAT 게이트웨이는 연결을 종료하기 위해 RST 패킷을 보냅니다.",
        "Explanation": "NAT 인스턴스와 NAT 게이트웨이는 연결 시간 초과를 다르게 처리합니다. NAT 인스턴스는 연결을 정상적으로 종료하기 위해 개인 리소스에 FIN 패킷을 보내고, NAT 게이트웨이는 적절한 종료 순서 없이 연결을 강제로 종료하는 RST 패킷을 보냅니다.",
        "Other Options": [
            "NAT 게이트웨이가 FIN 패킷을 보내는 것은 잘못된 정보입니다. 실제로 그들은 연결 시간 초과 시 RST 패킷을 보냅니다.",
            "이것은 잘못된 정보입니다. 오직 NAT 인스턴스만 FIN 패킷을 보내고, NAT 게이트웨이는 RST 패킷을 보냅니다.",
            "이것은 잘못된 정보입니다. NAT 인스턴스와 게이트웨이는 시간 초과 시 모두 FIN 패킷을 보내지 않으며, 연결 종료를 위해 서로 다른 메커니즘을 사용합니다."
        ]
    },
    {
        "Question Number": "73",
        "Situation": "한 금융 서비스 회사가 애플리케이션을 AWS로 마이그레이션하고 있으며, 컨테이너 호스팅 플랫폼을 선택해야 합니다. 이 회사는 손쉬운 확장, 높은 가용성 및 기존 CI/CD 파이프라인과의 통합을 허용하는 솔루션이 필요합니다. 애플리케이션은 마이크로서비스 기반이며, 빠른 배포 및 롤백 기능을 지원해야 하며, 보안 및 규정 준수 요구 사항을 충족해야 합니다.",
        "Question": "다음 중 회사의 요구 사항에 가장 적합한 컨테이너 호스팅 플랫폼은 무엇입니까?",
        "Options": {
            "1": "Amazon EC2에 Docker를 설치하여 가상 머신에서 컨테이너를 직접 실행하며, 전체 제어를 제공하지만 확장 및 관리가 복잡해집니다.",
            "2": "Amazon ECS와 AWS Fargate를 사용하여 컨테이너를 관리하고 서버리스 컴퓨팅을 가능하게 하여 확장 및 배포를 간소화합니다.",
            "3": "AWS Lambda를 사용하여 서버리스 방식으로 컨테이너화된 애플리케이션을 실행하며, 컨테이너 관리의 필요성을 없애지만 제어가 제한됩니다.",
            "4": "Amazon EKS와 Kubernetes를 사용하여 컨테이너를 관리하며, 고급 오케스트레이션 기능을 제공하지만 운영 오버헤드가 더 많이 필요합니다."
        },
        "Correct Answer": "Amazon ECS와 AWS Fargate를 사용하여 컨테이너를 관리하고 서버리스 컴퓨팅을 가능하게 하여 확장 및 배포를 간소화합니다.",
        "Explanation": "Amazon ECS와 AWS Fargate는 기본 인프라를 추상화하는 서버리스 컨테이너 호스팅 옵션을 제공하여 회사가 서버 유지 관리에 대한 걱정 없이 애플리케이션을 배포하고 관리하는 데 집중할 수 있게 합니다. 이는 손쉬운 확장을 지원하며 CI/CD 파이프라인과 잘 통합되어 회사의 요구 사항을 충족합니다.",
        "Other Options": [
            "Amazon EKS와 Kubernetes는 Kubernetes 제어 플레인을 관리해야 하므로 복잡성과 운영 오버헤드가 추가되어 단순성과 사용 용이성을 찾는 팀에는 적합하지 않습니다.",
            "AWS Lambda는 서버리스 아키텍처에서 코드를 실행하도록 설계되었지만, ECS나 EKS와 같은 수준의 컨테이너화된 애플리케이션에 대한 제어를 제공하지 않아 회사가 마이크로서비스를 효과적으로 관리하는 능력을 제한합니다.",
            "Amazon EC2에 Docker를 설치하면 환경에 대한 전체 제어를 제공하지만 확장 및 관리가 복잡해져 회사의 간소화되고 관리 가능한 솔루션 필요와 맞지 않습니다."
        ]
    },
    {
        "Question Number": "74",
        "Situation": "한 회사가 Amazon DynamoDB를 주요 데이터베이스로 사용하는 새로운 서버리스 애플리케이션을 설계하고 있습니다. 이 애플리케이션은 다양한 작업 부하를 처리하며, 개발 팀은 데이터 접근 패턴을 최적화하고 비용을 최소화하는 데 집중하고 있습니다. 그들은 효율적인 데이터 검색 및 저장을 보장하기 위해 기본 키의 적절한 사용을 결정해야 합니다. (두 가지 선택)",
        "Question": "DynamoDB에서 최적의 성능과 비용 효율성을 보장하는 두 가지 구성은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "적응형 용량을 구성하여 높은 트래픽을 경험하는 파티션의 처리량을 자동으로 조정하되, 총 프로비저닝 용량을 초과하지 않도록 합니다.",
            "2": "단순 기본 키를 사용하여 파티션 키만으로 구성하여 항목이 파티션에 고르게 분포되도록 합니다.",
            "3": "글로벌 보조 인덱스를 사용하여 기본 키 이외의 속성을 기준으로 쿼리할 수 있도록 합니다.",
            "4": "파티션 키와 정렬 키를 포함한 복합 기본 키를 사용하여 관련 항목의 효율적인 쿼리를 가능하게 합니다.",
            "5": "단일 테이블 설계를 구현하여 모든 관련 데이터를 단일 DynamoDB 테이블에 통합하여 성능을 향상시킵니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "파티션 키와 정렬 키를 포함한 복합 기본 키를 사용하여 관련 항목의 효율적인 쿼리를 가능하게 합니다.",
            "적응형 용량을 구성하여 높은 트래픽을 경험하는 파티션의 처리량을 자동으로 조정하되, 총 프로비저닝 용량을 초과하지 않도록 합니다."
        ],
        "Explanation": "복합 기본 키를 사용하면 관련 항목의 효율적인 쿼리 및 검색이 가능하여 복잡한 접근 패턴을 가진 애플리케이션에 매우 중요합니다. 또한 적응형 용량을 구성하면 애플리케이션이 다양한 작업 부하를 처리할 수 있도록 하여 스로틀링이나 과도한 프로비저닝으로 인한 불필요한 비용을 발생시키지 않도록 합니다.",
        "Other Options": [
            "단순 기본 키를 사용하면 관련 항목을 처리할 때 효율적인 데이터 검색에 필요한 유연성을 제공하지 못할 수 있으며, 이는 비효율적인 쿼리와 잠재적인 성능 문제로 이어질 수 있습니다.",
            "글로벌 보조 인덱스는 유용할 수 있지만, 최적의 성능을 위한 기본 키 설계를 직접적으로 해결하지 않으며, 보조 접근 패턴으로 작용하고 추가 비용이 발생할 수 있습니다.",
            "단일 테이블 설계를 구현하는 것은 일부 시나리오에서 유익할 수 있지만, 최적의 기본 키 구성의 필요를 직접적으로 해결하지 않으며 데이터 접근 패턴을 복잡하게 만들 수 있습니다."
        ]
    },
    {
        "Question Number": "75",
        "Situation": "한 금융 서비스 회사가 AWS Lambda를 사용하여 실시간 거래를 처리하는 새로운 서버리스 애플리케이션을 개발하고 있습니다. 이 애플리케이션은 하루 동안 다양한 트래픽 수준을 가질 것으로 예상되며, 업무 시간 동안 피크 사용이 발생합니다. 솔루션 아키텍트는 애플리케이션이 갑작스러운 트래픽 급증을 처리할 수 있도록 하면서 비용을 최소화해야 합니다.",
        "Question": "솔루션 아키텍트가 애플리케이션이 갑작스러운 트래픽 급증을 효율적으로 처리할 수 있도록 구현해야 할 동시성 제어 방법은 무엇입니까?",
        "Options": {
            "1": "프로비저닝된 동시성과 예약된 동시성을 조합하여 트래픽을 효과적으로 관리하고 비용을 최적화합니다.",
            "2": "예약된 동시성을 설정하여 모든 Lambda 함수에서 최대 동시 실행 수를 제한하여 스로틀링을 방지합니다.",
            "3": "AWS 계정의 총 동시성 한도를 늘려 모든 함수에서 더 많은 동시 실행을 허용합니다.",
            "4": "프로비저닝된 동시성을 구성하여 피크 트래픽 동안 즉시 사용 가능하도록 특정 수의 Lambda 인스턴스를 미리 준비합니다."
        },
        "Correct Answer": "프로비저닝된 동시성을 구성하여 피크 트래픽 동안 즉시 사용 가능하도록 특정 수의 Lambda 인스턴스를 미리 준비합니다.",
        "Explanation": "프로비저닝된 동시성은 아키텍트가 특정 수의 Lambda 인스턴스를 미리 초기화할 수 있도록 하여 요청을 즉시 처리할 준비가 되도록 보장합니다. 이는 갑작스러운 트래픽 급증을 경험하는 애플리케이션에 매우 중요합니다.",
        "Other Options": [
            "예약된 동시성만 설정하면 최대 동시 실행 수를 제한할 뿐 즉각적인 응답 시간을 보장하지 않으므로 피크 부하 시 지연이 발생할 수 있습니다.",
            "프로비저닝된 동시성과 예약된 동시성을 조합하면 일부 이점을 제공할 수 있지만 아키텍처를 복잡하게 만들고 갑작스러운 급증을 효과적으로 관리하는 데 필요하지 않을 수 있습니다.",
            "AWS 계정의 총 동시성 한도를 늘리는 것은 트래픽 급증 동안 Lambda 인스턴스의 즉각적인 가용성 필요를 해결하지 못할 수 있으며 추가 비용이 발생할 수 있습니다."
        ]
    }
]