[
    {
        "Question Number": "1",
        "Situation": "소매 회사가 고객의 구매 이력을 기반으로 고객 선호도를 예측하기 위한 머신 러닝 모델을 개발하고 있습니다. 데이터 세트는 방대하며, 데이터 과학자는 모델이 신뢰할 수 있고 보지 못한 데이터에 잘 일반화되도록 해야 합니다. 데이터 과학자는 데이터를 훈련 세트와 검증 세트로 나누기 위한 다양한 전략을 고려하고 있습니다.",
        "Question": "데이터 과학자가 강력한 모델 평가를 보장하고 과적합을 방지하기 위해 어떤 접근 방식을 구현해야 합니까?",
        "Options": {
            "1": "선호도의 분포를 고려하지 않고 데이터를 무작위로 훈련 세트와 검증 세트로 나눈다.",
            "2": "각 폴드에서 고객 선호도의 분포를 유지하기 위해 층화 k-겹 교차 검증을 사용한다.",
            "3": "구매 날짜를 기준으로 훈련 데이터와 검증 데이터를 분리하기 위해 시간 기반 분할을 사용한다.",
            "4": "단일 훈련-테스트 분할을 적용하여 데이터의 80%를 훈련에, 20%를 검증에 할당한다."
        },
        "Correct Answer": "각 폴드에서 고객 선호도의 분포를 유지하기 위해 층화 k-겹 교차 검증을 사용한다.",
        "Explanation": "층화 k-겹 교차 검증은 각 폴드가 목표 변수(고객 선호도)의 동일한 분포를 유지하도록 보장하여 더 신뢰할 수 있는 모델 평가를 가능하게 하고 검증 결과의 편향을 줄입니다.",
        "Other Options": [
            "분포를 고려하지 않고 데이터를 무작위로 나누면 불균형한 훈련 및 검증 세트가 발생할 수 있으며, 이는 전체 데이터 분포를 정확하게 나타내지 않을 수 있습니다.",
            "시간 기반 분할은 고객 선호도가 시간이 지남에 따라 변할 경우 편향을 초래할 수 있어, 모델이 미래 데이터에 대해 덜 일반화될 수 있습니다.",
            "단일 훈련-테스트 분할을 적용하면 모델 성능에 대한 포괄적인 평가를 제공하지 못할 수 있으며, 검증을 위해 단지 하나의 무작위 데이터 하위 집합에 의존합니다."
        ]
    },
    {
        "Question Number": "2",
        "Situation": "머신 러닝 전문가가 분류 모델을 작업하고 있으며 훈련 데이터에 과적합되지 않고 성능을 평가하고자 합니다. 전문가는 보다 강력한 모델 평가를 보장하기 위해 교차 검증 기법을 사용하기로 결정합니다.",
        "Question": "전문가가 구현할 수 있는 교차 검증 기법은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "k-겹 교차 검증",
            "2": "무작위 탐색 교차 검증",
            "3": "층화 k-겹 교차 검증",
            "4": "Leave-One-Out 교차 검증",
            "5": "그리드 탐색 교차 검증"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "k-겹 교차 검증",
            "층화 k-겹 교차 검증"
        ],
        "Explanation": "k-겹 교차 검증은 데이터 세트를 K개의 하위 집합으로 나누고, 각 하위 집합을 검증 세트로 사용하여 K번 모델을 훈련하는 방법입니다. 층화 k-겹 교차 검증은 각 폴드가 목표 클래스의 대표적인 분포를 가지도록 보장하는 변형으로, 불균형 데이터 세트에 특히 유용합니다.",
        "Other Options": [
            "그리드 탐색 교차 검증은 독립적인 교차 검증 기법이 아니라 교차 검증을 과정의 일부로 활용하는 하이퍼파라미터 조정 방법입니다.",
            "무작위 탐색 교차 검증은 교차 검증을 사용하는 하이퍼파라미터 조정 접근 방식이지만, 모델 성능 평가를 위한 직접적인 기법으로는 사용되지 않습니다.",
            "Leave-One-Out 교차 검증은 K가 데이터 세트의 샘플 수와 같아지는 k-겹 교차 검증의 특정 사례로, 계산 비용이 많이 들고 대규모 데이터 세트에는 실용적이지 않은 경우가 많습니다."
        ]
    },
    {
        "Question Number": "3",
        "Situation": "머신 러닝 엔지니어가 머신 러닝 모델 훈련에 사용할 대규모 데이터 세트를 위한 적절한 저장 솔루션을 선택하는 임무를 맡았습니다. 데이터 세트는 비구조적 데이터로 구성되어 있으며 높은 내구성과 접근성이 필요합니다.",
        "Question": "엔지니어가 훈련 데이터에 대한 최적의 성능과 접근 용이성을 위해 선택해야 할 저장 매체는 무엇입니까?",
        "Options": {
            "1": "Amazon S3",
            "2": "Amazon Elastic File System (EFS)",
            "3": "Amazon RDS",
            "4": "Amazon Elastic Block Store (EBS)"
        },
        "Correct Answer": "Amazon S3",
        "Explanation": "Amazon S3는 비구조적 데이터를 저장하고 검색하기 위해 설계되어 있으며, 머신 러닝에 사용되는 대규모 데이터 세트에 이상적입니다. 높은 내구성, 확장성 및 접근성을 제공하여 효율적인 모델 훈련에 필수적입니다.",
        "Other Options": [
            "Amazon Elastic Block Store (EBS)는 주로 EC2 인스턴스와 관련된 블록 저장소에 사용되며, 비구조적 데이터의 대규모 데이터 세트에 최적화되어 있지 않아 이 시나리오에서의 효과가 제한됩니다.",
            "Amazon Elastic File System (EFS)는 파일 저장소를 제공하지만 일반적으로 더 작은 데이터 세트나 공유 액세스가 필요한 애플리케이션에 더 적합합니다. S3에 비해 대규모 비구조적 데이터 세트에 대해 동일한 수준의 확장성과 비용 효율성을 제공하지 않을 수 있습니다.",
            "Amazon RDS는 관계형 데이터베이스 서비스로, 비구조적 데이터에 적합하지 않으며, 대규모 데이터 세트에 초점을 맞춘 머신 러닝 작업에 덜 최적화되어 있으며, 특히 확장성과 접근 용이성이 요구되는 경우에는 더욱 그렇습니다."
        ]
    },
    {
        "Question Number": "4",
        "Situation": "데이터 과학 팀은 머신 러닝 모델을 위한 고품질 훈련 데이터셋을 만드는 임무를 맡았습니다. 그들은 라벨이 없는 이미지의 대량 컬렉션을 보유하고 있으며, 정확한 주석을 보장하면서 비용을 최소화하고자 합니다. 이 과정에 Amazon SageMaker Ground Truth를 사용하기로 결정했습니다.",
        "Question": "데이터 과학 팀이 Amazon SageMaker Ground Truth를 사용하여 이미지를 효율적으로 라벨링하기 위해 어떤 접근 방식을 취해야 합니까?",
        "Options": {
            "1": "미리 정의된 지침에 따라 이미지를 라벨링하기 위해 내부 팀을 활용합니다.",
            "2": "명확한 지침과 함께 Mechanical Turk와 사설 팀의 조합을 사용하여 이미지를 라벨링합니다.",
            "3": "인간 검증 없이 자동 라벨링 방법만 사용합니다.",
            "4": "가이드라인 없이 모든 라벨링 작업을 제3자 공급업체에 아웃소싱합니다."
        },
        "Correct Answer": "명확한 지침과 함께 Mechanical Turk와 사설 팀의 조합을 사용하여 이미지를 라벨링합니다.",
        "Explanation": "Mechanical Turk와 사설 팀을 함께 사용하면 라벨링의 확장성과 유연성을 확보할 수 있습니다. 명확한 지침은 라벨러가 요구 사항을 이해하도록 하여 데이터셋의 정확성과 일관성을 높이는 데 기여할 수 있습니다.",
        "Other Options": [
            "내부 팀을 활용하는 것은 효과적일 수 있지만, 확장성을 제한할 수 있습니다. Mechanical Turk와의 조합은 라벨링 작업에서 품질과 양을 모두 제공합니다.",
            "자동 라벨링 방법만 의존하면 모델이 이미지를 올바르게 라벨링하도록 훈련되지 않은 경우 정확도가 낮아질 수 있습니다. 품질을 위한 인간의 감독이 필수적입니다.",
            "가이드라인 없이 모든 작업을 제3자 공급업체에 아웃소싱하면 일관되지 않은 라벨링 결과를 초래할 수 있으며, 특정 프로젝트 요구 사항과 일치하지 않을 수 있어 데이터셋 품질이 저하될 수 있습니다."
        ]
    },
    {
        "Question Number": "5",
        "Situation": "데이터 과학자는 역사적 데이터를 기반으로 주식 가격을 예측하는 모델을 구축하는 임무를 맡았습니다. 데이터의 시간적 의존성을 효과적으로 포착하기 위해 순환 신경망(Recurrent Neural Networks, RNN)을 사용하는 것을 고려하고 있습니다. 과학자는 LSTM(Long Short-Term Memory) 및 GRU(Gated Recurrent Units)와 같은 RNN 내의 다양한 아키텍처에 대해 읽었으며, 어떤 아키텍처가 자신의 필요에 가장 적합할지 평가하고 있습니다.",
        "Question": "다음 중 주식 가격 예측 작업에서 LSTM을 GRU보다 사용하는 장점을 가장 잘 설명하는 진술은 무엇입니까?",
        "Options": {
            "1": "LSTM은 GRU보다 장기 의존성을 더 효과적으로 학습할 수 있어 복잡한 시간적 관계에 적합합니다.",
            "2": "LSTM은 GRU보다 훈련 데이터가 적게 필요하고 구현이 더 간단합니다.",
            "3": "LSTM은 메모리 셀을 사용하지 않아 GRU에 비해 아키텍처가 단순합니다.",
            "4": "LSTM은 GRU에 비해 계산 비용이 적고 따라서 훈련 속도가 더 빠릅니다."
        },
        "Correct Answer": "LSTM은 GRU보다 장기 의존성을 더 효과적으로 학습할 수 있어 복잡한 시간적 관계에 적합합니다.",
        "Explanation": "LSTM은 정보를 오랜 기간 기억하도록 설계되어 있으며, 이는 복잡한 시퀀스나 시간적 의존성을 이해해야 하는 작업에 필수적입니다. 이러한 능력은 역사적 맥락이 중요한 주식 가격 예측과 같은 작업에 더 적합하게 만듭니다.",
        "Other Options": [
            "이 옵션은 LSTM이 일반적으로 GRU보다 더 복잡하고 더 많은 훈련 데이터가 필요하기 때문에 잘못되었습니다. GRU는 더 간단하고 빠르게 구현할 수 있습니다.",
            "이 옵션은 LSTM이 실제로 GRU보다 계산 비용이 더 많이 드는 복잡성과 추가 매개변수로 인해 잘못되었습니다.",
            "이 옵션은 LSTM이 메모리 셀을 아키텍처의 기본 요소로 사용하여 더 긴 시퀀스에서 정보를 유지하는 데 도움을 주기 때문에 잘못되었습니다."
        ]
    },
    {
        "Question Number": "6",
        "Situation": "머신 러닝 엔지니어는 몇 개월에 걸쳐 수집된 데이터셋을 사용하여 예측 모델을 구축할 준비를 하고 있습니다. 데이터셋은 시간 순서대로 정렬되어 있으며, 엔지니어는 이 정렬로 인해 발생할 수 있는 잠재적 편향에 대해 우려하고 있습니다. 모델이 잘 일반화되고 시간적 패턴을 학습하지 않도록 하기 위해, 엔지니어는 강력한 데이터 준비 전략을 수립해야 합니다.",
        "Question": "모델의 효과적인 훈련 및 검증을 보장하기 위해 엔지니어가 취해야 할 조치의 조합은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "각 데이터셋 분할에서 클래스 비율을 유지하기 위해 층화 샘플링 접근 방식을 사용합니다.",
            "2": "훈련, 검증 및 테스트 세트로 분할하기 전에 전체 데이터셋을 무작위로 섞습니다.",
            "3": "무작위화가 적용되기 전에 검증 데이터를 선택합니다.",
            "4": "수집 중에 도입된 편향을 피하기 위해 전체 데이터셋에서 테스트 데이터를 무작위로 선택합니다.",
            "5": "데이터의 시계열 특성을 유지하기 위해 시간 순서에 따라 데이터를 분할합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "훈련, 검증 및 테스트 세트로 분할하기 전에 전체 데이터셋을 무작위로 섞습니다.",
            "수집 중에 도입된 편향을 피하기 위해 전체 데이터셋에서 테스트 데이터를 무작위로 선택합니다."
        ],
        "Explanation": "데이터셋을 분할하기 전에 무작위로 섞으면 데이터의 순서와 관련된 편향을 방지하여 모델이 의도하지 않은 패턴을 학습하지 않도록 합니다. 전체 데이터셋에서 테스트 데이터를 무작위로 선택하는 것도 테스트 세트의 무작위성과 대표성을 유지하는 데 도움이 되며, 이는 편향 없는 평가에 중요합니다.",
        "Other Options": [
            "층화 샘플링 접근 방식을 사용하는 것은 클래스 비율을 유지하는 데 좋지만, 전체 데이터셋이 먼저 무작위화되지 않으면 데이터의 시간적 정렬로 인한 편향을 해결하지 못합니다.",
            "시간 순서에 따라 데이터를 분할하면 훈련 과정에 시간적 편향이 도입되어 보지 못한 데이터에서 성능이 저하될 수 있습니다.",
            "무작위화가 적용되기 전에 검증 데이터를 선택하면 데이터의 원래 순서에 따라 편향이 발생할 수 있으며, 이는 일반화에 이상적이지 않습니다."
        ]
    },
    {
        "Question Number": "7",
        "Situation": "한 의료 기관이 특정 질병에 대해 높은 위험에 처한 환자를 식별하기 위한 머신 러닝 모델을 개발하고 있습니다. 이들은 모델이 가능한 한 많은 진양성 사례를 탐지하도록 보장하고 싶어하며, 이는 일부 위양성을 초래하더라도 괜찮습니다. 이 기관은 잠재적인 위양성에 대해 후속 조치를 취할 의향이 있습니다.",
        "Question": "기관이 높은 위험 환자의 탐지를 극대화하기 위해 어떤 지표를 우선시해야 할까요?",
        "Options": {
            "1": "두 지표를 동등하게 고려하기 위한 균형 정확도.",
            "2": "모델의 위양성을 최소화하기 위한 높은 특이도.",
            "3": "가능한 한 많은 진양성 사례를 포착하기 위한 높은 민감도.",
            "4": "놓친 사례의 수를 줄이기 위한 위양성 비율."
        },
        "Correct Answer": "가능한 한 많은 진양성 사례를 포착하기 위한 높은 민감도.",
        "Explanation": "이 기관은 가능한 한 많은 진양성 사례를 포착하는 데 중점을 두기 때문에 높은 민감도(재현율)를 우선시해야 합니다. 이는 모든 높은 위험 환자를 식별하는 것이 중요한 의료 환경에서 매우 중요하며, 일부 위양성을 수용하는 것을 의미하더라도 마찬가지입니다.",
        "Other Options": [
            "높은 특이도는 위양성을 줄이는 것을 목표로 하기 때문에 이 시나리오에서 기관의 우선 사항이 아닙니다.",
            "균형 정확도는 진양성을 극대화하는 데 특별히 중점을 두지 않기 때문에 잘못된 선택입니다.",
            "위양성 비율은 실제 양성 사례가 얼마나 놓쳤는지를 측정하는 것이므로, 기관은 진양성 탐지를 극대화하는 데 집중하고 있습니다."
        ]
    },
    {
        "Question Number": "8",
        "Situation": "한 머신 러닝 전문가가 다양한 비즈니스 시나리오를 해결하기 위해 다양한 유형의 확률 분포를 이해하는 예측 모델링 작업을 진행하고 있습니다. 전문가는 주어진 시간 내에 매장에 도착하는 고객 수를 모델링하기 위한 최선의 접근 방식을 결정해야 합니다. 평균 도착 수는 알려져 있습니다.",
        "Question": "전문가는 매장에 도착하는 고객 수를 모델링하기 위해 어떤 확률 분포를 사용해야 할까요?",
        "Options": {
            "1": "두 가지 가능한 결과가 있는 여러 시험을 포함하는 시나리오에 적용되므로 고객 도착 수를 모델링하기 위해 이항 분포를 사용합니다.",
            "2": "단일 시험에서 두 가지 결과에 적합하므로 고객 도착 수를 모델링하기 위해 베르누이 분포를 사용합니다.",
            "3": "연속 데이터에 대해 알려진 평균과 표준 편차가 효과적이므로 고객 도착 수를 모델링하기 위해 정규 분포를 사용합니다.",
            "4": "고정된 시간 간격 내에 발생하는 사건의 수를 모델링하기에 적합하므로 고객 도착 수를 모델링하기 위해 포아송 분포를 사용합니다."
        },
        "Correct Answer": "고정된 시간 간격 내에 발생하는 사건의 수를 모델링하기에 적합하므로 고객 도착 수를 모델링하기 위해 포아송 분포를 사용합니다.",
        "Explanation": "포아송 분포는 평균 발생률이 알려져 있을 때 고정된 시간 또는 공간 내에서 발생하는 사건(이 경우 고객 도착 수)을 모델링하기 위해 특별히 설계되었습니다. 이는 사건의 이산 수를 다루는 이와 같은 시나리오에 이상적입니다.",
        "Other Options": [
            "정규 분포는 연속적이며 문제는 고객 도착 수의 이산 수를 포함하므로 적합하지 않습니다. 데이터가 연속적이고 종 모양의 곡선을 따를 때 적용될 수 있지만, 사건 수를 세는 경우에는 해당되지 않습니다.",
            "이항 분포는 이진 결과가 있는 고정된 수의 시험을 포함하는 시나리오에 사용되므로 적합하지 않습니다. 고객 도착 수는 고정된 수의 시험에 제한되지 않습니다.",
            "베르누이 분포는 두 가지 결과가 있는 단일 시험에 사용되는 이항 분포의 특별한 경우입니다. 우리는 단일 시험이 아니라 여러 도착에 관심이 있으므로 이 시나리오에 적합하지 않습니다."
        ]
    },
    {
        "Question Number": "9",
        "Situation": "한 데이터 엔지니어가 대규모 데이터 세트에 대해 실시간으로 변환 작업을 수행해야 하는 데이터 파이프라인을 설계하는 임무를 맡고 있습니다. 엔지니어는 이를 효율적으로 달성하기 위해 다양한 AWS 서비스를 고려하고 있습니다.",
        "Question": "스트리밍 데이터에 대한 ETL 변환을 수행하기 위해 가장 효과적인 AWS 서비스 조합은 무엇인가요?",
        "Options": {
            "1": "AWS Data Pipeline을 활용하여 데이터 흐름을 조정하고 Amazon DynamoDB를 데이터 저장소로 사용합니다.",
            "2": "데이터 처리를 위한 Spark 작업을 실행하기 위해 Amazon EMR을 배포하고 데이터 처리 이벤트를 트리거하기 위해 AWS Lambda를 사용합니다.",
            "3": "서버리스 ETL을 위해 AWS Glue를 사용하고 실시간 데이터 수집을 위해 Amazon Kinesis Data Streams를 사용합니다.",
            "4": "배치 모드에서 데이터를 처리하기 위해 AWS Batch를 활용하고 중간 결과 저장을 위해 Amazon S3를 사용합니다."
        },
        "Correct Answer": "서버리스 ETL을 위해 AWS Glue를 사용하고 실시간 데이터 수집을 위해 Amazon Kinesis Data Streams를 사용합니다.",
        "Explanation": "AWS Glue는 ETL 작업을 위해 설계되었으며, 데이터 처리 요구에 맞춰 자동으로 확장되는 서버리스 기능을 제공합니다. Amazon Kinesis Data Streams는 실시간 데이터 수집을 가능하게 하여 이 조합이 스트리밍 ETL 변환에 이상적입니다.",
        "Other Options": [
            "AWS Batch는 배치 처리를 최적화하였으며 실시간 변환에는 적합하지 않으므로 스트리밍 데이터 요구에 덜 효과적입니다.",
            "Amazon EMR은 대규모 데이터 세트를 처리할 수 있지만 일반적으로 실시간 시나리오보다는 배치 처리에 사용되며, AWS Lambda는 추가 아키텍처 없이 지속적인 데이터 스트림 처리를 위해 직접 적합하지 않습니다.",
            "AWS Data Pipeline은 주로 데이터 워크플로우를 예약하고 조정하는 데 사용되지만 스트리밍 데이터 애플리케이션에 필수적인 실시간 변환 기능을 제공하지 않으며, DynamoDB는 ETL 변환에 최적화되어 있지 않습니다."
        ]
    },
    {
        "Question Number": "10",
        "Situation": "데이터 과학자가 고객 이탈 예측을 위한 분류 모델 프로젝트에 참여하고 있습니다. 모델 성능을 개선하기 위해 데이터셋을 전처리하고 특성 공학 기법을 적용해야 합니다. 데이터셋에는 범주형 변수, 수치적 특성 및 이상치가 포함된 연속 변수가 포함되어 있습니다.",
        "Question": "범주형 변수를 기계 학습 알고리즘에 적합한 형식으로 변환하기 위해 가장 적합한 특성 공학 기법은 무엇입니까?",
        "Options": {
            "1": "Binning",
            "2": "Standardization",
            "3": "One-hot encoding",
            "4": "Principal Component Analysis"
        },
        "Correct Answer": "One-hot encoding",
        "Explanation": "One-hot encoding은 범주형 변수를 기계 학습 알고리즘이 이해할 수 있는 수치 형식으로 변환하는 가장 좋은 기법입니다. 각 범주에 대해 이진 열을 생성하여 모델이 범주 간의 순서 관계를 추론하지 않고 데이터를 해석할 수 있도록 합니다.",
        "Other Options": [
            "Standardization은 수치적 특성을 평균이 0이고 표준 편차가 1이 되도록 스케일링하는 데 사용되지만, 범주형 변수에는 적용되지 않습니다.",
            "Binning은 연속 변수를 범주형으로 변환하는 데 사용되는 기법으로, 이상치에 도움이 될 수 있지만 범주형 변수를 기계 학습을 위해 인코딩할 필요를 직접적으로 해결하지는 않습니다.",
            "Principal Component Analysis (PCA)는 특성을 새로운 공간으로 변환하는 차원 축소 기법이지만 범주형 변수를 인코딩하는 데 사용되지 않습니다."
        ]
    },
    {
        "Question Number": "11",
        "Situation": "한 금융 서비스 회사가 AWS를 사용하여 사기 탐지를 위한 기계 학습 모델을 배포하고 있습니다. 시스템의 무결성을 유지하기 위해 추론 또는 데이터 처리 중 발생하는 오류가 효과적으로 기록되고 모니터링되도록 해야 합니다.",
        "Question": "AWS에서 ML 애플리케이션을 위한 오류 모니터링 솔루션을 구축하는 가장 좋은 접근 방식은 무엇입니까?",
        "Options": {
            "1": "Amazon S3를 사용하여 로그를 저장하고 수동으로 오류를 검토합니다.",
            "2": "EC2 인스턴스에 사용자 정의 로깅 애플리케이션을 배포하여 오류를 추적합니다.",
            "3": "Amazon CloudWatch를 구현하여 로그를 수집하고 오류 임계값에 대한 알람을 설정합니다.",
            "4": "AWS Lambda를 사용하여 로그를 처리하고 Slack 채널에 알림을 보냅니다."
        },
        "Correct Answer": "Amazon CloudWatch를 구현하여 로그를 수집하고 오류 임계값에 대한 알람을 설정합니다.",
        "Explanation": "Amazon CloudWatch를 사용하는 것은 AWS 환경에서 오류를 모니터링하고 기록하는 가장 효율적인 방법입니다. 이는 메트릭, 로그 및 이벤트를 수집하고 추적하기 위한 완전 관리형 서비스를 제공합니다. 오류 임계값에 따라 알람을 쉽게 설정하여 문제에 신속하게 대응할 수 있습니다.",
        "Other Options": [
            "AWS Lambda를 사용하여 로그를 처리하고 알림을 보내는 것은 오류 처리 전략의 일부가 될 수 있지만, 이 시나리오에 필수적인 CloudWatch의 포괄적인 모니터링 기능이 부족합니다.",
            "EC2 인스턴스에 사용자 정의 로깅 애플리케이션을 배포하는 것은 CloudWatch와 같은 완전 관리형 솔루션을 사용하는 것에 비해 더 많은 관리 및 확장성 고려가 필요합니다.",
            "Amazon S3에 로그를 저장하고 수동으로 검토하는 것은 비효율적이며 기계 학습 애플리케이션에서 오류 탐지에 중요한 실시간 모니터링 기능을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "12",
        "Situation": "데이터 과학자가 여러 개의 결측값과 인스턴스가 매우 적은 클래스가 있는 데이터셋을 다루고 있습니다. 과학자는 기계 학습 모델을 훈련하기 전에 결측 데이터를 처리하고 클래스 불균형 문제를 해결해야 합니다.",
        "Question": "과학자가 결측값과 클래스 불균형을 처리하기 위해 사용할 수 있는 방법은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "도메인 지식을 활용한 합성 데이터 생성",
            "2": "수치적 특성에 대한 평균 대치",
            "3": "분류를 위한 랜덤 포레스트 사용",
            "4": "K 최근접 이웃 대치",
            "5": "결측 데이터가 있는 특성 제거"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "K 최근접 이웃 대치",
            "도메인 지식을 활용한 합성 데이터 생성"
        ],
        "Explanation": "K 최근접 이웃 대치는 데이터 포인트의 유사성을 기반으로 결측값을 채우는 강력한 방법입니다. 합성 데이터 생성은 저조하게 나타나는 클래스를 증대시켜 불균형 데이터셋에서 모델 성능을 개선하는 데 도움이 됩니다.",
        "Other Options": [
            "결측 데이터가 있는 특성을 제거하면 귀중한 정보가 손실될 수 있으며, 구현 전에 신중하게 고려해야 합니다.",
            "분류를 위한 랜덤 포레스트 사용은 결측값이나 클래스 불균형 문제를 직접적으로 해결하지 않으며, 이는 데이터 전처리 방법이 아닌 모델링 기법입니다.",
            "수치적 특성에 대한 평균 대치는 특히 이상치가 있는 경우 편향을 초래할 수 있으며, 데이터의 실제 분포를 반영하지 않을 수 있습니다."
        ]
    },
    {
        "Question Number": "13",
        "Situation": "머신 러닝 엔지니어는 여러 머신 러닝 모델이 실행되는 AWS 환경에 대한 강력한 모니터링 솔루션을 구현하는 임무를 맡았습니다. 엔지니어는 모델 추론 중 발생하는 오류가 신속하게 기록되고 경고되어 운영 효율성을 유지할 수 있도록 하고자 합니다.",
        "Question": "엔지니어가 효과적인 오류 모니터링 솔루션을 구축하기 위해 구현할 수 있는 전략은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "모델 아티팩트를 저장하기 위한 Amazon S3",
            "2": "API 호출 기록을 위한 AWS CloudTrail",
            "3": "애플리케이션 성능 모니터링을 위한 AWS X-Ray",
            "4": "데이터 전처리를 위한 AWS Lambda",
            "5": "오류 알림을 위한 Amazon CloudWatch Alarms"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "오류 알림을 위한 Amazon CloudWatch Alarms",
            "애플리케이션 성능 모니터링을 위한 AWS X-Ray"
        ],
        "Explanation": "Amazon CloudWatch Alarms는 메트릭을 모니터링하고 특정 오류 임계값이 초과될 때 알림을 트리거하도록 구성할 수 있어, 문제에 대한 실시간 경고를 가능하게 합니다. AWS X-Ray는 분산 시스템에서 오류를 추적하는 것을 포함하여 애플리케이션의 성능에 대한 통찰력을 제공하며, 이는 문제를 효과적으로 식별하고 해결하는 데 중요합니다.",
        "Other Options": [
            "AWS CloudTrail은 API 호출을 기록하는 데 주로 사용되며 애플리케이션 오류를 직접 모니터링하지 않기 때문에 실시간 오류 알림에는 적합하지 않습니다.",
            "AWS Lambda는 이벤트에 응답하여 코드를 실행하는 컴퓨팅 서비스이지만, 오류 모니터링을 위해 설계되지 않았습니다.",
            "Amazon S3는 주로 객체 저장소로 사용되며 머신 러닝 모델 추론 중 발생하는 오류에 대한 모니터링 기능을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "14",
        "Situation": "한 조직이 민감한 고객 데이터를 분석하기 위해 AWS에서 머신 러닝 솔루션을 배포하고 있습니다. 조직은 모델과 처리하는 데이터가 안전하고 산업 규정을 준수하도록 하고자 합니다.",
        "Question": "조직이 머신 러닝 솔루션의 보안을 강화하기 위해 구현해야 할 다음 중 어떤 관행이 있습니까?",
        "Options": {
            "1": "데이터 노출을 최소화하기 위해 ML 파이프라인에 관련된 모든 AWS 서비스의 로깅을 비활성화합니다.",
            "2": "개발, 스테이징 및 프로덕션을 포함한 모든 환경에 대해 단일 AWS 계정을 사용합니다.",
            "3": "IAM 역할을 사용하여 SageMaker 리소스에 대한 접근을 제어하고 최소 권한 원칙에 따라 권한을 제한합니다.",
            "4": "모델 아티팩트를 쉽게 공유하기 위해 공개 접근이 가능한 S3 버킷에 저장합니다."
        },
        "Correct Answer": "IAM 역할을 사용하여 SageMaker 리소스에 대한 접근을 제어하고 최소 권한 원칙에 따라 권한을 제한합니다.",
        "Explanation": "AWS 리소스에 대한 접근을 관리하기 위해 IAM 역할을 구현하면 권한이 있는 사용자와 서비스만 머신 러닝 솔루션과 상호작용할 수 있도록 보장합니다. 이는 민감한 데이터와 리소스에 대한 무단 접근의 위험을 최소화하는 최소 권한 원칙을 준수하는 기본적인 보안 관행입니다.",
        "Other Options": [
            "모델 아티팩트를 공개적으로 접근 가능한 S3 버킷에 저장하면 인터넷에 있는 누구나 접근할 수 있어 보안과 기밀성이 손상됩니다.",
            "AWS 서비스의 로깅을 비활성화하면 운영 및 접근 패턴에 대한 가시성이 사라져 잠재적인 보안 사건을 감사하고 모니터링하기 어려워집니다.",
            "모든 환경에 대해 단일 AWS 계정을 사용하면 프로덕션 데이터가 개발 또는 스테이징 환경에 우연히 노출될 위험이 증가하여 환경 격리에 대한 모범 사례를 위반하게 됩니다."
        ]
    },
    {
        "Question Number": "15",
        "Situation": "한 의료 기관이 환자 결과를 예측하기 위한 머신 러닝 모델을 개발하고 있습니다. 이 모델은 기밀을 유지해야 하고 HIPAA와 같은 규정을 준수해야 하는 민감한 환자 데이터를 처리할 것입니다. 기관은 훈련 및 추론 중 이 데이터를 보호할 방법을 고려하고 있습니다.",
        "Question": "기관이 환자 데이터의 기밀성을 유지하면서 모델이 이를 학습할 수 있도록 하기 위해 어떤 접근 방식을 사용해야 합니까?",
        "Options": {
            "1": "데이터 마스킹 기법",
            "2": "민감한 필드의 토큰화",
            "3": "동형 암호화",
            "4": "무작위 응답 기법"
        },
        "Correct Answer": "동형 암호화",
        "Explanation": "동형 암호화는 암호문에서 계산을 수행할 수 있게 하여 모델이 암호화된 데이터에서 학습할 수 있도록 하며, 기밀한 민감한 정보를 노출하지 않습니다. 이는 환자 데이터의 기밀성을 보장하면서도 효과적인 모델 훈련을 가능하게 합니다.",
        "Other Options": [
            "데이터 마스킹 기법은 실제 데이터에 대한 모델 훈련을 허용하지 않으며, 원래 값을 복구할 수 없도록 데이터를 충분히 변경하여 학습 과정을 방해할 수 있습니다.",
            "무작위 응답 기법은 설문 조사에서 개인의 응답을 공개하지 않고 정직한 보고를 보장하기 위해 주로 사용되며, 민감한 데이터로 머신 러닝 모델을 훈련하는 데는 적용되지 않습니다.",
            "민감한 필드의 토큰화는 민감한 데이터를 비민감한 동등물로 대체하지만, 원래 데이터의 맥락이 손실되면 효과적인 모델 훈련이 불가능할 수 있습니다."
        ]
    },
    {
        "Question Number": "16",
        "Situation": "머신 러닝 엔지니어가 고객 이탈을 예측하는 배포된 모델의 성능을 모니터링하고 있습니다. 최근 모델의 정확도가 크게 떨어졌습니다. 엔지니어는 고객 행동의 변화와 외부 요인이 모델의 예측에 영향을 미치고 있다고 의심하고 있습니다.",
        "Question": "성능 저하를 진단하고 완화하기 위해 엔지니어가 취해야 할 가장 효과적인 초기 단계는 무엇입니까?",
        "Options": {
            "1": "더 큰 데이터셋으로 모델을 재훈련합니다.",
            "2": "데이터 드리프트를 분석하고 특성 중요성을 평가합니다.",
            "3": "더 많은 레이어를 추가하여 모델의 복잡성을 증가시킵니다.",
            "4": "추가 분석 없이 새로운 모델 아키텍처를 배포합니다."
        },
        "Correct Answer": "데이터 드리프트를 분석하고 특성 중요성을 평가합니다.",
        "Explanation": "데이터 드리프트를 분석하고 특성 중요성을 평가하면 엔지니어가 입력 데이터가 변경되었는지 또는 특정 특성이 더 이상 예측적이지 않은지를 식별할 수 있습니다. 이 단계는 추가 수정 전에 성능 저하의 근본 원인을 이해하는 데 중요합니다.",
        "Other Options": [
            "더 큰 데이터셋으로 모델을 재훈련하는 것은 데이터 드리프트나 특성 관련성의 근본적인 문제를 해결하지 못할 수 있습니다. 문제를 먼저 진단하지 않고 단순히 데이터를 추가하는 것은 성능 향상으로 이어지지 않을 수 있습니다.",
            "더 많은 레이어를 추가하여 모델의 복잡성을 증가시키는 것은 과적합으로 이어질 수 있으며, 정확도 저하를 초래할 수 있는 입력 데이터의 잠재적 변화에 직접적으로 대응하지 않습니다.",
            "추가 분석 없이 새로운 모델 아키텍처를 배포하는 것은 중요한 진단 단계를 건너뛰어 비효율성을 초래하고 성능 문제를 효과적으로 해결하지 못할 수 있습니다."
        ]
    },
    {
        "Question Number": "17",
        "Situation": "데이터 과학자는 컴퓨터 비전 애플리케이션을 위한 대규모 이미지 데이터를 처리하기 위해 딥 러닝 모델을 구축하는 임무를 맡고 있습니다. 데이터셋이 방대하여 빠른 훈련과 효율적인 처리가 필요합니다. 데이터 과학자는 훈련 시간과 모델 성능을 최적화하기 위해 적절한 컴퓨팅 자원과 플랫폼을 선택해야 합니다.",
        "Question": "데이터 과학자가 효율성을 극대화하기 위해 선택해야 할 컴퓨팅 자원과 플랫폼의 조합은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "분산 훈련을 위한 Spark 클러스터를 구현합니다.",
            "2": "모델 훈련을 위한 단일 노드 설정을 활용합니다.",
            "3": "이미지 처리 작업을 위해 CPU 인스턴스를 사용합니다.",
            "4": "가속 훈련을 위해 GPU 인스턴스를 활용합니다.",
            "5": "병렬 처리를 위해 다중 GPU 설정을 채택합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "가속 훈련을 위해 GPU 인스턴스를 활용합니다.",
            "병렬 처리를 위해 다중 GPU 설정을 채택합니다."
        ],
        "Explanation": "GPU 인스턴스를 사용하면 병렬 처리 능력 덕분에 딥 러닝 모델의 훈련 과정을 크게 가속화할 수 있습니다. 또한, 다중 GPU 설정을 채택하면 작업 부하를 추가로 분산시켜 대규모 데이터셋에서 더욱 빠른 훈련 시간을 제공합니다.",
        "Other Options": [
            "CPU 인스턴스는 가능하지만, 딥 러닝 작업에 대해 GPU 인스턴스만큼의 성능과 속도를 제공하지 않습니다.",
            "Spark 클러스터는 분산 데이터 처리에 더 적합하며, 딥 러닝 모델을 직접 훈련하는 데는 일반적으로 GPU 자원이 필요합니다.",
            "단일 노드 설정은 대규모 이미지 데이터셋에 필요한 훈련 속도와 확장성을 제한할 수 있어, 다중 GPU를 활용하는 것보다 덜 효율적입니다."
        ]
    },
    {
        "Question Number": "18",
        "Situation": "머신 러닝 엔지니어가 다양한 특성을 기반으로 주택 가격을 예측하는 배포된 회귀 모델의 성능을 모니터링하고 있습니다. 배포 한 달 후, 엔지니어는 모델의 정확도가 크게 떨어진 것을 발견했습니다. 모델은 과거 데이터를 기반으로 훈련되었지만, 최근 경제 변화로 인해 주택 시장이 변화했습니다. 엔지니어는 시간이 지남에 따라 모델의 성능을 모니터링하고 유지하기 위한 최선의 접근 방식을 찾고자 합니다.",
        "Question": "모델의 성능을 효과적으로 모니터링하고 유지하기 위해 엔지니어가 구현해야 할 전략은 무엇입니까?",
        "Options": {
            "1": "시장 변화와 관계없이 성능 평가를 위해 고정된 데이터셋을 활용합니다.",
            "2": "최신 데이터를 사용하여 모델의 정기적인 재훈련을 계획합니다.",
            "3": "모니터링을 모델의 예측 정확도에만 제한합니다.",
            "4": "시간이 지나도 변하지 않는 정적 평가 지표를 구현합니다."
        },
        "Correct Answer": "최신 데이터를 사용하여 모델의 정기적인 재훈련을 계획합니다.",
        "Explanation": "최신 데이터로 모델을 정기적으로 재훈련하면 주택 시장의 변화에 적응할 수 있어, 예측이 시간이 지남에 따라 정확하고 관련성을 유지할 수 있습니다.",
        "Other Options": [
            "정적 평가 지표를 구현하는 것은 데이터 분포의 변화를 고려하지 않으며, 잘못된 성능 평가로 이어질 수 있습니다.",
            "모니터링을 모델의 예측 정확도에만 제한하는 것은 정밀도, 재현율, F1 점수와 같은 다른 중요한 지표를 무시하게 되어 모델 성능에 대한 포괄적인 이해를 저해합니다.",
            "성능 평가를 위해 고정된 데이터셋을 활용하는 것은 시장의 현재 상태를 반영하지 않아 모델의 지속적인 관련성과 정확성을 평가하는 데 효과적이지 않습니다."
        ]
    },
    {
        "Question Number": "19",
        "Situation": "데이터 과학자가 Amazon SageMaker를 사용하여 머신 러닝 모델을 구축하고 있습니다. 모델이 견고하고 쉽게 업데이트될 수 있도록 하기 위해, 데이터 과학자는 머신 러닝 구현 및 운영에 대한 AWS 모범 사례를 따르기를 원합니다.",
        "Question": "데이터 과학자가 AWS 모범 사례를 준수하기 위해 어떤 단계의 조합을 취해야 합니까? (두 가지 선택)",
        "Options": {
            "1": "모델 버전을 관리하기 위해 Amazon SageMaker Model Registry를 활용합니다.",
            "2": "비용을 최소화하기 위해 단일 인스턴스를 사용하여 모델을 훈련합니다.",
            "3": "최대 유연성을 위해 Amazon EC2 인스턴스를 사용하여 모델을 배포합니다.",
            "4": "엔드 투 엔드 워크플로우 자동화를 위해 Amazon SageMaker Pipelines를 구현합니다.",
            "5": "모델 성능을 추적하기 위해 Amazon CloudWatch를 사용하여 모니터링을 설정합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "모델 버전을 관리하기 위해 Amazon SageMaker Model Registry를 활용합니다.",
            "엔드 투 엔드 워크플로우 자동화를 위해 Amazon SageMaker Pipelines를 구현합니다."
        ],
        "Explanation": "Amazon SageMaker Model Registry를 활용하면 데이터 과학자가 다양한 모델 버전을 효율적으로 관리할 수 있어 업데이트와 추적이 용이해집니다. Amazon SageMaker Pipelines를 구현하면 전체 머신 러닝 워크플로우를 자동화하는 구조화된 방법을 제공하여 일관성과 재현성을 보장합니다. 이는 머신 러닝 운영의 핵심 모범 사례입니다.",
        "Other Options": [
            "Amazon EC2 인스턴스를 사용하여 모델을 배포하는 것은 유연성을 제공할 수 있지만, 확장성과 관리 측면에서 모범 사례와 일치하지 않습니다. 대신 Amazon SageMaker와 같은 서비스를 통해 배포하는 것이 권장됩니다.",
            "단일 인스턴스를 사용하여 모델을 훈련하면 비용을 최소화할 수 있지만, 더 큰 데이터 세트나 더 복잡한 모델에 필요한 컴퓨팅 자원을 제공하지 못할 수 있어 성능 문제를 초래할 수 있습니다.",
            "Amazon CloudWatch를 사용하여 모니터링을 설정하는 것은 프로덕션 모델에 중요하지만, 모델 자체의 구현 및 운영과 직접적인 관련이 없으므로 모범 사례의 맥락에서 덜 관련된 선택입니다."
        ]
    },
    {
        "Question Number": "20",
        "Situation": "데이터 과학자 팀이 시계열 데이터를 예측하기 위해 딥 러닝 모델을 구축하고 있습니다. 그들은 신경망 훈련 시 사라지는 기울기 문제로 어려움을 겪고 있습니다. 이 문제를 완화하기 위해 다양한 아키텍처 전략을 고려하고 있습니다.",
        "Question": "그들의 신경망에서 사라지는 기울기 문제를 해결하는 데 가장 도움이 되는 접근법은 무엇입니까?",
        "Options": {
            "1": "네트워크의 모든 레이어에 ReLU 활성화 함수를 적용합니다.",
            "2": "시그모이드 활성화 함수를 사용하는 표준 피드포워드 네트워크를 사용합니다.",
            "3": "네트워크를 더 작은 서브 네트워크로 나누고 독립적으로 훈련합니다.",
            "4": "장기 의존성 처리를 개선하기 위해 LSTM 아키텍처를 구현합니다."
        },
        "Correct Answer": "장기 의존성 처리를 개선하기 위해 LSTM 아키텍처를 구현합니다.",
        "Explanation": "Long Short-Term Memory (LSTM) 네트워크는 정보 흐름을 제어하는 게이팅 메커니즘을 사용하여 사라지는 기울기 문제를 해결하도록 특별히 설계되었습니다. 이를 통해 긴 시퀀스에서 정보를 유지할 수 있어 시계열 예측이나 장기 의존성이 중요한 작업에 적합합니다.",
        "Other Options": [
            "시그모이드 활성화 함수를 사용하는 표준 피드포워드 네트워크는 특히 더 깊은 아키텍처에서 사라지는 기울기 문제에 취약합니다. 이는 장기 의존성을 포착해야 하는 복잡한 데이터 세트에서 훈련하는 데 덜 효과적입니다.",
            "네트워크를 더 작은 서브 네트워크로 나누는 것은 훈련을 용이하게 할 수 있지만, 본질적으로 사라지는 기울기 문제를 해결하지는 않습니다. 적절한 아키텍처, 예를 들어 LSTM을 사용하지 않는 한 각 서브 네트워크는 여전히 동일한 문제에 직면할 수 있습니다.",
            "ReLU 활성화 함수를 적용하면 역전파 중 기울기가 더 자유롭게 흐를 수 있도록 하여 사라지는 기울기 문제를 어느 정도 완화할 수 있습니다. 그러나 이는 LSTM만큼 효과적으로 순차 데이터의 장기 의존성과 관련된 문제를 해결하지는 않습니다."
        ]
    },
    {
        "Question Number": "21",
        "Situation": "한 의료 기관이 당뇨병 발병 위험이 있는 환자를 식별하기 위한 예측 모델을 개발하고 있습니다. 모델의 출력은 정확도와 정밀도를 기준으로 평가됩니다. 초기 테스트 후, 개발 팀은 모델이 높은 정확도를 보이는 반면 정밀도가 상대적으로 낮다는 것을 발견했습니다. 이 불일치는 모델이 진짜 양성 사례를 식별하는 신뢰성에 대한 우려를 불러일으킵니다.",
        "Question": "전체 정확도를 희생하지 않고 정밀도를 개선하기 위해 팀이 취해야 할 단계는 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "진짜 양성과 거짓 양성을 구별하는 데 도움이 되는 추가 기능을 통합합니다.",
            "2": "소수 클래스의 오버샘플링을 통해 데이터 세트를 균형 있게 조정하는 데 집중합니다.",
            "3": "정밀도 대신 재현율을 독점적으로 측정하기 위해 평가 지표를 변경합니다.",
            "4": "예측의 양성 컷오프를 높이기 위해 임계값 조정을 구현합니다.",
            "5": "강건성을 보장하고 과적합을 줄이기 위해 교차 검증 기법을 활용합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "예측의 양성 컷오프를 높이기 위해 임계값 조정을 구현합니다.",
            "진짜 양성과 거짓 양성을 구별하는 데 도움이 되는 추가 기능을 통합합니다."
        ],
        "Explanation": "예측 임계값을 조정하면 거짓 양성이 적게 계산되도록 하여 정밀도를 개선할 수 있습니다. 이는 정밀도 계산에 직접적인 영향을 미칩니다. 또한, 모델에 더 관련성 있는 기능을 통합하면 진짜 양성 사례를 올바르게 분류하는 능력이 향상되어 정밀도가 증가할 수 있습니다.",
        "Other Options": [
            "교차 검증은 모델 성능을 평가하고 과적합을 피하는 데 중요하지만, 정밀도를 직접적으로 개선하지는 않습니다. 이는 모델이 다양한 데이터 세트에서 잘 일반화되도록 보장하는 것과 더 관련이 있습니다.",
            "데이터 세트를 균형 있게 조정하면 전체 모델 성능을 개선하는 데 도움이 될 수 있지만, 단순히 소수 클래스를 오버샘플링하는 것만으로는 모델이 여전히 많은 진짜 양성을 거짓 양성으로 잘못 분류한다면 정밀도가 높아지지 않을 수 있습니다.",
            "정밀도 대신 재현율을 측정하기 위해 평가 지표를 변경하는 것은 정밀도를 개선하는 데 도움이 되지 않습니다. 이는 가능한 많은 진짜 양성을 식별하는 데 초점을 맞출 수 있지만, 거짓 양성이 증가하여 정밀도가 더욱 감소할 수 있습니다."
        ]
    },
    {
        "Question Number": "22",
        "Situation": "데이터 과학자가 다중 클래스 분류 문제를 위한 신경망을 구축하고 있습니다. 그들은 네트워크의 출력 레이어가 각 분류에 대한 확률을 제공하면서 한 번에 하나의 레이블만 선택할 수 있도록 하기를 원합니다.",
        "Question": "데이터 과학자가 이 목표를 달성하기 위해 신경망의 출력 레이어에서 어떤 활성화 함수를 사용해야 합니까?",
        "Options": {
            "1": "Sigmoid",
            "2": "ReLU",
            "3": "TanH",
            "4": "Softmax"
        },
        "Correct Answer": "Softmax",
        "Explanation": "Softmax 활성화 함수는 다중 클래스 분류 문제를 위해 특별히 설계되었습니다. 이는 신경망의 원시 출력을 확률 분포로 변환하며, 모든 확률의 합이 1이 됩니다. 이를 통해 가장 가능성이 높은 클래스 레이블을 명확하게 선택할 수 있습니다.",
        "Other Options": [
            "Sigmoid 활성화 함수는 0과 1 사이의 값을 출력하지만, 출력의 합이 1이 되도록 보장하지 않으므로 독점 레이블을 가진 다중 클래스 분류에는 적합하지 않습니다.",
            "ReLU (Rectified Linear Unit) 활성화 함수는 입력이 양수일 경우 입력을 직접 출력하지만, 출력을 확률로 변환하지 않으며 다중 클래스 분류에는 적합하지 않습니다.",
            "TanH 활성화 함수는 -1과 1 사이의 값을 출력하며, 이는 숨겨진 레이어에서 유용할 수 있지만, 다중 클래스 분류 출력을 위해 필요한 확률 분포를 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "23",
        "Situation": "머신 러닝 엔지니어가 구독 서비스의 고객 이탈을 예측하기 위해 트리 기반 모델을 개발하고 있습니다. 엔지니어는 정확성과 계산 효율성을 균형 있게 유지하기 위해 모델의 구성, 특히 트리의 수와 각 트리의 최대 깊이를 결정해야 합니다.",
        "Question": "트리 기반 모델에서 모델 성능과 계산 효율성 간의 좋은 균형을 달성할 가능성이 있는 구성은 무엇입니까?",
        "Options": {
            "1": "정확성을 극대화하기 위해 매우 깊은 트리를 매우 많이 사용합니다.",
            "2": "보지 못한 데이터에 대해 잘 일반화하기 위해 적당한 수의 트리와 적당한 깊이를 사용합니다.",
            "3": "단순성과 해석의 용이성을 위해 적은 수의 깊은 트리를 사용합니다.",
            "4": "과적합 없이 상호작용을 포착하기 위해 많은 수의 얕은 트리를 사용합니다."
        },
        "Correct Answer": "보지 못한 데이터에 대해 잘 일반화하기 위해 적당한 수의 트리와 적당한 깊이를 사용합니다.",
        "Explanation": "적당한 수의 트리와 적당한 깊이를 결합하여 사용하면 모델이 데이터의 복잡한 패턴을 포착하면서 과적합을 피할 수 있어 보지 못한 데이터에 대한 일반화가 향상됩니다.",
        "Other Options": [
            "많은 수의 얕은 트리를 사용하면 데이터의 복잡성을 충분히 포착하지 못할 수 있어 과소적합 및 성능 저하로 이어질 수 있습니다.",
            "적은 수의 깊은 트리를 사용하면 모델을 단순화할 수 있지만, 깊은 트리는 훈련 데이터의 노이즈를 학습할 가능성이 높아 과적합이 발생할 수 있습니다.",
            "매우 많은 수의 매우 깊은 트리를 사용하면 과적합으로 이어져 모델이 새로운 보지 못한 데이터에서 성능이 저하될 수 있습니다."
        ]
    },
    {
        "Question Number": "24",
        "Situation": "데이터 과학자가 Amazon SageMaker에서 머신 러닝 모델 훈련을 위한 데이터셋을 준비하는 임무를 맡았습니다. 데이터셋에는 다양한 객체의 이미지가 포함되어 있지만, 각 객체 클래스의 이미지 수가 불균형합니다. 데이터 과학자는 모델이 효율적으로 학습할 수 있도록 데이터를 효과적으로 전처리해야 합니다.",
        "Question": "데이터 과학자가 데이터셋을 준비하기 위해 어떤 단계의 조합을 취해야 합니까? (두 가지 선택)",
        "Options": {
            "1": "층화 샘플링을 사용하여 데이터셋을 훈련, 검증 및 테스트 세트로 분할합니다.",
            "2": "데이터 증강 기법을 사용하여 추가적인 합성 이미지를 생성합니다.",
            "3": "이미지를 SageMaker 훈련에 적합한 형식으로 변환합니다(예: RecordIO).",
            "4": "객체 클래스에 맞지 않는 이상치 이미지를 제거합니다.",
            "5": "이미지의 픽셀 값에 정규화를 적용합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "데이터 증강 기법을 사용하여 추가적인 합성 이미지를 생성합니다.",
            "층화 샘플링을 사용하여 데이터셋을 훈련, 검증 및 테스트 세트로 분할합니다."
        ],
        "Explanation": "데이터 증강 기법을 사용하여 추가적인 합성 이미지를 생성하면 과소대표된 클래스의 표현을 증가시켜 클래스 불균형 문제를 해결하는 데 도움이 됩니다. 층화 샘플링을 사용하여 데이터셋을 분할하면 각 하위 집합(훈련, 검증, 테스트)이 원래 데이터셋과 동일한 클래스 분포를 유지하게 되어 모델 평가에 중요합니다.",
        "Other Options": [
            "이상치 이미지를 제거하는 것은 유익할 수 있지만, 클래스 불균형 문제를 직접적으로 해결하지 못할 수 있으며, 귀중한 데이터 손실로 이어질 수 있습니다.",
            "이미지를 SageMaker 훈련에 적합한 형식으로 변환하는 것은 중요하지만, 클래스 불균형 문제를 구체적으로 해결하지는 않습니다.",
            "이미지의 픽셀 값에 정규화를 적용하는 것은 훈련에 좋은 관행이지만, 데이터셋의 균형을 맞추거나 다양한 클래스 간의 적절한 분포를 보장하는 데 도움이 되지 않습니다."
        ]
    },
    {
        "Question Number": "25",
        "Situation": "머신 러닝 엔지니어가 Amazon SageMaker를 사용하여 실시간 추천 시스템을 위한 추론 엔드포인트를 배포하고 있습니다. 배포는 낮은 대기 시간을 유지하면서 다양한 트래픽 부하를 효율적으로 처리해야 합니다.",
        "Question": "추론 엔드포인트가 다양한 트래픽 부하를 효율적으로 처리할 수 있도록 보장하기 위한 최선의 접근 방식은 무엇입니까?",
        "Options": {
            "1": "트래픽 패턴에 따라 인스턴스 유형을 수동으로 조정합니다.",
            "2": "요청을 큐에 넣기 위해 배치 처리 접근 방식을 구현합니다.",
            "3": "피크 부하를 처리하기 위해 단일 대형 인스턴스에 모델을 배포합니다.",
            "4": "엔드포인트에 대해 Amazon SageMaker의 자동 스케일링 기능을 사용합니다."
        },
        "Correct Answer": "엔드포인트에 대해 Amazon SageMaker의 자동 스케일링 기능을 사용합니다.",
        "Explanation": "Amazon SageMaker의 자동 스케일링 기능을 사용하면 추론 엔드포인트가 들어오는 트래픽에 따라 인스턴스 수를 동적으로 조정할 수 있어, 다양한 부하에서 효율적인 자원 활용과 낮은 대기 시간을 보장합니다.",
        "Other Options": [
            "단일 대형 인스턴스에 모델을 배포하는 것은 피크 부하를 일시적으로 처리할 수 있지만, 낮은 트래픽 기간 동안 축소할 수 있는 유연성이 부족하여 비용 증가와 비효율적인 자원 사용으로 이어질 수 있습니다.",
            "배치 처리 접근 방식을 구현하면 대기 시간이 발생할 수 있으며, 추천 시스템에 즉각적인 응답이 필요한 실시간 추론 요구 사항에는 적합하지 않습니다.",
            "인스턴스 유형을 수동으로 조정하는 것은 지속적인 모니터링이 필요하며, 변화하는 트래픽 패턴에 대한 응답 지연을 초래할 수 있어 자동 스케일링 솔루션에 비해 효율성이 떨어집니다."
        ]
    },
    {
        "Question Number": "26",
        "Situation": "머신 러닝 전문가가 이진 분류 모델의 성능을 평가하고 혼동 행렬을 검토하고 있습니다. 행렬은 모델이 잘못된 긍정보다 잘못된 부정이 많은 것을 보여줍니다. 전문가는 이 정보를 바탕으로 결정을 내려야 합니다.",
        "Question": "전문가는 혼동 행렬에서 어떤 통찰을 얻을 수 있습니까? (두 가지 선택)",
        "Options": {
            "1": "모델은 높은 정밀도와 낮은 재현율을 가지고 있습니다.",
            "2": "모델이 훈련 데이터를 과소적합할 가능성이 높습니다.",
            "3": "모델의 전체 정확도가 현재 사용 사례에 충분합니다.",
            "4": "모델이 부정 클래스를 예측하는 데 편향되어 있습니다.",
            "5": "모델은 잘못된 부정을 줄이기 위해 조정이 필요할 수 있습니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "모델은 잘못된 부정을 줄이기 위해 조정이 필요할 수 있습니다.",
            "모델이 부정 클래스를 예측하는 데 편향되어 있습니다."
        ],
        "Explanation": "혼동 행렬은 잘못된 부정이 많음을 나타내며, 이는 모델이 긍정 인스턴스를 효과적으로 식별하지 못하고 있음을 시사합니다. 모델의 성능을 개선하기 위해 특히 잘못된 부정을 줄이는 데 있어 모델의 매개변수를 조정하거나 분류 임계값을 조정할 필요가 있을 수 있습니다. 또한, 잘못된 부정이 많다는 것은 모델이 부정 클래스를 예측하는 데 편향되어 있어 긍정 예측을 놓치는 결과를 초래합니다.",
        "Other Options": [
            "잘못된 부정이 많다고 해서 반드시 과소적합을 의미하는 것은 아니며, 모델이 너무 보수적이거나 잘못 보정된 결과일 수도 있습니다.",
            "높은 정밀도와 낮은 재현율은 모델의 편향의 결과이며, 모델이 긍정 예측을 잘할 때 실제 긍정 사례를 많이 놓치고 있다는 것을 나타내며, 이는 높은 잘못된 부정의 시나리오와 모순됩니다.",
            "전체 정확도는 오해의 소지가 있을 수 있으며, 특히 불균형 데이터셋에서 모델의 성능을 완전히 보여주지 않습니다. 많은 잘못된 부정이 있는 높은 정확도는 여전히 사용 사례에 적합하지 않을 수 있습니다."
        ]
    },
    {
        "Question Number": "27",
        "Situation": "소매 회사가 역사적인 고객 상호작용 데이터를 기반으로 고객 이탈을 예측하는 모델을 구축하려고 합니다. 데이터셋에는 거래 이력, 고객 인구 통계 및 고객 서비스 상호작용과 같은 다양한 특성이 포함되어 있습니다. 회사는 모델의 예측에서 높은 정확도와 해석 가능성을 달성하는 것을 목표로 하고 있습니다.",
        "Question": "높은 해석 가능성을 보장하면서 고객 이탈을 예측하는 데 가장 적합한 모델 유형은 무엇입니까?",
        "Options": {
            "1": "딥 뉴럴 네트워크",
            "2": "로지스틱 회귀",
            "3": "서포트 벡터 머신",
            "4": "랜덤 포레스트"
        },
        "Correct Answer": "로지스틱 회귀",
        "Explanation": "로지스틱 회귀는 높은 해석 가능성을 제공하는 간단한 모델로, 고객 이탈과 같은 이진 결과를 예측하는 데 적합합니다. 이해관계자가 예측에 대한 각 특성의 영향을 쉽게 이해할 수 있도록 하여 비즈니스 맥락에서 중요합니다.",
        "Other Options": [
            "딥 뉴럴 네트워크는 높은 정확도를 달성할 수 있는 복잡한 모델이지만 종종 해석 가능성이 부족합니다. 특성의 영향을 이해하는 것이 중요한 경우에는 덜 적합합니다.",
            "랜덤 포레스트는 좋은 정확도를 제공할 수 있지만 로지스틱 회귀만큼 해석 가능하지 않을 수 있습니다. 그들은 '블랙 박스'로 간주될 수 있어 이해관계자에게 예측을 설명하기가 더 어렵습니다.",
            "서포트 벡터 머신은 분류 작업에 효과적일 수 있지만 일반적으로 로지스틱 회귀와 같은 수준의 해석 가능성을 제공하지 않습니다. 그들의 결정 경계는 설명하기 어려울 수 있습니다."
        ]
    },
    {
        "Question Number": "28",
        "Situation": "헬스케어 조직의 머신 러닝 엔지니어가 환자 재입원을 예측하는 모델을 구축하는 임무를 맡았습니다. 그들은 전처리 및 모델 훈련을 위해 역사적인 환자 데이터를 효율적으로 저장해야 합니다. 이 조직은 다양한 출처에서 수집된 상당량의 구조화된 데이터와 비구조화된 데이터를 보유하고 있습니다.",
        "Question": "머신 러닝 목적을 위해 구조화된 데이터와 비구조화된 데이터 모두에 대해 가장 효율적인 접근 및 관리를 제공하는 저장 솔루션은 무엇입니까?",
        "Options": {
            "1": "구조화된 데이터에 대한 OLAP 분석을 위한 Amazon Redshift.",
            "2": "구조화된 데이터의 NoSQL 저장을 위한 Amazon DynamoDB.",
            "3": "SQL 데이터베이스 엔진이 포함된 Amazon RDS.",
            "4": "구조화된 데이터를 쿼리하기 위한 Amazon S3와 Athena."
        },
        "Correct Answer": "구조화된 데이터를 쿼리하기 위한 Amazon S3와 Athena.",
        "Explanation": "Amazon S3는 구조화된 데이터와 비구조화된 데이터를 대량으로 저장하는 데 매우 확장 가능하고 비용 효율적입니다. Athena를 사용하면 S3에서 구조화된 데이터를 직접 유연하게 쿼리할 수 있어 머신 러닝 데이터 준비 및 분석에 이상적입니다.",
        "Other Options": [
            "Amazon RDS는 구조화된 데이터에 한정되어 있으며 대규모 분석보다는 트랜잭션 작업에 더 적합하여 머신 러닝 데이터 저장소에는 덜 효율적입니다.",
            "Amazon DynamoDB는 고속 트랜잭션에서 뛰어난 NoSQL 데이터베이스이지만 복잡한 데이터 세트에 대한 분석 쿼리에 최적화되어 있지 않아 머신 러닝 데이터 저장 요구에 덜 적합합니다.",
            "Amazon Redshift는 OLAP를 위해 설계되었으며 구조화된 데이터를 쿼리하는 데 뛰어나지만 데이터를 변환하고 웨어하우스에 로드해야 하므로 구조화된 데이터와 비구조화된 데이터 관리를 모두 효율적으로 수행하기 어려울 수 있습니다."
        ]
    },
    {
        "Question Number": "29",
        "Situation": "데이터 과학자가 고객 이탈을 예측하는 머신 러닝 모델을 개발하고 이를 AWS 환경에 배포했습니다. 이 모델은 Amazon SageMaker를 사용하여 API 엔드포인트를 통해 노출됩니다. 데이터 과학자는 API가 많은 요청을 효율적으로 처리하고 사용자에게 실시간 예측을 제공할 수 있도록 해야 합니다.",
        "Question": "데이터 과학자가 API 엔드포인트의 확장성과 성능을 최적화하기 위한 최선의 접근 방식은 무엇입니까?",
        "Options": {
            "1": "더 많은 컴퓨팅 리소스를 위해 SageMaker 엔드포인트의 인스턴스 유형을 증가시킵니다.",
            "2": "더 빠른 응답 시간을 위해 Amazon CloudFront를 구성하여 모델 예측을 캐시합니다.",
            "3": "여러 모델을 제공하기 위해 Amazon SageMaker의 다중 모델 엔드포인트 기능을 사용합니다.",
            "4": "요청을 처리하기 위해 AWS Lambda를 구현한 후 SageMaker 엔드포인트로 전송합니다."
        },
        "Correct Answer": "여러 모델을 제공하기 위해 Amazon SageMaker의 다중 모델 엔드포인트 기능을 사용합니다.",
        "Explanation": "Amazon SageMaker의 다중 모델 엔드포인트 기능을 사용하면 여러 모델을 단일 엔드포인트에서 호스팅할 수 있어 리소스 사용을 최적화하고 들어오는 트래픽에 따라 효과적으로 확장됩니다. 이 접근 방식은 비용을 최소화하면서 API가 다양한 예측 요청을 효율적으로 처리할 수 있도록 보장합니다.",
        "Other Options": [
            "요청을 처리하기 위해 AWS Lambda를 구현하면 SageMaker 엔드포인트에 도달하기 전에 추가 단계를 도입하게 되어 지연과 복잡성이 증가할 수 있으며, 응답 시간이 느려질 수 있습니다.",
            "SageMaker 엔드포인트의 인스턴스 유형을 증가시키면 성능이 향상될 수 있지만 여러 모델을 제공하거나 트래픽 급증을 효율적으로 처리하는 확장성 문제를 해결하지는 않습니다.",
            "Amazon CloudFront를 캐싱을 위해 구성하는 것은 정적 데이터의 성능 향상에 도움이 될 수 있지만, 모델 예측은 입력 데이터에 따라 크게 달라질 수 있어 동적 API 응답에 대한 캐싱 효과가 떨어질 수 있습니다."
        ]
    },
    {
        "Question Number": "30",
        "Situation": "머신 러닝 엔지니어가 스트리밍 데이터 이벤트를 처리하기 위한 실시간 데이터 수집 파이프라인을 생성하는 임무를 맡았습니다. 이 데이터는 예측 모델 훈련에 사용될 것입니다. 솔루션은 수집된 데이터의 내구성을 유지하면서 낮은 지연 시간과 확장성을 보장해야 합니다.",
        "Question": "엔지니어가 어떤 AWS 서비스 조합을 사용해야 합니까? (두 개 선택)",
        "Options": {
            "1": "Amazon Kinesis Data Firehose를 사용하여 스트리밍 데이터를 캡처하고 변환한 후 Amazon S3에 전달합니다.",
            "2": "Amazon Kinesis Data Firehose를 사용하여 데이터를 Amazon Redshift로 직접 스트리밍하여 실시간 분석을 수행합니다.",
            "3": "AWS Lambda를 사용하여 데이터를 처리한 후 Amazon RDS에 저장하여 추가 분석을 수행합니다.",
            "4": "Amazon Kinesis Data Streams를 사용하여 스트리밍 데이터를 수집하고 Firehose를 구성하여 데이터 레이크에 전달합니다.",
            "5": "원시 데이터를 Amazon S3에 저장하고 나중에 AWS Glue를 사용하여 배치 처리를 수행합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon Kinesis Data Firehose를 사용하여 스트리밍 데이터를 캡처하고 변환한 후 Amazon S3에 전달합니다.",
            "Amazon Kinesis Data Streams를 사용하여 스트리밍 데이터를 수집하고 Firehose를 구성하여 데이터 레이크에 전달합니다."
        ],
        "Explanation": "Amazon Kinesis Data Firehose는 스트리밍 데이터를 캡처하고 변환하는 데 최적화되어 있어 실시간 수집에 이상적입니다. 이를 Amazon Kinesis Data Streams와 함께 사용하면 스트리밍 데이터를 저장 솔루션인 Amazon S3에 전달하기 전에 확장 가능하고 내구성 있는 처리가 가능하여 낮은 지연 시간과 높은 처리량을 보장합니다.",
        "Other Options": [
            "AWS Lambda를 사용하여 데이터를 처리하고 Amazon RDS에 저장하는 것은 실시간 수집에 적합하지 않으며 지연을 초래할 수 있고 RDS는 대량의 데이터 스트림을 효율적으로 처리하는 데 최적화되어 있지 않습니다.",
            "원시 데이터를 Amazon S3에 저장하고 나중에 AWS Glue를 사용하여 배치 처리를 수행하는 것은 유효한 접근 방식이지만 실시간 데이터 수집 요구를 충족하지 않습니다.",
            "데이터를 Amazon Redshift로 직접 스트리밍하여 분석하는 것은 Kinesis Data Firehose의 중간 처리 기능을 효과적으로 활용하지 않으며 로드하기 전에 필요한 변환 옵션을 제공하지 않을 수 있습니다."
        ]
    },
    {
        "Question Number": "31",
        "Situation": "데이터 엔지니어가 AWS에 머신 러닝 모델을 배포할 준비를 하고 있습니다. 그들은 배포가 AWS 서비스 할당량을 준수하여 런타임 문제를 피할 수 있도록 해야 합니다.",
        "Question": "데이터 엔지니어가 Amazon SageMaker를 사용하여 머신 러닝 모델을 배포할 때 주로 고려해야 할 AWS 서비스 할당량은 무엇입니까?",
        "Options": {
            "1": "생성할 수 있는 IAM 역할의 최대 수",
            "2": "계정당 최대 Amazon S3 버킷 수",
            "3": "동시에 실행할 수 있는 훈련 작업의 최대 수",
            "4": "지역에서 사용할 수 있는 EC2 인스턴스의 최대 수"
        },
        "Correct Answer": "동시에 실행할 수 있는 훈련 작업의 최대 수",
        "Explanation": "Amazon SageMaker를 사용하여 머신 러닝 모델을 배포할 때 훈련 작업과 관련된 서비스 할당량을 이해하는 것이 중요합니다. 이 한도를 초과하면 새로운 훈련 작업을 시작하는 데 실패하거나 배포 과정에서 지연이 발생할 수 있습니다.",
        "Other Options": [
            "Amazon S3 버킷의 최대 수는 SageMaker 모델 배포와 직접적인 관련이 없으며, 이 할당량은 저장소와 관련이 있습니다.",
            "IAM 역할의 최대 수는 모델 배포에 중요한 요소가 아니며, 머신 러닝 서비스의 운영 한도보다는 권한 및 접근 관리와 관련이 있습니다.",
            "지역에서 사용할 수 있는 EC2 인스턴스의 수는 용량 계획에 중요하지만, SageMaker 훈련 작업과 관련하여 동시 훈련 작업에 대한 특정 한도만큼 직접적으로 관련이 없습니다."
        ]
    },
    {
        "Question Number": "32",
        "Situation": "소매 회사가 다양한 제품 카테고리의 판매를 예측하기 위한 예측 모델을 개발하고 있습니다. 데이터 과학 팀은 모델 성능에 영향을 줄 수 있는 여러 하이퍼파라미터를 식별했습니다. 그들은 최상의 결과를 얻기 위해 이러한 하이퍼파라미터를 최적화하고자 합니다.",
        "Question": "팀이 예측 모델의 하이퍼파라미터 최적화를 효과적으로 수행하기 위해 어떤 접근 방식을 사용해야 합니까?",
        "Options": {
            "1": "팀의 직관과 유사한 모델에 대한 이전 경험을 바탕으로 하이퍼파라미터를 수동으로 조정합니다.",
            "2": "무작위 하이퍼파라미터 조합으로 여러 훈련 작업을 병렬로 실행하고, 이후 가장 성능이 좋은 모델을 선택합니다.",
            "3": "하이퍼파라미터의 모든 가능한 조합을 테스트하기 위해 간단한 그리드 검색 방법을 사용합니다. 검색 공간이 크더라도 말입니다.",
            "4": "Amazon SageMaker의 하이퍼파라미터 튜닝 기능을 활용하여 정의된 범위 내에서 최상의 하이퍼파라미터 값을 자동으로 검색합니다."
        },
        "Correct Answer": "Amazon SageMaker의 하이퍼파라미터 튜닝 기능을 활용하여 정의된 범위 내에서 최상의 하이퍼파라미터 값을 자동으로 검색합니다.",
        "Explanation": "Amazon SageMaker의 하이퍼파라미터 튜닝 기능을 사용하면 팀이 자동화된 검색 알고리즘을 활용하여 하이퍼파라미터 공간을 효율적으로 탐색할 수 있으며, 최적의 값을 찾을 가능성을 크게 높이고 시간과 계산 자원을 절약할 수 있습니다.",
        "Other Options": [
            "하이퍼파라미터를 수동으로 조정하면 직관에 크게 의존하게 되어 최적의 결과를 얻지 못할 수 있으며, 더 나은 성능을 낼 수 있는 조합을 간과할 수 있습니다.",
            "무작위 조합으로 여러 훈련 작업을 실행하는 것은 체계적이지 않을 수 있으며, 더 나은 구성을 놓치는 비효율적인 검색으로 이어질 수 있습니다.",
            "대규모 하이퍼파라미터 공간에 대해 그리드 검색을 사용하는 것은 관리할 수 없는 조합 수를 초래할 수 있으며, 최상의 솔루션을 찾을 보장이 없는 상태에서 계산 비용과 시간이 많이 소요될 수 있습니다."
        ]
    },
    {
        "Question Number": "33",
        "Situation": "데이터 과학자가 구독 서비스의 고객 이탈을 예측하기 위한 딥 러닝 모델을 개발하고 있습니다. 모델 아키텍처는 여러 개의 밀집 층으로 구성되어 있으며, 데이터 과학자는 훈련 데이터셋의 크기가 작아 과적합에 대해 우려하고 있습니다. 이를 완화하기 위해 데이터 과학자는 모델을 정규화하는 데 도움이 되는 기술을 사용하려고 합니다.",
        "Question": "데이터 과학자가 과적합을 줄이기 위해 구현해야 할 기술 조합은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "훈련 중 학습률을 증가시킵니다.",
            "2": "은닉층에 드롭아웃 정규화를 적용합니다.",
            "3": "각 밀집 층 후에 배치 정규화를 사용합니다.",
            "4": "데이터 증강을 사용하여 훈련 데이터셋을 증가시킵니다.",
            "5": "검증 손실에 기반하여 조기 중지를 추가합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "은닉층에 드롭아웃 정규화를 적용합니다.",
            "검증 손실에 기반하여 조기 중지를 추가합니다."
        ],
        "Explanation": "드롭아웃 정규화를 적용하면 훈련 중에 신경망의 유닛을 무작위로 드롭하여 모델이 특정 노드에 지나치게 의존하지 않도록 방지하고 과적합을 줄입니다. 조기 중지는 검증 손실을 모니터링하고 모델이 훈련 데이터에 과적합하기 시작할 때 훈련을 중단하여 과적합 없이 최상의 모델 성능을 유지합니다.",
        "Other Options": [
            "학습률을 증가시키면 훈련이 불안정해질 수 있으며, 과적합을 직접적으로 해결하지 않으며, 모델이 잘 수렴하지 않도록 악화시킬 수 있습니다.",
            "배치 정규화는 모델의 수렴을 개선하는 데 도움이 될 수 있으며 약간의 정규화 효과를 가질 수 있지만, 드롭아웃이나 조기 중지와 같은 방식으로 과적합을 직접적으로 목표로 하지는 않습니다.",
            "데이터 증강은 이미지 데이터에 유용하며 훈련 세트의 다양성을 증가시킬 수 있지만, 모델 자체에 적용되는 직접적인 정규화 기술은 아닙니다."
        ]
    },
    {
        "Question Number": "34",
        "Situation": "데이터 과학자는 고객 구매 데이터를 분석하여 향후 마케팅 전략에 도움이 될 수 있는 트렌드와 패턴을 식별하는 임무를 맡고 있습니다. 목표는 데이터를 효과적으로 시각화하여 이해관계자에게 결과를 전달하는 것입니다.",
        "Question": "고객 구매 데이터에서 시간에 따른 트렌드를 식별하는 데 가장 효과적인 시각화 기법은 무엇입니까?",
        "Options": {
            "1": "상자 그림",
            "2": "선 그래프",
            "3": "히트맵",
            "4": "산점도"
        },
        "Correct Answer": "선 그래프",
        "Explanation": "선 그래프는 시간에 따른 트렌드를 식별하는 데 가장 효과적인 시각화 방법으로, 데이터 포인트를 시계열 형식으로 표시하여 시청자가 시간에 따른 상승 또는 하강 트렌드를 쉽게 관찰할 수 있게 합니다.",
        "Other Options": [
            "상자 그림은 데이터 세트의 분포를 요약하는 데 주로 사용되며, 중앙값, 사분위수 및 잠재적 이상치를 강조하지만, 시간에 따른 트렌드를 효과적으로 전달하지는 않습니다.",
            "히트맵은 다양한 색상을 통해 데이터를 시각화하며 데이터 밀도의 패턴을 식별하는 데 유용하지만, 시간에 따른 트렌드를 간단하게 보여주기에는 적합하지 않습니다.",
            "산점도는 두 변수 간의 관계를 보여줄 수 있지만, 데이터 포인트를 순서대로 연결하지 않기 때문에 시간에 따른 트렌드를 효과적으로 나타내도록 설계되지 않았습니다."
        ]
    },
    {
        "Question Number": "35",
        "Situation": "머신 러닝 엔지니어는 데이터 세트가 상당히 불균형한 이진 분류 문제를 다루고 있으며, 긍정 클래스에 속하는 인스턴스는 10%에 불과합니다. 엔지니어는 다수 클래스의 단순 무작위 언더샘플링을 시도했지만 모델 성능이 저하되는 것을 발견했습니다. 그들은 소수 클래스를 정확하게 예측할 수 있는 모델의 능력을 향상시키기 위한 대체 방법을 고려하고 있습니다.",
        "Question": "엔지니어가 데이터 세트의 클래스 불균형을 효과적으로 해결하기 위해 고려해야 할 기법은 무엇입니까?",
        "Options": {
            "1": "다수 클래스의 잘못 분류에 대한 패널티를 부여하는 비용 민감 학습 적용",
            "2": "다수 클래스에 유리하도록 분류 임계값 변경",
            "3": "더 많은 다수 클래스 인스턴스를 추가하여 훈련 데이터 세트 크기 증가",
            "4": "SMOTE를 사용하여 소수 클래스의 합성 샘플 생성"
        },
        "Correct Answer": "SMOTE를 사용하여 소수 클래스의 합성 샘플 생성",
        "Explanation": "SMOTE(합성 소수 클래스 오버샘플링 기법)를 사용하면 K-최근접 이웃 알고리즘을 활용하여 소수 클래스의 합성 샘플을 생성하는 데 도움이 됩니다. 이는 모델이 소수 클래스에서 학습할 수 있는 능력을 향상시켜 클래스 불균형 상황에서 분류 성능을 개선할 수 있습니다.",
        "Other Options": [
            "비용 민감 학습을 적용하는 것은 유익하지만, 소수 클래스에 대한 더 많은 훈련 예제를 제공하여 데이터 불균형을 직접적으로 해결하지 않기 때문에 단독으로는 효과적이지 않을 수 있습니다.",
            "더 많은 다수 클래스 인스턴스를 추가하여 훈련 데이터 세트의 크기를 증가시키는 것은 불균형 문제를 악화시켜 모델이 소수 클래스의 특성을 효과적으로 학습하기 어렵게 만듭니다.",
            "다수 클래스에 유리하도록 분류 임계값을 변경하면 소수 클래스에 대한 잘못된 부정이 증가하여 불균형 문제를 악화시키고 실제로 모델 성능을 개선하지 않습니다."
        ]
    },
    {
        "Question Number": "36",
        "Situation": "소매 회사는 제품의 미래 수요를 예측하기 위해 판매 데이터를 분석하고 있습니다. 그들은 머신 러닝 모델을 개발할지 아니면 전통적인 통계 방법을 사용할지 고려하고 있습니다. 회사는 제한된 양의 역사적 판매 데이터를 보유하고 있으며 데이터는 그리 복잡하지 않습니다.",
        "Question": "이 상황에서 수요 예측을 위해 가장 효과적인 접근 방식은 무엇입니까?",
        "Options": {
            "1": "데이터의 복잡한 패턴을 포착하기 위해 머신 러닝 방법 사용.",
            "2": "더 나은 정확성을 위해 머신 러닝과 전통적인 방법을 결합.",
            "3": "데이터 분석을 무시하고 직감에 의존하여 예측.",
            "4": "시계열 분석과 같은 전통적인 통계 방법 사용."
        },
        "Correct Answer": "시계열 분석과 같은 전통적인 통계 방법 사용.",
        "Explanation": "전통적인 통계 방법, 특히 시계열 분석은 데이터 세트가 작고 복잡하지 않을 때 더 적합한 경우가 많습니다. 이러한 방법은 머신 러닝 방법에서 발생할 수 있는 과적합의 위험 없이 데이터의 패턴을 효과적으로 모델링할 수 있습니다.",
        "Other Options": [
            "데이터 양이 제한적이기 때문에 머신 러닝 방법은 적합하지 않을 수 있으며, 이는 과적합과 보지 못한 데이터에 대한 일반화 부족으로 이어질 수 있습니다.",
            "두 가지 방법을 결합하는 것이 매력적으로 보일 수 있지만, 머신 러닝 모델을 지원할 충분한 데이터가 없으면 예측 과정을 복잡하게 만들 수 있습니다.",
            "직감에 의존하는 것은 데이터 분석의 가치를 완전히 무시하는 것으로, 이는 부정확한 예측과 재고 및 수익의 잠재적 손실로 이어질 수 있습니다."
        ]
    },
    {
        "Question Number": "37",
        "Situation": "한 회사가 Amazon Lex를 사용하여 고객 지원 시스템을 위한 대화형 인터페이스를 개발하고 있습니다. 그들은 봇이 주문 상태, 제품 가용성 및 지원 티켓 생성에 대한 문의를 포함하여 다양한 사용자 의도를 처리할 수 있도록 하고 싶어합니다. ML 전문가는 비용을 최소화하면서 응답 생성의 정확성을 극대화하는 방식으로 솔루션을 구현해야 합니다.",
        "Question": "ML 전문가는 Amazon Lex 봇의 성능을 최적화하기 위해 어떤 접근 방식을 취해야 합니까?",
        "Options": {
            "1": "의도 인식을 위해 타사 자연어 처리 서비스를 활용합니다.",
            "2": "모든 가능한 사용자 쿼리를 포괄하기 위해 많은 샘플 발화를 포함한 단일 의도를 생성합니다.",
            "3": "Amazon Lex의 내장 응답 생성을 사용하는 대신 Amazon Polly를 구현하여 응답을 생성합니다.",
            "4": "Amazon Lex의 내장 슬롯 유형을 사용하고 특정 쿼리에 대한 사용자 정의 의도를 정의합니다."
        },
        "Correct Answer": "Amazon Lex의 내장 슬롯 유형을 사용하고 특정 쿼리에 대한 사용자 정의 의도를 정의합니다.",
        "Explanation": "Amazon Lex의 내장 슬롯 유형을 사용하고 사용자 정의 의도를 정의하면 봇이 사용자 쿼리를 더 잘 이해하고 정확하게 응답할 수 있습니다. 이 접근 방식은 Amazon Lex의 기능을 활용하여 다양한 사용자 의도를 효과적으로 처리하면서 비용 효율적인 솔루션을 유지합니다.",
        "Other Options": [
            "많은 샘플 발화를 포함한 단일 의도를 생성하면 모델이 서로 다른 쿼리를 구별하는 데 어려움을 겪을 수 있어 혼란과 정확도 감소로 이어져 사용자 경험이 저하될 수 있습니다.",
            "의도 인식을 위해 타사 자연어 처리 서비스를 활용하면 불필요한 복잡성과 잠재적인 비용이 추가되며, Amazon Lex는 의도 감지를 위한 강력한 내장 기능을 제공합니다.",
            "응답 생성을 위해 Amazon Polly를 구현할 필요는 없습니다. Amazon Lex는 이미 음성 및 채팅 인터페이스와의 통합을 위해 최적화된 내장 응답 생성 기능을 포함하고 있습니다."
        ]
    },
    {
        "Question Number": "38",
        "Situation": "한 금융 기관이 역사적 데이터를 기반으로 대출 신청이 승인될지 거부될지를 예측하기 위한 이진 분류 모델을 개발하고 있습니다. 데이터에는 소득, 신용 점수 및 부채 대비 소득 비율과 같은 다양한 특성이 포함됩니다. 모델을 훈련한 후, 전문가는 배포 전에 비즈니스 요구 사항을 충족하는지 확인하기 위해 성능을 평가하고자 합니다.",
        "Question": "전문가는 특히 잘못된 부정의 결과를 고려할 때 대출 승인을 올바르게 예측하는 모델의 능력을 평가하기 위해 어떤 지표를 우선시해야 합니까?",
        "Options": {
            "1": "곡선 아래 면적 (AUC)",
            "2": "정밀도",
            "3": "F1 점수",
            "4": "재현율"
        },
        "Correct Answer": "재현율",
        "Explanation": "재현율은 이 시나리오에서 가장 중요한 지표입니다. 이는 모델이 모든 관련 인스턴스, 특히 승인된 대출을 식별하는 능력을 측정합니다. 잘못된 부정(나쁜 대출 승인)은 심각한 결과를 초래할 수 있으므로, 재현율을 극대화하면 가능한 한 많은 실제 승인을 올바르게 식별할 수 있습니다.",
        "Other Options": [
            "F1 점수는 정밀도와 재현율의 균형을 맞추지만 잘못된 부정을 줄이는 것을 특별히 우선시하지 않으므로 잘못된 부정이 특히 비용이 많이 드는 경우에는 덜 적합합니다.",
            "정밀도는 긍정적인 예측의 정확성에 초점을 맞추지만 모든 관련 긍정적 인스턴스를 고려하지 않으므로 승인 누락이 치명적일 수 있는 이 맥락에서는 중요합니다.",
            "곡선 아래 면적 (AUC)은 진짜 긍정과 잘못된 긍정 비율 간의 균형을 이해하는 데 유용하지만, 대출 승인을 위한 잘못된 부정을 최소화하는 것의 중요성을 직접적으로 다루지 않습니다."
        ]
    },
    {
        "Question Number": "39",
        "Situation": "한 머신러닝 엔지니어가 다양한 환경에서 일관성을 보장하기 위해 Docker 컨테이너를 사용하여 예측 모델을 배포하는 임무를 맡고 있습니다. 엔지니어는 AWS 내에서 이러한 컨테이너를 생성하고 관리하기 위한 올바른 방법을 선택해야 합니다.",
        "Question": "엔지니어가 머신러닝 모델을 배포하기 위해 Docker 컨테이너를 생성하는 데 사용할 수 있는 방법은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "AWS Batch",
            "2": "Amazon Lightsail",
            "3": "AWS Elastic Beanstalk",
            "4": "AWS Lambda",
            "5": "Amazon ECS"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "AWS Elastic Beanstalk",
            "Amazon ECS"
        ],
        "Explanation": "AWS Elastic Beanstalk와 Amazon ECS는 모두 Docker 컨테이너를 원활하게 생성하고 관리할 수 있는 서비스를 제공합니다. Elastic Beanstalk는 Docker 컨테이너로 패키징된 웹 애플리케이션을 배포하는 것을 지원하며, Amazon ECS는 Docker 컨테이너를 대규모로 실행하고 관리할 수 있는 완전 관리형 컨테이너 오케스트레이션 서비스입니다.",
        "Other Options": [
            "AWS Lambda는 Docker 컨테이너를 직접 생성하고 관리하는 방법을 제공하지 않는 서버리스 컴퓨팅 서비스입니다. 컨테이너화된 애플리케이션을 실행할 수 있지만 Elastic Beanstalk나 ECS와 같은 컨테이너 관리에 주로 설계되지 않았습니다.",
            "Amazon Lightsail은 소규모 프로젝트를 위한 클라우드 사용을 단순화하는 데 주로 초점을 맞추고 있으며, 복잡한 컨테이너 관리를 위해서는 다른 옵션에 비해 덜 적합합니다.",
            "AWS Batch는 배치 컴퓨팅 작업을 실행할 수 있는 서비스이지만 Elastic Beanstalk나 ECS와 같은 애플리케이션 배포를 위한 Docker 컨테이너의 생성 및 관리를 직접 지원하지 않습니다."
        ]
    },
    {
        "Question Number": "40",
        "Situation": "소매 회사의 데이터 분석가는 다양한 지역의 판매 데이터를 시각화하기 위해 대화형 대시보드와 보고서를 만들어야 합니다. 분석가는 최종 사용자가 Amazon QuickSight를 사용하여 분석 및 시각화를 수행하는 동안 특정 데이터에 안전하게 접근할 수 있도록 하고자 합니다.",
        "Question": "분석가는 최종 사용자가 Amazon QuickSight에서 목표 데이터에 안전하게 접근할 수 있도록 어떤 인증 방법을 구현해야 합니까?",
        "Options": {
            "1": "SAML 또는 OIDC를 통한 연합 인증",
            "2": "사용자 인증을 위한 Amazon Cognito",
            "3": "사용자 세션 관리를 위한 AWS Lambda",
            "4": "사용자 접근 제어를 위한 IAM 역할"
        },
        "Correct Answer": "SAML 또는 OIDC를 통한 연합 인증",
        "Explanation": "SAML 또는 OIDC를 통한 연합 인증은 분석가가 외부 신원 공급자의 사용자들이 Amazon QuickSight에 안전하게 접근할 수 있도록 할 수 있게 해줍니다. 이 방법은 사용자가 기존 자격 증명으로 로그인할 수 있도록 하며, 그들이 볼 수 있는 데이터에 대한 권한만 부여하여 목표 사용자 접근의 요구에 부합합니다.",
        "Other Options": [
            "Amazon Cognito는 주로 애플리케이션의 사용자 가입, 로그인 및 접근 제어에 사용되지만, 이 시나리오에서 필요한 연합 접근 기능을 제공하지 않습니다.",
            "IAM 역할은 AWS 서비스 내에서 권한에 필수적이지만, 사용자 로그인 프로세스를 촉진하거나 QuickSight에서 외부 사용자 인증을 위한 직접적인 방법을 제공하지 않습니다.",
            "AWS Lambda는 다양한 백엔드 프로세스에 사용할 수 있는 서버리스 컴퓨팅 서비스이지만, 사용자 인증이나 QuickSight 대시보드에 대한 직접 접근을 처리하지 않습니다."
        ]
    },
    {
        "Question Number": "41",
        "Situation": "데이터 엔지니어는 IoT 장치에서 스트리밍 센서 데이터를 수집하는 데이터 수집 파이프라인을 구축하는 임무를 맡고 있습니다. 엔지니어는 데이터가 실시간으로 수집되고 가능한 한 빨리 처리할 수 있도록 해야 합니다. 솔루션은 높은 처리량을 처리하고 수집된 데이터의 내구성을 제공해야 합니다.",
        "Question": "이 시나리오에 대한 데이터 수집 솔루션을 구현하기 위한 최선의 접근 방식은 무엇입니까?",
        "Options": {
            "1": "AWS Snowball을 활용하여 센서 데이터의 배치 수집을 수행합니다.",
            "2": "데이터 수집을 위해 예약된 업로드와 함께 Amazon S3를 구현합니다.",
            "3": "Amazon Kinesis Data Streams를 활용하여 스트리밍 데이터를 캡처하고 처리합니다.",
            "4": "AWS Data Pipeline을 사용하여 데이터 수집 작업을 예약하고 관리합니다."
        },
        "Correct Answer": "Amazon Kinesis Data Streams를 활용하여 스트리밍 데이터를 캡처하고 처리합니다.",
        "Explanation": "Amazon Kinesis Data Streams는 실시간 데이터 수집 및 처리를 위해 특별히 설계되었습니다. 높은 처리량을 처리할 수 있으며 데이터 내구성을 보장하는 기능을 제공하여 IoT 장치에서 스트리밍 센서 데이터를 위한 가장 적합한 솔루션입니다.",
        "Other Options": [
            "AWS Data Pipeline은 주로 배치 처리 및 작업 예약에 사용되므로 실시간 데이터 수집에는 덜 적합합니다.",
            "AWS Snowball은 대규모 데이터 전송을 위한 것이며 스트리밍 데이터에 맞게 설계되지 않았으므로 실시간 수집 요구 사항을 충족하지 않습니다.",
            "예약된 업로드와 함께 Amazon S3는 주기적인 업로드에 의존하므로 실시간 데이터 수집을 효과적으로 지원하지 않습니다."
        ]
    },
    {
        "Question Number": "42",
        "Situation": "머신 러닝 엔지니어는 혼동 행렬을 사용하여 이진 분류 모델의 성능을 평가하고 있습니다. 엔지니어는 모델의 정확성을 향상시키기 위해 혼동 행렬에 제시된 값의 의미를 이해하고자 합니다.",
        "Question": "모델 성능을 평가하기 위해 혼동 행렬에서 파생할 수 있는 지표는 무엇입니까? (두 개 선택)",
        "Options": {
            "1": "평균 제곱 오차",
            "2": "정밀도",
            "3": "F1 점수",
            "4": "재현율",
            "5": "R 제곱"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "정밀도",
            "재현율"
        ],
        "Explanation": "정밀도와 재현율은 모두 혼동 행렬의 값에서 파생된 중요한 지표입니다. 정밀도는 실제 양성 예측의 비율을 총 예측 양성의 수로 측정하여 예측된 양성 사례 중 실제로 양성인 경우가 얼마나 되는지를 나타냅니다. 반면 재현율은 실제 양성의 총 수에 대한 실제 양성 예측의 비율을 측정하여 모델이 양성 사례를 얼마나 잘 식별하는지를 보여줍니다.",
        "Other Options": [
            "평균 제곱 오차는 일반적으로 회귀 분석에 사용되며, 분류에는 관련이 없습니다. 이는 예측 값과 실제 값 간의 평균 제곱 차이를 측정하므로 혼동 행렬 맥락에서 성능 평가에 적합하지 않습니다.",
            "R 제곱은 주로 회귀 작업에 사용되는 또 다른 지표입니다. 이는 종속 변수의 분산 중 독립 변수에 의해 설명될 수 있는 비율을 나타내며, 분류 문제에는 적용되지 않습니다.",
            "F1 점수는 분류와 관련이 있지만 혼동 행렬에서 직접 파생된 것이 아니라 정밀도와 재현율의 조합입니다. 따라서 혼동 행렬에서 파생된 지표로 독립적으로 존재하지 않습니다."
        ]
    },
    {
        "Question Number": "43",
        "Situation": "한 소매 회사가 고객 이탈을 예측하기 위해 머신 러닝 모델을 개발했습니다. 이 모델은 Amazon SageMaker를 사용하여 훈련되고 검증되었습니다. 회사는 이 모델을 실시간 추론을 위해 배포하여 이탈 위험이 있는 고객에게 신속하게 대응하고자 합니다. 또한, Amazon S3에 저장된 역사적 데이터를 기반으로 배치 추론을 수행하여 시간에 따른 트렌드를 분석하고자 합니다.",
        "Question": "Amazon SageMaker를 사용하여 실시간 및 배치 추론 요구 사항을 모두 해결하는 가장 적절한 방법은 무엇입니까?",
        "Options": {
            "1": "실시간 및 배치 처리 요구 사항을 모두 충족하기 위해 Amazon SageMaker Real-Time Inference를 활용하여 배포를 간소화합니다.",
            "2": "실시간 추론을 위해 모델을 Lambda 함수로 배포하고, 배치 처리를 위해 SageMaker Batch Transform을 사용합니다.",
            "3": "실시간 추론을 위해 SageMaker 엔드포인트를 생성하고, S3의 역사적 데이터를 처리하기 위해 배치 변환 작업을 설정합니다.",
            "4": "SageMaker를 사용하여 모델을 훈련한 후, 배치 처리를 위해 AWS Glue를 사용하고 실시간 요청을 위해 별도의 API Gateway를 설정합니다."
        },
        "Correct Answer": "실시간 추론을 위해 SageMaker 엔드포인트를 생성하고, S3의 역사적 데이터를 처리하기 위해 배치 변환 작업을 설정합니다.",
        "Explanation": "SageMaker 엔드포인트를 생성하면 효율적인 실시간 추론이 가능하며, 배치 변환 작업을 설정하면 회사가 S3에 저장된 대규모 데이터 세트를 배치 추론을 위해 처리할 수 있습니다. 이 솔루션은 두 가지 요구 사항을 효과적으로 충족합니다.",
        "Other Options": [
            "모델을 Lambda 함수로 배포하면 콜드 스타트로 인한 지연 문제가 발생할 수 있어 실시간 추론에 적합하지 않습니다. 또한, 배치 처리 측면을 복잡하게 만듭니다.",
            "두 가지 요구 사항에 대해 SageMaker Real-Time Inference를 사용하는 것은 실시간 추론과 배치 처리가 서로 다른 메커니즘을 포함하므로 실현 가능하지 않으며, SageMaker 엔드포인트는 배치 작업을 처리하지 않습니다.",
            "모델을 훈련한 후 AWS Glue를 사용하여 배치 처리를 수행하는 것은 추론을 위해 SageMaker의 기능을 효과적으로 활용하지 못합니다. SageMaker 엔드포인트를 직접 사용할 수 있을 때 실시간 추론을 위해 API Gateway는 필요하지 않습니다."
        ]
    },
    {
        "Question Number": "44",
        "Situation": "한 금융 서비스 회사가 고객의 신용 위험을 예측하기 위해 머신 러닝 모델을 평가하고 있습니다. 회사는 모델이 정확한 예측을 제공할 뿐만 아니라 해석 가능성을 제공하여 이해 관계자가 예측 뒤의 의사 결정 과정을 이해할 수 있도록 하기를 원합니다. 데이터에는 소득, 신용 기록 및 미지급 채무와 같은 다양한 고객 속성이 포함됩니다.",
        "Question": "모델 행동을 이해하고 해석 가능성을 보장하는 목표에 가장 잘 부합하는 접근 방식은 무엇입니까?",
        "Options": {
            "1": "TensorFlow를 사용하여 데이터의 복잡한 패턴을 포착하는 딥 러닝 모델을 사용합니다.",
            "2": "해석 가능성에 집중하지 않고 정확성을 개선하기 위해 XGBoost와 같은 앙상블 모델을 구현합니다.",
            "3": "결정 트리 모델을 활용하여 의사 결정 경로를 명확하게 시각화합니다.",
            "4": "중요한 입력 기능을 우선시하는 주의 메커니즘이 있는 신경망을 활용합니다."
        },
        "Correct Answer": "결정 트리 모델을 활용하여 의사 결정 경로를 명확하게 시각화합니다.",
        "Explanation": "결정 트리 모델은 본질적으로 해석 가능하며, 의사 결정 규칙과 경로를 명확하게 나타내어 이해 관계자가 예측이 어떻게 이루어지는지를 쉽게 이해할 수 있도록 합니다. 이는 신용 위험 예측 시나리오에서 해석 가능성 요구 사항과 완벽하게 일치합니다.",
        "Other Options": [
            "딥 러닝 모델은 강력하지만 일반적으로 더 복잡하고 해석 가능성이 낮아 이해 관계자가 예측 뒤의 이유를 이해하기 어렵습니다.",
            "XGBoost와 같은 앙상블 모델은 예측 성능을 향상시키지만 의사 결정 과정을 모호하게 만들어 해석 가능성을 저해할 수 있습니다.",
            "주의 메커니즘이 있는 신경망은 중요한 기능을 강조하도록 설계되었지만, 여전히 결정 트리와 같은 더 간단한 모델이 제공하는 직관적인 해석 가능성은 부족합니다."
        ]
    },
    {
        "Question Number": "45",
        "Situation": "한 머신 러닝 엔지니어가 상당한 계산 능력을 요구하는 딥 러닝 모델을 구축하는 임무를 맡았습니다. 엔지니어는 AWS에서 모델을 배포하기 위한 다양한 옵션을 고려하고 있습니다.",
        "Question": "모델 훈련 성능을 최적화하기 위해 엔지니어가 선택해야 할 AWS 서비스 및 인스턴스 유형은 무엇입니까?",
        "Options": {
            "1": "CPU 리소스만 있는 EC2 인스턴스를 선택하되, 훈련 프로세스를 확장하기 위해 AWS Lambda를 활용합니다.",
            "2": "머신 러닝 작업에 충분한 리소스를 제공하는 고성능 CPU 기능을 갖춘 EC2 표준 인스턴스를 활용합니다.",
            "3": "가속 컴퓨팅을 지원하는 GPU 인스턴스가 있는 EC2를 사용하고, 인기 있는 ML 라이브러리가 포함된 사전 로드된 AMI를 함께 사용합니다.",
            "4": "ML 라이브러리가 포함되지 않은 사용자 정의 AMI로 표준 EC2 인스턴스에 모델을 배포합니다."
        },
        "Correct Answer": "가속 컴퓨팅을 지원하는 GPU 인스턴스가 있는 EC2를 사용하고, 인기 있는 ML 라이브러리가 포함된 사전 로드된 AMI를 함께 사용합니다.",
        "Explanation": "EC2의 GPU 인스턴스는 딥 러닝 모델 훈련과 같은 계산 집약적인 작업을 위해 특별히 설계되어 훈련 시간을 크게 단축합니다. 머신 러닝 라이브러리가 포함된 사전 로드된 AMI를 사용하면 설정 프로세스가 간소화되고 필요한 도구를 즉시 사용할 수 있습니다.",
        "Other Options": [
            "EC2 표준 인스턴스는 강력하지만 GPU 인스턴스만큼 딥 러닝 작업에 대한 성능 수준을 제공하지 않으므로 요구되는 ML 작업에 덜 적합합니다.",
            "CPU 리소스만 있는 EC2 인스턴스를 사용하는 것은 모델의 훈련 성능과 확장성을 제한하며, AWS Lambda는 장기 실행 훈련 프로세스를 위해 설계되지 않았으므로 이 옵션은 비현실적입니다.",
            "ML 라이브러리가 없는 표준 EC2 인스턴스에 배포하면 필요한 프레임워크를 설치하는 데 상당한 추가 설정 시간과 노력이 필요하여 모델 훈련 프로세스의 비효율성을 초래합니다."
        ]
    },
    {
        "Question Number": "46",
        "Situation": "한 소매 회사가 이미지 인식 기술을 사용하여 제품 분류 시스템을 개선하고자 합니다. 이들은 전이 학습을 활용하여 사전 훈련된 합성곱 신경망(CNN) 모델을 사용하여 제품 이미지를 보다 효율적으로 분류하는 것을 고려하고 있습니다.",
        "Question": "회사가 사전 훈련된 CNN 모델로 전이 학습을 구현하기 위한 가장 효과적인 접근 방식은 무엇입니까?",
        "Options": {
            "1": "제품 이미지로부터 새로운 CNN 모델을 처음부터 훈련시켜 제품의 특정 특징을 완전히 이해하도록 합니다.",
            "2": "사전 훈련된 CNN 모델을 특징 추출기로 사용하고 모든 레이어를 고정한 후, 제품 이미지에서 추출된 특징 위에 새로운 분류기를 훈련시킵니다.",
            "3": "사전 훈련된 CNN 모델을 완전히 제거하고 제품 이미지에서 수동으로 추출한 특징을 사용하여 전통적인 기계 학습 알고리즘을 사용합니다.",
            "4": "라벨이 붙은 제품 이미지를 사용하여 사전 훈련된 CNN 모델의 마지막 몇 개 레이어를 미세 조정하여 특정 분류 작업에 적응시킵니다."
        },
        "Correct Answer": "라벨이 붙은 제품 이미지를 사용하여 사전 훈련된 CNN 모델의 마지막 몇 개 레이어를 미세 조정하여 특정 분류 작업에 적응시킵니다.",
        "Explanation": "사전 훈련된 CNN 모델의 마지막 몇 개 레이어를 미세 조정하면 회사가 기존 지식을 활용하면서 모델을 특정 데이터 세트에 적응시킬 수 있어 정확도가 향상되고 훈련 시간이 단축됩니다.",
        "Other Options": [
            "사전 훈련된 CNN 모델을 특징 추출기로 사용하는 것은 효과적일 수 있지만, 미세 조정이 일반적으로 더 나은 성능을 발휘합니다. 이는 모델이 새로운 작업과 관련된 특정 특징을 학습할 수 있게 해줍니다.",
            "새로운 CNN 모델을 처음부터 훈련시키는 것은 종종 시간이 많이 소요되며 대규모 데이터 세트가 필요하므로, 특히 사전 훈련된 모델이 있는 경우 회사에 실현 가능하지 않을 수 있습니다.",
            "사전 훈련된 CNN 모델을 완전히 제거하고 전통적인 기계 학습 알고리즘을 사용하는 것은 깊은 학습 모델의 강력한 표현 능력을 활용하지 못하게 되어 분류 정확도를 크게 향상시킬 수 있는 기회를 놓치게 됩니다."
        ]
    },
    {
        "Question Number": "47",
        "Situation": "데이터 과학자가 기계 학습 모델을 구축하기 위한 인터랙티브 개발 환경이 필요한 프로젝트를 진행하고 있습니다. 과학자는 쉽게 협업하고, 버전 관리를 하며, 특정 종속성을 충돌 없이 실행할 수 있는 솔루션이 필요합니다.",
        "Question": "사용자가 실시간 코드, 방정식, 시각화 및 서술 텍스트가 포함된 문서를 생성하고 공유할 수 있으며, 종속성을 효과적으로 관리할 수 있는 Jupyter 노트북 경험을 제공하는 Amazon 서비스는 무엇입니까?",
        "Options": {
            "1": "사용자 정의 구성 및 종속성을 위해 수동으로 Jupyter가 설치된 Amazon EC2.",
            "2": "격리된 환경을 갖춘 관리형 Jupyter 노트북을 제공하는 Amazon SageMaker Notebooks.",
            "3": "ETL 워크플로우를 구축하기 위한 시각적 인터페이스를 제공하지만 Jupyter 지원이 없는 AWS Glue Studio.",
            "4": "비즈니스 인텔리전스를 위해 설계되었으며 코딩 환경을 지원하지 않는 Amazon QuickSight."
        },
        "Correct Answer": "격리된 환경을 갖춘 관리형 Jupyter 노트북을 제공하는 Amazon SageMaker Notebooks.",
        "Explanation": "Amazon SageMaker Notebooks는 기계 학습 워크플로우를 위해 특별히 설계되어 있으며, 종속성을 격리할 수 있는 관리형 Jupyter 노트북 인스턴스를 제공하여 협업 프로젝트 및 실험에 이상적입니다.",
        "Other Options": [
            "수동으로 Jupyter가 설치된 Amazon EC2는 상당한 설정 및 유지 관리 노력이 필요하며, SageMaker와 같은 수준의 관리 서비스나 종속성 격리를 제공하지 않습니다.",
            "AWS Glue Studio는 ETL 프로세스에 중점을 두고 있으며 Jupyter와 같은 코딩 환경을 제공하지 않으므로 기계 학습 모델을 직접 구축하는 데 적합하지 않습니다.",
            "Amazon QuickSight는 코딩이나 모델 개발을 촉진하지 않는 비즈니스 인텔리전스 도구로, Jupyter 노트북을 대체할 수 없습니다."
        ]
    },
    {
        "Question Number": "48",
        "Situation": "데이터 과학자가 구독 기반 서비스의 고객 이탈을 예측하기 위한 기계 학습 모델을 개발하는 임무를 맡았습니다. 이 모델은 고객의 사용 패턴과 구독 세부정보를 기반으로 고객을 '위험 있음' 또는 '위험 없음' 카테고리로 분류해야 합니다. 데이터 과학자는 이 작업에 적합한 모델링 기법을 선택해야 합니다.",
        "Question": "데이터 과학자가 고객 이탈을 효과적으로 예측하기 위해 어떤 기계 학습 모델링 접근 방식을 사용해야 합니까?",
        "Options": {
            "1": "회귀",
            "2": "분류",
            "3": "군집화",
            "4": "예측"
        },
        "Correct Answer": "분류",
        "Explanation": "분류는 고객을 '위험 있음' 또는 '위험 없음'이라는 뚜렷한 클래스에 분류하는 것이 목표이므로 고객 이탈을 예측하는 데 가장 적합한 접근 방식입니다. 이는 분류 문제의 정의와 완벽하게 일치합니다.",
        "Other Options": [
            "군집화는 미리 정의된 레이블 없이 유사한 데이터 포인트를 그룹화하는 데 사용되므로 이탈 카테고리를 예측하는 목표와 일치하지 않기 때문에 부적절합니다.",
            "회귀는 연속적인 결과를 예측하는 데 사용되므로 이 경우 적합하지 않으며, 데이터를 이산 카테고리로 분류하는 데 사용되지 않습니다.",
            "예측은 시간 시계열 데이터를 기반으로 미래 값을 예측하는 데 중점을 두므로, 현재 상태에 따라 개인을 분류하는 이 시나리오에는 부적합합니다."
        ]
    },
    {
        "Question Number": "49",
        "Situation": "개발자는 Amazon Lex를 사용하여 고객 지원 챗봇을 위한 대화형 인터페이스를 만드는 임무를 맡고 있습니다. 챗봇은 사용자 요청을 이해하고 인식된 의도에 따라 적절한 응답을 제공해야 합니다.",
        "Question": "Amazon Lex로 챗봇을 구축할 때 의도를 정의하는 주요 목적은 무엇인가요?",
        "Options": {
            "1": "사용자 쿼리와 응답을 저장하기 위한 데이터베이스 제공",
            "2": "사용자 입력을 분류하고 레이블을 붙여 그 의미를 이해하기 위함",
            "3": "사용자 입력에 대한 임의의 응답을 생성하기 위한 프레임워크 역할",
            "4": "대화의 흐름을 관리하고 대화에서 다음 단계를 결정하기 위함"
        },
        "Correct Answer": "사용자 입력을 분류하고 레이블을 붙여 그 의미를 이해하기 위함",
        "Explanation": "Amazon Lex에서 의도를 정의하는 것은 사용자 입력을 분류하고 그 기본 의미를 이해하는 데 필수적이며, 이를 통해 챗봇이 다양한 유형의 요청에 적절하게 응답할 수 있습니다.",
        "Other Options": [
            "대화 흐름을 관리하는 것은 중요하지만, 의도의 주요 역할은 사용자 입력을 분류하고 레이블을 붙이는 것이지 대화 구조를 지시하는 것이 아닙니다.",
            "의도는 데이터베이스 역할을 하지 않으며, 오히려 사용자 입력을 해석하는 데 사용되므로 이 옵션은 관련이 없습니다.",
            "임의의 응답을 생성하는 것은 의도의 목적과 일치하지 않으며, 의도는 사용자 입력을 이해하고 분류하는 데 중점을 두고 있습니다."
        ]
    },
    {
        "Question Number": "50",
        "Situation": "연구팀은 위치, 크기 및 상태와 같은 다양한 특성을 기반으로 주택 가격을 예측하기 위한 딥 러닝 모델을 개발하고 있습니다. 그들은 훈련 과정을 최적화하여 모델이 최고의 성능을 달성하도록 하고 싶어합니다. 특히, 다양한 최적화 기법이 수렴과 모델의 전반적인 성능에 어떤 영향을 미칠 수 있는지 이해하는 데 관심이 있습니다.",
        "Question": "신경망 훈련 중 손실 함수를 최소화하여 더 빠른 수렴을 보장하는 데 일반적으로 사용되는 최적화 기법은 무엇인가요?",
        "Options": {
            "1": "Support Vector Machines (SVM)",
            "2": "Principal Component Analysis (PCA)",
            "3": "K-Means Clustering",
            "4": "Stochastic Gradient Descent (SGD)"
        },
        "Correct Answer": "Stochastic Gradient Descent (SGD)",
        "Explanation": "Stochastic Gradient Descent (SGD)는 신경망 훈련에서 손실 함수를 최소화하기 위해 널리 사용되는 최적화 기법입니다. 이는 손실 함수의 기울기를 기반으로 모델 매개변수를 반복적으로 업데이트하여, 전체 데이터 세트를 사용하는 대신 한 샘플씩 처리함으로써 더 빠른 수렴을 가능하게 합니다.",
        "Other Options": [
            "Support Vector Machines (SVM)은 주로 분류 작업에 사용되는 감독 학습 알고리즘으로, 신경망 훈련에서 손실을 최소화하기 위한 최적화 기법이 아닙니다.",
            "K-Means Clustering은 특성 유사성에 따라 데이터 포인트를 그룹으로 클러스터링하는 비감독 학습 알고리즘으로, 신경망 훈련에서 손실 함수를 최소화하는 것과는 관련이 없습니다.",
            "Principal Component Analysis (PCA)는 데이터 세트의 특성 수를 줄이면서 분산을 보존하는 차원 축소 기법이지만, 모델 훈련을 위한 최적화 방법으로 사용되지 않습니다."
        ]
    },
    {
        "Question Number": "51",
        "Situation": "소매 회사는 고객 구매 행동을 분석하여 타겟 마케팅 캠페인을 만들고 있습니다. 그들은 역사적 판매 데이터에 접근할 수 있으며, 미리 정의된 레이블 없이 구매 패턴에 따라 고객 세그먼트를 식별하고자 합니다.",
        "Question": "이 시나리오에 가장 적합한 기계 학습 접근 방식은 무엇인가요?",
        "Options": {
            "1": "Reinforcement learning",
            "2": "Unsupervised learning",
            "3": "Supervised learning",
            "4": "Semi-supervised learning"
        },
        "Correct Answer": "Unsupervised learning",
        "Explanation": "Unsupervised learning은 미리 정의된 레이블 없이 데이터에서 숨겨진 패턴이나 그룹을 찾는 것이 목표일 때 가장 적합한 접근 방식입니다. 이 경우 회사는 고객의 구매 행동에 따라 고객을 세분화하려고 하므로 비감독 학습 패러다임에 적합합니다.",
        "Other Options": [
            "Supervised learning은 모델을 훈련하기 위해 레이블이 있는 데이터가 필요하므로 잘못된 선택입니다. 여기서는 고객 세그먼트에 대한 미리 정의된 레이블이 없습니다.",
            "Reinforcement learning은 보상을 극대화하기 위해 환경과의 상호작용을 통해 학습하는 데 중점을 두므로 고객 구매 행동 분석 시나리오에 적용되지 않습니다.",
            "Semi-supervised learning은 레이블이 있는 데이터와 레이블이 없는 데이터를 결합하는 것이므로, 이 시나리오는 레이블이 없는 데이터를 분석하는 것과 관련이 있습니다."
        ]
    },
    {
        "Question Number": "52",
        "Situation": "소매 회사는 구매 이력 및 제품 리뷰를 포함한 고객 상호작용의 대규모 데이터 세트를 보유하고 있습니다. 데이터는 CSV 및 이미지와 같은 다양한 형식으로 저장되어 있습니다. 머신 러닝 팀은 추천 시스템 교육을 위해 이 데이터를 전처리해야 합니다. 또한, 덜 자주 구매되는 제품에 대한 충분한 교육 샘플이 확보되도록 하고자 합니다.",
        "Question": "머신 러닝 팀이 데이터를 전처리하고 추천 시스템을 위한 교육 세트를 향상시키기 위해 가장 좋은 접근 방식은 무엇입니까?",
        "Options": {
            "1": "Amazon SageMaker Data Wrangler를 사용하여 CSV 파일을 가져오고, 데이터 정리를 수행하며, 데이터를 시각화합니다. 저조하게 표현된 제품에 대한 합성 샘플을 생성합니다.",
            "2": "Amazon SageMaker Ground Truth를 사용하여 제품 이미지를 레이블링한 후, 레이블이 지정된 데이터를 CSV 파일로 내보내 모델 교육에 사용합니다.",
            "3": "AWS Lambda를 사용하여 이미지를 RecordIO 형식으로 변환한 후, 기존 데이터를 복제하여 덜 자주 구매되는 제품에 대한 추가 샘플을 수동으로 생성합니다.",
            "4": "CSV 데이터를 Amazon SageMaker에 로드하고, 노트북에서 직접 특성 공학을 적용하며, 데이터 세트를 교육, 검증 및 테스트 세트로 분할합니다."
        },
        "Correct Answer": "Amazon SageMaker Data Wrangler를 사용하여 CSV 파일을 가져오고, 데이터 정리를 수행하며, 데이터를 시각화합니다. 저조하게 표현된 제품에 대한 합성 샘플을 생성합니다.",
        "Explanation": "Amazon SageMaker Data Wrangler를 사용하면 팀이 데이터를 효율적으로 가져오고, 정리하고, 시각화할 수 있어 데이터 세트를 이해하고 필요한 전처리 단계를 수행하는 데 중요합니다. 저조하게 표현된 제품에 대한 합성 샘플을 생성하면 데이터 세트를 균형 있게 만들어 모델 성능을 향상시킬 수 있습니다.",
        "Other Options": [
            "이미지를 RecordIO 형식으로 변환하고 데이터를 수동으로 복제하는 것은 효과적인 데이터 정리 및 시각화의 필요성을 해결하지 않습니다. 이 방법은 복제된 샘플의 다양성이 부족하여 과적합으로 이어질 수 있습니다.",
            "Amazon SageMaker에 CSV 데이터를 로드하여 특성 공학을 적용하는 것은 유효한 접근 방식이지만, 데이터 분포를 이해하는 데 도움이 되는 시각화 측면이 부족합니다. 또한, 저조하게 표현된 클래스에 대한 합성 샘플 생성을 다루지 않습니다.",
            "Amazon SageMaker Ground Truth를 사용하여 이미지를 레이블링하는 것은 감독 학습 작업에 유용하지만, 기존 데이터 세트를 전처리하거나 추천 시스템을 위한 합성 샘플로 향상시키는 데 기여하지 않습니다."
        ]
    },
    {
        "Question Number": "53",
        "Situation": "금융 서비스 회사가 대출 기본 예측을 위한 머신 러닝 모델을 배포하고 있습니다. 그들은 주말 및 공휴일과 같은 피크 시간 동안 애플리케이션에 상당한 트래픽이 발생할 것으로 예상하고 있습니다. 애플리케이션이 다운타임 없이 다양한 부하를 처리할 수 있도록 로드 밸런싱 솔루션을 구현해야 합니다. 회사는 이 부하를 효과적으로 관리하기 위해 AWS 내의 옵션을 고려하고 있습니다.",
        "Question": "회사가 머신 러닝 애플리케이션의 로드 밸런싱을 구현하기 위해 어떤 AWS 서비스를 사용해야 합니까?",
        "Options": {
            "1": "Amazon Route 53을 사용하여 상태 검사에 따라 다양한 엔드포인트로 트래픽을 유도합니다.",
            "2": "Amazon Elastic Load Balancing을 사용하여 들어오는 애플리케이션 트래픽을 여러 대상에 분산합니다.",
            "3": "AWS Lambda를 사용하여 전용 로드 밸런서 없이 자동으로 기능을 확장합니다.",
            "4": "Amazon EC2 Auto Scaling을 사용하여 수요에 따라 동적으로 리소스를 조정합니다."
        },
        "Correct Answer": "Amazon Elastic Load Balancing을 사용하여 들어오는 애플리케이션 트래픽을 여러 대상에 분산합니다.",
        "Explanation": "Amazon Elastic Load Balancing은 들어오는 애플리케이션 트래픽을 EC2 인스턴스, 컨테이너 및 IP 주소와 같은 여러 대상으로 분산하도록 특별히 설계되었습니다. 이 서비스는 부하를 균형 있게 하여 높은 가용성과 신뢰성을 보장하는 데 도움이 됩니다.",
        "Other Options": [
            "Amazon EC2 Auto Scaling은 수요에 따라 EC2 인스턴스 수를 동적으로 조정하는 데 중점을 두지만, 자체적으로 로드 밸런싱을 제공하지는 않습니다.",
            "Amazon Route 53은 상태 검사에 따라 트래픽을 라우팅할 수 있는 DNS 서비스이지만, 인스턴스 간의 트래픽 분산을 처리하지는 않습니다.",
            "AWS Lambda는 요청 수에 따라 자동으로 확장되지만, 로드 밸런서가 아니며 전통적인 로드 밸런싱보다는 이벤트 기반 애플리케이션에 적합합니다."
        ]
    },
    {
        "Question Number": "54",
        "Situation": "머신 러닝 전문가가 생산 환경에서 두 가지 추천 알고리즘의 성능을 평가하는 임무를 맡고 있습니다. 전문가는 어떤 알고리즘이 더 나은 사용자 참여를 제공하는지 결정해야 하며, 이를 달성하기 위해 A/B 테스트 전략을 구현하는 것을 고려하고 있습니다.",
        "Question": "두 가지 추천 알고리즘을 평가하기 위한 A/B 테스트를 설정하는 가장 효과적인 방법은 무엇입니까?",
        "Options": {
            "1": "단일 알고리즘을 사용하되, 알고리즘 A와 알고리즘 B를 매일 번갈아 가며 성능 지표를 비교합니다.",
            "2": "사용자를 알고리즘 A 또는 알고리즘 B에 무작위로 할당하고, 고정된 시간 동안 참여 지표를 측정합니다.",
            "3": "모든 사용자에게 두 알고리즘을 동시에 구현하고 평균 참여 지표를 비교합니다.",
            "4": "사용자들 사이에서 추천 알고리즘에 대한 선호도를 조사합니다."
        },
        "Correct Answer": "사용자를 알고리즘 A 또는 알고리즘 B에 무작위로 할당하고, 고정된 시간 동안 참여 지표를 측정합니다.",
        "Explanation": "사용자를 알고리즘 A 또는 B에 무작위로 할당하면 샘플이 편향되지 않으며, 결과가 유사한 조건에서 각 알고리즘의 실제 성능을 반영하도록 보장합니다. 이 방법은 참여 지표의 명확한 비교를 가능하게 하여 A/B 테스트를 위한 가장 효과적인 전략입니다.",
        "Other Options": [
            "모든 사용자에게 두 알고리즘을 동시에 구현하는 것은 혼란 변수를 도입할 수 있으며, 사용자가 두 알고리즘을 모두 경험하게 되어 특정 알고리즘에 대한 참여 지표를 귀속시키기 어렵게 만듭니다.",
            "단일 알고리즘을 사용하되 알고리즘 A와 B를 매일 번갈아 가며 사용하는 것은 공정한 비교를 제공하지 않으며, 외부 요인이 다른 날의 사용자 참여에 영향을 미칠 수 있어 편향된 결과를 초래할 수 있습니다.",
            "사용자들 사이에서 추천 알고리즘에 대한 선호도를 조사하는 것은 정량적 참여 지표를 제공하지 않으며, 알고리즘에 대한 실제 사용자 행동이나 참여를 정확하게 반영하지 않을 수 있습니다."
        ]
    },
    {
        "Question Number": "55",
        "Situation": "기계 학습 엔지니어가 Amazon SageMaker를 사용하여 훈련된 모델을 배포할 준비를 하고 있습니다. 엔지니어는 예측을 제공하기 위해 엔드포인트를 설정해야 하지만, 배포 전에 엔드포인트 구성이 올바르게 정의되어 있는지 확인해야 합니다.",
        "Question": "모델을 위한 엔드포인트를 생성하고 배포하기 위해 엔지니어가 따라야 할 올바른 단계 순서는 무엇입니까?",
        "Options": {
            "1": "모델 정의를 생성하고, IAM 역할을 선택한 다음, 엔드포인트 구성을 생성하고, 엔드포인트를 생성합니다.",
            "2": "IAM 역할을 선택하고, 엔드포인트 구성을 생성한 다음, 모델 정의를 생성하고, 마지막으로 엔드포인트를 생성합니다.",
            "3": "엔드포인트 구성을 생성하고, 모델 정의를 생성한 다음, IAM 역할을 선택하고, 마지막으로 엔드포인트를 생성합니다.",
            "4": "엔드포인트를 생성하고, 모델 정의를 생성한 다음, IAM 역할을 선택하고, 마지막으로 엔드포인트 구성을 생성합니다."
        },
        "Correct Answer": "모델 정의를 생성하고, IAM 역할을 선택한 다음, 엔드포인트 구성을 생성하고, 엔드포인트를 생성합니다.",
        "Explanation": "올바른 단계 순서는 먼저 훈련 이미지와 모델 S3 위치를 포함하는 모델 정의를 생성한 다음, 권한을 위한 적절한 IAM 역할을 선택하는 것입니다. 그 후, 엔지니어는 모델 정의를 가리키는 엔드포인트 구성을 생성하고, 마지막으로 예측을 제공하기 위해 엔드포인트 자체를 생성해야 합니다.",
        "Other Options": [
            "이 옵션은 모델을 정의하기 전에 엔드포인트 구성을 생성하라고 제안하므로 잘못되었습니다. 엔드포인트 구성은 참조할 모델 정의가 필요합니다.",
            "이 옵션은 엔드포인트 구성을 모델 정의 및 IAM 역할 선택 이전에 생성하라고 잘못 제안하므로 배포의 필수 흐름을 방해합니다.",
            "이 옵션은 모델을 정의하고 엔드포인트 구성을 생성하기 전에 엔드포인트를 생성하라고 제안하므로 SageMaker에서 유효한 배포 프로세스가 아닙니다."
        ]
    },
    {
        "Question Number": "56",
        "Situation": "금융 기관의 데이터 과학자는 대출 채무 불이행 위험을 예측하기 위한 회귀 모델을 개발하는 임무를 맡고 있습니다. 데이터셋은 신청자 소득, 신용 점수, 대출 금액 및 지불 이력을 포함한 다양한 특성을 가진 10,000개의 레코드로 구성되어 있습니다. 목표는 이러한 요소를 기반으로 채무 불이행 확률을 정확하게 추정하는 것입니다.",
        "Question": "데이터 과학자가 최적의 성능을 위해 모델을 초기화하기 위해 어떤 기법을 사용해야 합니까?",
        "Options": {
            "1": "다중 공선성을 처리하기 위해 L2 정규화가 포함된 선형 회귀 모델을 구현합니다.",
            "2": "랜덤 포레스트 알고리즘을 선택하고 max_depth 매개변수를 10으로 설정하여 과적합을 방지합니다.",
            "3": "고차원 데이터 처리를 위해 선형 커널을 가진 서포트 벡터 머신을 활용합니다.",
            "4": "데이터의 지역 패턴을 포착하기 위해 k를 5로 설정한 k-최근접 이웃 알고리즘을 사용합니다."
        },
        "Correct Answer": "다중 공선성을 처리하기 위해 L2 정규화가 포함된 선형 회귀 모델을 구현합니다.",
        "Explanation": "L2 정규화가 포함된 선형 회귀 모델(릿지 회귀라고도 함)을 사용하는 것은 다중 공선성을 해결하는 데 효과적이며, 이는 특성 간의 관계가 강할 수 있는 금융 데이터셋의 예측 정확도를 향상시킬 수 있습니다.",
        "Other Options": [
            "선형 커널을 가진 서포트 벡터 머신은 회귀 작업, 특히 대출 채무 불이행 위험과 같은 연속 출력에 가장 적합한 선택이 아닐 수 있으며, 일반적으로 분류 문제에 더 효과적입니다.",
            "랜덤 포레스트 알고리즘은 강력하고 과적합을 잘 처리할 수 있지만, max_depth 매개변수를 10으로 설정하는 것은 교차 검증 없이 임의적일 수 있습니다. 하이퍼파라미터 조정에 대한 데이터 기반 접근 방식이 권장됩니다.",
            "k-최근접 이웃 알고리즘은 k 선택에 민감할 수 있으며, 고차원 데이터에 대해 덜 효과적이므로 이 회귀 작업에 비해 더 강력한 기법보다 적합하지 않습니다."
        ]
    },
    {
        "Question Number": "57",
        "Situation": "소매 회사는 온라인 상점의 거래 데이터와 모바일 앱의 사용자 상호작용 데이터를 포함한 다양한 출처에서 고객 행동을 분석하고자 합니다. 데이터는 즉각적인 분석 및 기계 학습 애플리케이션을 지원하기 위해 실시간으로 수집되어야 합니다.",
        "Question": "회사의 실시간 분석 요구 사항을 최소한의 지연으로 충족하기 위해 어떤 데이터 수집 솔루션이 가장 적합합니까?",
        "Options": {
            "1": "Amazon Kinesis Data Streams를 사용하여 거래 및 상호작용 데이터를 실시간으로 수집합니다. AWS Lambda를 사용하여 즉각적인 분석을 위해 데이터를 처리합니다.",
            "2": "Amazon RDS 인스턴스를 설정하여 모든 거래 및 상호작용 데이터를 중앙 집중식 데이터베이스에 수집하여 나중에 분석합니다.",
            "3": "Amazon S3 이벤트 알림을 구현하여 S3 버킷에 새 파일이 업로드될 때마다 데이터 처리 작업을 트리거합니다.",
            "4": "AWS Data Pipeline을 사용하여 온라인 상점과 모바일 앱에서 Amazon S3로 데이터의 정기적인 배치 업로드를 예약합니다. 업로드된 데이터에 대한 분석 작업을 실행합니다."
        },
        "Correct Answer": "Amazon Kinesis Data Streams를 사용하여 거래 및 상호작용 데이터를 실시간으로 수집합니다. AWS Lambda를 사용하여 즉각적인 분석을 위해 데이터를 처리합니다.",
        "Explanation": "Amazon Kinesis Data Streams를 사용하면 회사가 온라인 상점과 모바일 앱에서 데이터를 실시간으로 수집할 수 있어 즉각적인 분석이 가능하고 지연을 줄일 수 있습니다. AWS Lambda로 데이터를 처리하면 자동으로 확장되는 서버리스 아키텍처를 제공합니다.",
        "Other Options": [
            "AWS Data Pipeline을 사용하여 정기적인 배치 업로드를 수행하는 것은 배치 처리 특성으로 인해 실시간 분석 요구 사항을 충족하지 못하므로 지연을 초래합니다.",
            "Amazon RDS 인스턴스를 설정하면 데이터를 중앙 집중화하지만, 즉각적인 분석에 중요한 실시간 수집 기능을 제공하지 않습니다.",
            "Amazon S3 이벤트 알림을 구현하면 업로드에 반응할 수 있지만, Kinesis와 같은 출처에서 실시간 데이터 수집을 직접 촉진하지 않으므로 즉각적인 분석에 덜 적합합니다."
        ]
    },
    {
        "Question Number": "58",
        "Situation": "데이터 과학자가 50,000개의 이미지로 구성된 데이터셋을 사용하여 이미지 분류를 위한 딥 러닝 모델을 조정하고 있습니다. 과학자는 모델의 성능과 수렴 속도를 최적화하기 위해 훈련 중 다양한 배치 크기로 실험하고 있습니다.",
        "Question": "신경망 훈련에서 배치 크기에 대한 어떤 진술이 TRUE입니까?",
        "Options": {
            "1": "작은 배치 크기는 더 일관된 수렴과 더 나은 일반화를 가져올 수 있습니다.",
            "2": "큰 배치 크기는 모델 정확도에 영향을 주지 않고 더 빠른 훈련 시간을 보장합니다.",
            "3": "배치 크기는 지역 최소값에 갇힐 가능성에 영향을 미치지 않습니다.",
            "4": "작은 배치 크기는 큰 배치 크기와 비교할 때 잘못된 솔루션에 수렴할 가능성이 적습니다."
        },
        "Correct Answer": "작은 배치 크기는 더 일관된 수렴과 더 나은 일반화를 가져올 수 있습니다.",
        "Explanation": "작은 배치 크기는 훈련 중 더 많은 노이즈를 도입하는 경향이 있어 모델이 지역 최소값에서 벗어나고 보지 못한 데이터에 대한 더 강력한 일반화를 제공하는 데 도움이 될 수 있습니다.",
        "Other Options": [
            "큰 배치 크기는 훈련 속도를 높일 수 있지만 정확도가 낮아지고 최적이 아닌 솔루션으로 수렴할 위험이 있어 이 진술과는 반대입니다.",
            "큰 배치 크기는 훈련 시간을 줄일 수 있지만 더 나은 모델 정확도를 보장하지 않으며 수렴 문제를 초래할 수 있습니다.",
            "배치 크기는 훈련 역학에 상당한 영향을 미치며, 지역 최소값에 갇힐 가능성을 포함하여 이 진술이 잘못되었음을 나타냅니다."
        ]
    },
    {
        "Question Number": "59",
        "Situation": "금융 서비스 회사가 실시간 거래 데이터를 분석하여 사기 활동을 탐지하려고 합니다. 그들은 높은 처리량을 처리하고 빠르게 통찰력을 제공할 수 있는 시스템을 설정하고자 합니다. 데이터는 주로 JSON 형식의 다양한 형식으로 들어옵니다. 회사는 데이터를 미래 분석을 위해 저장하는 동시에 실시간으로 처리해야 합니다.",
        "Question": "회사가 거래 데이터를 효율적으로 수집, 처리 및 저장하기 위해 어떤 AWS 서비스 조합을 사용해야 합니까?",
        "Options": {
            "1": "AWS Lambda를 사용하여 스트리밍 서비스 없이 Amazon RDS에 직접 데이터를 저장합니다.",
            "2": "Kinesis Data Streams를 사용하여 데이터를 수집하고 Kinesis Data Firehose를 사용하여 S3에 저장합니다.",
            "3": "Amazon Redshift를 사용하여 지속적으로 데이터를 수집하고 통찰력을 위해 쿼리합니다.",
            "4": "Amazon S3를 사용하여 데이터를 수집한 다음 AWS Glue 작업을 실행하여 처리합니다."
        },
        "Correct Answer": "Kinesis Data Streams를 사용하여 데이터를 수집하고 Kinesis Data Firehose를 사용하여 S3에 저장합니다.",
        "Explanation": "Kinesis Data Streams를 사용하면 회사가 대규모로 실시간 거래 데이터를 수집할 수 있으며, Kinesis Data Firehose는 이 데이터를 자동으로 S3에 저장하여 미래 분석을 위해 제공합니다. 이 조합은 시스템이 높은 처리량을 처리할 수 있도록 하고 다양한 데이터 형식을 지원하여 회사의 요구 사항을 효과적으로 충족합니다.",
        "Other Options": [
            "AWS Lambda를 사용하여 Amazon RDS에 직접 데이터를 저장하면 Kinesis 서비스가 제공하는 실시간 수집 및 처리의 이점을 놓치게 되어 높은 처리량 시나리오에 덜 적합합니다.",
            "Amazon S3에 데이터를 수집한 다음 AWS Glue 작업을 실행하는 것은 실시간 처리를 촉진하지 않으며, 이 접근 방식은 지속적인 데이터 수집보다는 배치 처리에 더 적합합니다.",
            "Amazon Redshift를 지속적으로 수집하는 것은 최적이 아니며, 주로 데이터 웨어하우스 솔루션으로 실시간 데이터 수집에 필요한 스트리밍 기능이 부족합니다."
        ]
    },
    {
        "Question Number": "60",
        "Situation": "데이터 과학자가 구독 기반 서비스의 고객 이탈을 예측하는 임무를 맡았습니다. 데이터셋에는 사용 통계와 같은 수치적 특성과 구독 유형과 같은 범주형 특성이 혼합되어 있습니다. 데이터 과학자는 두 가지 유형의 특성을 효과적으로 처리하고 이해관계자에게 해석 가능성을 제공할 수 있는 기계 학습 모델을 선택해야 합니다.",
        "Question": "데이터 과학자가 이 예측 작업을 위해 선택해야 할 기계 학습 모델은 무엇입니까?",
        "Options": {
            "1": "K-Means 클러스터링",
            "2": "랜덤 포레스트",
            "3": "서포트 벡터 머신 (SVM)",
            "4": "선형 회귀"
        },
        "Correct Answer": "랜덤 포레스트",
        "Explanation": "랜덤 포레스트는 수치적 및 범주형 특성을 효과적으로 처리할 수 있는 앙상블 모델입니다. 또한 특성 중요도를 제공하여 이해관계자에게 해석 가능성을 돕습니다. 이는 고객 이탈을 예측하는 데 적합한 선택입니다.",
        "Other Options": [
            "서포트 벡터 머신 (SVM)은 범주형 특성이 적절히 인코딩되지 않으면 어려움을 겪을 수 있으므로 이 시나리오에 이상적이지 않으며, 일반적으로 랜덤 포레스트와 같은 앙상블 방법에 비해 해석 가능성이 낮습니다.",
            "K-Means 클러스터링은 분류나 회귀가 아닌 클러스터링을 위한 비지도 학습 알고리즘이므로 예측 작업에 적합하지 않습니다.",
            "선형 회귀는 입력 특성과 목표 변수 간의 선형 관계를 가정하므로 이 작업에 적합하지 않으며, 범주형 특성이 적절히 변환되지 않으면 어려움을 겪습니다."
        ]
    },
    {
        "Question Number": "61",
        "Situation": "금융 기관이 사기 거래를 탐지하기 위해 머신 러닝 모델을 개발하고 있습니다. 데이터 과학 팀은 여러 모델을 구축하고 ROC 및 AUC 지표를 사용하여 성능을 평가하고 있습니다. 그들은 특히 민감도와 특이성을 균형 있게 유지하면서 ROC 곡선 아래의 면적을 최대화하기 위한 최적의 임계값을 찾는 데 관심이 있습니다.",
        "Question": "팀이 모델의 최적 임계값을 효과적으로 결정하기 위해 사용할 수 있는 전략은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "각 모델에 대한 AUC를 계산하고 분리 능력을 기준으로 AUC가 가장 낮은 모델을 최상의 성능 모델로 선택합니다.",
            "2": "모델에서 생성된 ROC 곡선을 활용하여 성능을 시각적으로 평가하고 민감도와 특이성을 모두 최대화하는 임계값을 선택합니다.",
            "3": "0.5 AUC 값을 초래하는 임계값을 선택합니다. 이는 균형 잡힌 모델을 나타냅니다.",
            "4": "여러 임계값 수준에서 혼동 행렬을 생성하고 해당 민감도를 (1 - 특이성)와 플로팅하여 무릎 점을 식별합니다.",
            "5": "교차 검증을 적용하여 데이터셋의 다양한 폴드에서 일관되게 가장 높은 민감도를 제공하는 임계값을 결정합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "여러 임계값 수준에서 혼동 행렬을 생성하고 해당 민감도를 (1 - 특이성)와 플로팅하여 무릎 점을 식별합니다.",
            "모델에서 생성된 ROC 곡선을 활용하여 성능을 시각적으로 평가하고 민감도와 특이성을 모두 최대화하는 임계값을 선택합니다."
        ],
        "Explanation": "첫 번째 올바른 옵션은 다양한 임계값에서 혼동 행렬을 생성하여 팀이 민감도와 특이성 간의 균형을 시각적으로 평가할 수 있도록 하여 최적의 임계값 또는 무릎 점을 식별하는 데 도움을 줍니다. 두 번째 올바른 옵션은 모델 성능을 평가하고 민감도와 특이성을 최적으로 균형 잡는 임계값을 선택하는 데 있어 ROC 곡선의 중요성을 강조합니다.",
        "Other Options": [
            "0.5 AUC 값을 초래하는 임계값을 선택하는 것은 잘못된 것입니다. AUC가 0.5인 것은 무작위 추측과 유사한 분별력이 없는 모델을 나타냅니다. 더 높은 AUC가 더 나은 모델 성능을 위해 바람직합니다.",
            "AUC가 가장 낮은 모델을 선택하는 것은 잘못된 것입니다. 이는 AUC가 가장 높은 모델을 선택하는 목표와 모순되며, 이는 클래스 간의 더 나은 분리 능력을 나타냅니다.",
            "교차 검증을 적용하는 것은 좋은 관행이지만, ROC 곡선 및 민감도-특이성 균형에 따라 최적의 임계값을 찾는 것과는 직접적인 관련이 없습니다. 따라서 이 시나리오에 대해 특별히 효과적이지 않습니다."
        ]
    },
    {
        "Question Number": "62",
        "Situation": "머신 러닝 엔지니어가 이미지 분류를 위한 신경망 모델을 최적화하는 임무를 맡고 있습니다. 엔지니어는 모델이 효과적으로 학습하고 훈련 중에 좋은 솔루션으로 수렴하도록 보장하고 싶어합니다. 그는 모델의 최적화 프로세스를 개선할 수 있는 기술에 특히 관심이 있습니다.",
        "Question": "신경망 훈련 중 손실 함수를 최소화하는 데 중요한 최적화 기술은 무엇입니까?",
        "Options": {
            "1": "정규화 기법",
            "2": "경사 하강법",
            "3": "배치 정규화",
            "4": "학습률 스케줄링"
        },
        "Correct Answer": "경사 하강법",
        "Explanation": "경사 하강법은 손실 함수의 가장 가파른 하강 방향으로 모델 매개변수를 조정하는 최적화 알고리즘입니다. 이는 손실을 최소화하고 모델이 훈련 데이터에서 효과적으로 학습하도록 보장하는 데 기본적입니다.",
        "Other Options": [
            "학습률 스케줄링은 훈련 중 학습률을 조정하는 데 도움이 되지만, 최적화 프로세스 자체에 직접적인 영향을 미치지는 않습니다. 이는 수렴을 향상시키기 위한 기술이지 주요 최적화 방법은 아닙니다.",
            "배치 정규화는 각 레이어의 입력을 정규화하여 훈련의 안정성과 속도를 개선하는 데 사용되지만, 경사 하강법처럼 손실 함수를 직접 최소화하지는 않습니다.",
            "정규화 기법은 손실 함수에 패널티를 추가하여 과적합을 방지하는 데 사용되지만, 훈련 프로세스를 최적화하거나 손실 함수를 최소화하는 주요 방법은 아닙니다."
        ]
    },
    {
        "Question Number": "63",
        "Situation": "데이터 과학자가 Amazon SageMaker를 사용하여 머신 러닝 모델을 구축, 훈련 및 배포하고 있습니다. 그들은 개발 프로세스가 효율적이고 S3에 저장된 훈련 데이터에 쉽게 접근할 수 있도록 하고 싶어합니다. 또한, 필요한 리소스에 대한 접근을 유지하면서 특정 요구에 맞게 노트북 인스턴스를 사용자 정의하는 방법을 고려하고 있습니다.",
        "Question": "다음 중 Amazon SageMaker의 어떤 기능이 데이터 과학자가 노트북 인스턴스가 시작되기 전에 사용자 정의 설정 명령을 실행할 수 있게 해줍니까?",
        "Options": {
            "1": "노트북 인스턴스 유형",
            "2": "생애 주기 구성",
            "3": "관리형 알고리즘",
            "4": "사전 서명된 URL"
        },
        "Correct Answer": "생애 주기 구성",
        "Explanation": "생애 주기 구성은 사용자가 노트북 인스턴스가 시작될 때 자동으로 실행되는 스크립트를 지정할 수 있게 해주며, 이를 통해 사용자 정의 설정 명령을 사전에 실행할 수 있습니다. 이는 데이터 과학자의 작업에 필요한 환경을 설정하는 데 필수적입니다.",
        "Other Options": [
            "노트북 인스턴스 유형은 SageMaker 노트북을 실행하기 위해 사용할 수 있는 다양한 인스턴스 유형을 나타내지만, 인스턴스가 시작되기 전에 설정 명령을 실행하는 메커니즘을 제공하지 않습니다.",
            "사전 서명된 URL은 노트북 인스턴스에 대한 임시 접근을 부여하는 데 사용되지만, 인스턴스가 시작되기 전에 명령을 실행하거나 설정을 수행하는 것과는 관련이 없습니다.",
            "SageMaker의 관리형 알고리즘은 모델 훈련을 위한 내장 알고리즘을 제공하지만, 노트북 인스턴스의 시작 프로세스를 사용자 정의하는 기능과는 관련이 없습니다."
        ]
    },
    {
        "Question Number": "64",
        "Situation": "금융 서비스 회사가 신용 위험을 평가하기 위한 예측 모델을 구축하고 있습니다. 이 모델은 과적합을 최소화하면서 가장 높은 정확도를 달성하기 위해 최적화되어야 합니다. 머신 러닝 전문가가 모델 성능을 향상시키기 위해 하이퍼파라미터 최적화의 최선의 접근 방식을 선택하는 임무를 맡고 있습니다.",
        "Question": "이 시나리오에서 하이퍼파라미터 최적화에 가장 효과적인 방법은 무엇입니까?",
        "Options": {
            "1": "Grid Search",
            "2": "Bayesian Optimization",
            "3": "Manual Tuning",
            "4": "Random Search"
        },
        "Correct Answer": "Bayesian Optimization",
        "Explanation": "Bayesian Optimization은 하이퍼파라미터의 성능을 예측하기 위해 확률 모델을 사용하므로, 더 많은 정보에 기반한 결정과 하이퍼파라미터 공간의 효율적인 탐색이 가능하여, 더 적은 반복으로 더 나은 모델 성능을 얻을 수 있는 가장 효과적인 방법입니다.",
        "Other Options": [
            "Grid Search는 모든 하이퍼파라미터 조합을 평가하므로 소모적이고 계산 비용이 많이 들 수 있습니다. 이 방법은 더 큰 데이터셋이나 더 복잡한 모델에 대해 효율적이지 않을 수 있으며, 최적화 시간이 길어질 수 있습니다.",
            "Random Search는 하이퍼파라미터의 무작위 조합을 샘플링하므로 Grid Search보다 더 효율적입니다. 그러나 이전 평가에서 얻은 정보를 활용하지 않기 때문에 하이퍼파라미터 공간의 최적 영역을 놓칠 수 있습니다.",
            "Manual Tuning은 간단한 모델이나 도메인 지식이 강할 때 효과적일 수 있지만, 주관적일 수 있으며 하이퍼파라미터 공간을 체계적으로 탐색하지 못해 서브옵티멀한 모델 성능으로 이어질 수 있습니다."
        ]
    },
    {
        "Question Number": "65",
        "Situation": "머신 러닝 엔지니어가 여러 지리적 지역에서 고객에게 서비스를 제공하기 위해 예측 모델을 배포하는 임무를 맡고 있습니다. 이는 낮은 대기 시간과 높은 가용성을 보장해야 합니다. 모델은 다양한 부하를 수용할 수 있도록 확장 가능해야 하며, 지역 실패에 대해 복원력이 있어야 합니다.",
        "Question": "엔지니어가 여러 AWS 리전과 가용 영역에 걸쳐 모델을 효과적으로 배포하기 위해 어떤 AWS 서비스 조합을 사용해야 합니까?",
        "Options": {
            "1": "AWS Fargate with Amazon S3",
            "2": "AWS Lambda with Amazon API Gateway",
            "3": "Amazon SageMaker with Amazon Elastic Load Balancing",
            "4": "Amazon SageMaker with Amazon CloudFront"
        },
        "Correct Answer": "Amazon SageMaker with Amazon Elastic Load Balancing",
        "Explanation": "Amazon SageMaker를 사용하면 머신 러닝 모델을 쉽게 배포할 수 있으며, Amazon Elastic Load Balancing은 여러 가용 영역에서 들어오는 애플리케이션 트래픽을 여러 대상에 분산시켜 지역 간 높은 가용성과 낮은 대기 시간을 보장합니다.",
        "Other Options": [
            "Amazon SageMaker with Amazon CloudFront는 CloudFront가 정적 자산을 위한 콘텐츠 전송 네트워크(CDN)로 설계되었기 때문에 모델 배포에 적합하지 않습니다.",
            "AWS Lambda with Amazon API Gateway는 주로 서버리스 아키텍처에 사용되지만, SageMaker와 같은 전용 서비스에 비해 무거운 머신 러닝 추론 작업에 잘 확장되지 않을 수 있습니다.",
            "AWS Fargate with Amazon S3는 머신 러닝 모델 배포에 이상적이지 않습니다. Fargate는 컨테이너 관리용이고, S3는 저장소용으로, ML 모델에 필요한 직접 배포 기능이 부족합니다."
        ]
    }
]