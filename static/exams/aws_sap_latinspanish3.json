[
    {
        "Question Number": "1",
        "Situation": "Una empresa tiene múltiples cuentas de AWS para diferentes departamentos y quiere implementar la gestión de acceso entre cuentas para permitir que los usuarios de una cuenta accedan a recursos en otra cuenta de manera segura. El acceso debe gestionarse de manera efectiva sin utilizar credenciales a largo plazo. Están considerando varios servicios y metodologías de AWS para lograr esto.",
        "Question": "¿Qué combinación de acciones debe tomarse para implementar una gestión de acceso entre cuentas segura? (Seleccione Dos)",
        "Options": {
            "1": "Utilizar AWS Organizations para crear una política de control de servicio (SCP) que permita el acceso a recursos específicos en todas las cuentas.",
            "2": "Crear un rol de IAM en la cuenta de destino que otorgue los permisos necesarios. Permitir que los usuarios de la cuenta de origen asuman este rol utilizando el ARN del rol.",
            "3": "Crear una política basada en recursos en los recursos de la cuenta de destino que otorgue acceso a los usuarios de IAM en la cuenta de origen.",
            "4": "Implementar un Proveedor de Identidad (IdP) centralizado que federé las identidades de usuario en todas las cuentas y gestione el acceso a los recursos.",
            "5": "Configurar un grupo de identidades de Amazon Cognito en la cuenta de origen y configurarlo para otorgar acceso a los recursos en la cuenta de destino."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Crear un rol de IAM en la cuenta de destino que otorgue los permisos necesarios. Permitir que los usuarios de la cuenta de origen asuman este rol utilizando el ARN del rol.",
            "Crear una política basada en recursos en los recursos de la cuenta de destino que otorgue acceso a los usuarios de IAM en la cuenta de origen."
        ],
        "Explanation": "Crear un rol de IAM en la cuenta de destino permite que los usuarios de la cuenta de origen asuman este rol, otorgándoles así los permisos necesarios sin necesidad de credenciales a largo plazo. Además, implementar una política basada en recursos en los recursos de la cuenta de destino permite que usuarios específicos de IAM de la cuenta de origen accedan directamente a esos recursos, mejorando la seguridad y la gestionabilidad.",
        "Other Options": [
            "Configurar un grupo de identidades de Amazon Cognito en la cuenta de origen no es una solución adecuada para la gestión de acceso entre cuentas en este escenario, ya que principalmente facilita la autenticación de usuarios y no el acceso directo a recursos de AWS en otra cuenta.",
            "Utilizar AWS Organizations con políticas de control de servicio (SCP) no otorga directamente acceso a recursos entre cuentas; las SCP están diseñadas para controlar permisos a nivel de organización en lugar de facilitar el acceso entre cuentas.",
            "Implementar un Proveedor de Identidad (IdP) centralizado para identidades federadas es una solución más compleja y puede no ser necesaria para el requisito de permitir que usuarios específicos en una cuenta accedan a recursos en otra cuenta."
        ]
    },
    {
        "Question Number": "2",
        "Situation": "Una empresa de servicios financieros ha migrado recientemente su infraestructura a AWS. Están preocupados por la seguridad de su entorno y quieren asegurarse de poder detectar cualquier acceso no autorizado o amenazas potenciales. Después de revisar varios servicios de seguridad de AWS, deciden implementar Amazon GuardDuty para mejorar su postura de seguridad.",
        "Question": "¿Cuál de las siguientes afirmaciones sobre Amazon GuardDuty es VERDADERA?",
        "Options": {
            "1": "Amazon GuardDuty analiza automáticamente los registros de AWS CloudTrail, los registros de flujo de VPC y los registros de DNS para detectar comportamientos maliciosos sin requerir configuración adicional.",
            "2": "Amazon GuardDuty es un servicio que proporciona monitoreo en tiempo real para recursos de AWS, pero no analiza registros en busca de actividades sospechosas.",
            "3": "Amazon GuardDuty requiere configuración manual de fuentes de inteligencia de amenazas para monitorear efectivamente la actividad de la red.",
            "4": "Amazon GuardDuty solo puede detectar amenazas basadas en firmas predefinidas y no puede adaptarse a nuevas amenazas con el tiempo."
        },
        "Correct Answer": "Amazon GuardDuty analiza automáticamente los registros de AWS CloudTrail, los registros de flujo de VPC y los registros de DNS para detectar comportamientos maliciosos sin requerir configuración adicional.",
        "Explanation": "Amazon GuardDuty está diseñado para proporcionar detección continua de amenazas al analizar automáticamente los datos de registro de varias fuentes de AWS, incluidos CloudTrail, registros de flujo de VPC y registros de DNS. Esta característica le permite identificar amenazas potenciales sin necesidad de configuración manual, lo que lo convierte en una herramienta valiosa para mejorar la seguridad en un entorno de AWS.",
        "Other Options": [
            "Esta afirmación es incorrecta porque Amazon GuardDuty utiliza inteligencia de amenazas integrada y no requiere configuración manual de fuentes de inteligencia de amenazas para funcionar de manera efectiva.",
            "Esta afirmación es incorrecta porque Amazon GuardDuty utiliza más que solo firmas predefinidas; emplea aprendizaje automático y detección de anomalías para identificar amenazas nuevas y en evolución.",
            "Esta afirmación es incorrecta ya que representa incorrectamente la funcionalidad de GuardDuty. GuardDuty analiza registros en busca de actividades sospechosas y se centra en identificar amenazas de seguridad potenciales en tiempo real."
        ]
    },
    {
        "Question Number": "3",
        "Situation": "Una empresa ha implementado AWS Organizations para gestionar múltiples cuentas de AWS. Han definido Políticas de Control de Servicio (SCP) para hacer cumplir la seguridad y el cumplimiento en sus cuentas miembros. El equipo de seguridad está preocupado por los permisos otorgados a los usuarios en estas cuentas y quiere asegurarse de que ciertas acciones no estén permitidas, incluso si existe una declaración de Permitir explícita en otras SCP.",
        "Question": "¿Cuál de las siguientes afirmaciones sobre las Políticas de Control de Servicio (SCP) es verdadera en este escenario?",
        "Options": {
            "1": "Las SCP se pueden utilizar para restringir acciones para el usuario raíz en la cuenta maestra.",
            "2": "Una Permitir explícita en una SCP puede otorgar permisos independientemente de cualquier declaración de Denegar en otras SCP.",
            "3": "Una Denegar explícita en una SCP anulará cualquier permiso de Permitir otorgado por otras SCP.",
            "4": "Las SCP se pueden aplicar para gestionar roles vinculados a servicios en las cuentas miembros."
        },
        "Correct Answer": "Una Denegar explícita en una SCP anulará cualquier permiso de Permitir otorgado por otras SCP.",
        "Explanation": "Las Políticas de Control de Servicio (SCP) están diseñadas para gestionar permisos a través de AWS Organizations. Una Denegar explícita siempre tendrá prioridad sobre cualquier permiso de Permitir, asegurando que las acciones restringidas no puedan realizarse incluso si están permitidas en otras políticas.",
        "Other Options": [
            "Esta afirmación es incorrecta porque una Permitir explícita en una SCP no anula una Denegar explícita en la misma o en otra SCP. Denegar siempre tiene prioridad.",
            "Esta afirmación es incorrecta porque las SCP no afectan al usuario raíz de la cuenta maestra. Solo se aplican a las cuentas miembros.",
            "Esta afirmación es incorrecta porque las SCP no se aplican a roles vinculados a servicios. Se gestionan a nivel de cuenta y no se ven afectadas por las SCP."
        ]
    },
    {
        "Question Number": "4",
        "Situation": "Una institución financiera está migrando sus aplicaciones a AWS y requiere que solo el personal autorizado pueda acceder a recursos específicos. El equipo de seguridad enfatiza la necesidad de una estricta adherencia al principio de menor privilegio para mitigar riesgos. Como arquitecto de soluciones, se te ha encargado diseñar políticas de IAM que apliquen este principio en varios servicios y usuarios.",
        "Question": "¿Cuál de los siguientes enfoques implementaría mejor el acceso de menor privilegio para usuarios y roles en este entorno de AWS?",
        "Options": {
            "1": "Asignar permisos de IAM basados en el nivel de cuenta de AWS, permitiendo que todos los usuarios accedan a todos los recursos bajo esa cuenta.",
            "2": "Desarrollar políticas de IAM específicas para cada grupo de usuarios que otorguen solo los permisos necesarios para sus funciones laborales y aplicarlas a los roles de IAM correspondientes.",
            "3": "Crear un solo rol de IAM con permisos de acceso completo y asignarlo a todos los usuarios que necesiten acceso a los recursos de AWS.",
            "4": "Utilizar un solo usuario de IAM para todas las tareas administrativas y compartir las credenciales entre los miembros del equipo para simplificar la gestión de acceso."
        },
        "Correct Answer": "Desarrollar políticas de IAM específicas para cada grupo de usuarios que otorguen solo los permisos necesarios para sus funciones laborales y aplicarlas a los roles de IAM correspondientes.",
        "Explanation": "Este enfoque asegura que cada usuario o rol tenga solo los permisos necesarios para realizar sus funciones laborales, adhiriéndose al principio de menor privilegio. Al personalizar las políticas de IAM para los grupos de usuarios, minimizas el riesgo de permisos excesivos y posibles brechas de seguridad.",
        "Other Options": [
            "Crear un solo rol de IAM con permisos de acceso completo viola el principio de menor privilegio, ya que otorga permisos excesivos a todos los usuarios asignados a ese rol, aumentando los riesgos de seguridad.",
            "Asignar permisos de IAM a nivel de cuenta permite a todos los usuarios acceso sin restricciones a todos los recursos, lo cual es contrario al principio de menor privilegio y puede llevar a accesos no autorizados.",
            "Utilizar un solo usuario de IAM para todas las tareas administrativas socava las mejores prácticas de seguridad, ya que compartir credenciales puede llevar a problemas de responsabilidad y aumenta el riesgo de exposición de credenciales."
        ]
    },
    {
        "Question Number": "5",
        "Situation": "Una empresa multinacional de retail está desplegando sus aplicaciones en múltiples regiones en AWS. La empresa requiere una arquitectura altamente disponible que facilite la comunicación segura entre sus centros de datos locales y los recursos de AWS. Quieren implementar una solución que aproveche AWS Direct Connect y asegure que el tráfico se enrute de manera eficiente a través de sus Amazon VPCs en diferentes regiones. La solución también debe proporcionar redundancia en caso de falla de un enlace.",
        "Question": "¿Cuál de las siguientes opciones debería implementar el arquitecto de soluciones en AWS para cumplir con los requisitos de la empresa? (Selecciona Dos)",
        "Options": {
            "1": "Establecer una conexión redundante de Direct Connect en la misma región de AWS y configurar un Gateway Virtual Privado para conmutación por error.",
            "2": "Crear un gateway de Direct Connect y asociarlo con múltiples VPCs en diferentes regiones para habilitar el emparejamiento de VPC.",
            "3": "Implementar AWS Global Accelerator para mejorar la disponibilidad y el rendimiento al enrutar el tráfico a través de múltiples regiones de AWS.",
            "4": "Configurar una VPN de sitio a sitio como respaldo de la conexión de Direct Connect para mantener la conectividad en caso de una falla.",
            "5": "Utilizar AWS Transit Gateway para conectar múltiples VPCs y redes locales, proporcionando un único punto de gestión para el enrutamiento."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Utilizar AWS Transit Gateway para conectar múltiples VPCs y redes locales, proporcionando un único punto de gestión para el enrutamiento.",
            "Configurar una VPN de sitio a sitio como respaldo de la conexión de Direct Connect para mantener la conectividad en caso de una falla."
        ],
        "Explanation": "Utilizar AWS Transit Gateway permite a la empresa gestionar de manera eficiente la conectividad entre múltiples VPCs y sus redes locales, habilitando una solución de enrutamiento escalable y centralizada. La VPN de sitio a sitio sirve como un respaldo confiable para la conexión de Direct Connect, asegurando que la comunicación pueda continuar sin problemas en caso de una falla.",
        "Other Options": [
            "Crear un gateway de Direct Connect y asociarlo con múltiples VPCs no proporciona redundancia, ya que carece de un mecanismo de conmutación por error y depende únicamente de Direct Connect.",
            "Establecer una conexión redundante de Direct Connect en la misma región de AWS no aborda la comunicación entre regiones ni proporciona una estrategia de conmutación por error integral.",
            "Implementar AWS Global Accelerator no es adecuado para establecer una conexión directa entre recursos locales y de AWS; optimiza principalmente el enrutamiento del tráfico para aplicaciones a través de regiones de AWS."
        ]
    },
    {
        "Question Number": "6",
        "Situation": "Una empresa de servicios financieros está gestionando su cumplimiento con las regulaciones de la industria utilizando recursos de AWS. Actualmente tienen AWS Config configurado para monitorear sus recursos, pero quieren mejorar su marco de cumplimiento y gobernanza. El equipo está considerando implementar estrategias de remediación automatizadas para asegurar que cualquier desviación en la configuración de recursos o incumplimiento se corrija automáticamente sin intervención manual.",
        "Question": "¿Cuál de las siguientes soluciones debería implementar el arquitecto de soluciones para automatizar el monitoreo y la remediación del cumplimiento de recursos en AWS?",
        "Options": {
            "1": "Implementar AWS Systems Manager Run Command para ejecutar scripts en instancias no conformes cuando AWS Config detecte un problema de configuración.",
            "2": "Habilitar AWS Config para crear una instantánea de las configuraciones de recursos cada 24 horas y revisarlas manualmente para asegurar el cumplimiento con las políticas de la empresa.",
            "3": "Configurar alarmas de Amazon CloudWatch para alertar al equipo de operaciones cada vez que AWS Config detecte un recurso no conforme, permitiéndoles tomar acción manual para resolver los problemas.",
            "4": "Crear una función de AWS Lambda que se active en violaciones de reglas de AWS Config para remediar automáticamente los problemas volviendo los recursos a sus estados conformes."
        },
        "Correct Answer": "Crear una función de AWS Lambda que se active en violaciones de reglas de AWS Config para remediar automáticamente los problemas volviendo los recursos a sus estados conformes.",
        "Explanation": "Este enfoque aprovecha AWS Lambda para abordar automáticamente los problemas de cumplimiento a medida que surgen, asegurando que los recursos se restauren rápidamente a la conformidad sin requerir intervención manual. Esto apoya completamente el objetivo de monitoreo y remediación automatizados.",
        "Other Options": [
            "Esta opción depende de la revisión manual de instantáneas, lo que no proporciona remediación en tiempo real y podría llevar a períodos prolongados de incumplimiento.",
            "Si bien las alarmas de CloudWatch pueden alertar al equipo sobre problemas de cumplimiento, no automatizan la remediación, requiriendo intervención manual para resolver los problemas.",
            "Utilizar Systems Manager Run Command permite cierto nivel de automatización, pero no se vincula directamente con las reglas de AWS Config para la remediación automática basada en violaciones de cumplimiento."
        ]
    },
    {
        "Question Number": "7",
        "Situation": "Una empresa de servicios financieros ha desplegado una aplicación web en AWS que maneja datos sensibles de clientes. La aplicación se ejecuta en instancias de Amazon EC2 detrás de un Elastic Load Balancer y utiliza Amazon RDS para su base de datos. La empresa necesita asegurarse de que la seguridad se mantenga en todos los niveles de la arquitectura, desde la red hasta la aplicación y los datos. Se te ha encomendado la tarea de revisar las soluciones implementadas y hacer recomendaciones para mejorar la seguridad.",
        "Question": "¿Qué medidas de seguridad deberías recomendar para garantizar una protección integral en todos los niveles de la arquitectura?",
        "Options": {
            "1": "Implementar AWS WAF para proteger la aplicación de exploits web comunes y cifrar todos los datos en reposo utilizando AWS Key Management Service (KMS).",
            "2": "Implementar roles de IAM para las instancias de EC2 para asegurar el acceso con el menor privilegio y desplegar una solución de registro centralizada utilizando AWS CloudTrail para monitoreo.",
            "3": "Utilizar AWS Shield para proteger contra ataques DDoS y habilitar Amazon CloudFront para almacenar en caché contenido, reduciendo la carga en los servidores de la aplicación.",
            "4": "Desplegar Amazon Inspector para evaluar regularmente las instancias de EC2 en busca de vulnerabilidades y configurar grupos de seguridad para restringir el tráfico entrante a los puertos necesarios."
        },
        "Correct Answer": "Implementar AWS WAF para proteger la aplicación de exploits web comunes y cifrar todos los datos en reposo utilizando AWS Key Management Service (KMS).",
        "Explanation": "Implementar AWS WAF proporciona una capa robusta de seguridad contra ataques basados en la web, mientras que usar AWS KMS para cifrar datos en reposo asegura que la información sensible de los clientes esté protegida. Esta combinación garantiza la seguridad tanto en la capa de aplicación como en la de datos.",
        "Other Options": [
            "Si bien desplegar Amazon Inspector es una buena práctica para evaluaciones de vulnerabilidad, no proporciona el mismo nivel de protección contra ataques web que AWS WAF, ni aborda el cifrado de datos.",
            "Utilizar AWS Shield protege contra ataques DDoS, pero no proporciona medidas de seguridad integrales para vulnerabilidades de la aplicación o cifrado de datos en reposo.",
            "Implementar roles de IAM es esencial para el control de acceso, pero sin medidas adicionales como AWS WAF y cifrado de datos, no aborda completamente las necesidades de seguridad en todos los niveles."
        ]
    },
    {
        "Question Number": "8",
        "Situation": "Una gran plataforma de comercio electrónico está experimentando frecuentes ataques de Denegación de Servicio Distribuida (DDoS), lo que está afectando la disponibilidad y el rendimiento de su aplicación web alojada en AWS. La plataforma necesita un conjunto robusto de estrategias de mitigación para asegurar la fiabilidad y continuidad del servicio, al mismo tiempo que mantiene una experiencia de usuario positiva.",
        "Question": "¿Qué enfoque debería recomendar el arquitecto de soluciones para desarrollar estrategias efectivas de mitigación de ataques para la plataforma de comercio electrónico?",
        "Options": {
            "1": "Utilizar AWS Shield Advanced para protección DDoS y configurar un grupo de Auto Scaling para manejar automáticamente picos de tráfico.",
            "2": "Implementar AWS WAF para filtrar solicitudes maliciosas y usar Amazon CloudFront para almacenar en caché contenido estático en ubicaciones de borde.",
            "3": "Utilizar Amazon Route 53 para la gestión de DNS y configurar verificaciones de salud para redirigir el tráfico lejos de los recursos afectados.",
            "4": "Desplegar un balanceador de carga de aplicaciones con un firewall de aplicaciones web y dirigir todo el tráfico a través de una VPN para mayor seguridad."
        },
        "Correct Answer": "Utilizar AWS Shield Advanced para protección DDoS y configurar un grupo de Auto Scaling para manejar automáticamente picos de tráfico.",
        "Explanation": "AWS Shield Advanced proporciona protección DDoS mejorada adaptada para ataques complejos, mientras que Auto Scaling asegura que la aplicación pueda manejar el aumento de tráfico ajustando automáticamente la capacidad. Esta combinación mitiga efectivamente los ataques y mantiene el rendimiento de la aplicación.",
        "Other Options": [
            "Implementar AWS WAF por sí solo puede no ser suficiente contra ataques DDoS a gran escala, y aunque almacenar en caché con CloudFront ayuda, no aborda el problema subyacente de la mitigación de ataques.",
            "Desplegar un balanceador de carga de aplicaciones con un firewall de aplicaciones web proporciona seguridad adicional, pero dirigir todo el tráfico a través de una VPN introduce latencia y complejidad, lo que podría degradar el rendimiento.",
            "Utilizar Amazon Route 53 para la gestión de DNS es útil para la redirección, pero por sí solo, no proporciona la protección DDoS necesaria ni la escalabilidad para asegurar la disponibilidad de la aplicación bajo ataque."
        ]
    },
    {
        "Question Number": "9",
        "Situation": "Una empresa de servicios financieros está planeando migrar su base de datos MySQL local a AWS. La base de datos necesita permanecer operativa durante el proceso de migración para minimizar el tiempo de inactividad de sus aplicaciones. Además, la empresa requiere que los cambios continuos en la base de datos se capturen incluso después de que se complete la migración inicial. ¿Qué servicio de AWS debería recomendar el arquitecto de soluciones para cumplir con estos requisitos?",
        "Question": "¿Qué servicio de AWS proporciona la capacidad de migrar bases de datos mientras asegura un tiempo de inactividad mínimo y permite la replicación continua de cambios después de la migración?",
        "Options": {
            "1": "Amazon RDS Read Replica",
            "2": "AWS Database Migration Service (DMS)",
            "3": "Amazon Aurora Global Database",
            "4": "AWS Snowball"
        },
        "Correct Answer": "AWS Database Migration Service (DMS)",
        "Explanation": "AWS Database Migration Service (DMS) permite una migración de base de datos sin problemas con un tiempo de inactividad mínimo. Permite la replicación continua de cambios en la base de datos, asegurando que la base de datos de origen permanezca operativa durante todo el proceso de migración.",
        "Other Options": [
            "Amazon RDS Read Replica está diseñado para escalar operaciones de lectura y no proporciona las características de migración de datos continua y captura de cambios necesarias para este escenario.",
            "AWS Snowball es un servicio de transferencia de datos utilizado principalmente para mover grandes cantidades de datos a AWS y no admite migración continua de bases de datos ni captura de datos de cambios.",
            "Amazon Aurora Global Database está destinado a aplicaciones distribuidas globalmente y no se centra en migrar bases de datos existentes mientras asegura un tiempo de inactividad mínimo."
        ]
    },
    {
        "Question Number": "10",
        "Situation": "Una empresa está utilizando Amazon DynamoDB para almacenar registros de actividad de usuarios para una aplicación móvil. Quieren implementar una solución que capture cambios en los datos en tiempo real y procese estos cambios para actualizar una tabla de análisis separada. La empresa también quiere asegurarse de que ciertas acciones desencadenen notificaciones a los usuarios cuando ocurran eventos específicos en la tabla de DynamoDB.",
        "Question": "¿Cuál de las siguientes opciones se puede utilizar para lograr el procesamiento en tiempo real de los cambios en DynamoDB y enviar notificaciones a los usuarios? (Seleccione Dos)",
        "Options": {
            "1": "Habilitar DynamoDB Streams en la tabla de registros de actividad de usuarios y asociar el stream con una función de AWS Lambda que envíe notificaciones directamente a los usuarios.",
            "2": "Utilizar Amazon SNS para publicar notificaciones cada vez que haya cambios en la tabla de DynamoDB y hacer que las funciones de Lambda se suscriban a estas notificaciones.",
            "3": "Usar DynamoDB Streams para capturar cambios en la tabla y configurar una cola de Amazon SQS para procesar los mensajes en lugar de usar AWS Lambda.",
            "4": "Habilitar DynamoDB Streams en la tabla de registros de actividad de usuarios y configurar una función de AWS Lambda para procesar el stream y actualizar la tabla de análisis.",
            "5": "Crear una función de AWS Lambda programada para sondear la tabla de DynamoDB cada minuto y verificar cambios en los datos."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Habilitar DynamoDB Streams en la tabla de registros de actividad de usuarios y configurar una función de AWS Lambda para procesar el stream y actualizar la tabla de análisis.",
            "Habilitar DynamoDB Streams en la tabla de registros de actividad de usuarios y asociar el stream con una función de AWS Lambda que envíe notificaciones directamente a los usuarios."
        ],
        "Explanation": "Al habilitar DynamoDB Streams y configurar una función de AWS Lambda, la empresa puede procesar automáticamente los cambios en tiempo real, actualizando la tabla de análisis y enviando notificaciones a los usuarios basadas en esos cambios. Este enfoque proporciona una manera eficiente y escalable de manejar modificaciones de datos y notificaciones a usuarios.",
        "Other Options": [
            "Crear una función de Lambda programada para sondear la tabla de DynamoDB cada minuto no es eficiente para el procesamiento en tiempo real, ya que introduce latencia y no responde a los cambios de inmediato.",
            "Utilizar Amazon SNS para notificaciones sin usar DynamoDB Streams no proporciona un enlace directo para procesar los cambios en los datos; requiere lógica adicional para monitorear cambios.",
            "Usar una cola de SQS para procesar mensajes de DynamoDB Streams es una capa adicional que complica la arquitectura y es innecesaria ya que la función de Lambda puede procesar el stream directamente."
        ]
    },
    {
        "Question Number": "11",
        "Situation": "Una empresa de servicios financieros está planeando migrar su base de datos Oracle local a AWS. Quieren asegurarse de que el proceso de migración sea eficiente y que el esquema de la base de datos existente sea compatible con el servicio de base de datos de AWS objetivo. La empresa tiene un equipo de administradores de bases de datos que tienen experiencia con Oracle pero no con los servicios de AWS. Buscan herramientas que les ayuden a evaluar el entorno actual y facilitar la migración mientras minimizan el tiempo de inactividad. (Seleccione Dos)",
        "Question": "¿Qué combinación de herramientas ayudará a lograr la migración de manera eficiente?",
        "Options": {
            "1": "Emplear AWS Database Migration Service (AWS DMS) para el proceso de migración y AWS Schema Conversion Tool (AWS SCT) para analizar y convertir el esquema de la base de datos.",
            "2": "Implementar AWS Snowball para la transferencia de datos y AWS Database Migration Service (AWS DMS) para manejar la replicación continua.",
            "3": "Usar AWS Database Migration Service (AWS DMS) para replicar los datos y AWS Schema Conversion Tool (AWS SCT) para convertir el esquema de la base de datos.",
            "4": "Aprovechar AWS Glue para crear trabajos de ETL para la migración de datos y AWS Schema Conversion Tool (AWS SCT) para la conversión de esquemas.",
            "5": "Utilizar AWS Data Pipeline para mover datos a Amazon RDS y AWS Schema Conversion Tool (AWS SCT) para la evaluación del esquema."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Usar AWS Database Migration Service (AWS DMS) para replicar los datos y AWS Schema Conversion Tool (AWS SCT) para convertir el esquema de la base de datos.",
            "Emplear AWS Database Migration Service (AWS DMS) para el proceso de migración y AWS Schema Conversion Tool (AWS SCT) para analizar y convertir el esquema de la base de datos."
        ],
        "Explanation": "Ambas respuestas correctas utilizan AWS DMS para la migración de datos y AWS SCT para la conversión de esquemas, que están diseñadas específicamente para migrar bases de datos a AWS de manera efectiva mientras se asegura la compatibilidad del esquema.",
        "Other Options": [
            "AWS Data Pipeline se utiliza principalmente para la orquestación de datos y no está diseñado específicamente para la migración de bases de datos. No proporcionaría el mismo nivel de capacidades de conversión de esquemas que AWS SCT.",
            "AWS Snowball se utiliza para la transferencia de datos a gran escala, pero no es adecuado para escenarios de replicación continua. Esta opción no aborda la necesidad de conversión de esquemas.",
            "AWS Glue es un servicio de ETL que no se centra principalmente en la migración de bases de datos. Si bien puede facilitar las migraciones de datos, no ofrece las capacidades de conversión de esquemas dedicadas que proporciona AWS SCT."
        ]
    },
    {
        "Question Number": "12",
        "Situation": "Una empresa de servicios financieros está diseñando una aplicación segura que requiere que varios recursos de AWS sean accesibles por diferentes equipos dentro de la organización. La empresa está utilizando roles de IAM para gestionar el acceso de manera segura. Necesitan asegurarse de que solo usuarios y servicios específicos puedan asumir ciertos roles, mientras que también necesitan subir certificados SSL para comunicaciones seguras. Dadas estas necesidades, ¿cuál es la mejor estrategia para gestionar el acceso a roles y certificados SSL?",
        "Question": "¿Cuál de las siguientes estrategias debería implementar la empresa para controlar efectivamente el acceso a los roles de IAM y gestionar los certificados SSL?",
        "Options": {
            "1": "La empresa debería crear roles de IAM con políticas de confianza que especifiquen qué usuarios pueden asumirlos. Además, subir certificados SSL a AWS Certificate Manager (ACM) para el dominio de la aplicación para asegurar comunicaciones seguras.",
            "2": "La empresa debería crear roles de IAM sin especificar políticas de confianza, permitiendo que cualquier cuenta de AWS los asuma. Los certificados SSL deben ser subidos a IAM para su gestión en lugar de usar ACM.",
            "3": "La empresa debería crear múltiples roles de IAM con políticas de confianza restrictivas para cada equipo y subir certificados SSL a IAM para comunicaciones seguras en lugar de ACM.",
            "4": "La empresa necesita crear un solo rol de IAM con una política de confianza amplia que permita a todos los usuarios internos asumir el rol. Deberían gestionar los certificados SSL subiéndolos directamente al servidor en lugar de usar ACM."
        },
        "Correct Answer": "La empresa debería crear roles de IAM con políticas de confianza que especifiquen qué usuarios pueden asumirlos. Además, subir certificados SSL a AWS Certificate Manager (ACM) para el dominio de la aplicación para asegurar comunicaciones seguras.",
        "Explanation": "Esta opción sigue las mejores prácticas de AWS al implementar acceso de menor privilegio a través de políticas de confianza específicas para los roles de IAM, asegurando que solo los usuarios designados puedan asumirlos. También sugiere correctamente usar AWS Certificate Manager (ACM) para gestionar certificados SSL, que es el enfoque recomendado para los recursos de AWS.",
        "Other Options": [
            "Esta opción sugiere una política de confianza amplia que no sigue el principio de menor privilegio, permitiendo potencialmente el acceso no autorizado. Además, gestionar certificados SSL directamente en el servidor es menos seguro y no utiliza los mejores servicios de AWS.",
            "Esta opción indica crear roles de IAM sin políticas de confianza, lo que dejaría los roles abiertos a accesos no autorizados desde cualquier cuenta de AWS. También sugiere erróneamente subir certificados SSL a IAM, lo cual no es la mejor práctica en comparación con usar ACM.",
            "Esta opción propone usar múltiples roles pero sugiere incorrectamente gestionar certificados SSL a través de IAM en lugar de ACM, lo cual no es recomendado y podría llevar a complejidades innecesarias y problemas de seguridad."
        ]
    },
    {
        "Question Number": "13",
        "Situation": "Una empresa de servicios financieros está trasladando sus aplicaciones a AWS y desea aprovechar las Spot Instances para ahorrar costos en su entorno de Amazon ECS. La empresa requiere una solución que minimice las interrupciones del servicio durante las interrupciones de las Spot Instances, asegurando que sus tareas mantengan alta disponibilidad y rendimiento. Quieren utilizar las capacidades de ECS para gestionar el ciclo de vida de las tareas en respuesta a las interrupciones de las Spot Instances.",
        "Question": "¿Cuál de las siguientes configuraciones asegurará que las tareas de ECS que se ejecutan en Spot Instances se terminen y reemplacen de manera ordenada sin causar interrupciones en el servicio?",
        "Options": {
            "1": "Configurar ECS para ejecutar tareas exclusivamente en instancias On-Demand para evitar cualquier interrupción causada por la terminación de instancias Spot, asegurando disponibilidad constante a un costo más alto.",
            "2": "Utilizar una tarea programada para verificar periódicamente las interrupciones de las instancias Spot y reemplazar manualmente cualquier tarea terminada por nuevas en instancias saludables en el clúster.",
            "3": "Configurar un servicio de ECS con un porcentaje mínimo saludable que permita que algunas tareas sean terminadas durante las interrupciones de las instancias Spot, mientras se mantiene la capacidad general del servicio.",
            "4": "Habilitar el drenaje automático de instancias Spot en ECS, permitiendo que las tareas sean drenadas y apagadas de manera ordenada al recibir un aviso de interrupción de dos minutos, mientras se programan tareas de reemplazo en otras instancias."
        },
        "Correct Answer": "Habilitar el drenaje automático de instancias Spot en ECS, permitiendo que las tareas sean drenadas y apagadas de manera ordenada al recibir un aviso de interrupción de dos minutos, mientras se programan tareas de reemplazo en otras instancias.",
        "Explanation": "Habilitar el drenaje automático de instancias Spot en ECS permite que las tareas sean terminadas de manera ordenada utilizando la funcionalidad inherente de DRAINING. Este proceso asegura que las tareas se detengan y reemplacen sin problemas, minimizando las interrupciones del servicio y maximizando la eficiencia del uso de instancias Spot.",
        "Other Options": [
            "Utilizar una tarea programada para reemplazar manualmente las tareas terminadas puede llevar a retrasos y posibles interrupciones del servicio, ya que no responde automáticamente a las interrupciones de las instancias Spot.",
            "Configurar ECS para ejecutar tareas exclusivamente en instancias On-Demand elimina los beneficios de costo de usar instancias Spot y no aborda cómo manejar las interrupciones cuando ocurren.",
            "Configurar un porcentaje mínimo saludable puede llevar a una degradación del servicio durante las interrupciones de las instancias Spot, ya que no garantiza que todas las tareas sean terminadas o reemplazadas de manera ordenada y oportuna."
        ]
    },
    {
        "Question Number": "14",
        "Situation": "Una empresa de servicios financieros opera aplicaciones críticas que requieren tanto alta disponibilidad como protección de datos. El plan de recuperación ante desastres de la empresa incluye objetivos específicos de Tiempo de Recuperación (RTO) y Objetivos de Punto de Recuperación (RPO) para asegurar un tiempo de inactividad mínimo y pérdida de datos. El equipo está considerando varios servicios de AWS para cumplir efectivamente con estos objetivos.",
        "Question": "¿Qué combinación de servicios de AWS ayudaría mejor a la empresa a alcanzar sus objetivos de RTO y RPO para sus aplicaciones críticas?",
        "Options": {
            "1": "Implementar AWS Elastic Beanstalk para el despliegue de aplicaciones y AWS Backup para la protección de datos.",
            "2": "Aprovechar Amazon RDS con copias de seguridad automáticas y despliegue Multi-AZ para alta disponibilidad.",
            "3": "Utilizar Amazon S3 para almacenamiento de datos y AWS Lambda para procesar copias de seguridad de datos.",
            "4": "Utilizar Amazon EC2 con instantáneas de EBS para la copia de seguridad y recuperación de datos."
        },
        "Correct Answer": "Aprovechar Amazon RDS con copias de seguridad automáticas y despliegue Multi-AZ para alta disponibilidad.",
        "Explanation": "Amazon RDS proporciona copias de seguridad automáticas integradas y despliegues Multi-AZ que mejoran tanto el RTO como el RPO al permitir una conmutación por error rápida y recuperación a un punto en el tiempo, lo que lo convierte en una opción adecuada para aplicaciones críticas que requieren alta disponibilidad y mínima pérdida de datos.",
        "Other Options": [
            "Amazon EC2 con instantáneas de EBS puede proporcionar opciones de recuperación, pero la naturaleza manual de las instantáneas puede llevar a RTOs y RPOs más largos en comparación con servicios gestionados como RDS.",
            "AWS Elastic Beanstalk facilita el despliegue de aplicaciones, pero no gestiona inherentemente las copias de seguridad de bases de datos o la disponibilidad, lo que lo hace menos adecuado para requisitos estrictos de RTO y RPO.",
            "Amazon S3 es una opción de almacenamiento duradera, pero carece de capacidades integradas para alta disponibilidad y recuperación a nivel de aplicación, que son críticas para cumplir con objetivos bajos de RTO y RPO."
        ]
    },
    {
        "Question Number": "15",
        "Situation": "Una empresa está diseñando una arquitectura sin servidor que requiere varios servicios para invocar funciones de AWS Lambda de manera sincrónica. El arquitecto de soluciones necesita identificar qué servicios pueden activar funciones de Lambda directamente de manera sincrónica para manejar el procesamiento de datos en tiempo real y las interacciones de los usuarios.",
        "Question": "¿Cuál de los siguientes servicios puede invocar funciones de AWS Lambda de manera sincrónica?",
        "Options": {
            "1": "Amazon Kinesis Data Firehose, Amazon S3 Batch, Amazon CloudFront, Amazon Cognito",
            "2": "Amazon CloudFront, Amazon Lex, Elastic Load Balancing, Amazon S3 Batch",
            "3": "Amazon Lex, Amazon API Gateway, AWS Step Functions, Elastic Load Balancing",
            "4": "Amazon API Gateway, Amazon Kinesis Data Firehose, AWS Step Functions, Amazon Cognito"
        },
        "Correct Answer": "Amazon Lex, Amazon API Gateway, AWS Step Functions, Elastic Load Balancing",
        "Explanation": "Amazon Lex, Amazon API Gateway, AWS Step Functions y Elastic Load Balancing pueden invocar funciones de AWS Lambda de manera sincrónica. Estos servicios están diseñados para manejar solicitudes en tiempo real y pueden esperar una respuesta de la función Lambda antes de continuar.",
        "Other Options": [
            "La opción 1 es incorrecta porque, aunque Amazon API Gateway y AWS Step Functions pueden invocar funciones de Lambda de manera sincrónica, Amazon Kinesis Data Firehose se utiliza principalmente para datos en streaming y no invoca Lambda de manera sincrónica, y Amazon Cognito se centra en la autenticación de usuarios en lugar de la invocación directa.",
            "La opción 2 es incorrecta porque, aunque Amazon Lex puede invocar funciones de Lambda, Amazon CloudFront y Amazon S3 Batch no invocan Lambda de manera sincrónica. CloudFront utiliza Lambda@Edge para la manipulación de solicitudes/respuestas, y S3 Batch opera de manera asincrónica.",
            "La opción 4 es incorrecta porque, aunque Amazon Kinesis Data Firehose puede integrarse con Lambda, no invoca Lambda de manera sincrónica. Además, Amazon S3 Batch no está diseñado para la invocación sincrónica de funciones de Lambda."
        ]
    },
    {
        "Question Number": "16",
        "Situation": "Una empresa de tecnología está implementando una nueva versión de su aplicación web utilizando AWS Elastic Beanstalk. La aplicación es crítica para las transacciones de los clientes, y la empresa quiere minimizar el tiempo de inactividad durante el proceso de implementación. Están considerando varias políticas de implementación proporcionadas por Elastic Beanstalk para lograr sus objetivos.",
        "Question": "¿Qué políticas de implementación debería seleccionar el Arquitecto de Soluciones para asegurar un tiempo de inactividad mínimo durante la implementación de la aplicación? (Selecciona Dos)",
        "Options": {
            "1": "Blue/Green",
            "2": "RollingWithAdditionalBatch",
            "3": "Immutable",
            "4": "Rolling",
            "5": "AllAtOnce"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "RollingWithAdditionalBatch",
            "Immutable"
        ],
        "Explanation": "Tanto las políticas de implementación 'RollingWithAdditionalBatch' como 'Immutable' ayudan a mantener la disponibilidad de la aplicación durante las implementaciones. 'RollingWithAdditionalBatch' permite lanzar un lote adicional de instancias antes de que comience la implementación, asegurando que se mantenga la capacidad. 'Immutable' lanza un nuevo conjunto de instancias con la nueva versión de la aplicación en un grupo de Auto Scaling separado, asegurando que la versión anterior permanezca intacta hasta que las nuevas instancias estén listas, proporcionando así un tiempo de inactividad cero.",
        "Other Options": [
            "'AllAtOnce' implementa la nueva versión en todas las instancias simultáneamente, lo que puede llevar a un tiempo de inactividad si la implementación falla o si hay problemas con la nueva versión.",
            "'Rolling' permite implementaciones estándar en modo rolling, pero no proporciona el mismo nivel de garantía de capacidad que 'RollingWithAdditionalBatch', ya que puede no tener instancias adicionales listas antes de que se actualicen las antiguas.",
            "'Blue/Green' no es una política de implementación directa en Elastic Beanstalk; en cambio, se refiere a una estrategia de implementación que implica cambiar el tráfico entre dos entornos idénticos. Si bien esto puede lograr un tiempo de inactividad cero, no se clasifica como una política de implementación dentro de Elastic Beanstalk en sí."
        ]
    },
    {
        "Question Number": "17",
        "Situation": "Una empresa de servicios financieros depende de instancias de Amazon EC2 para sus cargas de trabajo de aplicación en un entorno altamente regulado. La empresa necesita asegurarse de que todas las instancias de EC2 se parchen regularmente para cumplir con los estándares de seguridad. El equipo de seguridad de TI ha creado una política de gestión de parches que especifica la frecuencia de parcheo, los tipos de parches y la necesidad de procedimientos de reversión. La empresa quiere automatizar el parcheo de sus instancias de EC2 mientras asegura un tiempo de inactividad mínimo y el cumplimiento de su política de gestión de parches.",
        "Question": "¿Cuál es el mejor enfoque para que la empresa automatice el parcheo de sus instancias de EC2 mientras se adhiere a su política de gestión de parches?",
        "Options": {
            "1": "Utilizar reglas de AWS Config para monitorear el cumplimiento de las instancias de EC2 con la política de gestión de parches. Aplicar parches manualmente según los informes de cumplimiento generados por AWS Config.",
            "2": "Implementar una herramienta de gestión de parches de terceros en las instancias de EC2 que se integre con los servicios de AWS para automatizar el proceso de parcheo y proporcionar capacidades de informes.",
            "3": "Configurar una función de AWS Lambda que se active según un horario para aplicar parches directamente a las instancias de EC2 usando SSH. Implementar manejo de errores para asegurar que la función reintente en caso de fallo.",
            "4": "Utilizar AWS Systems Manager Patch Manager para automatizar el parcheo de acuerdo con el horario de parcheo definido. Configurar ventanas de mantenimiento para especificar cuándo se deben aplicar los parches. Asegurarse de que la línea base de parches incluya los parches necesarios."
        },
        "Correct Answer": "Utilizar AWS Systems Manager Patch Manager para automatizar el parcheo de acuerdo con el horario de parcheo definido. Configurar ventanas de mantenimiento para especificar cuándo se deben aplicar los parches. Asegurarse de que la línea base de parches incluya los parches necesarios.",
        "Explanation": "Utilizar AWS Systems Manager Patch Manager es la solución óptima para automatizar el parcheo de instancias de EC2 porque se integra directamente con los servicios de AWS, permite la programación de ventanas de mantenimiento y proporciona un enfoque centralizado para la gestión de parches. Esto asegura el cumplimiento de la política de gestión de parches de la empresa mientras minimiza el tiempo de inactividad.",
        "Other Options": [
            "Configurar una función de AWS Lambda para gestionar el parcheo a través de SSH no es la mejor práctica para la automatización, ya que requiere codificación personalizada, carece de las características de cumplimiento integradas de Systems Manager y puede introducir riesgos de seguridad si las claves SSH no se gestionan correctamente.",
            "Utilizar reglas de AWS Config para monitorear el cumplimiento es útil, pero no automatiza el proceso de parcheo en sí. Solo proporciona visibilidad sobre el estado de cumplimiento, lo que significa que aún se requeriría intervención manual para aplicar parches.",
            "Implementar una herramienta de gestión de parches de terceros puede agregar complejidad y posibles desafíos de integración. Además, puede no proporcionar el mismo nivel de integración con los servicios de AWS que AWS Systems Manager, que está diseñado específicamente para gestionar recursos de AWS."
        ]
    },
    {
        "Question Number": "18",
        "Situation": "Una empresa de servicios financieros está desarrollando una nueva aplicación de banca en línea alojada en AWS. La aplicación necesita asegurar alta disponibilidad y mínima pérdida de datos en caso de fallos, mientras mantiene baja latencia para los usuarios finales en múltiples regiones.",
        "Question": "¿Cuál de las siguientes arquitecturas es la SOLUCIÓN MÁS efectiva para lograr alta disponibilidad y recuperación ante desastres para la aplicación de banca en línea?",
        "Options": {
            "1": "Utilizar AWS Lambda para la lógica de la aplicación y DynamoDB como base de datos, ambos desplegados en una sola región con capacidad provisionada para manejar cargas máximas.",
            "2": "Implementar un grupo de Auto Scaling de instancias de EC2 en múltiples Zonas de Disponibilidad en una sola región, utilizando Amazon Aurora con implementaciones Multi-AZ para la base de datos y configurar Route 53 para la conmutación por error de DNS.",
            "3": "Crear una arquitectura sin servidor utilizando AWS Fargate para la gestión de contenedores y Amazon S3 para el almacenamiento de datos, desplegando todo en múltiples Zonas de Disponibilidad dentro de una sola región.",
            "4": "Desplegar la aplicación en múltiples Regiones de AWS utilizando instancias de Amazon EC2 detrás de un Application Load Balancer. Utilizar Amazon RDS con Réplicas de Lectura en cada región y habilitar la replicación entre regiones."
        },
        "Correct Answer": "Desplegar la aplicación en múltiples Regiones de AWS utilizando instancias de Amazon EC2 detrás de un Application Load Balancer. Utilizar Amazon RDS con Réplicas de Lectura en cada región y habilitar la replicación entre regiones.",
        "Explanation": "Desplegar la aplicación en múltiples Regiones de AWS asegura que la aplicación permanezca disponible incluso si una región falla. Utilizar instancias de EC2 con un Application Load Balancer ayuda a distribuir el tráfico de manera eficiente. Amazon RDS con Réplicas de Lectura en cada región proporciona redundancia de datos y acceso de baja latencia para los usuarios en diferentes regiones, mientras que la replicación entre regiones mitiga la pérdida de datos en caso de un fallo regional.",
        "Other Options": [
            "Utilizar AWS Lambda y DynamoDB en una sola región no proporciona suficiente alta disponibilidad o recuperación ante desastres, ya que carece de redundancia entre regiones y es susceptible a fallos regionales.",
            "Si bien implementar un grupo de Auto Scaling con implementaciones Multi-AZ mejora la disponibilidad dentro de una sola región, no protege contra fallos regionales, lo cual es crítico para una aplicación de servicios financieros.",
            "Una arquitectura sin servidor utilizando AWS Fargate y S3 en una sola región no es suficiente para alta disponibilidad y recuperación ante desastres, ya que carece de la redundancia entre regiones necesaria para asegurar un tiempo de inactividad mínimo y pérdida de datos."
        ]
    },
    {
        "Question Number": "19",
        "Situation": "Una gran empresa de comercio electrónico está experimentando un crecimiento rápido y necesita rediseñar su arquitectura para garantizar escalabilidad y resiliencia. La empresa tiene como objetivo acomodar patrones de tráfico fluctuantes mientras minimiza costos. Requieren una solución que pueda ajustar automáticamente los recursos según la demanda sin intervención manual y que se alinee con sus objetivos comerciales de mantener alta disponibilidad y rendimiento durante los períodos de uso máximo.",
        "Question": "¿Cuál de los siguientes diseños arquitectónicos satisfará mejor los requisitos de la empresa para una solución elástica y rentable?",
        "Options": {
            "1": "Implementar grupos de autoescalado con instancias EC2 detrás de un Application Load Balancer para manejar el tráfico entrante. Configurar políticas de escalado basadas en métricas de utilización de CPU.",
            "2": "Configurar un servicio de orquestación de contenedores como Amazon ECS con un número fijo de tareas en todos los nodos para gestionar el tráfico, asegurando que los recursos estén siempre disponibles.",
            "3": "Utilizar funciones de AWS Lambda para manejar solicitudes entrantes, escalando automáticamente con el uso. Integrar Amazon API Gateway para proporcionar una interfaz RESTful para el front end.",
            "4": "Desplegar una flota de instancias EC2 de tamaño fijo en múltiples Zonas de Disponibilidad para garantizar alta disponibilidad. Usar Route 53 para conmutación por error basada en DNS sin escalado dinámico."
        },
        "Correct Answer": "Implementar grupos de autoescalado con instancias EC2 detrás de un Application Load Balancer para manejar el tráfico entrante. Configurar políticas de escalado basadas en métricas de utilización de CPU.",
        "Explanation": "Esta opción proporciona capacidades de escalado dinámico, permitiendo que la arquitectura se ajuste automáticamente según la demanda en tiempo real. Usar grupos de autoescalado con un Application Load Balancer asegura que los recursos puedan escalarse de manera eficiente hacia arriba o hacia abajo, proporcionando tanto resiliencia como rentabilidad durante las fluctuaciones de tráfico.",
        "Other Options": [
            "Esta opción no proporciona capacidades de escalado dinámico. Si bien asegura alta disponibilidad al distribuir instancias a través de Zonas de Disponibilidad, no puede ajustarse a patrones de tráfico cambiantes, lo que puede llevar a un sobreaprovisionamiento y costos incrementados durante períodos de bajo tráfico.",
            "Usar funciones de AWS Lambda es una solución escalable, pero esta opción no menciona el uso de Amazon API Gateway, que es esencial para una interfaz RESTful bien definida. Además, puede que no maneje cargas de trabajo complejas tan eficientemente como las instancias EC2 en ciertos escenarios.",
            "Esta opción no proporciona escalado dinámico. Si bien Amazon ECS puede gestionar contenedores, tener un número fijo de tareas limita la capacidad de la arquitectura para responder a tráfico fluctuante, lo que puede llevar a problemas de rendimiento durante los momentos pico."
        ]
    },
    {
        "Question Number": "20",
        "Situation": "Una empresa de servicios financieros está utilizando instancias EC2 de Amazon para ejecutar su aplicación en la nube. Han notado que algunas instancias están consistentemente subutilizadas mientras que otras están funcionando a máxima capacidad. El equipo quiere analizar sus informes de uso para identificar qué recursos están subutilizados y cuáles están sobreutilizados, para optimizar costos y rendimiento. Tienen acceso a métricas de AWS CloudWatch y AWS Cost Explorer.",
        "Question": "¿Cuál es el mejor enfoque para analizar los informes de uso e identificar instancias EC2 subutilizadas y sobreutilizadas?",
        "Options": {
            "1": "Utilizar AWS Trusted Advisor para revisar la utilización de las instancias y recibir recomendaciones.",
            "2": "Analizar las métricas de las instancias EC2 en CloudWatch para identificar patrones de uso de CPU y memoria a lo largo del tiempo.",
            "3": "Usar AWS Cost Explorer para evaluar los costos totales asociados con cada instancia e identificar anomalías.",
            "4": "Aprovechar AWS Budgets para establecer límites de gasto para cada instancia EC2 y analizar los informes."
        },
        "Correct Answer": "Analizar las métricas de las instancias EC2 en CloudWatch para identificar patrones de uso de CPU y memoria a lo largo del tiempo.",
        "Explanation": "Analizar las métricas de las instancias EC2 en CloudWatch permite observar directamente los métricas de rendimiento como la utilización de CPU y memoria a lo largo del tiempo. Estos datos son críticos para determinar si las instancias están subutilizadas o sobreutilizadas según los patrones de uso reales, lo que permite una optimización efectiva de recursos.",
        "Other Options": [
            "Si bien AWS Trusted Advisor proporciona recomendaciones basadas en mejores prácticas y optimización de recursos, no ofrece métricas detalladas a lo largo del tiempo necesarias para la identificación precisa de instancias subutilizadas o sobreutilizadas.",
            "AWS Cost Explorer es útil para entender los costos generales y tendencias, pero no proporciona las métricas de uso específicas necesarias para evaluar efectivamente el rendimiento de cada instancia.",
            "AWS Budgets ayuda a rastrear límites de gasto, pero no proporciona las métricas de rendimiento detalladas requeridas para identificar la subutilización o sobreutilización de instancias EC2."
        ]
    },
    {
        "Question Number": "21",
        "Situation": "Una empresa está gestionando una flota de instancias de contenedores Amazon ECS que requieren actualizaciones de configuración regulares y tareas de mantenimiento. El equipo de operaciones quiere agilizar el proceso de ejecutar comandos en múltiples instancias de contenedores sin iniciar sesión en cada una individualmente. Necesitan una solución que proporcione visibilidad sobre el estado y los resultados de estos comandos mientras asegura un acceso seguro a las instancias de contenedores.",
        "Question": "¿Qué servicio de AWS debería usar el equipo de operaciones para gestionar de manera eficiente las actualizaciones de configuración y las tareas administrativas en sus instancias de contenedores ECS?",
        "Options": {
            "1": "Aprovechar AWS CloudFormation para crear una pila que defina el estado deseado de las instancias de contenedores ECS, asegurando que todas las configuraciones se apliquen de manera consistente en la flota.",
            "2": "Utilizar Amazon EventBridge para programar tareas que ejecuten scripts localmente en cada instancia de contenedor ECS para actualizaciones de configuración y tareas administrativas.",
            "3": "Usar AWS Systems Manager Run Command para ejecutar comandos en múltiples instancias de contenedores ECS simultáneamente, proporcionando una vista centralizada del estado de ejecución de comandos y resultados.",
            "4": "Implementar funciones de AWS Lambda que se activen con eventos de CloudWatch para actualizar automáticamente las instancias de contenedores ECS cada vez que haya cambios en la configuración."
        },
        "Correct Answer": "Usar AWS Systems Manager Run Command para ejecutar comandos en múltiples instancias de contenedores ECS simultáneamente, proporcionando una vista centralizada del estado de ejecución de comandos y resultados.",
        "Explanation": "AWS Systems Manager Run Command permite gestionar y automatizar tareas administrativas en múltiples instancias EC2 o instancias de contenedores ECS de manera segura y eficiente. Proporciona una interfaz centralizada para ejecutar comandos y ver su estado, lo que lo hace ideal para el escenario dado.",
        "Other Options": [
            "AWS CloudFormation se utiliza para infraestructura como código y no proporciona la capacidad directa de ejecutar comandos o gestionar configuraciones en instancias en ejecución existentes. Se centra en aprovisionar y gestionar recursos en lugar de ejecutar comandos.",
            "Las funciones de AWS Lambda son más adecuadas para arquitecturas impulsadas por eventos. Si bien pueden usarse para activar acciones basadas en eventos, no proporcionan una forma sencilla de ejecutar comandos en masa en múltiples instancias de ECS ni ofrecen visibilidad sobre los resultados de la ejecución de comandos.",
            "Amazon EventBridge es un servicio de bus de eventos sin servidor que se puede usar para responder a eventos en su entorno de AWS, pero no permite inherentemente ejecutar comandos localmente en instancias de contenedores ECS. Requeriría una configuración adicional para ejecutar scripts, y carece de las características de ejecución de comandos centralizada e informes de Systems Manager."
        ]
    },
    {
        "Question Number": "22",
        "Situation": "Una empresa de servicios financieros está migrando sus aplicaciones a AWS y necesita asegurarse de que todos los datos sensibles estén cifrados tanto en reposo como en tránsito. El equipo está considerando varios servicios de AWS para una gestión efectiva del cifrado, mientras asegura el cumplimiento de los estándares de la industria. Quieren implementar una solución que minimice la carga operativa de gestionar las claves de cifrado.",
        "Question": "¿Cuál de las siguientes estrategias debería adoptar la empresa para implementar eficazmente el cifrado tanto para los datos en reposo como para los datos en tránsito?",
        "Options": {
            "1": "Utilizar AWS CloudHSM para gestionar las claves de cifrado y configurar el cifrado a nivel de aplicación para los datos en tránsito.",
            "2": "Usar AWS Key Management Service (KMS) para gestionar las claves de cifrado y habilitar el cifrado del lado del servidor de S3 con claves KMS.",
            "3": "Implementar políticas de bucket de Amazon S3 para restringir el acceso y usar cifrado del lado del cliente para los datos en reposo.",
            "4": "Habilitar el cifrado de Amazon RDS y usar SSL/TLS para asegurar los datos en tránsito sin gestión adicional de claves."
        },
        "Correct Answer": "Usar AWS Key Management Service (KMS) para gestionar las claves de cifrado y habilitar el cifrado del lado del servidor de S3 con claves KMS.",
        "Explanation": "Usar AWS Key Management Service (KMS) simplifica la gestión de claves de cifrado y permite una fácil integración con los servicios de AWS. Habilitar el cifrado del lado del servidor de S3 con claves KMS proporciona un cifrado fuerte para los datos en reposo, al tiempo que permite cumplir con los requisitos regulatorios. Este enfoque asegura eficazmente los datos tanto en reposo como en tránsito cuando se combina con HTTPS.",
        "Other Options": [
            "Utilizar AWS CloudHSM añade complejidad y carga operativa para la gestión de claves, lo cual puede no ser necesario cuando AWS KMS puede proporcionar una solución más simple. El cifrado a nivel de aplicación también requiere un esfuerzo adicional de implementación.",
            "Habilitar el cifrado de Amazon RDS proporciona protección para los datos en reposo, pero aunque SSL/TLS asegura los datos en tránsito, esta opción no aborda la gestión de claves. Se necesita una solución más integral para ambos aspectos.",
            "Implementar políticas de bucket de Amazon S3 puede restringir el acceso, pero no proporciona cifrado para los datos en reposo en sí. El cifrado del lado del cliente también coloca la carga de la gestión de claves en la aplicación, lo que lo hace menos eficiente."
        ]
    },
    {
        "Question Number": "23",
        "Situation": "Una empresa de servicios financieros requiere una arquitectura que pueda recuperarse automáticamente de fallos. La arquitectura debe asegurar que las aplicaciones críticas estén disponibles con un tiempo de inactividad mínimo y pueda gestionar eficientemente la conmutación por error entre diferentes regiones. La empresa prefiere una solución que requiera una intervención manual mínima y aproveche los servicios de AWS.",
        "Question": "¿Cuál de las siguientes soluciones proporciona el mecanismo de recuperación automática más efectivo para las aplicaciones de la empresa?",
        "Options": {
            "1": "Desplegar aplicaciones en múltiples regiones de AWS y usar Amazon Route 53 para configurar verificaciones de salud y políticas de enrutamiento de conmutación por error. Configurar una función de AWS Lambda que active copias de seguridad del estado de la aplicación en caso de un fallo.",
            "2": "Implementar una arquitectura de múltiples regiones con Amazon RDS para la replicación de bases de datos. Usar Amazon Route 53 para la conmutación por error de DNS y configurar Amazon CloudWatch para alertar cuando cualquier instancia de base de datos se vuelva no saludable.",
            "3": "Configurar AWS Elastic Load Balancing en múltiples Zonas de Disponibilidad en una sola región. Usar instancias de Amazon EC2 con verificaciones de salud para asegurar que el tráfico solo se dirija a instancias saludables.",
            "4": "Usar Amazon EC2 Auto Scaling para asegurar que siempre haya un número mínimo de instancias saludables en ejecución en una sola región. Configurar alarmas de CloudWatch para monitorear las instancias y reemplazar automáticamente cualquier instancia no saludable."
        },
        "Correct Answer": "Desplegar aplicaciones en múltiples regiones de AWS y usar Amazon Route 53 para configurar verificaciones de salud y políticas de enrutamiento de conmutación por error. Configurar una función de AWS Lambda que active copias de seguridad del estado de la aplicación en caso de un fallo.",
        "Explanation": "Esta opción proporciona el mecanismo de recuperación automática más completo al aprovechar el despliegue en múltiples regiones, lo que mejora la disponibilidad y la resiliencia. El uso de verificaciones de salud de Route 53 permite una conmutación por error sin problemas en caso de fallos específicos de la región, mientras que la función Lambda asegura que el estado de la aplicación se preserve y sea recuperable.",
        "Other Options": [
            "Esta opción depende únicamente de Auto Scaling dentro de una sola región, lo que no proporciona redundancia geográfica y puede no manejar eficazmente los fallos regionales.",
            "Si bien esta opción implica una configuración de múltiples regiones, se centra principalmente en la replicación de bases de datos y no aborda suficientemente los mecanismos de conmutación por error a nivel de aplicación para una recuperación ante desastres integral.",
            "Esta opción está limitada a una sola región y se centra en el balanceo de carga entre Zonas de Disponibilidad. Carece de las disposiciones necesarias para la recuperación automática en caso de un fallo a nivel regional, lo que la hace menos efectiva para los requisitos de la empresa."
        ]
    },
    {
        "Question Number": "24",
        "Situation": "Una empresa de servicios financieros está planeando migrar sus aplicaciones heredadas a AWS. Estas aplicaciones constan de múltiples componentes que necesitan ser analizados para identificar dependencias y utilización de recursos. La empresa quiere asegurar una transición fluida a la nube con una interrupción mínima de las operaciones comerciales en curso. Están considerando varias herramientas de AWS para ayudar en el proceso de descubrimiento y migración.",
        "Question": "¿Cuál de las siguientes herramientas sería más efectiva para identificar las dependencias y la utilización de recursos de las aplicaciones heredadas existentes durante la fase de planificación de la migración?",
        "Options": {
            "1": "AWS Application Discovery Service para recopilar y analizar datos sobre aplicaciones locales, incluyendo su utilización de recursos y dependencias.",
            "2": "AWS CloudTrail para monitorear llamadas a la API y actividad de usuarios dentro de la cuenta de AWS después de que se haya realizado la migración.",
            "3": "AWS Config para rastrear configuraciones de recursos y cumplimiento para las aplicaciones después de la migración.",
            "4": "AWS Systems Manager para gestionar y automatizar operaciones de aplicaciones en el entorno de AWS después de la migración."
        },
        "Correct Answer": "AWS Application Discovery Service para recopilar y analizar datos sobre aplicaciones locales, incluyendo su utilización de recursos y dependencias.",
        "Explanation": "AWS Application Discovery Service está diseñado específicamente para ayudar a las organizaciones a planificar su migración a AWS al identificar automáticamente las dependencias de las aplicaciones y la utilización de recursos. Esto permite una estrategia de migración más informada.",
        "Other Options": [
            "AWS CloudTrail se centra en registrar y monitorear la actividad de la API en su cuenta de AWS, lo que no proporcionaría información sobre las dependencias de las aplicaciones locales o la utilización de recursos antes de la migración.",
            "AWS Config se utiliza para monitorear y gestionar configuraciones de recursos de AWS, pero no es aplicable para analizar aplicaciones heredadas antes de la migración.",
            "AWS Systems Manager se utiliza principalmente para gestionar y operar aplicaciones en AWS, y aunque proporciona valiosas capacidades de gestión después de la migración, no ayuda en el descubrimiento de dependencias de aplicaciones locales."
        ]
    },
    {
        "Question Number": "25",
        "Situation": "Una empresa de servicios financieros está planeando migrar sus aplicaciones heredadas locales a AWS. La empresa tiene varias cargas de trabajo, algunas de las cuales son críticas para las operaciones comerciales, mientras que otras son menos urgentes. Se ha formado un equipo de migración, y necesitan priorizar qué cargas de trabajo migrar primero. Quieren asegurar una mínima interrupción al negocio y maximizar los beneficios de la nube.",
        "Question": "¿Cuál es el enfoque más efectivo para que el equipo de migración priorice las cargas de trabajo para la migración a AWS?",
        "Options": {
            "1": "Priorizar las cargas de trabajo según el impacto en el negocio y la complejidad de la migración.",
            "2": "Migrar las cargas de trabajo en orden alfabético para mantener la consistencia.",
            "3": "Comenzar con las cargas de trabajo menos críticas para probar el proceso de migración.",
            "4": "Migrar todas las cargas de trabajo a la vez para minimizar el tiempo de inactividad general."
        },
        "Correct Answer": "Priorizar las cargas de trabajo según el impacto en el negocio y la complejidad de la migración.",
        "Explanation": "Este enfoque permite al equipo de migración enfocarse primero en las aplicaciones más críticas, asegurando que los servicios más importantes funcionen bien en el entorno de la nube. También ayuda a identificar cualquier desafío potencial en el proceso de migración desde el principio, lo que permite una mejor planificación a futuro.",
        "Other Options": [
            "Esta opción puede resultar en un tiempo de inactividad significativo, ya que migrar todas las cargas de trabajo a la vez puede abrumar los recursos y llevar a posibles fallas.",
            "Migrar en orden alfabético no considera las necesidades reales del negocio o la complejidad de las aplicaciones, lo que puede llevar a interrupciones e ineficiencias.",
            "Comenzar con las cargas de trabajo menos críticas puede retrasar la realización de beneficios de la nube y puede llevar a riesgos innecesarios para el negocio, ya que las cargas de trabajo más críticas quedan sin atender."
        ]
    },
    {
        "Question Number": "26",
        "Situation": "Una empresa de servicios financieros está buscando mejorar su infraestructura adoptando nuevas tecnologías y servicios gestionados para mejorar la eficiencia operativa y reducir costos. La empresa ha identificado varias áreas donde podría aprovechar soluciones nativas de la nube, pero carece de una estrategia clara para la implementación. Están considerando opciones para modernizar su arquitectura mientras aseguran el cumplimiento y la seguridad.",
        "Question": "¿Qué enfoque debería tomar la empresa para adoptar efectivamente nuevas tecnologías y servicios gestionados mientras minimiza los riesgos?",
        "Options": {
            "1": "Realizar una evaluación exhaustiva de las cargas de trabajo actuales e identificar casos de uso específicos donde los servicios gestionados pueden reemplazar la infraestructura tradicional, seguido de un plan de implementación por fases.",
            "2": "Migrar todas las aplicaciones existentes a arquitecturas sin servidor de inmediato para aprovechar las capacidades de la nube sin una evaluación detallada.",
            "3": "Implementar una estrategia de múltiples nubes distribuyendo las cargas de trabajo entre varios proveedores de nube para evitar el bloqueo del proveedor, incluso si eso complica la gestión.",
            "4": "Adoptar una estrategia de lift-and-shift para todas las aplicaciones a la nube sin rediseñarlas, asegurando cambios mínimos en su infraestructura actual."
        },
        "Correct Answer": "Realizar una evaluación exhaustiva de las cargas de trabajo actuales e identificar casos de uso específicos donde los servicios gestionados pueden reemplazar la infraestructura tradicional, seguido de un plan de implementación por fases.",
        "Explanation": "Realizar una evaluación exhaustiva permite a la empresa entender sus cargas de trabajo actuales e identificar áreas específicas que se beneficiarían de los servicios gestionados. Este enfoque reduce los riesgos asociados con una migración apresurada y permite una implementación estructurada y por fases que se alinea con los objetivos comerciales.",
        "Other Options": [
            "Migrar todas las aplicaciones existentes a arquitecturas sin servidor de inmediato sin evaluación puede llevar a problemas inesperados, incompatibilidades y costos incrementados, ya que no todas las aplicaciones son adecuadas para modelos sin servidor.",
            "Implementar una estrategia de múltiples nubes sin una necesidad clara puede complicar la gestión, aumentar los costos operativos e introducir desafíos en seguridad y cumplimiento sin proporcionar beneficios inmediatos.",
            "Una estrategia de lift-and-shift a menudo conduce a un rendimiento subóptimo y a ineficiencias de costos, ya que las aplicaciones pueden no estar completamente optimizadas para entornos de nube, perdiendo los beneficios de las características nativas de la nube."
        ]
    },
    {
        "Question Number": "27",
        "Situation": "Una empresa está evaluando qué tipos de instancias EC2 son más adecuados para sus diferentes cargas de trabajo. Tienen una aplicación web que requiere un alto rendimiento de I/O, un modelo de aprendizaje automático que necesita alta potencia de cálculo y una base de datos que requiere una capacidad de memoria significativa para almacenamiento en caché.",
        "Question": "¿Qué combinación de familias de instancias satisfaría mejor las necesidades de las cargas de trabajo de la empresa? (Seleccione Dos)",
        "Options": {
            "1": "Instancias T3 para rendimiento variable.",
            "2": "Instancias C5 para cargas de trabajo intensivas en cómputo.",
            "3": "Instancias I3 para alto rendimiento de I/O.",
            "4": "Instancias M5 para cargas de trabajo de propósito general.",
            "5": "Instancias R5 para cargas de trabajo intensivas en memoria."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Instancias I3 para alto rendimiento de I/O.",
            "Instancias C5 para cargas de trabajo intensivas en cómputo."
        ],
        "Explanation": "Las instancias I3 están optimizadas para un alto rendimiento de I/O, lo que las hace ideales para cargas de trabajo que requieren acceso rápido al almacenamiento. Las instancias C5 están diseñadas para tareas intensivas en cómputo, proporcionando un alto nivel de potencia de procesamiento, lo que es adecuado para modelos de aprendizaje automático y otras aplicaciones que requieren mucho cómputo.",
        "Other Options": [
            "Las instancias R5 están optimizadas para memoria, lo cual no es el requisito principal para un alto rendimiento de I/O o tareas intensivas en cómputo especificadas en la situación.",
            "Las instancias T3 ofrecen rendimiento variable adecuado para cargas de trabajo variables, pero no proporcionan las capacidades de I/O o cómputo necesarias para las aplicaciones especificadas.",
            "Las instancias M5 son de propósito general y no serían la mejor opción para cargas de trabajo que requieren capacidades especializadas de I/O o computacionales como se mencionó."
        ]
    },
    {
        "Question Number": "28",
        "Situation": "Una empresa está buscando optimizar sus costos de AWS implementando una estrategia de etiquetado que permita una mejor visibilidad en el uso de sus recursos en la nube. La empresa tiene múltiples unidades de negocio, cada una con diferentes presupuestos y requisitos de recursos. Necesitas asegurarte de que los recursos estén etiquetados de una manera que se alinee con estas unidades de negocio y facilite el seguimiento de costos.",
        "Question": "¿Cuál de las siguientes opciones puede ayudarte a implementar una estrategia de etiquetado efectiva para la asignación de costos? (Selecciona Dos)",
        "Options": {
            "1": "Crear una política de etiquetado que exija el uso de etiquetas específicas para todos los recursos relacionados con cada unidad de negocio.",
            "2": "Implementar AWS Cost Explorer para analizar los costos asociados con etiquetas específicas.",
            "3": "Utilizar AWS Budgets para monitorear el gasto por unidad de negocio sin requerir etiquetas.",
            "4": "Utilizar AWS CloudTrail para rastrear las llamadas a la API relacionadas con la creación y etiquetado de recursos.",
            "5": "Hacer cumplir el cumplimiento de etiquetado utilizando reglas de AWS Config que evalúan las etiquetas de los recursos."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Crear una política de etiquetado que exija el uso de etiquetas específicas para todos los recursos relacionados con cada unidad de negocio.",
            "Implementar AWS Cost Explorer para analizar los costos asociados con etiquetas específicas."
        ],
        "Explanation": "Crear una política de etiquetado asegura que todos los recursos estén etiquetados de manera consistente según las unidades de negocio, facilitando el seguimiento efectivo de los costos. AWS Cost Explorer te permite analizar los costos basados en las etiquetas que defines, lo que permite visibilidad en el gasto por unidad de negocio.",
        "Other Options": [
            "AWS Budgets puede monitorear el gasto, pero no requiere inherentemente etiquetado para su funcionamiento, lo que lo hace menos efectivo para implementar una estrategia de etiquetado.",
            "AWS CloudTrail es útil para auditar las llamadas a la API, pero no contribuye directamente a las estrategias de etiquetado o asignación de costos.",
            "Las reglas de AWS Config pueden hacer cumplir el cumplimiento de etiquetado, pero no ayudan en el análisis real de los costos asociados con esas etiquetas."
        ]
    },
    {
        "Question Number": "29",
        "Situation": "Una organización de servicios financieros está migrando sus aplicaciones a AWS. La organización requiere un método seguro para gestionar identidades de usuario y permisos de acceso a través de múltiples cuentas de AWS. Quieren implementar una solución que permita a los usuarios tener acceso de inicio de sesión único (SSO) a varios servicios de AWS mientras mantienen un control de acceso detallado. La organización ya está utilizando un directorio corporativo para la gestión de usuarios.",
        "Question": "¿Cuál de los siguientes enfoques cumpliría mejor con los requisitos de la organización para gestionar el acceso de usuarios a través de múltiples cuentas de AWS?",
        "Options": {
            "1": "Crear usuarios de IAM en cada cuenta de AWS y gestionar manualmente sus permisos de acceso. Utilizar AWS Organizations para consolidar la facturación.",
            "2": "Utilizar roles de AWS IAM y establecer acceso a roles entre cuentas para cada usuario, requiriendo gestión manual de credenciales para cada usuario.",
            "3": "Configurar AWS IAM Identity Center (AWS SSO) y conectarlo al directorio corporativo. Crear conjuntos de permisos para definir los niveles de acceso de los usuarios a través de las cuentas de AWS.",
            "4": "Desplegar una solución de federación de identidades utilizando AWS Cognito para gestionar identidades de usuario y permisos de acceso a través de cuentas de AWS."
        },
        "Correct Answer": "Configurar AWS IAM Identity Center (AWS SSO) y conectarlo al directorio corporativo. Crear conjuntos de permisos para definir los niveles de acceso de los usuarios a través de las cuentas de AWS.",
        "Explanation": "Utilizar AWS IAM Identity Center (AWS SSO) permite la gestión centralizada de identidades de usuario y permisos de acceso a través de múltiples cuentas con capacidades de inicio de sesión único, lo que se alinea directamente con los requisitos de la organización para seguridad y facilidad de uso.",
        "Other Options": [
            "Crear usuarios de IAM en cada cuenta es ineficiente y no proporciona una solución de gestión centralizada. Este enfoque aumenta la carga administrativa y la complejidad, ya que los permisos deben gestionarse por separado en cada cuenta.",
            "Si bien AWS Cognito puede gestionar identidades de usuario, está diseñado principalmente para aplicaciones web y móviles y no proporciona el mismo nivel de integración y gestión para el acceso a servicios de AWS a través de múltiples cuentas como lo hace AWS IAM Identity Center.",
            "Utilizar roles de IAM para acceso entre cuentas requiere que los usuarios gestionen sus propias credenciales y no proporciona una experiencia SSO simple. Este enfoque puede llevar a riesgos de seguridad y aumentar la complejidad en la gestión de credenciales."
        ]
    },
    {
        "Question Number": "30",
        "Situation": "Una empresa de servicios financieros opera múltiples cuentas de AWS para gestionar sus diversas unidades de negocio. Cada cuenta requiere la capacidad de recibir notificaciones de eventos de un tema centralizado de Amazon SNS cuando se modifican recursos específicos de AWS. El arquitecto de soluciones necesita asegurarse de que las notificaciones de eventos se entreguen a todas las cuentas relevantes mientras se adhiere a las mejores prácticas de seguridad y gestión.",
        "Question": "¿Cuál es la forma más efectiva de configurar notificaciones de eventos entre cuentas utilizando servicios de AWS?",
        "Options": {
            "1": "Utilizar AWS Lambda en la cuenta maestra para sondear eventos de cada cuenta miembro y luego publicar esos eventos en un tema centralizado de Amazon SNS.",
            "2": "Desplegar un bus de eventos de Amazon EventBridge en cada cuenta miembro y configurar una regla para enviar eventos a un tema de Amazon SNS en la cuenta maestra.",
            "3": "Crear un tema de Amazon SNS en la cuenta maestra y configurar permisos entre cuentas para cada cuenta miembro que les permita suscribirse al tema.",
            "4": "Configurar reglas de AWS Config en cada cuenta miembro que activen una función de AWS Step para enviar notificaciones a un tema de Amazon SNS en la cuenta maestra."
        },
        "Correct Answer": "Crear un tema de Amazon SNS en la cuenta maestra y configurar permisos entre cuentas para cada cuenta miembro que les permita suscribirse al tema.",
        "Explanation": "Crear un tema de Amazon SNS en la cuenta maestra y configurar permisos entre cuentas permite que todas las cuentas miembros se suscriban de manera segura al tema centralizado. Este enfoque simplifica el proceso de notificación y se adhiere a las mejores prácticas para arquitecturas de múltiples cuentas.",
        "Other Options": [
            "Desplegar un bus de eventos de Amazon EventBridge en cada cuenta miembro agrega complejidad innecesaria, ya que el objetivo es centralizar las notificaciones en la cuenta maestra. Esta opción requeriría configuraciones adicionales para el reenvío de eventos.",
            "Utilizar AWS Lambda para sondear eventos de cada cuenta miembro crea sobrecarga y podría llevar a retrasos y costos incrementados. Usar directamente SNS con suscripciones entre cuentas es más eficiente.",
            "Configurar reglas de AWS Config genera eventos para cambios de recursos, pero no facilita directamente las notificaciones. Esta opción carece de la integración directa y eficiencia que proporciona un tema de SNS."
        ]
    },
    {
        "Question Number": "31",
        "Situation": "Una startup ejecuta una aplicación web en instancias de Amazon EC2 que experimentan cargas de trabajo variables a lo largo del día. La startup está preocupada por reducir costos mientras asegura que la aplicación siga siendo receptiva durante los momentos de mayor demanda. Actualmente utilizan instancias bajo demanda, pero quieren explorar opciones más rentables sin sacrificar el rendimiento.",
        "Question": "¿Qué opción de arquitectura debería recomendar el arquitecto de soluciones para optimizar costos mientras mantiene el rendimiento de la aplicación?",
        "Options": {
            "1": "Migrar la aplicación a AWS Lambda para evitar aprovisionar instancias de EC2 por completo y aprovechar la tarificación sin servidor.",
            "2": "Desplegar todas las instancias de EC2 como instancias bajo demanda y aumentar el tamaño de las instancias durante las horas pico para manejar el tráfico.",
            "3": "Utilizar instancias reservadas para todas las instancias de EC2 para asegurar que la aplicación esté siempre disponible a un costo menor.",
            "4": "Implementar Auto Scaling con una combinación de instancias bajo demanda y Spot, permitiendo ahorros de costos durante las horas de menor demanda."
        },
        "Correct Answer": "Implementar Auto Scaling con una combinación de instancias bajo demanda y Spot, permitiendo ahorros de costos durante las horas de menor demanda.",
        "Explanation": "Usar Auto Scaling con una combinación de instancias bajo demanda y Spot permite a la startup adaptarse dinámicamente a los cambios en la carga de trabajo mientras logra ahorros de costos significativos al aprovechar las instancias Spot de menor costo durante los períodos de menor demanda.",
        "Other Options": [
            "Migrar la aplicación a AWS Lambda puede no ser factible si la aplicación requiere un estado persistente o tiene procesos de larga duración, ya que Lambda es más adecuada para tareas de corta duración y basadas en eventos.",
            "Utilizar instancias reservadas para todas las instancias de EC2 compromete a la startup a un compromiso a largo plazo, lo cual puede no ser óptimo dada su carga de trabajo variable y situación financiera.",
            "Desplegar todas las instancias de EC2 como instancias bajo demanda sin considerar instancias Spot o Auto Scaling probablemente llevará a costos más altos y no proporcionará la flexibilidad necesaria durante los momentos de mayor y menor demanda."
        ]
    },
    {
        "Question Number": "32",
        "Situation": "Una empresa de servicios financieros está buscando migrar su carga de trabajo local a AWS. La arquitectura actual consiste en una aplicación monolítica que se ejecuta en servidores dedicados, lo que dificulta la escalabilidad y el mantenimiento. La empresa tiene un requisito estricto de cumplimiento para la integridad y seguridad de los datos. Están evaluando varios servicios de AWS que puedan apoyar una estrategia de migración gradual y asegurar una mínima interrupción en las operaciones comerciales.",
        "Question": "¿Cuál de las siguientes opciones debería recomendar el arquitecto de soluciones para migrar las cargas de trabajo existentes a AWS mientras aborda los requisitos de escalabilidad y cumplimiento?",
        "Options": {
            "1": "Levantar y trasladar toda la aplicación a instancias de Amazon EC2 mientras se implementa AWS Shield para mayor seguridad.",
            "2": "Reestructurar la aplicación utilizando AWS Elastic Beanstalk con un bucket de Amazon S3 para la distribución de contenido estático.",
            "3": "Refactorizar la aplicación en microservicios utilizando AWS Lambda, con datos almacenados en Amazon RDS para la integridad transaccional.",
            "4": "Contenerizar la aplicación utilizando Amazon ECS y desplegarla con Amazon EFS para acceso a almacenamiento compartido."
        },
        "Correct Answer": "Refactorizar la aplicación en microservicios utilizando AWS Lambda, con datos almacenados en Amazon RDS para la integridad transaccional.",
        "Explanation": "Refactorizar la aplicación en microservicios utilizando AWS Lambda permite una mejor escalabilidad y flexibilidad. Al usar Amazon RDS, la empresa puede asegurar que cumple con sus requisitos de integridad de datos y cumplimiento mientras aprovecha la arquitectura sin servidor para la eficiencia de costos y la reducción de la carga operativa.",
        "Other Options": [
            "Levantar y trasladar no aborda los problemas de escalabilidad y mantenimiento inherentes a una arquitectura monolítica, y depender únicamente de AWS Shield no asegura el cumplimiento con los requisitos de integridad de datos.",
            "Si bien usar AWS Elastic Beanstalk puede simplificar el despliegue, puede no aprovechar completamente los beneficios de la arquitectura sin servidor, lo que podría limitar la escalabilidad y flexibilidad para una aplicación en crecimiento.",
            "Contenerizar la aplicación con Amazon ECS introduce complejidad relacionada con la gestión y orquestación de contenedores, lo que puede no alinearse con el objetivo de una estrategia de migración gradual."
        ]
    },
    {
        "Question Number": "33",
        "Situation": "Una empresa de servicios financieros está implementando una estrategia de recuperación ante desastres (DR) para sus aplicaciones críticas alojadas en Amazon EC2. Necesitan una solución que asegure un tiempo de inactividad mínimo y pérdida de datos en caso de un desastre. La empresa está considerando varias opciones para lograr una arquitectura de DR resiliente.",
        "Question": "¿Qué estrategia de recuperación ante desastres debería recomendar el arquitecto de soluciones para asegurar la máxima disponibilidad con mínima pérdida de datos?",
        "Options": {
            "1": "Configurar una arquitectura de espera cálida con una instancia de EC2 ejecutándose en otra región que pueda escalar rápidamente durante un desastre.",
            "2": "Implementar una configuración activa-activa en múltiples regiones de AWS utilizando Amazon Route 53 para la distribución del tráfico.",
            "3": "Usar Amazon S3 para almacenamiento de copias de seguridad y establecer una política de ciclo de vida para eliminar copias de seguridad antiguas después de un período definido.",
            "4": "Desplegar una estrategia de DR de luz piloto manteniendo una huella mínima de la aplicación en una región secundaria que pueda ser activada rápidamente."
        },
        "Correct Answer": "Implementar una configuración activa-activa en múltiples regiones de AWS utilizando Amazon Route 53 para la distribución del tráfico.",
        "Explanation": "Una configuración activa-activa asegura que la aplicación esté completamente operativa en múltiples regiones, proporcionando así la máxima disponibilidad y minimizando el tiempo de inactividad. Esta configuración permite una distribución de tráfico y balanceo de carga sin interrupciones utilizando Amazon Route 53, resultando en una robusta solución de recuperación ante desastres.",
        "Other Options": [
            "Usar Amazon S3 para almacenamiento de copias de seguridad e implementar una política de ciclo de vida no proporciona capacidades de conmutación por error inmediatas. Si bien es esencial para la retención de datos, no minimiza el tiempo de inactividad durante un desastre, lo cual es un requisito crítico.",
            "Una arquitectura de espera cálida implica mantener una versión reducida de la aplicación que puede escalar rápidamente, pero aún puede llevar a algún tiempo de inactividad. Este enfoque no asegura el mismo nivel de disponibilidad que una configuración activa-activa.",
            "Una estrategia de DR de luz piloto requiere más tiempo para activar completamente el entorno secundario en comparación con una configuración activa-activa. Si bien es un enfoque rentable, no proporciona la disponibilidad inmediata necesaria durante un desastre, lo que puede llevar a una posible pérdida de datos y interrupción del servicio."
        ]
    },
    {
        "Question Number": "34",
        "Situation": "Una empresa está implementando una aplicación altamente disponible en AWS que requiere baja latencia y alto rendimiento. Están considerando usar Elastic Load Balancing para distribuir el tráfico entrante entre múltiples objetivos. La aplicación será accesible desde varias ubicaciones geográficas, y la empresa necesita asegurarse de que el tráfico se enrute de manera eficiente. También quieren configurar direcciones IP estáticas para una mejor integración con su red local.",
        "Question": "¿Qué combinación de características debería aprovechar la empresa para cumplir con estos requisitos? (Seleccione dos)",
        "Options": {
            "1": "Implementar un Application Load Balancer para manejar solo conexiones WebSocket.",
            "2": "Implementar un Network Load Balancer con direcciones IP estáticas en cada Zona de Disponibilidad.",
            "3": "Usar un Application Load Balancer con sesiones persistentes configuradas.",
            "4": "Utilizar el Network Load Balancer para crear un servicio de punto final de VPC.",
            "5": "Configurar el Network Load Balancer para usar grupos de seguridad para el control del tráfico entrante."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Implementar un Network Load Balancer con direcciones IP estáticas en cada Zona de Disponibilidad.",
            "Utilizar el Network Load Balancer para crear un servicio de punto final de VPC."
        ],
        "Explanation": "Implementar un Network Load Balancer con direcciones IP estáticas permite a la empresa mantener direcciones IP conocidas para una conectividad más fácil desde su red local, mientras que usar el Network Load Balancer para un servicio de punto final de VPC asegura un enrutamiento eficiente del tráfico hacia sus objetivos de aplicación dentro de la VPC.",
        "Other Options": [
            "Usar un Application Load Balancer con sesiones persistentes no es adecuado porque el requisito especifica la necesidad de direcciones IP estáticas y alto rendimiento, que son mejor manejados por un Network Load Balancer.",
            "Implementar un Application Load Balancer únicamente para conexiones WebSocket no aborda la necesidad de IPs estáticas y puede no proporcionar el mejor rendimiento para todos los tipos de tráfico.",
            "Configurar el Network Load Balancer para usar grupos de seguridad es incorrecto porque los Network Load Balancers no admiten grupos de seguridad, ya que operan a nivel de conexión y no a nivel de instancia."
        ]
    },
    {
        "Question Number": "35",
        "Situation": "Una empresa está utilizando AWS CloudFormation para gestionar su infraestructura. La empresa quiere almacenar de manera segura información sensible como contraseñas de bases de datos y claves API sin codificarlas en las plantillas. Deciden utilizar Systems Manager Parameter Store para lograr esto. El arquitecto de soluciones necesita hacer referencia a estos parámetros en la plantilla de CloudFormation.",
        "Question": "¿Cuál de las siguientes configuraciones en la plantilla de CloudFormation haría referencia correctamente a un parámetro de Systems Manager?",
        "Options": {
            "1": "Parameters: MyParameter: Type: AWS::SSM::Parameter::Value<String> Default: /myapp/dbpassword",
            "2": "Parameters: MyParameter: Type: AWS::SSM::Parameter::Value<String> Value: /myapp/dbpassword",
            "3": "Parameters: MyParameter: Type: AWS::SSM::Parameter::Value<String>",
            "4": "Parameters: MyParameter: Type: String Default: /myapp/dbpassword"
        },
        "Correct Answer": "Parameters: MyParameter: Type: AWS::SSM::Parameter::Value<String> Default: /myapp/dbpassword",
        "Explanation": "La opción correcta utiliza la sintaxis apropiada para definir un parámetro de Systems Manager en CloudFormation. Especifica el tipo correctamente como AWS::SSM::Parameter::Value<String> y proporciona un valor predeterminado válido, lo que permite a CloudFormation recuperar el parámetro de Parameter Store.",
        "Other Options": [
            "Esta opción es incorrecta porque no especifica un valor predeterminado, que es necesario para que CloudFormation recupere el parámetro de Systems Manager.",
            "Esta opción es incorrecta porque, aunque especifica el tipo correctamente, no define un valor predeterminado. La ausencia de un valor predeterminado significa que CloudFormation no puede recuperar el parámetro.",
            "Esta opción es incorrecta porque la clave 'Value' no es válida en este contexto. En su lugar, el enfoque correcto es usar 'Default' para especificar la clave del parámetro."
        ]
    },
    {
        "Question Number": "36",
        "Situation": "Una organización está planeando migrar su base de datos Oracle local a Amazon RDS para Oracle. La base de datos tiene varias características que son críticas para las operaciones de la organización. El administrador de la base de datos necesita asegurarse de que todas las características necesarias sean compatibles en el entorno de RDS.",
        "Question": "¿Cuál de las siguientes características de Oracle Database NO es compatible al usar Amazon RDS para Oracle?",
        "Options": {
            "1": "Real Application Clusters (Oracle RAC)",
            "2": "Automatic Storage Management (ASM)",
            "3": "Integración con Amazon S3 para transferencia de datos",
            "4": "Replicación entre regiones para MySQL"
        },
        "Correct Answer": "Real Application Clusters (Oracle RAC)",
        "Explanation": "Amazon RDS para Oracle no admite Real Application Clusters (Oracle RAC). Esta es una limitación clave a considerar al migrar una base de datos Oracle, ya que RAC está diseñado para proporcionar alta disponibilidad y escalabilidad a través de características de agrupamiento, que no están disponibles en RDS.",
        "Other Options": [
            "Automatic Storage Management (ASM) no es compatible en Amazon RDS para Oracle, pero esta opción no se indica explícitamente ya que la pregunta pide una característica que es compatible. Por lo tanto, esta opción es engañosa.",
            "La replicación entre regiones para MySQL es una característica que es compatible en RDS, pero no está relacionada con bases de datos Oracle y, por lo tanto, no aborda el enfoque de la pregunta sobre características de Oracle.",
            "La integración con Amazon S3 para la transferencia de datos es una característica compatible de Amazon RDS para Oracle, lo que permite transferencias de datos seguras y eficientes, haciendo que esta opción sea incorrecta ya que no se alinea con la pregunta."
        ]
    },
    {
        "Question Number": "37",
        "Situation": "Una empresa de medios utiliza Amazon S3 para almacenar imágenes y archivos de video. Han habilitado el versionado en su bucket de S3 para mantener múltiples versiones de sus archivos multimedia. El arquitecto de soluciones necesita asegurarse de que la empresa pueda recuperar archivos eliminados y gestionar versiones de manera efectiva, mientras implementa las medidas de seguridad adecuadas.",
        "Question": "Cuando se sube un archivo llamado video.mp4 a un bucket de S3 con versionado habilitado que ya contiene una versión del mismo archivo, ¿cuál de las siguientes afirmaciones es verdadera respecto al manejo de la versión anterior y la nueva carga?",
        "Options": {
            "1": "Se crea una nueva versión de video.mp4, y la versión anterior permanece en el bucket sin ser sobrescrita.",
            "2": "La operación de carga falla si existe una versión anterior en el bucket.",
            "3": "Se aplica un marcador de eliminación a la versión anterior de video.mp4, convirtiéndola en la versión actual.",
            "4": "La versión anterior de video.mp4 se elimina permanentemente y no puede ser recuperada."
        },
        "Correct Answer": "Se crea una nueva versión de video.mp4, y la versión anterior permanece en el bucket sin ser sobrescrita.",
        "Explanation": "En un bucket de S3 con versionado habilitado, subir una nueva versión de un objeto existente no elimina ni sobrescribe la versión anterior. En su lugar, se asigna un nuevo ID de versión a la nueva carga, mientras que la versión anterior permanece accesible en el bucket.",
        "Other Options": [
            "Esta opción es incorrecta porque el versionado permite la retención de versiones anteriores cuando ocurren nuevas cargas, previniendo cualquier eliminación permanente a menos que se solicite específicamente.",
            "Esta opción es incorrecta porque la operación de carga en un bucket versionado siempre tendrá éxito, independientemente de si existe una versión anterior para la misma clave.",
            "Esta opción es incorrecta porque un marcador de eliminación solo se aplica cuando un objeto es eliminado explícitamente, no cuando se carga una nueva versión."
        ]
    },
    {
        "Question Number": "38",
        "Situation": "Una empresa de servicios financieros está construyendo una nueva aplicación que requiere procesamiento de transacciones en tiempo real y análisis. La aplicación debe manejar eficientemente altos volúmenes de datos con baja latencia, mientras asegura que los datos puedan ser consultados fácilmente para fines de informes. El arquitecto de soluciones está evaluando varias opciones de bases de datos para cumplir con estos requisitos.",
        "Question": "¿Cuál de las siguientes soluciones de base de datos es la más adecuada para implementar un sistema de procesamiento de transacciones en tiempo real con capacidades de consulta eficientes?",
        "Options": {
            "1": "Amazon RDS para MySQL con réplicas de lectura para manejar un alto rendimiento y proporcionar baja latencia para análisis en tiempo real.",
            "2": "Amazon Redshift para almacenamiento de datos, optimizado para consultas complejas pero no adecuado para procesamiento de transacciones en tiempo real.",
            "3": "Amazon DynamoDB con rendimiento provisionado para asegurar acceso de baja latencia para transacciones en tiempo real y alta disponibilidad para análisis.",
            "4": "Amazon Aurora con compatibilidad con PostgreSQL, utilizando sus capacidades sin servidor para escalar ante altos volúmenes de transacciones mientras mantiene el rendimiento de consulta."
        },
        "Correct Answer": "Amazon Aurora con compatibilidad con PostgreSQL, utilizando sus capacidades sin servidor para escalar ante altos volúmenes de transacciones mientras mantiene el rendimiento de consulta.",
        "Explanation": "Amazon Aurora con compatibilidad con PostgreSQL está diseñado para un alto rendimiento y puede manejar el procesamiento de transacciones en tiempo real de manera eficiente. Sus capacidades sin servidor permiten la escalabilidad automática según la demanda, asegurando que pueda acomodar altos volúmenes de transacciones mientras mantiene baja latencia para las consultas, lo que lo hace ideal para este escenario.",
        "Other Options": [
            "Amazon RDS para MySQL con réplicas de lectura no es la mejor opción para el procesamiento de transacciones en tiempo real, ya que introduce latencia debido al retraso de replicación para análisis y puede no escalar tan efectivamente como Aurora.",
            "Amazon DynamoDB es adecuado para acceso de baja latencia, pero puede no proporcionar el mismo nivel de capacidades de consulta y uniones complejas que a menudo se requieren para análisis en comparación con una base de datos relacional como Aurora.",
            "Amazon Redshift es principalmente una solución de almacenamiento de datos diseñada para consultas analíticas complejas en lugar de procesamiento de transacciones en tiempo real, lo que lo hace inadecuado para los requisitos de esta aplicación."
        ]
    },
    {
        "Question Number": "39",
        "Situation": "Una corporación multinacional ha desarrollado una aplicación móvil que permite a los usuarios autenticarse utilizando sus cuentas de Google. La aplicación necesita acceder de manera segura a los recursos de AWS en nombre de los usuarios autenticados sin requerir que gestionen las credenciales de AWS directamente. La empresa está considerando utilizar servicios de AWS para facilitar este proceso de autenticación y autorización.",
        "Question": "¿Cuál de las siguientes soluciones permitirá que la aplicación obtenga credenciales temporales de AWS para los usuarios autenticados? (Seleccione Dos)",
        "Options": {
            "1": "Implementar AssumeRoleWithWebIdentity para obtener credenciales de seguridad temporales utilizando los tokens de autenticación de Google proporcionados por los usuarios.",
            "2": "Crear un usuario IAM para cada usuario de la aplicación y distribuir sus claves de acceso para autenticación.",
            "3": "Utilizar un proveedor de identidad personalizado que se interfase con AWS STS para emitir credenciales temporales basadas en los inicios de sesión de los usuarios.",
            "4": "Usar AWS Cognito para autenticar a los usuarios y configurar un rol que permita el acceso a recursos específicos de AWS.",
            "5": "Usar AWS SSO para gestionar el acceso de los usuarios directamente y habilitar la autenticación federada para la aplicación."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Usar AWS Cognito para autenticar a los usuarios y configurar un rol que permita el acceso a recursos específicos de AWS.",
            "Implementar AssumeRoleWithWebIdentity para obtener credenciales de seguridad temporales utilizando los tokens de autenticación de Google proporcionados por los usuarios."
        ],
        "Explanation": "Tanto AWS Cognito como AssumeRoleWithWebIdentity están diseñados para proporcionar credenciales de seguridad temporales a los usuarios autenticados a través de proveedores de identidad externos como Google. AWS Cognito permite una gestión fácil de grupos de usuarios y roles, mientras que AssumeRoleWithWebIdentity facilita directamente la autenticación federada utilizando tokens de identidad web.",
        "Other Options": [
            "Crear usuarios IAM para cada usuario de la aplicación no es escalable y va en contra del propósito del acceso federado, que está diseñado para evitar la gestión de credenciales a largo plazo.",
            "AWS SSO se centra en gestionar el acceso a través de cuentas y servicios de AWS, pero no emite directamente credenciales temporales utilizando proveedores de identidad web externos.",
            "Utilizar un proveedor de identidad personalizado puede introducir complejidad innecesaria y no es un enfoque estándar para obtener credenciales temporales de AWS en comparación con el soporte integrado que ofrecen los servicios de AWS."
        ]
    },
    {
        "Question Number": "40",
        "Situation": "Una empresa global de comercio minorista en línea está migrando sus aplicaciones a AWS para mejorar el rendimiento y reducir la latencia para sus usuarios internacionales. La empresa tiene varios microservicios que se comunican entre sí a través de varios puntos de servicio de AWS. El Arquitecto de Soluciones necesita asegurarse de que las aplicaciones puedan interactuar sin problemas con los servicios de AWS mientras mantiene la seguridad y minimiza los costos.",
        "Question": "¿Cuál de las siguientes estrategias debería implementar el Arquitecto de Soluciones para optimizar el uso de los puntos de servicio de AWS? (Seleccione dos)",
        "Options": {
            "1": "Utilizar puntos de enlace de VPC para conectarse de forma privada a los servicios de AWS sin atravesar Internet.",
            "2": "Implementar AWS Global Accelerator para mejorar la disponibilidad y el rendimiento de las aplicaciones alojadas en múltiples Regiones de AWS.",
            "3": "Configurar AWS PrivateLink para acceder de forma segura a servicios alojados en otra VPC sin utilizar IPs públicas.",
            "4": "Aprovechar AWS Direct Connect para establecer una conexión de red dedicada desde el centro de datos local a AWS.",
            "5": "Usar AWS Transit Gateway para simplificar la conexión entre múltiples VPCs y redes locales."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Utilizar puntos de enlace de VPC para conectarse de forma privada a los servicios de AWS sin atravesar Internet.",
            "Configurar AWS PrivateLink para acceder de forma segura a servicios alojados en otra VPC sin utilizar IPs públicas."
        ],
        "Explanation": "El uso de puntos de enlace de VPC permite una conexión privada a los servicios de AWS sin exponer el tráfico a Internet, mejorando la seguridad y reduciendo la latencia. AWS PrivateLink proporciona una forma segura de acceder a servicios alojados en otras VPCs sin utilizar direcciones IP públicas, lo que también contribuye a la seguridad y eficiencia en la interacción de servicios.",
        "Other Options": [
            "Implementar AWS Global Accelerator es útil para mejorar el rendimiento y la disponibilidad en las Regiones, pero no aborda específicamente la optimización del uso de los puntos de servicio.",
            "Usar AWS Transit Gateway simplifica la gestión de la red y la conectividad entre VPCs, pero no optimiza directamente el uso de los puntos de servicio.",
            "Aprovechar AWS Direct Connect proporciona una conexión dedicada a AWS, lo cual es beneficioso para arquitecturas híbridas, pero no se centra en optimizar el uso de los puntos de servicio."
        ]
    },
    {
        "Question Number": "41",
        "Situation": "Una empresa está planeando migrar sus aplicaciones locales existentes a AWS para reducir costos de infraestructura y mejorar la escalabilidad. Tienen una mezcla de aplicaciones web y servicios de backend que requieren una solución de base de datos robusta. La empresa está particularmente interesada en optimizar costos sin comprometer el rendimiento. Tienen una estrategia de crecimiento a largo plazo que implica escalar su aplicación para manejar un aumento en el tráfico de usuarios y el volumen de datos.",
        "Question": "¿Cuál de las siguientes estrategias de planificación de activos se alinea mejor con los objetivos de la empresa de optimización de costos y escalabilidad en AWS?",
        "Options": {
            "1": "Adoptar una arquitectura sin servidor convirtiendo las aplicaciones web en funciones de AWS Lambda y utilizando Amazon Aurora Serverless para la base de datos para escalar automáticamente con la demanda y reducir costos.",
            "2": "Migrar las aplicaciones a AWS desplegándolas en instancias de Amazon EC2 mientras se escalan manualmente los recursos según los patrones de tráfico, lo que puede llevar a un desperdicio de recursos y costos incrementados.",
            "3": "Implementar una estrategia de migración lift-and-shift moviendo las máquinas virtuales existentes a instancias de Amazon EC2 sin hacer modificaciones a las aplicaciones. Usar Amazon RDS para la base de datos existente sin considerar la optimización de costos.",
            "4": "Re-arquitectar las aplicaciones para que se ejecuten en Amazon ECS con Fargate y migrar la base de datos a Amazon DynamoDB para mejorar la escalabilidad, pero incurrir en costos operativos más altos debido a la complejidad de la arquitectura."
        },
        "Correct Answer": "Adoptar una arquitectura sin servidor convirtiendo las aplicaciones web en funciones de AWS Lambda y utilizando Amazon Aurora Serverless para la base de datos para escalar automáticamente con la demanda y reducir costos.",
        "Explanation": "Esta opción cumple efectivamente con los objetivos de la empresa de optimización de costos y escalabilidad. Al utilizar una arquitectura sin servidor con AWS Lambda, la empresa puede reducir significativamente los costos de infraestructura, ya que solo paga por el tiempo de cómputo utilizado. Además, Amazon Aurora Serverless ofrece una solución de base de datos con escalado automático bajo demanda que ajusta la capacidad según la carga de trabajo real, proporcionando tanto rendimiento como eficiencia en costos.",
        "Other Options": [
            "Esta opción no aborda la optimización de costos de manera efectiva, ya que implica un enfoque lift-and-shift que podría llevar a costos operativos más altos sin aprovechar las características de escalabilidad de AWS.",
            "Si bien esta opción sugiere una solución escalable, usar Amazon DynamoDB puede no proporcionar las mismas características de base de datos relacional que podrían ser necesarias para las aplicaciones existentes, y puede llevar a una mayor complejidad.",
            "Este enfoque puede llevar a una utilización ineficiente de los recursos, ya que el escalado manual puede resultar en sobreaprovisionamiento o subaprovisionamiento de recursos, aumentando en última instancia los costos sin lograr una escalabilidad óptima."
        ]
    },
    {
        "Question Number": "42",
        "Situation": "Una empresa global de retail opera tanto un centro de datos local como recursos en la nube de AWS para gestionar su inventario y plataforma de comercio electrónico. La empresa quiere asegurarse de que las consultas DNS de su infraestructura local puedan resolver tanto nombres de dominio internos como externos sin problemas. Además, quieren implementar una solución que permita características avanzadas de DNS como el reenvío condicional y el registro de consultas DNS. Están considerando usar Amazon Route 53 Resolver para lograr este objetivo.",
        "Question": "¿Cuál de las siguientes opciones proporciona la integración MÁS eficiente de DNS local con Amazon Route 53 Resolver mientras minimiza la latencia y la sobrecarga de gestión?",
        "Options": {
            "1": "Configurar un punto de entrada de Route 53 Resolver en la VPC. Configurar un reenvío condicional en el servidor DNS local para reenviar consultas para dominios alojados en AWS al Resolver. Implementar el registro de consultas DNS en Route 53 para monitorear patrones de tráfico.",
            "2": "Crear una zona privada alojada de Route 53 para nombres de dominio internos y un punto de salida en la VPC. Apuntar los servidores DNS locales al punto de salida para resolver recursos de AWS, mientras se mantiene la resolución de DNS externa separada.",
            "3": "Establecer una conexión VPN entre el centro de datos local y AWS, y configurar el servidor DNS local para resolver nombres de dominio de AWS directamente. Usar Route 53 para la gestión de DNS externa, pero no integrar con DNS local.",
            "4": "Desplegar una instancia de EC2 como un proxy DNS dentro de la VPC que reenvíe todas las consultas DNS al servidor DNS local. Configurar el DNS local para reenviar solicitudes de recursos de AWS a la instancia de EC2. Utilizar Amazon CloudWatch para monitorear consultas DNS."
        },
        "Correct Answer": "Configurar un punto de entrada de Route 53 Resolver en la VPC. Configurar un reenvío condicional en el servidor DNS local para reenviar consultas para dominios alojados en AWS al Resolver. Implementar el registro de consultas DNS en Route 53 para monitorear patrones de tráfico.",
        "Explanation": "Al configurar un punto de entrada de Route 53 Resolver, el DNS local puede reenviar consultas para dominios alojados en AWS directamente a Route 53, permitiendo una integración sin problemas. Esto minimiza la latencia ya que las consultas se resuelven dentro del entorno de AWS, y permite el uso de características avanzadas como el reenvío condicional y el registro de consultas, simplificando la gestión.",
        "Other Options": [
            "Desplegar una instancia de EC2 como un proxy DNS añade complejidad innecesaria y sobrecarga de gestión. Aumenta la latencia ya que cada consulta DNS requiere enrutamiento a través de una capa adicional, lo cual no es óptimo en comparación con la integración directa con Route 53 Resolver.",
            "Establecer una conexión VPN y permitir que el servidor DNS local resuelva nombres de dominio de AWS directamente carece de las características avanzadas de Route 53 Resolver. Este enfoque no proporciona las capacidades de reenvío condicional o registro, limitando las capacidades de gestión de DNS de la empresa.",
            "Crear una zona privada alojada y un punto de salida permite la resolución de dominios internos, pero no facilita la integración sin problemas para consultas externas. Además, apuntar los servidores DNS locales a los puntos de salida limita los beneficios de Route 53 Resolver, como el reenvío condicional."
        ]
    },
    {
        "Question Number": "43",
        "Situation": "Una empresa de servicios financieros está experimentando patrones de uso impredecibles y costos crecientes para sus instancias de Amazon EC2 y almacenamiento de Amazon S3. La empresa desea optimizar sus recursos de manera efectiva utilizando herramientas de visibilidad de AWS para obtener mejores conocimientos sobre su utilización de recursos. Se ha encargado al arquitecto de soluciones identificar el mejor enfoque para evaluar y optimizar el uso de estos recursos.",
        "Question": "¿Cuál de las siguientes herramientas debería utilizar el arquitecto de soluciones para analizar y optimizar efectivamente los recursos de computación y almacenamiento?",
        "Options": {
            "1": "Implementar AWS Trusted Advisor para las mejores prácticas generales y AWS Budgets para rastrear el gasto en recursos.",
            "2": "Utilizar AWS Compute Optimizer para evaluar el uso de instancias de EC2 y Amazon S3 Storage Lens para obtener información sobre la optimización del almacenamiento.",
            "3": "Usar AWS Cost Explorer para analizar patrones de gasto y AWS CloudTrail para monitorear el uso de la API de recursos.",
            "4": "Aprovechar AWS Config para evaluar el cumplimiento y Amazon CloudWatch para el monitoreo en tiempo real del rendimiento de los recursos."
        },
        "Correct Answer": "Utilizar AWS Compute Optimizer para evaluar el uso de instancias de EC2 y Amazon S3 Storage Lens para obtener información sobre la optimización del almacenamiento.",
        "Explanation": "AWS Compute Optimizer proporciona recomendaciones para optimizar los tipos de instancias de EC2 basadas en el uso real, mientras que Amazon S3 Storage Lens ofrece información sobre los patrones de uso del almacenamiento, ayudando a identificar oportunidades de ahorro de costos tanto en recursos de computación como de almacenamiento.",
        "Other Options": [
            "AWS Trusted Advisor ofrece mejores prácticas generales, pero no proporciona información específica sobre la utilización o optimización de recursos para EC2 y S3. AWS Budgets se centra en el seguimiento de costos en lugar de la optimización de recursos.",
            "AWS Cost Explorer ayuda a analizar patrones de gasto, pero no proporciona recomendaciones de optimización directa para recursos de computación y almacenamiento. AWS CloudTrail se utiliza principalmente para monitorear llamadas a la API y no ayuda en la optimización de recursos.",
            "AWS Config se utiliza para evaluar el cumplimiento de los recursos y asegurar que cumplan con ciertos criterios, pero no se centra en la optimización del rendimiento. Amazon CloudWatch es útil para el monitoreo, pero no proporciona información específica para optimizar la asignación de recursos o costos."
        ]
    },
    {
        "Question Number": "44",
        "Situation": "Una empresa está migrando su base de datos local a AWS. El esquema de la base de datos es complejo y necesita ser convertido para coincidir con el formato de una instancia de Amazon RDS. La empresa ha decidido utilizar la AWS Schema Conversion Tool (AWS SCT) para manejar la migración de manera eficiente. También planean usar un dispositivo AWS Snowball Edge para transferir sus datos de forma segura y por etapas. Además, requieren transformaciones debido a diferencias significativas entre las bases de datos de origen y destino.",
        "Question": "¿Cuál de las siguientes describe mejor cómo se pueden utilizar la AWS Schema Conversion Tool (AWS SCT) y un agente de AWS SCT para facilitar el proceso de migración de la base de datos?",
        "Options": {
            "1": "Confiar únicamente en AWS SCT para realizar tanto la conversión del esquema como la extracción de datos, eliminando la necesidad de agentes externos en el proceso de migración.",
            "2": "Usar AWS SCT para convertir el esquema de la base de datos y conectarse directamente a la instancia de Amazon RDS de destino para la migración de datos, sin necesidad de un agente.",
            "3": "Emplear AWS SCT para la conversión del esquema y usar funciones de AWS Lambda para transformar los datos a medida que se migran a la instancia de Amazon RDS de destino.",
            "4": "Utilizar AWS SCT para convertir el esquema y desplegar un agente de AWS SCT en una instancia de Amazon EC2 para manejar transformaciones adicionales de datos durante la migración."
        },
        "Correct Answer": "Utilizar AWS SCT para convertir el esquema y desplegar un agente de AWS SCT en una instancia de Amazon EC2 para manejar transformaciones adicionales de datos durante la migración.",
        "Explanation": "La respuesta correcta destaca el uso combinado de AWS SCT para la conversión del esquema y un agente de AWS SCT para la transformación de datos. El agente puede realizar las transformaciones necesarias en una instancia de EC2, lo cual es esencial cuando las bases de datos de origen y destino difieren significativamente.",
        "Other Options": [
            "Esta opción es incorrecta porque, aunque AWS SCT puede convertir esquemas de bases de datos, no puede conectarse directamente a la instancia de Amazon RDS de destino para la migración de datos sin un agente para transformaciones complejas.",
            "Esta opción es incorrecta ya que sugiere confiar únicamente en AWS SCT para tanto la conversión del esquema como la extracción de datos, lo cual no es factible para escenarios que requieren transformaciones complejas.",
            "Esta opción es incorrecta porque las funciones de AWS Lambda no están integradas con AWS SCT para el propósito de transformación de datos durante la migración, ya que el papel del agente está específicamente diseñado para estas tareas."
        ]
    },
    {
        "Question Number": "45",
        "Situation": "Una empresa de servicios financieros está migrando su aplicación crítica a AWS. La aplicación requiere almacenamiento de baja latencia y alto rendimiento para manejar grandes volúmenes de transacciones de manera eficiente. El arquitecto de soluciones necesita elegir el tipo de volumen de Amazon EBS más adecuado que cumpla con estos requisitos de rendimiento mientras equilibra costo y durabilidad.",
        "Question": "¿Cuál de los siguientes tipos de volúmenes de Amazon EBS debería seleccionar el arquitecto de soluciones para asegurar un rendimiento y durabilidad óptimos para la aplicación?",
        "Options": {
            "1": "Volúmenes gp2, que ofrecen un equilibrio de precio y rendimiento adecuado para cargas de trabajo generales, pero pueden no satisfacer altas demandas de transacciones.",
            "2": "Volúmenes st1, diseñados para cargas de trabajo intensivas en rendimiento, pero que carecen del rendimiento necesario para aplicaciones de baja latencia.",
            "3": "Volúmenes io2, que proporcionan alto rendimiento, baja latencia y 99.999% de durabilidad, ideales para cargas de trabajo transaccionales.",
            "4": "Volúmenes sc1, que son la opción de menor costo, pero no son adecuados para requisitos de acceso frecuente o baja latencia."
        },
        "Correct Answer": "Volúmenes io2, que proporcionan alto rendimiento, baja latencia y 99.999% de durabilidad, ideales para cargas de trabajo transaccionales.",
        "Explanation": "Los volúmenes io2 están diseñados específicamente para cargas de trabajo transaccionales sensibles a la latencia, ofreciendo el más alto rendimiento y durabilidad con un máximo de IOPS de 64,000 y una durabilidad del 99.999%. Esto los convierte en la mejor opción para la aplicación de servicios financieros.",
        "Other Options": [
            "Los volúmenes gp2 pueden proporcionar un buen equilibrio para cargas de trabajo generales, pero pueden no ofrecer la latencia baja y el alto rendimiento consistentes requeridos para aplicaciones financieras críticas.",
            "Los volúmenes st1 son opciones de HDD de bajo costo que sobresalen en rendimiento, pero no están diseñados para cargas de trabajo de baja latencia, lo que los hace inadecuados para este escenario.",
            "Los volúmenes sc1 están optimizados para datos de acceso poco frecuente y almacenamiento en frío, lo que no cumpliría con las necesidades de rendimiento de una aplicación de alta demanda y baja latencia."
        ]
    },
    {
        "Question Number": "46",
        "Situation": "Una empresa de servicios financieros está experimentando problemas de rendimiento con su sistema de procesamiento de transacciones en línea alojado en Amazon RDS. La aplicación está teniendo tiempos de respuesta lentos durante los períodos de mayor uso, y el equipo de gestión quiere identificar y resolver los cuellos de botella de rendimiento. La empresa está considerando soluciones que puedan proporcionar información sobre el rendimiento de las consultas y la utilización de recursos, minimizando al mismo tiempo los cambios en la arquitectura existente.",
        "Question": "¿Cuál de las siguientes opciones es la forma más efectiva de identificar cuellos de botella de rendimiento en la base de datos de Amazon RDS?",
        "Options": {
            "1": "Implementar alarmas de Amazon CloudWatch para monitorear las métricas de CPU y disco I/O de la instancia de RDS. Cuando se superen los umbrales, revisar manualmente las métricas de rendimiento de la base de datos para identificar posibles cuellos de botella.",
            "2": "Utilizar AWS CloudTrail para registrar las llamadas a la API realizadas a la instancia de RDS y recopilar información sobre los patrones de uso de la base de datos. Analizar los registros para identificar cualquier problema de contención de recursos durante los períodos pico.",
            "3": "Habilitar Amazon RDS Performance Insights para analizar la carga de la base de datos e identificar consultas problemáticas. Usar el panel para monitorear el uso de CPU, memoria y I/O a lo largo del tiempo. Optimizar las consultas identificadas en función de los conocimientos proporcionados.",
            "4": "Habilitar el monitoreo mejorado en la instancia de RDS para capturar métricas detalladas sobre el rendimiento del sistema operativo. Revisar las métricas a nivel de SO para determinar si los recursos subyacentes del servidor son la causa de los problemas de rendimiento."
        },
        "Correct Answer": "Habilitar Amazon RDS Performance Insights para analizar la carga de la base de datos e identificar consultas problemáticas. Usar el panel para monitorear el uso de CPU, memoria y I/O a lo largo del tiempo. Optimizar las consultas identificadas en función de los conocimientos proporcionados.",
        "Explanation": "Amazon RDS Performance Insights proporciona una herramienta poderosa para analizar el rendimiento de la base de datos. Ofrece una representación visual de la carga de la base de datos y permite a los usuarios profundizar en consultas específicas que pueden estar causando cuellos de botella de rendimiento. Este enfoque minimiza la necesidad de cambios extensos en la arquitectura mientras proporciona información útil para la optimización.",
        "Other Options": [
            "AWS CloudTrail se utiliza principalmente para registrar y monitorear llamadas a la API. No proporciona información directa sobre el rendimiento de la base de datos o la utilización de recursos, lo que lo hace menos efectivo para identificar cuellos de botella de rendimiento en RDS.",
            "Si bien Amazon CloudWatch puede monitorear métricas de CPU e I/O, revisar manualmente las métricas cuando se superan los umbrales no es tan efectivo como aprovechar una herramienta de análisis de rendimiento dedicada como Performance Insights, que ofrece información más profunda sobre el rendimiento de las consultas y el uso de recursos.",
            "El monitoreo mejorado proporciona métricas a nivel de SO, pero puede no correlacionarse directamente con problemas de rendimiento de la base de datos. Carece de la información enfocada sobre el rendimiento de las consultas y la distribución de carga que proporciona Performance Insights, lo que lo hace menos relevante para identificar cuellos de botella en RDS."
        ]
    },
    {
        "Question Number": "47",
        "Situation": "Una empresa tiene dos cuentas de AWS: una cuenta de desarrollo y una cuenta de producción. La cuenta de desarrollo alberga a un equipo de desarrolladores y operadores que necesitan acceso para crear y gestionar la infraestructura de la aplicación. Para mantener la seguridad y la gobernanza, la empresa desea proporcionar acceso controlado a la cuenta de producción, donde se despliega la aplicación. La empresa ha configurado grupos y usuarios de IAM en ambas cuentas de acuerdo con las mejores prácticas.",
        "Question": "¿Cómo debería la empresa configurar los roles y políticas de IAM para permitir que los desarrolladores y operadores en la cuenta de desarrollo accedan de manera segura a la cuenta de producción, cumpliendo con el principio de menor privilegio?",
        "Options": {
            "1": "Crear un rol de IAM compartido en la cuenta de desarrollo con permisos para gestionar la infraestructura de la aplicación, y permitir que la cuenta de producción asuma este rol.",
            "2": "Crear un grupo de IAM en la cuenta de producción con permisos para la gestión de aplicaciones y agregar directamente a los usuarios de IAM de la cuenta de desarrollo a este grupo.",
            "3": "Crear un rol de IAM compartido en la cuenta de producción con permisos para crear y eliminar infraestructura de la aplicación. Actualizar la política de confianza para permitir que los usuarios de la cuenta de desarrollo asuman este rol.",
            "4": "Crear un usuario de IAM en la cuenta de producción para cada desarrollador y operador en la cuenta de desarrollo, otorgándoles permisos para crear y eliminar infraestructura de la aplicación."
        },
        "Correct Answer": "Crear un rol de IAM compartido en la cuenta de producción con permisos para crear y eliminar infraestructura de la aplicación. Actualizar la política de confianza para permitir que los usuarios de la cuenta de desarrollo asuman este rol.",
        "Explanation": "Crear un rol de IAM compartido en la cuenta de producción con los permisos necesarios permite un acceso controlado para los usuarios en la cuenta de desarrollo. Al actualizar la política de confianza, el rol puede permitir específicamente que los desarrolladores y operadores lo asuman, asegurando el cumplimiento del principio de menor privilegio mientras se proporciona el acceso necesario.",
        "Other Options": [
            "Crear usuarios de IAM en la cuenta de producción para cada desarrollador y operador no es una buena práctica, ya que puede llevar a una sobrecarga de gestión y riesgos de seguridad potenciales. En su lugar, usar roles proporciona una solución más segura y manejable.",
            "Crear un grupo de IAM en la cuenta de producción y agregar directamente a los usuarios de IAM de la cuenta de desarrollo a este grupo no funcionaría, ya que los usuarios de IAM de una cuenta no pueden ser agregados a un grupo en otra cuenta. Los roles entre cuentas son el mecanismo apropiado para la gestión de acceso.",
            "Crear un rol de IAM compartido en la cuenta de desarrollo no ayuda a los operadores y desarrolladores a acceder a la cuenta de producción. El rol debe definirse en la cuenta de producción con una política de confianza que permita a la cuenta de desarrollo asumirlo."
        ]
    },
    {
        "Question Number": "48",
        "Situation": "Una empresa está planeando migrar sus cargas de trabajo existentes en las instalaciones a AWS. La arquitectura necesita ser rentable y asegurar que los recursos se utilicen de manera eficiente. La empresa está particularmente enfocada en gestionar costos mientras asegura suficiente capacidad para cargas de trabajo estacionales. Quieren entender los mejores modelos de precios a adoptar para sus instancias de EC2 y bases de datos de RDS.",
        "Question": "¿Cuál de los siguientes modelos de precios debería considerar el Arquitecto de Soluciones para optimizar costos mientras acomoda cargas de trabajo variables? (Seleccione Dos)",
        "Options": {
            "1": "Combinar Savings Plans con Spot Instances para optimizar el ahorro de costos en todas las cargas de trabajo.",
            "2": "Utilizar On-Demand Instances para todas las cargas de trabajo para mantener la máxima flexibilidad.",
            "3": "Usar Savings Plans para opciones de precios flexibles en múltiples familias de instancias y regiones.",
            "4": "Aprovechar Spot Instances para beneficiarse de la capacidad no utilizada de EC2 a tarifas reducidas.",
            "5": "Comprar Reserved Instances para cargas de trabajo a largo plazo y asegurar la reserva de capacidad."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Usar Savings Plans para opciones de precios flexibles en múltiples familias de instancias y regiones.",
            "Combinar Savings Plans con Spot Instances para optimizar el ahorro de costos en todas las cargas de trabajo."
        ],
        "Explanation": "Los Savings Plans proporcionan flexibilidad a través de tipos de instancias y regiones, lo cual es beneficioso para cargas de trabajo variables. Combinarlos con Spot Instances permite a la empresa aprovechar precios más bajos para cargas de trabajo menos críticas, optimizando así los costos generales.",
        "Other Options": [
            "Comprar Reserved Instances bloquea a la empresa en tipos de instancias y regiones específicas, lo que puede no ser ideal para cargas de trabajo variables que requieren flexibilidad.",
            "Utilizar On-Demand Instances para todas las cargas de trabajo puede ser costoso, ya que no proporciona los ahorros de costos asociados con el uso a largo plazo o la capacidad no utilizada.",
            "Aprovechar solo Spot Instances puede no garantizar capacidad durante los períodos pico, lo que podría llevar a interrupciones del servicio para cargas de trabajo críticas."
        ]
    },
    {
        "Question Number": "49",
        "Situation": "Una empresa de servicios financieros debe cumplir con estrictos requisitos regulatorios que exigen la encriptación de datos sensibles tanto en reposo como en tránsito. La empresa está migrando sus aplicaciones a AWS y necesita asegurarse de que todos los datos transmitidos hacia y desde los servicios de AWS estén encriptados. Además, los datos almacenados en Amazon S3 también deben estar encriptados utilizando un método que permita un control de acceso detallado.",
        "Question": "¿Qué combinación de acciones garantizará el cumplimiento de los requisitos de encriptación?",
        "Options": {
            "1": "Utilizar Amazon S3 Transfer Acceleration para acelerar las cargas sin encriptación. Usar políticas de IAM para permitir que cualquier usuario acceda a los objetos de S3. Establecer políticas de retención de datos para gestionar los ciclos de vida de los objetos.",
            "2": "Habilitar la encriptación del lado del servidor con claves de AWS KMS para los buckets de S3. Usar HTTPS para todas las llamadas a la API de los servicios de AWS. Establecer políticas de IAM para restringir el acceso a las claves de KMS.",
            "3": "Implementar encriptación del lado del cliente para los datos antes de cargarlos en S3. Usar transferencias de datos sin encriptar entre AWS y los centros de datos locales. Confiar en las políticas de los buckets de S3 para el control de acceso.",
            "4": "Usar AWS CloudHSM para gestionar las claves de encriptación para S3. Configurar todas las aplicaciones para usar HTTP sin encriptar para la transferencia de datos. Implementar grupos de seguridad para limitar el acceso al bucket de S3."
        },
        "Correct Answer": "Habilitar la encriptación del lado del servidor con claves de AWS KMS para los buckets de S3. Usar HTTPS para todas las llamadas a la API de los servicios de AWS. Establecer políticas de IAM para restringir el acceso a las claves de KMS.",
        "Explanation": "Habilitar la encriptación del lado del servidor con claves de AWS KMS asegura que los datos en reposo en S3 estén encriptados, y usar HTTPS asegura que los datos en tránsito estén encriptados. Establecer políticas de IAM para restringir el acceso a las claves de KMS añade una capa adicional de seguridad y control sobre las claves de encriptación, cumpliendo así con los requisitos regulatorios.",
        "Other Options": [
            "Usar AWS CloudHSM para gestionar las claves de encriptación es un enfoque seguro, pero configurar aplicaciones para usar HTTP sin encriptar no cumple con el requisito de encriptación en tránsito, lo que hace que esta opción no cumpla con las regulaciones.",
            "Utilizar Amazon S3 Transfer Acceleration puede proporcionar beneficios de rendimiento, pero no impone la encriptación. Permitir que cualquier usuario acceda a los objetos de S3 ignora la necesidad de un control de acceso detallado, fallando en cumplir con los estándares de cumplimiento.",
            "Implementar encriptación del lado del cliente es una estrategia válida para asegurar los datos antes de que lleguen a S3; sin embargo, usar transferencias de datos sin encriptar compromete la seguridad de los datos en tránsito. Confiar únicamente en las políticas de los buckets de S3 para el control de acceso es insuficiente para los estrictos requisitos del marco regulatorio."
        ]
    },
    {
        "Question Number": "50",
        "Situation": "Una empresa está construyendo una arquitectura de microservicios en AWS para soportar su plataforma de comercio electrónico. Cada servicio es responsable de una función comercial específica y necesita comunicarse sin problemas con otros servicios. La empresa quiere asegurarse de que los servicios estén desacoplados y puedan escalar de manera independiente. El arquitecto de soluciones tiene la tarea de seleccionar los servicios de integración de aplicaciones más apropiados para facilitar la comunicación entre estos microservicios.",
        "Question": "¿Cuál de las siguientes opciones debería implementar el arquitecto de soluciones para lograr los requisitos de integración de los microservicios? (Seleccione Dos)",
        "Options": {
            "1": "Utilizar AWS AppSync para conectar directamente los microservicios a las aplicaciones cliente.",
            "2": "Aprovechar Amazon EventBridge para enrutar eventos entre los microservicios según patrones específicos.",
            "3": "Usar Amazon Simple Queue Service (SQS) para desacoplar los servicios y habilitar la comunicación asíncrona.",
            "4": "Configurar AWS Step Functions para orquestar el flujo de trabajo entre los microservicios.",
            "5": "Implementar Amazon SNS para enviar notificaciones a múltiples servicios cuando ocurre un evento."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Usar Amazon Simple Queue Service (SQS) para desacoplar los servicios y habilitar la comunicación asíncrona.",
            "Aprovechar Amazon EventBridge para enrutar eventos entre los microservicios según patrones específicos."
        ],
        "Explanation": "Usar Amazon SQS permite una comunicación asíncrona y desacoplada entre microservicios, lo que mejora la escalabilidad y la resiliencia. Aprovechar Amazon EventBridge permite arquitecturas impulsadas por eventos, permitiendo que los servicios reaccionen a eventos en tiempo real mientras mantienen un desacoplamiento.",
        "Other Options": [
            "Si bien Amazon SNS puede enviar notificaciones a múltiples servicios, no proporciona el mismo nivel de desacoplamiento y procesamiento asíncrono que SQS.",
            "AWS AppSync se utiliza principalmente para APIs de GraphQL y puede no ser la mejor opción para la integración de microservicios en este escenario.",
            "AWS Step Functions son más adecuadas para orquestar flujos de trabajo en lugar de proporcionar comunicación directa entre microservicios."
        ]
    },
    {
        "Question Number": "51",
        "Situation": "Una empresa de servicios financieros está desarrollando una nueva aplicación que procesará datos sensibles de clientes. La empresa está comprometida con las mejores prácticas de seguridad y ha asignado a un arquitecto de soluciones para asegurarse de que todos los servicios y recursos de AWS estén configurados para adherirse al principio de acceso de menor privilegio. El arquitecto necesita establecer permisos de usuario para varios roles dentro de la aplicación, asegurándose de que los usuarios solo tengan acceso a los recursos que requieren para realizar sus funciones laborales específicas.",
        "Question": "¿Cuál de las siguientes acciones debería tomar el arquitecto de soluciones para implementar mejor el principio de acceso de menor privilegio para los usuarios de la aplicación?",
        "Options": {
            "1": "Crear roles de IAM con permisos específicos para cada función laboral y asignarlos a los usuarios.",
            "2": "Crear un solo rol de IAM con permisos amplios y asignarlo a todos los usuarios.",
            "3": "Asignar a los usuarios los mismos permisos que los administradores para asegurarse de que tengan todo el acceso necesario.",
            "4": "Conceder a todos los usuarios acceso total para asegurarse de que no haya problemas de permisos durante el desarrollo de la aplicación."
        },
        "Correct Answer": "Crear roles de IAM con permisos específicos para cada función laboral y asignarlos a los usuarios.",
        "Explanation": "Crear roles de IAM con permisos específicos para cada función laboral asegura que los usuarios solo tengan acceso a los recursos necesarios para sus tareas. Esto se alinea con el principio de acceso de menor privilegio y minimiza los riesgos de seguridad asociados con la sobre-permisión.",
        "Other Options": [
            "Conceder a todos los usuarios acceso total compromete la seguridad al proporcionar permisos innecesarios, lo que contradice el principio de acceso de menor privilegio.",
            "Crear un solo rol de IAM con permisos amplios expone la aplicación a riesgos de seguridad, ya que permite a todos los usuarios acceder a recursos que no necesitan.",
            "Asignar a los usuarios los mismos permisos que los administradores socava el principio de acceso de menor privilegio y podría llevar al uso accidental o intencional de recursos sensibles."
        ]
    },
    {
        "Question Number": "52",
        "Situation": "Una empresa de medios tiene un gran volumen de contenido de video que es generado y subido por los usuarios diariamente. La empresa necesita almacenar y gestionar este contenido de manera eficiente, asegurando que los videos sean accesibles para streaming. La mayoría de los videos subidos rara vez son accedidos después de los primeros días de haber sido subidos, pero deben ser retenidos por razones de cumplimiento. El arquitecto de soluciones tiene la tarea de diseñar una solución de almacenamiento que minimice costos mientras proporciona la durabilidad y accesibilidad necesarias para los videos.",
        "Question": "¿Cuál de las siguientes soluciones de almacenamiento satisfará mejor los requisitos de la empresa para un almacenamiento rentable y accesibilidad del contenido de video?",
        "Options": {
            "1": "Usar Amazon S3 Standard para todos los videos e implementar políticas de ciclo de vida para trasladar contenido más antiguo a Amazon S3 Glacier para almacenamiento a largo plazo.",
            "2": "Almacenar todos los videos en Amazon S3 Intelligent-Tiering para mover automáticamente los datos entre niveles de acceso frecuente e infrecuente según los patrones de uso.",
            "3": "Utilizar Amazon EFS para todo el almacenamiento de video para permitir un fácil compartir y acceso desde múltiples instancias sin preocuparse por la gestión del ciclo de vida.",
            "4": "Usar Amazon S3 Standard para videos recién subidos y configurar una política de ciclo de vida para trasladarlos a Amazon S3 One Zone-IA después de 30 días de no acceso."
        },
        "Correct Answer": "Usar Amazon S3 Intelligent-Tiering para mover automáticamente los datos entre niveles de acceso frecuente e infrecuente según los patrones de uso.",
        "Explanation": "Amazon S3 Intelligent-Tiering está diseñado para datos que tienen patrones de acceso desconocidos o cambiantes. Mueve automáticamente los datos entre dos niveles de acceso: frecuente e infrecuente, optimizando costos sin necesidad de intervención manual. Esto es ideal para el requisito de la empresa de medios de minimizar costos mientras asegura la accesibilidad para el contenido recién subido.",
        "Other Options": [
            "Usar Amazon S3 Standard para todos los videos puede incurrir en costos más altos, especialmente para videos que rara vez son accedidos después de la carga inicial, lo que lo hace menos rentable en comparación con Intelligent-Tiering.",
            "Amazon EFS no es la mejor opción para este escenario, ya que generalmente es más caro que S3 para almacenar grandes cantidades de datos, particularmente para contenido que es accedido infrecuentemente.",
            "Usar Amazon S3 Standard y configurar una política de ciclo de vida para trasladar a S3 One Zone-IA después de 30 días es una opción potencial, pero carece de la optimización automática que proporciona Intelligent-Tiering, que es crucial dado los patrones de acceso impredecibles de los videos."
        ]
    },
    {
        "Question Number": "53",
        "Situation": "Una empresa de servicios financieros está migrando sus bases de datos locales a AWS para mejorar la escalabilidad y reducir costos operativos. Están manejando un gran volumen de datos transaccionales que necesitan ser transferidos a una instancia de Amazon RDS. La empresa quiere asegurar un tiempo de inactividad mínimo durante la migración y mantener la integridad de los datos. El arquitecto de soluciones tiene la tarea de seleccionar el método más apropiado para transferir la base de datos a AWS.",
        "Question": "¿Cuál de las siguientes opciones es la solución más adecuada para migrar la base de datos con un tiempo de inactividad mínimo y mantener la integridad de los datos?",
        "Options": {
            "1": "Realizar una copia de seguridad manual de la base de datos, transferir los archivos de respaldo a Amazon RDS y restaurar la base de datos, asegurando que la aplicación esté fuera de línea durante el proceso.",
            "2": "Exportar la base de datos a un archivo plano, cargarlo en Amazon S3 y luego importarlo en la instancia de RDS, lo que requerirá un tiempo de inactividad significativo.",
            "3": "Usar AWS Database Migration Service con la instancia de replicación configurada para replicación continua de datos, permitiendo una migración con casi cero tiempo de inactividad.",
            "4": "Usar AWS Snowball para transferir toda la base de datos a AWS, lo que tomará varios días y llevará a un tiempo de inactividad prolongado durante la migración."
        },
        "Correct Answer": "Usar AWS Database Migration Service con la instancia de replicación configurada para replicación continua de datos, permitiendo una migración con casi cero tiempo de inactividad.",
        "Explanation": "AWS Database Migration Service (DMS) proporciona una forma de migrar bases de datos con un tiempo de inactividad mínimo. Al usar una instancia de replicación, DMS puede replicar continuamente los cambios de la base de datos de origen a la instancia de RDS de destino, permitiendo que la aplicación permanezca operativa hasta el corte final, asegurando la integridad de los datos y una mínima interrupción.",
        "Other Options": [
            "Exportar la base de datos a un archivo plano requiere un tiempo de inactividad significativo ya que la base de datos debe estar fuera de línea durante el proceso de exportación, lo que la hace inadecuada para minimizar el tiempo de inactividad.",
            "Realizar un proceso de copia de seguridad y restauración manual requeriría que la aplicación esté fuera de línea, lo que llevaría a un tiempo de inactividad significativo y a la interrupción de los servicios durante la migración.",
            "Usar AWS Snowball para la transferencia de la base de datos no es eficiente para este escenario, ya que lleva a un tiempo de inactividad prolongado mientras los datos son transportados físicamente y subidos a AWS."
        ]
    },
    {
        "Question Number": "54",
        "Situation": "Una empresa de servicios financieros necesita implementar una solución de recuperación ante desastres para sus aplicaciones críticas alojadas en AWS. Las aplicaciones deben permanecer disponibles con un tiempo de inactividad mínimo y pérdida de datos en caso de una falla. La empresa está utilizando actualmente múltiples Zonas de Disponibilidad dentro de una sola región para alta disponibilidad, pero quiere mejorar su estrategia de recuperación ante desastres. El presupuesto es limitado y tienen un requisito de un objetivo de punto de recuperación (RPO) de menos de 1 hora.",
        "Question": "¿Cuál de las siguientes soluciones de recuperación ante desastres en AWS satisfaría mejor los requisitos de la empresa para un tiempo de inactividad mínimo y baja pérdida de datos?",
        "Options": {
            "1": "Implementar una arquitectura activa-activa a través de dos regiones de AWS con replicación de datos sincrónica y Route 53 para conmutación por error de DNS.",
            "2": "Establecer una solución de espera cálida con un despliegue de Amazon RDS Multi-AZ y realizar copias de seguridad de datos regularmente en Amazon S3 para recuperación.",
            "3": "Desplegar una arquitectura activa-pasiva con Amazon S3 para almacenamiento y usar AWS Lambda para automatizar el proceso de conmutación por error cuando sea necesario.",
            "4": "Configurar una estrategia de recuperación ante desastres de piloto ligero con un Amazon RDS Read Replica en otra región y utilizar AWS CloudFormation para un despliegue rápido."
        },
        "Correct Answer": "Establecer una solución de espera cálida con un despliegue de Amazon RDS Multi-AZ y realizar copias de seguridad de datos regularmente en Amazon S3 para recuperación.",
        "Explanation": "Una solución de espera cálida con Amazon RDS Multi-AZ proporciona capacidades automáticas de conmutación por error y asegura alta disponibilidad, mientras que las copias de seguridad regulares en Amazon S3 cumplen con el requisito de RPO de menos de 1 hora, permitiendo una recuperación eficiente en caso de una falla.",
        "Other Options": [
            "Implementar una arquitectura activa-activa es generalmente más complejo y costoso, y aunque puede proporcionar un tiempo de inactividad mínimo, puede exceder el presupuesto limitado de la empresa y no es necesario dado sus requisitos.",
            "La estrategia de piloto ligero, aunque proporciona una solución rentable, puede no cumplir efectivamente con el RPO de menos de 1 hora, ya que típicamente implica más intervención manual y tiempo de configuración durante un desastre.",
            "Una arquitectura activa-pasiva con S3 y AWS Lambda puede introducir retrasos en la conmutación por error y no garantizaría la rápida disponibilidad de la aplicación, haciéndola menos adecuada para el requisito de la empresa de un tiempo de inactividad mínimo."
        ]
    },
    {
        "Question Number": "55",
        "Situation": "Una empresa de servicios financieros necesita almacenar datos sensibles de clientes de manera que garantice durabilidad, seguridad y cumplimiento con los requisitos regulatorios. Están buscando una solución de almacenamiento de AWS que pueda proporcionar almacenamiento de objetos escalable con capacidades de gestión del ciclo de vida y cifrado en reposo. La empresa también quiere asegurarse de que los datos se puedan acceder a través de una API y que tenga un costo bajo para accesos poco frecuentes.",
        "Question": "¿Qué servicio de almacenamiento de AWS debería recomendar el arquitecto de soluciones para cumplir con estos requisitos?",
        "Options": {
            "1": "Amazon S3 con Object Lock habilitado y cifrado del lado del servidor para la protección de datos.",
            "2": "Amazon FSx for Windows File Server para proporcionar un sistema de archivos de Windows administrado con características de seguridad avanzadas.",
            "3": "Amazon Elastic File System (Amazon EFS) con características de cifrado y respaldo para garantizar la seguridad de los datos.",
            "4": "Amazon Elastic Block Store (EBS) con instantáneas para respaldo y cifrado de volúmenes para asegurar los datos."
        },
        "Correct Answer": "Amazon S3 con Object Lock habilitado y cifrado del lado del servidor para la protección de datos.",
        "Explanation": "Amazon S3 proporciona almacenamiento de objetos escalable que puede almacenar una gran cantidad de datos de manera segura. Con Object Lock habilitado, permite políticas de retención de datos que ayudan a garantizar el cumplimiento con los requisitos regulatorios. Además, el cifrado del lado del servidor protege los datos en reposo, y S3 ofrece capacidades de gestión del ciclo de vida para opciones de almacenamiento rentables.",
        "Other Options": [
            "Amazon Elastic File System (Amazon EFS) está diseñado principalmente para almacenamiento de archivos y puede no ser tan rentable para almacenamiento de objetos a gran escala, especialmente para datos a los que se accede poco frecuentemente.",
            "Amazon FSx for Windows File Server está diseñado para aplicaciones de Windows y puede no ser la mejor opción para necesidades de almacenamiento de objetos o requisitos de acceso a API en comparación con Amazon S3.",
            "Amazon Elastic Block Store (EBS) se utiliza típicamente para almacenamiento en bloques adjunto a instancias de EC2 y, aunque ofrece instantáneas y cifrado, no proporciona las características de escalabilidad y gestión del ciclo de vida adecuadas para escenarios de almacenamiento de objetos a gran escala."
        ]
    },
    {
        "Question Number": "56",
        "Situation": "Una organización minorista global quiere consolidar sus cuentas de AWS para gestionar mejor los costos, la seguridad y el cumplimiento. La organización tiene múltiples departamentos, cada uno con su propia cuenta de AWS, y está considerando una nueva estructura de cuentas que pueda escalar con su crecimiento mientras asegura que cada departamento pueda mantener la autonomía necesaria sobre sus cargas de trabajo. El arquitecto de soluciones debe recomendar una estructura de cuentas que mejor cumpla con los requisitos de la organización.",
        "Question": "¿Cuál de las siguientes estructuras de cuentas debería recomendar el arquitecto de soluciones para lograr la gestión de costos, seguridad y cumplimiento mientras permite la autonomía departamental?",
        "Options": {
            "1": "Usar un enfoque híbrido creando cuentas de AWS separadas para cada departamento mientras se establece una cuenta de gestión centralizada para supervisar la facturación y el cumplimiento.",
            "2": "Desplegar múltiples Organizaciones de AWS, una para cada departamento, lo que permite una autonomía completa pero complica la gestión centralizada de la facturación y el cumplimiento.",
            "3": "Crear una sola cuenta de AWS para toda la organización y usar roles de IAM para gestionar el acceso departamental a los recursos, asegurando que cada departamento tenga control sobre sus propias cargas de trabajo.",
            "4": "Crear una Organización de AWS con múltiples Unidades Organizativas (OUs), asignando a cada departamento su propia OU para gestionar recursos de manera independiente mientras se mantiene la facturación centralizada."
        },
        "Correct Answer": "Crear una Organización de AWS con múltiples Unidades Organizativas (OUs), asignando a cada departamento su propia OU para gestionar recursos de manera independiente mientras se mantiene la facturación centralizada.",
        "Explanation": "Esta opción permite a la organización utilizar AWS Organizations para crear una estructura jerárquica con múltiples OUs. Cada departamento puede gestionar sus propios recursos y políticas mientras se beneficia de la facturación y gestión centralizadas, lo que se alinea con sus necesidades de gestión de costos, seguridad y cumplimiento.",
        "Other Options": [
            "Esta opción limita la capacidad de la organización para gestionar costos y seguridad de manera efectiva. Si bien los roles de IAM pueden proporcionar control de acceso, una sola cuenta carece de la flexibilidad y características organizativas que ofrecen las AWS Organizations.",
            "Esta opción crea una complejidad innecesaria en la gestión. Múltiples Organizaciones de AWS llevarían a desafíos en la facturación centralizada, seguimiento del cumplimiento y compartición de recursos, lo cual no es ideal para una organización que busca una gestión eficiente.",
            "Esta opción proporciona cierto nivel de separación para cada departamento, pero podría llevar a una gestión fragmentada de la facturación y el cumplimiento. Un enfoque centralizado a través de AWS Organizations es más efectivo para los objetivos de la organización."
        ]
    },
    {
        "Question Number": "57",
        "Situation": "Una empresa ha desplegado una aplicación web de múltiples capas en varias regiones de AWS, utilizando Amazon RDS para su capa de base de datos. La aplicación es crítica para las operaciones comerciales, y la empresa ha establecido un plan de recuperación ante desastres para garantizar un tiempo de inactividad mínimo en caso de una falla regional. Para validar este plan, la empresa quiere realizar una prueba de recuperación ante desastres sin impactar el entorno de producción.",
        "Question": "¿Qué enfoque debería recomendar el arquitecto de soluciones para realizar pruebas de recuperación ante desastres de manera que minimice los riesgos para el entorno de producción?",
        "Options": {
            "1": "Desplegar una réplica de lectura de Amazon RDS en una región diferente, promoverla a una base de datos independiente y usarla para la prueba de recuperación ante desastres.",
            "2": "Configurar una base de datos de Amazon RDS en la misma región que la producción pero en una zona de disponibilidad diferente y realizar la prueba de recuperación ante desastres utilizando esta nueva instancia.",
            "3": "Usar AWS CloudFormation para replicar la infraestructura de producción en una cuenta de AWS separada, luego realizar la prueba de recuperación ante desastres allí sin afectar los recursos de producción.",
            "4": "Crear una instantánea de la base de datos RDS de producción, restaurarla en un entorno de prueba dentro de la misma región y realizar la prueba de recuperación ante desastres con esa instantánea."
        },
        "Correct Answer": "Usar AWS CloudFormation para replicar la infraestructura de producción en una cuenta de AWS separada, luego realizar la prueba de recuperación ante desastres allí sin afectar los recursos de producción.",
        "Explanation": "Usar AWS CloudFormation para replicar la infraestructura de producción en una cuenta de AWS separada permite un entorno seguro para realizar pruebas de recuperación ante desastres sin el riesgo de impactar el entorno de producción. Esto asegura que la prueba se pueda realizar de manera aislada mientras se valida el plan de recuperación ante desastres de manera efectiva.",
        "Other Options": [
            "Crear una instantánea de la base de datos RDS de producción y restaurarla en la misma región arriesga impactos potenciales en el rendimiento o problemas de consistencia de datos en el entorno de producción durante la prueba.",
            "Desplegar una réplica de lectura de Amazon RDS en una región diferente y promoverla a una base de datos independiente podría llevar a la pérdida de datos o inconsistencia, ya que depende del retraso de replicación y no es una verdadera prueba del plan de recuperación ante desastres para la configuración de producción.",
            "Configurar una base de datos de Amazon RDS en la misma región pero en una zona de disponibilidad diferente no aísla completamente la prueba del entorno de producción y puede llevar a consecuencias no deseadas si la prueba impacta los recursos regionales en general."
        ]
    },
    {
        "Question Number": "58",
        "Situation": "Una empresa de medios está buscando migrar su almacenamiento de video local a AWS. La empresa requiere una solución que pueda almacenar grandes archivos de video y proporcionar alta disponibilidad y durabilidad. Además, la solución debe permitir el acceso inmediato a videos que se acceden con frecuencia, al mismo tiempo que proporciona una forma rentable de almacenar contenido que se accede con poca frecuencia. La empresa está considerando diferentes opciones de almacenamiento de AWS.",
        "Question": "¿Cuál de las siguientes soluciones de almacenamiento de AWS satisface mejor los requisitos de la empresa para alta disponibilidad, durabilidad, acceso inmediato a videos que se acceden con frecuencia y almacenamiento rentable para contenido que se accede con poca frecuencia?",
        "Options": {
            "1": "Amazon EBS con IOPS provisionadas para acceso de alto rendimiento a archivos de video.",
            "2": "Amazon S3 con la clase de almacenamiento Intelligent-Tiering para videos que se acceden con frecuencia y con poca frecuencia.",
            "3": "Amazon S3 Glacier para archivo a largo plazo de todos los archivos de video.",
            "4": "Amazon FSx para Windows File Server para compartir archivos de video entre múltiples instancias."
        },
        "Correct Answer": "Amazon S3 con la clase de almacenamiento Intelligent-Tiering para videos que se acceden con frecuencia y con poca frecuencia.",
        "Explanation": "Amazon S3 con Intelligent-Tiering está diseñado para optimizar costos al mover automáticamente los datos entre dos niveles de acceso cuando cambian los patrones de acceso. Esta solución proporciona alta disponibilidad y durabilidad para grandes archivos de video, al mismo tiempo que asegura que los videos que se acceden con frecuencia puedan recuperarse de inmediato, lo que la hace ideal para los requisitos de la empresa de medios.",
        "Other Options": [
            "Amazon EBS se utiliza principalmente para almacenamiento en bloque adjunto a instancias de EC2 y no proporciona el mismo nivel de durabilidad y disponibilidad para grandes archivos de video como S3. También carece de las características de optimización de costos automáticas necesarias para contenido que se accede con poca frecuencia.",
            "Amazon S3 Glacier está diseñado para almacenamiento a largo plazo y no es adecuado para acceso inmediato a archivos de video, ya que los tiempos de recuperación pueden variar de minutos a horas, lo que no cumple con el requisito de la empresa para acceso rápido a videos utilizados con frecuencia.",
            "Amazon FSx para Windows File Server es un servicio de sistema de archivos de Windows completamente administrado que es adecuado para compartir archivos, pero no ofrece la misma escalabilidad, durabilidad y rentabilidad para almacenamiento de video a gran escala como Amazon S3."
        ]
    },
    {
        "Question Number": "59",
        "Situation": "Una empresa de medios está migrando su aplicación de transmisión de video a AWS. La aplicación necesita soportar la entrega de video de alta calidad con una latencia mínima para usuarios en múltiples ubicaciones geográficas. La arquitectura actual utiliza instancias de Amazon EC2 para el procesamiento y un bucket de Amazon S3 para almacenar archivos de video. La dirección está considerando diferentes mecanismos para transferir archivos de video desde el almacenamiento local a AWS de manera eficiente.",
        "Question": "¿Qué combinación de opciones proporcionará el mecanismo de transferencia MÁS eficiente para archivos de video? (Seleccione Dos)",
        "Options": {
            "1": "Implementar una estrategia de carga de múltiples partes utilizando el SDK de AWS para una carga más rápida de archivos de video.",
            "2": "Usar AWS Storage Gateway para crear una solución de almacenamiento en la nube híbrida para una transferencia de datos sin problemas.",
            "3": "Transferir archivos de video a través de Internet utilizando AWS Transfer Family con el protocolo SFTP.",
            "4": "Utilizar AWS Direct Connect para establecer una conexión de red dedicada entre el almacenamiento local y AWS.",
            "5": "Aprovechar AWS Snowball para transferir grandes volúmenes de archivos de video de manera segura a AWS."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Utilizar AWS Direct Connect para establecer una conexión de red dedicada entre el almacenamiento local y AWS.",
            "Aprovechar AWS Snowball para transferir grandes volúmenes de archivos de video de manera segura a AWS."
        ],
        "Explanation": "Usar AWS Direct Connect proporciona una conexión de alto ancho de banda y baja latencia ideal para transferir grandes archivos de video, asegurando una transferencia de datos eficiente y confiable. AWS Snowball está diseñado específicamente para migraciones de datos a gran escala, permitiendo la transferencia segura y eficiente de grandes volúmenes de datos directamente a AWS sin depender de limitaciones de ancho de banda.",
        "Other Options": [
            "AWS Storage Gateway es más adecuado para la sincronización de datos continua en lugar de transferencias masivas de datos, lo que lo hace menos eficiente para videos grandes inicialmente.",
            "AWS Transfer Family es efectivo para transferencias de archivos más pequeños, pero puede no ser óptimo para archivos de video grandes debido a posibles limitaciones de ancho de banda de Internet y latencia.",
            "Una estrategia de carga de múltiples partes es útil para mejorar las velocidades de carga a través de HTTP, pero para grandes volúmenes de datos, AWS Snowball o Direct Connect serían más eficientes."
        ]
    },
    {
        "Question Number": "60",
        "Situation": "Una organización de servicios financieros está revisando su arquitectura en la nube para identificar áreas que pueden beneficiarse de la automatización. La arquitectura incluye múltiples servicios de AWS como Amazon EC2, Amazon RDS y AWS Lambda. El equipo se centra en mejorar la eficiencia operativa y reducir la intervención manual.",
        "Question": "¿Qué oportunidad de automatización debería priorizar la organización para mejorar la eficiencia operativa en su arquitectura de AWS?",
        "Options": {
            "1": "Monitorear manualmente los métricas de rendimiento de cada servicio utilizando la Consola de Administración de AWS.",
            "2": "Implementar Amazon CloudWatch Events para activar funciones de AWS Lambda para tareas rutinarias entre servicios.",
            "3": "Programar el mantenimiento regular de instancias de EC2 utilizando AWS Systems Manager Run Command sin notificaciones automáticas.",
            "4": "Utilizar AWS CloudFormation para implementar cambios de infraestructura manualmente para cada servicio."
        },
        "Correct Answer": "Implementar Amazon CloudWatch Events para activar funciones de AWS Lambda para tareas rutinarias entre servicios.",
        "Explanation": "Implementar Amazon CloudWatch Events para activar funciones de AWS Lambda permite la automatización de tareas rutinarias, mejorando la eficiencia operativa al reducir las intervenciones manuales y permitiendo respuestas en tiempo real a eventos en toda la arquitectura.",
        "Other Options": [
            "Monitorear manualmente los métricas de rendimiento es un enfoque reactivo y no aprovecha la automatización, lo que limitaría las mejoras en la eficiencia.",
            "Programar mantenimiento regular sin notificaciones automáticas puede llevar a retrasos en la resolución de problemas, ya que carece de las capacidades de monitoreo proactivo y respuesta que proporciona la automatización.",
            "Utilizar AWS CloudFormation manualmente derrota el propósito de la infraestructura como código, que está diseñada para automatizar los procesos de implementación y gestión."
        ]
    },
    {
        "Question Number": "61",
        "Situation": "Una gran empresa de medios necesita migrar enormes cantidades de datos de archivo desde su centro de datos local a AWS. La transferencia de datos debe ser segura, rentable y capaz de manejar petabytes de datos sin afectar significativamente el rendimiento de la red existente de la empresa. El arquitecto de soluciones debe seleccionar la herramienta de migración de datos más adecuada que cumpla con estos criterios mientras minimiza el tiempo requerido para el proceso de migración.",
        "Question": "¿Cuál de los siguientes servicios de AWS es el más apropiado para migrar grandes volúmenes de datos de archivo desde un centro de datos local a AWS de manera segura y eficiente?",
        "Options": {
            "1": "AWS Transfer Family, ya que ofrece una forma sencilla de transferir archivos hacia y desde AWS utilizando los protocolos FTP, SFTP y FTPS, lo que lo hace adecuado para migraciones de grandes datos.",
            "2": "AWS Snowball, ya que está diseñado específicamente para transferir grandes cantidades de datos físicamente utilizando dispositivos seguros y robustos, lo que es ideal para migraciones a escala de petabytes.",
            "3": "AWS DataSync, ya que proporciona transferencia de datos automatizada y segura a través de Internet con cifrado incorporado y está optimizado para migraciones de datos a gran escala.",
            "4": "S3 Transfer Acceleration, ya que acelera las cargas de contenido a Amazon S3 utilizando las ubicaciones de borde distribuidas globalmente de Amazon CloudFront, lo que lo hace efectivo para grandes conjuntos de datos."
        },
        "Correct Answer": "AWS Snowball, ya que está diseñado específicamente para transferir grandes cantidades de datos físicamente utilizando dispositivos seguros y robustos, lo que es ideal para migraciones a escala de petabytes.",
        "Explanation": "AWS Snowball es la mejor opción para migrar volúmenes masivos de datos de archivo debido a su capacidad para transferir de manera segura petabytes de datos utilizando dispositivos físicos. Este método evita sobrecargar el ancho de banda de Internet de la empresa y asegura un manejo rápido y seguro de los datos durante el proceso de migración.",
        "Other Options": [
            "AWS DataSync es excelente para transferencias de datos automatizadas a través de Internet, pero puede no ser la opción más rentable para transferir petabytes de datos en comparación con un dispositivo físico como Snowball.",
            "AWS Transfer Family está diseñado para protocolos de transferencia de archivos, pero no está optimizado para migraciones de datos a gran escala, especialmente al tratar con petabytes de datos de archivo.",
            "S3 Transfer Acceleration puede acelerar las cargas a S3, pero depende de Internet, lo que podría ser un cuello de botella al transferir grandes volúmenes de datos, haciéndolo menos adecuado para este escenario."
        ]
    },
    {
        "Question Number": "62",
        "Situation": "Una empresa de servicios financieros ha desplegado una aplicación de múltiples capas en AWS que incluye instancias de Amazon EC2 para la capa de aplicación, Amazon RDS para la capa de base de datos y Amazon S3 para almacenar documentos subidos por los usuarios. El arquitecto de soluciones tiene la tarea de evaluar la arquitectura existente para identificar áreas que pueden no ser suficientemente confiables, especialmente durante los períodos de uso máximo cuando la aplicación experimenta un alto tráfico. La empresa no ha implementado ninguna forma de redundancia o conmutación por error para sus servidores de base de datos o de aplicación.",
        "Question": "¿Cuál de las siguientes acciones debería recomendar el arquitecto de soluciones para mejorar la confiabilidad de la arquitectura durante los períodos de tráfico máximo?",
        "Options": {
            "1": "Desplegar la aplicación en una instancia de EC2 con un tipo de instancia más grande para manejar picos de tráfico.",
            "2": "Implementar Auto Scaling para las instancias de EC2 y utilizar implementaciones Multi-AZ de Amazon RDS para asegurar alta disponibilidad de la base de datos.",
            "3": "Cambiar a Amazon DynamoDB para el almacenamiento de datos para eliminar la necesidad de redundancia y escalado.",
            "4": "Migrar la aplicación a una sola instancia de EC2 que utilice IOPS provisionados para mejoras de rendimiento."
        },
        "Correct Answer": "Implementar Auto Scaling para las instancias de EC2 y utilizar implementaciones Multi-AZ de Amazon RDS para asegurar alta disponibilidad de la base de datos.",
        "Explanation": "Implementar Auto Scaling para las instancias de EC2 permite que la aplicación ajuste automáticamente el número de instancias según las demandas de tráfico, mientras que las implementaciones Multi-AZ de Amazon RDS proporcionan alta disponibilidad y soporte de conmutación por error para la base de datos, asegurando que la aplicación permanezca operativa incluso durante cargas máximas o interrupciones.",
        "Other Options": [
            "Cambiar a Amazon DynamoDB puede mejorar el rendimiento, pero no aborda directamente las preocupaciones de confiabilidad de la arquitectura existente y puede introducir complejidad adicional en el modelado de datos.",
            "Migrar la aplicación a una sola instancia de EC2 crea un único punto de falla y no proporciona redundancia ni la capacidad de escalar durante el tráfico máximo, lo cual es crítico para la confiabilidad.",
            "Desplegar la aplicación en una instancia de EC2 más grande puede mejorar el rendimiento, pero no aborda la necesidad de redundancia o conmutación por error, dejando a la aplicación vulnerable a interrupciones."
        ]
    },
    {
        "Question Number": "63",
        "Situation": "Una empresa de análisis de datos está procesando grandes conjuntos de datos que requieren un alto rendimiento y baja latencia. Están utilizando una arquitectura de aplicación distribuida que aprovecha múltiples instancias de Amazon EC2, y necesitan un sistema de archivos compartido que pueda ofrecer un rendimiento rápido para cargas de trabajo que involucran datos de acceso frecuente. La empresa busca optimizar costos mientras asegura que el sistema de archivos pueda integrarse sin problemas con su lago de datos S3 existente para necesidades de procesamiento de datos temporales.",
        "Question": "¿Cuál de las siguientes soluciones cumpliría MEJOR con los requisitos de la empresa para un sistema de archivos compartido de alto rendimiento mientras se integra eficientemente con Amazon S3?",
        "Options": {
            "1": "Utilizar Amazon FSx for Lustre para crear un sistema de archivos compartido de alto rendimiento que cargue datos desde Amazon S3 para su procesamiento, asegurando acceso de baja latencia a datos de acceso frecuente.",
            "2": "Configurar un bucket de Amazon S3 con políticas de ciclo de vida para trasladar automáticamente datos de acceso frecuente a Amazon Glacier para ahorrar en costos de almacenamiento.",
            "3": "Desplegar un sistema de archivos Amazon FSx for Windows File Server para proporcionar acceso compartido a datos con aplicaciones basadas en Windows e integrarse con Active Directory para autenticación.",
            "4": "Implementar un Sistema de Archivos Elástico de Amazon (EFS) para proporcionar almacenamiento de archivos escalable para las instancias de EC2, permitiendo escalado automático para acomodar cargas de trabajo fluctuantes."
        },
        "Correct Answer": "Utilizar Amazon FSx for Lustre para crear un sistema de archivos compartido de alto rendimiento que cargue datos desde Amazon S3 para su procesamiento, asegurando acceso de baja latencia a datos de acceso frecuente.",
        "Explanation": "Amazon FSx for Lustre está diseñado para manejar cargas de trabajo de alto rendimiento y puede integrarse directamente con Amazon S3, permitiendo que los datos sean accesibles de manera rápida y eficiente. Esto lo convierte en una solución ideal para los requisitos de la empresa tanto en rendimiento como en optimización de costos.",
        "Other Options": [
            "Desplegar un Amazon FSx for Windows File Server no es óptimo para cargas de trabajo de alto rendimiento, ya que está diseñado para aplicaciones basadas en Windows y puede no ofrecer el rendimiento y la latencia requeridos para la empresa de análisis.",
            "Implementar Amazon Elastic File System (EFS) proporciona escalabilidad, pero puede no coincidir con las necesidades de alto rendimiento de las cargas de trabajo de análisis de datos en comparación con FSx for Lustre, especialmente al trabajar con grandes conjuntos de datos.",
            "Configurar un bucket de Amazon S3 con políticas de ciclo de vida para trasladar datos a Amazon Glacier no es adecuado, ya que Glacier está diseñado para datos de acceso poco frecuente y aumentaría la latencia para la necesidad de acceso rápido y compartido de la empresa."
        ]
    },
    {
        "Question Number": "64",
        "Situation": "Una empresa de servicios financieros requiere una solución de respaldo confiable para sus datos críticos almacenados en Amazon S3. Los datos necesitan ser respaldados automáticamente, deben ser rentables y deben garantizar la continuidad del negocio a través de múltiples Zonas de Disponibilidad para evitar la pérdida de datos en caso de una interrupción.",
        "Question": "¿Cuál de las siguientes arquitecturas aborda mejor los requisitos de la empresa para una solución de respaldo automatizada y rentable que soporte la continuidad del negocio a través de múltiples Zonas de Disponibilidad?",
        "Options": {
            "1": "Configurar una función programada de AWS Lambda que copie objetos del bucket S3 principal a otro bucket en una región diferente utilizando la API de S3.",
            "2": "Implementar una replicación entre regiones de Amazon S3 a un bucket en otra región y usar políticas de ciclo de vida para trasladar versiones más antiguas a Amazon S3 Glacier.",
            "3": "Utilizar Amazon S3 Object Lock con versionado habilitado para mantener múltiples copias de los objetos en el mismo bucket a través de diferentes Zonas de Disponibilidad.",
            "4": "Usar AWS Backup para crear un plan de respaldo que respalde automáticamente los datos de S3 a otro bucket en la misma región con el versionado habilitado."
        },
        "Correct Answer": "Implementar una replicación entre regiones de Amazon S3 a un bucket en otra región y usar políticas de ciclo de vida para trasladar versiones más antiguas a Amazon S3 Glacier.",
        "Explanation": "Esta opción asegura que los datos no solo se respalden automáticamente a otra región, mejorando la durabilidad y disponibilidad, sino que también utiliza políticas de ciclo de vida para gestionar costos al trasladar datos a una clase de almacenamiento de menor costo.",
        "Other Options": [
            "Si bien AWS Backup proporciona buena funcionalidad, respaldar a otro bucket en la misma región no cumple con el requisito de continuidad del negocio a través de múltiples Zonas de Disponibilidad o Regiones.",
            "Usar una función programada de AWS Lambda para copiar datos puede introducir complejidad y posibles puntos de falla, haciéndola menos confiable como solución de respaldo en comparación con características integradas como la replicación entre regiones.",
            "Amazon S3 Object Lock con versionado es beneficioso para la retención de datos y protección contra eliminaciones accidentales, pero no proporciona una solución de respaldo entre regiones, lo cual es esencial para la continuidad del negocio."
        ]
    },
    {
        "Question Number": "65",
        "Situation": "Una institución financiera está utilizando Amazon S3 para almacenar datos sensibles de clientes. Debido a los requisitos de cumplimiento regulatorio, necesitan asegurarse de que estos datos no puedan ser eliminados o modificados durante un período de retención específico. La institución desea implementar una solución que garantice la integridad de estos datos mientras aún permite un acceso y recuperación eficientes cuando sea necesario. Están considerando varias opciones para gestionar la retención y protección de datos.",
        "Question": "¿Qué solución debería implementar la institución financiera para garantizar el cumplimiento de las políticas de retención de datos mientras previene la eliminación o modificación accidental de datos sensibles?",
        "Options": {
            "1": "Habilitar S3 Object Lock en modo de cumplimiento en un bucket versionado para prevenir la eliminación o modificación de objetos durante un período de retención especificado.",
            "2": "Utilizar Amazon S3 Transfer Acceleration para acelerar las transferencias de datos y mejorar el acceso, mientras se confía en políticas de IAM para controlar el acceso al bucket.",
            "3": "Implementar AWS Backup para crear respaldos regulares del contenido del bucket S3, asegurando que las versiones anteriores de los objetos puedan ser restauradas si se eliminan.",
            "4": "Configurar Amazon CloudTrail para monitorear el acceso al bucket S3 y alertar sobre cualquier acción de eliminación, permitiendo a los administradores tomar medidas correctivas."
        },
        "Correct Answer": "Habilitar S3 Object Lock en modo de cumplimiento en un bucket versionado para prevenir la eliminación o modificación de objetos durante un período de retención especificado.",
        "Explanation": "Habilitar S3 Object Lock en modo de cumplimiento asegura que los objetos no puedan ser eliminados o sobrescritos durante el período de retención especificado, cumpliendo así con los requisitos regulatorios para la protección e integridad de los datos.",
        "Other Options": [
            "Implementar AWS Backup no previene la eliminación o modificación de objetos; simplemente permite la recuperación de versiones anteriores, lo que no cumple con el requisito de prevenir cambios durante el período de retención.",
            "Utilizar Amazon S3 Transfer Acceleration mejora las velocidades de transferencia pero no ofrece ninguna protección contra eliminación o modificación; no cumple con el requisito de cumplimiento.",
            "Configurar Amazon CloudTrail permite monitorear las acciones realizadas en el bucket S3, pero no previene eliminaciones o modificaciones, por lo tanto, no satisface la necesidad de protección de retención de datos."
        ]
    },
    {
        "Question Number": "66",
        "Situation": "Una empresa está utilizando AWS CloudFormation para gestionar su infraestructura como código. La empresa tiene un stack que consiste en múltiples recursos y desea implementar una política de stack para asegurar que solo ciertos recursos puedan ser actualizados durante las actualizaciones del stack. La empresa también necesita desplegar el mismo stack a través de múltiples cuentas y regiones para mantener la consistencia en sus entornos.",
        "Question": "¿Cuál de los siguientes enfoques permitirá a la empresa hacer cumplir las actualizaciones del stack mientras también habilita el despliegue de stacks de CloudFormation a través de múltiples cuentas y regiones?",
        "Options": {
            "1": "Crear una política de stack que niegue actualizaciones a todos los recursos por defecto, y asignar diferentes políticas de stack a diferentes cuentas de AWS utilizando roles de IAM para flexibilidad en las actualizaciones.",
            "2": "Implementar una política de stack que permita actualizaciones a todos los recursos y utilizar AWS CloudFormation StackSets para gestionar el despliegue a través de múltiples regiones sin restricciones.",
            "3": "Usar AWS CloudFormation StackSets para crear un único stack que incluya todos los recursos y prevenga actualizaciones por defecto. No se puede implementar una política de stack separada en este escenario.",
            "4": "Definir una política de stack en formato JSON que permita explícitamente actualizaciones solo a recursos específicos. Usar AWS CloudFormation StackSets para desplegar la política de stack y la plantilla a través de todas las cuentas y regiones objetivo."
        },
        "Correct Answer": "Definir una política de stack en formato JSON que permita explícitamente actualizaciones solo a recursos específicos. Usar AWS CloudFormation StackSets para desplegar la política de stack y la plantilla a través de todas las cuentas y regiones objetivo.",
        "Explanation": "Esta opción describe correctamente el proceso de definir una política de stack que permite actualizaciones a recursos específicos mientras se utilizan StackSets para el despliegue en múltiples cuentas y regiones. Esto se adhiere a las mejores prácticas de AWS para gestionar infraestructura como código.",
        "Other Options": [
            "Esta opción es incorrecta porque AWS CloudFormation no permite diferentes políticas de stack para diferentes cuentas. Una sola política de stack se aplica a todos los usuarios que intentan actualizar el stack.",
            "Esta opción es engañosa ya que sugiere crear un único stack con una política que previene actualizaciones. Una política de stack que niega actualizaciones a todos los recursos no cumpliría con el requisito de permitir actualizaciones a recursos específicos.",
            "Esta opción es incorrecta porque implementar una política de stack que permita actualizaciones a todos los recursos contradice el requisito de proteger recursos específicos durante las actualizaciones del stack."
        ]
    },
    {
        "Question Number": "67",
        "Situation": "Una empresa de servicios financieros está buscando implementar una solución de registro centralizado para todos los eventos de seguridad en su entorno de AWS. La empresa quiere asegurar el cumplimiento de los requisitos regulatorios mientras mejora los tiempos de respuesta ante incidentes. El arquitecto de soluciones debe desarrollar una estrategia que abarque el registro de varios servicios y aplicaciones de AWS, asegurando que los registros estén almacenados de manera segura y sean fácilmente accesibles para auditorías.",
        "Question": "¿Qué arquitectura apoyará mejor las notificaciones de eventos de seguridad centralizados y la auditoría para la empresa?",
        "Options": {
            "1": "Configurar AWS Config para monitorear configuraciones y cambios de recursos, e integrarlo con AWS Security Hub para enviar alertas basadas en violaciones de cumplimiento. Almacenar registros en Amazon S3 para almacenamiento a largo plazo.",
            "2": "Utilizar Amazon CloudWatch Logs para agregar registros de los servicios de AWS y configurar Amazon SNS para enviar notificaciones de eventos de seguridad específicos. Almacenar registros en Amazon S3 con políticas de ciclo de vida para gestionar la retención.",
            "3": "Desplegar un clúster de Amazon Elasticsearch Service para indexar registros de varios servicios de AWS, utilizando una solución personalizada para enviar registros al clúster. Configurar alertas a través de Amazon SNS basadas en consultas de Elasticsearch.",
            "4": "Implementar AWS CloudTrail para capturar llamadas a la API y transmitir registros a Amazon Kinesis para procesamiento en tiempo real. Usar Amazon S3 para almacenamiento de registros y configurar AWS Lambda para activar alertas basadas en patrones de registro específicos."
        },
        "Correct Answer": "Utilizar Amazon CloudWatch Logs para agregar registros de los servicios de AWS y configurar Amazon SNS para enviar notificaciones de eventos de seguridad específicos. Almacenar registros en Amazon S3 con políticas de ciclo de vida para gestionar la retención.",
        "Explanation": "El uso de Amazon CloudWatch Logs permite la agregación de registros de varios servicios de AWS, proporcionando una vista centralizada de los eventos de seguridad. Acoplar esto con Amazon SNS permite notificaciones oportunas para eventos específicos, mejorando la respuesta ante incidentes. Almacenar registros en Amazon S3 con políticas de ciclo de vida asegura el cumplimiento de los requisitos de retención de datos mientras optimiza los costos de almacenamiento.",
        "Other Options": [
            "Implementar AWS CloudTrail captura principalmente llamadas a la API, pero no proporciona una solución de registro integral para todos los eventos de seguridad en los servicios. Aunque Kinesis permite el procesamiento en tiempo real, puede no ser necesario para todos los casos de uso y añade complejidad sin beneficios claros para el registro centralizado.",
            "Desplegar un clúster de Amazon Elasticsearch Service requiere una sobrecarga adicional de gestión y no proporciona inherentemente un mecanismo de notificación para eventos de seguridad. La solución personalizada para enviar registros añade complejidad y posibles puntos de falla, lo que puede obstaculizar la respuesta oportuna a los eventos.",
            "Configurar AWS Config está más enfocado en monitorear configuraciones de recursos en lugar de un registro centralizado de eventos de seguridad. Si bien puede proporcionar alertas de cumplimiento, no abarca la amplitud de eventos de seguridad en los servicios de AWS, lo que lo hace menos adecuado para una estrategia de auditoría integral."
        ]
    },
    {
        "Question Number": "68",
        "Situation": "Una empresa está desarrollando una arquitectura de microservicios en AWS que requiere comunicación confiable entre diferentes servicios. Los servicios necesitan enviar y recibir mensajes de manera desacoplada, asegurando que los mensajes no se pierdan incluso si el servicio receptor está temporalmente no disponible. La arquitectura también debe soportar diferentes tipos de cargas de trabajo, incluyendo aquellas que requieren procesamiento en tiempo real de eventos.",
        "Question": "¿Cuál de los siguientes servicios de AWS sería la MEJOR opción para implementar un sistema de mensajería confiable entre los microservicios?",
        "Options": {
            "1": "Usar Amazon Simple Queue Service (Amazon SQS) para crear una cola para el procesamiento de mensajes.",
            "2": "Usar Amazon Kinesis Data Streams para procesar y analizar flujos de datos en tiempo real.",
            "3": "Usar AWS Step Functions para orquestar el flujo de trabajo entre servicios directamente.",
            "4": "Usar Amazon Simple Notification Service (Amazon SNS) para enviar mensajes a todos los suscriptores."
        },
        "Correct Answer": "Usar Amazon Simple Queue Service (Amazon SQS) para crear una cola para el procesamiento de mensajes.",
        "Explanation": "Amazon SQS proporciona un servicio de colas de mensajes confiable, escalable y completamente administrado que permite la comunicación desacoplada entre microservicios. Asegura que los mensajes no se pierdan y puedan ser procesados de manera asíncrona, lo que lo hace ideal para arquitecturas de microservicios.",
        "Other Options": [
            "Amazon SNS está diseñado para mensajería pub/sub y es más adecuado para transmitir mensajes a múltiples suscriptores en lugar de asegurar un procesamiento confiable de mensajes entre servicios.",
            "AWS Step Functions se utiliza principalmente para orquestar flujos de trabajo complejos y gestionar el estado de las aplicaciones en lugar de servir como un servicio de mensajería.",
            "Amazon Kinesis Data Streams se centra en el streaming y procesamiento de datos en tiempo real, lo que no es el requisito principal para la mensajería confiable entre microservicios."
        ]
    },
    {
        "Question Number": "69",
        "Situation": "Una empresa global de servicios financieros tiene múltiples centros de datos locales y está buscando integrar sus sistemas con AWS mientras asegura una transferencia de datos segura y eficiente. Tienen datos sensibles que requieren una conexión segura y baja latencia para el procesamiento en tiempo real. La empresa está evaluando opciones para conectar su red local a AWS para optimizar su arquitectura híbrida.",
        "Question": "¿Cuál de las siguientes opciones proporciona la conectividad más eficiente y segura para integrar los centros de datos locales de la empresa con AWS, minimizando la latencia para el procesamiento en tiempo real?",
        "Options": {
            "1": "Configurar AWS Direct Connect para establecer una conexión de fibra dedicada desde los centros de datos locales a AWS, emparejada con una VPN de respaldo para redundancia. Usar Direct Connect para toda la transferencia de datos para minimizar la latencia y maximizar el ancho de banda.",
            "2": "Implementar un AWS Transit Gateway para conectar múltiples VPCs y redes locales. Usar AWS Direct Connect con una conexión VPN como respaldo. Esta configuración simplifica la gestión mientras asegura una conectividad segura y eficiente.",
            "3": "Usar AWS VPN CloudHub para conectar múltiples sitios remotos a una VPC de AWS. Esta solución ofrece una conexión segura, pero puede introducir latencia adicional debido a la naturaleza de las conexiones VPN basadas en internet.",
            "4": "Establecer una conexión VPN utilizando AWS Site-to-Site VPN para conectar los centros de datos locales a AWS. Utilizar AWS Direct Connect para crear una conexión dedicada para requisitos de alto ancho de banda, asegurando que el tráfico se enrute a través de la VPN por seguridad."
        },
        "Correct Answer": "Configurar AWS Direct Connect para establecer una conexión de fibra dedicada desde los centros de datos locales a AWS, emparejada con una VPN de respaldo para redundancia. Usar Direct Connect para toda la transferencia de datos para minimizar la latencia y maximizar el ancho de banda.",
        "Explanation": "El uso de AWS Direct Connect proporciona una conexión confiable y de alta velocidad con baja latencia, ideal para el procesamiento de datos en tiempo real. Emparejarlo con una VPN para redundancia asegura conectividad segura en caso de que falle el enlace de Direct Connect.",
        "Other Options": [
            "Establecer una conexión VPN con AWS Site-to-Site VPN junto con Direct Connect introduce complejidad innecesaria. La VPN enrutaría el tráfico a través del enlace de Direct Connect, negando algunos beneficios de baja latencia.",
            "Implementar un AWS Transit Gateway simplifica la gestión, pero puede añadir sobrecarga y latencia en el enrutamiento del tráfico. Es más beneficioso para arquitecturas de red complejas en lugar de conectividad sencilla.",
            "Usar AWS VPN CloudHub conecta sitios remotos pero depende de conexiones a internet, lo que puede llevar a una mayor latencia. Esta opción no es adecuada para el requisito de la empresa de conexiones de baja latencia."
        ]
    },
    {
        "Question Number": "70",
        "Situation": "Una empresa está evaluando su cartera de servicios en la nube para optimizar costos y rendimiento. La arquitectura actual incluye varias instancias de EC2 que ejecutan diversas aplicaciones, pero la empresa no está segura de si está utilizando los recursos de manera eficiente. Se ha encargado al arquitecto de soluciones realizar una evaluación de la cartera para identificar posibles mejoras.",
        "Question": "¿Cuál de las siguientes acciones debería tomar PRIMERO el arquitecto de soluciones para evaluar la utilización actual de los recursos de las instancias de EC2?",
        "Options": {
            "1": "Implementar grupos de Auto Scaling para todas las instancias de EC2 para mejorar la eficiencia.",
            "2": "Desplegar AWS CloudWatch para monitorear la utilización de CPU y memoria en las instancias de EC2.",
            "3": "Habilitar AWS Cost Explorer para analizar los patrones de gasto durante los últimos seis meses.",
            "4": "Usar AWS CloudTrail para revisar las llamadas a la API realizadas a las instancias de EC2 para métricas de rendimiento."
        },
        "Correct Answer": "Desplegar AWS CloudWatch para monitorear la utilización de CPU y memoria en las instancias de EC2.",
        "Explanation": "Desplegar AWS CloudWatch para monitorear la utilización de CPU y memoria proporciona información inmediata sobre cómo se están utilizando los recursos. Estos datos son esenciales para identificar instancias infrautilizadas o sobreaprovisionadas, lo que permite tomar decisiones informadas sobre la optimización de recursos.",
        "Other Options": [
            "Implementar grupos de Auto Scaling es una estrategia para optimizar la asignación de recursos, pero no proporciona información inmediata sobre la utilización actual, lo que lo convierte en un paso secundario después de evaluar el uso de recursos.",
            "Usar AWS CloudTrail es útil para auditoría y propósitos de seguridad, pero no proporciona métricas de rendimiento relacionadas con la utilización de recursos. No es el mejor primer paso en una evaluación de cartera.",
            "Habilitar AWS Cost Explorer ayuda a rastrear el gasto, pero no proporciona datos de utilización de recursos en tiempo real. Entender cómo se están utilizando actualmente los recursos es crítico antes de analizar costos."
        ]
    },
    {
        "Question Number": "71",
        "Situation": "Una empresa de servicios financieros está evaluando sus procesos de implementación actuales para identificar áreas de mejora. Las aplicaciones de la empresa están desplegadas en instancias de Amazon EC2, pero el equipo enfrenta desafíos con la escalabilidad y la eficiencia operativa. Están considerando un cambio a una arquitectura más moderna que permita una mejor utilización y gestión de recursos. El objetivo es mejorar el rendimiento mientras se reducen los costos operativos.",
        "Question": "Considerando los requisitos de la empresa para mejorar la escalabilidad y la eficiencia operativa, ¿qué estrategia de implementación debería adoptar la empresa para lograr sus objetivos?",
        "Options": {
            "1": "Desplegar las aplicaciones en una mezcla de instancias de Amazon EC2 On-Demand y Reservadas, asegurando que la escalabilidad se maneje a través de intervención manual basada en cargas de trabajo proyectadas.",
            "2": "Migrar las aplicaciones a Amazon ECS con AWS Fargate para eliminar la necesidad de gestionar instancias de EC2 manualmente y asegurar la escalabilidad automática basada en la demanda.",
            "3": "Continuar usando instancias de Amazon EC2, pero implementar una solución de monitoreo integral para optimizar el uso de instancias y ajustar manualmente la escalabilidad basada en métricas de rendimiento observadas.",
            "4": "Refactorizar las aplicaciones para que se ejecuten en AWS Lambda, habilitando una arquitectura sin servidor que escale automáticamente según eventos y patrones de uso."
        },
        "Correct Answer": "Migrar las aplicaciones a Amazon ECS con AWS Fargate para eliminar la necesidad de gestionar instancias de EC2 manualmente y asegurar la escalabilidad automática basada en la demanda.",
        "Explanation": "Migrar a Amazon ECS con AWS Fargate permite a la empresa centrarse en desplegar aplicaciones sin gestionar las instancias de EC2 subyacentes. Fargate proporciona capacidades de escalabilidad automática, optimizando el uso de recursos y reduciendo la sobrecarga operativa, lo que se alinea con los objetivos de la empresa en cuanto a eficiencia y reducción de costos.",
        "Other Options": [
            "Continuar con instancias de Amazon EC2 puede llevar a desafíos continuos con la escalabilidad y la gestión manual de recursos, lo que no aborda la necesidad de la empresa de mejorar la eficiencia operativa.",
            "Desplegar una mezcla de instancias On-Demand y Reservadas no simplifica la gestión ni proporciona escalabilidad automática, lo que podría llevar a costos operativos más altos y una utilización de recursos menos eficiente.",
            "Refactorizar aplicaciones para que se ejecuten en AWS Lambda puede no ser adecuado para todas las cargas de trabajo, especialmente si no son impulsadas por eventos o requieren procesos de larga duración. Este enfoque podría introducir complejidad y puede no alinearse con la arquitectura actual."
        ]
    },
    {
        "Question Number": "72",
        "Situation": "Una empresa de servicios financieros está planeando migrar sus aplicaciones locales a AWS. Las aplicaciones consisten en una mezcla de servidores web, servidores de aplicaciones y una base de datos. La empresa quiere asegurar un tiempo de inactividad mínimo durante la migración y mantener el rendimiento de las aplicaciones. Están considerando varias herramientas de migración de AWS para facilitar el proceso.",
        "Question": "¿Qué herramienta de AWS es la más adecuada para evaluar las dependencias de las aplicaciones locales y planificar la estrategia de migración?",
        "Options": {
            "1": "AWS Database Migration Service",
            "2": "AWS Server Migration Service",
            "3": "AWS Application Migration Service",
            "4": "AWS Application Discovery Service"
        },
        "Correct Answer": "AWS Application Discovery Service",
        "Explanation": "AWS Application Discovery Service está diseñado específicamente para ayudar a las organizaciones a descubrir y comprender sus aplicaciones locales, incluidas sus dependencias y métricas de rendimiento. Esta información es crucial para planificar una estrategia de migración efectiva a AWS con un tiempo de inactividad mínimo.",
        "Other Options": [
            "AWS Application Migration Service se centra principalmente en la migración automatizada de aplicaciones en lugar de evaluar y planificar la estrategia de migración.",
            "AWS Database Migration Service está diseñado para migrar bases de datos, no para evaluar dependencias de aplicaciones en múltiples tipos de servidores.",
            "AWS Server Migration Service se utiliza para automatizar la migración de servidores virtuales a AWS, pero no proporciona un análisis integral de las dependencias de las aplicaciones."
        ]
    },
    {
        "Question Number": "73",
        "Situation": "Una empresa está experimentando aumentos inesperados en su factura de AWS debido a patrones de uso fluctuantes de sus servicios en la nube. El arquitecto de soluciones necesita diseñar una estrategia de gestión de costos que incluya la configuración de alarmas de facturación basadas en patrones de uso esperados. La estrategia debe ayudar a la empresa a gestionar proactivamente los costos y recibir alertas antes de que superen los umbrales presupuestarios.",
        "Question": "¿Cuál de los siguientes enfoques es la forma más efectiva de diseñar alarmas de facturación basadas en patrones de uso esperados?",
        "Options": {
            "1": "Configurar AWS CloudTrail para registrar todas las llamadas a la API relacionadas con la facturación y establecer alertas basadas en los datos registrados para monitorear picos de uso.",
            "2": "Crear AWS Budgets para establecer umbrales de costo y uso personalizados, y utilizar Amazon CloudWatch para activar alarmas cuando se supere el umbral del presupuesto.",
            "3": "Implementar AWS Cost Explorer para analizar el uso pasado y definir alertas basadas en patrones de uso promedio, utilizando SNS para notificaciones.",
            "4": "Utilizar AWS Trusted Advisor para generar informes de costos mensuales y monitorear manualmente los informes para activar alertas cuando se alcancen los umbrales."
        },
        "Correct Answer": "Crear AWS Budgets para establecer umbrales de costo y uso personalizados, y utilizar Amazon CloudWatch para activar alarmas cuando se supere el umbral del presupuesto.",
        "Explanation": "Crear AWS Budgets permite a la empresa definir umbrales específicos de costo y uso adaptados a sus patrones esperados. Cuando se combina con Amazon CloudWatch, la empresa puede recibir alertas inmediatas cuando se superen esos umbrales, lo que permite una gestión proactiva de costos.",
        "Other Options": [
            "Implementar AWS Cost Explorer es útil para analizar el uso, pero no proporciona capacidades de alerta en tiempo real. Ayuda en el análisis retrospectivo en lugar de la gestión proactiva de costos.",
            "Configurar AWS CloudTrail se centra en registrar llamadas a la API y no se relaciona directamente con la gestión de umbrales de facturación. Se utiliza principalmente para gobernanza, cumplimiento y auditoría operativa.",
            "Utilizar AWS Trusted Advisor para informes de costos proporciona información, pero carece de la capacidad de alerta en tiempo real necesaria para una gestión proactiva. El monitoreo manual no es eficiente para un control de costos oportuno."
        ]
    },
    {
        "Question Number": "74",
        "Situation": "Una empresa de servicios financieros está implementando una nueva aplicación utilizando AWS. La aplicación necesita asegurarse de que las implementaciones puedan revertirse rápidamente en caso de problemas, y también necesita soportar implementaciones blue-green para un tiempo de inactividad mínimo.",
        "Question": "¿Qué combinación de estrategias satisfará mejor el requisito de reversiones rápidas y implementaciones blue-green? (Seleccione Dos)",
        "Options": {
            "1": "Implementar AWS Elastic Beanstalk con versionado de aplicaciones.",
            "2": "Implementar con Amazon ECS utilizando actualizaciones continuas y verificaciones de salud.",
            "3": "Utilizar AWS CloudFormation para la provisión de infraestructura con actualizaciones de pila.",
            "4": "Utilizar AWS CodeDeploy con grupos de implementación para la implementación blue-green.",
            "5": "Aprovechar AWS Lambda con API Gateway para puntos finales versionados."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Utilizar AWS CodeDeploy con grupos de implementación para la implementación blue-green.",
            "Implementar AWS Elastic Beanstalk con versionado de aplicaciones."
        ],
        "Explanation": "Utilizar AWS CodeDeploy permite configurar implementaciones blue-green, lo que facilita reversiones rápidas. Además, implementar AWS Elastic Beanstalk con versionado de aplicaciones permite revertir rápidamente a una versión anterior de la aplicación si es necesario.",
        "Other Options": [
            "Usar AWS CloudFormation es beneficioso para gestionar infraestructura como código, pero no aborda específicamente el mecanismo de reversión para implementaciones de aplicaciones.",
            "Implementar con Amazon ECS utilizando actualizaciones continuas es efectivo para minimizar el tiempo de inactividad, pero puede no proporcionar las capacidades de reversión rápida que ofrecen las implementaciones blue-green.",
            "Aprovechar AWS Lambda con API Gateway es excelente para microservicios, pero no soporta inherentemente las implementaciones blue-green o estrategias de reversión rápida."
        ]
    },
    {
        "Question Number": "75",
        "Situation": "Una empresa de servicios financieros almacena datos sensibles de clientes en una única instancia de Amazon RDS. La base de datos requiere copias de seguridad regulares por motivos de cumplimiento y recuperación ante desastres. Sin embargo, la empresa ha experimentado algunas instancias de pérdida de datos debido a errores humanos y necesita diseñar una solución de respaldo que sea tanto automatizada como eficiente, asegurando la integridad y disponibilidad de los datos.",
        "Question": "¿Cuál de las siguientes opciones es la solución más efectiva para implementar un proceso de respaldo robusto para la instancia de Amazon RDS?",
        "Options": {
            "1": "Usar AWS Backup para crear copias de seguridad diarias de la instancia de RDS y configurarlo para retener copias de seguridad durante 30 días, asegurando el cumplimiento de los requisitos regulatorios.",
            "2": "Crear manualmente instantáneas de la instancia de RDS todos los días y almacenarlas en un bucket de S3 con versionado habilitado para recuperar versiones anteriores si es necesario.",
            "3": "Implementar un trabajo cron en una instancia de EC2 para exportar la base de datos a un bucket de S3 cada semana y eliminar copias de seguridad más antiguas después de 60 días.",
            "4": "Habilitar copias de seguridad automatizadas en la instancia de RDS, establecer un período de retención de 35 días y configurar implementaciones multi-AZ para asegurar alta disponibilidad y redundancia de datos."
        },
        "Correct Answer": "Habilitar copias de seguridad automatizadas en la instancia de RDS, establecer un período de retención de 35 días y configurar implementaciones multi-AZ para asegurar alta disponibilidad y redundancia de datos.",
        "Explanation": "Habilitar copias de seguridad automatizadas en una instancia de RDS proporciona recuperación en un punto en el tiempo y asegura que las copias de seguridad se creen regularmente sin intervención manual. Establecer un período de retención de 35 días permite a la empresa cumplir con los requisitos de cumplimiento, mientras que las implementaciones multi-AZ mejoran la disponibilidad y redundancia de los datos.",
        "Other Options": [
            "Si bien crear instantáneas manualmente puede proporcionar una solución de respaldo, introduce el riesgo de error humano y falta de automatización, lo que la hace menos confiable para la protección continua de datos.",
            "Usar AWS Backup es una buena opción, pero no es el método más eficiente en comparación con habilitar copias de seguridad automatizadas directamente en la instancia de RDS, que está diseñada para este propósito.",
            "Implementar un trabajo cron en una instancia de EC2 agrega sobrecarga operativa y complejidad al proceso de respaldo, y exportar la base de datos semanalmente puede no cumplir con los objetivos de tiempo de recuperación en caso de pérdida de datos."
        ]
    }
]