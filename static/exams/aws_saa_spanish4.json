[
    {
        "Question Number": "1",
        "Situation": "Una empresa necesita otorgar a un miembro específico del equipo acceso a un bucket de Amazon S3, pero restringir el acceso solo a ciertos objetos dentro del bucket. El administrador de IAM quiere mantener la carga de gestión baja mientras asegura que el miembro del equipo tenga solo los permisos necesarios.",
        "Question": "¿Qué tipo de política debería usar el administrador y qué formato de ARN de recurso debería especificar para limitar el acceso a los objetos dentro del bucket? (Elige dos.)",
        "Options": {
            "1": "Usar una política en línea y especificar el ARN como arn:aws:s3:::bucket-name/*",
            "2": "Usar una política gestionada por el cliente y especificar el ARN como arn:aws:s3:::bucket-name",
            "3": "Usar una política gestionada por AWS y especificar el ARN como arn:aws:s3:::bucket-name/*",
            "4": "Usar una política en línea y especificar el ARN como arn:aws:s3:::bucket-name",
            "5": "Usar una política de bucket y especificar el ARN como arn:aws:s3:::bucket-name/specific-object-key"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Usar una política en línea y especificar el ARN como arn:aws:s3:::bucket-name/*",
            "Usar una política de bucket y especificar el ARN como arn:aws:s3:::bucket-name/specific-object-key"
        ],
        "Explanation": "Una política en línea es una política que está incrustada en una única identidad de IAM (un usuario, grupo o rol). Esto permitiría al administrador otorgar permisos específicos a un solo usuario, que es el requisito en este caso. El ARN 'arn:aws:s3:::bucket-name/*' otorgaría acceso a todos los objetos dentro del bucket. Una política de bucket es una política basada en recursos: permite crear una política y adjuntarla directamente al bucket de S3. El ARN 'arn:aws:s3:::bucket-name/specific-object-key' restringiría el acceso a un objeto específico dentro del bucket.",
        "Other Options": [
            "Usar una política gestionada por el cliente y especificar el ARN como 'arn:aws:s3:::bucket-name' no restringiría el acceso a objetos específicos dentro del bucket. En cambio, otorgaría acceso a todo el bucket.",
            "Usar una política gestionada por AWS y especificar el ARN como 'arn:aws:s3:::bucket-name/*' no sería ideal porque las políticas gestionadas por AWS están diseñadas para proporcionar permisos para casos de uso comunes y son gestionadas por AWS. Esto puede no proporcionar el control granular requerido en este escenario.",
            "Usar una política en línea y especificar el ARN como 'arn:aws:s3:::bucket-name' no restringiría el acceso a objetos específicos dentro del bucket. En cambio, otorgaría acceso a todo el bucket."
        ]
    },
    {
        "Question Number": "2",
        "Situation": "Una empresa quiere gestionar permisos para un gran número de usuarios de IAM de diferentes equipos dentro de la organización. Necesitan una estructura que permita la asignación fácil de permisos para cada equipo sin necesidad de asignar políticas individuales a cada usuario. Además, quieren evitar que cualquier usuario individual sea referenciado directamente en las políticas de recursos.",
        "Question": "¿Qué característica de IAM sería la SOLUCIÓN MÁS efectiva para cumplir con estos requisitos?",
        "Options": {
            "1": "Crear roles individuales de IAM para cada usuario con políticas específicas del equipo adjuntas.",
            "2": "Usar grupos de IAM para organizar a los usuarios por equipo y adjuntar políticas específicas del equipo a cada grupo.",
            "3": "Configurar un único rol de IAM para todos los usuarios y confiar en AWS Organizations para gestionar permisos.",
            "4": "Asignar políticas en línea a cada usuario según sus permisos específicos del equipo."
        },
        "Correct Answer": "Usar grupos de IAM para organizar a los usuarios por equipo y adjuntar políticas específicas del equipo a cada grupo.",
        "Explanation": "Usar grupos de IAM es la solución más efectiva porque permite a la empresa gestionar permisos a nivel de equipo en lugar de individualmente. Al crear grupos para cada equipo, la empresa puede adjuntar políticas que definan los permisos para todos los usuarios en ese grupo. Esto simplifica la gestión de permisos, ya que cualquier cambio en la política se aplicará automáticamente a todos los usuarios en el grupo. Además, los grupos de IAM evitan que los usuarios individuales sean referenciados directamente en las políticas de recursos, alineándose con el requisito de la empresa.",
        "Other Options": [
            "Crear roles individuales de IAM para cada usuario con políticas específicas del equipo adjuntas llevaría a una estructura compleja y difícil de gestionar, especialmente con un gran número de usuarios. Este enfoque requeriría actualizaciones constantes y gestión de cada rol, lo cual es ineficiente.",
            "Configurar un único rol de IAM para todos los usuarios y confiar en AWS Organizations para gestionar permisos no proporciona la granularidad necesaria para permisos específicos del equipo. Esto resultaría en que todos los usuarios tendrían los mismos permisos, lo que no cumple con el requisito de gestionar permisos por equipo.",
            "Asignar políticas en línea a cada usuario según sus permisos específicos del equipo no es escalable. Las políticas en línea se adjuntan directamente a los usuarios, lo que dificulta la gestión colectiva de permisos para un equipo. Este enfoque también llevaría a redundancias y aumentaría la carga administrativa."
        ]
    },
    {
        "Question Number": "3",
        "Situation": "Una empresa está configurando una VPC en AWS con subredes privadas y públicas. Necesitan habilitar el acceso a Internet para las instancias en la subred pública mientras mantienen las instancias en la subred privada aisladas del acceso directo a Internet.",
        "Question": "¿Qué pasos debería seguir la empresa para configurar el acceso a Internet para la subred pública y asegurar un enrutamiento seguro dentro de la VPC?",
        "Options": {
            "1": "Adjuntar un Internet Gateway (IGW) a la VPC, asociar una tabla de rutas con la subred pública que dirija el tráfico 0.0.0.0/0 al IGW, y asignar direcciones IPv4 públicas a las instancias en la subred pública.",
            "2": "Configurar un NAT Gateway en la subred privada, adjuntarlo a la VPC y crear una tabla de rutas que dirija el tráfico 0.0.0.0/0 desde la subred pública al NAT Gateway.",
            "3": "Crear un Internet Gateway (IGW) y adjuntarlo a cada instancia en la subred pública individualmente para proporcionar acceso a Internet, mientras se usa la tabla de rutas predeterminada para el enrutamiento.",
            "4": "Usar una conexión de VPC Peering entre las subredes privadas y públicas para enrutar el tráfico de Internet, y asegurar que todas las instancias en ambas subredes tengan direcciones IPv4 públicas para la conectividad."
        },
        "Correct Answer": "Adjuntar un Internet Gateway (IGW) a la VPC, asociar una tabla de rutas con la subred pública que dirija el tráfico 0.0.0.0/0 al IGW, y asignar direcciones IPv4 públicas a las instancias en la subred pública.",
        "Explanation": "Para habilitar el acceso a Internet para las instancias en la subred pública, la empresa debe adjuntar un Internet Gateway (IGW) a la VPC. El IGW permite la comunicación entre las instancias en la subred pública y el Internet. Además, se debe asociar una tabla de rutas con la subred pública que dirija todo el tráfico saliente (0.0.0.0/0) al IGW. Finalmente, las instancias en la subred pública necesitan tener direcciones IPv4 públicas para ser accesibles desde Internet. Esta configuración asegura que las instancias puedan enviar y recibir tráfico desde Internet mientras mantienen la subred privada aislada.",
        "Other Options": [
            "Configurar un NAT Gateway en la subred privada es incorrecto para proporcionar acceso a Internet a la subred pública. Un NAT Gateway se utiliza para permitir que las instancias en una subred privada inicien tráfico saliente hacia Internet mientras se previene el tráfico entrante desde Internet, lo cual no se aplica a la subred pública.",
            "Crear un Internet Gateway (IGW) y adjuntarlo a cada instancia en la subred pública individualmente es incorrecto. Un IGW debe ser adjuntado a la VPC en su totalidad, no a instancias individuales. Además, la tabla de rutas debe configurarse para dirigir el tráfico al IGW, en lugar de depender de la tabla de rutas predeterminada.",
            "Usar una conexión de VPC Peering entre las subredes privadas y públicas no es un método válido para enrutar tráfico de Internet. VPC Peering se utiliza para conectar dos VPCs, no para habilitar el acceso a Internet. Además, las instancias en la subred privada no deberían tener direcciones IPv4 públicas si se desea que permanezcan aisladas del acceso directo a Internet."
        ]
    },
    {
        "Question Number": "4",
        "Situation": "Una empresa multinacional de retail está expandiendo su presencia en línea a Europa y Asia. Quieren asegurar un acceso de baja latencia a su base de datos de clientes para los usuarios en estas nuevas regiones, mientras cumplen con los requisitos de soberanía de datos.",
        "Question": "¿Qué estrategia arquitectónica de AWS debería recomendar el arquitecto de soluciones para cumplir con estos requisitos? (Elige dos.)",
        "Options": {
            "1": "Desplegar una única instancia de Amazon RDS en la región principal de AWS y usar Amazon CloudFront para almacenar en caché las consultas a la base de datos globalmente.",
            "2": "Configurar Amazon Aurora Global Database con réplicas de lectura secundarias en las regiones de Europa y Asia.",
            "3": "Usar Amazon DynamoDB con tablas globales habilitadas para replicación automática entre regiones.",
            "4": "Implementar una conexión VPN al centro de datos local en cada nueva región y replicar la base de datos manualmente.",
            "5": "Utilizar AWS DataSync para automatizar la replicación de datos entre regiones."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Configurar Amazon Aurora Global Database con réplicas de lectura secundarias en las regiones de Europa y Asia.",
            "Usar Amazon DynamoDB con tablas globales habilitadas para replicación automática entre regiones."
        ],
        "Explanation": "Configurar Amazon Aurora Global Database con réplicas de lectura secundarias en las regiones de Europa y Asia es una respuesta correcta porque permite lecturas de baja latencia y recuperación ante desastres. Los datos se replican en múltiples regiones, lo que asegura la soberanía de datos y el acceso de baja latencia. Usar Amazon DynamoDB con tablas globales habilitadas para replicación automática entre regiones también es correcto. Las tablas globales replican tus datos en múltiples regiones de AWS para ofrecer acceso rápido y local a los datos para tus aplicaciones distribuidas globalmente, asegurando así un acceso de baja latencia y soberanía de datos.",
        "Other Options": [
            "Desplegar una única instancia de Amazon RDS en la región principal de AWS y usar Amazon CloudFront para almacenar en caché las consultas a la base de datos globalmente no es una solución viable porque CloudFront es una red de entrega de contenido, no un servicio de almacenamiento en caché de base de datos. No está diseñado para almacenar en caché consultas a bases de datos.",
            "Implementar una conexión VPN al centro de datos local en cada nueva región y replicar la base de datos manualmente no es una solución eficiente. Requeriría un esfuerzo manual significativo y no proporcionaría el acceso de baja latencia requerido para los usuarios en las nuevas regiones.",
            "Utilizar AWS DataSync para automatizar la replicación de datos entre regiones no es la mejor solución porque DataSync se utiliza principalmente para transferir datos entre almacenamiento local y AWS o entre servicios de almacenamiento de AWS. No proporciona el acceso de baja latencia requerido para los usuarios en las nuevas regiones."
        ]
    },
    {
        "Question Number": "5",
        "Situation": "Una plataforma de comercio electrónico global experimenta picos de tráfico intenso durante eventos de ventas, con millones de usuarios accediendo a la plataforma simultáneamente desde diferentes regiones. Para asegurar una experiencia fluida para todos los usuarios, la plataforma necesita manejar altos volúmenes de tráfico sin comprometer la latencia o la disponibilidad.",
        "Question": "¿Cuál de las siguientes estrategias abordaría mejor estos requisitos?",
        "Options": {
            "1": "Usar un único centro de datos con servidores potentes",
            "2": "Implementar una arquitectura distribuida y multi-región para servir a los usuarios desde la ubicación más cercana",
            "3": "Confiar únicamente en almacenar en caché los datos a nivel de base de datos",
            "4": "Agregar más CPU y memoria a sus servidores de aplicaciones principales"
        },
        "Correct Answer": "Implementar una arquitectura distribuida y multi-región para servir a los usuarios desde la ubicación más cercana",
        "Explanation": "Implementar una arquitectura distribuida y multi-región permite a la plataforma de comercio electrónico manejar altos volúmenes de tráfico distribuyendo la carga entre múltiples servidores ubicados en diferentes regiones geográficas. Este enfoque minimiza la latencia al servir a los usuarios desde el centro de datos más cercano, mejorando los tiempos de respuesta y asegurando una alta disponibilidad. También proporciona redundancia; si una región experimenta problemas, otras pueden seguir sirviendo a los usuarios, manteniendo así el rendimiento general de la plataforma durante los picos de tráfico.",
        "Other Options": [
            "Usar un único centro de datos con servidores potentes no manejaría eficazmente los picos de tráfico intenso, ya que crea un único punto de falla y puede llevar a una mayor latencia para los usuarios ubicados lejos de ese centro de datos. Este enfoque limita la escalabilidad y no proporciona redundancia.",
            "Confiar únicamente en almacenar en caché los datos a nivel de base de datos puede mejorar el rendimiento, pero no aborda el problema del alto volumen de tráfico en diferentes regiones. Almacenar en caché puede reducir la carga en la base de datos, pero si los servidores de aplicaciones o la infraestructura de red no pueden manejar el tráfico entrante, los usuarios aún pueden experimentar retrasos o interrupciones.",
            "Agregar más CPU y memoria a sus servidores de aplicaciones principales puede proporcionar un impulso temporal en el rendimiento, pero no resuelve el problema subyacente de escalabilidad y latencia para los usuarios ubicados lejos del servidor. Este enfoque puede llevar a rendimientos decrecientes y no proporciona la distribución geográfica necesaria para gestionar eficazmente los picos de tráfico global."
        ]
    },
    {
        "Question Number": "6",
        "Situation": "Una empresa está desplegando una aplicación crítica para la misión en AWS y quiere asegurar alta disponibilidad y una rápida recuperación en caso de fallos en la infraestructura. Están considerando diferentes estrategias de conmutación por error para minimizar el tiempo de inactividad durante las interrupciones.",
        "Question": "¿Cuál de las siguientes estrategias de conmutación por error es la más adecuada para mantener la disponibilidad del servicio con un tiempo de inactividad mínimo? (Elige dos.)",
        "Options": {
            "1": "Usar una estrategia de conmutación por error activa-activa a través de múltiples Zonas de Disponibilidad para asegurar que el tráfico se dirija automáticamente a recursos saludables.",
            "2": "Usar una estrategia de respaldo y restauración que respalde periódicamente el estado de la aplicación y lo restaure cuando ocurre un fallo.",
            "3": "Usar una estrategia de conmutación por error en espera caliente, donde solo una pequeña parte de los recursos está funcionando en una región de respaldo, y la capacidad total se escala cuando es necesario.",
            "4": "Usar una estrategia de conmutación por error de luz piloto con infraestructura mínima funcionando en la región secundaria, escalando los recursos solo cuando ocurre un fallo.",
            "5": "Implementar una estrategia de conmutación por error en frío donde no se ejecutan recursos en la región de respaldo hasta que ocurre un fallo, luego se despliegan completamente los recursos."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Usar una estrategia de conmutación por error activa-activa a través de múltiples Zonas de Disponibilidad para asegurar que el tráfico se dirija automáticamente a recursos saludables.",
            "Usar una estrategia de conmutación por error en espera caliente, donde solo una pequeña parte de los recursos está funcionando en una región de respaldo, y la capacidad total se escala cuando es necesario."
        ],
        "Explanation": "Una estrategia de conmutación por error activa-activa es un método altamente efectivo para mantener la disponibilidad del servicio con un tiempo de inactividad mínimo. Implica ejecutar instancias de la aplicación en múltiples Zonas de Disponibilidad simultáneamente. Si una instancia falla, el tráfico se redirige automáticamente a las otras instancias activas, asegurando la disponibilidad continua del servicio. Una estrategia de conmutación por error en espera caliente también ayuda a minimizar el tiempo de inactividad. En esta estrategia, una versión reducida de la aplicación siempre está funcionando en la región de respaldo. En caso de un fallo, el sistema puede escalar rápidamente para manejar la carga completa, reduciendo el tiempo de inactividad experimentado por los usuarios.",
        "Other Options": [
            "Una estrategia de respaldo y restauración, aunque útil para la recuperación de datos, no es la mejor opción para mantener la disponibilidad del servicio con un tiempo de inactividad mínimo. Restaurar desde un respaldo puede ser un proceso que consume tiempo, lo que lleva a períodos prolongados de inactividad.",
            "Una estrategia de conmutación por error de luz piloto implica mantener una versión mínima del entorno funcionando en la región secundaria. Aunque esta estrategia puede ser efectiva, puede no ser tan rápida para escalar a plena capacidad como la estrategia de espera caliente, lo que potencialmente lleva a períodos más largos de inactividad.",
            "Una estrategia de conmutación por error en frío implica no tener recursos funcionando en la región de respaldo hasta que ocurra un fallo. Esta estrategia puede llevar a los períodos más largos de inactividad, ya que los recursos deben ser completamente desplegados después de que ocurre un fallo, lo que puede llevar una cantidad significativa de tiempo."
        ]
    },
    {
        "Question Number": "7",
        "Situation": "Una startup está desarrollando un sistema de pujas en tiempo real para anuncios en línea que requiere una latencia extremadamente baja y un alto rendimiento para procesar las pujas. El sistema también debe ser altamente disponible y escalable sin intervención manual.",
        "Question": "¿Qué solución de base de datos de AWS debería recomendar el arquitecto de soluciones para cumplir con estos requisitos?",
        "Options": {
            "1": "Amazon RDS for MySQL con IOPS provisionadas",
            "2": "Amazon DynamoDB con modo de capacidad bajo demanda",
            "3": "Amazon ElastiCache for Redis en una configuración agrupada",
            "4": "Amazon Aurora Serverless con optimización en memoria"
        },
        "Correct Answer": "Amazon DynamoDB con modo de capacidad bajo demanda",
        "Explanation": "Amazon DynamoDB es un servicio de base de datos NoSQL totalmente gestionado que proporciona tiempos de respuesta de un solo dígito en milisegundos, lo que lo hace ideal para aplicaciones que requieren una latencia extremadamente baja. Su modo de capacidad bajo demanda permite que la base de datos se escale automáticamente hacia arriba y hacia abajo según el tráfico, asegurando un alto rendimiento sin intervención manual. Esto es particularmente beneficioso para un sistema de pujas en tiempo real donde el número de pujas puede fluctuar significativamente. Además, DynamoDB está diseñado para alta disponibilidad y durabilidad, lo que se alinea perfectamente con los requisitos del sistema de la startup.",
        "Other Options": [
            "Amazon RDS for MySQL con IOPS provisionadas es un servicio de base de datos relacional que puede proporcionar un alto rendimiento, pero puede no alcanzar la misma latencia baja que DynamoDB para cargas de trabajo de alta velocidad. Además, RDS requiere más gestión para escalar y garantizar disponibilidad en comparación con DynamoDB.",
            "Amazon ElastiCache for Redis en una configuración agrupada es un almacén de datos en memoria que puede proporcionar baja latencia, pero se utiliza principalmente para almacenamiento en caché en lugar de como base de datos principal. No proporciona inherentemente las características de durabilidad y persistencia requeridas para un sistema de pujas.",
            "Amazon Aurora Serverless con optimización en memoria es una base de datos relacional que puede escalar automáticamente, pero puede no proporcionar el mismo nivel de baja latencia y alto rendimiento que DynamoDB, especialmente bajo cargas de trabajo impredecibles típicas en escenarios de pujas en tiempo real."
        ]
    },
    {
        "Question Number": "8",
        "Situation": "Una empresa está desarrollando una aplicación sin servidor utilizando funciones de AWS Lambda. La aplicación necesita procesar imágenes subidas por los usuarios y almacenar los resultados en una base de datos. La arquitectura debe asegurar que cada imagen se procese exactamente una vez, incluso si la misma imagen se sube varias veces.",
        "Question": "¿Qué combinación de servicios de AWS debería utilizar el arquitecto de soluciones para lograr este requisito? (Elija DOS.)",
        "Options": {
            "1": "Amazon S3",
            "2": "Amazon DynamoDB con escrituras condicionales",
            "3": "Amazon Simple Queue Service (SQS)",
            "4": "Amazon Simple Notification Service (SNS)",
            "5": "AWS Step Functions"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon S3",
            "Amazon DynamoDB con escrituras condicionales"
        ],
        "Explanation": "Amazon S3 se puede utilizar para almacenar las imágenes subidas por los usuarios. También puede activar funciones de AWS Lambda cuando se sube una nueva imagen, que luego puede procesar la imagen. Amazon DynamoDB con escrituras condicionales se puede utilizar para almacenar los resultados del procesamiento de imágenes. Las escrituras condicionales aseguran que un elemento se escriba en la tabla solo si se cumple la condición especificada. En este caso, la condición podría ser que la imagen no se haya procesado antes, asegurando que cada imagen se procese exactamente una vez.",
        "Other Options": [
            "Amazon Simple Queue Service (SQS) es un servicio de colas de mensajes totalmente gestionado que permite desacoplar y escalar microservicios, sistemas distribuidos y aplicaciones sin servidor. Sin embargo, no impide inherentemente que el mismo mensaje se procese más de una vez.",
            "Amazon Simple Notification Service (SNS) es un servicio de mensajería totalmente gestionado para la comunicación entre aplicaciones (A2A) y de aplicación a persona (A2P). Sin embargo, no impide inherentemente que el mismo mensaje se procese más de una vez.",
            "AWS Step Functions es un servicio de flujo de trabajo sin servidor que te permite coordinar múltiples servicios de AWS en flujos de trabajo sin servidor. Si bien se puede utilizar para orquestar funciones de AWS Lambda, no impide inherentemente que la misma función se ejecute más de una vez para la misma entrada."
        ]
    },
    {
        "Question Number": "9",
        "Situation": "Una empresa está configurando un grupo de Auto Scaling para sus instancias de EC2 y quiere asegurarse de que pueden actualizar configuraciones sin tener que recrear toda la configuración.",
        "Question": "¿Qué opción deberían elegir y por qué?",
        "Options": {
            "1": "Usar Configuraciones de Lanzamiento, ya que admiten versionado y permiten actualizaciones sin recreación.",
            "2": "Usar Plantillas de Lanzamiento, ya que admiten versionado, lo que permite actualizaciones de configuración sin crear una nueva plantilla.",
            "3": "Usar Configuraciones de Lanzamiento, ya que son más fáciles de gestionar y tienen características de versionado integradas.",
            "4": "Usar Plantillas de Lanzamiento, ya que admiten actualizaciones en vivo directamente dentro del grupo de Auto Scaling sin control de versiones."
        },
        "Correct Answer": "Usar Plantillas de Lanzamiento, ya que admiten versionado, lo que permite actualizaciones de configuración sin crear una nueva plantilla.",
        "Explanation": "Las Plantillas de Lanzamiento son la opción recomendada para configurar grupos de Auto Scaling en AWS porque admiten versionado. Esto significa que cuando necesitas actualizar configuraciones, puedes crear una nueva versión de la Plantilla de Lanzamiento sin tener que recrear toda la configuración. Esta característica permite mayor flexibilidad y una gestión más fácil de las configuraciones a lo largo del tiempo, lo que la hace ideal para entornos que requieren actualizaciones o cambios frecuentes.",
        "Other Options": [
            "Usar Configuraciones de Lanzamiento, ya que admiten versionado y permiten actualizaciones sin recreación. - Esta opción es incorrecta porque las Configuraciones de Lanzamiento no admiten versionado. Una vez que se crea una Configuración de Lanzamiento, no se puede modificar; cualquier actualización requiere la creación de una nueva Configuración de Lanzamiento.",
            "Usar Configuraciones de Lanzamiento, ya que son más fáciles de gestionar y tienen características de versionado integradas. - Esta opción es incorrecta porque las Configuraciones de Lanzamiento no tienen características de versionado integradas. Son menos flexibles que las Plantillas de Lanzamiento, lo que puede llevar a una mayor carga de gestión cuando se necesitan actualizaciones.",
            "Usar Plantillas de Lanzamiento, ya que admiten actualizaciones en vivo directamente dentro del grupo de Auto Scaling sin control de versiones. - Esta opción es engañosa porque, aunque las Plantillas de Lanzamiento admiten versionado, no admiten actualizaciones en vivo directamente dentro del grupo de Auto Scaling. Las actualizaciones requieren crear una nueva versión de la plantilla, que luego se utiliza para nuevas instancias."
        ]
    },
    {
        "Question Number": "10",
        "Situation": "Una aplicación de atención médica necesita manejar millones de solicitudes por segundo, distribuyendo el tráfico entrante entre múltiples instancias de Amazon EC2 para un procesamiento eficiente. Debido a los requisitos de cumplimiento, la aplicación también necesita soportar cifrado de extremo a extremo para la transferencia segura de datos. Además, la aplicación debe operar con una latencia ultra baja, ya que procesa datos médicos sensibles al tiempo.",
        "Question": "¿Qué solución de balanceo de carga de AWS cumpliría mejor con estos requisitos?",
        "Options": {
            "1": "Application Load Balancer (ALB) con terminación SSL",
            "2": "Network Load Balancer (NLB) con oyentes TCP y TLS",
            "3": "Classic Load Balancer con oyentes HTTP y HTTPS",
            "4": "Amazon CloudFront con caché HTTPS"
        },
        "Correct Answer": "Network Load Balancer (NLB) con oyentes TCP y TLS",
        "Explanation": "El Network Load Balancer (NLB) está diseñado para manejar millones de solicitudes por segundo mientras mantiene una latencia ultra baja, lo que lo hace ideal para el procesamiento de datos médicos sensibles al tiempo. Opera en la capa de transporte (Capa 4) y puede distribuir eficientemente el tráfico TCP entre múltiples instancias de EC2. Además, el NLB soporta oyentes TLS, lo que permite el cifrado de extremo a extremo, cumpliendo con los requisitos de cumplimiento para la transferencia segura de datos. Esta combinación de alto rendimiento, baja latencia y soporte para cifrado hace que el NLB sea la mejor opción para esta aplicación de atención médica.",
        "Other Options": [
            "Application Load Balancer (ALB) con terminación SSL está diseñado principalmente para tráfico HTTP/HTTPS y opera en la Capa 7. Aunque soporta la terminación SSL, puede introducir latencia adicional debido a su procesamiento en la capa de aplicación, lo cual no es ideal para requisitos de latencia ultra baja.",
            "Classic Load Balancer con oyentes HTTP y HTTPS es una opción más antigua que no proporciona el mismo nivel de rendimiento y escalabilidad que el NLB. Opera tanto en la Capa 4 como en la Capa 7, pero carece de las características avanzadas y optimizaciones que se encuentran en el NLB, lo que lo hace menos adecuado para manejar millones de solicitudes por segundo de manera eficiente.",
            "Amazon CloudFront con caché HTTPS es una red de entrega de contenido (CDN) que puede almacenar contenido en ubicaciones de borde, lo que es beneficioso para la entrega de contenido estático. Sin embargo, no es un balanceador de carga y no distribuye directamente el tráfico entre instancias de EC2, lo que lo hace inadecuado para el requisito de distribuir el tráfico entrante para el procesamiento de datos médicos."
        ]
    },
    {
        "Question Number": "11",
        "Situation": "Una empresa de comercio electrónico global quiere asegurar alta disponibilidad y tolerancia a fallos para su sitio web dirigiendo el tráfico a múltiples regiones. Quieren hacer un failover automático a una región de respaldo si la región principal se vuelve no disponible.",
        "Question": "¿Qué configuración de Amazon Route 53 debería usar la empresa para lograr un failover DNS resiliente, y qué característica habilita esta funcionalidad?",
        "Options": {
            "1": "Usar Route 53 Weighted Routing para distribuir el tráfico entre regiones basado en pesos definidos y configurar chequeos de salud para el failover.",
            "2": "Usar Route 53 Latency-Based Routing para dirigir a los usuarios a la región con la latencia más baja, con chequeos de salud para hacer failover a otra región si es necesario.",
            "3": "Usar Route 53 Geolocation Routing para dirigir el tráfico basado en la ubicación del usuario y configurar chequeos de salud para redirigir a los usuarios si una región falla.",
            "4": "Usar Route 53 Failover Routing para dirigir el tráfico a una región primaria y redirigir automáticamente a una región secundaria en caso de fallo, utilizando chequeos de salud para monitorear la disponibilidad de la región primaria."
        },
        "Correct Answer": "Usar Route 53 Failover Routing para dirigir el tráfico a una región primaria y redirigir automáticamente a una región secundaria en caso de fallo, utilizando chequeos de salud para monitorear la disponibilidad de la región primaria.",
        "Explanation": "Route 53 Failover Routing está diseñado específicamente para escenarios donde la alta disponibilidad es crítica. Permite designar un recurso primario (en este caso, la región primaria) y un recurso secundario (la región de respaldo). Si los chequeos de salud determinan que la región primaria no está disponible, Route 53 redirige automáticamente el tráfico a la región secundaria. Esta configuración asegura que los usuarios experimenten una mínima interrupción y que el sitio web permanezca accesible incluso si una región falla.",
        "Other Options": [
            "Usar Route 53 Weighted Routing distribuye el tráfico basado en pesos definidos, pero no proporciona inherentemente un failover automático. Aunque se pueden configurar chequeos de salud, esta opción no está diseñada específicamente para escenarios de failover, lo que la hace menos adecuada para las necesidades de la empresa.",
            "Route 53 Latency-Based Routing dirige a los usuarios a la región con la latencia más baja, lo que es beneficioso para el rendimiento, pero no proporciona un mecanismo de failover directo. Aunque se pueden implementar chequeos de salud, esta opción se centra principalmente en optimizar la experiencia del usuario en lugar de asegurar disponibilidad durante fallos.",
            "Route 53 Geolocation Routing dirige el tráfico basado en la ubicación del usuario, lo que es útil para apuntar a regiones específicas, pero no proporciona capacidades de failover automático. Aunque se pueden configurar chequeos de salud, este método de enrutamiento no prioriza la disponibilidad de la misma manera que lo hace el Failover Routing."
        ]
    },
    {
        "Question Number": "12",
        "Situation": "Una empresa está diseñando una aplicación sin servidor para procesar las cargas de usuario y transformarlas en un formato específico. La aplicación debe escalar automáticamente para acomodar el tráfico fluctuante y manejar múltiples cargas de archivos de manera concurrente. La empresa quiere evitar gestionar servidores e infraestructura mientras asegura que los procesos de transformación se completen de manera rápida y confiable.",
        "Question": "¿Qué servicios de AWS debería usar la empresa para implementar esta solución? (Elija dos.)",
        "Options": {
            "1": "Usar AWS Lambda para activar las funciones de procesamiento cuando se carga un archivo en Amazon S3, y usar Amazon SQS para encolar tareas de transformación.",
            "2": "Usar AWS Fargate para ejecutar trabajos de procesamiento en contenedores, permitiendo escalado automático basado en el número de cargas.",
            "3": "Usar Amazon EC2 para gestionar la infraestructura y procesar archivos manualmente.",
            "4": "Usar Amazon S3 Event Notifications para activar funciones de AWS Lambda para procesar cada archivo cargado.",
            "5": "Usar Amazon S3 para procesar las cargas directamente, sin necesidad de activar funciones o servicios adicionales."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Usar AWS Lambda para activar las funciones de procesamiento cuando se carga un archivo en Amazon S3, y usar Amazon SQS para encolar tareas de transformación.",
            "Usar Amazon S3 Event Notifications para activar funciones de AWS Lambda para procesar cada archivo cargado."
        ],
        "Explanation": "AWS Lambda es un servicio de computación sin servidor que ejecuta tu código en respuesta a eventos, como cambios en los datos de un bucket de Amazon S3. Esto lo convierte en una opción adecuada para el requisito de la empresa de procesar cargas de usuario y transformarlas en un formato específico sin gestionar servidores. Amazon SQS es un servicio de colas de mensajes totalmente gestionado que te permite desacoplar y escalar microservicios, sistemas distribuidos y aplicaciones sin servidor. SQS elimina la complejidad y la sobrecarga asociadas con la gestión y operación de middleware orientado a mensajes, y empodera a los desarrolladores para centrarse en el trabajo diferenciador. Usar Amazon S3 Event Notifications junto con AWS Lambda permite a la empresa activar funciones de procesamiento inmediatamente después de que se carga un archivo, cumpliendo con el requisito de transformaciones rápidas y confiables.",
        "Other Options": [
            "AWS Fargate es un motor de computación sin servidor para contenedores. Aunque permite el escalado automático, es más complejo y menos directo que usar AWS Lambda para este caso de uso específico. También requeriría que la empresa gestionara aplicaciones en contenedores, lo que quieren evitar.",
            "Amazon EC2 es un servicio web que proporciona capacidad de computación redimensionable en la nube. Está diseñado para facilitar la computación en la nube a escala web, pero requiere gestión manual de la infraestructura, lo que la empresa quiere evitar.",
            "Amazon S3 es un servicio de almacenamiento, no tiene la capacidad de procesar cargas directamente o transformarlas en un formato específico. Puede almacenar y recuperar cualquier cantidad de datos, pero no puede realizar cálculos o transformaciones sobre esos datos."
        ]
    },
    {
        "Question Number": "13",
        "Situation": "Una empresa está desarrollando una aplicación de comercio electrónico y necesita implementar una arquitectura basada en eventos para gestionar los pedidos de los clientes, el procesamiento de pagos y las actualizaciones de inventario. Quieren asegurarse de que el sistema sea altamente disponible, escalable y desacoplado.",
        "Question": "¿Cuál de las siguientes arquitecturas debería utilizar la empresa para alcanzar estos objetivos?",
        "Options": {
            "1": "Utilizar Amazon SQS para desacoplar servicios y asegurar el procesamiento asíncrono de eventos. Usar AWS Lambda para procesar eventos y Amazon SNS para difundir eventos a múltiples suscriptores para notificaciones eficientes.",
            "2": "Utilizar instancias de Amazon EC2 con una cola de mensajes, donde cada instancia de EC2 procesa los eventos y envía actualizaciones a una base de datos de Amazon RDS.",
            "3": "Utilizar Amazon DynamoDB Streams para capturar datos de eventos y configurar AWS Step Functions para orquestar flujos de trabajo para el procesamiento de eventos.",
            "4": "Utilizar Amazon S3 para almacenar datos de eventos y configurar una instancia de EC2 para sondear el bucket de S3 en busca de nuevos eventos a procesar."
        },
        "Correct Answer": "Utilizar Amazon SQS para desacoplar servicios y asegurar el procesamiento asíncrono de eventos. Usar AWS Lambda para procesar eventos y Amazon SNS para difundir eventos a múltiples suscriptores para notificaciones eficientes.",
        "Explanation": "Esta opción implementa de manera efectiva una arquitectura basada en eventos que es altamente disponible, escalable y desacoplada. Amazon SQS (Simple Queue Service) permite la comunicación asíncrona entre servicios, lo que ayuda a desacoplarlos. AWS Lambda puede procesar eventos sin necesidad de gestionar servidores, permitiendo una escalabilidad automática basada en el número de eventos entrantes. Además, Amazon SNS (Simple Notification Service) puede difundir mensajes a múltiples suscriptores, asegurando que varios componentes de la aplicación puedan reaccionar a los eventos de manera eficiente. Esta combinación proporciona una solución robusta para manejar pedidos de clientes, procesamiento de pagos y actualizaciones de inventario de manera escalable.",
        "Other Options": [
            "Utilizar instancias de Amazon EC2 con una cola de mensajes introduce más complejidad y carga de gestión. Las instancias de EC2 requieren aprovisionamiento, escalado y mantenimiento, lo que contradice el objetivo de tener una arquitectura altamente disponible y escalable. Además, esta opción no aprovecha las capacidades sin servidor, lo que puede llevar a ineficiencias en la utilización de recursos.",
            "Utilizar Amazon DynamoDB Streams y AWS Step Functions es una opción viable, pero puede no ser tan sencilla como la primera opción. Si bien DynamoDB Streams puede capturar cambios en la base de datos, requiere configuración y gestión adicionales. AWS Step Functions son útiles para orquestar flujos de trabajo, pero pueden añadir complejidad innecesaria para tareas simples de procesamiento de eventos en comparación con el enfoque directo basado en eventos utilizando SQS y Lambda.",
            "Utilizar Amazon S3 para almacenar datos de eventos y sondear una instancia de EC2 en busca de nuevos eventos no es una solución ideal para una arquitectura basada en eventos. El sondeo introduce latencia y puede llevar a ineficiencias, ya que el sistema estaría esperando a que se procesen los eventos en lugar de reaccionar a ellos en tiempo real. Este enfoque también carece de los beneficios de desacoplamiento y escalabilidad que proporcionan las colas de mensajes y las funciones sin servidor."
        ]
    },
    {
        "Question Number": "14",
        "Situation": "Una gran plataforma de comercio electrónico experimenta un alto tráfico, especialmente durante eventos de ventas, lo que lleva a un aumento significativo en el número de conexiones a la base de datos. Para optimizar el rendimiento de la base de datos y prevenir sobrecargas, deciden utilizar un servicio proxy para gestionar estas conexiones de manera eficiente.",
        "Question": "¿Qué servicio de AWS deberían implementar para manejar las conexiones a la base de datos de manera eficiente y qué ventajas ofrece en términos de escalabilidad y conmutación por error?",
        "Options": {
            "1": "Amazon RDS Proxy, ya que agrupa y comparte conexiones a la base de datos, reduciendo la carga en la base de datos y mejorando la escalabilidad de la aplicación.",
            "2": "AWS App Mesh, que gestiona la comunicación de servicio a servicio pero no se especializa en manejar conexiones a bases de datos.",
            "3": "Amazon API Gateway, ya que proporciona un proxy para solicitudes de API, pero está diseñado principalmente para APIs RESTful, no para conexiones a bases de datos.",
            "4": "AWS Direct Connect, que proporciona una conexión de red dedicada pero no gestiona ni agrupa conexiones a bases de datos."
        },
        "Correct Answer": "Amazon RDS Proxy, ya que agrupa y comparte conexiones a la base de datos, reduciendo la carga en la base de datos y mejorando la escalabilidad de la aplicación.",
        "Explanation": "Amazon RDS Proxy está diseñado específicamente para gestionar conexiones a la base de datos de manera eficiente. Agrupa y comparte conexiones a la base de datos, lo que reduce el número de conexiones abiertas y la carga asociada en el servidor de la base de datos. Esto es particularmente beneficioso durante períodos de alto tráfico, como eventos de ventas, ya que permite que la aplicación escale de manera más efectiva sin abrumar la base de datos. Además, RDS Proxy proporciona capacidades de conmutación por error, permitiendo que las aplicaciones se reconecten automáticamente a una base de datos de reserva en caso de fallo, mejorando así la disponibilidad y fiabilidad.",
        "Other Options": [
            "AWS App Mesh es una malla de servicios que gestiona la comunicación de servicio a servicio, pero no se especializa en manejar conexiones a bases de datos. Se centra en la comunicación entre microservicios en lugar de en la agrupación o gestión de conexiones a bases de datos.",
            "Amazon API Gateway está diseñado para crear, publicar, mantener, monitorear y asegurar APIs a cualquier escala. Si bien actúa como un proxy para solicitudes de API, no está destinado a gestionar conexiones a bases de datos, que es el requisito principal en este escenario.",
            "AWS Direct Connect proporciona una conexión de red dedicada desde sus instalaciones a AWS, lo que puede mejorar el ancho de banda y reducir la latencia. Sin embargo, no gestiona ni agrupa conexiones a bases de datos, lo que lo hace inadecuado para la necesidad específica de optimizar el rendimiento de la base de datos durante un alto tráfico."
        ]
    },
    {
        "Question Number": "15",
        "Situation": "Una empresa de biotecnología ejecuta cargas de trabajo intensivas en computación para la secuenciación de ADN, que solo requiere recursos de computación unas pocas horas al día. Quieren minimizar costos pero asegurarse de que sus trabajos puedan completarse durante estas ventanas de tiempo.",
        "Question": "¿Qué opción de compra optimizaría mejor los costos para esta carga de trabajo?",
        "Options": {
            "1": "Instancias Reservadas con un compromiso de 1 año",
            "2": "Planes de Ahorro con un compromiso de 3 años",
            "3": "Instancias Spot con asignación optimizada de capacidad",
            "4": "Instancias bajo demanda con escalado automático programado"
        },
        "Correct Answer": "Instancias Spot con asignación optimizada de capacidad",
        "Explanation": "Las Instancias Spot permiten a los usuarios aprovechar la capacidad de computación no utilizada a precios significativamente más bajos en comparación con las Instancias bajo demanda o Reservadas. Dado que la empresa de biotecnología solo requiere recursos de computación durante unas pocas horas al día, utilizar Instancias Spot puede reducir drásticamente los costos, especialmente si pueden tolerar interrupciones. La asignación optimizada de capacidad asegura que las Instancias Spot tengan más probabilidades de estar disponibles cuando se necesiten, lo que las convierte en una opción adecuada para sus cargas de trabajo intensivas en computación que tienen ventanas de tiempo específicas.",
        "Other Options": [
            "Las Instancias Reservadas con un compromiso de 1 año no serían rentables para cargas de trabajo que solo se necesitan durante unas pocas horas al día, ya que requieren un compromiso de pago por la capacidad independientemente del uso.",
            "Los Planes de Ahorro con un compromiso de 3 años también implican un compromiso financiero a largo plazo que puede no alinearse con la naturaleza esporádica de la carga de trabajo, lo que podría llevar a recursos y costos desperdiciados.",
            "Las Instancias bajo demanda con escalado automático programado proporcionarían flexibilidad, pero generalmente son más caras que las Instancias Spot y no ofrecen el mismo nivel de ahorro de costos, especialmente para cargas de trabajo que pueden ejecutarse de manera intermitente."
        ]
    },
    {
        "Question Number": "16",
        "Situation": "Una empresa de servicios financieros está implementando una nueva aplicación que requiere cifrado continuo y sin interrupciones entre los dispositivos de los clientes y los servidores backend. Además, la aplicación debe utilizar una dirección IP estática para facilitar la lista blanca de IPs y mejorar la seguridad.",
        "Question": "¿Qué tipo de balanceador de carga de AWS debería desplegar la empresa para cumplir con estos requisitos, y cuáles son las razones principales para esta elección?",
        "Options": {
            "1": "Application Load Balancer (ALB) por su capacidad para realizar enrutamiento basado en contenido y manejar la terminación SSL.",
            "2": "Network Load Balancer (NLB) debido a su funcionamiento en la Capa 4, soporte para direcciones IP estáticas y capacidad para mantener cifrado de extremo a extremo a través del reenvío TCP.",
            "3": "Classic Load Balancer (CLB) porque soporta HTTPS y puede gestionar sesiones persistentes para conexiones seguras.",
            "4": "Application Load Balancer (ALB) ya que ofrece direcciones IP estáticas y asegura un alto rendimiento."
        },
        "Correct Answer": "Network Load Balancer (NLB) debido a su funcionamiento en la Capa 4, soporte para direcciones IP estáticas y capacidad para mantener cifrado de extremo a extremo a través del reenvío TCP.",
        "Explanation": "El Network Load Balancer (NLB) es la mejor opción para este escenario porque opera en la Capa 4 del modelo OSI, lo que le permite manejar el tráfico TCP de manera eficiente. Soporta direcciones IP estáticas, lo cual es esencial para el requisito de lista blanca de IPs de la empresa. Además, el NLB puede mantener el cifrado de extremo a extremo al reenviar el tráfico TCP sin desencriptarlo, asegurando que los datos permanezcan seguros entre los dispositivos de los clientes y los servidores backend. Esto se alinea perfectamente con la necesidad de cifrado continuo y sin interrupciones.",
        "Other Options": [
            "Application Load Balancer (ALB) está diseñado principalmente para tráfico de Capa 7 (capa de aplicación) y sobresale en el enrutamiento basado en contenido y la terminación SSL. Sin embargo, no soporta direcciones IP estáticas de forma nativa, lo cual es un requisito crítico en este caso.",
            "Classic Load Balancer (CLB) sí soporta HTTPS y puede gestionar sesiones persistentes, pero opera tanto en la Capa 4 como en la Capa 7. Carece de la capacidad para proporcionar direcciones IP estáticas y generalmente se considera menos eficiente que el NLB para escenarios de alto rendimiento, lo que lo hace menos adecuado para los requisitos expuestos.",
            "Application Load Balancer (ALB) no ofrece direcciones IP estáticas directamente, lo cual es un requisito clave para la lista blanca de IPs. Aunque proporciona un alto rendimiento y capacidades avanzadas de enrutamiento, no satisface la necesidad de mantener el cifrado de extremo a extremo tan eficazmente como el NLB."
        ]
    },
    {
        "Question Number": "17",
        "Situation": "Un proveedor de atención médica está diseñando una aplicación para garantizar un servicio ininterrumpido y proteger datos críticos de pacientes. La aplicación debe seguir operativa a pesar de cualquier fallo en los componentes, pero en caso de un desastre, el proveedor también quiere una estrategia para recuperar datos vitales.",
        "Question": "¿Cuál de los siguientes enfoques satisface mejor estos requisitos? (Elija dos.)",
        "Options": {
            "1": "Implementar Alta Disponibilidad desplegando recursos en múltiples Zonas de Disponibilidad, asegurando un tiempo de inactividad mínimo durante fallos de componentes y una recuperación más rápida.",
            "2": "Centrarse en la Tolerancia a Fallos configurando recursos en modo activo-activo en múltiples servidores, para que la aplicación continúe sin interrupciones incluso si un componente falla.",
            "3": "Desarrollar un plan de Recuperación ante Desastres (DR) programando copias de seguridad periódicas y estableciendo servidores en espera en una región separada, permitiendo que la aplicación se restaure en caso de un desastre regional.",
            "4": "Combinar Alta Disponibilidad y Recuperación ante Desastres desplegando en múltiples Zonas de Disponibilidad y programando copias de seguridad regulares, para mantener el tiempo de actividad y proteger los datos durante cualquier fallo o desastre.",
            "5": "Utilizar un despliegue en una única Zona de Disponibilidad con instantáneas automatizadas para asegurar la recuperación de datos en caso de fallo del servidor."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Implementar Alta Disponibilidad desplegando recursos en múltiples Zonas de Disponibilidad, asegurando un tiempo de inactividad mínimo durante fallos de componentes y una recuperación más rápida.",
            "Combinar Alta Disponibilidad y Recuperación ante Desastres desplegando en múltiples Zonas de Disponibilidad y programando copias de seguridad regulares, para mantener el tiempo de actividad y proteger los datos durante cualquier fallo o desastre."
        ],
        "Explanation": "La primera respuesta correcta se refiere a implementar Alta Disponibilidad. Este enfoque asegura que la aplicación permanezca operativa incluso si uno o más componentes fallan. Al desplegar recursos en múltiples Zonas de Disponibilidad, la aplicación puede seguir funcionando con un tiempo de inactividad mínimo durante fallos de componentes y recuperarse más rápidamente. La segunda respuesta correcta combina Alta Disponibilidad y Recuperación ante Desastres. Este enfoque no solo asegura el tiempo de actividad de la aplicación durante fallos de componentes, sino que también protege los datos críticos de los pacientes al programar copias de seguridad regulares. En caso de un desastre, los datos pueden ser recuperados, asegurando la continuidad de la aplicación.",
        "Other Options": [
            "Centrarse en la Tolerancia a Fallos configurando recursos en modo activo-activo en múltiples servidores no es suficiente. Aunque asegura que la aplicación continúe sin interrupciones incluso si un componente falla, no proporciona una estrategia para la recuperación de datos en caso de un desastre.",
            "Desarrollar un plan de Recuperación ante Desastres (DR) programando copias de seguridad periódicas y estableciendo servidores en espera en una región separada es una buena estrategia para la recuperación de datos. Sin embargo, no asegura el servicio ininterrumpido de la aplicación en caso de fallos de componentes.",
            "Utilizar un despliegue en una única Zona de Disponibilidad con instantáneas automatizadas puede asegurar la recuperación de datos en caso de fallo del servidor. Sin embargo, no proporciona alta disponibilidad ni tolerancia a fallos, ya que un fallo en la única Zona de Disponibilidad podría llevar a un tiempo de inactividad de la aplicación."
        ]
    },
    {
        "Question Number": "18",
        "Situation": "Una plataforma de trading financiero está alojada en instancias de Amazon EC2 y requiere un volumen EBS que pueda soportar IOPS extremadamente altos (operaciones de entrada/salida por segundo) para una base de datos de alta frecuencia sensible a la latencia. La plataforma necesita hasta 250,000 IOPS y un alto rendimiento para un rendimiento óptimo.",
        "Question": "¿Qué tipo de volumen EBS satisfaría mejor estos requisitos?",
        "Options": {
            "1": "General Purpose SSD (gp3)",
            "2": "Provisioned IOPS SSD (io2)",
            "3": "Throughput Optimized HDD (st1)",
            "4": "Cold HDD (sc1)"
        },
        "Correct Answer": "Provisioned IOPS SSD (io2)",
        "Explanation": "El tipo de volumen Provisioned IOPS SSD (io2) está diseñado específicamente para aplicaciones intensivas en I/O que requieren alto rendimiento y baja latencia. Puede soportar hasta 256,000 IOPS por volumen, lo que lo hace adecuado para el requisito de hasta 250,000 IOPS de la plataforma de trading financiero. Además, los volúmenes io2 ofrecen un alto rendimiento y están optimizados para cargas de trabajo sensibles a la latencia, lo que los convierte en la mejor opción para una base de datos de alta frecuencia.",
        "Other Options": [
            "Los volúmenes General Purpose SSD (gp3) pueden proporcionar hasta 16,000 IOPS y son adecuados para una variedad de cargas de trabajo, pero no cumplen con el requisito de 250,000 IOPS necesario para esta aplicación específica.",
            "Los volúmenes Throughput Optimized HDD (st1) están diseñados para cargas de trabajo que requieren un alto rendimiento en lugar de altas IOPS. No son adecuados para aplicaciones sensibles a la latencia como una base de datos de alta frecuencia, ya que solo pueden proporcionar un máximo de 500 IOPS por volumen.",
            "Los volúmenes Cold HDD (sc1) están destinados a datos a los que se accede con poca frecuencia y ofrecen el rendimiento más bajo entre los tipos de volúmenes EBS, con un máximo de 250 IOPS por volumen. Esto los hace inadecuados para aplicaciones de alto rendimiento y sensibles a la latencia."
        ]
    },
    {
        "Question Number": "19",
        "Situation": "Una institución financiera opera aplicaciones críticas que requieren conectividad estable, de alta capacidad y baja latencia entre sus centros de datos locales y AWS para soportar el procesamiento de datos en tiempo real y actividades de trading. Quieren asegurarse de que todas las transferencias de datos se realicen a través de una conexión segura y privada que evite el internet público, protegiéndose contra posibles riesgos de seguridad y variabilidad en el rendimiento.",
        "Question": "¿Qué opciones cumplirían mejor con sus requisitos? (Elige dos.)",
        "Options": {
            "1": "Usar una línea arrendada de alta velocidad de un proveedor de telecomunicaciones directamente a AWS",
            "2": "Establecer una VPN Site-to-Site de AWS a través del internet público",
            "3": "Desplegar AWS Direct Connect para una conexión de red privada y dedicada",
            "4": "Configurar un protocolo de transferencia de archivos (FTP) cifrado para sincronizaciones de datos periódicas",
            "5": "Implementar AWS Transit Gateway con Direct Connect Gateway para conectividad entre múltiples regiones"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Usar una línea arrendada de alta velocidad de un proveedor de telecomunicaciones directamente a AWS",
            "Desplegar AWS Direct Connect para una conexión de red privada y dedicada"
        ],
        "Explanation": "Usar una línea arrendada de alta velocidad de un proveedor de telecomunicaciones directamente a AWS y desplegar AWS Direct Connect para una conexión de red privada y dedicada son las mejores opciones para esta institución financiera. Estas opciones proporcionan una conexión estable, de alta capacidad y baja latencia que evita el internet público, lo cual es crucial para el procesamiento de datos en tiempo real y actividades de trading de la institución. AWS Direct Connect, en particular, proporciona una conexión de red dedicada desde los centros de datos locales de la institución a AWS, asegurando una conexión segura y confiable.",
        "Other Options": [
            "Establecer una VPN Site-to-Site de AWS a través del internet público no es la mejor opción porque aún utiliza el internet público, lo que puede llevar a variabilidad en el rendimiento y posibles riesgos de seguridad.",
            "Configurar un protocolo de transferencia de archivos (FTP) cifrado para sincronizaciones de datos periódicas no cumple con el requisito de procesamiento de datos en tiempo real y actividades de trading, ya que está diseñado para transferencias de datos periódicas, no en tiempo real.",
            "Implementar AWS Transit Gateway con Direct Connect Gateway para conectividad entre múltiples regiones no es necesariamente requerido para las necesidades de la institución. Aunque proporciona conectividad entre múltiples regiones, no proporciona inherentemente la conexión de alta capacidad y baja latencia requerida para el procesamiento de datos en tiempo real y actividades de trading."
        ]
    },
    {
        "Question Number": "20",
        "Situation": "Imagina que estás gestionando una aplicación que procesa archivos de video para transcodificación y tiene una demanda fluctuante. Para asegurar un procesamiento resiliente y eficiente, utilizas Amazon SQS para la cola de mensajes y Grupos de Auto Scaling (ASGs) para tu grupo de trabajadores. Sin embargo, algunos mensajes ocasionalmente fallan y necesitan un manejo especial para evitar la sobrecarga del sistema.",
        "Question": "¿Qué enfoque deberías implementar para mejorar la resiliencia y asegurar que los mensajes fallidos sean manejados de manera efectiva?",
        "Options": {
            "1": "Usar una Cola de Mensajes Muertos (DLQ) dentro de SQS para capturar mensajes problemáticos que fallan en el procesamiento múltiples veces.",
            "2": "Configurar políticas de escalado de ASG para agregar instancias solo cuando la utilización de CPU supere el 80%.",
            "3": "Usar Amazon RDS para almacenar y reintentar mensajes fallidos hasta que sean procesados con éxito.",
            "4": "Configurar Alarmas de CloudWatch para notificarte cada vez que un mensaje falla, para que puedas reprocesarlo manualmente."
        },
        "Correct Answer": "Usar una Cola de Mensajes Muertos (DLQ) dentro de SQS para capturar mensajes problemáticos que fallan en el procesamiento múltiples veces.",
        "Explanation": "Una Cola de Mensajes Muertos (DLQ) está diseñada específicamente para manejar mensajes que no pueden ser procesados con éxito después de un número especificado de intentos. Al usar una DLQ, puedes aislar estos mensajes problemáticos para una investigación adicional sin afectar el procesamiento de otros mensajes en la cola. Este enfoque mejora la resiliencia de tu aplicación al prevenir que las fallas en el procesamiento de mensajes abrumen tu sistema y permite una depuración y manejo más fácil de los mensajes fallidos.",
        "Other Options": [
            "Configurar políticas de escalado de ASG para agregar instancias solo cuando la utilización de CPU supere el 80% no aborda directamente el problema del procesamiento de mensajes fallidos. Aunque puede ayudar a gestionar la asignación de recursos, no proporciona un mecanismo para manejar mensajes que fallan en procesarse, que es el problema central en este escenario.",
            "Usar Amazon RDS para almacenar y reintentar mensajes fallidos hasta que sean procesados con éxito no es una solución óptima. RDS es un servicio de base de datos relacional y no está diseñado para la cola de mensajes. Este enfoque introduciría complejidad y latencia innecesarias, ya que requeriría lógica adicional para gestionar el estado de los mensajes y sus reintentos.",
            "Configurar Alarmas de CloudWatch para notificarte cada vez que un mensaje falla crearía un enfoque reactivo en lugar de uno proactivo. Aunque podría ayudarte a monitorear fallas, no proporciona una forma automatizada de manejar mensajes fallidos, lo cual es esencial para mantener la resiliencia y eficiencia del sistema."
        ]
    },
    {
        "Question Number": "21",
        "Situation": "Una empresa de servicios financieros está desplegando una aplicación que requiere cifrado rápido y continuo entre los clientes y las instancias de backend, y la capacidad de usar una IP estática para la lista blanca.",
        "Question": "¿Qué tipo de balanceador de carga de AWS es más adecuado para este escenario, y por qué?",
        "Options": {
            "1": "Application Load Balancer (ALB), porque permite el enrutamiento basado en contenido y proporciona terminación SSL.",
            "2": "Network Load Balancer (NLB), porque opera en la Capa 4, soporta IPs estáticas y permite cifrado continuo con reenvío TCP.",
            "3": "Classic Load Balancer (CLB), porque es compatible con HTTPS y soporta sesiones persistentes para conexiones seguras.",
            "4": "Application Load Balancer (ALB), porque soporta direcciones IP estáticas y proporciona alta capacidad."
        },
        "Correct Answer": "Network Load Balancer (NLB), porque opera en la Capa 4, soporta IPs estáticas y permite cifrado continuo con reenvío TCP.",
        "Explanation": "El Network Load Balancer (NLB) es la opción más adecuada para este escenario porque opera en la Capa 4 (Capa de Transporte) del modelo OSI, lo que le permite manejar tráfico TCP directamente. Esta capacidad le permite mantener un cifrado continuo entre los clientes y las instancias de backend, ya que puede reenviar paquetes TCP sin desencriptarlos. Además, el NLB soporta direcciones IP estáticas, lo cual es esencial para fines de lista blanca. Esta combinación de características hace que el NLB sea ideal para aplicaciones que requieren conexiones rápidas y seguras con IPs estáticas.",
        "Other Options": [
            "El Application Load Balancer (ALB) no es adecuado porque, aunque proporciona terminación SSL y enrutamiento basado en contenido, opera en la Capa 7 (Capa de Aplicación), lo que significa que desencriptaría el tráfico, potencialmente rompiendo el requisito de cifrado continuo.",
            "El Classic Load Balancer (CLB) no es la mejor opción porque, aunque soporta HTTPS, es una tecnología más antigua que no proporciona el mismo nivel de rendimiento y características que el NLB. También no soporta IPs estáticas de la misma manera que el NLB.",
            "El Application Load Balancer (ALB) se indica incorrectamente que soporta direcciones IP estáticas; no proporciona IPs estáticas directamente. En su lugar, utiliza IPs dinámicas y requiere configuraciones adicionales (como usar un NLB delante) para lograr la funcionalidad de IP estática."
        ]
    },
    {
        "Question Number": "22",
        "Situation": "Una empresa tiene un bucket S3 llamado \"secretcatproject\" que contiene datos sensibles. La empresa necesita permitir el acceso a este bucket desde usuarios específicos en una cuenta asociada, asegurando al mismo tiempo que los datos permanezcan seguros y no sean accesibles al público.",
        "Question": "¿Qué método debería utilizar la empresa para otorgar el acceso necesario mientras previene el acceso no autorizado por parte de usuarios anónimos?",
        "Options": {
            "1": "Establecer la política del bucket para permitir el acceso público a todos los usuarios para simplificar la gestión de accesos.",
            "2": "Utilizar una política de bucket S3 que especifique los roles IAM de la cuenta asociada como principales con permiso para acceder al bucket.",
            "3": "Habilitar \"Bloquear el acceso público\" en el bucket y utilizar listas de control de acceso (ACLs) para gestionar el acceso de la cuenta asociada.",
            "4": "Adjuntar una política IAM directamente al bucket para controlar el acceso de los usuarios en la cuenta asociada."
        },
        "Correct Answer": "Utilizar una política de bucket S3 que especifique los roles IAM de la cuenta asociada como principales con permiso para acceder al bucket.",
        "Explanation": "Utilizar una política de bucket S3 para especificar los roles IAM de la cuenta asociada como principales permite un control detallado sobre quién puede acceder al bucket. Este método asegura que solo los usuarios designados de la cuenta asociada puedan acceder a los datos sensibles, al mismo tiempo que se previene cualquier acceso público. Las políticas de bucket son herramientas poderosas para gestionar permisos y pueden adaptarse a requisitos de seguridad específicos, lo que hace que este sea el método más seguro y apropiado para la situación descrita.",
        "Other Options": [
            "Establecer la política del bucket para permitir el acceso público a todos los usuarios expondría los datos sensibles a cualquier persona en Internet, lo que es contrario al requisito de mantener los datos seguros frente al acceso público.",
            "Habilitar 'Bloquear el acceso público' en el bucket y utilizar listas de control de acceso (ACLs) no es la mejor práctica para gestionar el acceso. Aunque previene el acceso público, las ACLs pueden ser complejas y menos manejables que las políticas de bucket, especialmente al tratar con accesos entre cuentas. Las políticas de bucket son generalmente preferidas para este propósito.",
            "Adjuntar una política IAM directamente al bucket no es posible, ya que las políticas IAM se adjuntan a usuarios, grupos o roles IAM, no directamente a buckets S3. El control de acceso para los buckets S3 se gestiona a través de políticas de bucket o ACLs, lo que hace que esta opción sea incorrecta."
        ]
    },
    {
        "Question Number": "23",
        "Situation": "Una empresa de salud necesita respaldar los datos de los pacientes en AWS para fines de recuperación ante desastres. Para reducir costos, requieren una solución que minimice los costos de almacenamiento mientras asegura la retención a largo plazo de las copias de seguridad. También quieren la opción de recuperar datos en unas pocas horas si es necesario.",
        "Question": "¿Qué estrategias de respaldo cumplirían mejor con estos requisitos? (Elija dos.)",
        "Options": {
            "1": "Almacenar copias de seguridad en Amazon S3 Standard",
            "2": "Utilizar Amazon S3 Glacier Flexible Retrieval para almacenamiento de archivos de archivo",
            "3": "Almacenar copias de seguridad en Amazon S3 Standard-IA",
            "4": "Utilizar instantáneas de Amazon EBS almacenadas en la misma región",
            "5": "Implementar AWS Backup con políticas de ciclo de vida para trasladar copias de seguridad a clases de almacenamiento de menor costo"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Utilizar Amazon S3 Glacier Flexible Retrieval para almacenamiento de archivos de archivo",
            "Implementar AWS Backup con políticas de ciclo de vida para trasladar copias de seguridad a clases de almacenamiento de menor costo"
        ],
        "Explanation": "Amazon S3 Glacier Flexible Retrieval es una solución rentable para el almacenamiento a largo plazo de datos y permite la recuperación de datos en unas pocas horas, lo que se alinea con los requisitos de la empresa. AWS Backup con políticas de ciclo de vida permite la transición automática de copias de seguridad a clases de almacenamiento de menor costo después de un cierto período, lo que puede reducir significativamente los costos de almacenamiento con el tiempo.",
        "Other Options": [
            "Almacenar copias de seguridad en Amazon S3 Standard no es la solución más rentable para la retención de datos a largo plazo. Aunque proporciona alta durabilidad, disponibilidad y rendimiento, su costo es más alto en comparación con otras clases de almacenamiento como S3 Glacier o S3 Standard-IA.",
            "Almacenar copias de seguridad en Amazon S3 Standard-IA (Acceso poco frecuente) podría ser una solución rentable para datos que se acceden con menos frecuencia, pero puede no proporcionar el mismo nivel de ahorro de costos para almacenamiento a largo plazo como S3 Glacier o AWS Backup con políticas de ciclo de vida.",
            "Utilizar instantáneas de Amazon EBS almacenadas en la misma región no necesariamente minimiza los costos de almacenamiento, especialmente para la retención a largo plazo. Además, almacenar copias de seguridad en la misma región no proporciona la redundancia geográfica que a menudo se desea para fines de recuperación ante desastres."
        ]
    },
    {
        "Question Number": "24",
        "Situation": "Un sitio web de noticias almacena archivos multimedia en Amazon S3. Estos archivos se acceden con frecuencia dentro de los primeros 7 días después de ser subidos, pero tienen muy poco acceso después de ese período. El sitio web quiere reducir los costos de almacenamiento basándose en estos patrones de acceso.",
        "Question": "¿Qué configuración de almacenamiento optimizaría mejor los costos?",
        "Options": {
            "1": "Almacenar todos los archivos en S3 Standard",
            "2": "Almacenar archivos en S3 Intelligent-Tiering",
            "3": "Mover archivos a S3 Standard-IA después de 7 días",
            "4": "Utilizar S3 Glacier para todos los archivos multimedia"
        },
        "Correct Answer": "Mover archivos a S3 Standard-IA después de 7 días",
        "Explanation": "Mover archivos a S3 Standard-IA (Acceso poco frecuente) después de 7 días es la mejor opción porque está diseñado para datos que se acceden con menos frecuencia pero requieren acceso rápido cuando es necesario. Dado que los archivos multimedia se acceden con frecuencia dentro de los primeros 7 días y tienen poco acceso después, la transición a Standard-IA después de este período reducirá significativamente los costos de almacenamiento mientras permite un acceso rápido cuando sea necesario. S3 Standard-IA ofrece costos de almacenamiento más bajos en comparación con S3 Standard, lo que lo convierte en una solución rentable para el patrón de acceso descrito.",
        "Other Options": [
            "Almacenar todos los archivos en S3 Standard no optimizaría los costos, ya que S3 Standard es más caro que S3 Standard-IA para datos de acceso poco frecuente. Esta opción no aprovecha los costos más bajos disponibles para datos que no se acceden con frecuencia después de los primeros 7 días.",
            "Almacenar archivos en S3 Intelligent-Tiering podría ser una opción viable, pero incurre en costos adicionales debido a la monitorización y el escalado automático. Dado que el patrón de acceso es predecible (acceso frecuente en los primeros 7 días y poco acceso después), mover manualmente los archivos a Standard-IA después de 7 días es más rentable que utilizar Intelligent-Tiering.",
            "Utilizar S3 Glacier para todos los archivos multimedia no es adecuado porque Glacier está diseñado para almacenamiento de archivo y tiene tiempos de recuperación que pueden variar de minutos a horas. Esto no cumpliría con el requisito de acceso rápido a archivos que aún pueden ser necesarios poco después de la carga inicial."
        ]
    },
    {
        "Question Number": "25",
        "Situation": "Una empresa ha creado recientemente una nueva cuenta de AWS, y el fundador está utilizando actualmente el usuario root para gestionar los recursos dentro de la cuenta. El usuario root tiene control total y sin restricciones sobre todos los recursos en la cuenta, y por defecto, ningún otro usuario tiene permisos hasta que se le otorguen explícitamente. Para mejorar la seguridad, el fundador quiere delegar responsabilidades a otros miembros del equipo creando usuarios IAM con permisos específicos en lugar de usar la cuenta root para tareas diarias.",
        "Question": "¿Qué acciones debería tomar el fundador para asegurar que la cuenta de AWS permanezca segura mientras gestiona el acceso de manera efectiva? (Elija dos.)",
        "Options": {
            "1": "Continuar usando el usuario root para todas las tareas administrativas diarias y crear usuarios IAM con acceso solo de lectura para los miembros del equipo.",
            "2": "Activar la Autenticación Multifactor (MFA) en la cuenta root, crear usuarios IAM para cada miembro del equipo con los permisos necesarios y evitar usar la cuenta root para actividades regulares.",
            "3": "Compartir las credenciales de la cuenta root con los miembros del equipo y configurar grupos IAM para organizar los permisos.",
            "4": "Crear un usuario root separado para cada miembro del equipo para darles acceso directo a la cuenta de AWS.",
            "5": "Rotar regularmente las claves de acceso root y limitar el uso de la cuenta root a tareas esenciales."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Activar la Autenticación Multifactor (MFA) en la cuenta root, crear usuarios IAM para cada miembro del equipo con los permisos necesarios y evitar usar la cuenta root para actividades regulares.",
            "Rotar regularmente las claves de acceso root y limitar el uso de la cuenta root a tareas esenciales."
        ],
        "Explanation": "Activar la Autenticación Multifactor (MFA) en la cuenta root añade una capa extra de seguridad al requerir dos formas de identificación para iniciar sesión. Crear usuarios IAM para cada miembro del equipo permite al fundador delegar responsabilidades y gestionar el acceso de manera efectiva al otorgar permisos específicos a cada usuario. De esta manera, la cuenta root, que tiene control total sobre todos los recursos, no se utiliza para actividades regulares, reduciendo el riesgo de cambios accidentales o brechas de seguridad. Rotar regularmente las claves de acceso root es otra buena práctica para mantener la seguridad. Esto asegura que, incluso si una clave se ve comprometida, solo será válida por un período limitado. Limitar el uso de la cuenta root a tareas esenciales también minimiza el riesgo de cambios accidentales o brechas de seguridad.",
        "Other Options": [
            "Continuar usando el usuario root para todas las tareas administrativas diarias no es una buena práctica, ya que aumenta el riesgo de cambios accidentales o brechas de seguridad. Crear usuarios IAM con acceso solo de lectura para los miembros del equipo limita su capacidad para realizar tareas necesarias.",
            "Compartir las credenciales de la cuenta root con los miembros del equipo es un grave riesgo de seguridad. Les da control total y sin restricciones sobre todos los recursos en la cuenta. Configurar grupos IAM para organizar los permisos es una buena práctica, pero debe hacerse con usuarios IAM, no con la cuenta root.",
            "Crear un usuario root separado para cada miembro del equipo no es posible. AWS permite solo un usuario root por cuenta. Además, dar acceso directo a la cuenta de AWS a los miembros del equipo es un grave riesgo de seguridad."
        ]
    },
    {
        "Question Number": "26",
        "Situation": "Una empresa quiere construir una aplicación de servicio al cliente que pueda analizar la retroalimentación de los clientes para identificar temas clave y sentimientos, y luego convertir el análisis en un resumen de audio para accesibilidad.",
        "Question": "¿Qué combinación de servicios gestionados por AWS sería más apropiada para estas tareas, y por qué? (Elija dos.)",
        "Options": {
            "1": "Amazon SageMaker y Amazon Rekognition, porque permiten modelado avanzado de aprendizaje automático y capacidades de reconocimiento de imágenes.",
            "2": "Amazon Comprehend y Amazon Polly, ya que Comprehend puede analizar texto para temas y sentimientos, mientras que Polly puede convertir texto en voz natural.",
            "3": "AWS Glue y Amazon Athena, para procesar datos de retroalimentación y realizar consultas complejas sobre datos estructurados.",
            "4": "Amazon Translate y Amazon Lex, para traducir la retroalimentación de los clientes a diferentes idiomas y construir interfaces conversacionales.",
            "5": "Amazon Transcribe y Amazon Translate, para transcribir retroalimentación hablada y traducirla a múltiples idiomas."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon SageMaker y Amazon Rekognition, porque permiten modelado avanzado de aprendizaje automático y capacidades de reconocimiento de imágenes.",
            "Amazon Comprehend y Amazon Polly, ya que Comprehend puede analizar texto para temas y sentimientos, mientras que Polly puede convertir texto en voz natural."
        ],
        "Explanation": "Amazon SageMaker es un servicio completamente gestionado que proporciona a cada desarrollador y científico de datos la capacidad de construir, entrenar y desplegar modelos de aprendizaje automático (ML) rápidamente. SageMaker elimina la carga pesada de cada paso del proceso de aprendizaje automático para facilitar el desarrollo de modelos de alta calidad. Amazon Rekognition facilita la adición de análisis de imágenes y videos a tus aplicaciones utilizando tecnología de aprendizaje profundo probada y altamente escalable que no requiere experiencia en aprendizaje automático para usar. Amazon Comprehend utiliza aprendizaje automático para encontrar información y relaciones en el texto. Puede identificar el idioma del texto; extraer frases clave, lugares, personas, marcas o eventos; entender cuán positivo o negativo es el texto; analizar texto utilizando tokenización y partes del habla; y organizar automáticamente una colección de archivos de texto por tema. Amazon Polly es un servicio que convierte texto en voz realista, permitiéndote crear aplicaciones que hablan y construir categorías completamente nuevas de productos habilitados para voz.",
        "Other Options": [
            "AWS Glue y Amazon Athena se utilizan para trabajos de ETL (Extraer, Transformar, Cargar) y consultar datos, no para análisis de sentimientos o conversión de texto a voz.",
            "Amazon Translate y Amazon Lex se utilizan para traducción de idiomas y construcción de interfaces conversacionales, no para análisis de sentimientos o conversión de texto a voz.",
            "Amazon Transcribe y Amazon Translate se utilizan para transcribir retroalimentación hablada y traducirla a múltiples idiomas, no para análisis de sentimientos o conversión de texto a voz."
        ]
    },
    {
        "Question Number": "27",
        "Situation": "Tu equipo está diseñando una aplicación altamente resiliente que depende de una base de datos backend para la recuperación rápida de datos y durabilidad.",
        "Question": "¿Qué característica de Amazon DynamoDB mejoraría la resiliencia y garantizaría la disponibilidad de datos en caso de fallos regionales?",
        "Options": {
            "1": "DynamoDB Streams, que permite la replicación en tiempo real de cambios a otros servicios de AWS.",
            "2": "DynamoDB Global Tables, que permite la replicación en múltiples regiones para conmutación por error automática y resiliencia entre regiones.",
            "3": "DynamoDB Accelerator (DAX), que proporciona almacenamiento en caché en memoria para acelerar los tiempos de lectura durante cargas máximas.",
            "4": "DynamoDB Auto Scaling, que ajusta dinámicamente el rendimiento de lectura y escritura para coincidir con los picos de demanda."
        },
        "Correct Answer": "DynamoDB Global Tables, que permite la replicación en múltiples regiones para conmutación por error automática y resiliencia entre regiones.",
        "Explanation": "DynamoDB Global Tables proporciona una solución completamente gestionada para implementar bases de datos replicadas completamente en múltiples regiones. Esta característica asegura que tu aplicación pueda seguir funcionando incluso en caso de un fallo regional, ya que replica automáticamente los datos a través de múltiples regiones de AWS. Esta replicación permite la conmutación por error automática, lo que significa que si una región se vuelve no disponible, la aplicación puede cambiar sin problemas a otra región donde los datos aún son accesibles, mejorando así la resiliencia y asegurando la disponibilidad de datos.",
        "Other Options": [
            "DynamoDB Streams permite la replicación en tiempo real de cambios a otros servicios de AWS, pero no proporciona replicación en múltiples regiones ni capacidades de conmutación por error automática. Es más adecuado para arquitecturas impulsadas por eventos en lugar de garantizar la resiliencia contra fallos regionales.",
            "DynamoDB Accelerator (DAX) está diseñado para mejorar el rendimiento de lectura proporcionando almacenamiento en caché en memoria, lo que puede ayudar durante cargas máximas, pero no aborda el problema de la disponibilidad de datos en caso de fallos regionales.",
            "DynamoDB Auto Scaling ajusta el rendimiento de lectura y escritura según los picos de demanda, lo que es beneficioso para el rendimiento y la gestión de costos, pero no mejora la resiliencia ni asegura la disponibilidad de datos a través de regiones en caso de fallos."
        ]
    },
    {
        "Question Number": "28",
        "Situation": "Una empresa necesita asegurarse de que los datos sensibles almacenados en Amazon S3 estén cifrados en reposo utilizando claves gestionadas por el cliente.",
        "Question": "¿Qué servicio debería utilizar la empresa para gestionar las claves de cifrado?",
        "Options": {
            "1": "AWS Certificate Manager (ACM)",
            "2": "AWS Key Management Service (AWS KMS)",
            "3": "Amazon S3 Server-Side Encryption with AES-256",
            "4": "AWS Secrets Manager"
        },
        "Correct Answer": "AWS Key Management Service (AWS KMS)",
        "Explanation": "AWS Key Management Service (AWS KMS) está diseñado específicamente para gestionar claves de cifrado y proporciona una forma centralizada de crear, gestionar y controlar el uso de claves criptográficas en los servicios de AWS. Al utilizar AWS KMS, puedes crear claves gestionadas por el cliente (CMKs) que se pueden utilizar para cifrar datos almacenados en Amazon S3. Esto permite un control detallado sobre quién puede usar las claves y cómo se pueden utilizar, asegurando que los datos sensibles estén cifrados en reposo de acuerdo con los requisitos de seguridad de la empresa.",
        "Other Options": [
            "AWS Certificate Manager (ACM) se utiliza principalmente para gestionar certificados SSL/TLS para asegurar sitios web y aplicaciones. No proporciona funcionalidad para gestionar claves de cifrado para datos en reposo en servicios como Amazon S3.",
            "Amazon S3 Server-Side Encryption with AES-256 ofrece cifrado en reposo, pero utiliza claves gestionadas por AWS de forma predeterminada. Aunque también puede utilizar claves gestionadas por el cliente, no proporciona las capacidades de gestión de claves que ofrece AWS KMS, lo que hace que AWS KMS sea la opción más adecuada para gestionar claves de cifrado.",
            "AWS Secrets Manager está diseñado para gestionar secretos como claves API, credenciales de bases de datos y otra información sensible. No está destinado a gestionar claves de cifrado para datos en reposo en Amazon S3."
        ]
    },
    {
        "Question Number": "29",
        "Situation": "Una aplicación de redes sociales tiene una base de datos MySQL que recibe solicitudes de lectura frecuentes para contenido popular. Para reducir los costos de la base de datos y mejorar los tiempos de respuesta, quieren implementar una capa de caché para descargar lecturas de la base de datos.",
        "Question": "¿Qué estrategia de caché sería la más rentable para este escenario?",
        "Options": {
            "1": "Usar Amazon S3 para almacenar en caché contenido de acceso frecuente",
            "2": "Implementar caché en memoria con un servicio gestionado como Amazon ElastiCache",
            "3": "Crear múltiples réplicas de lectura de la base de datos MySQL",
            "4": "Usar un sistema de procesamiento por lotes para precomputar consultas populares"
        },
        "Correct Answer": "Implementar caché en memoria con un servicio gestionado como Amazon ElastiCache",
        "Explanation": "Implementar caché en memoria con un servicio gestionado como Amazon ElastiCache es la estrategia más rentable para este escenario porque permite un acceso rápido a datos solicitados con frecuencia, reduciendo significativamente la carga en la base de datos MySQL. Las cachés en memoria almacenan datos en RAM, lo que proporciona tiempos de lectura mucho más rápidos en comparación con soluciones de almacenamiento basadas en disco. Este enfoque puede manejar tráfico de lectura alto de manera eficiente y puede escalar según sea necesario, lo que lo hace ideal para aplicaciones con solicitudes de lectura frecuentes para contenido popular.",
        "Other Options": [
            "Usar Amazon S3 para almacenar en caché contenido de acceso frecuente no es adecuado porque S3 es principalmente un servicio de almacenamiento de objetos, que está optimizado para durabilidad y disponibilidad en lugar de velocidad. Acceder a datos desde S3 implica una latencia más alta en comparación con la caché en memoria, lo que lo hace menos efectivo para reducir los tiempos de respuesta en un escenario de alta lectura.",
            "Crear múltiples réplicas de lectura de la base de datos MySQL puede mejorar el rendimiento de lectura al distribuir la carga entre varias réplicas, pero no aborda la rentabilidad de manera tan efectiva como la caché. Cada réplica incurre en costos adicionales por almacenamiento y mantenimiento, y aunque puede ayudar con la escalabilidad de lectura, no proporciona las mismas ventajas de velocidad que una caché en memoria.",
            "Usar un sistema de procesamiento por lotes para precomputar consultas populares no es una solución de caché directa y puede no proporcionar acceso en tiempo real a contenido de acceso frecuente. Aunque puede reducir la carga en la base de datos al precomputar resultados, no ofrece los tiempos de respuesta inmediatos que proporcionaría una caché en memoria para solicitudes de contenido dinámico."
        ]
    },
    {
        "Question Number": "30",
        "Situation": "Una empresa está construyendo una plataforma de soporte al cliente y quiere utilizar servicios de AWS para analizar la retroalimentación de los clientes y generar respuestas de voz automatizadas. Quieren extraer información clave de los datos de texto y convertir respuestas de texto en voz.",
        "Question": "¿Qué servicios de AWS debería utilizar la empresa para lograr estos objetivos?",
        "Options": {
            "1": "Usar Amazon Polly para convertir texto en voz y Amazon Comprehend para analizar el sentimiento del cliente y extraer frases clave de la retroalimentación.",
            "2": "Usar Amazon Lex para construir un chatbot conversacional y Amazon Polly para la conversión de voz a texto.",
            "3": "Usar Amazon S3 para almacenar la retroalimentación y AWS Lambda para analizar texto y generar voz.",
            "4": "Usar Amazon Transcribe para convertir voz a texto y Amazon Rekognition para el análisis de sentimiento."
        },
        "Correct Answer": "Usar Amazon Polly para convertir texto en voz y Amazon Comprehend para analizar el sentimiento del cliente y extraer frases clave de la retroalimentación.",
        "Explanation": "Esta opción es correcta porque Amazon Polly está diseñado específicamente para convertir texto en voz realista, lo que se alinea con el objetivo de la empresa de generar respuestas de voz automatizadas. Además, Amazon Comprehend es un servicio de procesamiento de lenguaje natural (NLP) que puede analizar datos de texto para extraer información como el sentimiento y frases clave, lo que lo hace ideal para analizar la retroalimentación de los clientes.",
        "Other Options": [
            "Esta opción es incorrecta porque Amazon Lex se utiliza para construir interfaces conversacionales (chatbots) y no se centra principalmente en analizar datos de texto para el sentimiento o extraer frases clave. Aunque Amazon Polly está incluido para la conversión de voz, no aborda el análisis de la retroalimentación de los clientes.",
            "Esta opción es incorrecta porque Amazon S3 es un servicio de almacenamiento y no proporciona capacidades de análisis. AWS Lambda se puede utilizar para computación sin servidor, pero requeriría servicios adicionales para el análisis de texto y la generación de voz, lo que lo hace menos eficiente que la respuesta correcta.",
            "Esta opción es incorrecta porque Amazon Transcribe se utiliza para convertir voz a texto, lo que no es relevante para el objetivo de la empresa de analizar la retroalimentación textual. Además, Amazon Rekognition es un servicio de análisis de imágenes y videos, no adecuado para el análisis de sentimiento de datos textuales."
        ]
    },
    {
        "Question Number": "31",
        "Situation": "Una empresa quiere almacenar datos sensibles en Amazon S3 y necesita asegurarse de que AWS no tenga acceso a los datos en texto plano. También desean tener control total sobre la gestión de claves y el procesamiento de cifrado.",
        "Question": "¿Qué método de cifrado debería utilizar la empresa para cumplir con estos requisitos?",
        "Options": {
            "1": "Cifrado del lado del servidor con claves gestionadas por S3 (SSE-S3)",
            "2": "Cifrado del lado del servidor con claves gestionadas por AWS KMS (SSE-KMS)",
            "3": "Cifrado del lado del cliente",
            "4": "Cifrado del lado del servidor con claves proporcionadas por el cliente (SSE-C)"
        },
        "Correct Answer": "Cifrado del lado del cliente",
        "Explanation": "El cifrado del lado del cliente permite a la empresa cifrar los datos antes de enviarlos a Amazon S3, asegurando que AWS no tenga acceso a los datos en texto plano. Este método proporciona a la empresa control total sobre el proceso de cifrado y la gestión de claves, ya que pueden utilizar sus propias claves y algoritmos de cifrado para asegurar los datos antes de subirlos a S3. Esto cumple con el requisito de asegurar que AWS no tenga acceso a los datos en texto plano.",
        "Other Options": [
            "El cifrado del lado del servidor con claves gestionadas por S3 (SSE-S3) utiliza las propias claves de Amazon para gestionar el cifrado, lo que significa que AWS tiene acceso a los datos en texto plano, por lo tanto, no cumple con el requisito de la empresa.",
            "El cifrado del lado del servidor con claves gestionadas por AWS KMS (SSE-KMS) permite un mayor control sobre la gestión de claves en comparación con SSE-S3, pero AWS aún tiene acceso a los datos en texto plano porque los procesos de cifrado y descifrado ocurren en el lado del servidor.",
            "El cifrado del lado del servidor con claves proporcionadas por el cliente (SSE-C) permite a los clientes proporcionar sus propias claves para el cifrado, pero AWS aún maneja los procesos de cifrado y descifrado, lo que significa que AWS podría potencialmente acceder a los datos en texto plano, lo que no cumple con el requisito de la empresa."
        ]
    },
    {
        "Question Number": "32",
        "Situation": "Un sitio web de noticias global con millones de lectores en todo el mundo utiliza Amazon CloudFront para entregar contenido de manera eficiente con baja latencia. El equipo del sitio web quiere agregar funciones que personalicen el contenido según el país del espectador, como resúmenes de noticias locales, y también necesita implementar pruebas A/B para probar diferentes diseños de artículos. La solución debe operar en ubicaciones de borde para garantizar una experiencia fluida y de baja latencia para los espectadores de todo el mundo.",
        "Question": "¿Qué servicio y configuración de AWS debería recomendar el arquitecto de soluciones?",
        "Options": {
            "1": "Desplegar AWS Lambda en una VPC con reglas de enrutamiento basadas en el país para la personalización del contenido",
            "2": "Utilizar funciones de Lambda@Edge, activadas por eventos de solicitud de visualizador y solicitud de origen de CloudFront, para personalizar el contenido según el país y realizar pruebas A/B en ubicaciones de borde",
            "3": "Lanzar instancias de Amazon EC2 en múltiples regiones con contenido específico de cada país almacenado localmente en cada instancia",
            "4": "Configurar Amazon CloudFront con comportamientos de caché específicos para cada país para servir contenido personalizado por país"
        },
        "Correct Answer": "Utilizar funciones de Lambda@Edge, activadas por eventos de solicitud de visualizador y solicitud de origen de CloudFront, para personalizar el contenido según el país y realizar pruebas A/B en ubicaciones de borde",
        "Explanation": "Utilizar Lambda@Edge permite al sitio web ejecutar código más cerca de los usuarios en las ubicaciones de borde de CloudFront, lo que minimiza la latencia y mejora la experiencia del usuario. Al activar funciones en eventos de solicitud de visualizador y solicitud de origen, el sitio web puede personalizar dinámicamente el contenido según el país del usuario e implementar pruebas A/B para diferentes diseños. Esta solución es eficiente y aprovecha las capacidades de CloudFront para entregar contenido personalizado de manera rápida y efectiva.",
        "Other Options": [
            "Desplegar AWS Lambda en una VPC con reglas de enrutamiento basadas en el país no sería óptimo porque introduciría latencia al requerir que el tráfico se enrute a través de la VPC en lugar de directamente en las ubicaciones de borde. Esta configuración no utiliza de manera efectiva los beneficios de baja latencia de CloudFront.",
            "Si bien utilizar funciones de Lambda@Edge es el enfoque correcto, esta opción no especifica el uso de eventos de CloudFront, que son esenciales para activar las funciones en los momentos adecuados. Por lo tanto, carece del detalle necesario para una solución completa.",
            "Lanzar instancias de Amazon EC2 en múltiples regiones sería ineficiente y costoso. Requeriría gestionar múltiples instancias y la sincronización de contenido entre ellas, lo que complica la arquitectura y no aprovecha los beneficios de la computación en el borde para la entrega de contenido de baja latencia."
        ]
    },
    {
        "Question Number": "33",
        "Situation": "Una empresa de streaming de video necesita conectar sus servicios de entrega de contenido, alojados en AWS, con su red de oficinas centrales en otra ciudad. La empresa requiere una conexión de alto rendimiento para transferir grandes archivos de video y baja latencia para prevenir problemas de almacenamiento en búfer durante la reproducción de video. También quieren que la conexión sea privada para asegurar que el contenido de video sensible no esté expuesto a Internet público y buscan una solución rentable para lograr estos objetivos.",
        "Question": "¿Qué enfoque cumpliría mejor con sus necesidades?",
        "Options": {
            "1": "AWS PrivateLink para crear un enlace privado para el contenido de video directamente a sus oficinas centrales",
            "2": "AWS Direct Connect para establecer una conexión privada de alto ancho de banda entre AWS y su red local",
            "3": "Un circuito MPLS punto a punto de un proveedor de telecomunicaciones para crear una conexión privada a AWS",
            "4": "Utilizar un servicio de internet gestionado con VPN dedicadas para la transferencia segura de datos"
        },
        "Correct Answer": "AWS Direct Connect para establecer una conexión privada de alto ancho de banda entre AWS y su red local",
        "Explanation": "AWS Direct Connect proporciona una conexión de red dedicada desde las oficinas centrales de la empresa a AWS, que es ideal para requisitos de alto rendimiento y baja latencia. Este servicio permite una conexión privada que no atraviesa Internet público, asegurando que el contenido de video sensible permanezca seguro. Direct Connect puede manejar transferencias de datos grandes de manera eficiente, lo que lo convierte en una solución rentable para transferir grandes archivos de video sin el riesgo de almacenamiento en búfer durante la reproducción.",
        "Other Options": [
            "AWS PrivateLink está diseñado para conectar servicios de manera segura dentro de AWS y no proporciona una conexión directa a redes locales. Es más adecuado para acceder a servicios de AWS de forma privada en lugar de transferir archivos grandes entre AWS y una red externa.",
            "Un circuito MPLS punto a punto de un proveedor de telecomunicaciones puede proporcionar una conexión privada, pero puede no ser tan rentable o flexible como AWS Direct Connect. Además, la configuración y gestión de circuitos MPLS pueden ser más complejas y no garantizar el mismo nivel de rendimiento que Direct Connect.",
            "Utilizar un servicio de internet gestionado con VPN dedicadas puede proporcionar una conexión segura, pero típicamente no ofrece el mismo nivel de rendimiento y baja latencia que AWS Direct Connect. Las VPN sobre Internet también pueden introducir variabilidad en el rendimiento, lo que podría llevar a problemas de almacenamiento en búfer durante la reproducción de video."
        ]
    },
    {
        "Question Number": "34",
        "Situation": "Una empresa de fabricación recopila datos de sensores en sus instalaciones locales y necesita archivar los datos en AWS para almacenamiento y análisis a largo plazo. Quieren minimizar costos, pero requieren una forma fluida de transferir datos a la nube con un esfuerzo manual mínimo.",
        "Question": "¿Qué opción de almacenamiento híbrido satisfaría mejor estos requisitos?",
        "Options": {
            "1": "AWS Direct Connect",
            "2": "AWS Storage Gateway",
            "3": "Amazon S3 con Transfer Acceleration",
            "4": "AWS DataSync"
        },
        "Correct Answer": "AWS Storage Gateway",
        "Explanation": "AWS Storage Gateway está diseñado específicamente para soluciones de almacenamiento en la nube híbrida, permitiendo que las aplicaciones locales utilicen el almacenamiento en la nube de manera fluida. Proporciona una forma de transferir datos a AWS con un esfuerzo manual mínimo, lo que lo hace ideal para archivar datos de sensores. Soporta varias configuraciones, como gateways de archivos, volúmenes y cintas, que pueden ayudar a minimizar costos mientras aseguran que los datos estén fácilmente disponibles para análisis en la nube.",
        "Other Options": [
            "AWS Direct Connect proporciona una conexión de red dedicada desde las instalaciones locales a AWS, lo que puede mejorar el ancho de banda y reducir costos para la transferencia de datos. Sin embargo, no ofrece una forma fluida de gestionar y transferir datos automáticamente, ya que requiere configuración y gestión adicionales.",
            "Amazon S3 con Transfer Acceleration acelera la transferencia de archivos a S3 a largas distancias, pero no proporciona una solución de almacenamiento híbrido. Es más adecuado para transferir archivos que para integrar datos locales con almacenamiento en la nube de manera fluida.",
            "AWS DataSync es un servicio que automatiza el movimiento de datos entre el almacenamiento local y los servicios de almacenamiento de AWS. Aunque es efectivo para transferir grandes cantidades de datos, puede requerir más configuración y gestión manual en comparación con AWS Storage Gateway, que está más integrado en los flujos de trabajo existentes."
        ]
    },
    {
        "Question Number": "35",
        "Situation": "Una empresa de medios está almacenando grandes archivos de video en Amazon S3. Los videos se acceden frecuentemente poco después de la carga, pero rara vez se acceden después de un mes. La empresa quiere optimizar los costos de almacenamiento sin comprometer el rendimiento de acceso a los videos recién cargados.",
        "Question": "¿Qué clase de almacenamiento S3 debería recomendar el arquitecto de soluciones?",
        "Options": {
            "1": "S3 Standard",
            "2": "S3 Intelligent-Tiering",
            "3": "S3 Standard-Infrequent Access (S3 Standard-IA)",
            "4": "S3 One Zone-Infrequent Access (S3 One Zone-IA)"
        },
        "Correct Answer": "S3 Intelligent-Tiering",
        "Explanation": "S3 Intelligent-Tiering es la mejor opción para este escenario porque mueve automáticamente los datos entre dos niveles de acceso (frecuente e infrecuente) según los patrones de acceso cambiantes. Dado que los videos se acceden frecuentemente poco después de la carga, pero rara vez después de un mes, esta clase de almacenamiento optimizará los costos al mover los datos al nivel de acceso infrecuente después del período de acceso inicial, sin comprometer el rendimiento de acceso a los videos recién cargados.",
        "Other Options": [
            "S3 Standard no es la opción más rentable para este caso de uso porque está diseñado para datos de acceso frecuente y no proporciona ahorros de costos para datos que se vuelven de acceso infrecuente después de un corto período.",
            "S3 Standard-Infrequent Access (S3 Standard-IA) no es ideal porque, aunque es más barato para datos de acceso infrecuente, incurre en tarifas de recuperación y no está optimizado para datos que se acceden frecuentemente poco después de la carga.",
            "S3 One Zone-Infrequent Access (S3 One Zone-IA) tampoco es adecuado porque almacena datos en una única zona de disponibilidad, lo que plantea un riesgo de pérdida de datos en caso de una falla de la zona de disponibilidad. Además, está diseñado para datos de acceso infrecuente, lo que no se alinea con la necesidad de acceso rápido poco después de la carga."
        ]
    },
    {
        "Question Number": "36",
        "Situation": "Una empresa de desarrollo de software está implementando una aplicación basada en microservicios utilizando contenedores Docker. La aplicación requiere implementación automatizada, escalado y gestión de contenedores a través de un clúster de instancias EC2.",
        "Question": "¿Qué servicios de AWS debería recomendar el arquitecto de soluciones para orquestar la aplicación en contenedores? (Elija dos.)",
        "Options": {
            "1": "Amazon Elastic Container Service (ECS)",
            "2": "AWS Lambda",
            "3": "Amazon EC2 Auto Scaling",
            "4": "AWS Batch",
            "5": "Amazon Elastic Kubernetes Service (EKS)"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon Elastic Container Service (ECS)",
            "Amazon Elastic Kubernetes Service (EKS)"
        ],
        "Explanation": "Amazon Elastic Container Service (ECS) y Amazon Elastic Kubernetes Service (EKS) son ambos servicios de AWS diseñados específicamente para orquestar aplicaciones en contenedores. ECS es un servicio de alto rendimiento y altamente escalable que permite ejecutar y gestionar aplicaciones habilitadas para Docker a través de un clúster de instancias Amazon EC2. EKS, por otro lado, es un servicio gestionado que facilita la ejecución de Kubernetes en AWS sin necesidad de instalar, operar y mantener su propio plano de control o nodos de Kubernetes. Ambos servicios proporcionan implementación automatizada, escalado y gestión de contenedores, que es exactamente lo que requiere el escenario de la pregunta.",
        "Other Options": [
            "AWS Lambda es un servicio de computación sin servidor que permite ejecutar su código sin aprovisionar o gestionar servidores. Aunque se puede utilizar junto con aplicaciones en contenedores, no es un servicio diseñado específicamente para orquestar contenedores.",
            "Amazon EC2 Auto Scaling es un servicio que ayuda a mantener la disponibilidad de la aplicación y permite agregar o eliminar automáticamente instancias EC2 según las condiciones que defina. Aunque se puede utilizar para escalar las instancias EC2 subyacentes, no proporciona capacidades de orquestación de contenedores.",
            "AWS Batch es un servicio que permite a los profesionales de TI programar y ejecutar trabajos de procesamiento por lotes. Aunque puede ejecutar trabajos que están en contenedores, no está diseñado específicamente para orquestar aplicaciones en contenedores."
        ]
    },
    {
        "Question Number": "37",
        "Situation": "Un sitio web de comercio electrónico necesita una forma rentable de dirigir el tráfico a diferentes aplicaciones en función de los nombres de dominio, y quieren evitar cargos adicionales por enrutamiento complejo.",
        "Question": "¿Qué servicio de red de AWS satisfaría mejor este requisito?",
        "Options": {
            "1": "Usar AWS Global Accelerator para enrutamiento global",
            "2": "Implementar Amazon Route 53 para enrutamiento basado en DNS",
            "3": "Usar un Application Load Balancer con enrutamiento basado en rutas",
            "4": "Configurar VPC Peering para enrutamiento de tráfico directo"
        },
        "Correct Answer": "Implementar Amazon Route 53 para enrutamiento basado en DNS",
        "Explanation": "Amazon Route 53 es un servicio web de Sistema de Nombres de Dominio (DNS) escalable y altamente disponible que puede dirigir el tráfico en función de los nombres de dominio. Permite un enrutamiento basado en DNS rentable, lo que es ideal para dirigir a los usuarios a diferentes aplicaciones según el dominio que acceden. Este servicio puede manejar políticas de enrutamiento como enrutamiento simple, enrutamiento ponderado, enrutamiento basado en latencia y más, sin incurrir en cargos adicionales por configuraciones de enrutamiento complejas. Está diseñado específicamente para este propósito, lo que lo convierte en la mejor opción para las necesidades del sitio web de comercio electrónico.",
        "Other Options": [
            "AWS Global Accelerator está diseñado para mejorar la disponibilidad y el rendimiento de las aplicaciones dirigiendo el tráfico a puntos finales óptimos en función de la salud, la geografía y las políticas de enrutamiento. Sin embargo, incurre en costos adicionales y es más adecuado para aplicaciones globales que para un enrutamiento simple basado en dominios.",
            "Un Application Load Balancer con enrutamiento basado en rutas se utiliza principalmente para distribuir el tráfico de aplicación entrante entre múltiples objetivos, como instancias de EC2, en función de la ruta de la solicitud. Aunque puede dirigir el tráfico de manera efectiva, no es la solución más rentable para el enrutamiento basado en nombres de dominio, ya que implica una configuración adicional y costos potenciales.",
            "VPC Peering permite el enrutamiento directo del tráfico de red entre dos VPCs (Nubes Privadas Virtuales) pero no maneja el enrutamiento basado en nombres de dominio. Es más adecuado para la comunicación de red interna que para dirigir el tráfico externo en función de los nombres de dominio, lo que lo convierte en una opción inapropiada para los requisitos del sitio web de comercio electrónico."
        ]
    },
    {
        "Question Number": "38",
        "Situation": "Una startup está preocupada por sus gastos en bases de datos y quiere monitorear los costos a lo largo del tiempo. Quieren configurar alertas de costos para mantenerse dentro del presupuesto y analizar las tendencias de gasto para identificar posibles ahorros.",
        "Question": "¿Qué combinación de herramientas de gestión de costos de AWS deberían usar? (Elige dos.)",
        "Options": {
            "1": "AWS Trusted Advisor y AWS Cost Explorer",
            "2": "AWS Budgets y AWS Cost Explorer",
            "3": "AWS Cost and Usage Report y AWS Support",
            "4": "AWS Trusted Advisor y AWS Budgets",
            "5": "AWS Cost Anomaly Detection y AWS Budgets"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "AWS Budgets y AWS Cost Explorer",
            "AWS Cost Anomaly Detection y AWS Budgets"
        ],
        "Explanation": "AWS Budgets permite a los usuarios establecer presupuestos de costos y uso personalizados que les alertan cuando sus costos o uso superan (o se prevé que superen) la cantidad presupuestada. Esto ayudaría a la startup a monitorear los costos y mantenerse dentro del presupuesto. AWS Cost Explorer permite a los usuarios visualizar, comprender y gestionar sus costos y uso de AWS a lo largo del tiempo. Esto ayudaría a la startup a analizar las tendencias de gasto e identificar posibles ahorros. AWS Cost Anomaly Detection analiza automáticamente los datos de costos y uso para detectar patrones de gasto inusuales, proporcionando otra capa de gestión de costos.",
        "Other Options": [
            "AWS Trusted Advisor y AWS Cost Explorer: Aunque AWS Cost Explorer es una herramienta correcta, AWS Trusted Advisor proporciona principalmente orientación en tiempo real para ayudar a aprovisionar recursos siguiendo las mejores prácticas de AWS, no específicamente gestión de costos.",
            "AWS Cost and Usage Report y AWS Support: AWS Cost and Usage Report proporciona datos completos sobre costos, pero no ofrece la función de alerta que la startup necesita. AWS Support es un servicio de soporte técnico y no ayuda directamente con la gestión de costos.",
            "AWS Trusted Advisor y AWS Budgets: Aunque AWS Budgets es una herramienta correcta, AWS Trusted Advisor proporciona principalmente orientación en tiempo real para ayudar a aprovisionar recursos siguiendo las mejores prácticas de AWS, no específicamente gestión de costos."
        ]
    },
    {
        "Question Number": "39",
        "Situation": "Una aplicación empresarial requiere acceso de baja latencia a los datos almacenados en Amazon S3. Los datos son accedidos por usuarios de diversas ubicaciones geográficas alrededor del mundo. La empresa quiere mejorar la velocidad de acceso a los datos para los usuarios almacenando en caché los datos de acceso frecuente más cerca de ellos.",
        "Question": "¿Qué servicio de AWS debería usar el arquitecto de soluciones para lograr este requisito?",
        "Options": {
            "1": "Amazon CloudFront",
            "2": "AWS Global Accelerator",
            "3": "Amazon Route 53",
            "4": "AWS Direct Connect"
        },
        "Correct Answer": "Amazon CloudFront",
        "Explanation": "Amazon CloudFront es un servicio de red de entrega de contenido (CDN) que almacena en caché contenido en ubicaciones de borde alrededor del mundo. Al usar CloudFront, los datos de acceso frecuente almacenados en Amazon S3 pueden ser almacenados en caché más cerca de los usuarios, reduciendo significativamente la latencia y mejorando la velocidad de acceso. Cuando un usuario solicita datos, CloudFront los sirve desde la ubicación de borde más cercana, lo que mejora el rendimiento para los usuarios ubicados en diversas regiones geográficas.",
        "Other Options": [
            "AWS Global Accelerator mejora la disponibilidad y el rendimiento de las aplicaciones dirigiendo el tráfico a puntos finales óptimos, pero no almacena contenido en caché. Es más adecuado para mejorar el rendimiento de aplicaciones TCP y UDP que para almacenar en caché contenido estático de S3.",
            "Amazon Route 53 es un servicio web de Sistema de Nombres de Dominio (DNS) escalable que proporciona registro de dominios, enrutamiento DNS y verificación de salud. Aunque ayuda a dirigir a los usuarios a los recursos más cercanos, no almacena datos en caché ni mejora directamente la velocidad de acceso a los datos.",
            "AWS Direct Connect proporciona una conexión de red dedicada desde sus instalaciones a AWS, lo que puede mejorar el ancho de banda y reducir la latencia para la transferencia de datos. Sin embargo, no almacena datos en caché ni proporciona un mecanismo de entrega de contenido, lo que lo hace inadecuado para el requisito de almacenar en caché datos de acceso frecuente."
        ]
    },
    {
        "Question Number": "40",
        "Situation": "Una empresa está diseñando una aplicación web de múltiples capas que se ejecutará en AWS. La aplicación consta de una capa web en el front-end, una capa de lógica de negocio y una capa de base de datos. La empresa requiere alta disponibilidad y tolerancia a fallos para la aplicación.",
        "Question": "¿Qué arquitectura debería recomendar el arquitecto de soluciones?",
        "Options": {
            "1": "Desplegar todas las capas en una única Zona de Disponibilidad con Auto Scaling y balanceo de carga.",
            "2": "Desplegar las capas web y de lógica de negocio en múltiples Zonas de Disponibilidad y la capa de base de datos en una única Zona de Disponibilidad con Multi-AZ RDS.",
            "3": "Desplegar la capa web en múltiples Zonas de Disponibilidad, la capa de lógica de negocio en una única Zona de Disponibilidad y la capa de base de datos utilizando Amazon DynamoDB.",
            "4": "Desplegar todas las capas en múltiples Regiones de AWS para asegurar disponibilidad global."
        },
        "Correct Answer": "Desplegar las capas web y de lógica de negocio en múltiples Zonas de Disponibilidad y la capa de base de datos en una única Zona de Disponibilidad con Multi-AZ RDS.",
        "Explanation": "Esta opción proporciona alta disponibilidad y tolerancia a fallos al desplegar las capas web y de lógica de negocio en múltiples Zonas de Disponibilidad (AZs). Esto asegura que si una AZ falla, la aplicación aún puede funcionar utilizando los recursos de las otras AZs. Además, utilizar Multi-AZ para la capa de base de datos con Amazon RDS mejora la disponibilidad y durabilidad al replicar automáticamente la base de datos en una instancia de espera en otra AZ, permitiendo la conmutación por error en caso de una interrupción. Esta arquitectura equilibra efectivamente la necesidad de alta disponibilidad mientras gestiona costos y complejidad.",
        "Other Options": [
            "Desplegar todas las capas en una única Zona de Disponibilidad con Auto Scaling y balanceo de carga no proporciona alta disponibilidad ni tolerancia a fallos, ya que una falla en esa AZ derribaría toda la aplicación.",
            "Desplegar las capas web y de lógica de negocio en múltiples Zonas de Disponibilidad y la capa de base de datos en una única Zona de Disponibilidad con Multi-AZ RDS es parcialmente correcto, pero no utiliza completamente los beneficios de alta disponibilidad para la capa de base de datos ya que solo está en una AZ. La base de datos también debería estar en múltiples AZs para una tolerancia a fallos completa.",
            "Desplegar la capa web en múltiples Zonas de Disponibilidad, la capa de lógica de negocio en una única Zona de Disponibilidad y la capa de base de datos utilizando Amazon DynamoDB no proporciona tolerancia a fallos para la capa de lógica de negocio, que es crítica para la aplicación. Aunque DynamoDB es altamente disponible, la arquitectura en su conjunto carece de redundancia en la capa de lógica de negocio."
        ]
    },
    {
        "Question Number": "41",
        "Situation": "Un equipo de desarrollo está desplegando nuevas versiones de su API y quiere probarlas en producción con un impacto mínimo en los usuarios finales. Deciden utilizar despliegues canarios para dirigir un pequeño porcentaje del tráfico de producción a la nueva versión antes de un lanzamiento completo.",
        "Question": "¿Qué estrategia de despliegue apoyaría mejor este enfoque de prueba y cómo?",
        "Options": {
            "1": "Endpoint Optimizado para Edge, porque dirige el tráfico a través de CloudFront y proporciona menor latencia para una audiencia global.",
            "2": "Endpoint Regional, ya que permite que el tráfico permanezca dentro de la misma región de AWS para aplicaciones específicas de la región.",
            "3": "Endpoint Privado, asegurando que la API sea accesible solo dentro de una VPC para pruebas internas.",
            "4": "Despliegue por Etapas con Lanzamiento Canario, permitiendo un lanzamiento controlado de la nueva versión de la API mientras se aumenta gradualmente el tráfico hacia ella."
        },
        "Correct Answer": "Despliegue por Etapas con Lanzamiento Canario, permitiendo un lanzamiento controlado de la nueva versión de la API mientras se aumenta gradualmente el tráfico hacia ella.",
        "Explanation": "Un Despliegue por Etapas con Lanzamiento Canario está diseñado específicamente para escenarios donde se necesitan probar nuevas versiones de una aplicación o API en producción con un riesgo mínimo. Esta estrategia permite al equipo de desarrollo dirigir un pequeño porcentaje de tráfico a la nueva versión, monitorear su rendimiento y aumentar gradualmente el tráfico si la nueva versión funciona bien. Este lanzamiento controlado minimiza el impacto en los usuarios finales y permite una rápida reversión si surgen problemas.",
        "Other Options": [
            "El Endpoint Optimizado para Edge se centra principalmente en reducir la latencia para usuarios globales al dirigir el tráfico a través de CloudFront. Aunque mejora el rendimiento, no apoya inherentemente la estrategia de despliegue canario, que requiere un mecanismo para controlar la distribución del tráfico entre versiones.",
            "El Endpoint Regional es adecuado para aplicaciones que necesitan mantener el tráfico dentro de una región específica de AWS. Sin embargo, no proporciona la funcionalidad necesaria para despliegues canarios, que requieren la capacidad de cambiar gradualmente el tráfico entre diferentes versiones de una API.",
            "El Endpoint Privado restringe el acceso a la API dentro de una Nube Privada Virtual (VPC), lo que lo hace adecuado para pruebas internas. Sin embargo, no facilita la estrategia de despliegue canario, que implica exponer la nueva versión a un subconjunto de usuarios externos para recopilar comentarios y monitorear el rendimiento."
        ]
    },
    {
        "Question Number": "42",
        "Situation": "Una organización de investigación en genómica está realizando análisis de secuencias de ADN a gran escala en AWS. Las cargas de trabajo requieren alta potencia computacional y necesitan escalar rápidamente para manejar demandas de procesamiento intensas. El equipo necesita asegurarse de que la aplicación pueda escalar dinámicamente para satisfacer las necesidades de rendimiento máximo mientras mantiene los costos operativos optimizados durante períodos de baja demanda.",
        "Question": "¿Qué enfoque cumpliría mejor con estos requisitos de alto rendimiento y eficiencia de costos?",
        "Options": {
            "1": "Provisionar instancias EC2 con el máximo vCPU y memoria para cargas de trabajo máximas y escalar hacia abajo manualmente",
            "2": "Utilizar un grupo de Auto Scaling con instancias EC2 optimizadas para computación y configurar una política de escalado basada en la utilización de CPU",
            "3": "Configurar funciones de Amazon Lambda para manejar todas las tareas computacionales de manera serverless",
            "4": "Ejecutar una única instancia EC2 con una gran cantidad de almacenamiento y asignar recursos manualmente según sea necesario"
        },
        "Correct Answer": "Utilizar un grupo de Auto Scaling con instancias EC2 optimizadas para computación y configurar una política de escalado basada en la utilización de CPU",
        "Explanation": "Utilizar un grupo de Auto Scaling con instancias EC2 optimizadas para computación permite a la organización ajustar automáticamente el número de instancias según la carga de trabajo. Este enfoque asegura que durante las necesidades de rendimiento máximo, se puedan aprovisionar instancias adicionales para manejar las demandas computacionales incrementadas, mientras que durante períodos de baja demanda, se pueden terminar instancias para optimizar costos. La política de escalado basada en la utilización de CPU es efectiva porque correlaciona directamente las acciones de escalado con el uso real de recursos, asegurando que la aplicación pueda responder dinámicamente a los cambios en la carga de trabajo de manera eficiente.",
        "Other Options": [
            "Provisionar instancias EC2 con el máximo vCPU y memoria para cargas de trabajo máximas y escalar hacia abajo manualmente no es eficiente. Este enfoque conduce a una sobreaprovisionamiento durante períodos de baja demanda, resultando en costos innecesarios. El escalado manual también es propenso a errores humanos y puede no responder lo suficientemente rápido a los cambios en la carga de trabajo.",
            "Configurar funciones de Amazon Lambda para manejar todas las tareas computacionales de manera serverless puede no ser adecuado para análisis de secuencias de ADN de alto rendimiento que requieren una potencia computacional y memoria significativas. Lambda tiene limitaciones en el tiempo de ejecución y la asignación de recursos, lo que puede no satisfacer las necesidades de cargas de trabajo genómicas intensivas.",
            "Ejecutar una única instancia EC2 con una gran cantidad de almacenamiento y asignar recursos manualmente según sea necesario no es una solución escalable. Este enfoque no permite un escalado dinámico, que es crucial para manejar cargas de trabajo variables de manera eficiente. Además, depender de una única instancia crea un único punto de fallo y puede llevar a cuellos de botella en el rendimiento."
        ]
    },
    {
        "Question Number": "43",
        "Situation": "Una empresa de servicios financieros genera y almacena grandes volúmenes de datos de clientes en sus instalaciones todos los días. Debido a estrictos requisitos regulatorios y de cumplimiento, deben retener estos datos localmente, pero quieren trasladar datos más antiguos y de acceso poco frecuente a AWS para ahorrar en costos de almacenamiento. Necesitan una solución que pueda extender sin problemas su infraestructura de almacenamiento actual a AWS, permitiendo el acceso a datos archivados sin interrumpir sus aplicaciones o flujos de trabajo existentes.",
        "Question": "¿Qué servicio de AWS satisfaría mejor los requisitos de la empresa?",
        "Options": {
            "1": "Amazon S3 con políticas de ciclo de vida",
            "2": "AWS Direct Connect",
            "3": "AWS Storage Gateway",
            "4": "Amazon EBS Snapshot Export"
        },
        "Correct Answer": "AWS Storage Gateway",
        "Explanation": "AWS Storage Gateway está diseñado para integrar sin problemas los entornos locales con el almacenamiento en la nube. Proporciona una solución de almacenamiento en la nube híbrida que permite a las empresas retener sus datos localmente mientras extienden sus capacidades de almacenamiento a AWS. En este escenario, la empresa de servicios financieros puede utilizar el Storage Gateway para trasladar datos más antiguos y de acceso poco frecuente a AWS, asegurando el cumplimiento de los requisitos regulatorios mientras ahorra en costos de almacenamiento. El servicio permite un acceso fácil a los datos archivados sin interrumpir las aplicaciones o flujos de trabajo existentes, lo que lo convierte en la mejor opción para las necesidades de la empresa.",
        "Other Options": [
            "Amazon S3 con políticas de ciclo de vida es un servicio de almacenamiento que permite a los usuarios gestionar el ciclo de vida de sus datos, pero no proporciona la integración sin problemas con la infraestructura local que la empresa requiere. Requeriría pasos adicionales para mover datos de las instalaciones a S3, lo que podría interrumpir los flujos de trabajo existentes.",
            "AWS Direct Connect es un servicio que proporciona una conexión de red dedicada desde las instalaciones a AWS. Aunque puede mejorar el ancho de banda y reducir la latencia para la transferencia de datos, no aborda directamente la necesidad de una solución de almacenamiento híbrido que permita el acceso sin problemas a los datos archivados.",
            "Amazon EBS Snapshot Export permite a los usuarios exportar instantáneas de EBS a S3, pero se centra principalmente en la copia de seguridad y recuperación de volúmenes de EBS en lugar de proporcionar una solución de almacenamiento híbrido. No facilita el acceso continuo a los datos archivados de la manera en que lo hace AWS Storage Gateway."
        ]
    },
    {
        "Question Number": "44",
        "Situation": "Una empresa tiene tanto una conexión VPN como un enlace de AWS Direct Connect establecidos entre su entorno local y su VPC de AWS. Para la transmisión de datos altamente segura, quieren asegurarse de que todo el tráfico permanezca cifrado mientras atraviesa la red.",
        "Question": "¿Qué enfoque garantizaría mejor la comunicación cifrada para todos los datos intercambiados entre su centro de datos y AWS?",
        "Options": {
            "1": "Confiar únicamente en AWS Direct Connect, ya que proporciona un enlace privado y dedicado, eliminando la necesidad de cifrado adicional.",
            "2": "Configurar una VPN sobre AWS Direct Connect para cifrar datos en una conexión privada, asegurando el cifrado de extremo a extremo.",
            "3": "Usar un Internet Gateway (IGW) con HTTPS para asegurar los datos mientras viajan por Internet.",
            "4": "Habilitar AWS Shield en Direct Connect para cifrar el tráfico y prevenir accesos no autorizados."
        },
        "Correct Answer": "Configurar una VPN sobre AWS Direct Connect para cifrar datos en una conexión privada, asegurando el cifrado de extremo a extremo.",
        "Explanation": "Aunque AWS Direct Connect proporciona un enlace privado y dedicado entre el entorno local y AWS, no cifra inherentemente los datos que se transmiten. Para asegurarse de que todos los datos intercambiados permanezcan cifrados, configurar una VPN sobre el enlace de Direct Connect es el mejor enfoque. Esta configuración permite una comunicación segura y cifrada mientras se aprovecha el ancho de banda dedicado y la menor latencia de Direct Connect. La VPN añade una capa adicional de seguridad al cifrar los paquetes de datos, asegurando que incluso si el enlace privado se viera comprometido, los datos seguirían siendo seguros.",
        "Other Options": [
            "Confiar únicamente en AWS Direct Connect no es suficiente para garantizar el cifrado. Aunque proporciona una conexión privada, no cifra los datos en tránsito, dejándolos vulnerables a la interceptación.",
            "Esta opción es en realidad la respuesta correcta. Configurar una VPN sobre AWS Direct Connect es el mejor enfoque para garantizar una comunicación cifrada.",
            "Usar un Internet Gateway (IGW) con HTTPS no es aplicable en este escenario, ya que la pregunta especifica un deseo de una conexión privada entre el centro de datos y AWS. Un IGW se utiliza para el acceso a Internet público, y aunque HTTPS proporciona cifrado, no cumple con el requisito de una conexión privada y segura."
        ]
    },
    {
        "Question Number": "45",
        "Situation": "Una empresa quiere mejorar la seguridad de su entorno de AWS detectando actividades inusuales y no autorizadas en múltiples cuentas. Están considerando Amazon GuardDuty para monitorear e identificar amenazas potenciales utilizando IA/ML e inteligencia de amenazas.",
        "Question": "¿Cómo ayuda Amazon GuardDuty a detectar amenazas de seguridad y cómo se manejan los hallazgos?",
        "Options": {
            "1": "GuardDuty analiza registros de DNS, flujo de VPC y CloudTrail, enviando hallazgos directamente al usuario raíz para revisión manual.",
            "2": "GuardDuty utiliza IA/ML en registros de DNS, flujo de VPC y CloudTrail, creando hallazgos que pueden activar respuestas automatizadas a través de CloudWatch Events, como notificaciones de SNS o invocaciones de Lambda para acciones de remediación.",
            "3": "GuardDuty monitorea solo el tráfico de una cuenta, requiriendo que los usuarios revisen los registros manualmente para detectar amenazas entre cuentas.",
            "4": "GuardDuty utiliza reglas estáticas para detectar actividad y notifica solo por anomalías en la red en los registros de flujo de VPC."
        },
        "Correct Answer": "GuardDuty utiliza IA/ML en registros de DNS, flujo de VPC y CloudTrail, creando hallazgos que pueden activar respuestas automatizadas a través de CloudWatch Events, como notificaciones de SNS o invocaciones de Lambda para acciones de remediación.",
        "Explanation": "Amazon GuardDuty aprovecha la inteligencia artificial (IA) y el aprendizaje automático (ML) para analizar diversas fuentes de datos, incluidos los registros de DNS, los registros de flujo de VPC y los registros de CloudTrail. Este análisis ayuda a identificar patrones inusuales y amenazas de seguridad potenciales. Cuando GuardDuty detecta una amenaza, genera hallazgos que pueden integrarse con servicios de AWS como CloudWatch Events. Esta integración permite respuestas automatizadas, como el envío de notificaciones a través de Amazon SNS o la invocación de funciones de AWS Lambda para acciones de remediación, mejorando así la postura de seguridad del entorno de AWS.",
        "Other Options": [
            "Si bien GuardDuty analiza registros de DNS, flujo de VPC y CloudTrail, no envía hallazgos directamente al usuario raíz para revisión manual. En cambio, los hallazgos se generan automáticamente y pueden integrarse con otros servicios de AWS para respuestas automatizadas.",
            "GuardDuty puede monitorear múltiples cuentas a través de AWS Organizations, permitiendo la detección centralizada de amenazas en toda una organización en lugar de solo en una cuenta. No requiere que los usuarios revisen manualmente los registros para detectar amenazas entre cuentas.",
            "GuardDuty no se basa únicamente en reglas estáticas; utiliza IA y ML para detectar una amplia gama de actividades, no solo anomalías en la red en los registros de flujo de VPC. Analiza varios tipos de registros para identificar amenazas potenciales de manera integral."
        ]
    },
    {
        "Question Number": "46",
        "Situation": "Una empresa de servicios financieros está haciendo la transición de una arquitectura monolítica a microservicios para manejar mejor las transacciones de los clientes. La empresa quiere implementar microservicios sin estado para garantizar alta disponibilidad, escalabilidad y tolerancia a fallos.",
        "Question": "¿Qué enfoque de diseño debería adoptar la empresa para asegurar microservicios resilientes y desacoplados?",
        "Options": {
            "1": "Diseñar cada microservicio para que sea sin estado, lo que significa que no retiene ninguna información de sesión entre solicitudes, y almacenar el estado en una caché distribuida como Amazon ElastiCache para rendimiento y durabilidad.",
            "2": "Diseñar cada microservicio para mantener el estado de sesión dentro del propio servicio, de modo que el estado pueda ser fácilmente accesible por otros servicios sin sistemas externos.",
            "3": "Implementar una base de datos monolítica que almacene todos los datos de sesión para los microservicios, de modo que el sistema pueda acceder a ella de forma centralizada para mantener el estado entre servicios.",
            "4": "Usar Amazon RDS con despliegue multi-AZ para manejar el estado de sesión de cada microservicio, asegurando la consistencia y disponibilidad de los datos."
        },
        "Correct Answer": "Diseñar cada microservicio para que sea sin estado, lo que significa que no retiene ninguna información de sesión entre solicitudes, y almacenar el estado en una caché distribuida como Amazon ElastiCache para rendimiento y durabilidad.",
        "Explanation": "Diseñar cada microservicio para que sea sin estado es crucial para lograr alta disponibilidad, escalabilidad y tolerancia a fallos. Los microservicios sin estado no retienen información de sesión, lo que les permite ser fácilmente replicados y escalados horizontalmente. Al almacenar el estado en una caché distribuida como Amazon ElastiCache, la empresa puede asegurarse de que los datos sean accesibles y duraderos sin acoplar los servicios a un sistema específico de gestión de estado. Este enfoque promueve un desacoplamiento entre servicios, ya que pueden operar de manera independiente sin depender de un estado compartido.",
        "Other Options": [
            "Diseñar cada microservicio para mantener el estado de sesión dentro del propio servicio contradice el principio de ausencia de estado. Este enfoque puede llevar a un acoplamiento estrecho entre servicios, dificultando su escalado y gestión de manera independiente, y también puede crear desafíos en la tolerancia a fallos y recuperación.",
            "Implementar una base de datos monolítica para almacenar todos los datos de sesión centraliza la gestión del estado, lo que va en contra del objetivo de descentralización de la arquitectura de microservicios. Esto puede crear un único punto de fallo y limitar la escalabilidad y resiliencia del sistema, ya que todos los servicios dependerían de la disponibilidad de la base de datos monolítica.",
            "Usar Amazon RDS con despliegue multi-AZ para la gestión del estado de sesión introduce una dependencia en una base de datos relacional, lo que puede llevar a cuellos de botella y reducción del rendimiento. Aunque proporciona consistencia y disponibilidad de datos, no se alinea con el principio de diseño sin estado que deben seguir los microservicios, aumentando así el acoplamiento entre servicios."
        ]
    },
    {
        "Question Number": "47",
        "Situation": "Una organización requiere que las claves de cifrado utilizadas para proteger datos sensibles se roten automáticamente cada año.",
        "Question": "¿Qué característica de AWS puede usar la organización para cumplir con este requisito?",
        "Options": {
            "1": "Configurar una política de ciclo de vida en Amazon S3",
            "2": "Habilitar la rotación automática de claves en AWS KMS",
            "3": "Usar Amazon GuardDuty para monitorear el uso de claves",
            "4": "Habilitar el cifrado en tránsito utilizando AWS Certificate Manager (ACM)"
        },
        "Correct Answer": "Habilitar la rotación automática de claves en AWS KMS",
        "Explanation": "AWS Key Management Service (KMS) proporciona la capacidad de rotar automáticamente las claves de cifrado. Al habilitar la rotación automática de claves, la organización puede asegurarse de que las claves utilizadas para cifrar datos sensibles se roten cada año sin intervención manual. Esta característica ayuda a mantener las mejores prácticas de seguridad al cambiar regularmente las claves de cifrado, reduciendo así el riesgo de compromiso de claves.",
        "Other Options": [
            "Configurar una política de ciclo de vida en Amazon S3 está relacionado con la gestión del ciclo de vida del almacenamiento de objetos en S3, como la transición de objetos a diferentes clases de almacenamiento o su eliminación después de un cierto período. No se refiere a la rotación automática de claves de cifrado.",
            "Usar Amazon GuardDuty para monitorear el uso de claves se centra en la detección de amenazas y el monitoreo de actividades maliciosas en cuentas de AWS. Aunque puede ayudar a identificar accesos no autorizados o anomalías en el uso de claves, no proporciona un mecanismo para la rotación de claves.",
            "Habilitar el cifrado en tránsito utilizando AWS Certificate Manager (ACM) se refiere a asegurar datos mientras viajan por la red. Esto es importante para proteger datos en tránsito, pero no aborda el requisito de rotación automática de claves de cifrado."
        ]
    },
    {
        "Question Number": "48",
        "Situation": "Una empresa está diseñando una VPC personalizada en la región us-east-1 con una arquitectura de tres niveles, que incluye un nivel web, un nivel de aplicación y un nivel de base de datos. Requieren que cada nivel esté aislado en tres zonas de disponibilidad (AZs) y necesitan acceso controlado tanto para recursos públicos como privados. La empresa también quiere habilitar soporte DNS para la resolución de nombres de host internos dentro de la VPC.",
        "Question": "¿Qué configuración debería implementar la empresa para cumplir con estos requisitos mientras asegura acceso público controlado y funcionalidad DNS interna?",
        "Options": {
            "1": "Asignar un bloque CIDR /16 a la VPC, usar subredes privadas para cada nivel en cada AZ, configurar una NAT Gateway en cada AZ para acceso a Internet saliente desde subredes privadas, y habilitar enableDnsHostnames y enableDnsSupport para funcionalidad DNS.",
            "2": "Usar un bloque CIDR /24 para la VPC, crear una subred pública en cada AZ para el nivel web, desplegar un Internet Gateway para acceso público directo, y deshabilitar enableDnsSupport para prevenir la resolución de nombres de host internos.",
            "3": "Asignar un bloque CIDR /28 a la VPC, configurar subredes públicas solo para todos los niveles, usar un Bastion Host para acceso a Internet, y deshabilitar enableDnsHostnames para restringir la funcionalidad DNS solo a IPs privadas.",
            "4": "Configurar la VPC con un bloque CIDR /20, establecer subredes privadas en cada AZ para el nivel web, usar instancias NAT para tráfico saliente, y deshabilitar enableDnsHostnames para mayor seguridad."
        },
        "Correct Answer": "Asignar un bloque CIDR /16 a la VPC, usar subredes privadas para cada nivel en cada AZ, configurar una NAT Gateway en cada AZ para acceso a Internet saliente desde subredes privadas, y habilitar enableDnsHostnames y enableDnsSupport para funcionalidad DNS.",
        "Explanation": "Esta opción cumple con todos los requisitos descritos en el escenario. Al asignar un bloque CIDR /16, la empresa asegura un amplio espacio de direcciones IP para su arquitectura de tres niveles. Usar subredes privadas para cada nivel en cada AZ proporciona el aislamiento y la seguridad necesarios. La NAT Gateway permite que las instancias en las subredes privadas accedan a Internet para actualizaciones o servicios externos, manteniéndolas inaccesibles desde Internet público. Habilitar tanto enableDnsHostnames como enableDnsSupport asegura que los recursos internos puedan resolver nombres de host, facilitando la comunicación dentro de la VPC.",
        "Other Options": [
            "Usar un bloque CIDR /24 para la VPC es insuficiente para una arquitectura de tres niveles que abarca múltiples AZs, ya que limita el número de direcciones IP disponibles. Crear subredes públicas para el nivel web expondría directamente a Internet, lo que no se alinea con el requisito de acceso controlado. Deshabilitar enableDnsSupport impediría la resolución de nombres de host internos, que es un requisito crítico.",
            "Asignar un bloque CIDR /28 es demasiado pequeño para una VPC que necesita soportar múltiples niveles en tres AZs, lo que llevaría al agotamiento de IPs. Configurar subredes públicas para todos los niveles contradice el requisito de aislamiento y acceso controlado. Además, deshabilitar enableDnsHostnames restringiría la funcionalidad DNS, impidiendo la resolución de nombres de host internos.",
            "Configurar la VPC con un bloque CIDR /20 proporciona más direcciones IP que un /28, pero aún no es óptimo para una arquitectura de tres niveles. Configurar subredes privadas solo para el nivel web no proporciona el aislamiento necesario para los niveles de aplicación y base de datos. Usar instancias NAT en lugar de NAT Gateways puede llevar a problemas de rendimiento y sobrecarga de gestión. Deshabilitar enableDnsHostnames nuevamente restringiría la funcionalidad DNS, lo cual no es aceptable dado los requisitos."
        ]
    },
    {
        "Question Number": "49",
        "Situation": "Una startup está monitoreando de cerca sus gastos mensuales en AWS para evitar sobrepasar el presupuesto y configurar alertas si el gasto supera sus límites previstos. Además, la startup quiere analizar las tendencias en los patrones de gasto a lo largo del tiempo para identificar oportunidades de ahorro y optimizar su uso de AWS.",
        "Question": "¿Qué combinación de herramientas de gestión de costos de AWS satisfaría mejor estos requisitos?",
        "Options": {
            "1": "Usar AWS Budgets para configurar alertas de gasto y AWS Cost Explorer para analizar patrones y tendencias de gasto a lo largo del tiempo.",
            "2": "Implementar AWS Trusted Advisor para identificar recomendaciones de ahorro y utilizar el AWS Cost and Usage Report para un seguimiento detallado de costos.",
            "3": "Activar el AWS Cost and Usage Report para un seguimiento integral y suscribirse a AWS Support para obtener información adicional sobre gestión de costos.",
            "4": "Usar AWS Cost Explorer para visualizar tendencias de costos y AWS Trusted Advisor para recibir recomendaciones regulares sobre optimización de costos."
        },
        "Correct Answer": "Usar AWS Budgets para configurar alertas de gasto y AWS Cost Explorer para analizar patrones y tendencias de gasto a lo largo del tiempo.",
        "Explanation": "Esta opción aborda directamente los requisitos de la startup al permitirles configurar alertas para los límites de gasto utilizando AWS Budgets, lo que ayuda a prevenir sobrepasos del presupuesto. Además, AWS Cost Explorer proporciona herramientas poderosas para analizar patrones y tendencias de gasto a lo largo del tiempo, lo que permite a la startup identificar oportunidades de ahorro y optimizar su uso de AWS de manera efectiva.",
        "Other Options": [
            "Implementar AWS Trusted Advisor para recomendaciones de ahorro es útil, pero no proporciona la capacidad de configurar alertas de gasto. El AWS Cost and Usage Report es detallado pero se centra más en datos en bruto que en el análisis de tendencias, lo que hace que esta combinación sea menos efectiva para las necesidades de la startup.",
            "Activar el AWS Cost and Usage Report es beneficioso para un seguimiento integral de costos, pero suscribirse a AWS Support no proporciona directamente información sobre gestión de costos. Esta opción carece de la función proactiva de alertas que ofrece AWS Budgets, que es crucial para monitorear gastos.",
            "Usar AWS Cost Explorer para visualizar tendencias es una buena elección, pero depender únicamente de AWS Trusted Advisor para recomendaciones no proporciona el mecanismo de alerta necesario para la gestión del presupuesto. Esta combinación no cumple completamente con el requisito de la startup de monitorear y alertar sobre límites de gasto."
        ]
    },
    {
        "Question Number": "50",
        "Situation": "Una empresa está configurando una VPC segura en AWS y necesita habilitar el acceso a Internet saliente para instancias en una subred privada. Están considerando usar una instancia NAT o una puerta de enlace NAT.",
        "Question": "¿Cuál de las siguientes describe correctamente las diferencias clave entre las instancias NAT y las puertas de enlace NAT, especialmente en lo que respecta a configuraciones de seguridad y mantenimiento?",
        "Options": {
            "1": "Las instancias NAT admiten el uso de Grupos de Seguridad y son altamente disponibles, mientras que las puertas de enlace NAT no admiten Grupos de Seguridad y dependen de ACLs de Red para el filtrado de tráfico.",
            "2": "Las puertas de enlace NAT ofrecen mayor disponibilidad, ancho de banda y requieren menos mantenimiento que las instancias NAT, pero solo admiten ACLs de Red para el filtrado de tráfico, no Grupos de Seguridad.",
            "3": "Las instancias NAT proporcionan escalado automático y alta disponibilidad dentro de una zona de disponibilidad, lo que las hace ideales para cargas de trabajo de producción.",
            "4": "Las puertas de enlace NAT permiten un uso multipropósito, como actuar como un host bastión, lo cual no es posible con las instancias NAT debido a las restricciones de gestión de AWS."
        },
        "Correct Answer": "Las puertas de enlace NAT ofrecen mayor disponibilidad, ancho de banda y requieren menos mantenimiento que las instancias NAT, pero solo admiten ACLs de Red para el filtrado de tráfico, no Grupos de Seguridad.",
        "Explanation": "Las puertas de enlace NAT están diseñadas para proporcionar una solución gestionada y altamente disponible para habilitar el acceso a Internet saliente para instancias en una subred privada. Se escalan automáticamente para acomodar las necesidades de ancho de banda del tráfico, lo que las hace adecuadas para cargas de trabajo de producción. Además, las puertas de enlace NAT requieren un mantenimiento mínimo ya que son gestionadas por AWS, a diferencia de las instancias NAT, que requieren configuración manual, escalado y mantenimiento. Aunque las puertas de enlace NAT no admiten Grupos de Seguridad, pueden ser controladas mediante ACLs de Red, lo que es una diferencia clave respecto a las instancias NAT que sí admiten Grupos de Seguridad.",
        "Other Options": [
            "Las instancias NAT admiten el uso de Grupos de Seguridad y son altamente disponibles, mientras que las puertas de enlace NAT no admiten Grupos de Seguridad y dependen de ACLs de Red para el filtrado de tráfico. Esta afirmación es incorrecta porque, aunque las instancias NAT admiten Grupos de Seguridad, las puertas de enlace NAT no los admiten en absoluto, dependiendo únicamente de ACLs de Red para el filtrado de tráfico. Además, las puertas de enlace NAT están diseñadas para alta disponibilidad.",
            "Las instancias NAT proporcionan escalado automático y alta disponibilidad dentro de una zona de disponibilidad, lo que las hace ideales para cargas de trabajo de producción. Esta afirmación es incorrecta porque las instancias NAT no proporcionan escalado automático; requieren intervención manual para escalar y no son inherentemente altamente disponibles a menos que se configuren con múltiples instancias en diferentes zonas de disponibilidad.",
            "Las puertas de enlace NAT permiten un uso multipropósito, como actuar como un host bastión, lo cual no es posible con las instancias NAT debido a las restricciones de gestión de AWS. Esta afirmación es incorrecta porque las puertas de enlace NAT no pueden actuar como hosts bastión; están específicamente diseñadas para funcionalidad NAT. Los hosts bastión son típicamente instancias EC2 configuradas para permitir acceso seguro a instancias en subredes privadas."
        ]
    },
    {
        "Question Number": "51",
        "Situation": "Una empresa de retail, ShopSmart, almacena datos de clientes, incluyendo PII, en buckets de Amazon S3. Para cumplir con las regulaciones de privacidad de datos, necesitan una solución que pueda identificar y clasificar automáticamente información sensible. Además, quieren la opción de crear reglas personalizadas para detectar patrones de datos únicos específicos de su negocio. ShopSmart está considerando Amazon Macie para abordar estas necesidades.",
        "Question": "¿Cómo ayuda Amazon Macie a garantizar la seguridad y privacidad de los datos para información sensible en buckets de S3, y qué opciones están disponibles para crear identificadores de datos?",
        "Options": {
            "1": "Amazon Macie solo proporciona identificadores de datos predefinidos, limitando su uso a tipos de datos específicos, como información financiera y registros de salud, sin opciones de personalización para otros patrones de datos sensibles.",
            "2": "Amazon Macie utiliza aprendizaje automático e identificadores de datos gestionados para el descubrimiento y clasificación automatizados de datos sensibles, incluyendo PII e información financiera. También permite la creación de identificadores de datos personalizados utilizando expresiones regulares y proximidad de palabras clave, lo que permite una identificación de datos más granular basada en necesidades organizacionales únicas.",
            "3": "Amazon Macie se centra principalmente en monitorear el tráfico de red para patrones inusuales, proporcionando alertas sobre el movimiento de datos pero no identificando directamente información sensible almacenada en buckets de S3.",
            "4": "Amazon Macie depende únicamente de AWS Security Hub para el descubrimiento y clasificación de datos, requiriendo que los usuarios configuren reglas personalizadas de EventBridge para detectar y clasificar datos basados en criterios predefinidos."
        },
        "Correct Answer": "Amazon Macie utiliza aprendizaje automático e identificadores de datos gestionados para el descubrimiento y clasificación automatizados de datos sensibles, incluyendo PII e información financiera. También permite la creación de identificadores de datos personalizados utilizando expresiones regulares y proximidad de palabras clave, lo que permite una identificación de datos más granular basada en necesidades organizacionales únicas.",
        "Explanation": "Amazon Macie está diseñado para ayudar a las organizaciones a descubrir, clasificar y proteger automáticamente datos sensibles almacenados en Amazon S3. Utiliza algoritmos de aprendizaje automático para identificar y clasificar información sensible, incluyendo información personal identificable (PII) y datos financieros. Además, Macie proporciona la flexibilidad de crear identificadores de datos personalizados, que pueden adaptarse a requisitos comerciales específicos. Esto se realiza a través del uso de expresiones regulares y proximidad de palabras clave, permitiendo a las organizaciones definir patrones únicos que son relevantes para sus operaciones, mejorando así sus esfuerzos de seguridad de datos y cumplimiento.",
        "Other Options": [
            "Amazon Macie no limita su funcionalidad solo a identificadores de datos predefinidos. Ofrece tanto identificadores de datos gestionados como la capacidad de crear identificadores personalizados, permitiendo una gama más amplia de detección de datos sensibles.",
            "Amazon Macie no se centra principalmente en monitorear el tráfico de red. En cambio, su función principal es identificar y clasificar datos sensibles dentro de los buckets de S3, lo que lo convierte en una herramienta clave para la privacidad y seguridad de los datos.",
            "Amazon Macie opera de manera independiente en términos de descubrimiento y clasificación de datos. Si bien puede integrarse con AWS Security Hub para una gestión de seguridad más amplia, no depende únicamente de él para sus funcionalidades principales."
        ]
    },
    {
        "Question Number": "52",
        "Situation": "Una empresa de juegos en línea tiene usuarios en todo el mundo y quiere minimizar la latencia desplegando su aplicación más cerca de los usuarios finales. Además, quieren optimizar costos evitando cargos por transferencia de datos entre regiones cuando usuarios de diferentes regiones acceden a la aplicación.",
        "Question": "¿Qué enfoque les ayudaría mejor a cumplir con estos requisitos?",
        "Options": {
            "1": "Desplegar todos los recursos en una única región de AWS y usar CloudFront para el almacenamiento en caché",
            "2": "Desplegar recursos en múltiples Zonas de Disponibilidad en una región de AWS",
            "3": "Desplegar la aplicación en múltiples regiones de AWS según las ubicaciones de los usuarios",
            "4": "Usar una única Zona de Disponibilidad y confiar en el enrutamiento DNS global"
        },
        "Correct Answer": "Desplegar la aplicación en múltiples regiones de AWS según las ubicaciones de los usuarios",
        "Explanation": "Desplegar la aplicación en múltiples regiones de AWS permite a la empresa de juegos colocar sus recursos más cerca de los usuarios finales, reduciendo significativamente la latencia. Al tener instancias en varias regiones, los usuarios pueden conectarse al servidor más cercano, lo que minimiza el tiempo que tarda en viajar la información. Además, este enfoque ayuda a evitar cargos por transferencia de datos entre regiones, ya que los usuarios que acceden a la aplicación desde su región local no incurrirán en costos asociados con la transferencia de datos entre regiones.",
        "Other Options": [
            "Desplegar todos los recursos en una única región de AWS y usar CloudFront para el almacenamiento en caché puede ayudar con la latencia hasta cierto punto, pero no aborda el problema de los cargos por transferencia de datos entre regiones cuando usuarios de diferentes regiones acceden a la aplicación. CloudFront puede almacenar contenido en caché, pero puede no mitigar completamente la latencia para todos los usuarios en todo el mundo.",
            "Desplegar recursos en múltiples Zonas de Disponibilidad en una región de AWS mejora la disponibilidad y la tolerancia a fallos, pero no reduce significativamente la latencia para usuarios ubicados lejos de esa región. También no ayuda con los costos de transferencia de datos entre regiones, ya que todos los usuarios seguirían accediendo a la misma región.",
            "Usar una única Zona de Disponibilidad y confiar en el enrutamiento DNS global no minimizaría efectivamente la latencia para usuarios ubicados lejos de esa zona. Si bien el enrutamiento DNS puede dirigir a los usuarios al punto final más cercano, no resuelve el problema de alta latencia para usuarios que están geográficamente distantes de la única Zona de Disponibilidad, ni aborda los cargos por transferencia de datos entre regiones."
        ]
    },
    {
        "Question Number": "53",
        "Situation": "Una empresa de análisis de datos realiza trabajos de procesamiento a gran escala para sus clientes, pero la demanda varía significativamente a lo largo de la semana. La empresa quiere una solución de computación rentable que les permita manejar estas cargas de trabajo mientras minimizan costos durante los períodos de baja demanda.",
        "Question": "¿Qué enfoque optimizaría mejor los costos para esta carga de trabajo? (Elige dos.)",
        "Options": {
            "1": "Usar instancias EC2 bajo demanda y comenzar instancias manualmente según sea necesario",
            "2": "Usar instancias reservadas para un número fijo de instancias EC2",
            "3": "Desplegar un grupo de Auto Scaling con instancias Spot para trabajos de procesamiento",
            "4": "Usar AWS Lambda para ejecutar todos los trabajos de procesamiento bajo demanda",
            "5": "Implementar planes de ahorro de EC2 para reducir costos en cargas de trabajo predecibles"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Desplegar un grupo de Auto Scaling con instancias Spot para trabajos de procesamiento",
            "Usar AWS Lambda para ejecutar todos los trabajos de procesamiento bajo demanda"
        ],
        "Explanation": "Desplegar un grupo de Auto Scaling con instancias Spot para trabajos de procesamiento es una solución rentable para cargas de trabajo variables. Las instancias Spot están disponibles con hasta un 90% de descuento en comparación con los precios bajo demanda y son ideales para aplicaciones con horarios de inicio y fin flexibles, o que pueden soportar interrupciones. Auto Scaling asegura que la empresa tenga la cantidad adecuada de capacidad para manejar la carga en cualquier momento, optimizando así los costos. Usar AWS Lambda para ejecutar todos los trabajos de procesamiento bajo demanda también es una buena opción, ya que permite a la empresa ejecutar código sin aprovisionar o gestionar servidores y solo paga por el tiempo de computación que consume, lo que puede ser muy rentable para cargas de trabajo esporádicas.",
        "Other Options": [
            "Usar instancias EC2 bajo demanda y comenzar instancias manualmente según sea necesario no es la solución más rentable para cargas de trabajo variables. Si bien proporciona flexibilidad, no aprovecha los ahorros de costos de las instancias Spot o de AWS Lambda.",
            "Usar instancias reservadas para un número fijo de instancias EC2 no es ideal para cargas de trabajo variables, ya que no proporciona la flexibilidad para escalar hacia arriba o hacia abajo según la demanda. Las instancias reservadas ofrecen un descuento significativo en comparación con los precios bajo demanda, pero requieren un compromiso de uno o tres años, lo que puede no ser adecuado para cargas de trabajo variables.",
            "Implementar planes de ahorro de EC2 para reducir costos en cargas de trabajo predecibles no es la mejor opción para este escenario. Los planes de ahorro ofrecen un descuento en el uso de computación de AWS, pero requieren un compromiso con una cantidad consistente de uso (medido en $/hora) durante 1 o 3 años, lo que puede no ser adecuado para cargas de trabajo variables."
        ]
    },
    {
        "Question Number": "54",
        "Situation": "Una aplicación de informes utilizada por un equipo de análisis debe manejar un alto volumen de consultas de lectura para generar información de manera rápida y eficiente. Mientras que la base de datos tiene una única fuente para las operaciones de escritura, necesita soportar un alto tráfico de lectura con baja latencia, incluso cuando la instancia principal está procesando una carga de trabajo pesada. El equipo quiere una configuración que pueda equilibrar la carga de lectura y proporcionar acceso ininterrumpido a la base de datos para consultas analíticas.",
        "Question": "¿Qué estrategia de replicación de base de datos lograría mejor esto?",
        "Options": {
            "1": "Habilitar el despliegue Multi-AZ para la base de datos principal, permitiendo la conmutación por error automática a una instancia de espera para mejorar la disponibilidad",
            "2": "Usar réplicas de lectura para descargar el tráfico de lectura de la base de datos principal, distribuyendo la carga de trabajo y reduciendo la latencia en las solicitudes de lectura",
            "3": "Desplegar una configuración activa-activa multi-región para soportar alta disponibilidad y equilibrar el tráfico de lectura y escritura entre diferentes regiones",
            "4": "Configurar la base de datos para replicación síncrona únicamente para asegurar la consistencia de los datos durante períodos de alto tráfico de lectura"
        },
        "Correct Answer": "Usar réplicas de lectura para descargar el tráfico de lectura de la base de datos principal, distribuyendo la carga de trabajo y reduciendo la latencia en las solicitudes de lectura",
        "Explanation": "Usar réplicas de lectura es la estrategia más efectiva para manejar altos volúmenes de consultas de lectura en este escenario. Las réplicas de lectura permiten que la base de datos principal se concentre en las operaciones de escritura mientras distribuyen las solicitudes de lectura entre múltiples réplicas. Esta configuración no solo equilibra la carga de lectura, sino que también reduce la latencia, ya que las consultas de lectura pueden ser procesadas por réplicas que están optimizadas para operaciones de lectura. Además, si la instancia principal está bajo una carga pesada, las réplicas de lectura aún pueden proporcionar acceso ininterrumpido a los datos, asegurando que las consultas analíticas se puedan ejecutar de manera rápida y eficiente.",
        "Other Options": [
            "Habilitar el despliegue Multi-AZ mejora principalmente la disponibilidad y las capacidades de conmutación por error, pero no aborda específicamente la necesidad de manejar un alto tráfico de lectura. Proporciona una instancia de espera para la conmutación por error, pero no distribuye la carga de lectura, lo cual es crucial para los requisitos del equipo de análisis.",
            "Desplegar una configuración activa-activa multi-región puede proporcionar alta disponibilidad y balanceo de carga, pero es más complejo y puede introducir latencia debido a la sincronización de datos entre regiones. Esta opción no es necesaria para el escenario dado, que se centra en gestionar el tráfico de lectura de manera eficiente en lugar de equilibrar tanto las operaciones de lectura como de escritura entre regiones.",
            "Configurar la base de datos para replicación síncrona asegura la consistencia de los datos, pero puede introducir latencia durante períodos de alto tráfico de lectura. La replicación síncrona requiere que todas las réplicas confirmen la recepción de datos antes de que la principal pueda continuar, lo que puede ralentizar las operaciones de lectura y no aborda efectivamente la necesidad de acceso a lectura de baja latencia."
        ]
    },
    {
        "Question Number": "55",
        "Situation": "Una startup almacena datos de usuarios en Amazon S3 y quiere optimizar los costos de almacenamiento implementando políticas de ciclo de vida de datos. Los datos se acceden con frecuencia durante los primeros 30 días y rara vez después de eso, pero deben ser retenidos durante 5 años por motivos de cumplimiento.",
        "Question": "¿Cuál política de ciclo de vida de datos sería la más rentable?",
        "Options": {
            "1": "Almacenar datos en S3 Standard y moverlos a Glacier después de 30 días",
            "2": "Almacenar datos en S3 Intelligent-Tiering durante todo su ciclo de vida",
            "3": "Mover datos a S3 Standard-IA después de 30 días, luego a Glacier Deep Archive después de un año",
            "4": "Almacenar todos los datos en S3 Standard y eliminarlos después de 5 años"
        },
        "Correct Answer": "Mover datos a S3 Standard-IA después de 30 días, luego a Glacier Deep Archive después de un año",
        "Explanation": "Esta opción es la más rentable porque aprovecha S3 Standard durante los primeros 30 días, cuando los datos se acceden con frecuencia, asegurando un rendimiento y costo óptimos para los datos activos. Después de 30 días, mover los datos a S3 Standard-IA (Acceso Infrecuente) reduce los costos de almacenamiento para datos que rara vez se acceden pero que aún deben ser retenidos. Finalmente, la transición a Glacier Deep Archive después de un año proporciona el costo de almacenamiento más bajo para la retención a largo plazo, lo que se alinea con el requisito de mantener los datos durante 5 años por motivos de cumplimiento. Esta estrategia equilibra eficazmente los costos y las necesidades de acceso a lo largo del ciclo de vida de los datos.",
        "Other Options": [
            "Almacenar datos en S3 Standard y moverlos a Glacier después de 30 días: Esta opción incurre en costos más altos durante los primeros 30 días porque mantiene los datos en S3 Standard, que es más caro que Standard-IA. Además, mover a Glacier después de 30 días puede no ser óptimo ya que los datos aún necesitarán ser retenidos durante 5 años, y Glacier no está diseñado para acceso frecuente.",
            "Almacenar datos en S3 Intelligent-Tiering durante todo su ciclo de vida: Aunque S3 Intelligent-Tiering mueve automáticamente los datos entre dos niveles de acceso según los patrones de acceso cambiantes, puede no ser la solución más rentable para este caso específico. Dado que los datos se acceden con frecuencia durante los primeros 30 días y rara vez después, un enfoque más adaptado (como mover a Standard-IA) probablemente ahorraría más en costos en comparación con las tarifas de Intelligent-Tiering.",
            "Almacenar todos los datos en S3 Standard y eliminarlos después de 5 años: Esta opción es la menos rentable porque mantiene todos los datos en S3 Standard durante toda la duración, que es la clase de almacenamiento más cara. Además, no aprovecha las opciones de almacenamiento de menor costo para datos que se acceden infrecuentemente después de los primeros 30 días."
        ]
    },
    {
        "Question Number": "56",
        "Situation": "Una empresa de comercio electrónico quiere proteger sus datos de transacciones en caso de una falla del sistema. Para limitar la posible pérdida de datos, han establecido un estricto Objetivo de Punto de Recuperación (RPO) de 5 minutos, lo que significa que solo pueden permitirse perder hasta 5 minutos de datos en caso de una interrupción. Necesitan una solución que mantenga la replicación de datos actualizada para lograr este RPO mínimo.",
        "Question": "¿Cuál de los siguientes enfoques cumpliría mejor con este requisito de RPO?",
        "Options": {
            "1": "Tomar instantáneas horarias de la base de datos para proporcionar puntos de recuperación de datos regulares, permitiendo la restauración hasta la última copia de seguridad horaria",
            "2": "Implementar replicación continua de datos a una base de datos secundaria, asegurando actualizaciones casi en tiempo real y minimizando la posible pérdida de datos",
            "3": "Respaldar datos en Amazon S3 cada 10 minutos, creando puntos de recuperación regulares que se pueden restaurar según sea necesario",
            "4": "Usar copias de seguridad completas semanales con copias de seguridad incrementales diarias para capturar cambios en los datos de manera rentable"
        },
        "Correct Answer": "Implementar replicación continua de datos a una base de datos secundaria, asegurando actualizaciones casi en tiempo real y minimizando la posible pérdida de datos",
        "Explanation": "La replicación continua de datos permite actualizaciones en tiempo real o casi en tiempo real de la base de datos principal a una base de datos secundaria. Este enfoque asegura que cualquier cambio realizado en la base de datos principal se refleje de inmediato en la base de datos secundaria, minimizando así la posible pérdida de datos a solo unos pocos segundos o minutos, lo que se alinea perfectamente con el estricto Objetivo de Punto de Recuperación (RPO) de 5 minutos establecido por la empresa de comercio electrónico. Este método es la forma más efectiva de cumplir con el requisito de mantener la replicación de datos actualizada.",
        "Other Options": [
            "Tomar instantáneas horarias de la base de datos no cumpliría con el requisito de RPO de 5 minutos, ya que permitiría la pérdida de hasta 59 minutos de datos si se produjera una falla justo después de que se tomara la última instantánea.",
            "Respaldar datos en Amazon S3 cada 10 minutos no cumpliría suficientemente con el RPO de 5 minutos, ya que aún podría haber una posible pérdida de hasta 9 minutos de datos si se produjera una falla justo antes de la siguiente copia de seguridad.",
            "Usar copias de seguridad completas semanales con copias de seguridad incrementales diarias no es adecuado para un RPO de 5 minutos, ya que este método resultaría en una pérdida significativa de datos, potencialmente de hasta 24 horas, dependiendo de cuándo se tomó la última copia de seguridad incremental."
        ]
    },
    {
        "Question Number": "57",
        "Situation": "Una gran plataforma de comercio electrónico necesita implementar una arquitectura impulsada por eventos para gestionar actualizaciones de inventario, procesamiento de pedidos y notificaciones a clientes. La plataforma necesita asegurar que el sistema sea altamente disponible, resistente a fallos y capaz de escalar automáticamente según el tráfico.",
        "Question": "¿Qué diseño de arquitectura debería implementarse para lograr estos objetivos? (Elija dos.)",
        "Options": {
            "1": "Usar Amazon SQS para desacoplar los servicios y asegurar el procesamiento asíncrono de mensajes, y usar Amazon SNS para transmitir eventos a múltiples suscriptores. Implementar AWS Lambda para procesar eventos y escalar automáticamente.",
            "2": "Usar instancias de Amazon EC2 ejecutando una aplicación personalizada para manejar mensajes de las fuentes de eventos, y configurar Amazon Route 53 para dirigir el tráfico según la carga.",
            "3": "Usar Amazon RDS con implementación en múltiples zonas de disponibilidad para manejar el procesamiento de eventos, y almacenar mensajes en Amazon DynamoDB para escalabilidad.",
            "4": "Usar Amazon Kinesis Data Streams para manejar datos de eventos en tiempo real, e integrarse con Amazon Elasticsearch Service para consultar los datos.",
            "5": "Implementar AWS Step Functions para orquestar flujos de trabajo de procesamiento de eventos y usar Amazon MQ para la intermediación de mensajes."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Usar Amazon SQS para desacoplar los servicios y asegurar el procesamiento asíncrono de mensajes, y usar Amazon SNS para transmitir eventos a múltiples suscriptores. Implementar AWS Lambda para procesar eventos y escalar automáticamente.",
            "Usar Amazon Kinesis Data Streams para manejar datos de eventos en tiempo real, e integrarse con Amazon Elasticsearch Service para consultar los datos."
        ],
        "Explanation": "Amazon SQS y SNS se utilizan para desacoplar servicios y transmitir eventos a múltiples suscriptores, respectivamente. Esto asegura alta disponibilidad y resiliencia a fallos. AWS Lambda es sin servidor y escala automáticamente según la carga de trabajo, lo que lo hace adecuado para procesar eventos. Por otro lado, Amazon Kinesis Data Streams está diseñado para manejar datos de eventos en tiempo real, lo cual es crucial para una plataforma de comercio electrónico. Amazon Elasticsearch Service permite la consulta eficiente de estos datos.",
        "Other Options": [
            "Usar instancias de Amazon EC2 ejecutando una aplicación personalizada para manejar mensajes de las fuentes de eventos, y configurar Amazon Route 53 para dirigir el tráfico según la carga no es la mejor opción. Aunque las instancias de EC2 pueden usarse para ejecutar aplicaciones y Route 53 puede ayudar a distribuir la carga, este enfoque no proporciona inherentemente la arquitectura impulsada por eventos, alta disponibilidad, resiliencia a fallos y escalado automático requeridos.",
            "Usar Amazon RDS con implementación en múltiples zonas de disponibilidad para manejar el procesamiento de eventos, y almacenar mensajes en Amazon DynamoDB para escalabilidad no es ideal. Aunque RDS y DynamoDB son servicios robustos de AWS, no están diseñados para arquitecturas impulsadas por eventos. RDS es un servicio de base de datos relacional, no un servicio de procesamiento de eventos, y DynamoDB, aunque escalable, no está diseñado para mensajería de eventos.",
            "Implementar AWS Step Functions para orquestar flujos de trabajo de procesamiento de eventos y usar Amazon MQ para la intermediación de mensajes no es la mejor elección. Aunque Step Functions puede orquestar flujos de trabajo y Amazon MQ puede intermediar mensajes, no proporcionan inherentemente la alta disponibilidad, resiliencia a fallos y escalado automático requeridos para este escenario."
        ]
    },
    {
        "Question Number": "58",
        "Situation": "Una empresa está implementando una aplicación de computación de alto rendimiento en Amazon EC2 y quiere optimizar para la menor latencia de red posible y el mayor rendimiento de paquetes por segundo entre sus instancias. Al mismo tiempo, tienen otra aplicación que requiere la máxima disponibilidad y resiliencia al aislar cada instancia en diferentes racks.",
        "Question": "¿Qué tipos de grupos de colocación debería utilizar la empresa para estas aplicaciones, y por qué?",
        "Options": {
            "1": "Utilizar Grupos de Colocación en Clúster para la aplicación de alto rendimiento para lograr baja latencia y alto rendimiento, y Grupos de Colocación Dispersos para la aplicación que requiere alta disponibilidad y aislamiento entre racks.",
            "2": "Utilizar Grupos de Colocación Dispersos para ambas aplicaciones para asegurar resiliencia y aislar instancias en múltiples racks.",
            "3": "Utilizar Grupos de Colocación por Partición para la aplicación de alto rendimiento para proporcionar alto rendimiento y Grupos de Colocación en Clúster para la aplicación aislada para reducir la latencia.",
            "4": "Utilizar Grupos de Colocación en Clúster para ambas aplicaciones para minimizar la latencia y aumentar el rendimiento entre instancias."
        },
        "Correct Answer": "Utilizar Grupos de Colocación en Clúster para la aplicación de alto rendimiento para lograr baja latencia y alto rendimiento, y Grupos de Colocación Dispersos para la aplicación que requiere alta disponibilidad y aislamiento entre racks.",
        "Explanation": "Los Grupos de Colocación en Clúster están diseñados para proporcionar baja latencia y alto rendimiento al colocar instancias cerca unas de otras dentro de una única Zona de Disponibilidad. Esto es ideal para aplicaciones de computación de alto rendimiento que requieren comunicación rápida entre instancias. Por otro lado, los Grupos de Colocación Dispersos aseguran que las instancias se coloquen en diferentes racks, lo que mejora la disponibilidad y resiliencia al reducir el riesgo de fallos simultáneos. Esto hace que los Grupos de Colocación Dispersos sean adecuados para aplicaciones que necesitan estar aisladas entre sí para mantener una alta disponibilidad.",
        "Other Options": [
            "Utilizar Grupos de Colocación Dispersos para ambas aplicaciones aseguraría resiliencia y aislamiento, pero no optimizaría para baja latencia y alto rendimiento para la aplicación de alto rendimiento, que es un requisito crítico.",
            "Utilizar Grupos de Colocación por Partición para la aplicación de alto rendimiento es incorrecto porque los Grupos de Colocación por Partición están diseñados para aplicaciones que requieren alta disponibilidad y tolerancia a fallos, no específicamente para baja latencia y alto rendimiento. Además, utilizar Grupos de Colocación en Clúster para la aplicación aislada no proporcionaría la resiliencia necesaria entre racks.",
            "Utilizar Grupos de Colocación en Clúster para ambas aplicaciones optimizaría para baja latencia y rendimiento, pero no proporcionaría el aislamiento y resiliencia necesarios para la aplicación que requiere alta disponibilidad, ya que todas las instancias se colocarían en el mismo rack."
        ]
    },
    {
        "Question Number": "59",
        "Situation": "Una empresa está desarrollando una aplicación que expondrá APIs a los clientes a través de una interfaz web. La empresa necesita asegurarse de que las APIs puedan escalar automáticamente según la demanda, manejar picos de tráfico y proporcionar una gestión eficiente de las APIs.",
        "Question": "¿Qué servicio de AWS debería utilizar la empresa para lograr esto, y qué principios de diseño deberían seguirse para asegurar escalabilidad y resiliencia?",
        "Options": {
            "1": "Utilizar Amazon API Gateway para crear y gestionar las APIs, y combinarlo con AWS Lambda para computación sin estado para manejar cargas de trabajo impredecibles. Implementar estrategias de caché para reducir la latencia y mejorar el rendimiento.",
            "2": "Utilizar Amazon EC2 para alojar las APIs y gestionar el tráfico con un grupo de Auto Scaling, mientras se almacena la información en Amazon RDS para alta disponibilidad.",
            "3": "Utilizar AWS Fargate para gestionar contenedores Docker que ejecutan las APIs, e implementar llamadas directas a la API de Amazon DynamoDB para almacenar datos de la aplicación.",
            "4": "Utilizar AWS Elastic Load Balancer para dirigir el tráfico de la API a instancias de EC2, y almacenar los datos de la API en Amazon S3 para alta escalabilidad."
        },
        "Correct Answer": "Utilizar Amazon API Gateway para crear y gestionar las APIs, y combinarlo con AWS Lambda para computación sin estado para manejar cargas de trabajo impredecibles. Implementar estrategias de caché para reducir la latencia y mejorar el rendimiento.",
        "Explanation": "Amazon API Gateway está diseñado específicamente para crear, publicar y gestionar APIs a gran escala. Puede manejar automáticamente picos de tráfico y proporciona características integradas para caché, limitación y monitoreo. Cuando se combina con AWS Lambda, que permite la ejecución sin servidor de código, la aplicación puede escalar automáticamente según la demanda sin necesidad de aprovisionar servidores. Esta combinación soporta computación sin estado, que es ideal para manejar cargas de trabajo impredecibles. Las estrategias de caché pueden mejorar aún más el rendimiento al reducir el número de llamadas realizadas a los servicios de backend, mejorando así los tiempos de respuesta y reduciendo costos.",
        "Other Options": [
            "Utilizar Amazon EC2 para alojar las APIs requiere gestión manual de instancias y configuraciones de escalado, lo que puede complicar la arquitectura y puede no manejar picos de tráfico tan eficientemente como las soluciones sin servidor. Aunque los grupos de Auto Scaling pueden ayudar, todavía implican más sobrecarga en comparación con el enfoque sin servidor.",
            "AWS Fargate es una buena opción para gestionar contenedores, pero añade complejidad en comparación con el uso de API Gateway y Lambda. Las llamadas directas a DynamoDB pueden funcionar, pero sin las características de gestión de API de API Gateway, la solución puede carecer de la escalabilidad y capacidades de monitoreo necesarias.",
            "AWS Elastic Load Balancer puede distribuir el tráfico a instancias de EC2, pero esta configuración aún requiere gestionar esas instancias y escalarlas manualmente. Almacenar datos de la API en Amazon S3 no es adecuado para respuestas dinámicas de API, ya que S3 es principalmente para almacenamiento de objetos y no proporciona el mismo nivel de rendimiento y capacidades de consulta que una solución de base de datos."
        ]
    },
    {
        "Question Number": "60",
        "Situation": "Una empresa está experimentando un aumento en el tráfico de clientes en su aplicación web y necesita escalar su infraestructura para manejar la carga. Están considerando opciones de escalado horizontal y vertical.",
        "Question": "¿Cuál es una diferencia clave entre el escalado horizontal y el vertical, y cuál sería más adecuado para minimizar las interrupciones de la aplicación?",
        "Options": {
            "1": "El escalado vertical implica aumentar el tamaño de la instancia, requiriendo un reinicio, lo que puede causar interrupciones temporales, mientras que el escalado horizontal implica agregar más instancias sin necesidad de reinicio, evitando así interrupciones.",
            "2": "El escalado horizontal añade más recursos a la misma instancia, lo que aumenta la capacidad sin interrupciones, mientras que el escalado vertical añade nuevas instancias para manejar más tráfico.",
            "3": "El escalado vertical requiere modificación de la aplicación para cada nuevo tamaño de instancia, mientras que el escalado horizontal no requiere modificaciones en la aplicación.",
            "4": "El escalado horizontal tiene un límite estricto en el número de instancias que se pueden agregar, mientras que el escalado vertical ofrece capacidad ilimitada."
        },
        "Correct Answer": "El escalado vertical implica aumentar el tamaño de la instancia, requiriendo un reinicio, lo que puede causar interrupciones temporales, mientras que el escalado horizontal implica agregar más instancias sin necesidad de reinicio, evitando así interrupciones.",
        "Explanation": "La diferencia clave entre el escalado horizontal y el vertical radica en cómo se añaden recursos para manejar la carga aumentada. El escalado vertical (también conocido como 'escalado hacia arriba') implica actualizar los recursos del servidor existente, como CPU, RAM o almacenamiento. Este proceso a menudo requiere un reinicio del servidor, lo que puede llevar a un tiempo de inactividad temporal de la aplicación. En contraste, el escalado horizontal (o 'escalado hacia afuera') implica agregar más instancias o servidores para distribuir la carga. Este método permite que la aplicación continúe funcionando sin interrupciones, lo que lo hace más adecuado para minimizar interrupciones durante períodos de tráfico elevado.",
        "Other Options": [
            "Esta opción afirma incorrectamente que el escalado horizontal añade recursos a la misma instancia, lo cual no es preciso. El escalado horizontal añade más instancias en lugar de aumentar la capacidad de una sola instancia.",
            "Esta opción es incorrecta porque sugiere que el escalado vertical requiere modificación de la aplicación para cada nuevo tamaño de instancia. En realidad, el escalado vertical no requiere modificaciones en la aplicación en sí, pero sí requiere un reinicio, lo que puede causar interrupciones.",
            "Esta opción es engañosa ya que afirma que el escalado horizontal tiene un límite estricto en las instancias, lo cual no es universalmente cierto. Aunque puede haber límites prácticos basados en la infraestructura o las capacidades del proveedor de la nube, el escalado horizontal es generalmente más flexible que el escalado vertical, que está limitado por la capacidad máxima de un solo servidor."
        ]
    },
    {
        "Question Number": "61",
        "Situation": "Al configurar una conexión VPN IPSEC entre dos sitios empresariales, ¿cuál de las siguientes describe correctamente el papel de IKE (Intercambio de Claves de Internet) Fase 1 y Fase 2 en el establecimiento de una conexión segura?",
        "Question": "¿Cuál de las siguientes afirmaciones son verdaderas respecto a IKE Fase 1 y Fase 2? (Elige dos.)",
        "Options": {
            "1": "IKE Fase 1 establece un túnel seguro utilizando cifrado simétrico, mientras que IKE Fase 2 utiliza cifrado asimétrico para la transferencia de datos en bloque a través del túnel.",
            "2": "IKE Fase 1 es responsable de autenticar y establecer una conexión segura con cifrado asimétrico, configurando una clave simétrica y creando la Asociación de Seguridad (SA) de IKE; IKE Fase 2 utiliza esta clave para una rápida transferencia de datos en bloque cifrados, creando la SA IPSEC.",
            "3": "IKE Fase 1 establece directamente la SA IPSEC utilizando claves simétricas intercambiadas a través de una red pública, mientras que IKE Fase 2 gestiona la re-autenticación de cada sesión.",
            "4": "IKE Fase 1 y Fase 2 utilizan cifrado asimétrico durante todo el proceso de configuración de la conexión y transferencia de datos para garantizar el más alto nivel de seguridad.",
            "5": "IKE Fase 1 negocia los parámetros para el túnel IPSEC, y IKE Fase 2 maneja el cifrado real de los datos que se transmiten."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "IKE Fase 1 es responsable de autenticar y establecer una conexión segura con cifrado asimétrico, configurando una clave simétrica y creando la Asociación de Seguridad (SA) de IKE; IKE Fase 2 utiliza esta clave para una rápida transferencia de datos en bloque cifrados, creando la SA IPSEC.",
            "IKE Fase 1 negocia los parámetros para el túnel IPSEC, y IKE Fase 2 maneja el cifrado real de los datos que se transmiten."
        ],
        "Explanation": "IKE Fase 1 es responsable de autenticar a los pares, establecer una conexión segura y configurar una clave simétrica para el cifrado de datos. Utiliza cifrado asimétrico para estas tareas para garantizar la seguridad. Una vez hecho esto, crea la Asociación de Seguridad (SA) de IKE. IKE Fase 2 utiliza la clave simétrica configurada en la Fase 1 para una rápida transferencia de datos en bloque cifrados. Crea la SA IPSEC que se utiliza para la transferencia real de datos. La Fase 1 también negocia los parámetros para el túnel IPSEC, y la Fase 2 maneja el cifrado real de los datos que se transmiten.",
        "Other Options": [
            "IKE Fase 1 utiliza cifrado asimétrico para el establecimiento de la conexión segura y la configuración de la clave simétrica, no cifrado simétrico. IKE Fase 2 utiliza la clave simétrica de la Fase 1 para la transferencia de datos, no cifrado asimétrico.",
            "IKE Fase 1 no establece directamente la SA IPSEC, establece la SA de IKE. La SA IPSEC se establece en la Fase 2. Además, las claves simétricas no se intercambian a través de una red pública, se configuran de forma segura utilizando cifrado asimétrico en la Fase 1.",
            "Aunque IKE Fase 1 utiliza cifrado asimétrico para el establecimiento de la conexión segura y la configuración de la clave simétrica, la Fase 2 utiliza la clave simétrica de la Fase 1 para la transferencia de datos, no cifrado asimétrico."
        ]
    },
    {
        "Question Number": "62",
        "Situation": "Una empresa financiera necesita almacenar datos críticos de transacciones en una solución de almacenamiento altamente disponible y resiliente para garantizar la durabilidad y accesibilidad de los datos. También quieren proteger los datos contra eliminaciones accidentales y recuperarlos rápidamente en caso de cualquier desastre.",
        "Question": "¿Cuál configuración en Amazon S3 cumple mejor con estos requisitos? (Elige dos.)",
        "Options": {
            "1": "Utiliza la clase de almacenamiento Amazon S3 Standard con versionado habilitado y replicación entre regiones para proteger contra eliminaciones accidentales y garantizar la disponibilidad de datos en múltiples regiones.",
            "2": "Utiliza Amazon S3 Glacier para almacenamiento de bajo costo y habilita el bloqueo de objetos para prevenir eliminaciones accidentales mientras mantienes un acceso rápido a los datos.",
            "3": "Almacena datos en Amazon S3 Intelligent-Tiering para reducir costos, confiando en AWS Backup para la recuperación ante desastres entre regiones.",
            "4": "Utiliza Amazon S3 One Zone-Infrequent Access para almacenar datos en una única Zona de Disponibilidad y habilita el versionado para proteger contra la pérdida de datos.",
            "5": "Habilita la eliminación con Autenticación Multifactor (MFA) en los buckets de Amazon S3 para proporcionar una capa adicional de protección contra eliminaciones accidentales."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Utiliza la clase de almacenamiento Amazon S3 Standard con versionado habilitado y replicación entre regiones para proteger contra eliminaciones accidentales y garantizar la disponibilidad de datos en múltiples regiones.",
            "Habilita la eliminación con Autenticación Multifactor (MFA) en los buckets de Amazon S3 para proporcionar una capa adicional de protección contra eliminaciones accidentales."
        ],
        "Explanation": "La clase de almacenamiento Amazon S3 Standard proporciona un almacenamiento de objetos de alta durabilidad, disponibilidad y rendimiento para datos de acceso frecuente. Cuando se habilita el versionado, mantiene todas las versiones de un objeto (incluyendo todas las escrituras y eliminaciones) en el bucket. La replicación entre regiones permite la copia automática y asíncrona de objetos entre buckets en diferentes regiones, lo que puede ayudar a cumplir con los requisitos de cumplimiento y minimizar la latencia. La eliminación con Autenticación Multifactor (MFA) añade una capa adicional de seguridad al requerir MFA para eliminar una versión de objeto o suspender el versionado en el bucket.",
        "Other Options": [
            "Amazon S3 Glacier es una clase de almacenamiento segura, duradera y de bajo costo para archivo de datos y copias de seguridad a largo plazo. Sin embargo, no proporciona acceso rápido a los datos, ya que los tiempos de recuperación pueden ser de minutos a horas.",
            "Amazon S3 Intelligent-Tiering está diseñado para optimizar costos moviendo automáticamente los datos a la capa de acceso más rentable, sin impacto en el rendimiento ni sobrecarga operativa. AWS Backup puede ser utilizado para la recuperación ante desastres, pero esta opción no proporciona protección contra eliminaciones accidentales.",
            "Amazon S3 One Zone-Infrequent Access es una opción de menor costo para datos de acceso poco frecuente, pero almacena datos en una única Zona de Disponibilidad, lo que es menos resiliente y no cumple con el requisito de alta disponibilidad."
        ]
    },
    {
        "Question Number": "63",
        "Situation": "Una empresa de servicios financieros está migrando su aplicación local a AWS. La aplicación consta de una capa web, una capa de aplicación y una capa de base de datos. La empresa requiere un estricto aislamiento entre capas por razones de seguridad y cumplimiento. También necesitan optimizar la dirección IP para acomodar el crecimiento futuro.",
        "Question": "¿Qué arquitectura de red debería diseñar el arquitecto de soluciones para cumplir con estos requisitos? (Elige dos.)",
        "Options": {
            "1": "Desplegar todas las capas en una única subred pública con grupos de seguridad controlando el acceso.",
            "2": "Utilizar una única subred privada para todas las capas con ACLs de red para aislamiento.",
            "3": "Crear subredes privadas separadas para cada capa a través de múltiples Zonas de Disponibilidad, utilizando una VPC con bloques CIDR que permitan la expansión futura.",
            "4": "Colocar la capa web en una subred pública y tanto la capa de aplicación como la de base de datos en una única subred privada con rangos IP superpuestos.",
            "5": "Implementar múltiples subredes privadas para cada capa dentro de una VPC y utilizar emparejamiento de VPC para aislar el tráfico entre capas."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Crear subredes privadas separadas para cada capa a través de múltiples Zonas de Disponibilidad, utilizando una VPC con bloques CIDR que permitan la expansión futura.",
            "Implementar múltiples subredes privadas para cada capa dentro de una VPC y utilizar emparejamiento de VPC para aislar el tráfico entre capas."
        ],
        "Explanation": "Crear subredes privadas separadas para cada capa a través de múltiples Zonas de Disponibilidad permite un estricto aislamiento entre capas, que es un requisito para la empresa. Utilizar una VPC con bloques CIDR que permitan la expansión futura ayuda a optimizar la dirección IP para acomodar el crecimiento futuro. Implementar múltiples subredes privadas para cada capa dentro de una VPC y utilizar emparejamiento de VPC para aislar el tráfico entre capas también proporciona el aislamiento y la seguridad requeridos.",
        "Other Options": [
            "Desplegar todas las capas en una única subred pública con grupos de seguridad controlando el acceso no es una buena práctica ya que no proporciona el aislamiento requerido entre capas y expone la aplicación a posibles riesgos de seguridad.",
            "Utilizar una única subred privada para todas las capas con ACLs de red para aislamiento no proporciona el aislamiento requerido entre capas ya que todas las capas están en la misma subred.",
            "Colocar la capa web en una subred pública y tanto la capa de aplicación como la de base de datos en una única subred privada con rangos IP superpuestos no proporciona el aislamiento requerido entre capas y puede causar conflictos de IP debido a los rangos IP superpuestos."
        ]
    },
    {
        "Question Number": "64",
        "Situation": "Una empresa está utilizando Amazon RDS para su base de datos y requiere cifrado de datos por motivos de cumplimiento. La empresa quiere asegurarse de que los datos estén cifrados tanto en reposo como en tránsito, y que las claves de cifrado se gestionen de forma segura. Además, están utilizando Oracle como su motor de base de datos.",
        "Question": "¿Qué enfoque satisfaría mejor estos requisitos de seguridad? (Elija dos.)",
        "Options": {
            "1": "Utilizar SSL/TLS integrado de RDS para el cifrado en tránsito y habilitar el Cifrado de Datos Transparente (TDE) para el cifrado en reposo dentro del motor de base de datos Oracle.",
            "2": "Habilitar Amazon RDS para utilizar claves gestionadas por KMS para el cifrado en reposo y configurar SSL/TLS para manejar el cifrado en tránsito.",
            "3": "Integrar CloudHSM con Amazon RDS para gestionar las claves de cifrado para Oracle, asegurando que AWS no tenga acceso a las claves, y habilitar SSL/TLS para el cifrado en tránsito.",
            "4": "Utilizar la configuración de cifrado predeterminada de RDS y confiar en el cifrado de volumen EBS para los datos en reposo, sin ninguna configuración adicional para el cifrado en tránsito.",
            "5": "Implementar cifrado a nivel de aplicación para manejar el cifrado de datos antes de enviarlos a RDS y utilizar conexiones VPN para el cifrado en tránsito."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Utilizar SSL/TLS integrado de RDS para el cifrado en tránsito y habilitar el Cifrado de Datos Transparente (TDE) para el cifrado en reposo dentro del motor de base de datos Oracle.",
            "Habilitar Amazon RDS para utilizar claves gestionadas por KMS para el cifrado en reposo y configurar SSL/TLS para manejar el cifrado en tránsito."
        ],
        "Explanation": "La primera respuesta correcta es utilizar SSL/TLS integrado de RDS para el cifrado en tránsito y habilitar el Cifrado de Datos Transparente (TDE) para el cifrado en reposo dentro del motor de base de datos Oracle. SSL/TLS es un protocolo que asegura la transmisión segura de datos a través de redes, y TDE es una característica de Oracle que proporciona cifrado de datos en reposo. La segunda respuesta correcta es habilitar Amazon RDS para utilizar claves gestionadas por KMS para el cifrado en reposo y configurar SSL/TLS para manejar el cifrado en tránsito. Amazon Key Management Service (KMS) es un servicio gestionado que facilita la creación y control de las claves de cifrado utilizadas para cifrar sus datos.",
        "Other Options": [
            "Integrar CloudHSM con Amazon RDS para gestionar las claves de cifrado para Oracle y habilitar SSL/TLS para el cifrado en tránsito no es necesario porque AWS KMS puede manejar la gestión de claves para RDS, y es más simple y rentable.",
            "Utilizar la configuración de cifrado predeterminada de RDS y confiar en el cifrado de volumen EBS para los datos en reposo, sin ninguna configuración adicional para el cifrado en tránsito, no es suficiente porque no asegura el cifrado en tránsito.",
            "Implementar cifrado a nivel de aplicación para manejar el cifrado de datos antes de enviarlos a RDS y utilizar conexiones VPN para el cifrado en tránsito no es el mejor enfoque porque añade complejidad y sobrecarga innecesarias. Es más eficiente utilizar los servicios integrados de AWS para el cifrado en reposo y en tránsito."
        ]
    },
    {
        "Question Number": "65",
        "Situation": "Una empresa de producción de video almacena miles de archivos de video, que rara vez se acceden después de la producción inicial. Quieren una solución de almacenamiento rentable que les permita archivar estos archivos pero que aún les permita recuperarlos en unos minutos cuando sea necesario.",
        "Question": "¿Qué servicios de almacenamiento de AWS satisfarían mejor estos requisitos? (Elija dos.)",
        "Options": {
            "1": "Amazon EFS",
            "2": "Amazon S3 Glacier Instant Retrieval",
            "3": "Amazon FSx for Windows File Server",
            "4": "Amazon EBS Provisioned IOPS",
            "5": "Amazon S3 Intelligent-Tiering"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon S3 Glacier Instant Retrieval",
            "Amazon S3 Intelligent-Tiering"
        ],
        "Explanation": "Amazon S3 Glacier Instant Retrieval es una solución de almacenamiento rentable para la archivación de datos. Está diseñado para el almacenamiento a largo plazo de datos que se acceden con poca frecuencia, pero que, cuando se necesita, se pueden recuperar en minutos. Esto lo convierte en una opción adecuada para la empresa de producción de video. Amazon S3 Intelligent-Tiering es otra opción adecuada, ya que mueve automáticamente los datos al nivel de acceso más rentable, sin impacto en el rendimiento ni sobrecarga operativa. Es ideal para datos con patrones de acceso desconocidos o cambiantes, lo que lo convierte en una buena opción para almacenar archivos de video que rara vez se acceden.",
        "Other Options": [
            "Amazon EFS (Elastic File System) es un servicio de almacenamiento de archivos para usar con Amazon EC2. Aunque podría utilizarse técnicamente para almacenar archivos de video, no es la solución más rentable para datos que rara vez se acceden.",
            "Amazon FSx for Windows File Server proporciona un sistema de archivos nativo de Microsoft Windows totalmente gestionado. Esta no es la solución más rentable para almacenar archivos de video que rara vez se acceden, y es más adecuada para cargas de trabajo empresariales que requieren sistemas de archivos de Windows.",
            "Amazon EBS (Elastic Block Store) Provisioned IOPS es un tipo de almacenamiento diseñado para ofrecer un rendimiento dentro del 10% de las IOPS provisionadas el 99.9% del tiempo. Esto es más adecuado para cargas de trabajo que requieren alto rendimiento en lugar de almacenamiento a largo plazo rentable de datos que rara vez se acceden."
        ]
    }
]