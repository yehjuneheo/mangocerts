[
    {
        "Question Number": "1",
        "Situation": "Ein Finanzdienstleistungsunternehmen sammelt Transaktionsdaten in verschiedenen Formaten aus mehreren Quellen. Bevor Analysen durchgeführt werden, müssen die Daten bereinigt, normalisiert und angereichert werden. Das Unternehmen sucht nach einer serverlosen Lösung, die diesen ETL (Extract, Transform, Load)-Prozess automatisieren kann.",
        "Question": "Welchen AWS-Dienst sollte der Lösungsarchitekt für die Datenumwandlung empfehlen?",
        "Options": {
            "1": "Amazon EMR",
            "2": "AWS Glue",
            "3": "AWS Lambda",
            "4": "Amazon Redshift Spectrum"
        },
        "Correct Answer": "AWS Glue",
        "Explanation": "AWS Glue ist ein vollständig verwalteter ETL (Extract, Transform, Load)-Dienst, der speziell für die Datenvorbereitung und -umwandlung entwickelt wurde. Er automatisiert den Prozess der Entdeckung, Katalogisierung und Transformation von Daten, was ihn ideal für das Finanzdienstleistungsunternehmen macht, das Transaktionsdaten aus verschiedenen Quellen bereinigen, normalisieren und anreichern muss. AWS Glue kann serverlose Operationen durchführen, was den Anforderungen des Unternehmens an eine serverlose Lösung entspricht.",
        "Other Options": [
            "Amazon EMR ist eine verwaltete Cluster-Plattform, die das Ausführen von Big-Data-Frameworks wie Apache Hadoop und Apache Spark vereinfacht. Obwohl es ETL-Aufgaben durchführen kann, ist es keine serverlose Lösung und erfordert mehr Verwaltung und Konfiguration im Vergleich zu AWS Glue.",
            "AWS Lambda ist ein serverloser Compute-Dienst, der Code als Reaktion auf Ereignisse ausführt. Obwohl es für die Datenumwandlung verwendet werden kann, ist es nicht speziell für ETL-Prozesse konzipiert und verfügt nicht über die integrierten Funktionen zur Katalogisierung von Daten und Schema-Inferenz, die AWS Glue bietet.",
            "Amazon Redshift Spectrum ermöglicht es Ihnen, Abfragen gegen Daten zu führen, die in S3 gespeichert sind, ohne sie in Redshift zu laden. Es ist jedoch hauptsächlich ein Abfragedienst und kein ETL-Dienst und bietet nicht die erforderlichen Datenumwandlungsfunktionen zum Bereinigen und Anreichern von Daten vor der Analyse."
        ]
    },
    {
        "Question Number": "2",
        "Situation": "Ein Unternehmen verwendet Amazon CloudWatch, um die Sicherheit seiner AWS-Ressourcen zu überwachen. Das Unternehmen muss ein System einrichten, das automatisch auf potenzielle Sicherheitsbedrohungen reagiert, indem es Abhilfemaßnahmen auslöst, wenn ein ungewöhnliches Muster im Netzwerkverkehr oder unbefugte Zugriffsversuche erkannt werden.",
        "Question": "Welche der folgenden Konfigurationen sollte das Unternehmen implementieren, um sicherzustellen, dass Sicherheitsvorfälle in Echtzeit erkannt und behoben werden?",
        "Options": {
            "1": "Verwenden Sie CloudWatch Logs, um Protokolle von EC2-Instanzen zu sammeln, und richten Sie CloudWatch Alarme ein, um Lambda-Funktionen für Abhilfemaßnahmen auszulösen, wenn bestimmte Muster in den Protokollen erkannt werden.",
            "2": "Verwenden Sie CloudWatch Metrics, um die Gesundheit von EC2-Instanzen zu überwachen, und konfigurieren Sie automatisches Scaling, wenn Sicherheitsgrenzen überschritten werden, ohne mit anderen AWS-Sicherheitsdiensten zu integrieren.",
            "3": "Richten Sie CloudWatch Events ein, um Protokolldaten von CloudTrail an ein externes SIEM (Security Information and Event Management)-System zur Echtzeitanalyse und automatisierten Behebung weiterzuleiten.",
            "4": "Aktivieren Sie CloudWatch Dashboards, um EC2-Metriken zu visualisieren und die Daten manuell auf Sicherheitsbedrohungen zu überprüfen, wobei bei Bedarf über Amazon SNS Warnungen ausgelöst werden."
        },
        "Correct Answer": "Verwenden Sie CloudWatch Logs, um Protokolle von EC2-Instanzen zu sammeln, und richten Sie CloudWatch Alarme ein, um Lambda-Funktionen für Abhilfemaßnahmen auszulösen, wenn bestimmte Muster in den Protokollen erkannt werden.",
        "Explanation": "Diese Option ist korrekt, da sie direkt auf die Notwendigkeit der Echtzeiterkennung und -behebung von Sicherheitsvorfällen eingeht. Durch die Verwendung von CloudWatch Logs zur Sammlung von Protokollen von EC2-Instanzen kann das Unternehmen nach spezifischen Mustern suchen, die potenzielle Sicherheitsbedrohungen anzeigen. Das Einrichten von CloudWatch Alarmen ermöglicht automatisierte Reaktionen über AWS Lambda-Funktionen, die vordefinierte Abhilfemaßnahmen sofort ausführen können, wenn eine Bedrohung erkannt wird. Diese Konfiguration stellt sicher, dass Sicherheitsvorfälle nicht nur in Echtzeit erkannt, sondern auch automatisch bearbeitet werden, was die allgemeine Sicherheitslage der AWS-Ressourcen verbessert.",
        "Other Options": [
            "Diese Option ist inkorrekt, da sie zwar die Verwendung von CloudWatch Logs und Alarmen vorschlägt, jedoch nicht die Verwendung von Lambda-Funktionen für automatisierte Abhilfemaßnahmen spezifiziert. Ohne Automatisierung wäre die Reaktion auf erkannte Bedrohungen nicht in Echtzeit, was für ein effektives Sicherheitsmanagement entscheidend ist.",
            "Diese Option ist inkorrekt, da sie sich auf die Überwachung der Gesundheit von EC2-Instanzen und automatisches Scaling konzentriert, was nicht direkt mit der Erkennung und Behebung von Sicherheitsbedrohungen zusammenhängt. Während die Überwachung der Instanzgesundheit wichtig ist, adressiert sie nicht die spezifische Notwendigkeit, auf Sicherheitsvorfälle wie ungewöhnlichen Netzwerkverkehr oder unbefugte Zugriffsversuche zu reagieren.",
            "Diese Option ist inkorrekt, da das Weiterleiten von Protokolldaten an ein externes SIEM-System zwar für die Analyse vorteilhaft sein kann, jedoch keinen direkten Mechanismus für Echtzeit-Abhilfemaßnahmen bietet. Die Abhängigkeit von einem externen System führt zu Verzögerungen in der Reaktionszeit, was für die sofortige Bedrohungsbewältigung nicht geeignet ist."
        ]
    },
    {
        "Question Number": "3",
        "Situation": "Ein Finanzdienstleistungsunternehmen muss sicherstellen, dass seine kritische Handelsanwendung im Falle einer Katastrophe innerhalb eines sehr kurzen Zeitrahmens wiederhergestellt und betriebsbereit ist. Um seinen betrieblichen Anforderungen gerecht zu werden, hat das Unternehmen ein Recovery Time Objective (RTO) von 15 Minuten festgelegt, was bedeutet, dass die Anwendung innerhalb dieser Zeit wieder online sein muss, wenn ein Ausfall auftritt.",
        "Question": "Welche Katastrophenwiederherstellungsstrategie würde am besten dieses RTO-Anforderung erfüllen?",
        "Options": {
            "1": "Backup und Restore, unter Verwendung eines nächtlichen Backups, das in Amazon S3 gespeichert ist und wiederhergestellt werden kann, um die Anwendung bei Bedarf wieder online zu bringen.",
            "2": "Pilot Light, wobei eine vorkonfigurierte Infrastruktur aufrechterhalten wird, die ausgeschaltet bleibt, aber schnell gestartet werden kann, um die Anwendung bei Bedarf wiederherzustellen.",
            "3": "Warm Standby, mit einer minimalen laufenden Version der Anwendung, die innerhalb des 15-minütigen RTO auf volle Produktionskapazität hochskaliert werden kann.",
            "4": "Multi-Site Active-Active-Setup, bei dem vollständig betriebsfähige Ressourcen an mehreren Standorten aufrechterhalten werden, um sofortigen Failover und null Ausfallzeiten zu gewährleisten."
        },
        "Correct Answer": "Multi-Site Active-Active-Setup, bei dem vollständig betriebsfähige Ressourcen an mehreren Standorten aufrechterhalten werden, um sofortigen Failover und null Ausfallzeiten zu gewährleisten.",
        "Explanation": "Das Multi-Site Active-Active-Setup ist die beste Katastrophenwiederherstellungsstrategie, um das 15-minütige Recovery Time Objective (RTO) zu erfüllen, da es sicherstellt, dass jederzeit vollständig betriebsfähige Ressourcen an mehreren Standorten verfügbar sind. Im Falle einer Katastrophe kann das System sofort auf einen anderen Standort umschalten, ohne dass Ausfallzeiten entstehen, und somit die strengen Anforderungen erfüllen, die Anwendung sofort wieder online zu haben. Dieses Setup bietet das höchste Maß an Verfügbarkeit und Resilienz, was es ideal für kritische Handelsanwendungen macht, die keine Verzögerungen tolerieren können.",
        "Other Options": [
            "Backup und Restore würden die 15-minütige RTO-Anforderung nicht erfüllen, da die Wiederherstellung von einem nächtlichen Backup erheblich länger als 15 Minuten dauern kann, insbesondere wenn das Backup groß ist oder wenn es während des Wiederherstellungsprozesses Probleme gibt.",
            "Pilot Light beinhaltet die Aufrechterhaltung einer minimalen Infrastruktur, die schnell gestartet werden kann, erfordert jedoch dennoch Zeit, um die erforderlichen Ressourcen bereitzustellen, und garantiert möglicherweise nicht, dass die Anwendung innerhalb des 15-minütigen RTO vollständig betriebsbereit ist.",
            "Warm Standby hält eine minimale Version der Anwendung aufrecht, die hochskaliert werden kann, aber das Hochskalieren auf volle Produktionskapazität kann länger als 15 Minuten dauern, insbesondere wenn es Ressourcenengpässe gibt oder wenn die Anwendung erhebliche Initialisierungszeit benötigt."
        ]
    },
    {
        "Question Number": "4",
        "Situation": "Eine Hochleistungsrechenanwendung (HPC), die auf Amazon EC2-Instanzen läuft, benötigt ultra-niedrige Latenz und die höchstmöglichen IOPS für temporäre Datenspeicherung. Die Daten müssen nicht behalten werden, wenn die Instanz gestoppt oder fehlerhaft ist, und die Kosten sind ein Hauptanliegen.",
        "Question": "Welche Speicheroption sollte der Lösungsarchitekt empfehlen?",
        "Options": {
            "1": "Amazon EBS General Purpose SSD (gp3)",
            "2": "Amazon EBS Provisioned IOPS SSD (io2)",
            "3": "Instance Store",
            "4": "Amazon S3 mit Transfer Acceleration"
        },
        "Correct Answer": "Instance Store",
        "Explanation": "Instance Store bietet die höchstmöglichen IOPS und ultra-niedrige Latenz, da es physisch mit dem Host-Server verbunden ist. Dies macht es ideal für Hochleistungsrechenanwendungen, die eine schnelle temporäre Datenspeicherung benötigen. Da die Daten nicht behalten werden müssen, wenn die Instanz gestoppt oder fehlerhaft ist, ist die Verwendung von Instance Store kosteneffektiv, da keine zusätzlichen Gebühren wie bei EBS-Volumes anfallen.",
        "Other Options": [
            "Amazon EBS General Purpose SSD (gp3) bietet eine gute Leistung und ist kosteneffektiv, bietet jedoch nicht das gleiche Maß an IOPS und Latenz wie Instance Store, was es weniger geeignet für HPC-Anwendungen macht, die ultra-niedrige Latenz erfordern.",
            "Amazon EBS Provisioned IOPS SSD (io2) bietet hohe IOPS und ist für Anwendungen konzipiert, die eine nachhaltige Leistung erfordern, ist jedoch teurer als Instance Store und nicht notwendig für temporäre Datenspeicherung, die nicht behalten werden muss.",
            "Amazon S3 mit Transfer Acceleration ist für den Hochgeschwindigkeitsdatenübertrag über das Internet konzipiert und nicht für ultra-niedrige Latenzanforderungen geeignet. Darüber hinaus ist S3 ein Objektspeicherdienst, der nicht für temporäre Datenspeicherung in HPC-Anwendungen geeignet ist, die schnellen Zugriff erfordern."
        ]
    },
    {
        "Question Number": "5",
        "Situation": "Ein E-Commerce-Unternehmen benötigt eine Katastrophenwiederherstellungslösung, um ihre Datenbank im Falle eines unerwarteten regionalen Ausfalls schnell wiederherzustellen. Sie erfordern minimale Ausfallzeiten und Datenverluste.",
        "Question": "Welchen AWS-Dienst und welche Strategie sollte das Unternehmen in Betracht ziehen, um ein niedriges Recovery Point Objective (RPO) und ein niedriges Recovery Time Objective (RTO) zu erreichen?",
        "Options": {
            "1": "Amazon RDS mit einer Multi-AZ-Bereitstellung und Cross-Region-Read-Replicas, da es automatischen Failover und Cross-Region-Replikation für eine schnelle Wiederherstellung mit minimalem Datenverlust bietet.",
            "2": "Amazon S3 mit aktivierter Versionierung, da es die Datensicherheit gewährleistet, indem mehrere Versionen jedes Objekts über Verfügbarkeitszonen hinweg aufbewahrt werden.",
            "3": "AWS Backup für regelmäßige Snapshots der Datenbank, da es eine Wiederherstellung zu einem bestimmten Zeitpunkt der Datenbank über mehrere Regionen hinweg ermöglicht.",
            "4": "Amazon EC2 Auto Scaling mit geplanten Backups, da es automatisiertes Scaling und periodische Datenwiederherstellung ermöglicht."
        },
        "Correct Answer": "Amazon RDS mit einer Multi-AZ-Bereitstellung und Cross-Region-Read-Replicas, da es automatischen Failover und Cross-Region-Replikation für eine schnelle Wiederherstellung mit minimalem Datenverlust bietet.",
        "Explanation": "Amazon RDS mit einer Multi-AZ-Bereitstellung ist für hohe Verfügbarkeit und Haltbarkeit konzipiert. In einem Multi-AZ-Setup repliziert RDS automatisch die Datenbank auf eine Standby-Instanz in einer anderen Verfügbarkeitszone, was einen automatischen Failover im Falle eines Ausfalls ermöglicht. Dieses Setup minimiert die Ausfallzeiten (niedriges RTO) und stellt sicher, dass die Daten kontinuierlich repliziert werden, wodurch ein niedriges Recovery Point Objective (RPO) erreicht wird. Darüber hinaus ermöglicht die Verwendung von Cross-Region-Read-Replicas eine weitere Datenredundanz und schnellere Wiederherstellung im Falle eines regionalen Ausfalls, was es zu einer idealen Lösung für die Anforderungen des Unternehmens macht.",
        "Other Options": [
            "Amazon S3 mit aktivierter Versionierung ist hauptsächlich für Objektspeicherung gedacht und bietet nicht die notwendigen Wiederherstellungsfähigkeiten für Datenbanken. Während es die Datensicherheit gewährleistet, indem mehrere Versionen von Objekten aufbewahrt werden, adressiert es nicht die Notwendigkeit für niedriges RPO und RTO für eine Datenbank.",
            "AWS Backup für regelmäßige Snapshots der Datenbank kann eine Wiederherstellung zu einem bestimmten Zeitpunkt ermöglichen, erfüllt jedoch möglicherweise nicht die Anforderungen an niedriges RPO und RTO so effektiv wie eine Multi-AZ-Bereitstellung mit Cross-Region-Read-Replicas. Snapshots können Zeit in Anspruch nehmen, um wiederhergestellt zu werden, was zu längeren Ausfallzeiten führen könnte.",
            "Amazon EC2 Auto Scaling mit geplanten Backups konzentriert sich auf das Scaling von EC2-Instanzen und bietet nicht von sich aus eine Katastrophenwiederherstellungslösung für Datenbanken. Geplante Backups bieten möglicherweise nicht den sofortigen Failover und das niedrige RPO/RTO, das das Unternehmen benötigt."
        ]
    },
    {
        "Question Number": "6",
        "Situation": "Ein Unternehmen betreibt eine Webanwendung auf Amazon RDS und möchte die Leseleistung der Anwendung verbessern, indem es Leseabfragen von der primären Datenbank entlastet. Das Unternehmen muss sicherstellen, dass die primäre Datenbank während der Spitzenverkehrszeiten nicht überlastet wird. Sie ziehen in Betracht, Lese-Replikate zu verwenden, um die erhöhte Leseauslastung zu bewältigen.",
        "Question": "Welche der folgenden Aussagen beschreibt am besten, wann das Unternehmen Lese-Replikate verwenden sollte?",
        "Options": {
            "1": "Verwenden Sie Lese-Replikate, wenn die Anwendung eine hohe Schreibdurchsatzrate erfordert und Schreibvorgänge über mehrere Regionen verteilt werden müssen.",
            "2": "Verwenden Sie Lese-Replikate, wenn die Anwendung eine hohe Anzahl von leseintensiven Abfragen hat und die Lesekapazität über mehrere Replikate skalieren muss.",
            "3": "Verwenden Sie Lese-Replikate, wenn die Anwendung unstrukturierte Daten wie Bilder oder Dokumente speichern muss und hohe Verfügbarkeit erfordert.",
            "4": "Verwenden Sie Lese-Replikate nur für Datenmigrationszwecke, nicht zur Verbesserung der Anwendungsleistung."
        },
        "Correct Answer": "Verwenden Sie Lese-Replikate, wenn die Anwendung eine hohe Anzahl von leseintensiven Abfragen hat und die Lesekapazität über mehrere Replikate skalieren muss.",
        "Explanation": "Lese-Replikate sind speziell dafür ausgelegt, den Leseverkehr von der primären Datenbank zu entlasten. Wenn eine Anwendung ein hohes Volumen an Leseabfragen erlebt, ermöglicht die Verwendung von Lese-Replikaten der Anwendung, diese Abfragen über mehrere Instanzen zu verteilen, wodurch die Leseleistung verbessert wird und sichergestellt wird, dass die primäre Datenbank während der Spitzenverkehrszeiten nicht überlastet wird. Diese Konfiguration verbessert die Skalierbarkeit und Reaktionsfähigkeit für leseintensive Arbeitslasten.",
        "Other Options": [
            "Verwenden Sie Lese-Replikate, wenn die Anwendung eine hohe Schreibdurchsatzrate erfordert und Schreibvorgänge über mehrere Regionen verteilt werden müssen. Dies ist falsch, da Lese-Replikate für Lesevorgänge gedacht sind, nicht für die Verteilung von Schreibvorgängen. Schreibvorgänge werden immer an die primäre Datenbank gerichtet.",
            "Verwenden Sie Lese-Replikate, wenn die Anwendung unstrukturierte Daten wie Bilder oder Dokumente speichern muss und hohe Verfügbarkeit erfordert. Dies ist falsch, da Lese-Replikate nicht zum Speichern unstrukturierter Daten verwendet werden; sie dienen dazu, die Leseleistung für strukturierte Daten in Datenbanken zu verbessern.",
            "Verwenden Sie Lese-Replikate nur für Datenmigrationszwecke, nicht zur Verbesserung der Anwendungsleistung. Dies ist falsch, da Lese-Replikate zwar während der Datenmigration verwendet werden können, ihr Hauptzweck jedoch darin besteht, die Anwendungsleistung zu verbessern, indem sie Leseabfragen verarbeiten, nicht nur für Migration."
        ]
    },
    {
        "Question Number": "7",
        "Situation": "Ein Medienproduktionsunternehmen benötigt leistungsstarken Speicher für die Videobearbeitung, möchte jedoch die Kosten niedrig halten. Sie haben eine Mischung aus hochleistungsfähigen und niedrigleistungsfähigen Arbeitslasten und müssen geeignete Blockspeichertypen auswählen.",
        "Question": "Welche Kombinationen von Blockspeicheroptionen sollte das Unternehmen verwenden, um die Kosten zu optimieren und gleichzeitig die Leistungsanforderungen zu erfüllen? (Wählen Sie zwei.)",
        "Options": {
            "1": "Provisioned IOPS SSD (io2) für alle Volumes",
            "2": "General Purpose SSD (gp3) für hochleistungsfähige Aufgaben und Throughput Optimized HDD (st1) für weniger leistungsstarke Aufgaben",
            "3": "Cold HDD (sc1) für alle Volumes",
            "4": "Verwenden Sie Amazon S3 anstelle von Blockspeicher für alle Daten",
            "5": "General Purpose SSD (gp3) für die meisten Arbeitslasten und Cold HDD (sc1) für Archivspeicherbedürfnisse"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Provisioned IOPS SSD (io2) für alle Volumes",
            "General Purpose SSD (gp3) für hochleistungsfähige Aufgaben und Throughput Optimized HDD (st1) für weniger leistungsstarke Aufgaben"
        ],
        "Explanation": "Provisioned IOPS SSD (io2) ist eine leistungsstarke Speicheroption, die schnellen, vorhersehbaren und konsistenten Durchsatz bietet, was sie für hochleistungsfähige Arbeitslasten wie Videobearbeitung geeignet macht. Sie ist jedoch teurer als andere Optionen. General Purpose SSD (gp3) bietet ein ausgewogenes Verhältnis von Preis und Leistung, was sie für eine Vielzahl von Arbeitslasten geeignet macht. Throughput Optimized HDD (st1) ist eine kostengünstige Option, die moderate Leistung bietet und sich somit für weniger anspruchsvolle Aufgaben eignet.",
        "Other Options": [
            "Cold HDD (sc1) für alle Volumes ist keine geeignete Option, da es für selten zugegriffene, langfristige und sequenzielle kalte Daten oder Archivspeicher konzipiert ist. Es bietet nicht die hohe Leistung, die für die Videobearbeitung erforderlich ist.",
            "Die Verwendung von Amazon S3 anstelle von Blockspeicher für alle Daten ist nicht ideal, da S3 ein Objektspeicherdienst ist, kein Blockspeicherdienst. Es ist nicht für hochleistungsfähige Arbeitslasten wie Videobearbeitung ausgelegt, die einen latenzarmen Zugriff auf Daten erfordern.",
            "General Purpose SSD (gp3) für die meisten Arbeitslasten und Cold HDD (sc1) für Archivspeicherbedürfnisse ist nicht die beste Option, da gp3 zwar für die meisten Arbeitslasten geeignet ist, sc1 jedoch nicht für hochleistungsfähige Aufgaben geeignet ist. Es ist für selten zugegriffene, langfristige und sequenzielle kalte Daten oder Archivspeicher konzipiert."
        ]
    },
    {
        "Question Number": "8",
        "Situation": "In einer großen Multi-VPC-Architektur haben Sie Schwierigkeiten, zahlreiche Punkt-zu-Punkt-Verbindungen aufrechtzuerhalten und die Netzwerkkomplexität zu erhöhen.",
        "Question": "Welche Lösung würde Ihre Netzwerkarchitektur am besten vereinfachen und gleichzeitig die Skalierbarkeit und Resilienz verbessern?",
        "Options": {
            "1": "Richten Sie eine VPN-Verbindung zwischen jedem Paar von VPCs ein, um die direkte Kommunikation sicherzustellen und die Sicherheit zu erhöhen.",
            "2": "Verwenden Sie AWS Direct Connect für jede VPC, damit jede unabhängig mit Ihrem lokalen Netzwerk verbunden werden kann.",
            "3": "Implementieren Sie ein Transit Gateway (TGW), um als zentrales Hub zu fungieren, das alle VPCs verbindet und die Notwendigkeit individueller Verbindungen reduziert.",
            "4": "Konfigurieren Sie eine Peering-Verbindung zwischen jeder VPC, um hohe Verfügbarkeit aufrechtzuerhalten und minimale Latenz über Verbindungen hinweg sicherzustellen."
        },
        "Correct Answer": "Implementieren Sie ein Transit Gateway (TGW), um als zentrales Hub zu fungieren, das alle VPCs verbindet und die Notwendigkeit individueller Verbindungen reduziert.",
        "Explanation": "Ein Transit Gateway (TGW) vereinfacht die Netzwerkarchitektur, indem es als zentrales Hub für die Verbindung mehrerer VPCs und lokaler Netzwerke fungiert. Dies reduziert die Komplexität der Verwaltung zahlreicher Punkt-zu-Punkt-Verbindungen, da alle VPCs über das TGW kommunizieren können. Es verbessert die Skalierbarkeit, da Sie problemlos weitere VPCs hinzufügen können, ohne neue Verbindungen für jedes Paar herstellen zu müssen. Darüber hinaus verbessert es die Resilienz, indem es einen einzigen Punkt für Verwaltung und Überwachung bereitstellt, was die Fehlersuche und Wartung erleichtert.",
        "Other Options": [
            "Das Einrichten einer VPN-Verbindung zwischen jedem Paar von VPCs würde ein komplexes Netz von Verbindungen schaffen, was zu erhöhtem Verwaltungsaufwand und potenziellen Leistungsengpässen führen könnte. Dieser Ansatz skaliert nicht gut, wenn die Anzahl der VPCs zunimmt.",
            "Die Verwendung von AWS Direct Connect für jede VPC ermöglicht unabhängige Verbindungen zu lokalen Netzwerken, adressiert jedoch nicht die Komplexität der inter-VPC-Kommunikation. Jede VPC müsste weiterhin ihre eigene Einrichtung und Verwaltung haben, was zu einer fragmentierten Netzwerkarchitektur führen kann.",
            "Das Konfigurieren einer Peering-Verbindung zwischen jeder VPC würde ebenfalls ein komplexes Mesh-Netzwerk schaffen. Während es niedrige Latenzverbindungen bieten kann, wird die Verwaltung zahlreicher Peering-Verbindungen umständlich, wenn die Anzahl der VPCs wächst, was es im Vergleich zu einem Transit Gateway weniger skalierbar macht."
        ]
    },
    {
        "Question Number": "9",
        "Situation": "Ein Gesundheitsunternehmen muss Patientendaten zur Sicherung in AWS für Notfallwiederherstellungszwecke sichern. Um die Kosten zu senken, benötigen sie eine Lösung, die die Speicherkosten minimiert und gleichzeitig eine langfristige Aufbewahrung der Backups gewährleistet. Sie möchten auch die Möglichkeit haben, Daten bei Bedarf innerhalb weniger Stunden abzurufen.",
        "Question": "Welche Backup-Strategie würde diese Anforderungen am besten erfüllen?",
        "Options": {
            "1": "Backups in Amazon S3 Standard speichern",
            "2": "Amazon S3 Glacier Flexible Retrieval für Archivspeicher verwenden",
            "3": "Backups in Amazon S3 Standard-IA speichern",
            "4": "Amazon EBS-Snapshots in derselben Region speichern"
        },
        "Correct Answer": "Amazon S3 Glacier Flexible Retrieval für Archivspeicher verwenden",
        "Explanation": "Amazon S3 Glacier Flexible Retrieval ist für die langfristige Datenarchivierung konzipiert und bietet eine kosteneffektive Lösung für die Speicherung von Daten, auf die selten zugegriffen wird. Es ermöglicht den Abruf von Daten innerhalb weniger Stunden, was mit der Anforderung des Gesundheitsunternehmens übereinstimmt, Backups zeitnah abzurufen. Diese Option minimiert die Speicherkosten und gewährleistet gleichzeitig, dass die Daten über längere Zeiträume aufbewahrt werden, was sie zur besten Wahl für Notfallwiederherstellungszwecke macht.",
        "Other Options": [
            "Backups in Amazon S3 Standard zu speichern, ist nicht kosteneffektiv für die langfristige Speicherung, da es für häufig zugegriffene Daten konzipiert ist. Diese Option würde im Vergleich zu Glacier für dieselbe Datenmenge über die Zeit höhere Kosten verursachen.",
            "Die Verwendung von Amazon S3 Glacier Flexible Retrieval für Archivspeicher ist die richtige Antwort, aber wenn wir die Option von S3 Glacier Deep Archive in Betracht ziehen, wäre es für die langfristige Speicherung noch günstiger. Allerdings erfüllt es nicht die Anforderung, Daten innerhalb weniger Stunden abzurufen, da die Abrufzeiten bis zu 12 Stunden dauern können.",
            "Backups in Amazon S3 Standard-IA (Infrequent Access) zu speichern, ist eine bessere Option als Standard, aber immer noch nicht so kosteneffektiv wie Glacier für die langfristige Speicherung. Während es für Daten geeignet ist, die seltener abgerufen werden, bietet es nicht dasselbe Maß an Kosteneinsparungen für die langfristige Aufbewahrung wie Glacier."
        ]
    },
    {
        "Question Number": "10",
        "Situation": "Ein SaaS-Unternehmen bietet eine Webanwendung an, die mit einer zentralen Amazon RDS für MySQL-Datenbank verbunden ist. Die Anwendung erlebt sporadische Verbindungsanstiege, die gelegentlich die maximal zulässigen Verbindungen in der Datenbank überschreiten.",
        "Question": "Welche Lösung sollte der Lösungsarchitekt implementieren, um Datenbankverbindungen effektiv zu verwalten und zu verhindern, dass das Verbindungslimit überschritten wird?",
        "Options": {
            "1": "Erhöhen Sie die maximale Anzahl der auf der Amazon RDS-Instanz zulässigen Verbindungen.",
            "2": "Setzen Sie ein Amazon ElastiCache-Cluster ein, um Datenbankabfragen zu verarbeiten und direkte Verbindungen zu reduzieren.",
            "3": "Implementieren Sie Amazon RDS Proxy, um Datenbankverbindungen effizient zu bündeln und zu teilen.",
            "4": "Verwenden Sie AWS Lambda-Funktionen, um Datenbankverbindungen dynamisch zu verwalten und zu verteilen."
        },
        "Correct Answer": "Implementieren Sie Amazon RDS Proxy, um Datenbankverbindungen effizient zu bündeln und zu teilen.",
        "Explanation": "Amazon RDS Proxy ist dafür konzipiert, Datenbankverbindungen effizient zu verwalten, indem es Verbindungen zwischen mehreren Anwendungsinstanzen bündelt und teilt. Dies hilft, die Anzahl der gleichzeitigen Verbindungen zur Datenbank zu reduzieren, was besonders nützlich ist, wenn die Anwendung Anstiege bei den Verbindungsanfragen erlebt. Durch die Verwendung von RDS Proxy kann die Anwendung eine kleinere Anzahl aktiver Verbindungen zur Datenbank aufrechterhalten, wodurch verhindert wird, dass das Verbindungslimit überschritten wird, und die Gesamtleistung und Zuverlässigkeit der Anwendung verbessert wird.",
        "Other Options": [
            "Die Erhöhung der maximal zulässigen Verbindungen auf der Amazon RDS-Instanz kann eine vorübergehende Lösung bieten, behebt jedoch nicht das zugrunde liegende Problem der Verbindungsanstiege. Dieser Ansatz kann zu einem höheren Ressourcenverbrauch führen und möglicherweise nicht nachhaltig sein, wenn die Anwendung weiterhin wächst.",
            "Das Bereitstellen eines Amazon ElastiCache-Clusters kann helfen, die Last auf der Datenbank zu reduzieren, indem häufig abgerufene Daten zwischengespeichert werden, verwaltet jedoch nicht direkt die Datenbankverbindungen. Während es die Leistung verbessern kann, indem die Anzahl der an die Datenbank gesendeten Abfragen reduziert wird, löst es nicht das Problem, das maximale Verbindungslimit zu überschreiten.",
            "Die Verwendung von AWS Lambda-Funktionen zur dynamischen Verwaltung und Verteilung von Datenbankverbindungen ist für dieses Szenario keine effektive Lösung. Lambda-Funktionen sind zustandslos und für ereignisgesteuerte Architekturen konzipiert, die möglicherweise nicht die erforderlichen Funktionen zur Verbindungspooling und -verwaltung bieten, die benötigt werden, um Anstiege bei den Datenbankverbindungen zu bewältigen."
        ]
    },
    {
        "Question Number": "11",
        "Situation": "Ein Unternehmen möchte eine Datenbanklösung auf AWS bereitstellen und möchte Flexibilität für benutzerdefinierte OS-Patches und Softwareinstallationen beibehalten, während es gleichzeitig von einem verwalteten Service für Backups und Skalierung profitiert. Es zieht Amazon RDS, RDS Custom und das Ausführen der Datenbank auf EC2 in Betracht.",
        "Question": "Welche Option entspricht am besten ihren Anforderungen an ein Gleichgewicht zwischen Kontrolle und verwalteten Services?",
        "Options": {
            "1": "Amazon RDS, da es eine vollständige Verwaltung durch AWS mit automatischen Backups und Skalierung bietet, jedoch eine eingeschränkte Anpassung von OS und Software ermöglicht.",
            "2": "RDS Custom, das es dem Unternehmen ermöglicht, benutzerdefinierte OS-Patches und Softwareinstallationen zu verwalten, während AWS Backups und Skalierung verwaltet.",
            "3": "EC2 mit einer selbstverwalteten Datenbank, die vollständige Kontrolle über OS und Software bietet, jedoch erfordert, dass das Unternehmen alle Verwaltungsaufgaben, einschließlich Backups, selbst übernimmt.",
            "4": "Amazon RDS mit Multi-AZ aktiviert, da es Verfügbarkeit und Backups ausbalanciert, jedoch keinen OS-Zugriff für Anpassungen ermöglicht."
        },
        "Correct Answer": "RDS Custom, das es dem Unternehmen ermöglicht, benutzerdefinierte OS-Patches und Softwareinstallationen zu verwalten, während AWS Backups und Skalierung verwaltet.",
        "Explanation": "RDS Custom ist speziell dafür konzipiert, die Flexibilität von benutzerdefinierten OS-Patches und Softwareinstallationen zu bieten, während es gleichzeitig von den verwalteten Services profitiert, die AWS anbietet, wie automatisierte Backups und Skalierung. Diese Option bietet das richtige Gleichgewicht zwischen Kontrolle und Verwaltung, sodass das Unternehmen seine Datenbankumgebung an seine spezifischen Bedürfnisse anpassen kann, ohne die Vorteile eines verwalteten Services zu opfern.",
        "Other Options": [
            "Amazon RDS bietet eine vollständige Verwaltung durch AWS, einschließlich automatischer Backups und Skalierung, erlaubt jedoch keine Anpassung des OS oder der Softwareinstallationen, was nicht den Anforderungen des Unternehmens an Flexibilität entspricht.",
            "EC2 mit einer selbstverwalteten Datenbank bietet vollständige Kontrolle über das Betriebssystem und die Software, erfordert jedoch, dass das Unternehmen alle Aspekte der Datenbank, einschließlich Backups und Skalierung, selbst verwaltet, was dem Wunsch nach einem verwalteten Service widerspricht.",
            "Amazon RDS mit Multi-AZ aktiviert verbessert die Verfügbarkeit und bietet automatisierte Backups, erlaubt jedoch, wie das Standard-RDS, keinen OS-Zugriff oder Anpassungen, was es für die Bedürfnisse des Unternehmens ungeeignet macht."
        ]
    },
    {
        "Question Number": "12",
        "Situation": "Ein Unternehmen mit mehreren AWS-Konten möchte einen zentralisierten Ansatz implementieren, um Sicherheit und Berechtigungen über alle Konten hinweg zu verwalten. Das Unternehmen verlangt, dass jedes Konto strengen Compliance-Richtlinien folgt, während es einzelnen Kontoadministratoren erlaubt ist, Benutzer innerhalb ihrer Konten zu verwalten.",
        "Question": "Welchen AWS-Service sollte das Unternehmen nutzen, um diese Anforderungen zu erfüllen?",
        "Options": {
            "1": "AWS IAM Identity Center (AWS Single Sign-On)",
            "2": "AWS Organizations mit Service Control Policies (SCPs)",
            "3": "AWS IAM mit rollenübergreifenden Berechtigungen",
            "4": "Amazon Cognito"
        },
        "Correct Answer": "AWS Organizations mit Service Control Policies (SCPs)",
        "Explanation": "AWS Organizations ermöglicht es Ihnen, mehrere AWS-Konten zentral zu verwalten und Richtlinien über diese Konten hinweg anzuwenden. Service Control Policies (SCPs) sind ein Feature von AWS Organizations, das es Ihnen ermöglicht, Berechtigungsrichtlinien für Ihre Konten festzulegen, um die Einhaltung strenger Richtlinien sicherzustellen, während es gleichzeitig einzelnen Kontoadministratoren erlaubt, Benutzer und Berechtigungen innerhalb ihrer eigenen Konten zu verwalten. Dieses Setup erfüllt die Anforderungen des Unternehmens an zentrale Verwaltung und Durchsetzung von Compliance über mehrere Konten.",
        "Other Options": [
            "AWS IAM Identity Center (AWS Single Sign-On) wird hauptsächlich zur Verwaltung des Benutzerzugriffs und der einmaligen Anmeldung über AWS-Konten und -Anwendungen verwendet. Während es bei der Benutzerverwaltung hilft, bietet es nicht die zentralisierte Durchsetzungsfähigkeit von Richtlinien, die AWS Organizations mit SCPs bietet.",
            "AWS IAM mit rollenübergreifenden Berechtigungen ermöglicht es, Berechtigungen über verschiedene AWS-Konten hinweg zu gewähren, bietet jedoch keinen zentralisierten Weg zur Durchsetzung von Compliance-Richtlinien über mehrere Konten. Jedes Konto müsste weiterhin seine eigenen IAM-Richtlinien verwalten, ohne die übergeordnete Kontrolle, die SCPs bieten.",
            "Amazon Cognito ist für die Benutzerauthentifizierung und -verwaltung für Web- und mobile Anwendungen konzipiert. Es ist nicht geeignet, um Berechtigungen und Compliance über mehrere AWS-Konten hinweg zu verwalten, da es sich auf die Benutzeridentität und nicht auf die Durchsetzung von Richtlinien auf Kontoebene konzentriert."
        ]
    },
    {
        "Question Number": "13",
        "Situation": "Ein E-Commerce-Unternehmen, ABC Online, hostet seine Website und APIs auf AWS mit Services wie CloudFront, Application Load Balancer (ALB), AppSync und API Gateway. Um sich gegen Bedrohungen wie SQL-Injection, Cross-Site-Scripting (XSS) und IP-basierte Angriffe zu schützen, möchte ABC Online eine Firewall-Lösung implementieren, die bösartigen Datenverkehr dynamisch blockieren kann, während legitimen Benutzern ununterbrochenen Zugriff gewährt wird. Sie ziehen in Betracht, AWS Web Application Firewall (WAF) zusammen mit Web Access Control Lists (Web ACLs) zu verwenden, um ihre Anwendungen über mehrere AWS-Services hinweg zu sichern. Das Sicherheitsteam möchte benutzerdefinierte Regeln konfigurieren und den Datenverkehr basierend auf spezifischen Kriterien steuern, um Angriffe zu verhindern, die ihre Anwendung und Kundendaten gefährden könnten.",
        "Question": "Welche der folgenden Aussagen beschreibt am besten, wie AWS Web Application Firewall (WAF) und Web ACLs funktionieren, um Anwendungen zu schützen, die auf AWS-Services wie CloudFront, ALB, AppSync und API Gateway bereitgestellt werden?",
        "Options": {
            "1": "AWS WAF wendet vordefinierte Regeln an, um automatisch allen eingehenden Datenverkehr ohne manuelle Anpassungen oder Updates zuzulassen oder abzulehnen, und bietet statischen Schutz gegen häufige Bedrohungen.",
            "2": "Web ACLs in AWS WAF bestehen aus Regeln und Regelgruppen, die auf spezifische Ressourcen wie CloudFront oder regionale Services angewendet werden können, um den Zugriff basierend auf definierten Kriterien wie IP-Reputation, SQL-Injection und Cross-Site-Scripting (XSS)-Angriffen zu steuern.",
            "3": "AWS WAF funktioniert, indem es Web ACLs verwendet, die nur den Datenverkehr blockieren, der von bestimmten IP-Adressen stammt, wodurch es nur für die Verhinderung von IP-basierten Angriffen wirksam ist.",
            "4": "Web ACLs sind nur mit CloudFront-Distributionen kompatibel und können nicht mit anderen AWS-Services wie ALB, AppSync oder API Gateway verwendet werden."
        },
        "Correct Answer": "Web ACLs in AWS WAF bestehen aus Regeln und Regelgruppen, die auf spezifische Ressourcen wie CloudFront oder regionale Services angewendet werden können, um den Zugriff basierend auf definierten Kriterien wie IP-Reputation, SQL-Injection und Cross-Site-Scripting (XSS)-Angriffen zu steuern.",
        "Explanation": "AWS WAF ermöglicht es Benutzern, Web Access Control Lists (Web ACLs) zu erstellen, die Regeln und Regelgruppen enthalten, um den Webverkehr zu filtern. Diese Regeln können angepasst werden, um spezifische Bedrohungen wie SQL-Injection und XSS zu zielen und können auf verschiedene AWS-Services angewendet werden, einschließlich CloudFront, ALB, AppSync und API Gateway. Diese Flexibilität ermöglicht es Organisationen, bösartigen Datenverkehr dynamisch zu blockieren, während legitimen Benutzern ununterbrochenen Zugriff gewährt wird, was für die Aufrechterhaltung der Anwendungssicherheit von entscheidender Bedeutung ist.",
        "Other Options": [
            "AWS WAF verlässt sich nicht ausschließlich auf vordefinierte Regeln; es ermöglicht die Erstellung benutzerdefinierter Regeln und erfordert manuelle Anpassungen, um sich an sich entwickelnde Bedrohungen anzupassen. Es bietet dynamischen Schutz statt statischen.",
            "AWS WAF ist nicht darauf beschränkt, nur den Datenverkehr von bestimmten IP-Adressen zu blockieren. Es kann den Datenverkehr basierend auf einer Vielzahl von Kriterien blockieren oder zulassen, einschließlich SQL-Injection und XSS, was es zu einer umfassenden Lösung für die Sicherheit von Webanwendungen macht.",
            "Web ACLs sind mit mehreren AWS-Services kompatibel, nicht nur mit CloudFront. Sie können auch auf Application Load Balancers, API Gateway und andere regionale Services angewendet werden, was einen einheitlichen Ansatz zur Sicherheit von Webanwendungen über verschiedene Plattformen hinweg bietet."
        ]
    },
    {
        "Question Number": "14",
        "Situation": "Ein Unternehmen möchte eine hochverfügbare relationale Datenbank auf AWS bereitstellen, die im Falle eines Ausfalls einer Availability Zone nahtlos umschalten kann. Es ist auch daran interessiert, Leseverkehr zu entlasten und Backups für die Notfallwiederherstellung aufrechtzuerhalten.",
        "Question": "Welche AWS RDS-Konfiguration sollten sie verwenden, um diese Anforderungen zu erfüllen?",
        "Options": {
            "1": "Konfigurieren Sie Amazon RDS mit Multi-AZ-Bereitstellungen für synchrone Replikation auf eine Standby-Instanz und erstellen Sie Lese-Replikate in verschiedenen Regionen für die Leseskalierung.",
            "2": "Verwenden Sie eine einzelne Amazon RDS-Instanz mit regelmäßigen EBS-Snapshots und konfigurieren Sie eine öffentliche Adressierung, um den Fernzugriff für Failover zu ermöglichen.",
            "3": "Richten Sie Amazon RDS mit Multi-AZ-Bereitstellungen und asynchroner Replikation für Lese-Replikate innerhalb derselben Availability Zone ein.",
            "4": "Bereitstellen von Amazon RDS mit regionaler Replikation, die ein Failover zu einer primären Instanz in einer anderen AWS-Region ermöglicht, wenn die Hauptinstanz ausfällt."
        },
        "Correct Answer": "Konfigurieren Sie Amazon RDS mit Multi-AZ-Bereitstellungen für synchrone Replikation auf eine Standby-Instanz und erstellen Sie Lese-Replikate in verschiedenen Regionen für die Leseskalierung.",
        "Explanation": "Diese Konfiguration erfüllt alle Anforderungen, die in der Situation skizziert sind. Multi-AZ-Bereitstellungen bieten hohe Verfügbarkeit, indem sie automatisch auf eine Standby-Instanz in einer anderen Availability Zone im Falle eines Ausfalls umschalten, was ein nahtloses Failover gewährleistet. Die synchrone Replikation stellt sicher, dass Daten konsistent auf die Standby-Instanz repliziert werden. Darüber hinaus ermöglicht das Erstellen von Lese-Replikaten in verschiedenen Regionen dem Unternehmen, Leseverkehr zu entlasten und Lesevorgänge zu skalieren, während auch Optionen für die Notfallwiederherstellung durch Backups bereitgestellt werden.",
        "Other Options": [
            "Die Verwendung einer einzelnen Amazon RDS-Instanz mit regelmäßigen EBS-Snapshots bietet keine hohe Verfügbarkeit oder nahtloses Failover, da sie auf manuelle Intervention für die Wiederherstellung angewiesen ist. Die öffentliche Adressierung verbessert die Verfügbarkeit nicht und kann die Datenbank Sicherheitsrisiken aussetzen.",
            "Die Einrichtung von Amazon RDS mit Multi-AZ-Bereitstellungen und asynchroner Replikation für Lese-Replikate innerhalb derselben Availability Zone bietet nicht die erforderliche hohe Verfügbarkeit und Failover-Fähigkeiten, da sie nicht die Vorteile von Multi-AZ für das Failover nutzt und nicht effektiv Leseverkehr entlastet.",
            "Die Bereitstellung von Amazon RDS mit regionaler Replikation ist für die angegebenen Anforderungen nicht notwendig, da sie die Einrichtung kompliziert und möglicherweise Latenz einführt. Der Schwerpunkt sollte auf Multi-AZ-Bereitstellungen für hohe Verfügbarkeit innerhalb derselben Region liegen, mit Lese-Replikaten für Skalierbarkeit."
        ]
    },
    {
        "Question Number": "15",
        "Situation": "Ein Unternehmen richtet eine CloudFront-Distribution ein, um Inhalte sicher über SSL bereitzustellen. Sie möchten einen alternativen Domainnamen verwenden und sichere Verbindungen von den Zuschauern zu CloudFront und dann von CloudFront zu ihren Ursprüngen, die einen S3-Bucket und einen Application Load Balancer (ALB) umfassen, sicherstellen.",
        "Question": "Welche Schritte müssen sie unternehmen, um sichere SSL-Verbindungen durchgehend zu gewährleisten?",
        "Options": {
            "1": "Konfigurieren Sie ein SSL-Zertifikat in CloudFront mit ACM in der Region, in der CloudFront bereitgestellt wird.",
            "2": "Konfigurieren Sie ein SSL-Zertifikat in ACM für den S3-Bucket, damit CloudFront den Bucket direkt mit HTTPS verwenden kann.",
            "3": "Verwenden Sie ein Zertifikat von ACM für den ALB und ein externes Zertifikat für alle benutzerdefinierten Ursprünge; selbstsignierte Zertifikate sind akzeptabel.",
            "4": "Konfigurieren Sie die SNI-Unterstützung in CloudFront, um mehrere HTTPS-Sites auf einer einzigen IP zu bedienen, und generieren Sie ein ACM-Zertifikat in us-east-1 für den alternativen Domainnamen."
        },
        "Correct Answer": "Konfigurieren Sie ein SSL-Zertifikat in CloudFront mit ACM in der Region, in der CloudFront bereitgestellt wird.",
        "Explanation": "Um sichere SSL-Verbindungen durchgehend zu gewährleisten, muss das Unternehmen ein SSL-Zertifikat in CloudFront mit AWS Certificate Manager (ACM) konfigurieren. Dieses Zertifikat wird verwendet, um die Verbindung zwischen Zuschauern und CloudFront zu verschlüsseln. Es ist wichtig zu beachten, dass CloudFront das SSL-Zertifikat in der Region US East (N. Virginia) (us-east-1) benötigt, damit es mit alternativen Domainnamen verwendet werden kann. Dieser Schritt stellt sicher, dass die von CloudFront bereitgestellten Inhalte sicher über HTTPS geliefert werden.",
        "Other Options": [
            "Die Konfiguration eines SSL-Zertifikats in ACM für den S3-Bucket ist nicht notwendig, da CloudFront Inhalte von S3 über HTTPS bereitstellen kann, ohne ein separates SSL-Zertifikat für den Bucket selbst zu benötigen. CloudFront übernimmt die SSL-Terminierung.",
            "Die Verwendung eines Zertifikats von ACM für den ALB und eines externen Zertifikats für alle benutzerdefinierten Ursprünge ist nicht die beste Praxis. Alle Ursprünge sollten idealerweise ACM-Zertifikate für Konsistenz und einfache Verwaltung verwenden. Selbstsignierte Zertifikate werden in Produktionsumgebungen aufgrund von Vertrauensproblemen im Allgemeinen nicht empfohlen.",
            "Die Konfiguration der SNI-Unterstützung in CloudFront ist für dieses Szenario nicht erforderlich. Während SNI (Server Name Indication) es ermöglicht, mehrere SSL-Zertifikate von einer einzigen IP-Adresse bereitzustellen, besteht die Hauptanforderung darin, das SSL-Zertifikat korrekt in ACM für CloudFront zu konfigurieren, das die SSL-Terminierung für den alternativen Domainnamen übernimmt."
        ]
    },
    {
        "Question Number": "16",
        "Situation": "Ein Unternehmen muss eine sichere und zuverlässige Verbindung zwischen seinem lokalen Rechenzentrum und seiner AWS-Umgebung herstellen, um auf sensible Daten zuzugreifen. Das Unternehmen benötigt eine niedrige Latenz, hohe Bandbreite und Verschlüsselung für Daten während der Übertragung.",
        "Question": "Welche Lösung würde diese Anforderungen am besten erfüllen?",
        "Options": {
            "1": "Richten Sie eine AWS Direct Connect-Verbindung mit einem VPN-Overlay ein, um Verschlüsselung und sichere Datenübertragung zwischen lokal und AWS bereitzustellen.",
            "2": "Konfigurieren Sie ein Standard-Internet-Gateway in der VPC und verwenden Sie IPsec-VPN-Tunnel, um Daten während der Übertragung zu verschlüsseln.",
            "3": "Verwenden Sie ein Internet-Gateway zusammen mit AWS Shield zum DDoS-Schutz und verlassen Sie sich auf HTTPS zur Verschlüsselung.",
            "4": "Stellen Sie eine VPC-Peering-Verbindung zwischen dem lokalen Rechenzentrum und der AWS VPC her, um eine sichere, latenzarme Kommunikation zu gewährleisten."
        },
        "Correct Answer": "Richten Sie eine AWS Direct Connect-Verbindung mit einem VPN-Overlay ein, um Verschlüsselung und sichere Datenübertragung zwischen lokal und AWS bereitzustellen.",
        "Explanation": "AWS Direct Connect bietet eine dedizierte Netzwerkverbindung vom lokalen Rechenzentrum zu AWS, die niedrige Latenz und hohe Bandbreite gewährleistet. Durch das Hinzufügen eines VPN-Overlays können die Daten während der Übertragung verschlüsselt werden, was den Anforderungen des Unternehmens an eine sichere Übertragung sensibler Daten entspricht. Diese Kombination bietet sowohl die Leistungs Vorteile von Direct Connect als auch die Sicherheit eines VPN, was es zur besten Lösung für das gegebene Szenario macht.",
        "Other Options": [
            "Die Konfiguration eines Standard-Internet-Gateways in der VPC und die Verwendung von IPsec-VPN-Tunneln würden zwar Verschlüsselung bieten, aber das Internet-Gateway ist auf das öffentliche Internet angewiesen, was im Vergleich zu einer dedizierten Verbindung wie Direct Connect zu höherer Latenz und weniger Zuverlässigkeit führen kann.",
            "Die Verwendung eines Internet-Gateways zusammen mit AWS Shield zum DDoS-Schutz und die Abhängigkeit von HTTPS zur Verschlüsselung erfüllen nicht die Anforderungen an niedrige Latenz und hohe Bandbreite. HTTPS eignet sich zur Sicherung von Daten während der Übertragung, aber die Abhängigkeit vom öffentlichen Internet kann zu variablen Leistungen führen, was für den Zugriff auf sensible Daten nicht ideal ist.",
            "Die Einrichtung einer VPC-Peering-Verbindung ist in diesem Kontext nicht anwendbar, da VPC-Peering verwendet wird, um zwei VPCs innerhalb von AWS zu verbinden, nicht um ein lokales Rechenzentrum mit AWS zu verbinden. Darüber hinaus bietet VPC-Peering keine Verschlüsselung oder eine dedizierte Verbindung, die für die Bedürfnisse des Unternehmens entscheidend sind."
        ]
    },
    {
        "Question Number": "17",
        "Situation": "Ein Unternehmen hat eine Anwendung auf Amazon EC2-Instanzen innerhalb eines privaten Subnetzes einer VPC bereitgestellt. Die Anwendung muss auf das Internet zugreifen, um Updates herunterzuladen und mit anderen öffentlichen Diensten zu kommunizieren, sollte jedoch nicht direkt vom Internet aus zugänglich sein.",
        "Question": "Welche Konfiguration sollte das Unternehmen verwenden, um diese Anforderungen zu erfüllen?",
        "Options": {
            "1": "Fügen Sie dem privaten Subnetz ein Internet-Gateway hinzu und konfigurieren Sie die EC2-Instanzen mit öffentlichen IPs für den ausgehenden Zugriff.",
            "2": "Stellen Sie ein NAT-Gateway in einem öffentlichen Subnetz bereit, verknüpfen Sie eine Routingtabelle mit dem privaten Subnetz, um den Datenverkehr 0.0.0.0/0 zum NAT-Gateway zu leiten, und stellen Sie sicher, dass das NAT-Gateway eine Elastic IP hat.",
            "3": "Verwenden Sie VPC-Peering, um das private Subnetz mit einer anderen VPC zu verbinden, die Internetzugang hat, und konfigurieren Sie das Routing zwischen den beiden VPCs.",
            "4": "Richten Sie eine VPN-Verbindung zwischen dem privaten Subnetz und einem lokalen Netzwerk mit Internetzugang ein, sodass EC2-Instanzen über das lokale Netzwerk für ausgehenden Datenverkehr routen können."
        },
        "Correct Answer": "Stellen Sie ein NAT-Gateway in einem öffentlichen Subnetz bereit, verknüpfen Sie eine Routingtabelle mit dem privaten Subnetz, um den Datenverkehr 0.0.0.0/0 zum NAT-Gateway zu leiten, und stellen Sie sicher, dass das NAT-Gateway eine Elastic IP hat.",
        "Explanation": "Ein NAT-Gateway ermöglicht es Instanzen in einem privaten Subnetz, ausgehenden Datenverkehr zum Internet zu initiieren, während eingehender Datenverkehr aus dem Internet verhindert wird. Durch die Bereitstellung eines NAT-Gateways in einem öffentlichen Subnetz und die Verknüpfung der Routingtabelle des privaten Subnetzes mit einer Route, die den Datenverkehr 0.0.0.0/0 zum NAT-Gateway leitet, können die EC2-Instanzen auf das Internet zugreifen, um Updates und Kommunikationen zu erhalten, ohne direkt vom Internet aus zugänglich zu sein. Die Elastic IP, die dem NAT-Gateway zugewiesen ist, bietet eine öffentliche IP für den ausgehenden Datenverkehr und gewährleistet eine ordnungsgemäße Internetkonnektivität.",
        "Other Options": [
            "Das Hinzufügen eines Internet-Gateways zum privaten Subnetz und die Konfiguration der EC2-Instanzen mit öffentlichen IPs würden die Instanzen direkt dem Internet aussetzen, was den Anforderungen widerspricht, nicht direkt vom Internet aus zugänglich zu sein.",
            "Die Verwendung von VPC-Peering zur Verbindung des privaten Subnetzes mit einer anderen VPC mit Internetzugang bietet keinen direkten Weg für die Instanzen des privaten Subnetzes, um auf das Internet zuzugreifen. VPC-Peering erleichtert den Internetzugang für private Subnetze nicht ohne zusätzliche Konfigurationen, wie z.B. NAT.",
            "Die Einrichtung einer VPN-Verbindung zwischen dem privaten Subnetz und einem lokalen Netzwerk mit Internetzugang würde die Architektur komplizieren und Latenz einführen. Es adressiert auch nicht direkt die Anforderung, dass die EC2-Instanzen auf das Internet zugreifen können, ohne exponiert zu sein, da es auf ein externes Netzwerk für den Internetzugang angewiesen ist."
        ]
    },
    {
        "Question Number": "18",
        "Situation": "Ein Finanzdienstleistungsunternehmen generiert und speichert täglich große Mengen an Kundendaten vor Ort. Aufgrund strenger regulatorischer und Compliance-Anforderungen müssen sie diese Daten lokal aufbewahren, möchten jedoch ältere, selten abgerufene Daten zu AWS auslagern, um Speicherplatzkosten zu sparen. Sie benötigen eine Lösung, die ihre aktuelle Speicherinfrastruktur nahtlos auf AWS erweitern kann, um den Zugriff auf archivierte Daten zu ermöglichen, ohne ihre bestehenden Anwendungen oder Arbeitsabläufe zu stören.",
        "Question": "Welcher AWS-Dienst würde die Anforderungen des Unternehmens am besten erfüllen? (Wählen Sie zwei.)",
        "Options": {
            "1": "Amazon S3 mit Lebenszyklusrichtlinien",
            "2": "AWS Direct Connect",
            "3": "AWS Storage Gateway",
            "4": "Amazon EBS Snapshot Export",
            "5": "Amazon Glacier Deep Archive mit Vault Lock"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon S3 mit Lebenszyklusrichtlinien",
            "AWS Storage Gateway"
        ],
        "Explanation": "Amazon S3 mit Lebenszyklusrichtlinien ist eine korrekte Antwort, da es die automatische Migration von Daten in verschiedene Speicherklassen basierend auf definierten Regeln ermöglicht, was dem Unternehmen helfen kann, bei selten abgerufenen Daten Speicherplatzkosten zu sparen. AWS Storage Gateway ist ebenfalls korrekt, da es eine nahtlose Verbindung zwischen lokalen Anwendungen und AWS-Speicher bietet. Es unterstützt Datei-, Volume- und Band-Speichertypen und kann verwendet werden, um Daten in S3, Glacier und EBS zu speichern, was es zu einer guten Lösung für die Anforderungen des Unternehmens macht.",
        "Other Options": [
            "AWS Direct Connect wird hauptsächlich verwendet, um eine dedizierte Netzwerkverbindung von Ihren Räumlichkeiten zu AWS herzustellen, nicht speziell für Speicher- oder Archivierungszwecke.",
            "Amazon EBS Snapshot Export ermöglicht es Ihnen, einen Amazon EBS-Snapshot in einen Amazon S3-Bucket zu exportieren, bietet jedoch keine nahtlose Erweiterung der lokalen Speicherinfrastruktur zu AWS.",
            "Amazon Glacier Deep Archive mit Vault Lock ist eine Speicherklasse für Datenarchivierung und langfristige Sicherung zu sehr niedrigen Kosten. Es bietet jedoch keine nahtlose Möglichkeit, den lokalen Speicher auf AWS zu erweitern, und die Datenabrufzeiten können bis zu 12 Stunden betragen, was möglicherweise nicht den Bedürfnissen des Unternehmens für den Zugriff auf archivierte Daten entspricht."
        ]
    },
    {
        "Question Number": "19",
        "Situation": "Ein Video-Streaming-Dienst erlebt unvorhersehbare Spitzen im Zuschauerverkehr, insbesondere während Live-Events. Der Dienst muss sicherstellen, dass er plötzliche Laststeigerungen ohne manuelles Eingreifen bewältigen kann, während die Kosten während der Nebenzeiten minimiert werden.",
        "Question": "Welche AWS-Funktion sollte der Lösungsarchitekt konfigurieren, um die Anzahl der EC2-Instanzen automatisch basierend auf den Verkehrsmustern anzupassen?",
        "Options": {
            "1": "AWS Elastic Beanstalk Skalierung",
            "2": "Amazon CloudWatch Alarme",
            "3": "Amazon EC2 Auto Scaling",
            "4": "AWS Lambda Auto-Skalierung"
        },
        "Correct Answer": "Amazon EC2 Auto Scaling",
        "Explanation": "Amazon EC2 Auto Scaling ist darauf ausgelegt, die Anzahl der EC2-Instanzen automatisch als Reaktion auf sich ändernde Verkehrsmuster anzupassen. Es kann während Spitzenzeiten skalieren (Instanzen hinzufügen) und während Nebenzeiten skalieren (Instanzen entfernen), ohne manuelles Eingreifen. Diese Funktion ist ideal, um unvorhersehbare Spitzen im Zuschauerverkehr, wie während Live-Events, zu bewältigen und gleichzeitig die Kosten in Zeiten geringer Nachfrage zu minimieren.",
        "Other Options": [
            "AWS Elastic Beanstalk Skalierung ist eine Funktion, die das Management von Anwendungen und deren Umgebungen, einschließlich Skalierung, ermöglicht, aber nicht so direkt auf das Management von EC2-Instanzen fokussiert ist wie EC2 Auto Scaling. Es eignet sich mehr für Anwendungen als für die rohe Instanzskalierung basierend auf Verkehrsmustern.",
            "Amazon CloudWatch Alarme können Metriken überwachen und Aktionen basierend auf Schwellenwerten auslösen, aber sie skalieren EC2-Instanzen nicht direkt. Sie können in Verbindung mit EC2 Auto Scaling verwendet werden, um Skalierungsaktionen auszulösen, führen jedoch die Skalierung selbst nicht durch.",
            "AWS Lambda Auto-Skalierung bezieht sich auf serverloses Computing und passt die Anzahl der Lambda-Funktionsinstanzen automatisch basierend auf der Anzahl der eingehenden Anfragen an. Es ist jedoch nicht anwendbar für die Skalierung von EC2-Instanzen, was die Anforderung in diesem Szenario ist."
        ]
    },
    {
        "Question Number": "20",
        "Situation": "Ein Unternehmen betreibt kritische Anwendungen auf Amazon EC2-Instanzen innerhalb der Region us-east-1, um kontinuierliche Verfügbarkeit und Resilienz sicherzustellen. Um eine hochverfügbare Architektur zu erreichen, müssen sie ihre EC2-Bereitstellung so gestalten, dass sie potenzielle Ausfälle auf verschiedenen Ebenen, wie z.B. einzelnen Hosts, Availability Zones (AZs) oder Instanzen, überstehen kann.",
        "Question": "Welche der folgenden Ansätze unterstützt am besten eine resiliente EC2-Architektur? (Wählen Sie zwei.)",
        "Options": {
            "1": "Stellen Sie EC2-Instanzen über mehrere Availability Zones innerhalb der Region bereit, um Fehlertoleranz und Redundanz im Falle eines AZ-Ausfalls zu gewährleisten.",
            "2": "Stellen Sie EC2-Instanzen in einer einzigen Availability Zone bereit, nutzen Sie jedoch EC2 Auto Scaling, um fehlgeschlagene Instanzen sofort zu ersetzen.",
            "3": "Platzieren Sie alle EC2-Instanzen in einem dedizierten Host innerhalb einer Availability Zone, um die Ressourcennutzung zu maximieren und das Management zu vereinfachen.",
            "4": "Konfigurieren Sie EC2-Instanzen nur mit Instance Store Volumes, um hohe Leistung sicherzustellen, und verlassen Sie sich auf Snapshots für die Haltbarkeit.",
            "5": "Verwenden Sie Elastic Load Balancing (ELB) in Verbindung mit Auto Scaling-Gruppen, die über mehrere Availability Zones verteilt sind, um den Datenverkehr zu verteilen und Instanzfehler nahtlos zu bewältigen."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Stellen Sie EC2-Instanzen über mehrere Availability Zones innerhalb der Region bereit, um Fehlertoleranz und Redundanz im Falle eines AZ-Ausfalls zu gewährleisten.",
            "Verwenden Sie Elastic Load Balancing (ELB) in Verbindung mit Auto Scaling-Gruppen, die über mehrere Availability Zones verteilt sind, um den Datenverkehr zu verteilen und Instanzfehler nahtlos zu bewältigen."
        ],
        "Explanation": "Die Bereitstellung von EC2-Instanzen über mehrere Availability Zones innerhalb der Region bietet Fehlertoleranz und Redundanz im Falle eines AZ-Ausfalls. Dies stellt sicher, dass die Anwendung auch dann verfügbar bleibt, wenn eine AZ ausfällt. Die Verwendung von Elastic Load Balancing (ELB) in Verbindung mit Auto Scaling-Gruppen, die über mehrere Availability Zones verteilt sind, ermöglicht die Verteilung des Datenverkehrs und die nahtlose Handhabung von Instanzfehlern. ELB sorgt dafür, dass der Datenverkehr gleichmäßig auf die Instanzen verteilt wird, und Auto Scaling stellt sicher, dass die Anzahl der Instanzen je nach Nachfrage skaliert, was hohe Verfügbarkeit und Fehlertoleranz bietet.",
        "Other Options": [
            "Die Bereitstellung von EC2-Instanzen in einer einzigen Availability Zone und die Nutzung von EC2 Auto Scaling zur sofortigen Ersetzung fehlgeschlagener Instanzen bieten keine Fehlertoleranz auf AZ-Ebene. Wenn die einzige AZ ausfällt, wird die gesamte Anwendung nicht verfügbar.",
            "Das Platzieren aller EC2-Instanzen in einem dedizierten Host innerhalb einer Availability Zone zur Maximierung der Ressourcennutzung und Vereinfachung des Managements bietet keine Fehlertoleranz auf AZ-Ebene. Wenn die einzige AZ ausfällt, wird die gesamte Anwendung nicht verfügbar.",
            "Die Konfiguration von EC2-Instanzen nur mit Instance Store Volumes zur Sicherstellung hoher Leistung und die Abhängigkeit von Snapshots für die Haltbarkeit bieten keine Fehlertoleranz auf AZ-Ebene. Instance Store Volumes sind flüchtig und Daten gehen verloren, wenn die Instanz gestoppt oder fehlerhaft ist, was diese Option weniger resilient macht."
        ]
    },
    {
        "Question Number": "21",
        "Situation": "Ein Startup baut eine Datenverarbeitungspipeline auf AWS, die Daten aus verschiedenen Quellen aufnimmt, verarbeitet und die Ergebnisse zur Analyse speichert. Die Pipeline muss mit spitzen Arbeitslasten umgehen können und sich automatisch basierend auf dem eingehenden Datenvolumen skalieren. Das Unternehmen möchte den operativen Aufwand für die Verwaltung von Servern minimieren.",
        "Question": "Welche Kombination von AWS-Diensten sollte der Lösungsarchitekt für diese Pipeline empfehlen? (Wählen Sie ZWEI aus.)",
        "Options": {
            "1": "Amazon EC2-Instanzen mit Auto Scaling",
            "2": "AWS Lambda",
            "3": "Amazon EMR",
            "4": "Amazon Kinesis Data Firehose",
            "5": "Amazon RDS"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "AWS Lambda",
            "Amazon Kinesis Data Firehose"
        ],
        "Explanation": "AWS Lambda ist ein serverloser Compute-Dienst, der Ihren Code als Reaktion auf Ereignisse ausführt und automatisch die zugrunde liegenden Compute-Ressourcen für Sie verwaltet, was den Anforderungen des Unternehmens entspricht, den operativen Aufwand zu minimieren. Es kann sich auch automatisch basierend auf dem eingehenden Datenvolumen skalieren, was ideal ist, um spitze Arbeitslasten zu bewältigen. Amazon Kinesis Data Firehose ist der einfachste Weg, um Streaming-Daten zuverlässig in Datenseen, Datenspeichern und Analysediensten zu laden. Es kann Streaming-Daten in AWS-Dienste wie Amazon S3, Amazon Redshift, Amazon Elasticsearch Service und Splunk erfassen, transformieren und laden, was nahezu Echtzeitanalysen mit vorhandenen Business-Intelligence-Tools und Dashboards ermöglicht.",
        "Other Options": [
            "Amazon EC2-Instanzen mit Auto Scaling: Während EC2-Instanzen mit Auto Scaling spitze Arbeitslasten bewältigen und basierend auf dem eingehenden Datenvolumen skalieren können, minimiert es nicht den operativen Aufwand für die Verwaltung von Servern, da das Unternehmen weiterhin die EC2-Instanzen verwalten müsste.",
            "Amazon EMR: Amazon EMR ist eine cloud-native Big-Data-Plattform, die die Verarbeitung großer Datenmengen schnell und kosteneffektiv im großen Maßstab mit beliebten verteilten Frameworks wie Apache Spark und Hadoop ermöglicht. Es erfordert jedoch die Verwaltung von Serverclustern, was nicht mit den Anforderungen des Unternehmens übereinstimmt, den operativen Aufwand zu minimieren.",
            "Amazon RDS: Amazon RDS ist ein relationaler Datenbankdienst, der nicht mit den Anforderungen einer Datenverarbeitungspipeline übereinstimmt, die spitze Arbeitslasten bewältigen und sich automatisch basierend auf dem eingehenden Datenvolumen skalieren muss."
        ]
    },
    {
        "Question Number": "22",
        "Situation": "Eine Video-Streaming-Plattform erlebt unvorhersehbare Verkehrsspitzen, insbesondere während Live-Events, die Millionen von Zuschauern anziehen. Um die Leistung aufrechtzuerhalten und Unterbrechungen zu vermeiden, muss die Plattform ihre Compute-Kapazität schnell und effizient skalieren. Die Streaming-Anwendung läuft derzeit auf Amazon EC2-Instanzen in mehreren Verfügbarkeitszonen, und das Team möchte sicherstellen, dass diese Instanzen automatisch basierend auf der Nachfrage bereitgestellt werden, insbesondere während unerwarteter Verkehrsspitzen, um eine Leistungsverschlechterung zu verhindern.",
        "Question": "Welche Konfiguration sollte der Lösungsarchitekt implementieren, um diese Anforderungen zu erfüllen? (Wählen Sie zwei aus.)",
        "Options": {
            "1": "Eine feste Anzahl von EC2-Instanzen in allen Verfügbarkeitszonen festlegen, um Spitzenlasten zu bewältigen",
            "2": "Eine Auto Scaling-Gruppe verwenden, die mit dynamischen Skalierungsrichtlinien basierend auf Metriken wie CPU-Auslastung konfiguriert ist, um automatisch hoch- und herunterzuskalieren, wenn die Nachfrage schwankt",
            "3": "Verkehrsmuster manuell überwachen und EC2-Instanzen nach Bedarf während hochfrequentierter Ereignisse hinzufügen",
            "4": "Die Website-Inhalte auf Amazon S3 hosten und die Notwendigkeit von EC2-Instanzen zur Handhabung des Website-Verkehrs beseitigen",
            "5": "Prädiktives Scaling mit Amazon CloudWatch implementieren, um Verkehrsspitzen vorherzusehen und die Kapazität proaktiv anzupassen"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Eine Auto Scaling-Gruppe verwenden, die mit dynamischen Skalierungsrichtlinien basierend auf Metriken wie CPU-Auslastung konfiguriert ist, um automatisch hoch- und herunterzuskalieren, wenn die Nachfrage schwankt",
            "Prädiktives Scaling mit Amazon CloudWatch implementieren, um Verkehrsspitzen vorherzusehen und die Kapazität proaktiv anzupassen"
        ],
        "Explanation": "Auto Scaling-Gruppen in AWS ermöglichen die dynamische Skalierung von EC2-Instanzen basierend auf der Nachfrage. Das bedeutet, dass bei steigender Nachfrage mehr Instanzen bereitgestellt werden können, um die Last zu bewältigen, und bei sinkender Nachfrage Instanzen beendet werden können, um Kosten zu sparen. Dies ist ideal, um unvorhersehbare Verkehrsspitzen zu bewältigen. Prädiktives Scaling in Amazon CloudWatch verwendet maschinelles Lernen, um zukünftige Nachfrage vorherzusagen und die Kapazität im Voraus anzupassen. Dies ist nützlich, um Verkehrsspitzen vorherzusehen und proaktiv zu skalieren, um der Nachfrage gerecht zu werden.",
        "Other Options": [
            "Eine feste Anzahl von EC2-Instanzen in allen Verfügbarkeitszonen festzulegen, um Spitzenlasten zu bewältigen, ist keine effiziente Lösung. Es berücksichtigt keine Schwankungen in der Nachfrage und kann zu Überprovisionierung (Ressourcenverschwendung bei niedriger Nachfrage) oder Unterprovisionierung (nicht genügend Ressourcen bei hoher Nachfrage) führen.",
            "Verkehrsmuster manuell zu überwachen und EC2-Instanzen nach Bedarf während hochfrequentierter Ereignisse hinzuzufügen, ist keine skalierbare oder effiziente Lösung. Es erfordert ständige Überwachung und manuelles Eingreifen, und es kann Verzögerungen beim Hochskalieren geben, die die Leistung beeinträchtigen könnten.",
            "Die Website-Inhalte auf Amazon S3 zu hosten und die Notwendigkeit von EC2-Instanzen zur Handhabung des Website-Verkehrs zu beseitigen, ist keine geeignete Lösung für eine Video-Streaming-Plattform. Während S3 großartig für das Hosting statischer Websites ist, erfordert eine Video-Streaming-Plattform die Bereitstellung dynamischer Inhalte und Compute-Kapazität, die besser von EC2-Instanzen gehandhabt werden."
        ]
    },
    {
        "Question Number": "23",
        "Situation": "Ein Unternehmen erwägt AWS Direct Connect, um die Konsistenz und Geschwindigkeit der Netzwerkverbindung zwischen ihrem lokalen Rechenzentrum und AWS zu verbessern.",
        "Question": "Welche der folgenden Aussagen beschreibt genau einen Vorteil und eine Einschränkung der Verwendung von AWS Direct Connect zu diesem Zweck?",
        "Options": {
            "1": "AWS Direct Connect bietet sichere Datenübertragung über eine private, dedizierte Leitung mit integrierter Resilienz; jedoch ist es auf eine Bandbreite von 1 Gbps pro Verbindung beschränkt.",
            "2": "AWS Direct Connect kann sowohl Hochgeschwindigkeits- als auch latenzarme Konnektivität direkt zu AWS-öffentlichen und -privaten Diensten ohne Internetabhängigkeit bieten; jedoch bietet es nicht von sich aus Resilienz, da es auf physische Kabel angewiesen ist, die von Ausfällen betroffen sein können.",
            "3": "AWS Direct Connect bietet resiliente Hochgeschwindigkeitsdatenübertragung zwischen AWS und lokalen Umgebungen, mit der Option für automatisches Failover; jedoch ist es nur in ausgewählten AWS-Regionen weltweit verfügbar.",
            "4": "AWS Direct Connect bietet eine kosteneffektive Lösung für internetbasierte Datenübertragung, die es ermöglicht, Daten über AWS-öffentliche Endpunkte zu leiten; jedoch kann es aufgrund der gemeinsamen Infrastruktur höhere Latenz als VPN-basierte Lösungen aufweisen."
        },
        "Correct Answer": "AWS Direct Connect kann sowohl Hochgeschwindigkeits- als auch latenzarme Konnektivität direkt zu AWS-öffentlichen und -privaten Diensten ohne Internetabhängigkeit bieten; jedoch bietet es nicht von sich aus Resilienz, da es auf physische Kabel angewiesen ist, die von Ausfällen betroffen sein können.",
        "Explanation": "AWS Direct Connect ist darauf ausgelegt, Hochgeschwindigkeits- und latenzarme Verbindungen zu AWS-Diensten anzubieten, indem das öffentliche Internet umgangen wird, was die Leistung und Zuverlässigkeit verbessert. Während es eine dedizierte Verbindung bietet, beinhaltet es nicht automatisch Redundanz oder Resilienz; wenn die physische Verbindung unterbrochen wird, kann dies zu Ausfällen führen. Daher müssen Benutzer zusätzliche Maßnahmen ergreifen, wie z.B. die Verwendung mehrerer Verbindungen oder Failover-Strategien, um Resilienz sicherzustellen.",
        "Other Options": [
            "Während AWS Direct Connect sichere Datenübertragung über eine private Leitung bietet, hat es keine strikte Einschränkung von 1 Gbps Bandbreite pro Verbindung. AWS Direct Connect bietet mehrere Verbindungsgeschwindigkeiten, einschließlich 10 Gbps und höher, je nach den Anforderungen.",
            "AWS Direct Connect bietet Optionen für Resilienz, wie die Möglichkeit, redundante Verbindungen an verschiedenen Standorten zu erstellen. Darüber hinaus ist es in vielen AWS-Regionen verfügbar, nicht nur in ausgewählten, was die Zugänglichkeit erhöht.",
            "AWS Direct Connect ist keine internetbasierte Lösung; es bietet eine dedizierte Verbindung, die typischerweise zu geringerer Latenz im Vergleich zu VPN-Lösungen führt. Es leitet Daten nicht über öffentliche Endpunkte, was einen wesentlichen Vorteil der Nutzung von Direct Connect darstellt."
        ]
    },
    {
        "Question Number": "24",
        "Situation": "Ein multinationales Unternehmen plant die Bereitstellung einer neuen kundenorientierten Anwendung auf AWS, die Benutzer in Nordamerika, Europa und Asien bedienen wird. Um die Anwendungsleistung zu optimieren und die Vorschriften zur Datenresidenz in jeder Region einzuhalten, möchte das Unternehmen sicherstellen, dass Benutzerdaten sowohl verarbeitet als auch in der Nähe der geografischen Standorte der Benutzer gespeichert werden. Darüber hinaus möchten sie die Latenz minimieren, indem sie die Benutzerbasis jeder Region mit der nächstgelegenen Infrastruktur bedienen.",
        "Question": "Was ist die geeignetste Strategie für die Bereitstellung dieser Anwendung?",
        "Options": {
            "1": "Die Anwendung in einer einzigen AWS-Region mit Hochkapazitätsinstanzen bereitstellen und die Ressourcen der Region nutzen, um alle globalen Benutzer von einem zentralen Standort aus zu bedienen",
            "2": "Die Anwendung über mehrere AWS-Regionen bereitstellen und sicherstellen, dass jede Region über lokale Infrastruktur verfügt, um ihre Benutzerbasis zu bedienen und die Anforderungen an die Datenresidenz zu erfüllen",
            "3": "Die Anwendung in einer zentralen AWS-Region bereitstellen und dann ein Content Delivery Network (CDN) verwenden, um Daten in anderen Regionen zwischenzuspeichern und die Zugriffszeiten zu verbessern",
            "4": "Verfügbarkeitszonen innerhalb einer einzigen AWS-Region verwenden, um globale Benutzer zu bedienen und Redundanz zu gewährleisten, ohne über mehrere Regionen zu deployen"
        },
        "Correct Answer": "Die Anwendung über mehrere AWS-Regionen bereitstellen und sicherstellen, dass jede Region über lokale Infrastruktur verfügt, um ihre Benutzerbasis zu bedienen und die Anforderungen an die Datenresidenz zu erfüllen",
        "Explanation": "Die Bereitstellung der Anwendung über mehrere AWS-Regionen ermöglicht es dem Unternehmen, die Verarbeitung und Speicherung von Benutzerdaten in der Nähe der Benutzer in Nordamerika, Europa und Asien zu platzieren. Diese Strategie optimiert nicht nur die Anwendungsleistung, indem sie die Latenz für Benutzer, die auf die Anwendung zugreifen, reduziert, sondern stellt auch die Einhaltung der Vorschriften zur Datenresidenz sicher, die vorschreiben, dass Daten innerhalb bestimmter geografischer Standorte gespeichert werden müssen. Durch die lokale Infrastruktur in jeder Region kann das Unternehmen seine Benutzerbasis effektiv bedienen und gleichzeitig rechtlichen Anforderungen nachkommen.",
        "Other Options": [
            "Die Anwendung in einer einzigen AWS-Region mit Hochkapazitätsinstanzen bereitzustellen, würde einen zentralen Ausfallpunkt schaffen und die Latenz für Benutzer erhöhen, die weit von dieser Region entfernt sind. Dieser Ansatz berücksichtigt nicht die Vorschriften zur Datenresidenz, die vorschreiben können, dass Daten an bestimmten geografischen Standorten gespeichert werden müssen.",
            "Die Verwendung eines Content Delivery Networks (CDN), um Daten in anderen Regionen zwischenzuspeichern, kann die Zugriffszeiten für statische Inhalte verbessern, löst jedoch nicht das Problem der Datenresidenz und der Verarbeitungsanforderungen. Die dynamische Datenverarbeitung und -speicherung muss weiterhin in den entsprechenden Regionen erfolgen, um den Vorschriften zu entsprechen.",
            "Die Verwendung von Verfügbarkeitszonen innerhalb einer einzigen AWS-Region bietet Redundanz und hohe Verfügbarkeit, adressiert jedoch nicht die Notwendigkeit einer geografischen Verteilung. Diese Option würde immer noch zu einer erhöhten Latenz für Benutzer führen, die weit von dieser einzigen Region entfernt sind, und würde die Anforderungen an die Datenresidenz nicht erfüllen."
        ]
    },
    {
        "Question Number": "25",
        "Situation": "Eine Gesundheitsorganisation sucht nach einer umfassenden Backup-Lösung für sensible Patientendaten, die über mehrere AWS-Dienste verteilt sind, einschließlich Amazon EC2-Instanzen, RDS-Datenbanken und EFS-Dateisystemen. Sie benötigen eine Lösung, die Backups über mehrere AWS-Konten und -Regionen verwalten kann, die Datenintegrität mit Write-Once, Read-Many (WORM)-Compliance gewährleistet, um versehentliche Änderungen zu verhindern, und eine Wiederherstellung zu einem bestimmten Zeitpunkt bietet, um regulatorische und betriebliche Anforderungen an den Schutz kritischer Daten zu erfüllen.",
        "Question": "Welche AWS-Dienstkonfiguration würde diese Anforderungen am besten erfüllen?",
        "Options": {
            "1": "Manuelle Snapshots für jede Ressource einrichten und die Replikation über Regionen hinweg aktivieren, um zusätzliche Redundanz zu gewährleisten",
            "2": "AWS Backup mit Backup-Plänen, Vault Lock für WORM-Compliance und Point-in-Time Recovery (PITR) für zuverlässige Backups und Wiederherstellungen verwenden",
            "3": "Backups in Amazon S3 mit aktivierter Versionierung und Replikation speichern, um Datenintegrität und Verfügbarkeit über Regionen hinweg sicherzustellen",
            "4": "AWS CloudTrail für das Logging aktivieren und manuelle Wiederherstellungsverfahren basierend auf Protokolldaten erstellen"
        },
        "Correct Answer": "AWS Backup mit Backup-Plänen, Vault Lock für WORM-Compliance und Point-in-Time Recovery (PITR) für zuverlässige Backups und Wiederherstellungen verwenden",
        "Explanation": "AWS Backup ist speziell dafür konzipiert, die Sicherung von AWS-Ressourcen über mehrere Konten und Regionen hinweg zu zentralisieren und zu automatisieren. Es ermöglicht Benutzern, Backup-Pläne zu erstellen, die die Backup-Häufigkeit und Aufbewahrungsrichtlinien definieren. Darüber hinaus unterstützt AWS Backup Vault Lock, das WORM-Compliance bietet, um versehentliche Änderungen an Backup-Daten zu verhindern und die Datenintegrität zu gewährleisten. Die Funktion Point-in-Time Recovery (PITR) ermöglicht die Wiederherstellung von Daten zu einem bestimmten Zeitpunkt, was entscheidend ist, um regulatorische und betriebliche Anforderungen an den Schutz kritischer Daten zu erfüllen.",
        "Other Options": [
            "Manuelle Snapshots für jede Ressource einzurichten und die Replikation über Regionen hinweg zu aktivieren, kann ein gewisses Maß an Redundanz bieten, aber es fehlt an Automatisierung und zentraler Verwaltung. Dieser Ansatz ist arbeitsintensiv und gewährleistet nicht die WORM-Compliance oder die Wiederherstellung zu einem bestimmten Zeitpunkt, was ihn weniger geeignet für die umfassenden Backup-Bedürfnisse der Organisation macht.",
            "Backups in Amazon S3 mit aktivierter Versionierung und Replikation zu speichern, kann zur Datenintegrität und Verfügbarkeit beitragen, bietet jedoch nicht die erforderlichen Verwaltungsfunktionen für Backups über mehrere AWS-Dienste oder -Konten hinweg. Darüber hinaus bietet es nicht von sich aus WORM-Compliance oder Point-in-Time Recovery, die für sensible Patientendaten entscheidend sind.",
            "AWS CloudTrail für das Logging zu aktivieren und manuelle Wiederherstellungsverfahren basierend auf Protokolldaten zu erstellen, ist keine Backup-Lösung. CloudTrail dient hauptsächlich der Prüfung und Überwachung von API-Aufrufen, und während es helfen kann, Änderungen an Ressourcen zu verstehen, bietet es keinen Mechanismus zum Sichern oder Wiederherstellen von Daten und erfüllt nicht die Anforderungen an WORM-Compliance oder Point-in-Time Recovery."
        ]
    },
    {
        "Question Number": "26",
        "Situation": "Ein Technologieunternehmen konfiguriert eine Auto Scaling-Gruppe für seine EC2-Instanzen. Sie möchten ein Setup implementieren, das Konfigurationsupdates ermöglicht, ohne die gesamte Infrastruktur jedes Mal neu erstellen zu müssen, wenn eine Änderung erforderlich ist.",
        "Question": "Welche Option sollte das Unternehmen wählen, um Konfigurationsupdates effizient zu erleichtern, und was ist die Begründung für diese Wahl?",
        "Options": {
            "1": "Nutzen Sie Launch Configurations, da sie Versionierung unterstützen und Updates ohne Neuschaffung ermöglichen.",
            "2": "Verwenden Sie Launch Templates, da sie Versionierungsfunktionen bieten, die Konfigurationsupdates ohne Erstellung neuer Templates ermöglichen.",
            "3": "Wählen Sie Launch Configurations wegen ihrer einfachen Verwaltung und der integrierten Versionierungsfunktionen.",
            "4": "Entscheiden Sie sich für Launch Templates, die Live-Updates direkt innerhalb der Auto Scaling-Gruppe ermöglichen, ohne dass eine Versionskontrolle erforderlich ist."
        },
        "Correct Answer": "Verwenden Sie Launch Templates, da sie Versionierungsfunktionen bieten, die Konfigurationsupdates ohne Erstellung neuer Templates ermöglichen.",
        "Explanation": "Launch Templates sind die bevorzugte Wahl zur Konfiguration von Auto Scaling-Gruppen, da sie Versionierung unterstützen, was es den Benutzern ermöglicht, mehrere Versionen eines Templates zu erstellen. Das bedeutet, dass das Unternehmen bei erforderlichen Konfigurationsänderungen einfach eine neue Version des bestehenden Templates erstellen kann, ohne die gesamte Infrastruktur neu erstellen zu müssen. Diese Funktion vereinfacht den Prozess der Aktualisierung von Konfigurationen und verbessert die Verwaltungseffizienz, was es einfacher macht, bei Bedarf auf frühere Versionen zurückzugreifen.",
        "Other Options": [
            "Nutzen Sie Launch Configurations, da sie Versionierung unterstützen und Updates ohne Neuschaffung ermöglichen. (Falsch, da Launch Configurations keine Versionierung unterstützen; sie sind statisch und können nach der Erstellung nicht aktualisiert werden. Jede Änderung erfordert die Erstellung einer neuen Launch Configuration.)",
            "Wählen Sie Launch Configurations wegen ihrer einfachen Verwaltung und der integrierten Versionierungsfunktionen. (Falsch, da Launch Configurations keine Versionierungsfunktionen bieten, was sie weniger flexibel für Konfigurationsupdates im Vergleich zu Launch Templates macht.)",
            "Entscheiden Sie sich für Launch Templates, die Live-Updates direkt innerhalb der Auto Scaling-Gruppe ermöglichen, ohne dass eine Versionskontrolle erforderlich ist. (Falsch, da Launch Templates zwar Versionierung ermöglichen, jedoch keine Live-Updates direkt innerhalb der Auto Scaling-Gruppe erlauben; Updates erfordern weiterhin die Erstellung einer neuen Version des Templates.)"
        ]
    },
    {
        "Question Number": "27",
        "Situation": "Ein Forschungsteam führt hochkomplexe wissenschaftliche Modellierungssimulationen durch, die eine extrem hohe CPU-Leistung und schnelle Verarbeitungsgeschwindigkeiten erfordern, um genaue Ergebnisse schnell zu generieren. Diese Simulationen sind rechenintensiv und umfassen Aufgaben wie Medienkodierung, numerische Strömungsmechanik und allgemeines Training von Maschinenlernmodellen. Das Team benötigt keine hohe Speicherkapazität oder GPU-Unterstützung, da diese Aufgaben hauptsächlich CPU-gebunden sind.",
        "Question": "Welche EC2-Instanzkategorie würde am besten zu ihren Bedürfnissen passen?",
        "Options": {
            "1": "Allzweck",
            "2": "Speicheroptimiert",
            "3": "Rechenoptimiert",
            "4": "Beschleunigtes Rechnen"
        },
        "Correct Answer": "Rechenoptimiert",
        "Explanation": "Die Kategorie der rechenoptimierten EC2-Instanzen ist speziell für rechenintensive Aufgaben konzipiert, die eine hohe CPU-Leistung erfordern. Da die Simulationen des Forschungsteams CPU-gebunden sind und keine hohe Speicherkapazität oder GPU-Unterstützung benötigen, bieten rechenoptimierte Instanzen die notwendige Verarbeitungsleistung und Geschwindigkeit, um Aufgaben wie Medienkodierung, numerische Strömungsmechanik und Training von Maschinenlernmodellen effizient zu bewältigen. Diese Instanzen sind ideal für Workloads, die eine hohe Rechenkapazität erfordern und die Zeit zur Generierung genauer Ergebnisse erheblich reduzieren können.",
        "Other Options": [
            "Allzweckinstanzen bieten ein Gleichgewicht zwischen Rechen-, Speicher- und Netzwerkressourcen, was sie für eine Vielzahl von Workloads geeignet macht, jedoch nicht speziell für rechenintensive Aufgaben optimiert ist. Sie liefern möglicherweise nicht die hohe CPU-Leistung, die für die beschriebenen Simulationen erforderlich ist.",
            "Speicheroptimierte Instanzen sind für Workloads konzipiert, die eine hohe Speicherkapazität und Durchsatz erfordern, wie z. B. In-Memory-Datenbanken und Echtzeitanalysen großer Datenmengen. Da das Forschungsteam keine hohe Speicherkapazität benötigt, ist diese Kategorie für ihre rechenintensiven Simulationen nicht geeignet.",
            "Instanzen für beschleunigtes Rechnen sind auf Workloads zugeschnitten, die von Hardwarebeschleunigern wie GPUs oder FPGAs profitieren. Diese Instanzen sind ideal für Aufgaben wie Maschinenlernen-Inferenz und Grafikverarbeitung, jedoch nicht notwendig für CPU-gebundene Aufgaben, was sie weniger geeignet für die Bedürfnisse des Teams macht."
        ]
    },
    {
        "Question Number": "28",
        "Situation": "Ein Logistikunternehmen muss Daten von Lieferfahrzeugen in Echtzeit verarbeiten, um Routen und Verkehrsbedingungen zu überwachen. Sie möchten Daten so nah wie möglich an der Quelle verarbeiten, um die Latenz zu reduzieren und die Menge der an die Cloud gesendeten Daten zu minimieren.",
        "Question": "Welche verteilte Rechenstrategie würde diese Bedürfnisse am besten erfüllen?",
        "Options": {
            "1": "Führen Sie die gesamte Datenverarbeitung auf Amazon EC2-Instanzen in der nächstgelegenen AWS-Region durch",
            "2": "Verwenden Sie Edge-Processing, um Daten lokal auf Geräten zu verarbeiten",
            "3": "Senden Sie Daten an AWS Lambda zur serverlosen Verarbeitung",
            "4": "Verwenden Sie ein AWS Outposts-Rack im Rechenzentrum des Unternehmens"
        },
        "Correct Answer": "Verwenden Sie Edge-Processing, um Daten lokal auf Geräten zu verarbeiten",
        "Explanation": "Edge-Processing ermöglicht es, Daten so nah wie möglich an der Quelle zu verarbeiten, was für die Echtzeitüberwachung von Lieferfahrzeugen entscheidend ist. Durch die lokale Verarbeitung der Daten auf den Geräten kann das Logistikunternehmen die Latenz erheblich reduzieren, da die Daten nicht zu einem entfernten Cloud-Server zur Verarbeitung reisen müssen. Dieser Ansatz minimiert auch die Menge der an die Cloud gesendeten Daten und entspricht perfekt den Anforderungen des Unternehmens an Effizienz und Geschwindigkeit in der Datenverarbeitung.",
        "Other Options": [
            "Die gesamte Datenverarbeitung auf Amazon EC2-Instanzen in der nächstgelegenen AWS-Region durchzuführen, würde Latenz einführen, da die Daten eine Strecke zurücklegen müssen, um die Cloud zu erreichen. Diese Option erfüllt die Anforderung an die Echtzeitverarbeitung nicht so effektiv wie Edge-Processing.",
            "Das Senden von Daten an AWS Lambda zur serverlosen Verarbeitung würde ebenfalls Latenz verursachen, da die Daten zur Verarbeitung in die Cloud übertragen werden müssen. Während AWS Lambda für viele Anwendungsfälle effizient ist, ist es nicht optimal für die Echtzeitverarbeitung von Daten, die von Lieferfahrzeugen generiert werden und sofortige Analysen benötigen.",
            "Die Verwendung eines AWS Outposts-Racks im Rechenzentrum des Unternehmens könnte einige Vorteile der lokalen Verarbeitung bieten, erfordert jedoch immer noch eine physische Einrichtung und ist möglicherweise nicht so agil oder kosteneffektiv wie echtes Edge-Processing. Darüber hinaus könnte es nicht so nah an der Datenquelle sein wie Edge-Geräte, was zu einer erhöhten Latenz im Vergleich zur Verarbeitung direkt auf den Geräten führen kann."
        ]
    },
    {
        "Question Number": "29",
        "Situation": "Ein Unternehmen hostet zwei Webanwendungen, jede mit einem einzigartigen HTTPS-Domainnamen. Sie müssen die Anzahl der verwendeten Lastenausgleicher reduzieren, während sie gleichzeitig die HTTPS-Unterstützung für beide Anwendungen aufrechterhalten.",
        "Question": "Welcher Typ von AWS-Lastenausgleicher wäre am besten für diese Anforderung geeignet und warum?",
        "Options": {
            "1": "Classic Load Balancer (CLB), da er die Konsolidierung mehrerer Domains in einem einzigen Lastenausgleicher ermöglicht.",
            "2": "Application Load Balancer (ALB), da er hostbasiertes Routing mit Server Name Indication (SNI) unterstützt und mehrere HTTPS-Domains auf einem einzigen Lastenausgleicher ermöglicht.",
            "3": "Network Load Balancer (NLB), da er Routing auf Layer 4 bietet und mehrere HTTPS-Domains verarbeiten kann.",
            "4": "Elastic Load Balancer (ELB) mit Sticky Sessions, da er mehrere Zielgruppen unter demselben Lastenausgleicher ermöglicht."
        },
        "Correct Answer": "Application Load Balancer (ALB), da er hostbasiertes Routing mit Server Name Indication (SNI) unterstützt und mehrere HTTPS-Domains auf einem einzigen Lastenausgleicher ermöglicht.",
        "Explanation": "Der Application Load Balancer (ALB) ist speziell dafür konzipiert, HTTP- und HTTPS-Verkehr zu verarbeiten und unterstützt erweiterte Routing-Funktionen, einschließlich hostbasiertem Routing. Das bedeutet, dass er Anfragen basierend auf dem Hostnamen in der Anfrage an verschiedene Zielgruppen weiterleiten kann, was für das Hosting mehrerer Webanwendungen mit einzigartigen HTTPS-Domainnamen entscheidend ist. Darüber hinaus unterstützt der ALB Server Name Indication (SNI), was es ihm ermöglicht, mehrere SSL-Zertifikate auf einer einzigen IP-Adresse bereitzustellen und sichere Verbindungen für jede Domain zu ermöglichen, ohne separate Lastenausgleicher zu benötigen.",
        "Other Options": [
            "Classic Load Balancer (CLB) unterstützt kein hostbasiertes Routing oder SNI, was ihn weniger geeignet macht, mehrere HTTPS-Domains effizient zu verwalten. Er ist hauptsächlich für grundlegendes Load Balancing konzipiert und verfügt nicht über die erweiterten Funktionen, die für dieses Szenario erforderlich sind.",
            "Network Load Balancer (NLB) arbeitet auf Layer 4 und ist für die Verarbeitung von TCP-Verkehr optimiert. Während er mehrere Domains verarbeiten kann, bietet er nicht die notwendigen Funktionen für SSL-Terminierung oder hostbasiertes Routing, die entscheidend für die effektive Verwaltung von HTTPS-Verkehr sind.",
            "Elastic Load Balancer (ELB) ist ein allgemeiner Begriff, der sowohl ALB als auch NLB umfasst. Während Sticky Sessions konfiguriert werden können, erfüllen sie nicht die Anforderung, mehrere HTTPS-Domains auf einem einzigen Lastenausgleicher zu unterstützen. Der ALB ist der spezifische Typ, der die Anforderungen dieses Szenarios erfüllt."
        ]
    },
    {
        "Question Number": "30",
        "Situation": "Ein Unternehmen plant, seine On-Premises-Anwendungen zu AWS zu migrieren. Diese Anwendungen sind stark von Active Directory für die Benutzerauthentifizierung und Gruppenverwaltung abhängig. Das IT-Team möchte eine verwaltete Lösung auf AWS, die bis zu 3.000 Benutzer unterstützt, mit Amazon Workspaces integriert ist und keine komplexe On-Premises-Integration erfordert. Darüber hinaus benötigen sie eine Lösung, die Windows-Umgebungen mit demselben Benutzernamen und Passwort für das zentrale Management von Ressourcen unterstützt.",
        "Question": "Welche AWS Directory Service-Option würde diese Anforderungen am besten erfüllen?",
        "Options": {
            "1": "Simple AD mit einer Small-Instanz für die eigenständige Verzeichnisverwaltung",
            "2": "AWS Managed Microsoft AD mit Multi-AZ-Bereitstellung",
            "3": "AWS SSO (Single Sign-On) für den plattformübergreifenden Zugriff",
            "4": "Amazon Cognito für die Verwaltung von Benutzerpools"
        },
        "Correct Answer": "AWS Managed Microsoft AD mit Multi-AZ-Bereitstellung",
        "Explanation": "AWS Managed Microsoft AD ist darauf ausgelegt, ein vollständig verwaltetes Active Directory in der AWS-Cloud bereitzustellen. Es unterstützt Windows-Umgebungen und ermöglicht eine nahtlose Integration mit Anwendungen, die auf Active Directory für Authentifizierung und Gruppenverwaltung angewiesen sind. Es kann bis zu 50.000 Benutzer unterstützen, was die Anforderung von 3.000 Benutzern übersteigt. Darüber hinaus integriert es sich gut mit Amazon Workspaces, sodass Benutzer denselben Benutzernamen und dasselbe Passwort für das zentrale Management haben, was die Anforderungen des Unternehmens erfüllt, ohne dass eine komplexe On-Premises-Integration erforderlich ist. Die Multi-AZ-Bereitstellung sorgt für hohe Verfügbarkeit und Resilienz.",
        "Other Options": [
            "Simple AD mit einer Small-Instanz ist ein grundlegender Verzeichnisdienst, der nur eine begrenzte Anzahl von Active Directory-Funktionen unterstützt und nicht für Anwendungen geeignet ist, die vollständige Active Directory-Funktionen erfordern. Es unterstützt auch nicht das gleiche Maß an Integration mit Amazon Workspaces wie AWS Managed Microsoft AD.",
            "AWS SSO (Single Sign-On) ist hauptsächlich für die Verwaltung des Zugriffs auf mehrere AWS-Konten und Anwendungen konzipiert, bietet jedoch nicht die vollständigen Active Directory-Funktionen, die für die Benutzerauthentifizierung und Gruppenverwaltung in einer Windows-Umgebung erforderlich sind. Es ist kein direkter Ersatz für Active Directory.",
            "Amazon Cognito konzentriert sich auf die Benutzerauthentifizierung und -verwaltung für Web- und mobile Anwendungen, bietet jedoch nicht die Active Directory-Funktionen, die für die Anwendungen des Unternehmens erforderlich sind. Es eignet sich eher für Benutzerpools und föderierte Identitäten als für die Verwaltung von Windows-Umgebungen mit Active Directory-Integration."
        ]
    },
    {
        "Question Number": "31",
        "Situation": "Ein Unternehmen setzt eine Webanwendung auf mehreren Amazon EC2-Instanzen in verschiedenen Availability Zones ein. Die Anwendung benötigt ein gemeinsames Dateisystem zum Speichern und Zugreifen auf von Benutzern generierte Inhalte. Das Unternehmen möchte auch die Flexibilität, sein lokales Rechenzentrum mit dem gemeinsamen Speicher in AWS zu verbinden.",
        "Question": "Welche AWS-Lösung sollte der Solutions Architect empfehlen, um diese Anforderungen zu erfüllen?",
        "Options": {
            "1": "Amazon EBS mit Multi-Attach über Availability Zones",
            "2": "Amazon EFS mit Mount-Zielen in jeder Availability Zone und Zugriff über VPN oder Direct Connect für die lokale Konnektivität",
            "3": "Amazon S3 mit Transfer Acceleration für den Zugriff über Regionen hinweg",
            "4": "Amazon RDS mit Read Replicas in jeder Availability Zone"
        },
        "Correct Answer": "Amazon EFS mit Mount-Zielen in jeder Availability Zone und Zugriff über VPN oder Direct Connect für die lokale Konnektivität",
        "Explanation": "Amazon EFS (Elastic File System) ist ein vollständig verwalteter Dateispeicherdienst, der auf mehreren EC2-Instanzen in verschiedenen Availability Zones gemountet werden kann und ein gemeinsames Dateisystem für Anwendungen bereitstellt. Es unterstützt NFS (Network File System)-Protokolle, was es für Anwendungen geeignet macht, die einen gemeinsamen Zugriff auf Dateien benötigen. Darüber hinaus kann EFS von lokalen Rechenzentren über ein VPN oder AWS Direct Connect erreicht werden, was die Anforderung an die Konnektivität zwischen lokalem und AWS-Speicher erfüllt.",
        "Other Options": [
            "Amazon EBS (Elastic Block Store) mit Multi-Attach ermöglicht es mehreren EC2-Instanzen, sich an ein einzelnes EBS-Volume anzuschließen, ist jedoch auf eine einzelne Availability Zone beschränkt. Dies erfüllt nicht die Anforderung an ein gemeinsames Dateisystem über mehrere Availability Zones.",
            "Amazon S3 (Simple Storage Service) ist ein Objektspeicherdienst und während er von Benutzern generierte Inhalte speichern kann, bietet er keine traditionelle Dateisystemschnittstelle, die Anwendungen typischerweise für den gemeinsamen Zugriff benötigen. Transfer Acceleration dient der Beschleunigung von Uploads und Downloads, adressiert jedoch nicht die Notwendigkeit eines gemeinsamen Dateisystems über EC2-Instanzen.",
            "Amazon RDS (Relational Database Service) ist ein verwalteter Datenbankdienst und während er Read Replicas in verschiedenen Availability Zones für hohe Verfügbarkeit haben kann, ist er nicht geeignet, um von Benutzern generierte Inhalte in einem gemeinsamen Dateisystemformat zu speichern. RDS ist für strukturierte Daten und relationale Datenbankanwendungen konzipiert, nicht für die Dateispeicherung."
        ]
    },
    {
        "Question Number": "32",
        "Situation": "Ein Medienunternehmen streamt Videoinhalte weltweit und muss die Liefergeschwindigkeit verbessern und die Latenz für Benutzer in verschiedenen geografischen Regionen reduzieren. Das Unternehmen sieht während der Spitzenzeiten eine hohe Nachfrage, und das Puffern von Inhalten beeinträchtigt die Benutzererfahrung. Sie müssen auch die Last auf ihren Ursprungsservern reduzieren, um eine Ressourcenerschöpfung zu verhindern.",
        "Question": "Welchen AWS-Dienst sollte das Unternehmen nutzen, um diese Ziele zu erreichen, und welche Vorteile bietet er?",
        "Options": {
            "1": "Verwenden Sie Amazon CloudFront als CDN, um Inhalte an Edge-Standorten weltweit zwischenzuspeichern, die Latenz zu reduzieren und den Datenverkehr von den Ursprungsservern zu entlasten.",
            "2": "Verwenden Sie Amazon Route 53 mit Geolokalisierungsrouting, um Benutzer zum nächstgelegenen S3-Bucket zu leiten, in dem Videoinhalte gespeichert sind.",
            "3": "Verwenden Sie Amazon S3 für die Speicherung und leiten Sie Benutzer zu einer einzelnen EC2-Instanz in einer Region, um alle Videoinhalte bereitzustellen.",
            "4": "Verwenden Sie AWS Direct Connect, um dedizierte Netzwerkverbindungen zu allen Kunden weltweit für eine schnellere Inhaltslieferung herzustellen."
        },
        "Correct Answer": "Verwenden Sie Amazon CloudFront als CDN, um Inhalte an Edge-Standorten weltweit zwischenzuspeichern, die Latenz zu reduzieren und den Datenverkehr von den Ursprungsservern zu entlasten.",
        "Explanation": "Amazon CloudFront ist ein Content Delivery Network (CDN), das Inhalte an Edge-Standorten weltweit zwischen speichert. Durch die Verwendung von CloudFront kann das Medienunternehmen Videoinhalte näher an den Benutzern bereitstellen, was die Latenz erheblich reduziert und die Liefergeschwindigkeit verbessert. Dieser Caching-Mechanismus entlastet auch den Datenverkehr von den Ursprungsservern, was hilft, Ressourcenerschöpfung während Zeiten hoher Nachfrage zu verhindern. Insgesamt verbessert CloudFront die Benutzererfahrung, indem es das Puffern minimiert und einen schnelleren Zugriff auf Inhalte gewährleistet.",
        "Other Options": [
            "Die Verwendung von Amazon Route 53 mit Geolokalisierungsrouting könnte helfen, Benutzer zu den nächstgelegenen Ressourcen zu leiten, jedoch speichert es keine Inhalte zwischen und reduziert die Latenz nicht effektiv. Es verwaltet hauptsächlich das DNS-Routing und adressiert nicht die Pufferprobleme oder die Last auf den Ursprungsservern.",
            "Die Verwendung von Amazon S3 für die Speicherung und die Weiterleitung der Benutzer zu einer einzelnen EC2-Instanz in einer Region wäre für die globale Inhaltslieferung nicht effektiv. Dieser Ansatz könnte zu hoher Latenz für Benutzer führen, die weit von der EC2-Instanz entfernt sind, und würde die Last auf den Ursprungsservern nicht verringern, was zu potenziellen Leistungsproblemen während der Spitzenzeiten führen könnte.",
            "AWS Direct Connect bietet dedizierte Netzwerkverbindungen, ist jedoch nicht für die Inhaltslieferung konzipiert. Es eignet sich besser für die Einrichtung privater Verbindungen zwischen lokalen Rechenzentren und AWS, als die Geschwindigkeit der Inhaltslieferung an Endbenutzer weltweit zu verbessern."
        ]
    },
    {
        "Question Number": "33",
        "Situation": "Eine Organisation möchte eine sichere Verbindung zwischen ihrem lokalen Rechenzentrum und ihrer AWS-Umgebung herstellen. Die Verbindung muss hohe Verfügbarkeit und eine latenzarme Verbindung für kritische Anwendungsdaten unterstützen.",
        "Question": "Welche Lösung erfüllt diese Anforderungen am besten?",
        "Options": {
            "1": "Richten Sie eine VPN-Verbindung über das Internet ein",
            "2": "Verwenden Sie AWS Direct Connect mit einer redundanten Verbindung",
            "3": "Konfigurieren Sie einen Elastic Load Balancer, um den Datenverkehr zu verteilen",
            "4": "Verwenden Sie eine VPC-Peering-Verbindung"
        },
        "Correct Answer": "Verwenden Sie AWS Direct Connect mit einer redundanten Verbindung",
        "Explanation": "AWS Direct Connect bietet eine dedizierte Netzwerkverbindung vom lokalen Rechenzentrum zu AWS, die ideal für Anforderungen an hohe Verfügbarkeit und niedrige Latenz ist. Durch die Verwendung von Direct Connect mit einer redundanten Verbindung kann die Organisation sicherstellen, dass eine Backup-Verbindung verfügbar ist, falls die primäre Verbindung ausfällt, wodurch die hohe Verfügbarkeit aufrechterhalten wird. Diese Lösung ist speziell für die Konnektivität auf Unternehmensebene konzipiert und kann kritische Anwendungsdaten effizient verarbeiten.",
        "Other Options": [
            "Das Einrichten einer VPN-Verbindung über das Internet kann eine sichere Verbindung bieten, garantiert jedoch typischerweise keine niedrige Latenz oder hohe Verfügbarkeit im Vergleich zu einer dedizierten Verbindung wie AWS Direct Connect. VPN-Verbindungen können durch Internetverkehr beeinträchtigt werden und können Variabilität in der Latenz einführen.",
            "Die Konfiguration eines Elastic Load Balancers ist nicht relevant für die Herstellung einer direkten Verbindung zwischen dem lokalen Rechenzentrum und AWS. Lastenausgleicher werden verwendet, um eingehenden Anwendungsdatenverkehr auf mehrere Ziele zu verteilen, bieten jedoch nicht die sichere Verbindung, die in diesem Szenario benötigt wird.",
            "Die Verwendung einer VPC-Peering-Verbindung ist nützlich, um zwei VPCs innerhalb von AWS zu verbinden, adressiert jedoch nicht die Anforderung, ein lokales Rechenzentrum mit AWS zu verbinden. VPC-Peering bietet keine dedizierte, latenzarme Verbindung und ist für dieses Szenario nicht geeignet."
        ]
    },
    {
        "Question Number": "34",
        "Situation": "Ein Unternehmen muss externen Auftragnehmern vorübergehenden Zugriff auf einen S3-Bucket gewähren. Der Zugriff muss automatisch nach einem bestimmten Zeitraum ablaufen und sollte auf bestimmte Aktionen beschränkt sein.",
        "Question": "Welche Lösungen sollte das Unternehmen implementieren? (Wählen Sie zwei.)",
        "Options": {
            "1": "Erstellen Sie IAM-Benutzer für jeden Auftragnehmer und fügen Sie eine S3-Zugriffsrichtlinie hinzu",
            "2": "Verwenden Sie AWS IAM Identity Center (AWS Single Sign-On) mit einer temporären Zugriffsrolle",
            "3": "Generieren Sie vorab signierte URLs für die S3-Objekte, auf die die Auftragnehmer zugreifen müssen",
            "4": "Fügen Sie eine Bucket-Richtlinie mit einer zeitbasierten Bedingung hinzu, um den Zugriff einzuschränken",
            "5": "Implementieren Sie temporäre Sicherheitsanmeldeinformationen mithilfe des AWS Security Token Service (STS)"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Generieren Sie vorab signierte URLs für die S3-Objekte, auf die die Auftragnehmer zugreifen müssen",
            "Implementieren Sie temporäre Sicherheitsanmeldeinformationen mithilfe des AWS Security Token Service (STS)"
        ],
        "Explanation": "Vorab signierte URLs bieten eine Möglichkeit, vorübergehenden Zugriff auf bestimmte S3-Objekte zu gewähren. Sie werden mit einer Ablaufzeit generiert, nach der sie nicht mehr gültig sind. Dies entspricht der Anforderung, dass der Zugriff automatisch nach einem bestimmten Zeitraum abläuft. Der AWS Security Token Service (STS) ist ein Webdienst, der es Ihnen ermöglicht, temporäre, eingeschränkte Anmeldeinformationen für AWS Identity and Access Management (IAM)-Benutzer anzufordern. Sie können die Berechtigungen für diese temporären Sicherheitsanmeldeinformationen festlegen, was es ermöglicht, die Aktionen, die die Auftragnehmer durchführen können, einzuschränken.",
        "Other Options": [
            "Das Erstellen von IAM-Benutzern für jeden Auftragnehmer und das Hinzufügen einer S3-Zugriffsrichtlinie ist keine vorübergehende Lösung und läuft nicht automatisch ab. Dies würde manuelle Eingriffe erfordern, um den Zugriff zu widerrufen.",
            "Die Verwendung von AWS IAM Identity Center (AWS Single Sign-On) mit einer temporären Zugriffsrolle könnte verwendet werden, um vorübergehenden Zugriff zu gewähren, jedoch schränkt es nicht von sich aus den Zugriff auf bestimmte Aktionen oder S3-Objekte ein.",
            "Das Hinzufügen einer Bucket-Richtlinie mit einer zeitbasierten Bedingung zur Einschränkung des Zugriffs ist keine praktikable Lösung, da AWS keine zeitbasierten Bedingungen in Bucket-Richtlinien unterstützt."
        ]
    },
    {
        "Question Number": "35",
        "Situation": "Ein Unternehmen entwirft eine Webanwendung und möchte eine mehrschichtige Architektur implementieren, um die Anliegen zu trennen und die Skalierbarkeit zu verbessern. Sie erwarten schwankende Arbeitslasten basierend auf der Benutzernachfrage, und die Architektur muss sich automatisch basierend auf den Verkehrsmustern skalieren. Das Unternehmen möchte auch die Sicherheit verbessern, indem es Schichten isoliert, um unbefugten Zugriff zu verhindern.",
        "Question": "Welche der folgenden Beschreibungen beschreibt am besten die Architektur, die das Unternehmen implementieren sollte? (Wählen Sie zwei.)",
        "Options": {
            "1": "Verwenden Sie eine Amazon EC2-Instanz als Webschicht, Amazon RDS als Datenschicht und einen Application Load Balancer (ALB), um den Datenverkehr unter den Instanzen in der Webschicht zu verteilen.",
            "2": "Verwenden Sie AWS Lambda-Funktionen für sowohl die Web- als auch die Datenschicht, um das Infrastrukturmanagement zu reduzieren und automatische Skalierung zu ermöglichen.",
            "3": "Verwenden Sie Amazon S3 für die Speicherung, Amazon EC2-Instanzen für die Berechnung und AWS Direct Connect für die sichere Kommunikation zwischen den Schichten.",
            "4": "Implementieren Sie eine VPC mit öffentlichen Subnetzen für die Webschicht und privaten Subnetzen für die Anwendungs- und Datenschichten, verwenden Sie Auto Scaling-Gruppen für die Web- und Anwendungsschichten und setzen Sie eine RDS-Instanz im privaten Subnetz ein.",
            "5": "Verwenden Sie eine einzelne EC2-Instanz für sowohl die Web- als auch die Datenschicht und verbinden Sie diese über eine Virtual Private Cloud (VPC) zur Isolation."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Verwenden Sie eine Amazon EC2-Instanz als Webschicht, Amazon RDS als Datenschicht und einen Application Load Balancer (ALB), um den Datenverkehr unter den Instanzen in der Webschicht zu verteilen.",
            "Implementieren Sie eine VPC mit öffentlichen Subnetzen für die Webschicht und privaten Subnetzen für die Anwendungs- und Datenschichten, verwenden Sie Auto Scaling-Gruppen für die Web- und Anwendungsschichten und setzen Sie eine RDS-Instanz im privaten Subnetz ein."
        ],
        "Explanation": "Die erste korrekte Antwort verwendet Amazon EC2 für die Webschicht, die schwankende Arbeitslasten bewältigen kann und automatisch skaliert werden kann. Amazon RDS wird für die Datenschicht verwendet, die eine skalierbare und sichere Lösung für das Datenbankmanagement bietet. Der Application Load Balancer verteilt den Datenverkehr unter den Instanzen in der Webschicht, was hilft, schwankende Arbeitslasten zu verwalten. Die zweite korrekte Antwort verwendet eine VPC mit öffentlichen Subnetzen für die Webschicht und privaten Subnetzen für die Anwendungs- und Datenschichten, was Isolation bietet und die Sicherheit verbessert. Auto Scaling-Gruppen werden für die Web- und Anwendungsschichten verwendet, die schwankende Arbeitslasten bewältigen können und automatisch skaliert werden können. Eine RDS-Instanz wird im privaten Subnetz bereitgestellt, was eine skalierbare und sichere Lösung für das Datenbankmanagement bietet.",
        "Other Options": [
            "Die Verwendung von AWS Lambda-Funktionen für sowohl die Web- als auch die Datenschicht kann tatsächlich das Infrastrukturmanagement reduzieren und automatische Skalierung ermöglichen. Es bietet jedoch möglicherweise nicht die notwendige Isolation zwischen den Schichten, um die Sicherheit zu verbessern.",
            "Die Verwendung von Amazon S3 für die Speicherung, Amazon EC2-Instanzen für die Berechnung und AWS Direct Connect für die sichere Kommunikation zwischen den Schichten kann eine mehrschichtige Architektur bieten. Es wird jedoch kein Mechanismus erwähnt, um schwankende Arbeitslasten zu bewältigen oder automatisch basierend auf Verkehrsmustern zu skalieren.",
            "Die Verwendung einer einzelnen EC2-Instanz für sowohl die Web- als auch die Datenschicht und die Verbindung über eine Virtual Private Cloud (VPC) zur Isolation bietet keine mehrschichtige Architektur. Es wird auch kein Mechanismus erwähnt, um schwankende Arbeitslasten zu bewältigen oder automatisch basierend auf Verkehrsmustern zu skalieren."
        ]
    },
    {
        "Question Number": "36",
        "Situation": "Eine Gesundheitsanwendung muss Patientendaten sicher speichern. Die Daten müssen häufig für Aktualisierungen abgerufen werden und müssen die Dateihierarchie und Metadaten beibehalten. Das Anwendungsteam möchte die Speicherkosten optimieren, benötigt jedoch auch konsistenten, latenzarmen Zugriff.",
        "Question": "Welcher Speichertyp würde diese Anforderungen am besten erfüllen?",
        "Options": {
            "1": "Object storage (Amazon S3)",
            "2": "File storage (Amazon EFS)",
            "3": "Block storage (Amazon EBS)",
            "4": "Cold storage (Amazon S3 Glacier)"
        },
        "Correct Answer": "File storage (Amazon EFS)",
        "Explanation": "File storage, wie Amazon EFS (Elastic File System), ist für Anwendungsfälle konzipiert, die eine Dateihierarchie und Metadaten erfordern, was es ideal für die Speicherung von Patientendaten macht. EFS bietet latenzarmen Zugriff und ermöglicht es mehreren Instanzen, gleichzeitig auf dieselben Daten zuzugreifen, was für Anwendungen, die Patientendaten häufig aktualisieren müssen, unerlässlich ist. Darüber hinaus kann EFS automatisch skalieren, um die Speicherkosten zu optimieren und gleichzeitig die Leistung aufrechtzuerhalten.",
        "Other Options": [
            "Object storage (Amazon S3) ist für dieses Szenario nicht geeignet, da es für unstrukturierte Daten konzipiert ist und keine Dateihierarchie beibehält oder traditionelle Dateisystemsemantiken unterstützt, die für die effektive Verwaltung von Patientendaten erforderlich sind.",
            "Block storage (Amazon EBS) wird typischerweise für Anwendungen verwendet, die leistungsstarken Speicher für Datenbanken oder virtuelle Maschinen benötigen. Obwohl es latenzarmen Zugriff bietet, bietet es keine Dateihierarchie oder einfache Freigabe von Dateien über mehrere Instanzen, was eine Anforderung für die Gesundheitsanwendung ist.",
            "Cold storage (Amazon S3 Glacier) ist für Daten konzipiert, die selten abgerufen werden, und ist nicht geeignet für Anwendungen, die häufige Aktualisierungen und latenzarmen Zugriff erfordern. Es wird hauptsächlich für die Archivierung von Daten und nicht für das aktive Datenmanagement verwendet."
        ]
    },
    {
        "Question Number": "37",
        "Situation": "Ein Unternehmen hat einen S3-Bucket mit sensiblen Daten, auf die spezifische IAM-Rollen über mehrere AWS-Konten zugreifen müssen. Das Unternehmen möchte sicherstellen, dass nur diese Rollen Zugriff haben, während die Verwaltung einfach bleibt und komplexe IAM-Benutzerkonfigurationen vermieden werden.",
        "Question": "Was sind die geeignetsten Möglichkeiten, um diese Zugriffskontrolle zu implementieren? (Wählen Sie zwei aus.)",
        "Options": {
            "1": "Erstellen Sie eine IAM-Richtlinie in jedem Konto, die den Zugriff auf den S3-Bucket gewährt, und fügen Sie sie den erforderlichen Rollen hinzu.",
            "2": "Fügen Sie eine Bucket-Richtlinie zum S3-Bucket hinzu, die den Zugriff auf die erforderlichen IAM-Rollen in jedem Konto ausdrücklich gewährt.",
            "3": "Verwenden Sie AWS Secrets Manager, um Zugriffsdaten für jede IAM-Rolle, die auf den Bucket zugreifen muss, zu speichern und zu verwalten.",
            "4": "Richten Sie VPC-Endpunkte in jedem Konto ein, um den Zugriff auf den S3-Bucket basierend auf der VPC-Netzwerkkonfiguration zu steuern.",
            "5": "Verwenden Sie Amazon S3 Access Points mit Richtlinien, die die zulässigen IAM-Rollen über mehrere Konten angeben."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Erstellen Sie eine IAM-Richtlinie in jedem Konto, die den Zugriff auf den S3-Bucket gewährt, und fügen Sie sie den erforderlichen Rollen hinzu.",
            "Fügen Sie eine Bucket-Richtlinie zum S3-Bucket hinzu, die den Zugriff auf die erforderlichen IAM-Rollen in jedem Konto ausdrücklich gewährt."
        ],
        "Explanation": "Das Erstellen einer IAM-Richtlinie in jedem Konto, die den Zugriff auf den S3-Bucket gewährt, und das Hinzufügen zu den erforderlichen Rollen ist eine korrekte Antwort, da IAM-Richtlinien eine Möglichkeit sind, Berechtigungen für mehrere AWS-Konten zu verwalten. Dieser Ansatz ermöglicht es dem Unternehmen, festzulegen, welche Rollen in jedem Konto Zugriff auf den S3-Bucket haben. Das Hinzufügen einer Bucket-Richtlinie zum S3-Bucket, die den Zugriff auf die erforderlichen IAM-Rollen in jedem Konto ausdrücklich gewährt, ist ebenfalls korrekt. Eine Bucket-Richtlinie gilt für alle Objekte in diesem Bucket und kann verwendet werden, um den Zugriff auf den S3-Bucket über Konten hinweg zu gewähren, was das Unternehmen möchte.",
        "Other Options": [
            "Die Verwendung von AWS Secrets Manager zur Speicherung und Verwaltung von Zugriffsdaten für jede IAM-Rolle, die auf den Bucket zugreifen muss, ist nicht die beste Option, da dies unnötige Komplexität in die Verwaltung der Zugriffsdaten einbringen würde. Das Unternehmen möchte komplexe IAM-Benutzerkonfigurationen vermeiden, und die Verwendung von Secrets Manager würde die Verwaltung des Zugriffs auf den S3-Bucket nicht vereinfachen.",
            "Das Einrichten von VPC-Endpunkten in jedem Konto zur Steuerung des Zugriffs auf den S3-Bucket basierend auf der VPC-Netzwerkkonfiguration ist nicht die beste Option, da es nicht direkt steuert, welche IAM-Rollen Zugriff auf den S3-Bucket haben. VPC-Endpunkte werden verwendet, um Ihr VPC privat mit unterstützten AWS-Diensten zu verbinden, nicht um den Zugriff auf S3-Buckets auf IAM-Rollenebene zu verwalten.",
            "Die Verwendung von Amazon S3 Access Points mit Richtlinien, die die zulässigen IAM-Rollen über mehrere Konten angeben, ist nicht die beste Option, da S3 Access Points verwendet werden, um die Verwaltung des Datenzugriffs im großen Maßstab für Anwendungen mit gemeinsamen Datensätzen zu vereinfachen. Sie bieten keine Möglichkeit, den Zugriff auf S3-Buckets auf IAM-Rollenebene über mehrere Konten hinweg zu verwalten."
        ]
    },
    {
        "Question Number": "38",
        "Situation": "Ein Unternehmen möchte eine hochverfügbare Webanwendung entwerfen, die Infrastrukturfehler innerhalb einer Region überstehen kann und latenzarmen Zugriff für Benutzer an mehreren Standorten bietet.",
        "Question": "Welchen AWS-Dienst sollte das Unternehmen verwenden, um die Verkehrsverteilung über mehrere Verfügbarkeitszonen zu verwalten, und welchen Vorteil bietet er?",
        "Options": {
            "1": "Amazon Route 53",
            "2": "AWS Direct Connect",
            "3": "Amazon S3",
            "4": "Amazon DynamoDB"
        },
        "Correct Answer": "Amazon Route 53",
        "Explanation": "Amazon Route 53 ist ein skalierbarer Domain Name System (DNS) Webdienst, der hochzuverlässige und kosteneffektive Domainregistrierung, DNS-Routing und Gesundheitsprüfungen von Ressourcen bietet. Es kann die Verkehrsverteilung über mehrere Verfügbarkeitszonen verwalten, indem es Benutzeranfragen an den nächstgelegenen gesunden Endpunkt weiterleitet, um latenzarmen Zugriff und hohe Verfügbarkeit zu gewährleisten. Dies macht es zu einer idealen Wahl für Anwendungen, die Infrastrukturfehler überstehen und die Leistung an verschiedenen geografischen Standorten aufrechterhalten müssen.",
        "Other Options": [
            "AWS Direct Connect ist ein Cloud-Dienst, der eine dedizierte Netzwerkverbindung von Ihren Räumlichkeiten zu AWS bereitstellt. Obwohl es die Netzwerkleistung verbessern kann, verwaltet es nicht die Verkehrsverteilung über Verfügbarkeitszonen.",
            "Amazon S3 (Simple Storage Service) ist ein Objektspeicherdienst, der hochskalierbaren Speicher für Daten bereitstellt. Es verwaltet nicht die Verkehrsverteilung oder das Routing für Webanwendungen.",
            "Amazon DynamoDB ist ein vollständig verwalteter NoSQL-Datenbankdienst, der schnelle und vorhersehbare Leistung mit nahtloser Skalierbarkeit bietet. Es ist nicht für die Verkehrsverteilung oder die Verwaltung von Benutzeranfragen über mehrere Verfügbarkeitszonen hinweg konzipiert."
        ]
    },
    {
        "Question Number": "39",
        "Situation": "Ein Unternehmen möchte seine AWS Lambda-Funktion sicher mit DynamoDB und S3 integrieren. Sie müssen sicherstellen, dass die Lambda-Funktion nur bestimmte Aktionen auf diesen Diensten ausführen kann, während auch eingeschränkt wird, welche anderen AWS-Dienste und Konten die Funktion aufrufen können.",
        "Question": "Welche der folgenden Ansätze sollten sie verfolgen, um dies zu erreichen?",
        "Options": {
            "1": "Fügen Sie der Lambda-Funktion eine Inline-Richtlinie hinzu, die die zulässigen Aktionen auf DynamoDB und S3 angibt, und wenden Sie eine Ressourcenrichtlinie an, die einschränkt, welche Dienste und Konten die Lambda-Funktion aufrufen können.",
            "2": "Verwenden Sie eine Lambda-Ausführungsrolle, die Berechtigungen für die erforderlichen Aktionen auf DynamoDB und S3 gewährt, und fügen Sie eine Lambda-Ressourcenrichtlinie hinzu, um die Aufrufberechtigungen zu steuern.",
            "3": "Fügen Sie der Lambda-Funktion eine verwaltete IAM-Richtlinie für den Zugriff auf DynamoDB und S3 hinzu und konfigurieren Sie eine Lambda-Berechtigungsgrenze, um den Aufruf einzuschränken.",
            "4": "Erstellen Sie eine dienstgebundene Rolle für die Lambda-Funktion, um auf DynamoDB und S3 zuzugreifen, und verwenden Sie eine S3-Bucket-Richtlinie, um den Aufruf einzuschränken."
        },
        "Correct Answer": "Verwenden Sie eine Lambda-Ausführungsrolle, die Berechtigungen für die erforderlichen Aktionen auf DynamoDB und S3 gewährt, und fügen Sie eine Lambda-Ressourcenrichtlinie hinzu, um die Aufrufberechtigungen zu steuern.",
        "Explanation": "Die Verwendung einer Lambda-Ausführungsrolle ist die beste Praxis zur Gewährung von Berechtigungen für AWS Lambda-Funktionen. Diese Rolle ermöglicht es der Funktion, spezifische Aktionen auf DynamoDB und S3 auszuführen, und stellt sicher, dass nur die erforderlichen Berechtigungen gewährt werden. Darüber hinaus kann eine Lambda-Ressourcenrichtlinie angewendet werden, um zu steuern, welche AWS-Dienste und Konten die Lambda-Funktion aufrufen können, was eine sichere und flexible Möglichkeit zur Verwaltung des Zugriffs bietet.",
        "Other Options": [
            "Das Hinzufügen einer Inline-Richtlinie zur Lambda-Funktion wird nicht empfohlen, da Inline-Richtlinien an eine bestimmte Ressource gebunden sind und schwierig zu verwalten sein können. Eine Lambda-Ausführungsrolle ist ein skalierbarer und verwaltbarer Ansatz. Während eine Ressourcenrichtlinie wichtig ist, ist die Ausführungsrolle die primäre Methode zur Gewährung von Berechtigungen für den Zugriff auf andere AWS-Dienste.",
            "Das Hinzufügen einer verwalteten IAM-Richtlinie zur Lambda-Funktion ist nicht der beste Ansatz, da verwaltete Richtlinien breiter sind und möglicherweise mehr Berechtigungen gewähren als notwendig. Darüber hinaus kann eine Berechtigungsgrenze zwar helfen, Berechtigungen einzuschränken, ist jedoch nicht die primäre Methode zur Steuerung der Aufrufberechtigungen, die besser durch eine Ressourcenrichtlinie verwaltet wird.",
            "Das Erstellen einer dienstgebundenen Rolle für die Lambda-Funktion ist in diesem Fall nicht anwendbar, da dienstgebundene Rollen vordefinierte Rollen sind, die AWS-Dienste verwenden, um in Ihrem Namen Aktionen auszuführen. Sie bieten nicht die notwendige Granularität zur Steuerung des Zugriffs auf DynamoDB und S3. Eine S3-Bucket-Richtlinie ist ebenfalls nicht geeignet, um die Aufrufberechtigungen für Lambda zu steuern, da sie spezifisch für S3 ist und nicht auf Lambda-Funktionen anwendbar ist."
        ]
    },
    {
        "Question Number": "40",
        "Situation": "Eine globale Handelsplattform für Finanzdienstleistungen muss die Latenz für Benutzer in verschiedenen Teilen der Welt minimieren. Die Plattform erfordert konsistenten, hochgeschwindigkeits Datenverkehr mit minimalen Hops, um das Risiko von Verzögerungen oder Paketverlusten zu reduzieren. Darüber hinaus muss sie TCP- und UDP-Verkehr für verschiedene Echtzeitanwendungen unterstützen.",
        "Question": "Welcher AWS-Dienst würde diese Anforderungen am besten erfüllen?",
        "Options": {
            "1": "Amazon CloudFront mit Edge-Caching",
            "2": "AWS Direct Connect für dedizierte Verbindungen",
            "3": "AWS Global Accelerator mit Anycast-IP-Adressen",
            "4": "Amazon Route 53 mit latenzbasierter Weiterleitung"
        },
        "Correct Answer": "AWS Global Accelerator mit Anycast-IP-Adressen",
        "Explanation": "AWS Global Accelerator ist speziell dafür konzipiert, die Verfügbarkeit und Leistung von Anwendungen mit global verteilten Benutzern zu verbessern. Es verwendet Anycast-IP-Adressen, um den Benutzerverkehr zum nächstgelegenen AWS-Edge-Standort zu leiten, wodurch die Latenz minimiert und ein konsistenter Datenübertragungsweg bereitgestellt wird. Dieser Dienst unterstützt sowohl TCP- als auch UDP-Verkehr, was ihn ideal für Echtzeitanwendungen macht, die eine niedrige Latenz und einen hochgeschwindigkeits Datenverkehr erfordern. Darüber hinaus reduziert er die Anzahl der Hops zwischen dem Benutzer und der Anwendung, was hilft, Verzögerungen und Paketverluste zu minimieren.",
        "Other Options": [
            "Amazon CloudFront mit Edge-Caching ist hauptsächlich ein Content Delivery Network (CDN), das Inhalte an Edge-Standorten zwischenspeichert, um die Latenz bei der Bereitstellung statischer Inhalte zu reduzieren. Obwohl es die Leistung für bestimmte Arten von Anwendungen verbessern kann, ist es nicht für Echtzeitanwendungen optimiert, die konsistenten, hochgeschwindigkeits Datenverkehr und Unterstützung für sowohl TCP- als auch UDP-Verkehr erfordern.",
            "AWS Direct Connect bietet dedizierte Netzwerkverbindungen von Ihren Räumlichkeiten zu AWS, was die Latenz für Datenübertragungen reduzieren kann. Es ist jedoch besser für hybride Cloud-Architekturen geeignet und bietet nicht von sich aus globale Routing- oder Unterstützung für TCP- und UDP-Verkehr über mehrere Regionen, was es weniger ideal für eine globale Handelsplattform für Finanzdienstleistungen macht.",
            "Amazon Route 53 mit latenzbasierter Weiterleitung ist ein DNS-Dienst, der Benutzeranfragen an die nächstgelegene AWS-Region basierend auf der Latenz weiterleitet. Obwohl es die Leistung verbessern kann, bietet es nicht dasselbe Maß an konsistentem, hochgeschwindigkeits Datenverkehr und minimalen Hops wie AWS Global Accelerator, noch unterstützt es direkt TCP- und UDP-Verkehr auf die gleiche Weise."
        ]
    },
    {
        "Question Number": "41",
        "Situation": "Ein IAM-Administrator richtet den Zugriff für ein Entwicklerteam ein, das langfristigen Zugriff auf AWS-Ressourcen benötigt. Um den Verwaltungsaufwand zu reduzieren, möchte der Administrator die gleichen Berechtigungen für mehrere Teammitglieder anwenden und gleichzeitig sicherstellen, dass die Richtlinien wiederverwendbar und leicht aktualisierbar sind.",
        "Question": "Welchen Ansatz sollte der Administrator wählen, um diese Anforderungen umzusetzen?",
        "Options": {
            "1": "Fügen Sie jedem IAM-Benutzer individuelle Inline-Richtlinien mit spezifischen Berechtigungen hinzu.",
            "2": "Erstellen Sie eine kundenverwaltete Richtlinie und fügen Sie sie einer IAM-Gruppe hinzu, und fügen Sie dann die Benutzer zur Gruppe hinzu.",
            "3": "Verwenden Sie eine von AWS verwaltete Richtlinie und fügen Sie sie direkt jedem IAM-Benutzer hinzu.",
            "4": "Definieren Sie eine Ressourcenrichtlinie mit den erforderlichen Berechtigungen und wenden Sie sie direkt auf die Ressourcen an."
        },
        "Correct Answer": "Erstellen Sie eine kundenverwaltete Richtlinie und fügen Sie sie einer IAM-Gruppe hinzu, und fügen Sie dann die Benutzer zur Gruppe hinzu.",
        "Explanation": "Die Erstellung einer kundenverwalteten Richtlinie ermöglicht es dem IAM-Administrator, eine Reihe von Berechtigungen zu definieren, die über mehrere Benutzer hinweg wiederverwendet werden können. Durch das Anhängen dieser Richtlinie an eine IAM-Gruppe erben alle Benutzer in dieser Gruppe die in der Richtlinie definierten Berechtigungen. Dieser Ansatz reduziert den Verwaltungsaufwand, da der Administrator, wenn Berechtigungen aktualisiert werden müssen, die Richtlinie einfach an einem Ort ändern kann, anstatt jeden Benutzer einzeln zu aktualisieren. Diese Methode stellt auch sicher, dass die Berechtigungen für alle Teammitglieder konsistent sind.",
        "Other Options": [
            "Das Anhängen individueller Inline-Richtlinien an jeden IAM-Benutzer erstellt eine einzigartige Richtlinie für jeden Benutzer, was den Verwaltungsaufwand erhöht und es schwierig macht, konsistente Berechtigungen im Team aufrechtzuerhalten. Inline-Richtlinien sind nicht wiederverwendbar und müssen für jeden Benutzer einzeln aktualisiert werden.",
            "Die Verwendung einer von AWS verwalteten Richtlinie und deren direkte Anhängung an jeden IAM-Benutzer kann zu Herausforderungen bei der Verwaltung von Berechtigungen führen, da von AWS verwaltete Richtlinien vordefiniert sind und möglicherweise nicht den spezifischen Bedürfnissen des Entwicklerteams entsprechen. Darüber hinaus müsste, wenn Änderungen erforderlich sind, jeder Benutzer einzeln aktualisiert werden, was den Verwaltungsaufwand erhöht.",
            "Das Definieren einer Ressourcenrichtlinie mit den erforderlichen Berechtigungen und deren direkte Anwendung auf die Ressourcen ist nicht geeignet, um Benutzerberechtigungen zu verwalten. Ressourcenrichtlinien sind dafür gedacht, den Zugriff auf spezifische AWS-Ressourcen zu steuern, und nicht, um Benutzerberechtigungen über mehrere Benutzer hinweg zu verwalten. Dieser Ansatz erfüllt nicht die Anforderung nach wiederverwendbaren und leicht aktualisierbaren Berechtigungen für ein Team von Benutzern."
        ]
    },
    {
        "Question Number": "42",
        "Situation": "Ein Unternehmen speichert kritische Geschäftsdaten in AWS und muss eine Speicherlösung wählen, die hohe Haltbarkeit und Replikation über mehrere Regionen für die Notfallwiederherstellung bietet.",
        "Question": "Welche Speicheroption sollte das Unternehmen wählen, um Haltbarkeit und Datenreplikation sicherzustellen?",
        "Options": {
            "1": "Verwenden Sie Amazon EBS (Elastic Block Store) mit Snapshots für Backup und Replikation, um sicherzustellen, dass Daten in eine andere Availability Zone repliziert werden.",
            "2": "Verwenden Sie Amazon S3 mit aktivierter Versionierung und Cross-Region-Replikation, um die Datenhaltbarkeit und globale Replikation sicherzustellen.",
            "3": "Verwenden Sie Amazon EFS (Elastic File System) für den gemeinsamen Zugriff, da es automatische Replikation bietet, jedoch keine Datenhaltbarkeit über Regionen hinweg garantiert.",
            "4": "Verwenden Sie Amazon Glacier für die Archivspeicherung, da es kostengünstige Haltbarkeit bietet, jedoch keine Replikation über Regionen unterstützt."
        },
        "Correct Answer": "Verwenden Sie Amazon S3 mit aktivierter Versionierung und Cross-Region-Replikation, um die Datenhaltbarkeit und globale Replikation sicherzustellen.",
        "Explanation": "Amazon S3 ist für hohe Haltbarkeit und Verfügbarkeit ausgelegt, mit einer SLA von 99.999999999% (11 Neunen) Haltbarkeit. Durch die Aktivierung der Versionierung kann das Unternehmen mehrere Versionen eines Objekts aufbewahren, was bei versehentlichen Löschungen oder Überschreibungen hilft. Die Cross-Region-Replikation (CRR) ermöglicht es dem Unternehmen, Daten automatisch über verschiedene AWS-Regionen hinweg zu replizieren, was eine zusätzliche Schicht der Notfallwiederherstellung bietet und sicherstellt, dass kritische Daten verfügbar sind, selbst wenn eine Region einen Ausfall erleidet. Dies macht S3 zur besten Wahl für die Anforderungen des Unternehmens an Haltbarkeit und Replikation über mehrere Regionen.",
        "Other Options": [
            "Die Verwendung von Amazon EBS mit Snapshots bietet Haltbarkeit und die Möglichkeit, Backups zu erstellen, repliziert jedoch hauptsächlich Daten innerhalb derselben Availability Zone oder kann manuell in eine andere Region kopiert werden. EBS ist nicht für die automatische Cross-Region-Replikation ausgelegt, was es weniger geeignet für die Notfallwiederherstellung über mehrere Regionen macht.",
            "Amazon EFS bietet ein verwaltetes Dateisystem, auf das mehrere Instanzen zugreifen können, und bietet ein gewisses Maß an Redundanz und Verfügbarkeit. Es repliziert jedoch keine Daten automatisch über Regionen hinweg, was eine kritische Anforderung für die Notfallwiederherstellung in diesem Szenario ist.",
            "Amazon Glacier ist hauptsächlich für die langfristige Archivspeicherung konzipiert und bietet kostengünstige Haltbarkeit. Obwohl es hochgradig haltbar ist, unterstützt es keine automatische Replikation über Regionen hinweg, was es ungeeignet für die Bedürfnisse des Unternehmens nach sofortigem Zugriff und Notfallwiederherstellungsfähigkeiten macht."
        ]
    },
    {
        "Question Number": "43",
        "Situation": "Ein Unternehmen möchte sicherstellen, dass es eine widerstandsfähige Backup-Strategie für seine Amazon RDS-Datenbank hat, um Daten im Falle eines Ausfalls wiederherzustellen. Sie benötigen, dass Backups automatisch erstellt und bis zu 35 Tage lang aufbewahrt werden, mit der Möglichkeit, bei Bedarf zu einem bestimmten Zeitpunkt wiederherzustellen.",
        "Question": "Welche Konfiguration sollten sie verwenden, um diese Anforderungen zu erfüllen, und welche sind die wichtigsten Funktionen? (Wählen Sie zwei.)",
        "Options": {
            "1": "Konfigurieren Sie automatisierte Backups, um Daten bis zu 35 Tage lang aufzubewahren, mit inkrementellen Backups nach dem ersten vollständigen Snapshot. Automatisierte Backups ermöglichen die Wiederherstellung zu jedem 5-Minuten-Intervall innerhalb des Aufbewahrungszeitraums.",
            "2": "Verwenden Sie manuelle Snapshots täglich und bewahren Sie jeden Snapshot unbegrenzt auf, um die Datenwiederherstellung sicherzustellen, da automatisierte Backups keine Wiederherstellung zu einem bestimmten Zeitpunkt unterstützen.",
            "3": "Richten Sie eine Cross-Region-Replikation für Backups ein, um sicherzustellen, dass sie über mehrere Regionen hinweg widerstandsfähig sind, jedoch die Aufbewahrung auf 7 Tage beschränken, um Kosten zu reduzieren.",
            "4": "Implementieren Sie ein einmaliges vollständiges Backup und aktivieren Sie automatische RDS-Snapshots alle 5 Minuten, um die Anforderung der Wiederherstellung zu einem bestimmten Zeitpunkt zu erfüllen.",
            "5": "Aktivieren Sie kontinuierliche Backups zu Amazon S3 mit aktivierter Versionierung, um die Wiederherstellung zu jedem vorherigen Zustand innerhalb von 35 Tagen zu ermöglichen."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Konfigurieren Sie automatisierte Backups, um Daten bis zu 35 Tage lang aufzubewahren, mit inkrementellen Backups nach dem ersten vollständigen Snapshot. Automatisierte Backups ermöglichen die Wiederherstellung zu jedem 5-Minuten-Intervall innerhalb des Aufbewahrungszeitraums.",
            "Aktivieren Sie kontinuierliche Backups zu Amazon S3 mit aktivierter Versionierung, um die Wiederherstellung zu jedem vorherigen Zustand innerhalb von 35 Tagen zu ermöglichen."
        ],
        "Explanation": "Automatisierte Backups in Amazon RDS sind eine Funktion, die automatisch ein Backup Ihrer Datenbank erstellt, mit der Möglichkeit, diese Backups bis zu 35 Tage lang aufzubewahren. Sie ermöglichen auch die Wiederherstellung zu einem bestimmten Zeitpunkt, was bedeutet, dass Sie Ihre Datenbank zu einem bestimmten Zeitpunkt innerhalb des Aufbewahrungszeitraums wiederherstellen können. Dies erfüllt die Anforderung des Unternehmens nach automatischer Erstellung und Aufbewahrung von Backups sowie der Möglichkeit, zu einem bestimmten Zeitpunkt wiederherzustellen. Kontinuierliche Backups zu Amazon S3 mit aktivierter Versionierung erfüllen ebenfalls diese Anforderungen, da sie die Wiederherstellung zu jedem vorherigen Zustand innerhalb des Aufbewahrungszeitraums ermöglichen.",
        "Other Options": [
            "Manuelle Snapshots erfüllen nicht die Anforderung nach automatischer Erstellung von Backups. Darüber hinaus unterstützen sie zwar eine unbegrenzte Aufbewahrung, jedoch keine Wiederherstellung zu einem bestimmten Zeitpunkt, was eine Anforderung ist.",
            "Die Cross-Region-Replikation für Backups bietet zwar Widerstandsfähigkeit, jedoch erfüllt die Beschränkung der Aufbewahrung auf 7 Tage nicht die Anforderung nach einer Aufbewahrung von bis zu 35 Tagen.",
            "Die Implementierung eines einmaligen vollständigen Backups und die Aktivierung automatischer RDS-Snapshots alle 5 Minuten erfüllen nicht die Anforderung nach einer Aufbewahrung von bis zu 35 Tagen, da nicht angegeben wird, wie lange diese Snapshots aufbewahrt werden."
        ]
    },
    {
        "Question Number": "44",
        "Situation": "Ein E-Commerce-Unternehmen verarbeitet ein großes Volumen an Transaktionsdaten und möchte die Datenhaltbarkeit und Verfügbarkeit über Regionen hinweg sicherstellen. Sie benötigen eine zuverlässige Backup- und Replikationsstrategie, die es ihnen ermöglicht, Daten im Falle einer Katastrophe oder Datenkorruption schnell wiederherzustellen. Um diese Anforderungen zu erfüllen, muss das Unternehmen die am besten geeigneten AWS-Dienste und -Konfigurationen für die Implementierung von Backups und Cross-Region-Replikation bestimmen.",
        "Question": "Was sollten sie bei der Einrichtung dieser Backup- und Replikationsstrategie berücksichtigen?",
        "Options": {
            "1": "Verwenden Sie Amazon S3 mit aktivierter Cross-Region-Replikation, um Daten automatisch über verschiedene Regionen hinweg zu duplizieren, und richten Sie Lebenszyklusrichtlinien ein, um Backups zu verwalten.",
            "2": "Verlassen Sie sich auf Amazon EC2-Snapshots und übertragen Sie manuell Backup-Dateien über Regionen hinweg für jede Instanz.",
            "3": "Aktivieren Sie AWS Shield Advanced, um Daten im Falle einer Katastrophe zu replizieren und zu schützen.",
            "4": "Speichern Sie Backups nur in Amazon Glacier und rufen Sie sie im Notfall ab, um niedrigere Speicherkosten zu erzielen."
        },
        "Correct Answer": "Verwenden Sie Amazon S3 mit aktivierter Cross-Region-Replikation, um Daten automatisch über verschiedene Regionen hinweg zu duplizieren, und richten Sie Lebenszyklusrichtlinien ein, um Backups zu verwalten.",
        "Explanation": "Die Verwendung von Amazon S3 mit aktivierter Cross-Region-Replikation (CRR) ist die effektivste Strategie, um Datenhaltbarkeit und Verfügbarkeit über Regionen hinweg sicherzustellen. CRR repliziert automatisch Objekte in S3-Buckets in eine andere AWS-Region und bietet Redundanz sowie schnelle Wiederherstellungsoptionen im Falle von Datenverlust oder -korruption. Darüber hinaus ermöglicht das Einrichten von Lebenszyklusrichtlinien dem Unternehmen, die Datenaufbewahrung zu verwalten und ältere Daten in kostengünstigere Speicherklassen zu überführen, wodurch die Kosten optimiert werden, während sichergestellt wird, dass die Daten angemessen gesichert sind.",
        "Other Options": [
            "Sich auf Amazon EC2-Snapshots zu verlassen und Backup-Dateien manuell über Regionen hinweg zu übertragen, ist für ein großes Volumen an Transaktionsdaten nicht ideal. Snapshots sind an einzelne EC2-Instanzen gebunden und bieten nicht dasselbe Maß an Automatisierung und Effizienz wie S3 mit CRR. Diese Methode erhöht auch das Risiko menschlicher Fehler und kann zu inkonsistenten Backups führen.",
            "Die Aktivierung von AWS Shield Advanced konzentriert sich hauptsächlich auf DDoS-Schutz und bietet keine Backup- oder Replikationsfähigkeiten. Während es wichtig für die Sicherheit ist, erfüllt es nicht die Anforderungen des Unternehmens an Datenhaltbarkeit und Verfügbarkeit über Regionen hinweg.",
            "Backups nur in Amazon Glacier zu speichern, ist für schnelle Wiederherstellungsbedürfnisse nicht geeignet. Glacier ist für die langfristige Archivspeicherung konzipiert und die Abrufzeiten können Stunden betragen, was für Notfallwiederherstellungsszenarien, in denen sofortiger Zugriff auf Daten erforderlich ist, nicht ideal ist. Diese Option bietet auch keine Cross-Region-Replikation."
        ]
    },
    {
        "Question Number": "45",
        "Situation": "Ein Unternehmen richtet einen Elastic Load Balancer (ELB) in AWS ein, um den eingehenden Verkehr auf mehrere EC2-Instanzen in verschiedenen Availability Zones (AZs) zu verteilen. Sie möchten, dass der Load Balancer über das Internet zugänglich ist, möchten jedoch auch den Zugriff auf sowohl öffentliche als auch private Instanzen innerhalb ihres VPC steuern.",
        "Question": "Welche Konfiguration sollten sie wählen, und warum ist dieses Setup vorteilhaft für die Handhabung von Verkehr in großem Maßstab?",
        "Options": {
            "1": "Konfigurieren Sie einen internetfähigen ELB mit öffentlichen IPs, die den Knoten zugewiesen sind, sodass er den Verkehr sowohl zu öffentlichen als auch zu privaten EC2-Instanzen innerhalb des VPC leiten kann. Dieses Setup unterstützt das Skalieren über AZs hinweg und bietet hohe Verfügbarkeit.",
            "2": "Verwenden Sie einen internen Load Balancer mit privaten IPs, um den Zugriff auf das VPC einzuschränken und sicherzustellen, dass nur interner Verkehr über die Instanzen verteilt wird.",
            "3": "Richten Sie einen internetfähigen ELB mit nur privaten EC2-Instanzen ein, um den öffentlichen Zugriff zu beschränken und gleichzeitig die Skalierbarkeit aufrechtzuerhalten.",
            "4": "Konfigurieren Sie den Load Balancer als Einzelknoten-Setup in einer AZ, um die Ressourcennutzung zu optimieren und das Skalieren über mehrere AZs hinweg zu beschränken."
        },
        "Correct Answer": "Konfigurieren Sie einen internetfähigen ELB mit öffentlichen IPs, die den Knoten zugewiesen sind, sodass er den Verkehr sowohl zu öffentlichen als auch zu privaten EC2-Instanzen innerhalb des VPC leiten kann. Dieses Setup unterstützt das Skalieren über AZs hinweg und bietet hohe Verfügbarkeit.",
        "Explanation": "Ein internetfähiger Elastic Load Balancer (ELB) ist dafür ausgelegt, eingehenden Verkehr aus dem Internet zu verarbeiten und Anfragen sowohl an öffentliche als auch an private EC2-Instanzen weiterzuleiten. Durch die Zuweisung öffentlicher IPs an den ELB kann er direkt Verkehr von externen Quellen empfangen und gleichzeitig internen Verkehr zu privaten Instanzen verwalten. Diese Konfiguration ermöglicht hohe Verfügbarkeit und Fehlertoleranz, indem der Verkehr auf mehrere EC2-Instanzen in verschiedenen Availability Zones (AZs) verteilt wird, sodass, wenn eine AZ ausfällt, die anderen weiterhin die Last bewältigen können. Dieses Setup ist vorteilhaft für die Handhabung von Verkehr in großem Maßstab, da es eine nahtlose Skalierung der Ressourcen basierend auf der Nachfrage ermöglicht und gleichzeitig die Kontrolle über den Zugriff auf die Instanzen aufrechterhält.",
        "Other Options": [
            "Die Verwendung eines internen Load Balancers mit privaten IPs schränkt den Zugriff nur auf internen Verkehr innerhalb des VPC ein, was nicht der Anforderung entspricht, über das Internet zugänglich zu sein. Diese Option würde externen Benutzern den Zugriff auf die auf den EC2-Instanzen gehosteten Dienste verwehren.",
            "Die Einrichtung eines internetfähigen ELB mit nur privaten EC2-Instanzen würde nicht funktionieren, da private Instanzen nicht direkt aus dem Internet zugänglich sind. Diese Konfiguration würde verhindern, dass der ELB den Verkehr effektiv leitet, da er keine öffentlich zugänglichen Instanzen hätte, um eingehende Anfragen zu bearbeiten.",
            "Die Konfiguration des Load Balancers als Einzelknoten-Setup in einer AZ schränkt die Vorteile des Lastenausgleichs, wie hohe Verfügbarkeit und Fehlertoleranz, ein. Dieses Setup nutzt nicht die Vorteile der Verteilung des Verkehrs über mehrere AZs hinweg, was entscheidend für die Handhabung von Verkehr in großem Maßstab ist."
        ]
    },
    {
        "Question Number": "46",
        "Situation": "Ein Startup möchte seine monatlichen Netzwerk Kosten auf AWS genau überwachen und Benachrichtigungen erhalten, wenn die Ausgaben den budgetierten Betrag überschreiten. Sie möchten auch die Datenübertragungskosten über die Regionen im Laufe der Zeit analysieren.",
        "Question": "Welche AWS-Kostenmanagement-Tools sollten sie verwenden, um diese Ziele zu erreichen?",
        "Options": {
            "1": "AWS Cost and Usage Report und AWS Trusted Advisor",
            "2": "AWS Budgets und AWS Cost Explorer",
            "3": "AWS Trusted Advisor und AWS Budgets",
            "4": "AWS Support und AWS Cost Explorer"
        },
        "Correct Answer": "AWS Budgets und AWS Cost Explorer",
        "Explanation": "AWS Budgets ermöglicht es Benutzern, benutzerdefinierte Kosten- und Nutzungsbudgets festzulegen, die Benachrichtigungen auslösen können, wenn die Ausgaben die definierten Schwellenwerte überschreiten. Dies ist entscheidend für das Startup, um seine monatlichen Netzwerk Kosten zu überwachen und Benachrichtigungen zu erhalten. AWS Cost Explorer bietet detaillierte Einblicke in Kosten- und Nutzungsmuster im Laufe der Zeit, was nützlich ist, um die Datenübertragungskosten über die Regionen zu analysieren. Zusammen erfüllen diese Tools die Anforderungen des Startups an die Budgetüberwachung und Kostenanalyse effektiv.",
        "Other Options": [
            "AWS Cost and Usage Report bietet detaillierte Abrechnungsinformationen, bietet jedoch keine Benachrichtigungsfunktionen. AWS Trusted Advisor bietet Empfehlungen zu Best Practices, ist jedoch nicht speziell für die Budgetüberwachung oder detaillierte Kostenanalyse konzipiert.",
            "Obwohl AWS Budgets korrekt für die Budgetüberwachung identifiziert wurde, ist AWS Cost Explorer die bessere Wahl für die Analyse von Kosten im Laufe der Zeit im Vergleich zu AWS Trusted Advisor, das sich auf die Ressourcennutzung konzentriert und nicht auf das Kostenmanagement.",
            "AWS Support ist ein Service für technische Unterstützung und bietet keine Funktionen für das Kostenmanagement. AWS Cost Explorer ist nützlich zur Analyse von Kosten, aber ohne AWS Budgets würde dem Startup die erforderliche Benachrichtigungsfunktionalität für die Budgetüberwachung fehlen."
        ]
    },
    {
        "Question Number": "47",
        "Situation": "Eine E-Commerce-Anwendung verwendet Amazon DynamoDB, um Produktkatalogdaten zu speichern, und muss während Blitzverkäufen ein hohes Volumen an Leseanfragen verarbeiten. Das Anwendungsteam möchte die Latenz für Leseanfragen reduzieren, um sicherzustellen, dass Benutzer die Produktdetails nahezu sofort abrufen können. Sie benötigen jedoch keine stark konsistenten Lesevorgänge.",
        "Question": "Welche Lösung würde diese Anforderungen am besten erfüllen?",
        "Options": {
            "1": "DynamoDB Auto Scaling aktivieren, um die erhöhte Last während Blitzverkäufen zu bewältigen",
            "2": "DynamoDB mit Amazon ElastiCache für Redis integrieren, um schnelleren Lesezugriff zu ermöglichen",
            "3": "DynamoDB Accelerator (DAX) aktivieren, um einen In-Memory-Cache für leseintensive Workloads bereitzustellen",
            "4": "DynamoDB-Global-Tabellen verwenden, um den Produktkatalog über mehrere Regionen zu replizieren"
        },
        "Correct Answer": "DynamoDB Accelerator (DAX) aktivieren, um einen In-Memory-Cache für leseintensive Workloads bereitzustellen",
        "Explanation": "DynamoDB Accelerator (DAX) ist speziell dafür konzipiert, schnelles In-Memory-Caching für DynamoDB bereitzustellen, was die Lese-Latenz erheblich reduziert. Da die Anwendung keine stark konsistenten Lesevorgänge benötigt, kann DAX eventual consistency Reads mit sehr niedriger Latenz bedienen, was es ideal macht, um hohe Volumina an Leseanfragen während Blitzverkäufen zu verarbeiten. DAX kann Verkehrsspitzen bewältigen und die Leistung von leseintensiven Workloads verbessern, sodass Benutzer die Produktdetails nahezu sofort abrufen können.",
        "Other Options": [
            "Die Aktivierung von DynamoDB Auto Scaling würde helfen, die erhöhte Last zu verwalten, indem die Lese- und Schreibkapazität automatisch an die Verkehrsmuster angepasst wird. Es adressiert jedoch nicht direkt das Latenzproblem für Leseanfragen, das während Blitzverkäufen kritisch ist.",
            "Die Integration von DynamoDB mit Amazon ElastiCache für Redis könnte die Leseleistung verbessern, indem häufig abgerufene Daten zwischengespeichert werden. Es fügt jedoch Komplexität zur Architektur hinzu und ist möglicherweise nicht so eng mit DynamoDB integriert wie DAX, das speziell für diesen Zweck optimiert ist.",
            "Die Verwendung von DynamoDB-Global-Tabellen würde die Replikation des Produktkatalogs über mehrere Regionen ermöglichen, die Verfügbarkeit verbessern und die Latenz für Benutzer an verschiedenen geografischen Standorten reduzieren. Diese Lösung adressiert jedoch nicht direkt die Notwendigkeit, die Latenz während einer hohen Leseanforderung zu reduzieren, da sie sich mehr auf Datenverfügbarkeit und Redundanz konzentriert."
        ]
    },
    {
        "Question Number": "48",
        "Situation": "Ein Online-Gaming-Unternehmen muss Spieldaten speichern, einschließlich Profile, Spielstände und Inventarartikel. Die Daten müssen hochverfügbar und langlebig sein und in der Lage sein, Millionen von Lese- und Schreibanfragen pro Sekunde zu verarbeiten. Das Unternehmen erwartet auch ein schnelles Wachstum und benötigt eine Speicherlösung, die nahtlos skalieren kann, um die steigende Nachfrage zu erfüllen, ohne die Leistung zu beeinträchtigen.",
        "Question": "Welche Speicherlösung sollte der Lösungsarchitekt empfehlen, um diese Anforderungen zu erfüllen?",
        "Options": {
            "1": "Amazon RDS für MySQL",
            "2": "Amazon DynamoDB",
            "3": "Amazon S3 Intelligent-Tiering",
            "4": "Amazon Redshift"
        },
        "Correct Answer": "Amazon DynamoDB",
        "Explanation": "Amazon DynamoDB ist ein vollständig verwalteter NoSQL-Datenbankdienst, der hohe Verfügbarkeit und Langlebigkeit bietet. Er ist darauf ausgelegt, Millionen von Lese- und Schreibanfragen pro Sekunde zu verarbeiten, was ihn ideal für Anwendungen mit hohen Durchsatzanforderungen macht, wie z.B. Online-Gaming. DynamoDB skaliert automatisch, um die steigende Nachfrage zu bewältigen, ohne die Leistung zu beeinträchtigen, was perfekt mit dem Bedarf des Unternehmens an einer Speicherlösung übereinstimmt, die schnell wachsen kann, während die Spielerbasis sich erweitert. Darüber hinaus bietet es Funktionen wie automatische Backups und globale Replikation, die die Datenhaltbarkeit und -verfügbarkeit gewährleisten.",
        "Other Options": [
            "Amazon RDS für MySQL ist ein relationaler Datenbankdienst, der für strukturierte Daten geeignet ist und SQL-Abfragen unterstützt. Es kann jedoch möglicherweise nicht das gleiche Durchsatzniveau wie DynamoDB bewältigen und erfordert mehr Verwaltung für die Skalierung, was es weniger ideal für die schnell wachsenden und hochverfügbaren Anforderungen einer Online-Gaming-Plattform macht.",
            "Amazon S3 Intelligent-Tiering ist ein Objektspeicherdienst, der für die Speicherung großer Mengen unstrukturierter Daten konzipiert ist. Obwohl er Langlebigkeit und Verfügbarkeit bietet, ist er nicht für hochfrequente Lese- und Schreibvorgänge optimiert, wie sie für Spieldaten in einem Online-Gaming-Kontext erforderlich sind, was ihn für dieses Szenario ungeeignet macht.",
            "Amazon Redshift ist ein Data-Warehousing-Dienst, der für analytische Abfragen und Berichterstattung optimiert ist. Er ist nicht für hochdynamische Transaktionslasten wie die für das Echtzeit-Management von Spieldaten benötigten konzipiert, was ihn zu einer ungeeigneten Wahl für die skizzierten Anforderungen macht."
        ]
    },
    {
        "Question Number": "49",
        "Situation": "Ein Unternehmen entwirft eine sichere VPC-Architektur für seine Anwendungen auf AWS. Sie müssen sowohl den eingehenden als auch den ausgehenden Datenverkehr zu bestimmten Instanzen innerhalb eines Subnetzes steuern und zusätzliche Sicherheitskontrollen auf Subnetzebene anwenden.",
        "Question": "Welche der folgenden Erklärungen beschreibt korrekt die Verwendung und Unterschiede zwischen NACLs und Sicherheitsgruppen zu diesem Zweck? (Wählen Sie zwei aus.)",
        "Options": {
            "1": "NACLs arbeiten auf Instanzebene und bieten zustandsbehaftete Datenverkehrsfilterung, während Sicherheitsgruppen auf Subnetzebene arbeiten und zustandslose Kontrollen für jede Anfrage bieten.",
            "2": "Sicherheitsgruppen werden auf Instanzebene angewendet und bieten zustandsbehaftete Kontrollen, die spezifische IP-Adressen erlauben oder verweigern, während NACLs auf Subnetzebene angewendet werden und so konfiguriert werden können, dass sie spezifische IP-Bereiche zustandslos erlauben oder verweigern.",
            "3": "NACLs gelten nur für eingehenden Datenverkehr auf Subnetzebene, während Sicherheitsgruppen sowohl eingehenden als auch ausgehenden Datenverkehr steuern und standardmäßig zustandsbehaftet sind.",
            "4": "Sicherheitsgruppen und NACLs arbeiten beide auf Instanzebene, aber NACLs sind zustandsbehaftet und ermöglichen eine dynamische Paketfilterung über mehrere Instanzen hinweg.",
            "5": "NACLs bieten eine zusätzliche Sicherheitsebene, indem sie als Firewall fungieren, um den Datenverkehr in und aus einem oder mehreren Subnetzen unabhängig von Sicherheitsgruppen zu steuern."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Sicherheitsgruppen werden auf Instanzebene angewendet und bieten zustandsbehaftete Kontrollen, die spezifische IP-Adressen erlauben oder verweigern, während NACLs auf Subnetzebene angewendet werden und so konfiguriert werden können, dass sie spezifische IP-Bereiche zustandslos erlauben oder verweigern.",
            "NACLs bieten eine zusätzliche Sicherheitsebene, indem sie als Firewall fungieren, um den Datenverkehr in und aus einem oder mehreren Subnetzen unabhängig von Sicherheitsgruppen zu steuern."
        ],
        "Explanation": "Sicherheitsgruppen in AWS werden auf Instanzebene angewendet und bieten zustandsbehaftete Kontrollen, was bedeutet, dass sie den Zustand von Netzwerkverbindungen verfolgen und automatisch Rückverkehre für erlaubte ausgehende Verbindungen zulassen. Sie können so konfiguriert werden, dass sie spezifische IP-Adressen erlauben oder verweigern. Auf der anderen Seite bieten Network Access Control Lists (NACLs) auf Subnetzebene zustandslose Kontrollen, was bedeutet, dass sie jedes Paket einzeln bewerten, ohne bestehende Verbindungen zu berücksichtigen. Sie können so konfiguriert werden, dass sie spezifische IP-Bereiche erlauben oder verweigern. NACLs bieten auch eine zusätzliche Sicherheitsebene, indem sie als Firewall fungieren, um den Datenverkehr in und aus einem oder mehreren Subnetzen unabhängig von Sicherheitsgruppen zu steuern.",
        "Other Options": [
            "NACLs arbeiten auf Subnetzebene und bieten zustandslose Datenverkehrsfilterung, nicht auf Instanzebene. Auch Sicherheitsgruppen arbeiten auf Instanzebene und bieten zustandsbehaftete Kontrollen, nicht auf Subnetzebene.",
            "NACLs gelten sowohl für eingehenden als auch für ausgehenden Datenverkehr auf Subnetzebene, nicht nur für eingehenden Datenverkehr.",
            "Sicherheitsgruppen und NACLs arbeiten nicht beide auf Instanzebene. Sicherheitsgruppen arbeiten auf Instanzebene, während NACLs auf Subnetzebene arbeiten. Auch sind NACLs zustandslos, nicht zustandsbehaftet."
        ]
    },
    {
        "Question Number": "50",
        "Situation": "Ein Medienunternehmen richtet eine serverlose Architektur ein, um den Ansturm von Video-Uploads während der Feiertage von seinen Benutzern zu bewältigen. Sie möchten, dass die Einrichtung vollständig verwaltet wird, automatisch skaliert, um unvorhersehbaren Verkehr zu bewältigen, und den Benutzern eine nahtlose Authentifizierung ermöglicht. Der ideale Workflow sollte Video-Uploads, die Verarbeitung in mehreren Formaten und die Speicherung umfassen, alles mit minimalem Aufwand.",
        "Question": "Welche Kombination von AWS-Diensten würde diese Architektur am besten unterstützen und was macht sie zur optimalen Wahl?",
        "Options": {
            "1": "Amazon Cognito für die Benutzerauthentifizierung nutzen, um sicher Tokens des Identitätsanbieters gegen temporäre AWS-Anmeldeinformationen auszutauschen, was direkte Uploads in einen S3-Bucket ermöglicht. Eine AWS Lambda-Funktion bei jedem Upload auslösen, um die Videoverarbeitungspipeline zu starten.",
            "2": "Eine Flotte von Amazon EC2-Instanzen für die Benutzerauthentifizierung, Video-Uploads und Transkodierung nutzen, wobei Videodateien auf angehängten EBS-Volumes gespeichert werden. Die Instanzen manuell skalieren, um den Nachfrage-Spitzen gerecht zu werden.",
            "3": "Amazon S3 für die Videospeicherung einrichten, eine AWS Lambda-Funktion pro Video-Upload zur Verarbeitung initiieren und die Verarbeitungsjobdetails in einer Amazon RDS-Datenbank für Resilienz aufzeichnen.",
            "4": "Benutzer mit IAM-Rollen authentifizieren, Videos in DynamoDB speichern und EC2-Instanzen für die Verarbeitungsaufgaben verwenden, wobei die finalen verarbeiteten Videos zur Abholung wieder in S3 gespeichert werden."
        },
        "Correct Answer": "Amazon Cognito für die Benutzerauthentifizierung nutzen, um sicher Tokens des Identitätsanbieters gegen temporäre AWS-Anmeldeinformationen auszutauschen, was direkte Uploads in einen S3-Bucket ermöglicht. Eine AWS Lambda-Funktion bei jedem Upload auslösen, um die Videoverarbeitungspipeline zu starten.",
        "Explanation": "Diese Option ist optimal, da sie vollständig verwaltete Dienste nutzt, die automatisch skalieren und minimalen Betriebsaufwand erfordern. Amazon Cognito bietet eine nahtlose Benutzerauthentifizierung, die es Benutzern ermöglicht, Videos direkt in einen S3-Bucket hochzuladen, der für hohe Verfügbarkeit und Langlebigkeit ausgelegt ist. Die Verwendung von AWS Lambda zur Auslösung der Videoverarbeitung bei jedem Upload stellt sicher, dass die Verarbeitung automatisch mit der Anzahl der Uploads skaliert und unvorhersehbaren Verkehr effizient bewältigt. Diese Architektur entspricht perfekt den Anforderungen, serverlos und vollständig verwaltet zu sein.",
        "Other Options": [
            "Die Nutzung einer Flotte von Amazon EC2-Instanzen für die Benutzerauthentifizierung, Video-Uploads und Transkodierung bringt erheblichen Verwaltungsaufwand mit sich und bietet keine automatische Skalierung. EC2-Instanzen erfordern manuelle Eingriffe zur Skalierung, was für unvorhersehbare Verkehrsmuster nicht ideal ist und diese Option weniger geeignet macht.",
            "Die Einrichtung von Amazon S3 für die Videospeicherung und die Initiierung einer AWS Lambda-Funktion pro Video-Upload zur Verarbeitung ist ein guter Ansatz, aber die Aufzeichnung der Verarbeitungsjobdetails in einer Amazon RDS-Datenbank fügt unnötige Komplexität und Verwaltungsaufwand hinzu. Der Fokus sollte darauf liegen, den Aufwand zu minimieren, und die Verwendung einer Datenbank zu diesem Zweck könnte in einer vollständig verwalteten serverlosen Architektur nicht erforderlich sein.",
            "Die Authentifizierung von Benutzern mit IAM-Rollen ist in diesem Kontext nicht geeignet, da IAM-Rollen typischerweise für AWS-Dienstberechtigungen und nicht für die Benutzerauthentifizierung verwendet werden. Videos in DynamoDB zu speichern, ist ebenfalls nicht ideal für große Videodateien, da S3 speziell für solche Anwendungsfälle konzipiert ist. Darüber hinaus widerspricht die Verwendung von EC2-Instanzen für Verarbeitungsaufgaben der Anforderung an eine serverlose Architektur."
        ]
    },
    {
        "Question Number": "51",
        "Situation": "Ein Unternehmen verwendet Amazon Elastic Block Store (EBS) zur Speicherung von Daten, die an ihre EC2-Instanzen innerhalb einer einzelnen Availability Zone (AZ) in der Region us-east-1 angehängt sind. Um die Datenhaltbarkeit und Resilienz zu verbessern, möchte das Unternehmen sicherstellen, dass ihre Daten auch im Falle eines AZ-Ausfalls geschützt sind.",
        "Question": "Welche Strategie bietet die beste Resilienz für ihre EBS-Daten?",
        "Options": {
            "1": "Verwenden Sie EBS-Snapshots, die in Amazon S3 gespeichert sind, und kopieren Sie sie in eine andere Region, um eine plattformübergreifende Notfallwiederherstellung zu ermöglichen.",
            "2": "Hängen Sie EBS-Volumes an mehrere EC2-Instanzen in verschiedenen AZs innerhalb derselben Region für Redundanz an.",
            "3": "Konfigurieren Sie EBS-Volumes, um automatisch über alle Availability Zones innerhalb der Region zu replizieren.",
            "4": "Verwenden Sie S3 zur direkten Speicherung von Daten anstelle von EBS, da es eine höhere Haltbarkeit und Verfügbarkeit über AZs hinweg bietet."
        },
        "Correct Answer": "Verwenden Sie EBS-Snapshots, die in Amazon S3 gespeichert sind, und kopieren Sie sie in eine andere Region, um eine plattformübergreifende Notfallwiederherstellung zu ermöglichen.",
        "Explanation": "Die Verwendung von EBS-Snapshots, die in Amazon S3 gespeichert sind, und deren Kopie in eine andere Region bietet die beste Resilienz für EBS-Daten, da sichergestellt wird, dass die Daten nicht nur gesichert, sondern auch an einem anderen geografischen Standort gespeichert sind. Dies schützt vor Datenverlust aufgrund eines vollständigen Ausfalls einer Availability Zone, da die Snapshots in einer anderen Region wiederhergestellt werden können. Diese Strategie nutzt die Haltbarkeit von Amazon S3 und die plattformübergreifenden Möglichkeiten, um die Optionen zur Notfallwiederherstellung zu verbessern.",
        "Other Options": [
            "Das Anhängen von EBS-Volumes an mehrere EC2-Instanzen in verschiedenen AZs innerhalb derselben Region bietet keine Resilienz gegen einen AZ-Ausfall, da EBS-Volumes nur an eine Instanz gleichzeitig angehängt werden können. Während es möglicherweise ein gewisses Maß an Redundanz bietet, schützt es nicht vor dem Verlust der gesamten AZ.",
            "Die Konfiguration von EBS-Volumes zur automatischen Replikation über alle Availability Zones innerhalb der Region ist kein von EBS angebotenes Feature. EBS-Volumes sind an eine bestimmte AZ gebunden, und während Sie Snapshots erstellen können, gibt es keine automatische Replikation über AZs. Daher verbessert diese Option nicht die Resilienz gegen AZ-Ausfälle.",
            "Die Verwendung von S3 zur direkten Speicherung von Daten anstelle von EBS bietet zwar eine höhere Haltbarkeit und Verfügbarkeit über AZs hinweg, ist jedoch möglicherweise nicht für alle Anwendungsfälle geeignet, insbesondere für solche, die Blockspeicher erfordern. Darüber hinaus adressiert es nicht direkt den Bedarf an EBS-Datenresilienz im Kontext von EC2-Instanzen, da es ein anderes Speicherparadigma umfasst."
        ]
    },
    {
        "Question Number": "52",
        "Situation": "Ein Finanzdienstleistungsunternehmen migriert sein lokales Data Warehouse zu AWS. Das Data Warehouse verarbeitet große Mengen an Transaktionsdaten und erfordert eine hohe Durchsatzrate für ETL-Vorgänge. Das Unternehmen möchte die Kosten minimieren und gleichzeitig Skalierbarkeit und Leistung sicherstellen.",
        "Question": "Welchen AWS-Dienst sollte der Lösungsarchitekt für die Speicherung des Data Warehouses empfehlen?",
        "Options": {
            "1": "Amazon RDS für PostgreSQL",
            "2": "Amazon Redshift",
            "3": "Amazon DynamoDB",
            "4": "Amazon Aurora"
        },
        "Correct Answer": "Amazon Redshift",
        "Explanation": "Amazon Redshift ist ein vollständig verwalteter, petabyte-großer Data Warehouse-Dienst, der speziell für analytische Workloads entwickelt wurde. Er ist für hohen Durchsatz optimiert und kann große Mengen an Transaktionsdaten effizient verarbeiten, was ihn ideal für ETL-Vorgänge macht. Die spaltenbasierte Speicherung und die parallelen Verarbeitungsfähigkeiten von Redshift ermöglichen eine schnelle Abfrageleistung und Skalierbarkeit, die den Anforderungen des Unternehmens an Leistung und Kosteneffizienz während der Migration ihres Data Warehouses zu AWS entsprechen.",
        "Other Options": [
            "Amazon RDS für PostgreSQL ist ein relationaler Datenbankdienst, der für transaktionale Workloads geeignet ist, jedoch nicht für große Datenlager und Analysen wie Redshift optimiert ist. Er bietet möglicherweise nicht das gleiche Maß an Leistung und Skalierbarkeit für ETL-Vorgänge bei großen Datensätzen.",
            "Amazon DynamoDB ist ein NoSQL-Datenbankdienst, der für hohe Verfügbarkeit und latenzarmen Zugriff auf Schlüssel-Wert- und Dokumentdaten ausgelegt ist. Während es für bestimmte Arten von Anwendungen hervorragend geeignet ist, ist es nicht für traditionelle Data-Warehousing-Bedürfnisse geeignet, insbesondere nicht für komplexe Abfragen und Analysen großer Datensätze.",
            "Amazon Aurora ist ein relationaler Datenbankdienst, der hohe Leistung und Verfügbarkeit bietet. Allerdings ist er, wie RDS, nicht speziell für Data Warehousing konzipiert und bietet möglicherweise nicht das gleiche Maß an Leistung für analytische Abfragen und ETL-Vorgänge wie Amazon Redshift."
        ]
    },
    {
        "Question Number": "53",
        "Situation": "Ein Medienproduktionsunternehmen benötigt leistungsstarken Speicher für die Videobearbeitung, möchte jedoch die Kosten niedrig halten. Sie haben eine Mischung aus hochleistungsfähigen und niedrigleistungsfähigen Workloads und müssen geeignete Blockspeichertypen auswählen.",
        "Question": "Welche Kombination von Blockspeicheroptionen sollte das Unternehmen verwenden, um die Kosten zu optimieren und gleichzeitig die Leistungsanforderungen zu erfüllen?",
        "Options": {
            "1": "Provisioned IOPS SSD (io2) für alle Volumes",
            "2": "General Purpose SSD (gp3) für hochleistungsfähige Aufgaben und Throughput Optimized HDD (st1) für weniger leistungsstarke Aufgaben",
            "3": "Cold HDD (sc1) für alle Volumes",
            "4": "Verwenden Sie Amazon S3 anstelle von Blockspeicher für alle Daten"
        },
        "Correct Answer": "General Purpose SSD (gp3) für hochleistungsfähige Aufgaben und Throughput Optimized HDD (st1) für weniger leistungsstarke Aufgaben",
        "Explanation": "Diese Kombination ermöglicht es dem Medienproduktionsunternehmen, Leistung und Kosten effektiv auszubalancieren. General Purpose SSD (gp3) bietet ein gutes Gleichgewicht zwischen Preis und Leistung für hochleistungsfähige Workloads, wie z.B. Videobearbeitung, bei denen niedrige Latenz und hoher Durchsatz entscheidend sind. Auf der anderen Seite ist Throughput Optimized HDD (st1) kosteneffizienter für weniger leistungsstarke Aufgaben, wie z.B. das Speichern von weniger häufig abgerufenen Videodateien oder Backups. Dieser hybride Ansatz optimiert die Kosten und erfüllt gleichzeitig die Leistungsanforderungen für beide Arten von Workloads.",
        "Other Options": [
            "Provisioned IOPS SSD (io2) für alle Volumes wäre für weniger leistungsstarke Aufgaben unnötig teuer, da es für hoch IOPS-Workloads ausgelegt ist und keine Kosteneffizienz für Aufgaben bietet, die diese Leistung nicht erfordern.",
            "Cold HDD (sc1) für alle Volumes würde die Leistungsanforderungen für hochleistungsfähige Aufgaben wie Videobearbeitung nicht erfüllen, da sc1 für seltenen Zugriff ausgelegt ist und eine viel niedrigere Leistung im Vergleich zu SSD-Optionen hat.",
            "Die Verwendung von Amazon S3 anstelle von Blockspeicher für alle Daten ist möglicherweise nicht für Videobearbeitungs-Workloads geeignet, die niedrige Latenz und hohen Durchsatz erfordern, da S3 Objektspeicher ist und nicht für den blockbasierten Zugriff optimiert ist, der für hochleistungsfähige Anwendungen benötigt wird."
        ]
    },
    {
        "Question Number": "54",
        "Situation": "Ein Unternehmen möchte sicheren Zugang für ein Team von Entwicklern einrichten, die an einem Projekt in einem gemeinsamen AWS-Konto arbeiten. Das Team benötigt flexiblen Zugang zu bestimmten AWS-Ressourcen innerhalb des Kontos, und der Zugang muss pro Benutzer widerrufbar sein.",
        "Question": "Welcher der folgenden Ansätze ist der SICHERSTE und FLEXIBELSTE, um den Zugang zu diesen Ressourcen zu gewähren?",
        "Options": {
            "1": "Erstellen Sie IAM-Benutzer für jeden Entwickler mit spezifischen Berechtigungen und Richtlinien",
            "2": "Erstellen Sie einen einzelnen IAM-Benutzer mit Zugriffsschlüsseln, die unter den Entwicklern geteilt werden",
            "3": "Verwenden Sie AWS IAM Identity Center (AWS Single Sign-On), um Rollen jedem Entwickler zuzuweisen",
            "4": "Weisen Sie eine IAM-Rolle den gemeinsamen Ressourcen zu und gewähren Sie Berechtigungen an eine IAM-Gruppe, die die Entwickler enthält"
        },
        "Correct Answer": "Verwenden Sie AWS IAM Identity Center (AWS Single Sign-On), um Rollen jedem Entwickler zuzuweisen",
        "Explanation": "Die Verwendung von AWS IAM Identity Center (AWS Single Sign-On) ermöglicht eine zentrale Verwaltung des Benutzerzugriffs über AWS-Konten und Anwendungen hinweg. Es bietet eine flexible und sichere Möglichkeit, Rollen einzelnen Entwicklern zuzuweisen, sodass sie nur auf die Ressourcen zugreifen können, die sie benötigen. Dieser Ansatz ermöglicht auch eine einfache Widerrufung des Zugangs auf pro Benutzer-Basis, was für die Aufrechterhaltung der Sicherheit in einer gemeinsamen Umgebung unerlässlich ist. Darüber hinaus unterstützt IAM Identity Center die Integration mit bestehenden Identitätsanbietern, was die Sicherheit und Benutzerverwaltung verbessert.",
        "Other Options": [
            "Das Erstellen von IAM-Benutzern für jeden Entwickler mit spezifischen Berechtigungen und Richtlinien ist ein gültiger Ansatz, kann jedoch unhandlich werden, wenn das Team wächst. Jeder Benutzer müsste individuell verwaltet werden, und der Widerruf des Zugangs würde erfordern, dass die Berechtigungen jedes Benutzers geändert werden, was weniger effizient ist als die Verwendung von IAM Identity Center.",
            "Das Erstellen eines einzelnen IAM-Benutzers mit Zugriffsschlüsseln, die unter den Entwicklern geteilt werden, ist äußerst unsicher. Dieser Ansatz verstößt gegen das Prinzip der minimalen Berechtigung und erschwert die Nachverfolgung individueller Benutzeraktionen. Wenn die Zugriffsschlüssel kompromittiert werden, ist der Zugang aller Entwickler gefährdet, und der Widerruf des Zugangs für einen Benutzer würde erfordern, dass die Schlüssel für alle geändert werden.",
            "Das Zuweisen einer IAM-Rolle zu den gemeinsamen Ressourcen und das Gewähren von Berechtigungen an eine IAM-Gruppe, die die Entwickler enthält, ist ein vernünftiger Ansatz, bietet jedoch nicht die Flexibilität und die einfache Verwaltung, die AWS IAM Identity Center bietet. Während es ein gewisses Maß an Zugriffskontrolle ermöglicht, bietet es nicht das gleiche Maß an individueller Benutzerverwaltung und Widerrufsmöglichkeiten wie IAM Identity Center."
        ]
    },
    {
        "Question Number": "55",
        "Situation": "Ein multinationales E-Commerce-Unternehmen hat weltweit Nutzer, die schnellen Zugriff auf ihre Bestellinformationen benötigen. Die Anwendung erfordert eine Multi-Region-Replikation von Daten, um hohe Verfügbarkeit und niedrige Latenz für Nutzer auf verschiedenen Kontinenten sicherzustellen. Darüber hinaus muss das System potenzielle Konflikte elegant handhaben, wenn Aktualisierungen gleichzeitig in verschiedenen Regionen erfolgen.",
        "Question": "Welche Funktion von DynamoDB Global Tables erfüllt diese Anforderungen am besten?",
        "Options": {
            "1": "Multi-Master-Replikation mit \"Last Writer Wins\"-Konfliktauflösung",
            "2": "Single-Master-Replikation zur Sicherstellung der Datenkonsistenz",
            "3": "Globale starke Konsistenz für alle Lese- und Schreibvorgänge über Regionen hinweg",
            "4": "Strikte FIFO (First-In-First-Out)-Konfliktauflösung über Regionen hinweg"
        },
        "Correct Answer": "Multi-Master-Replikation mit 'Last Writer Wins'-Konfliktauflösung",
        "Explanation": "DynamoDB Global Tables nutzen die Multi-Master-Replikation, die es ermöglicht, Aktualisierungen gleichzeitig in mehreren Regionen vorzunehmen. Dies ist entscheidend für ein multinationales E-Commerce-Unternehmen, das schnellen Zugriff auf Bestellinformationen über verschiedene Kontinente hinweg bereitstellen muss. Die 'Last Writer Wins'-Konfliktauflösungsstrategie stellt sicher, dass, wenn Aktualisierungen gleichzeitig in verschiedenen Regionen erfolgen, die aktuellste Aktualisierung (basierend auf einem Zeitstempel) beibehalten wird, was eine elegante Handhabung potenzieller Konflikte ermöglicht. Diese Funktion unterstützt hohe Verfügbarkeit und niedrige Latenz und erfüllt die Anforderungen der Anwendung effektiv.",
        "Other Options": [
            "Die Single-Master-Replikation würde die Anforderung an hohe Verfügbarkeit und niedrige Latenz über mehrere Regionen hinweg nicht erfüllen, da sie Aktualisierungen auf eine einzige Region beschränkt und möglicherweise zu Verzögerungen für Nutzer in anderen Regionen führen könnte.",
            "Globale starke Konsistenz für alle Lese- und Schreibvorgänge über Regionen hinweg wird in DynamoDB Global Tables nicht unterstützt, da dies eine Koordination erfordern würde, die Latenz einführen und die Verfügbarkeit verringern könnte, was den Bedarf an schnellem Zugriff und niedriger Latenz widerspricht.",
            "Strikte FIFO (First-In-First-Out)-Konfliktauflösung ist kein Feature von DynamoDB Global Tables. Dieser Ansatz wäre für eine Multi-Region-Umgebung, in der Aktualisierungen gleichzeitig erfolgen können, nicht geeignet, da er zu Verzögerungen und Inkonsistenzen in der Datenverfügbarkeit führen könnte."
        ]
    },
    {
        "Question Number": "56",
        "Situation": "Ein Unternehmen richtet eine neue AWS-Umgebung ein und benötigt ein privates, isoliertes Netzwerk innerhalb einer bestimmten AWS-Region. Sie möchten den IP-Adressbereich für dieses Netzwerk kontrollieren und mehrere Subnetze haben, die jeweils in einer anderen Availability Zone (AZ) für hohe Verfügbarkeit liegen. Das Unternehmen möchte auch wissen, ob es mehrere VPCs in derselben Region haben kann und welche Standardeinstellungen angewendet werden, wenn sie die Standard-VPC verwenden.",
        "Question": "Welchen Ansatz sollte das Unternehmen wählen, um ihr Netzwerk gemäß diesen Anforderungen zu konfigurieren?",
        "Options": {
            "1": "Erstellen Sie eine Standard-VPC, die automatisch Subnetze in jeder Availability Zone innerhalb der Region bereitstellt. Die Standard-VPC hat einen festen CIDR-Bereich von 172.31.0.0/16, und zusätzliche benutzerdefinierte VPCs können in derselben Region nicht erstellt werden.",
            "2": "Erstellen Sie eine benutzerdefinierte VPC, die es dem Unternehmen ermöglicht, ihren eigenen CIDR-Bereich festzulegen und mehrere Subnetze in jeder Availability Zone zu erstellen. Die Standard-VPC wird ebenfalls standardmäßig verfügbar sein, und sie können sie bei Bedarf löschen oder neu erstellen.",
            "3": "Verwenden Sie die von AWS bereitgestellte Standard-VPC, die benutzerdefinierte CIDR-Bereiche zulässt und vollständige Kontrolle über die IP-Adresszuweisungen der Subnetze bietet. Die Standard-VPC erlaubt nur ein Subnetz pro Availability Zone.",
            "4": "Richten Sie eine einzige VPC über mehrere Regionen ein, da VPCs standardmäßig global sind. Diese Konfiguration ermöglicht es dem Unternehmen, mehrere Availability Zones in einer einzigen VPC über verschiedene Regionen hinweg zu haben, was Redundanz und hohe Verfügbarkeit bietet."
        },
        "Correct Answer": "Erstellen Sie eine benutzerdefinierte VPC, die es dem Unternehmen ermöglicht, ihren eigenen CIDR-Bereich festzulegen und mehrere Subnetze in jeder Availability Zone zu erstellen. Die Standard-VPC wird ebenfalls standardmäßig verfügbar sein, und sie können sie bei Bedarf löschen oder neu erstellen.",
        "Explanation": "Die Erstellung einer benutzerdefinierten VPC ermöglicht es dem Unternehmen, ihren eigenen IP-Adressbereich (CIDR-Block) festzulegen und mehrere Subnetze in verschiedenen Availability Zones (AZs) für hohe Verfügbarkeit zu erstellen. Diese Konfiguration erfüllt ihre Anforderung an ein privates, isoliertes Netzwerk mit Kontrolle über den IP-Adressbereich. Darüber hinaus erlaubt AWS die Erstellung mehrerer VPCs innerhalb derselben Region, und die Standard-VPC ist standardmäßig verfügbar, die bei Bedarf gelöscht oder neu erstellt werden kann.",
        "Other Options": [
            "Die Erstellung einer Standard-VPC erlaubt es dem Unternehmen nicht, ihren eigenen CIDR-Bereich festzulegen, da sie einen festen CIDR-Bereich von 172.31.0.0/16 hat. Darüber hinaus können in derselben Region tatsächlich mehrere benutzerdefinierte VPCs erstellt werden, sodass diese Option falsch ist.",
            "Die Standard-VPC erlaubt keine benutzerdefinierten CIDR-Bereiche; sie hat einen festen CIDR-Bereich. Darüber hinaus bietet die Standard-VPC zwar Subnetze in jeder AZ, jedoch nicht die vollständige Kontrolle über die IP-Adresszuweisungen der Subnetze, wie es eine benutzerdefinierte VPC tun würde. Diese Option ist daher falsch.",
            "VPCs sind nicht global; sie sind regional. Jede VPC ist auf eine einzelne Region beschränkt, und während eine VPC mehrere AZs innerhalb dieser Region umfassen kann, kann sie nicht mehrere Regionen umfassen. Diese Option ist falsch, da sie missverständlich darstellt, wie VPCs in AWS funktionieren."
        ]
    },
    {
        "Question Number": "57",
        "Situation": "Sie richten ein Content-Delivery-System mit Amazon CloudFront ein, um sichere Inhalte aus einem S3-Bucket und einem Application Load Balancer (ALB) bereitzustellen. Um eine verschlüsselte Kommunikation sicherzustellen, entscheiden Sie sich, SSL-Zertifikate zu konfigurieren.",
        "Question": "In Anbetracht der SSL-Anforderungen, was ist entscheidend, um sichere HTTPS-Verbindungen zwischen dem Viewer und Ihrer CloudFront-Distribution zu ermöglichen?",
        "Options": {
            "1": "Generieren oder importieren Sie ein gültiges öffentliches Zertifikat in ACM (Amazon Certificate Manager) in der Region us-east-1 und stellen Sie sicher, dass es mit dem DNS-Namen Ihrer Domain übereinstimmt.",
            "2": "Verwenden Sie selbstsignierte Zertifikate an den Ursprüngen (S3 und ALB), um Kosten zu sparen, da CloudFront die SSL-Terminierung übernimmt.",
            "3": "Weisen Sie jeder CloudFront-Edge-Location eine dedizierte IP für SSL-Unterstützung zu, da dies für moderne Browser erforderlich ist, um HTTPS-Verbindungen herzustellen.",
            "4": "Aktivieren Sie SSL nur auf der CloudFront-Distribution und nicht auf den Ursprungsservern, da CloudFront automatisch den gesamten Datenverkehr mit den Viewern verschlüsselt."
        },
        "Correct Answer": "Generieren oder importieren Sie ein gültiges öffentliches Zertifikat in ACM (Amazon Certificate Manager) in der Region us-east-1 und stellen Sie sicher, dass es mit dem DNS-Namen Ihrer Domain übereinstimmt.",
        "Explanation": "Um sichere HTTPS-Verbindungen zwischen dem Viewer und Ihrer CloudFront-Distribution zu ermöglichen, ist es entscheidend, ein gültiges SSL-Zertifikat zu haben. Amazon Certificate Manager (ACM) ermöglicht es Ihnen, SSL-Zertifikate zu generieren oder zu importieren, die für die Herstellung sicherer Verbindungen erforderlich sind. Das Zertifikat muss in der Region us-east-1 sein, da CloudFront das SSL-Zertifikat aus dieser Region benötigt, um es mit Distributionen zu verwenden. Darüber hinaus muss das Zertifikat mit dem Domainnamen übereinstimmen, der in der CloudFront-Distribution verwendet wird, um eine ordnungsgemäße Validierung während des SSL-Handshakes sicherzustellen.",
        "Other Options": [
            "Die Verwendung selbstsignierter Zertifikate an den Ursprüngen (S3 und ALB) wird für Produktionsumgebungen nicht empfohlen, da sie von Clients nicht vertraut werden und zu Sicherheitswarnungen führen können. CloudFront übernimmt nicht die SSL-Terminierung für selbstsignierte Zertifikate, und Clients werden keine sicheren Verbindungen ohne ein vertrauenswürdiges Zertifikat herstellen.",
            "Die Zuweisung einer dedizierten IP für SSL-Unterstützung an jeder CloudFront-Edge-Location ist nicht erforderlich. CloudFront verwendet eine gemeinsame Infrastruktur für die SSL-Terminierung, und moderne Browser benötigen keine dedizierten IPs für HTTPS-Verbindungen. Stattdessen verlassen sie sich auf die SSL-Zertifikate, um sichere Verbindungen herzustellen.",
            "SSL nur auf der CloudFront-Distribution und nicht auf den Ursprungsservern zu aktivieren, ist nicht ratsam. Während CloudFront den Datenverkehr zwischen sich und den Viewern verschlüsseln kann, ist es wichtig, auch die Verbindung zwischen CloudFront und den Ursprungsservern (S3 und ALB) zu sichern, um eine End-to-End-Verschlüsselung zu gewährleisten. Dies verhindert potenzielle Schwachstellen während des Datentransfers von CloudFront zum Ursprung."
        ]
    },
    {
        "Question Number": "58",
        "Situation": "Ein Unternehmen für maschinelles Lernen führt Hochleistungsrechnungs (HPC)-Simulationen durch, die extrem niedrige Netzwerkverzögerungen und hohe Paket-pro-Sekunde (PPS)-Leistung zwischen Instanzen erfordern. Die Simulationen sind rechenintensiv und benötigen Instanzen, die direkt miteinander kommunizieren, mit minimaler Verzögerung.",
        "Question": "Welche EC2-Platzierungsgruppen-Konfiguration sollte der Lösungsarchitekt wählen, um diese Anforderungen zu erfüllen?",
        "Options": {
            "1": "Spread Placement Group über mehrere Availability Zones",
            "2": "Cluster Placement Group innerhalb einer einzelnen Availability Zone",
            "3": "Partition Placement Group über mehrere Racks",
            "4": "Dedicated Host Placement"
        },
        "Correct Answer": "Cluster Placement Group innerhalb einer einzelnen Availability Zone",
        "Explanation": "Eine Cluster Placement Group ist darauf ausgelegt, niedrige Latenz und hohe Durchsatzraten zwischen Instanzen zu bieten, indem sie physisch nahe beieinander in derselben Availability Zone platziert werden. Diese Konfiguration ist ideal für rechenintensive Anwendungen, die eine schnelle Kommunikation zwischen Instanzen erfordern, da sie die Netzwerkverzögerung minimiert und die Paket-pro-Sekunde-Leistung maximiert. Da die Simulationen rechenintensiv sind und eine direkte Kommunikation mit minimaler Verzögerung erfordern, ist die Cluster Placement Group die beste Wahl.",
        "Other Options": [
            "Spread Placement Group über mehrere Availability Zones ist darauf ausgelegt, Instanzen über verschiedene physische Hardware zu verteilen, um das Risiko gleichzeitiger Ausfälle zu reduzieren. Während es hohe Verfügbarkeit bietet, gewährleistet es nicht die niedrige Latenz und hohe PPS-Leistung, die für rechenintensive Simulationen erforderlich sind, da die Instanzen nicht nahe beieinander liegen.",
            "Partition Placement Group über mehrere Racks ist nützlich für Anwendungen, die hohe Verfügbarkeit und Fehlertoleranz erfordern, da sie Instanzen über verschiedene Racks verteilt. Es garantiert jedoch nicht die niedrige Latenz und den hohen Durchsatz, die für die direkte Kommunikation zwischen Instanzen erforderlich sind, was es weniger geeignet für das gegebene Szenario macht.",
            "Dedicated Host Placement ist ein physischer Server, der für Ihre Nutzung reserviert ist, was mehr Kontrolle über die Platzierung von Instanzen und Lizenzen ermöglicht. Es bietet jedoch nicht von Natur aus die niedrige Latenz und hohe Paket-pro-Sekunde-Leistung, die für die beschriebenen HPC-Simulationen entscheidend sind, da es mehr auf Compliance und Kontrolle als auf Netzwerkleistung fokussiert."
        ]
    },
    {
        "Question Number": "59",
        "Situation": "Eine Gesundheitsorganisation muss eine sichere und zuverlässige Verbindung zwischen ihrem lokalen Rechenzentrum und ihrer AWS-Umgebung herstellen, um den regulatorischen Anforderungen zu entsprechen. Die Verbindung muss hohe Bandbreite unterstützen und niedrige Latenz für die Verarbeitung von Echtzeitdaten bieten.",
        "Question": "Welche Netzwerkverbindungsoption sollte der Lösungsarchitekt empfehlen?",
        "Options": {
            "1": "AWS Site-to-Site VPN mit dynamischem Routing",
            "2": "AWS Direct Connect mit einer dedizierten Verbindung",
            "3": "AWS Transit Gateway mit VPC-Peering",
            "4": "AWS PrivateLink, um AWS-Dienste privat zuzugreifen"
        },
        "Correct Answer": "AWS Direct Connect mit einer dedizierten Verbindung",
        "Explanation": "AWS Direct Connect bietet eine dedizierte, hochbandbreitige, latenzarme Verbindung zwischen einem lokalen Rechenzentrum und AWS. Diese Option ist ideal für Organisationen, die eine sichere und zuverlässige Verbindung benötigen, um regulatorische Compliance zu gewährleisten, insbesondere für die Verarbeitung von Echtzeitdaten. Direct Connect umgeht das öffentliche Internet, reduziert die Latenz und verbessert die Leistung, was es für Anwendungen mit hohem Durchsatz geeignet macht.",
        "Other Options": [
            "AWS Site-to-Site VPN mit dynamischem Routing verwendet das öffentliche Internet, um eine sichere Verbindung herzustellen, was Variabilität in der Latenz und Bandbreite einführen kann. Während es eine sichere Option ist, erfüllt es möglicherweise nicht die hohen Bandbreiten- und niedrigen Latenzanforderungen, die für die Verarbeitung von Echtzeitdaten erforderlich sind.",
            "AWS Transit Gateway mit VPC-Peering wird hauptsächlich verwendet, um mehrere VPCs und lokale Netzwerke zu verbinden. Während es die Kommunikation zwischen verschiedenen Netzwerken erleichtern kann, bietet es keine dedizierte Verbindung und erfüllt möglicherweise nicht die hohen Bandbreiten- und niedrigen Latenzanforderungen so effektiv wie Direct Connect.",
            "AWS PrivateLink ist darauf ausgelegt, AWS-Dienste privat zuzugreifen, ohne den Datenverkehr dem öffentlichen Internet auszusetzen. Es stellt jedoch keine direkte Verbindung zwischen einem lokalen Rechenzentrum und AWS her, was es ungeeignet für die spezifische Anforderung einer sicheren und zuverlässigen Verbindung für hohe Bandbreite und niedrige Latenz macht."
        ]
    },
    {
        "Question Number": "60",
        "Situation": "Ein Finanzdienstleistungsunternehmen möchte die Kosten über verschiedene Abteilungen hinweg mit einem einzigen AWS-Konto verfolgen. Sie benötigen eine Methode, um Ressourcen nach Abteilung zu kategorisieren und detaillierte Kostenberichte zu erstellen.",
        "Question": "Welches AWS-Kostenmanagement-Feature würde ihnen am besten helfen, dies zu erreichen?",
        "Options": {
            "1": "Aktivieren Sie die Abrechnung für mehrere Konten",
            "2": "Verwenden Sie Kostenallokationstags",
            "3": "Richten Sie AWS Budgets für jede Abteilung ein",
            "4": "Aktivieren Sie S3 Requester Pays für abteilungsspezifischen Speicher"
        },
        "Correct Answer": "Verwenden Sie Kostenallokationstags",
        "Explanation": "Kostenallokationstags ermöglichen es Ihnen, AWS-Ressourcen nach Abteilung oder einem anderen Kriterium Ihrer Wahl zu kategorisieren. Durch die Anwendung dieser Tags auf Ressourcen kann das Finanzdienstleistungsunternehmen die mit jeder Abteilung verbundenen Kosten verfolgen und detaillierte Kostenberichte basierend auf diesen Tags erstellen. Dieses Feature ist speziell für die Verfolgung und Berichterstattung von Kosten konzipiert und stellt die beste Option für ihre Bedürfnisse dar.",
        "Other Options": [
            "Die Aktivierung der Abrechnung für mehrere Konten ist nicht geeignet, da sie die Verwendung mehrerer AWS-Konten zur Trennung von Kosten beinhaltet, was nicht dem entspricht, was das Unternehmen möchte, da es die Kosten innerhalb eines einzigen AWS-Kontos verfolgen möchte.",
            "Das Einrichten von AWS Budgets für jede Abteilung ist nützlich, um die Ausgaben zu überwachen und Warnungen festzulegen, bietet jedoch nicht die Kategorisierung von Ressourcen, die für detaillierte Kostenberichte erforderlich ist. Budgets dienen mehr der Verfolgung und Kontrolle von Kosten als deren Kategorisierung.",
            "Die Aktivierung von S3 Requester Pays für abteilungsspezifischen Speicher ist in diesem Kontext nicht relevant. Dieses Feature ermöglicht es Benutzern, den Anforderer des Zugriffs auf S3-Daten zu belasten, hilft jedoch nicht bei der Kategorisierung von Kosten über Abteilungen hinweg oder bei der Erstellung detaillierter Kostenberichte."
        ]
    },
    {
        "Question Number": "61",
        "Situation": "Ein E-Commerce-Unternehmen betreibt mehrere AWS-Konten in verschiedenen Geschäftsbereichen, wie Marketing, Vertrieb und Entwicklung, und möchte die AWS-Kosten nach Abteilung genau verfolgen und überwachen. Sie benötigen eine Methode, um gemeinsam genutzte Ressourcen wie Datenbanken und Rechenressourcen dem Budget jeder Abteilung zuzuordnen und eine transparente Kostenverfolgung für jede Geschäftseinheit sicherzustellen.",
        "Question": "Welches AWS-Kostenmanagement-Feature sollten sie verwenden, um diese Anforderungen zu erfüllen?",
        "Options": {
            "1": "Verwenden Sie konsolidierte Abrechnung über alle Konten und wenden Sie Kostenverteilungstags an, um Kosten bestimmten Abteilungen zuzuordnen.",
            "2": "Erstellen Sie ein einzelnes AWS-Konto für alle Abteilungen und verwenden Sie interne Abrechnungspraktiken zur Kostenverteilung.",
            "3": "Aktivieren Sie S3 Requester Pays für die Ressourcen jeder Abteilung, um die Kosten auf einzelne Benutzer innerhalb jeder Abteilung zu übertragen.",
            "4": "Richten Sie separate Abrechnungsbenachrichtigungen für jede Abteilung ein, um die Kosten unabhängig zu verfolgen."
        },
        "Correct Answer": "Verwenden Sie konsolidierte Abrechnung über alle Konten und wenden Sie Kostenverteilungstags an, um Kosten bestimmten Abteilungen zuzuordnen.",
        "Explanation": "Die Verwendung von konsolidierter Abrechnung ermöglicht es dem E-Commerce-Unternehmen, mehrere AWS-Konten unter einem einzigen Abrechnungskonto zu verwalten, was den Zahlungsprozess vereinfacht. Durch die Anwendung von Kostenverteilungstags können sie Kosten kategorisieren und verfolgen, die mit bestimmten Ressourcen verbunden sind, die von jeder Abteilung genutzt werden. Diese Methode bietet Transparenz in der Kostenverteilung und ermöglicht eine genaue Budgetverfolgung für jede Geschäftseinheit, wodurch die Anforderung zur effektiven Überwachung der AWS-Kosten erfüllt wird.",
        "Other Options": [
            "Die Erstellung eines einzelnen AWS-Kontos für alle Abteilungen würde die Kostenverfolgung komplizieren, da alle Ressourcen unter einem Konto aggregiert wären. Dieser Ansatz fehlt die Granularität, die erforderlich ist, um Kosten genau einzelnen Abteilungen zuzuordnen, was es schwierig macht, Budgets effektiv zu verwalten.",
            "Die Aktivierung von S3 Requester Pays ist nicht geeignet, um Kosten über Abteilungen hinweg zu verfolgen, da sie nur für Amazon S3-Ressourcen gilt. Diese Funktion ermöglicht es dem Anforderer der Daten, die Kosten für den Datentransfer zu tragen, bietet jedoch keine umfassende Lösung zur Verfolgung und Zuordnung von Kosten über verschiedene AWS-Dienste und Abteilungen hinweg.",
            "Das Einrichten separater Abrechnungsbenachrichtigungen für jede Abteilung kann helfen, die Kosten zu überwachen, bietet jedoch keine Methode zur Zuordnung gemeinsam genutzter Ressourcen oder zur genauen Verfolgung der Kosten gegenüber den Abteilungsbudgets. Benachrichtigungen sind reaktiv und nicht proaktiv und erleichtern kein detailliertes Kostenmanagement oder die Zuordnung."
        ]
    },
    {
        "Question Number": "62",
        "Situation": "Ein Finanzunternehmen möchte Daten während der Übertragung zwischen seiner lokalen Umgebung und AWS verschlüsseln. Die Daten müssen mit einem TLS-Zertifikat verschlüsselt werden.",
        "Question": "Welchen AWS-Dienst sollte das Unternehmen verwenden, um das TLS-Zertifikat zu verwalten und bereitzustellen?",
        "Options": {
            "1": "AWS Key Management Service (AWS KMS)",
            "2": "AWS Secrets Manager",
            "3": "AWS Certificate Manager (ACM)",
            "4": "Amazon S3"
        },
        "Correct Answer": "AWS Certificate Manager (ACM)",
        "Explanation": "AWS Certificate Manager (ACM) ist speziell dafür konzipiert, TLS/SSL-Zertifikate für die Verwendung mit AWS-Diensten und -Anwendungen zu verwalten und bereitzustellen. Es vereinfacht den Prozess der Bereitstellung, Verwaltung und Bereitstellung von Zertifikaten, sodass das Finanzunternehmen Daten während der Übertragung zwischen seiner lokalen Umgebung und AWS einfach verschlüsseln kann. ACM kümmert sich auch automatisch um die Erneuerung von Zertifikaten, sodass die Verschlüsselung ohne manuelles Eingreifen gültig bleibt.",
        "Other Options": [
            "AWS Key Management Service (AWS KMS) wird hauptsächlich zur Verwaltung kryptografischer Schlüssel für Ihre Anwendungen und Dienste verwendet. Obwohl es eine entscheidende Rolle bei Verschlüsselungs- und Entschlüsselungsprozessen spielt, verwaltet es TLS-Zertifikate nicht direkt.",
            "AWS Secrets Manager wird zur Verwaltung von Geheimnissen wie Datenbankanmeldeinformationen, API-Schlüsseln und anderen sensiblen Informationen verwendet. Es bietet keine Funktionalität zur Verwaltung von TLS-Zertifikaten, was es für diese spezifische Anforderung ungeeignet macht.",
            "Amazon S3 ist ein Speicher-Service, der es Ihnen ermöglicht, beliebige Datenmengen jederzeit zu speichern und abzurufen. Es verfügt nicht über Funktionen zur Verwaltung oder Bereitstellung von TLS-Zertifikaten und ist daher für die Aufgabe der Verschlüsselung von Daten während der Übertragung nicht relevant."
        ]
    },
    {
        "Question Number": "63",
        "Situation": "Ein Unternehmen entwickelt eine Webanwendung auf AWS, die eine sichere Benutzerauthentifizierung und Schutz vor externen Bedrohungen wie DDoS-Angriffen und SQL-Injection erfordert. Die Anwendung muss auch sicherstellen, dass Benutzeranmeldeinformationen sicher verwaltet werden und dass Benutzer basierend auf ihren Rollen eingeschränkten Zugriff haben.",
        "Question": "Welche Kombination von AWS-Diensten sollte das Unternehmen verwenden, um diese Sicherheitsanforderungen zu erfüllen?",
        "Options": {
            "1": "Verwenden Sie AWS Shield für DDoS-Schutz, Amazon Cognito für die Benutzerauthentifizierung und AWS WAF, um SQL-Injection-Angriffe zu blockieren.",
            "2": "Verwenden Sie Amazon GuardDuty für DDoS-Schutz, IAM-Rollen für die Benutzerauthentifizierung und AWS CloudFront für den Schutz vor SQL-Injection.",
            "3": "Verwenden Sie AWS Identity Center (AWS SSO) für die Benutzerauthentifizierung, AWS WAF für DDoS-Schutz und Amazon Macie zur Verhinderung von SQL-Injection.",
            "4": "Verwenden Sie AWS Secrets Manager für die Benutzerauthentifizierung, AWS Shield für DDoS-Schutz und AWS Lambda für den Schutz vor SQL-Injection."
        },
        "Correct Answer": "Verwenden Sie AWS Shield für DDoS-Schutz, Amazon Cognito für die Benutzerauthentifizierung und AWS WAF, um SQL-Injection-Angriffe zu blockieren.",
        "Explanation": "Diese Kombination von Diensten erfüllt effektiv alle Sicherheitsanforderungen, die im Szenario beschrieben sind. AWS Shield bietet robusten DDoS-Schutz, der für den Schutz der Webanwendung vor externen Bedrohungen unerlässlich ist. Amazon Cognito ist speziell für die Benutzerauthentifizierung konzipiert und ermöglicht eine sichere Verwaltung von Benutzeranmeldeinformationen sowie die Implementierung von rollenbasiertem Zugriff. AWS WAF (Web Application Firewall) ist speziell darauf ausgelegt, Webanwendungen vor gängigen Web-Exploits, einschließlich SQL-Injection-Angriffen, zu schützen, indem Sie Regeln erstellen, die solche bösartigen Anfragen blockieren.",
        "Other Options": [
            "Die Verwendung von Amazon GuardDuty für DDoS-Schutz ist falsch, da GuardDuty hauptsächlich ein Bedrohungserkennungsdienst ist, der bösartige Aktivitäten und unbefugtes Verhalten überwacht, anstatt direkten DDoS-Schutz zu bieten. IAM-Rollen sind kein Dienst zur Benutzerauthentifizierung; sie werden verwendet, um Berechtigungen für AWS-Ressourcen zu gewähren. AWS CloudFront ist ein Content Delivery Network und bietet keinen direkten Schutz vor SQL-Injection.",
            "AWS Identity Center (AWS SSO) ist ein Dienst für Single Sign-On und Benutzerauthentifizierung, aber AWS WAF ist nicht für DDoS-Schutz konzipiert; es ist für die Sicherheit von Webanwendungen gedacht. Amazon Macie ist ein Dienst für Datensicherheit und Datenschutz, der hilft, sensible Daten zu entdecken und zu schützen, verhindert jedoch keine SQL-Injection-Angriffe.",
            "AWS Secrets Manager wird zur Verwaltung von Geheimnissen wie API-Schlüsseln und Datenbankanmeldeinformationen verwendet, ist jedoch kein Authentifizierungsdienst. AWS Shield ist geeignet für DDoS-Schutz, aber AWS Lambda bietet keinen inhärenten Schutz vor SQL-Injection; es ist ein Rechenservice, der Code als Reaktion auf Ereignisse ausführen kann und nicht direkt die Sicherheit von Webanwendungen anspricht."
        ]
    },
    {
        "Question Number": "64",
        "Situation": "Ein Unternehmen konfiguriert eine Virtual Private Cloud (VPC) und muss mehrere Subnetze für eine Anwendung entwerfen, die über mehrere Availability Zones (AZs) bereitgestellt werden soll. Sie möchten sicherstellen, dass IP-Adressen innerhalb jedes Subnetzes korrekt zugewiesen und für spezifische Funktionen im Netzwerk reserviert sind.",
        "Question": "Welche der folgenden Aussagen beschreibt am besten die Regeln für die Einrichtung von VPC-Subnetzen und den Umgang mit reservierten IP-Adressen?",
        "Options": {
            "1": "Ein einzelnes Subnetz kann sich über mehrere Availability Zones erstrecken, um die Nutzung von IP-Adressen innerhalb des VPC CIDR-Blocks zu maximieren.",
            "2": "Jedes Subnetz hat einen Bereich von IP-Adressen, wobei fünf spezifische IP-Adressen in jedem Subnetz automatisch von AWS für Netzwerkfunktionen reserviert sind, einschließlich Adressen für DNS und VPC-Routing.",
            "3": "IPv4 CIDR-Blöcke, die Subnetzen zugewiesen sind, können sich überschneiden, um den Platzverbrauch zu optimieren, insbesondere wenn Subnetze in verschiedenen AZs liegen.",
            "4": "DHCP-Optionssätze in AWS erlauben das Bearbeiten und Entfernen automatisch zugewiesener IP-Adressen innerhalb jedes Subnetzes."
        },
        "Correct Answer": "Jedes Subnetz hat einen Bereich von IP-Adressen, wobei fünf spezifische IP-Adressen in jedem Subnetz automatisch von AWS für Netzwerkfunktionen reserviert sind, einschließlich Adressen für DNS und VPC-Routing.",
        "Explanation": "In AWS wird jedem Subnetz ein Bereich von IP-Adressen aus dem CIDR-Block der VPC zugewiesen, und AWS reserviert automatisch fünf IP-Adressen in jedem Subnetz für spezifische Netzwerkfunktionen. Diese reservierten Adressen werden für den VPC-Router, DNS und andere wesentliche Dienste verwendet, um sicherzustellen, dass sie nicht zur Zuweisung an Instanzen verfügbar sind. Diese Regel ist entscheidend für die Aufrechterhaltung der Funktionalität der VPC und ihrer Subnetze.",
        "Other Options": [
            "Ein einzelnes Subnetz kann sich nicht über mehrere Availability Zones erstrecken; jedes Subnetz muss vollständig innerhalb einer Availability Zone liegen. Dieses Design stellt sicher, dass Ressourcen in verschiedenen AZs isoliert sind und hohe Verfügbarkeit und Fehlertoleranz bieten können.",
            "IPv4 CIDR-Blöcke, die Subnetzen zugewiesen sind, können sich nicht überschneiden. Jedes Subnetz muss einen einzigartigen Bereich von IP-Adressen haben, um Konflikte zu vermeiden und eine ordnungsgemäße Weiterleitung innerhalb der VPC sicherzustellen. Überlappende CIDR-Blöcke würden zu Routingproblemen und Verbindungsproblemen führen.",
            "DHCP-Optionssätze in AWS erlauben nicht das Bearbeiten oder Entfernen automatisch zugewiesener IP-Adressen innerhalb jedes Subnetzes. DHCP-Optionssätze werden verwendet, um DHCP-Einstellungen für Instanzen zu konfigurieren, wie z. B. Domain-Name-Server und NTP-Server, beeinflussen jedoch nicht die reservierten IP-Adressen innerhalb des Subnetzes."
        ]
    },
    {
        "Question Number": "65",
        "Situation": "Ein Unternehmen stellt eine globale Webanwendung bereit und möchte hohe Verfügbarkeit und latenzarmen Zugriff für Benutzer weltweit sicherstellen. Das Unternehmen verwendet Amazon Route 53 für das DNS-Management und erwägt, die Anwendung über mehrere Availability Zones (AZs) in mehreren AWS-Regionen bereitzustellen, um Fehlertoleranz zu gewährleisten.",
        "Question": "Welcher der folgenden Ansätze würde am besten die Anforderungen des Unternehmens an hohe Verfügbarkeit und Notfallwiederherstellung erfüllen?",
        "Options": {
            "1": "Verwenden Sie Route 53 mit Geolokalisierungsrouting, um Benutzer zur nächstgelegenen Region zu leiten, und stellen Sie die Anwendung in mehreren Availability Zones in diesen Regionen bereit, um hohe Verfügbarkeit sicherzustellen.",
            "2": "Verwenden Sie Route 53 mit einer Failover-Routing-Policy, um sicherzustellen, dass der Datenverkehr im Falle eines Ausfalls der primären Region an eine Backup-Region geleitet wird.",
            "3": "Stellen Sie die Anwendung in einer einzigen Availability Zone in einer Region bereit, um das Management zu vereinfachen und die Betriebskomplexität zu reduzieren.",
            "4": "Verwenden Sie Route 53 mit gewichteter Weiterleitung, um den Datenverkehr gleichmäßig auf alle Regionen zu verteilen, unabhängig von Verfügbarkeit oder Latenz, für eine ausgewogenere Verkehrverteilung."
        },
        "Correct Answer": "Verwenden Sie Route 53 mit Geolokalisierungsrouting, um Benutzer zur nächstgelegenen Region zu leiten, und stellen Sie die Anwendung in mehreren Availability Zones in diesen Regionen bereit, um hohe Verfügbarkeit sicherzustellen.",
        "Explanation": "Die Verwendung von Route 53 mit Geolokalisierungsrouting ermöglicht es dem Unternehmen, Benutzer zur nächstgelegenen AWS-Region zu leiten, was die Latenz minimiert und die Benutzererfahrung verbessert. Durch die Bereitstellung der Anwendung in mehreren Availability Zones (AZs) innerhalb dieser Regionen kann das Unternehmen hohe Verfügbarkeit sicherstellen, da der Datenverkehr im Falle eines Ausfalls automatisch an gesunde Instanzen in verschiedenen AZs weitergeleitet werden kann. Dieser Ansatz bietet auch Fehlertoleranz und Notfallwiederherstellungsfähigkeiten, da er die Redundanz mehrerer AZs und Regionen nutzt.",
        "Other Options": [
            "Die Verwendung von Route 53 mit einer Failover-Routing-Policy ist vorteilhaft für die Notfallwiederherstellung, konzentriert sich jedoch hauptsächlich darauf, den Datenverkehr nur dann an eine Backup-Region zu leiten, wenn die primäre Region ausfällt. Dies adressiert nicht die Notwendigkeit eines latenzarmen Zugriffs für Benutzer weltweit, da es möglicherweise nicht die Benutzer zur nächstgelegenen Region für optimale Leistung leitet.",
            "Die Bereitstellung der Anwendung in einer einzigen Availability Zone in einer Region erhöht erheblich das Risiko von Ausfallzeiten und bietet keine hohe Verfügbarkeit oder Fehlertoleranz. Wenn diese einzelne AZ einen Ausfall erleidet, wäre die gesamte Anwendung nicht verfügbar, was den Anforderungen des Unternehmens an hohe Verfügbarkeit widerspricht.",
            "Die Verwendung von Route 53 mit gewichteter Weiterleitung, um den Datenverkehr gleichmäßig auf alle Regionen zu leiten, ignoriert die Verfügbarkeit und Latenz dieser Regionen. Dies könnte zu suboptimaler Leistung für Benutzer führen, da der Datenverkehr möglicherweise an eine Region gesendet wird, die weiter entfernt ist oder Probleme hat, und somit die Ziele des Unternehmens für latenzarmen Zugriff und hohe Verfügbarkeit nicht erfüllt."
        ]
    }
]