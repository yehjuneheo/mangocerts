[
    {
        "Question Number": "1",
        "Situation": "한 금융 서비스 회사가 AWS에서 애플리케이션을 호스팅하고 Amazon CloudWatch를 사용하여 로깅 및 모니터링을 수행합니다. DevOps 팀은 애플리케이션 성능과 인프라 건강을 효과적으로 모니터링해야 합니다. 그들은 높은 대기 시간과 오류에 대한 경고를 설정하고 문제 해결을 위한 로그 데이터에 대한 포괄적인 뷰를 확보하고자 합니다.",
        "Question": "DevOps 팀이 애플리케이션 및 인프라 모니터링을 효과적으로 달성하기 위해 어떤 조치를 취해야 합니까?",
        "Options": {
            "1": "높은 대기 시간 및 오류 메트릭에 대한 CloudWatch 경고를 생성합니다. EC2 인스턴스에 대한 세부 모니터링을 활성화하고 CloudWatch Logs를 사용하여 로그 집계를 설정합니다.",
            "2": "AWS X-Ray를 사용하여 분산 추적을 통해 애플리케이션 성능을 모니터링합니다. Amazon S3를 사용하여 애플리케이션 로그를 저장하고 수동으로 문제를 분석합니다.",
            "3": "API 호출 로깅을 위해 Amazon CloudTrail을 설정하고 무단 접근에 대한 경고를 구성합니다. 비용 절감을 위해 EC2 인스턴스에 대한 기본 모니터링을 사용합니다.",
            "4": "AWS Config를 구현하여 구성 변경 사항을 추적하고 준수 위반에 대한 SNS 알림을 설정합니다. 수동 로그 검토를 통해 애플리케이션 성능을 모니터링합니다."
        },
        "Correct Answer": "높은 대기 시간 및 오류 메트릭에 대한 CloudWatch 경고를 생성합니다. EC2 인스턴스에 대한 세부 모니터링을 활성화하고 CloudWatch Logs를 사용하여 로그 집계를 설정합니다.",
        "Explanation": "높은 대기 시간 및 오류 메트릭에 대한 CloudWatch 경고를 생성하면 팀이 성능 임계값이 초과될 때 즉각적인 알림을 받을 수 있습니다. EC2 인스턴스에 대한 세부 모니터링을 활성화하면 인스턴스 성능에 대한 보다 세밀한 통찰력을 제공합니다. 또한 CloudWatch Logs를 사용한 로그 집계는 문제 검색 및 해결을 용이하게 하여 포괄적인 모니터링 솔루션을 제공합니다.",
        "Other Options": [
            "AWS X-Ray는 애플리케이션 요청 추적에 유용하지만, S3에 로그를 단독으로 의존하는 것은 실시간 모니터링 기능이 부족하고 사건 발생 시 로그를 분석하는 효율적인 방법을 제공하지 않습니다.",
            "CloudTrail은 API 호출 추적에 유용하지만 애플리케이션 성능이나 대기 시간 모니터링에 맞춰져 있지 않습니다. EC2 인스턴스에 대한 기본 모니터링은 사전 관리에 필요한 통찰력을 제공하지 않습니다.",
            "AWS Config는 구성 변경 사항을 추적하지만 애플리케이션 성능을 직접 모니터링하지 않습니다. 수동 로그 검토는 비효율적이며 성능 문제에 대한 실시간 경고를 촉진하지 않습니다."
        ]
    },
    {
        "Question Number": "2",
        "Situation": "한 금융 서비스 회사가 AWS Organizations를 통해 관리되는 다중 계정 AWS 환경을 가지고 있습니다. 이 회사는 모든 CloudFormation 스택이 특정 구성 표준을 준수하도록 보장해야 하는 준수 요구 사항이 있습니다. 그들은 이러한 스택에서 구성 드리프트를 자동으로 감지하고자 합니다. DevOps 팀은 조직 내 모든 계정의 CloudFormation 스택에서 드리프트를 모니터링하고 보고할 수 있는 솔루션을 구현하는 임무를 맡았습니다.",
        "Question": "DevOps 팀이 조직 내 여러 계정에서 CloudFormation 스택 드리프트를 자동으로 감지하고 알리기 위해 사용할 수 있는 AWS 서비스는 무엇입니까?",
        "Options": {
            "1": "관리 계정에서 cloudformation-stack-drift-detection-check 규칙과 함께 AWS Config를 구현하고 모든 계정에 대해 활성화합니다.",
            "2": "AWS CloudTrail을 설정하여 모든 스택 변경 사항을 로깅한 다음, 드리프트를 감지하고 알림을 보내는 사용자 지정 Lambda 함수를 생성합니다.",
            "3": "Amazon CloudWatch Events를 활용하여 CloudFormation 스택 변경 사항을 모니터링하고 드리프트가 발생할 때 알림을 트리거합니다.",
            "4": "각 계정에 사용자 지정 AWS Lambda 함수를 배포하여 주기적으로 스택 구성을 예상 상태와 비교합니다."
        },
        "Correct Answer": "관리 계정에서 cloudformation-stack-drift-detection-check 규칙과 함께 AWS Config를 구현하고 모든 계정에 대해 활성화합니다.",
        "Explanation": "cloudformation-stack-drift-detection-check 관리 규칙이 포함된 AWS Config는 드리프트를 모니터링하기 위해 특별히 설계되었습니다. 이 규칙을 관리 계정에서 활성화하고 모든 계정에 적용함으로써 회사는 구성 드리프트 감지를 효과적으로 자동화하고 준수 요구 사항을 충족할 수 있습니다.",
        "Other Options": [
            "AWS CloudTrail은 변경 사항을 로깅하지만 드리프트 감지를 위한 내장 메커니즘을 제공하지 않으며, 모니터링 및 알림을 보내기 위해 상당한 사용자 지정 개발이 필요합니다.",
            "Amazon CloudWatch Events는 이벤트를 모니터링할 수 있지만 스택 구성을 확인하는 사용자 지정 구현 없이는 본질적으로 드리프트를 감지하지 않습니다.",
            "각 계정에 사용자 지정 Lambda 함수를 배포하면 불필요한 복잡성과 관리 오버헤드가 추가되며, 반면 AWS Config는 중앙 집중식이고 자동화된 솔루션을 제공합니다."
        ]
    },
    {
        "Question Number": "3",
        "Situation": "한 금융 서비스 조직은 AWS 리소스의 변경 사항을 추적해야 하는 엄격한 규제 기준을 준수해야 합니다. DevOps 팀은 AWS 환경 전반에 걸쳐 구성 변경 사항 및 준수 상태에 대한 실시간 가시성을 제공하는 솔루션을 구축해야 합니다. 그들은 또한 리소스의 구성을 지정된 규칙에 따라 자동으로 평가할 수 있는 서비스를 찾고 있습니다. 다음 중 이러한 요구 사항을 충족하기 위한 가장 효과적인 솔루션은 무엇입니까?",
        "Question": "DevOps 팀이 구성 변경 사항 및 준수 상태의 실시간 모니터링을 달성하기 위해 구현해야 할 AWS 서비스는 무엇입니까?",
        "Options": {
            "1": "AWS Systems Manager를 배포하여 인스턴스 구성에 대한 준수 검사를 실행하고 AWS Lambda 함수를 활용하여 발견된 불일치에 대해 팀에 알립니다.",
            "2": "AWS Trusted Advisor를 구현하여 AWS 리소스를 주기적으로 검토하고 리소스 구성에 대한 모범 사례를 기반으로 권장 사항을 제공합니다.",
            "3": "AWS Config를 활용하여 AWS 리소스 구성을 지속적으로 모니터링하고 기록하며 지정된 준수 규칙에 따라 평가하고 Amazon SNS를 통해 변경 사항에 대한 알림을 보냅니다.",
            "4": "AWS CloudTrail을 설정하여 AWS 리소스에서 수행된 API 호출을 로깅하고 Amazon CloudWatch를 사용하여 로그에서 감지된 구성 변경 사항에 대한 경고를 생성합니다."
        },
        "Correct Answer": "AWS Config를 활용하여 AWS 리소스 구성을 지속적으로 모니터링하고 기록하며 지정된 준수 규칙에 따라 평가하고 Amazon SNS를 통해 변경 사항에 대한 알림을 보냅니다.",
        "Explanation": "AWS Config는 AWS 리소스의 구성에 대한 세부적인 가시성을 제공하도록 특별히 설계되어 지속적인 모니터링, 변경 사항 기록 및 정의된 규칙에 대한 준수 평가를 가능하게 합니다. 이는 조직의 준수 요구 사항에 가장 적합한 선택입니다.",
        "Other Options": [
            "AWS CloudTrail은 주로 API 호출 로깅에 중점을 두고 있으며 AWS Config가 제공하는 것처럼 실시간 구성 변경 모니터링이나 준수 평가를 제공하지 않습니다.",
            "AWS Systems Manager는 준수 검사를 수행할 수 있지만 AWS Config처럼 모든 AWS 리소스에 대한 구성 변경 사항을 지속적으로 모니터링하도록 설계되지 않았습니다.",
            "AWS Trusted Advisor는 모범 사례 권장 사항을 제공하지만 구성 변경 사항을 지속적으로 모니터링하거나 실시간으로 준수를 평가하는 기능이 부족하여 조직의 요구에 충분하지 않습니다."
        ]
    },
    {
        "Question Number": "4",
        "Situation": "당신은 AWS OpsWorks를 사용하여 애플리케이션 배포를 관리하고 있으며, 종속성을 설치하고 스택의 여러 레이어에서 특정 레시피를 실행하는 배포를 구현해야 합니다. 당신은 사용자 정의 요리책을 준비했으며, 배포 프로세스가 효율적이고 요리책 관리를 위한 Berkshelf의 기능을 활용하도록 하고 싶습니다.",
        "Question": "Berkshelf를 활용하여 AWS OpsWorks에서 종속성을 설치하고 지정된 레시피를 실행하는 배포를 생성하기 위해 어떤 명령을 사용하시겠습니까?",
        "Options": {
            "1": "aws opsworks --region us-east-1 create-deployment --stack-id <stack-id> --app-id <app-id> --instance-ids <instance-ids> --command deploy --custom-json <json>",
            "2": "aws opsworks --region us-east-1 create-deployment --stack-id <stack-id> --app-id <app-id> --instance-ids <instance-ids> --command execute_recipes --custom-json <json>",
            "3": "aws opsworks --region us-east-1 create-deployment --stack-id <stack-id> --app-id <app-id> --instance-ids <instance-ids> --command update_custom_cookbooks --custom-json <json>",
            "4": "aws opsworks --region us-east-1 create-deployment --stack-id <stack-id> --app-id <app-id> --instance-ids <instance-ids> --command install_dependencies --custom-json <json>"
        },
        "Correct Answer": "aws opsworks --region us-east-1 create-deployment --stack-id <stack-id> --app-id <app-id> --instance-ids <instance-ids> --command deploy --custom-json <json>",
        "Explanation": "'deploy' 명령은 종속성을 설치하고 사용자 정의 요리책에 정의된 필요한 레시피를 실행하는 전체 배포 프로세스를 시작하도록 설계되어 있어 이 시나리오에 적합한 선택입니다.",
        "Other Options": [
            "'install_dependencies' 명령은 종속성만 설치하고 레시피를 실행하지 않으므로 레이어에서 특정 레시피를 실행해야 하는 요구 사항을 충족하지 않습니다.",
            "'execute_recipes' 명령은 지정된 레시피를 실행하지만 종속성을 설치하지 않으므로 전체 배포를 위한 필수 설정 단계가 부족합니다.",
            "'update_custom_cookbooks' 명령은 스택의 요리책을 업데이트하는 데 사용되지만 실제 배포 프로세스를 시작하지 않으므로 배포 요구 사항을 해결하지 않습니다."
        ]
    },
    {
        "Question Number": "5",
        "Situation": "당신은 AWS OpsWorks를 사용하여 마이크로서비스 아키텍처에 새로운 웹 애플리케이션을 배포하는 임무를 맡은 DevOps 엔지니어입니다. 당신의 팀은 다양한 서비스에 대해 여러 레이어를 설계했으며, 배포 프로세스가 효율적이고 OpsWorks에 정의된 라이프사이클 이벤트를 준수하도록 해야 합니다. 특히 애플리케이션이 올바르게 구성되고 인스턴스 종료 시 필요한 정리 작업이 수행되도록 하는 데 중점을 두고 있습니다.",
        "Question": "AWS OpsWorks에서 인스턴스가 종료되기 전에 정리 레시피를 실행할 수 있는 라이프사이클 이벤트는 무엇입니까?",
        "Options": {
            "1": "SHUTDOWN - 인스턴스가 종료되기 직전에 정리 레시피를 실행합니다.",
            "2": "DEPLOY - 대상 인스턴스에서 애플리케이션 배포 레시피를 실행할 수 있습니다.",
            "3": "CONFIGURE - 인스턴스가 온라인 상태로 들어가거나 나갈 때 트리거됩니다.",
            "4": "SETUP - 인스턴스가 부팅을 마치고 구성 준비가 완료되었을 때 실행됩니다."
        },
        "Correct Answer": "SHUTDOWN - 인스턴스가 종료되기 직전에 정리 레시피를 실행합니다.",
        "Explanation": "AWS OpsWorks의 SHUTDOWN 이벤트는 인스턴스가 종료되기 직전에 정리 작업을 수행할 수 있도록 특별히 설계되었습니다. 이는 리소스 관리와 필요한 정리 작업이 실행되도록 보장하는 데 중요합니다.",
        "Other Options": [
            "DEPLOY 이벤트는 배포 명령이 실행될 때 인스턴스에서 배포 레시피를 실행하는 데 사용되며, 정리 작업을 위한 것이 아닙니다.",
            "CONFIGURE 이벤트는 인스턴스 상태가 변경될 때 발생하지만 종료 전에 정리를 허용하지 않습니다.",
            "SETUP 이벤트는 인스턴스가 부팅을 마친 후 실행되며, 주로 초기 구성에 해당하며 정리 작업과는 관련이 없습니다."
        ]
    },
    {
        "Question Number": "6",
        "Situation": "한 금융 서비스 회사가 AWS CloudFormation을 사용하여 복잡한 클라우드 인프라를 배포하고 있습니다. 그들은 로드 밸런서가 트래픽을 라우팅하기 시작하기 전에 초기화해야 하는 Auto Scaling Group (ASG) 내에 여러 EC2 인스턴스를 가지고 있습니다. 이 인스턴스의 초기화가 완료된 후 스택 생성이 완료된 것으로 표시되도록 하기를 원합니다. DevOps 엔지니어로서 어떤 접근 방식을 추천하시겠습니까?",
        "Question": "스택 생성이 성공적으로 표시되기 전에 Auto Scaling Group의 EC2 인스턴스가 초기화를 완료하도록 보장하기 위해 어떤 CloudFormation 기능을 활용해야 합니까?",
        "Options": {
            "1": "EC2 인스턴스와 함께 Creation Policy를 사용하여 초기화가 완료된 후 인스턴스에서 신호를 포함합니다.",
            "2": "CloudFormation 템플릿에서 지정된 수와 타임아웃을 가진 Wait Conditions를 구현합니다.",
            "3": "CloudFormation 스택 내에서 Load Balancer 리소스에 대한 종속성을 정의합니다.",
            "4": "CloudFormation 템플릿에서 초기화 상태를 기록하기 위해 Output 섹션을 구성합니다."
        },
        "Correct Answer": "EC2 인스턴스와 함께 Creation Policy를 사용하여 초기화가 완료된 후 인스턴스에서 신호를 포함합니다.",
        "Explanation": "Creation Policy는 EC2 인스턴스와 Auto Scaling Groups가 초기화를 완료했을 때 신호를 보내도록 특별히 설계되었습니다. 신호를 사용하는 Creation Policy를 구현함으로써 인스턴스가 준비될 때까지 스택이 진행되지 않도록 보장하여 종속성을 효과적으로 관리할 수 있습니다.",
        "Other Options": [
            "Wait Conditions는 유용하지만 추가 설정과 복잡성이 필요합니다. 사용할 수는 있지만 Creation Policy와 같은 방식으로 EC2 인스턴스에서 신호를 보내도록 설계되지 않았습니다.",
            "Load Balancer에 대한 종속성을 정의하는 것은 EC2 인스턴스가 초기화되었음을 보장하지 않습니다. 종속성은 리소스 생성 순서만 제어하며 준비 상태를 보장하지 않습니다.",
            "Output 섹션은 스택 생성 후 정보를 표시하는 데 사용되지만 생성 프로세스에 영향을 미치거나 리소스가 준비되었음을 보장하지 않습니다."
        ]
    },
    {
        "Question Number": "7",
        "Situation": "당신은 웹 애플리케이션을 실행하는 EC2 인스턴스의 플릿을 모니터링하고 관리하는 책임이 있습니다. 애플리케이션이 최적의 성능을 발휘하도록 다양한 메트릭과 알람을 추적하기 위해 CloudWatch를 설정했습니다. 특정 조건에 따라 알람 설정을 프로그래밍 방식으로 조정할 수 있는 메커니즘을 만들고자 합니다.",
        "Question": "다음 중 이전에 비활성화된 알람을 프로그래밍 방식으로 활성화할 수 있는 AWS CloudWatch 작업은 무엇입니까?",
        "Options": {
            "1": "put-metric-alarm",
            "2": "set-alarm-state",
            "3": "disable-alarm-actions",
            "4": "enable-alarm-actions"
        },
        "Correct Answer": "enable-alarm-actions",
        "Explanation": "enable-alarm-actions 명령은 비활성화된 특정 알람의 작업을 프로그래밍 방식으로 활성화하도록 특별히 설계되었습니다. 이를 통해 알람이 ALARM 상태로 전환될 때 작업을 수행할 수 있습니다.",
        "Other Options": [
            "set-alarm-state는 알람의 상태를 수동으로 설정하는 데 사용되지만 알람 작업을 활성화하지 않으므로 알람을 다시 활성화하는 올바른 선택이 아닙니다.",
            "put-metric-alarm은 지정된 메트릭 조건에 따라 알람을 생성하거나 업데이트하는 데 사용되지만 기존 알람의 작업을 직접 활성화하거나 비활성화하지는 않습니다.",
            "disable-alarm-actions는 반대 작업으로, 알람과 관련된 모든 작업을 비활성화하고 활성화하지 않습니다."
        ]
    },
    {
        "Question Number": "8",
        "Situation": "귀사는 고가용성과 복원력을 보장하기 위해 여러 AWS 리전과 가용 영역에 애플리케이션을 배포했습니다. Multi-AZ 구성으로 배포된 Amazon RDS 데이터베이스의 장애 조치 메커니즘을 테스트하고자 합니다. 또한, 장애 조치 시 Route 53 헬스 체크가 트래픽을 제대로 리디렉션하는지 확인하고 싶습니다. 프로덕션 작업에 영향을 주지 않고 장애 조치 시나리오를 시뮬레이션할 수 있는 신뢰할 수 있는 방법이 필요합니다.",
        "Question": "Route 53 구성이 손상되지 않도록 하면서 Multi-AZ Amazon RDS 데이터베이스의 장애 조치를 효과적으로 테스트하기 위해 어떤 접근 방식을 취해야 합니까?",
        "Options": {
            "1": "다른 리전에서 Amazon RDS 인스턴스의 읽기 복제본을 생성하고 이를 기본 인스턴스로 승격시켜 장애 조치를 시뮬레이션한 다음 Route 53 동작을 확인합니다.",
            "2": "장애 조치를 시작하기 위해 기본 Amazon RDS 인스턴스를 일시적으로 중지하고 Route 53의 트래픽 라우팅을 확인하여 대기 인스턴스를 가리키는지 확인합니다.",
            "3": "Amazon RDS 인스턴스의 수동 장애 조치를 수행하여 Multi-AZ 기능을 테스트하고 Route 53 헬스 체크를 모니터링하여 트래픽 리디렉션을 확인합니다.",
            "4": "AWS Fault Injection Simulator를 사용하여 Amazon RDS 인스턴스의 장애 조치를 시뮬레이션하는 테스트 시나리오를 생성하고 Route 53의 반응을 관찰합니다."
        },
        "Correct Answer": "Amazon RDS 인스턴스의 수동 장애 조치를 수행하여 Multi-AZ 기능을 테스트하고 Route 53 헬스 체크를 모니터링하여 트래픽 리디렉션을 확인합니다.",
        "Explanation": "수동 장애 조치를 수행하는 것은 Amazon RDS의 Multi-AZ 기능을 테스트하는 가장 직접적인 방법입니다. 이 방법을 통해 Route 53 헬스 체크가 장애 조치 이벤트에 어떻게 반응하는지 관찰할 수 있으며, 트래픽이 중단 없이 새로운 기본 인스턴스로 라우팅되는지 확인할 수 있습니다.",
        "Other Options": [
            "기본 Amazon RDS 인스턴스를 중지하는 것은 다운타임을 초래할 수 있으므로 권장되지 않으며, 실제 장애 발생 시 자동 장애 조치를 정확하게 시뮬레이션하지 않습니다. 이 접근 방식은 프로덕션 작업에 영향을 줄 수 있습니다.",
            "다른 리전에서 읽기 복제본을 생성하고 이를 승격시키는 것은 Multi-AZ 장애 조치 메커니즘을 테스트하지 않으며, 이는 Amazon RDS의 자동 장애 조치 기능을 반영하지 않는 수동 프로세스입니다. 또한 데이터 불일치를 초래할 수 있습니다.",
            "이 시나리오에 AWS Fault Injection Simulator를 사용하는 것은 최선의 선택이 아닙니다. 이는 애플리케이션에 결함을 주입하여 복원력을 테스트하기 위해 설계되었지만, RDS Multi-AZ 장애 조치 및 Route 53 트래픽 관리 테스트에 필요한 특정 통찰력을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "9",
        "Situation": "귀 조직은 애플리케이션 성능 및 가용성과 관련된 여러 사건을 경험했습니다. 사건 관리 및 대응 시간을 개선하기 위해 서비스 건강 및 운영 성능에 대한 통찰력을 제공하는 AWS 서비스를 활용하고자 합니다. 사건을 모니터링하고 운영 이벤트 중 효과적인 대응을 촉진할 수 있는 다양한 AWS 서비스를 평가하고 있습니다.",
        "Question": "다음 중 AWS 서비스 건강에 대한 포괄적인 뷰를 제공하고 운영 이벤트에 대한 사용자 정의 알림을 생성할 수 있는 AWS 서비스는 무엇입니까?",
        "Options": {
            "1": "AWS Health Dashboard는 AWS 서비스의 성능 및 가용성에 대한 개인화된 뷰를 제공하고 리소스에 영향을 미칠 수 있는 이벤트에 대해 알림을 제공합니다.",
            "2": "Amazon CloudWatch는 메트릭을 수집하고 추적하며 로그 파일을 수집하고 AWS 리소스 및 애플리케이션을 실시간으로 모니터링하기 위해 알람을 설정합니다.",
            "3": "AWS Config는 AWS 리소스 인벤토리, 구성 이력 및 구성 변경 알림을 제공하여 준수 및 보안을 관리하는 데 도움을 줍니다.",
            "4": "AWS Systems Manager OpsCenter는 다양한 출처의 운영 데이터를 집계하여 사건 관리를 지원하고 효과적인 사건 대응을 가능하게 합니다."
        },
        "Correct Answer": "AWS Health Dashboard는 AWS 서비스의 성능 및 가용성에 대한 개인화된 뷰를 제공하고 리소스에 영향을 미칠 수 있는 이벤트에 대해 알림을 제공합니다.",
        "Explanation": "AWS Health Dashboard는 AWS 서비스의 건강에 대한 포괄적인 뷰와 애플리케이션에 영향을 미칠 수 있는 이벤트에 대한 사용자 정의 알림을 제공하여 서비스 건강과 관련된 사건을 모니터링하는 데 가장 적합한 옵션입니다.",
        "Other Options": [
            "AWS Systems Manager OpsCenter는 주로 운영 데이터를 집계하고 사건을 관리하는 데 중점을 두지만, Health Dashboard와 같은 AWS 서비스 건강에 대한 개인화된 뷰를 제공하지 않습니다.",
            "Amazon CloudWatch는 메트릭 및 로그 모니터링에 탁월하지만, Health Dashboard와 같은 방식으로 AWS 서비스 건강 및 사건에 특별히 집중하지 않습니다.",
            "AWS Config는 리소스 구성을 추적하고 준수를 관리하는 데 유용하지만, Health Dashboard만큼 효과적으로 운영 이벤트나 서비스 건강 모니터링에 대한 통찰력을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "10",
        "Situation": "한 금융 서비스 회사가 애플리케이션을 AWS로 마이그레이션하고 있으며, 자원에 대한 최소 권한 액세스를 시행해야 합니다. 이 회사는 애플리케이션의 서로 다른 부분을 담당하는 여러 팀이 있으며, 팀원들이 자신의 직무 기능에 필요한 자원만 접근할 수 있도록 엄격한 통제가 필요합니다. 보안 팀은 이러한 제한을 효과적으로 시행하기 위해 IAM 정책을 설계하는 임무를 맡고 있습니다.",
        "Question": "보안 팀이 서로 다른 팀을 위해 최소 권한 액세스를 구현하기 위해 어떤 접근 방식을 취해야 합니까?",
        "Options": {
            "1": "각 팀에 대해 필요한 특정 AWS 리소스에만 접근할 수 있는 정책을 가진 IAM 역할을 생성합니다. AWS Organizations를 사용하여 이러한 역할을 관리하고 서비스 제어 정책을 적용하여 계정 수준에서 제한을 시행합니다.",
            "2": "각 팀에 대해 일반 직무 기능에 따라 권한을 부여하는 AWS 관리 정책을 사용합니다. 이를 통해 팀원들은 사용자 정의 정책 관리 없이 권한을 상속받을 수 있습니다.",
            "3": "모든 팀을 위한 단일 IAM 역할을 생성하여 모든 AWS 리소스에 대한 광범위한 권한을 부여합니다. 이렇게 하면 관리가 간소화되고 모든 팀이 제한 없이 작업을 수행할 수 있습니다.",
            "4": "각 팀원에 대해 모든 팀의 리소스에 접근할 수 있는 권한이 부여된 IAM 사용자 계정을 정의합니다. 이를 통해 개인들이 접근 문제 없이 자유롭게 협업할 수 있습니다."
        },
        "Correct Answer": "각 팀에 대해 필요한 특정 AWS 리소스에만 접근할 수 있는 정책을 가진 IAM 역할을 생성합니다. AWS Organizations를 사용하여 이러한 역할을 관리하고 서비스 제어 정책을 적용하여 계정 수준에서 제한을 시행합니다.",
        "Explanation": "각 팀에 대해 특정 권한을 가진 IAM 역할을 생성하는 것은 팀원들이 자신의 작업에 필요한 리소스에만 접근할 수 있도록 보장하여 최소 권한을 시행합니다. AWS Organizations를 사용하면 여러 계정에서 보안 정책을 더 잘 관리하고 시행할 수 있습니다.",
        "Other Options": [
            "단일 IAM 역할을 생성하여 광범위한 권한을 부여하는 것은 최소 권한 원칙을 저해하며, 모든 팀이 모든 리소스에 무제한으로 접근할 수 있게 되어 우발적이거나 악의적인 행동의 위험을 증가시킵니다.",
            "모든 팀의 리소스에 접근할 수 있는 권한이 부여된 IAM 사용자 계정을 정의하는 것은 최소 권한을 시행하지 않으며, 너무 많은 접근을 부여하고 사용자를 특정 직무 기능에 필요한 것만으로 제한하지 않습니다.",
            "AWS 관리 정책을 사용하는 것은 권한 관리를 간소화할 수 있지만, 특정 팀의 요구에 맞게 최소 권한을 효과적으로 시행하기 위한 세분화가 부족할 수 있습니다."
        ]
    },
    {
        "Question Number": "11",
        "Situation": "한 회사가 여러 EC2 인스턴스에서 애플리케이션 로그를 실시간으로 효과적으로 모니터링하고 분석할 수 있도록 해야 합니다. 이 회사는 특정 오류 패턴에 대한 경고도 필요하며, 과도한 저장 비용을 피하기 위해 로그 보존 설정을 관리하고자 합니다. DevOps 엔지니어로서, 최소한의 운영 오버헤드로 이러한 목표를 달성할 수 있는 AWS 서비스를 사용하여 솔루션을 구현하는 임무를 맡고 있습니다.",
        "Question": "AWS CloudWatch에서 애플리케이션 로그를 모니터링하고, 오류 패턴에 대해 경고하며, 로그 보존을 관리하는 가장 좋은 방법은 무엇입니까?",
        "Options": {
            "1": "타사 로그 관리 도구를 사용하여 EC2 인스턴스에서 로그를 수집하고, 오류 패턴을 모니터링하고 임계값에 대해 경고하도록 구성합니다. 이 외부 도구를 통해 로그 보존 설정을 관리하여 회사 정책을 준수합니다.",
            "2": "각 EC2 인스턴스에서 cron 작업을 설정하여 매시간 애플리케이션 로그를 S3 버킷으로 푸시합니다. AWS Lambda를 사용하여 이러한 로그를 처리하고 필요에 따라 알림을 보냅니다. S3에서 오래된 로그를 수동으로 삭제하여 보존을 관리합니다.",
            "3": "모든 EC2 인스턴스에 CloudWatch Logs 에이전트를 설치하여 애플리케이션 로그를 CloudWatch로 스트리밍합니다. 특정 오류 패턴에 대한 메트릭 필터를 생성하고, 임계값이 초과될 때 알림을 보내도록 CloudWatch 경고를 설정합니다. 30일 이상 된 로그를 삭제하도록 로그 보존 설정을 구성합니다.",
            "4": "Amazon Kinesis Data Streams를 사용하여 EC2 인스턴스에서 로그를 수집하는 중앙 집중식 로깅 솔루션을 배포합니다. Kinesis Data Analytics를 사용하여 실시간으로 오류 패턴을 분석하고 SNS를 통해 경고를 설정합니다. 보존 정책은 S3 수명 주기 규칙을 통해 관리할 수 있습니다."
        },
        "Correct Answer": "모든 EC2 인스턴스에 CloudWatch Logs 에이전트를 설치하여 애플리케이션 로그를 CloudWatch로 스트리밍합니다. 특정 오류 패턴에 대한 메트릭 필터를 생성하고, 임계값이 초과될 때 알림을 보내도록 CloudWatch 경고를 설정합니다. 30일 이상 된 로그를 삭제하도록 로그 보존 설정을 구성합니다.",
        "Explanation": "CloudWatch Logs 에이전트를 사용하면 AWS 서비스와의 원활한 통합이 가능합니다. 실시간 로그 스트리밍, 오류 패턴 모니터링을 위한 메트릭 필터의 손쉬운 생성, 로그 보존 정책의 간단한 구성을 가능하게 합니다. 이 솔루션은 운영 복잡성을 최소화하면서 모니터링 및 준수 요구를 충족합니다.",
        "Other Options": [
            "타사 로그 관리 도구를 사용하는 것은 AWS 생태계 외부에서 로그를 관리하는 데 추가 비용과 복잡성을 초래합니다. 이는 통합 문제를 일으킬 수 있으며 CloudWatch와 같은 실시간 모니터링 및 경고 기능을 제공하지 않을 수 있습니다.",
            "로그를 S3로 푸시하기 위해 cron 작업을 설정하는 것은 모니터링을 위한 로그 가용성에 지연을 초래하고 추가 Lambda 구현이 필요합니다. 이 접근 방식은 복잡성을 추가하고 실시간 모니터링 또는 경고 기능을 효과적으로 제공하지 않습니다.",
            "Kinesis Data Streams 솔루션을 배포하는 것은 더 복잡하며, 명시된 요구 사항에 필요하지 않을 수 있습니다. 이는 CloudWatch Logs를 사용하는 것에 비해 추가 비용과 운영 오버헤드를 초래합니다."
        ]
    },
    {
        "Question Number": "12",
        "Situation": "한 회사가 AWS에서 새로운 애플리케이션을 배포하고 있으며, 성능 메트릭을 모니터링해야 합니다. 이 애플리케이션은 CloudWatch 접근을 허용하는 사용자 정의 IAM 역할이 있는 EC2 인스턴스에서 실행됩니다. DevOps 엔지니어는 애플리케이션의 가동 시간을 매 분마다 추적하기 위해 CloudWatch 사용자 정의 메트릭을 설정하는 임무를 맡고 있습니다.",
        "Question": "DevOps 엔지니어가 사용자 정의 메트릭이 CloudWatch에 올바르게 보고되도록 하기 위해 어떤 단계를 수행해야 합니까?",
        "Options": {
            "1": "CloudWatch 전체 액세스 권한이 있는 IAM 역할을 생성하고 이를 EC2 인스턴스에 할당합니다. 인스턴스에 SSH로 접속하여 AWS SDK를 설치하고, 리포지토리를 클론한 후, 스크립트를 수동으로 실행하고, CloudWatch가 스크립트 출력을 가져오도록 구성합니다.",
            "2": "CloudWatch 전체 액세스 권한이 있는 IAM 역할을 생성하고 이를 EC2 인스턴스에 할당합니다. 인스턴스에 SSH로 접속하여 Node.js를 설치하고, 리포지토리를 클론한 후, 스크립트를 실행하고, CloudWatch가 API를 통해 메트릭을 가져오도록 구성합니다.",
            "3": "CloudWatch 전체 액세스 권한이 있는 IAM 역할을 생성하고 이를 EC2 인스턴스에 할당합니다. 인스턴스에 SSH로 접속하여 필요한 패키지를 설치하고, 리포지토리를 클론한 후, 스크립트를 실행 가능하게 만들고, cron 작업을 설정하여 매 분마다 스크립트를 실행합니다.",
            "4": "CloudWatch 전체 액세스 권한이 있는 IAM 역할을 생성하고 이를 EC2 인스턴스에 연결합니다. 인스턴스에 SSH로 접속하여 Docker를 설치하고, 리포지토리를 클론한 후, 컨테이너에서 스크립트를 실행하고, CloudWatch 에이전트를 설정하여 메트릭을 푸시합니다."
        },
        "Correct Answer": "CloudWatch 전체 액세스 권한이 있는 IAM 역할을 생성하고 이를 EC2 인스턴스에 할당합니다. 인스턴스에 SSH로 접속하여 필요한 패키지를 설치하고, 리포지토리를 클론한 후, 스크립트를 실행 가능하게 만들고, cron 작업을 설정하여 매 분마다 스크립트를 실행합니다.",
        "Explanation": "이 옵션은 매 분마다 실행되는 스크립트를 사용하여 CloudWatch 사용자 정의 메트릭을 생성하는 데 필요한 모든 단계를 설명합니다. cron 작업을 설정함으로써 스크립트는 원하는 메트릭을 지속적으로 CloudWatch에 보고할 수 있으며, 이는 애플리케이션 성능 모니터링에 중요합니다.",
        "Other Options": [
            "이 옵션은 스크립트를 수동으로 실행하는 것을 제안하는데, 이는 자동화된 cron 작업의 목적을 무색하게 하며, CloudWatch에 정기적인 메트릭 업데이트를 제공하지 않습니다.",
            "이 옵션은 Docker를 사용하는 것을 포함하는데, 이는 이 작업에 필요하지 않습니다. 메트릭을 푸시하기 위해 EC2 인스턴스에서 직접 스크립트를 실행하는 데 집중해야 합니다.",
            "이 옵션은 스크립트를 실행하는 데 필요하지 않은 Node.js 설치를 잘못 지정하고 있습니다. 메트릭을 생성하고 보고하기 위해 스크립트를 실행하는 것이며, 더 간단한 설정으로도 가능합니다."
        ]
    },
    {
        "Question Number": "13",
        "Situation": "DevOps 팀이 AWS EC2 Image Builder를 사용하여 애플리케이션 배포를 위한 맞춤형 Amazon Machine Images (AMIs)를 생성하고 관리하고 있습니다. 그들은 최신 AMI가 여러 AWS 계정 간에 공유되고 안전하게 저장되어 쉽게 검색될 수 있도록 해야 합니다.",
        "Question": "팀이 이를 달성하기 위해 어떤 단계를 밟아야 합니까? (두 가지 선택)",
        "Options": {
            "1": "AWS Resource Access Manager를 사용하여 AMI를 공유합니다.",
            "2": "이미지 생성을 하기 전에 인스턴스를 테스트하기 위해 Image Builder 구성 요소를 사용합니다.",
            "3": "AMI ID를 AWS Systems Manager Parameter Store에 저장합니다.",
            "4": "각 이미지 사용자 정의 요구 사항에 대해 새로운 레시피를 정의합니다.",
            "5": "각 AMI 빌드 작업을 위해 새로운 EC2 인스턴스를 생성합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "AWS Resource Access Manager를 사용하여 AMI를 공유합니다.",
            "AMI ID를 AWS Systems Manager Parameter Store에 저장합니다."
        ],
        "Explanation": "AWS Resource Access Manager를 사용하여 AMI를 공유하면 팀이 서로 다른 AWS 계정 간에 AMI에 대한 액세스를 부여할 수 있어 모든 필요한 팀이 동일한 이미지를 활용할 수 있습니다. AMI ID를 AWS Systems Manager Parameter Store에 저장하면 배포 시 필요할 때마다 최신 AMI ID를 안전하고 중앙 집중화된 방식으로 검색할 수 있습니다.",
        "Other Options": [
            "각 AMI 빌드 작업을 위해 새로운 EC2 인스턴스를 생성하는 것은 불필요하고 비효율적입니다. Image Builder는 추가 인스턴스 없이 이미지 생성 프로세스를 자동화할 수 있습니다.",
            "이미지 생성을 하기 전에 인스턴스를 테스트하기 위해 Image Builder 구성 요소를 사용하는 것은 AMI 공유와 관련이 없습니다. 테스트는 파이프라인의 일부여야 하지만 AMI를 계정 간에 공유하는 데는 도움이 되지 않습니다.",
            "각 이미지 사용자 정의 요구 사항에 대해 새로운 레시피를 정의하는 것은 AMI 공유에 필요하지 않습니다. 레시피는 이미지를 구축하기 위한 것이며, 기존 레시피로 업데이트가 충분해야 합니다. 단, 중요한 변경이 필요한 경우는 제외입니다."
        ]
    },
    {
        "Question Number": "14",
        "Situation": "소프트웨어 개발 팀은 애플리케이션을 AWS로 마이그레이션하면서 지속적인 통합 및 배포(CI/CD) 파이프라인을 개선하는 데 집중하고 있습니다. 그들은 코드 변경 사항이 최소한의 수동 개입으로 자동으로 빌드, 테스트 및 프로덕션 환경에 배포되도록 하고 싶어합니다. 팀은 이 프로세스를 용이하게 하기 위해 다양한 AWS 도구를 탐색하고 있습니다.",
        "Question": "팀이 애플리케이션 코드를 Amazon EC2 인스턴스에 자동으로 배포하고 일관된 배포 관행을 보장하기 위해 주로 사용해야 하는 AWS 서비스는 무엇입니까?",
        "Options": {
            "1": "AWS CloudFormation은 코드로 인프라를 관리하는 도구로, 애플리케이션 코드를 배포하는 것보다 리소스 프로비저닝에 중점을 둡니다.",
            "2": "AWS Elastic Beanstalk는 내장된 스케일링 및 로드 밸런싱으로 애플리케이션 배포를 관리하지만 EC2 인스턴스 관리에 대한 제어가 적습니다.",
            "3": "AWS Lambda는 이벤트 기반 애플리케이션에 효과적인 서버리스 배포를 위한 것이지만 전통적인 서버 기반 애플리케이션에는 적합하지 않습니다.",
            "4": "AWS CodeDeploy는 EC2 인스턴스에 애플리케이션 코드를 자동으로 배포하여 블루/그린 배포 및 롤링 업데이트를 가능하게 합니다."
        },
        "Correct Answer": "AWS CodeDeploy는 EC2 인스턴스에 애플리케이션 코드를 자동으로 배포하여 블루/그린 배포 및 롤링 업데이트를 가능하게 합니다.",
        "Explanation": "AWS CodeDeploy는 Amazon EC2를 포함한 다양한 컴퓨팅 서비스에 애플리케이션 코드를 자동으로 배포하도록 설계되었습니다. 블루/그린 및 롤링 업데이트와 같은 배포 전략을 지원하여 배포 프로세스를 향상시킵니다. 이는 최소한의 수동 개입으로 배포를 자동화하려는 팀의 요구에 가장 적합한 선택입니다.",
        "Other Options": [
            "AWS Elastic Beanstalk는 애플리케이션 배포 및 스케일링을 단순화하는 플랫폼 서비스(PaaS)지만, 기본 EC2 인스턴스 관리를 추상화합니다. 이는 팀의 배포 프로세스에 대한 제어를 제한할 수 있습니다.",
            "AWS Lambda는 서버리스 애플리케이션을 실행하도록 설계되었으며 이벤트에 의해 트리거됩니다. EC2 인스턴스에 배포가 필요한 전통적인 애플리케이션에는 적합하지 않으므로 이 시나리오에 대한 잘못된 선택입니다.",
            "AWS CloudFormation은 코드를 사용하여 AWS 리소스를 프로비저닝하는 도구이지만, 애플리케이션 코드를 직접 배포하는 것은 처리하지 않습니다. 따라서 애플리케이션 코드의 배포를 자동화하는 기본 요구를 충족하지 않습니다."
        ]
    },
    {
        "Question Number": "15",
        "Situation": "한 회사는 AWS CodePipeline을 사용하여 배포 프로세스를 자동화하고 있습니다. 최근에 프로덕션 환경에 대한 배포가 실패하여 애플리케이션에 다운타임이 발생했습니다. DevOps 엔지니어는 서비스를 복원하기 위해 배포 문제를 신속하게 해결해야 합니다.",
        "Question": "DevOps 엔지니어가 AWS CodePipeline에서 배포 실패를 진단하기 위한 최선의 첫 번째 단계는 무엇입니까?",
        "Options": {
            "1": "애플리케이션 코드와 관련된 오류가 있는지 Amazon CloudWatch 로그를 확인합니다.",
            "2": "Amazon EC2 인스턴스 상태 확인을 살펴보아 인스턴스가 실행 중인지 확인합니다.",
            "3": "리소스 프로비저닝의 문제를 찾기 위해 AWS CloudFormation 스택 이벤트를 검사합니다.",
            "4": "실패한 작업 세부정보를 식별하기 위해 AWS CodePipeline 실행 기록을 검토합니다."
        },
        "Correct Answer": "AWS CodePipeline 실행 기록을 검토하여 실패한 작업 세부정보를 식별합니다.",
        "Explanation": "AWS CodePipeline에서 배포 실패를 해결하기 위한 첫 번째 단계는 실행 기록을 검토하는 것입니다. 이는 파이프라인에서 어떤 작업이 실패했는지와 그 이유에 대한 자세한 정보를 제공하여 문제 해결을 위한 목표 지향적인 접근을 가능하게 합니다.",
        "Other Options": [
            "Amazon CloudWatch 로그를 확인하는 것은 애플리케이션 특정 오류를 식별하는 데 도움이 될 수 있지만, 배포 자체가 파이프라인 내에서 왜 실패했는지에 대한 즉각적인 통찰력을 제공하지는 않습니다.",
            "AWS CloudFormation 스택 이벤트를 검사하는 것은 배포가 CloudFormation과 관련된 경우 유용하지만, CodePipeline에서의 실패를 해결하는 가장 직접적인 방법은 아닙니다.",
            "Amazon EC2 인스턴스 상태 확인을 살펴보는 것은 전체 인스턴스 건강에 중요하지만, CodePipeline의 배포 실패와 직접적으로 관련이 없습니다."
        ]
    },
    {
        "Question Number": "16",
        "Situation": "개발 팀은 AWS CodePipeline을 사용하여 소프트웨어 릴리스 프로세스를 자동화하고 있습니다. 그들은 모든 풀 리퀘스트가 메인 브랜치에 병합되기 전에 자동으로 빌드되고 테스트되도록 보장하고 싶어합니다. 팀은 이 요구 사항을 효율적으로 구현하기 위한 여러 옵션을 고려하고 있습니다.",
        "Question": "DevOps 엔지니어가 메인 브랜치에 병합되기 전에 풀 리퀘스트에 대해 자동으로 빌드 및 테스트가 실행되도록 보장하기 위해 어떤 솔루션을 구현해야 합니까?",
        "Options": {
            "1": "개발자가 소스 리포지토리에 풀 리퀘스트를 제출하기 전에 로컬에서 빌드 및 테스트를 실행하는 수동 프로세스를 생성합니다.",
            "2": "AWS CodeBuild를 AWS CodePipeline의 빌드 제공자로 구성하고 소스 리포지토리의 풀 리퀘스트에 따라 빌드를 시작하는 트리거를 설정합니다.",
            "3": "풀 리퀘스트가 열릴 때 AWS CodeBuild에서 빌드를 시작하고 빌드가 완료될 때까지 대기하는 AWS Step Function을 구현합니다.",
            "4": "AWS Lambda를 사용하여 소스 리포지토리에서 풀 리퀘스트 이벤트를 모니터링하고 풀 리퀘스트가 생성될 때마다 AWS CodeBuild에서 빌드를 트리거합니다."
        },
        "Correct Answer": "AWS CodeBuild를 AWS CodePipeline의 빌드 제공자로 구성하고 소스 리포지토리의 풀 리퀘스트에 따라 빌드를 시작하는 트리거를 설정합니다.",
        "Explanation": "AWS CodePipeline과 AWS CodeBuild를 사용하면 풀 리퀘스트와 직접 연결된 빌드 및 테스트 프로세스의 원활한 통합과 자동화를 가능하게 합니다. 이는 모든 변경 사항이 메인 브랜치에 병합되기 전에 검증되도록 하여 코드 품질을 높이고 통합 문제를 줄입니다.",
        "Other Options": [
            "AWS Lambda를 사용하여 풀 리퀘스트 이벤트를 모니터링하는 것은 가능하지만, 추가적인 복잡성과 오버헤드를 도입합니다. 이는 사용자 정의 코드와 Lambda 함수 관리가 필요하여 내장된 CodePipeline 기능을 사용하는 것보다 효율성이 떨어집니다.",
            "이 작업을 위해 AWS Step Function을 구현하는 것은 불필요한 복잡성입니다. AWS CodePipeline은 이미 빌드 및 테스트 워크플로를 관리하는 데 필요한 기능을 제공하므로, Step Functions는 간단한 풀 리퀘스트 이벤트에 대해 과도하게 설계된 솔루션입니다.",
            "로컬에서 빌드 및 테스트를 실행하는 수동 프로세스는 효율적이지 않거나 신뢰할 수 없습니다. 이는 개발자에게 부담을 주고 메인 브랜치로 오류가 넘어갈 가능성을 높입니다. 일관되고 반복 가능한 결과를 보장하기 위해 자동화된 프로세스가 바람직합니다."
        ]
    },
    {
        "Question Number": "17",
        "Situation": "한 소매 회사는 Amazon CloudWatch를 사용하여 애플리케이션 로그를 모니터링하고 있습니다. 팀은 사고 대응 및 분석을 개선하기 위해 로그 이벤트의 실시간 처리를 가능하게 하는 솔루션을 설정하고자 합니다. 그들은 로그 데이터를 다른 서비스로 스트리밍하기 위해 구독 사용을 탐색하고 있습니다.",
        "Question": "다음 서비스 중 CloudWatch Logs를 실시간으로 처리하기 위한 구독의 대상으로 사용할 수 있는 것은 무엇입니까? (두 개 선택)",
        "Options": {
            "1": "Amazon EC2를 사용하여 로그를 저장하고 추가 분석을 수행합니다.",
            "2": "AWS Lambda를 사용하여 로그 데이터의 사용자 정의 처리 및 분석을 수행합니다.",
            "3": "Amazon Kinesis 스트림을 사용하여 로그 이벤트의 실시간 처리를 가능하게 합니다.",
            "4": "Amazon S3를 사용하여 규정 준수 및 보존 목적으로 로그를 보관합니다.",
            "5": "Amazon Kinesis Data Firehose를 사용하여 로그를 다른 시스템이나 저장소로 전달합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "AWS Lambda를 사용하여 로그 데이터의 사용자 정의 처리 및 분석을 수행합니다.",
            "Amazon Kinesis 스트림을 사용하여 로그 이벤트의 실시간 처리를 가능하게 합니다."
        ],
        "Explanation": "AWS Lambda는 로그 데이터가 도착할 때 사용자 정의 코드를 실행하는 데 사용할 수 있습니다. 유사하게, Amazon Kinesis 스트림은 데이터 스트림의 실시간 처리를 위해 설계되어 있어 두 서비스 모두 CloudWatch Logs의 구독 대상으로 이상적입니다.",
        "Other Options": [
            "Amazon EC2는 로그 데이터 스트리밍의 대상으로 직접 사용되지 않습니다. 로그를 처리하는 애플리케이션을 실행하는 데 사용할 수 있지만, 실시간 로그 구독을 본래 지원하지 않습니다.",
            "Amazon S3는 주로 저장 솔루션이며 실시간 처리 기능을 제공하지 않습니다. 이는 로그를 즉각적으로 분석하기보다는 보관하는 데 사용됩니다.",
            "Amazon Kinesis Data Firehose는 일반적으로 데이터 레이크 및 분석 서비스에 스트리밍 데이터를 로드하는 데 사용되지만, Kinesis 스트림과 같이 로그 이벤트를 실시간으로 직접 처리하기 위한 것은 아닙니다."
        ]
    },
    {
        "Question Number": "18",
        "Situation": "당신은 AWS Lambda와 API Gateway를 사용하여 마이크로서비스 애플리케이션을 배포하는 책임이 있습니다. 애플리케이션이 건강하게 유지되고 문제 해결을 용이하게 하기 위해, 종료 코드를 기반으로 애플리케이션 건강을 캡처하는 메커니즘을 구현하고자 합니다. Lambda 함수의 건강을 효과적으로 측정하고 보고하는 방법을 고려하고 있습니다.",
        "Question": "AWS Lambda에서 종료 코드를 기반으로 애플리케이션 건강을 측정하는 가장 효과적인 접근 방식은 무엇입니까?",
        "Options": {
            "1": "API Gateway에 종료 코드를 기반으로 애플리케이션 상태를 반환하는 사용자 정의 헬스 체크 엔드포인트를 구현합니다.",
            "2": "AWS X-Ray를 활용하여 실행을 추적하고 비제로 종료 코드를 반환하는 함수를 식별합니다.",
            "3": "Lambda가 종료 코드를 CloudWatch Metrics에 직접 반환하도록 설정하여 자동 모니터링을 수행합니다.",
            "4": "CloudWatch Logs를 활용하여 종료 코드를 모니터링하고 비제로 코드에 대한 CloudWatch Alarm을 생성합니다."
        },
        "Correct Answer": "CloudWatch Logs를 활용하여 종료 코드를 모니터링하고 비제로 코드에 대한 CloudWatch Alarm을 생성합니다.",
        "Explanation": "CloudWatch Logs를 사용하면 Lambda 함수에서 생성된 종료 코드를 캡처하고 분석할 수 있습니다. 비제로 종료 코드에 대한 CloudWatch Alarm을 설정함으로써 애플리케이션 건강을 사전 모니터링하고 문제가 발생할 때 알림을 받을 수 있습니다.",
        "Other Options": [
            "사용자 정의 헬스 체크 엔드포인트를 만드는 것은 유용하지만, Lambda 실행 컨텍스트에서 종료 코드를 직접 측정하지 않으므로 이 목적에 대해 덜 효과적입니다.",
            "AWS X-Ray는 추적 및 디버깅에 유용하지만 종료 코드를 구체적으로 측정하지는 않습니다. 이는 지연 시간 및 오류에 대한 통찰력을 제공하지만 직접적인 종료 코드 모니터링은 아닙니다.",
            "Lambda 함수는 종료 코드를 CloudWatch Metrics에 직접 반환하지 않습니다. 종료 코드는 일반적으로 CloudWatch Logs에 기록되므로 이 접근 방식은 의도한 대로 작동하지 않습니다."
        ]
    },
    {
        "Question Number": "19",
        "Situation": "개발 팀이 AWS 서비스를 사용하여 마이크로서비스 애플리케이션을 배포하고 있습니다. 팀은 애플리케이션이 고가용성을 보장하고 실패 시 롤백할 수 있는 배포 전략을 구현하고자 합니다. 그들은 컨테이너화된 애플리케이션과 서버리스 애플리케이션을 위해 AWS 서비스를 사용하는 것을 고려하고 있습니다.",
        "Question": "DevOps 엔지니어가 마이크로서비스 애플리케이션을 위해 구현해야 할 배포 전략은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "서버리스 함수에 대한 롤링 업데이트.",
            "2": "EC2 인스턴스에 대한 카나리 배포.",
            "3": "서버리스 함수에 대한 A/B 테스트.",
            "4": "컨테이너화된 서비스에 대한 불변 배포.",
            "5": "컨테이너화된 서비스에 대한 블루/그린 배포."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "컨테이너화된 서비스에 대한 블루/그린 배포.",
            "컨테이너화된 서비스에 대한 불변 배포."
        ],
        "Explanation": "블루/그린 배포는 두 환경 간의 원활한 전환을 가능하게 하여 업그레이드 중 다운타임과 위험을 최소화합니다. 불변 배포는 각 배포가 애플리케이션의 새로운 인스턴스를 생성하도록 보장하여 신뢰성을 높이고 롤백 절차를 단순화합니다.",
        "Other Options": [
            "서버리스 함수에 대한 롤링 업데이트는 일반적으로 지원되지 않으며, 서버리스 함수는 이러한 업데이트 없이 자동으로 확장되도록 설계되었습니다.",
            "EC2 인스턴스에 대한 카나리 배포는 유효하지만, 컨테이너가 선호되는 마이크로서비스 아키텍처에서는 그 효과가 떨어집니다.",
            "A/B 테스트는 신뢰성과 롤백을 위한 배포 전략보다는 사용자 경험 최적화와 관련이 있습니다."
        ]
    },
    {
        "Question Number": "20",
        "Situation": "한 회사가 AWS Lambda, Amazon API Gateway 및 Amazon ECS에서 실행되는 마이크로서비스 애플리케이션을 개발하고 있습니다. 개발 팀은 아키텍처를 통해 흐르는 요청을 추적하여 성능 병목 현상과 오류를 식별해야 합니다. 그들은 애플리케이션의 성능에 대한 통찰력을 제공하고 서비스를 디버깅할 수 있는 효과적인 모니터링 솔루션을 구현하고자 합니다. 팀은 이 모니터링 기능을 달성하기 위해 AWS X-Ray를 사용하기로 결정했습니다.",
        "Question": "이 서비스 전반에 걸쳐 애플리케이션 모니터링을 위해 AWS X-Ray를 구성하는 가장 효과적인 방법은 무엇입니까?",
        "Options": {
            "1": "Amazon CloudWatch 메트릭을 설정하여 애플리케이션 성능을 모니터링하고 메트릭에 따라 알람을 구성합니다. CloudWatch Logs를 사용하여 애플리케이션의 자세한 로그를 캡처합니다.",
            "2": "AWS CloudTrail을 구현하여 애플리케이션에서 수행된 모든 API 호출을 기록하고 로그를 분석하여 성능 문제를 식별합니다. 이러한 로그를 Amazon CloudWatch Logs에 통합하여 추가 통찰력을 얻습니다.",
            "3": "Amazon ECS 컨테이너 인스턴스에서 AWS X-Ray 데몬을 사용하여 서비스에서 추적 데이터를 수집하고 컨테이너를 구성하여 데이터를 X-Ray로 전송합니다. API Gateway에 대해 X-Ray 추적을 활성화하여 들어오는 요청을 캡처합니다.",
            "4": "AWS Lambda 함수 구성에서 AWS X-Ray 추적을 활성화하고 API Gateway를 설정하여 추적 헤더를 Lambda 함수로 전달합니다. Lambda 함수에서 X-Ray SDK를 사용하여 주석 및 메타데이터를 기록합니다."
        },
        "Correct Answer": "AWS Lambda 함수 구성에서 AWS X-Ray 추적을 활성화하고 API Gateway를 설정하여 추적 헤더를 Lambda 함수로 전달합니다. Lambda 함수에서 X-Ray SDK를 사용하여 주석 및 메타데이터를 기록합니다.",
        "Explanation": "이 접근 방식은 AWS X-Ray를 Lambda 및 API Gateway와 효과적으로 통합하여 요청의 종단 간 추적을 가능하게 합니다. Lambda에서 X-Ray 추적을 구성하고 API Gateway를 통해 추적 헤더를 전달함으로써 팀은 마이크로서비스 애플리케이션의 성능 및 동작에 대한 자세한 통찰력을 수집할 수 있습니다.",
        "Other Options": [
            "Amazon ECS에서 AWS X-Ray 데몬을 사용하는 것은 추적 데이터를 수집할 수 있지만, AWS Lambda 또는 API Gateway와의 완전한 통합을 제공하지 않아 전체 애플리케이션에서 요청을 원활하게 추적하는 능력이 제한됩니다.",
            "AWS CloudTrail은 주로 API 호출을 기록하는 데 사용되며, X-Ray가 제공하는 깊이 있는 요청 추적 기능을 제공하지 않으므로 마이크로서비스 애플리케이션의 성능 병목 현상을 식별하는 데 덜 효과적입니다.",
            "Amazon CloudWatch 메트릭과 로그는 모니터링에 유용하지만, AWS X-Ray가 제공하는 요청 추적 및 자세한 성능 통찰력 수준을 제공하지 않으므로 마이크로서비스 디버깅에 필수적입니다."
        ]
    },
    {
        "Question Number": "21",
        "Situation": "한 전자상거래 회사는 웹 서버와 데이터베이스를 포함한 다양한 작업을 처리하는 여러 EC2 인스턴스를 운영하고 있습니다. 운영 팀은 이러한 인스턴스의 성능과 상태를 모니터링하여 문제에 신속하게 대응할 수 있도록 해야 합니다. 그들은 더 나은 가시성과 로깅 기능을 위해 AWS 서비스를 사용하여 모니터링 에이전트를 설치하고 구성하는 것을 고려하고 있습니다.",
        "Question": "다양한 환경의 모든 EC2 인스턴스에 모니터링 에이전트를 설치하고 구성하는 가장 효율적인 방법은 무엇입니까?",
        "Options": {
            "1": "CloudWatch 에이전트가 미리 설치된 사용자 지정 AMI를 생성하고 이 AMI를 모든 새로운 EC2 인스턴스에 사용하여 필요한 모니터링 기능이 포함되도록 합니다.",
            "2": "AWS CloudFormation을 활용하여 EC2 인스턴스에 CloudWatch 에이전트를 설치하는 리소스를 포함하는 스택을 정의합니다.",
            "3": "각 EC2 인스턴스에 수동으로 SSH로 접속하여 CloudWatch 에이전트를 설치하고 각 인스턴스의 특정 작업 부하에 따라 구성합니다.",
            "4": "AWS Systems Manager Run Command를 활용하여 태그로 인스턴스를 타겟팅하여 모든 EC2 인스턴스에 CloudWatch 에이전트를 설치하는 스크립트를 단일 명령으로 실행합니다."
        },
        "Correct Answer": "AWS Systems Manager Run Command를 활용하여 태그로 인스턴스를 타겟팅하여 모든 EC2 인스턴스에 CloudWatch 에이전트를 설치하는 스크립트를 단일 명령으로 실행합니다.",
        "Explanation": "AWS Systems Manager Run Command를 사용하면 여러 EC2 인스턴스에서 스크립트를 중앙 집중식으로 관리하고 동시에 실행할 수 있어 모니터링 에이전트를 설치하고 구성하는 가장 효율적인 방법입니다. 이 접근 방식은 수동 개입을 최소화하고 불일치의 위험을 줄입니다.",
        "Other Options": [
            "각 인스턴스에 수동으로 SSH로 접속하는 것은 시간이 많이 소요되고 인적 오류가 발생할 수 있어 여러 인스턴스를 관리하는 데 비효율적입니다.",
            "CloudWatch 에이전트가 미리 설치된 사용자 지정 AMI를 생성하는 것은 새로운 인스턴스에 유용하지만, 모니터링 에이전트를 설치해야 하는 기존 인스턴스에는 적용되지 않습니다.",
            "AWS CloudFormation을 사용하는 것은 CloudWatch 에이전트 설치를 자동화할 수 있지만, 스택을 생성하고 관리해야 하므로 Systems Manager Run Command를 사용하는 것보다 빠른 설치에는 덜 직관적일 수 있습니다."
        ]
    },
    {
        "Question Number": "22",
        "Situation": "DevOps 엔지니어가 높은 가용성과 빠른 읽기 성능을 요구하는 애플리케이션을 위한 데이터베이스 아키텍처를 설계해야 합니다. 이 애플리케이션은 상당한 양의 읽기 트래픽을 처리할 것으로 예상되며, 가끔 쓰기 작업이 발생합니다. 엔지니어는 이러한 요구 사항을 충족하기 위해 적절한 구성으로 Amazon RDS를 사용하는 것을 고려하고 있습니다.",
        "Question": "엔지니어가 높은 가용성을 보장하면서 최적의 읽기 성능을 달성하기 위해 어떤 구성을 구현해야 합니까?",
        "Options": {
            "1": "단일 인스턴스의 Amazon RDS를 사용하고 자동 백업을 구성하여 데이터 내구성을 보장하며, 인스턴스에 대해 읽기와 쓰기를 모두 수행합니다.",
            "2": "Amazon RDS를 Multi-AZ 구성으로 설정하고 동기식 데이터 복제를 활성화하지만, 비용을 최소화하기 위해 읽기 복제본을 사용하지 않습니다.",
            "3": "비용 절감을 위해 예약 인스턴스를 사용하여 Amazon RDS를 배포하고 읽기 및 쓰기 작업을 분산하기 위해 샤딩된 데이터베이스 설정을 만듭니다.",
            "4": "장애 조치를 지원하기 위해 Multi-AZ 배포로 Amazon RDS를 구성하고 읽기 트래픽을 효율적으로 처리하기 위해 최대 다섯 개의 읽기 복제본을 설정합니다."
        },
        "Correct Answer": "장애 조치를 지원하기 위해 Multi-AZ 배포로 Amazon RDS를 구성하고 읽기 트래픽을 효율적으로 처리하기 위해 최대 다섯 개의 읽기 복제본을 설정합니다.",
        "Explanation": "이 옵션은 Multi-AZ 배포를 통해 높은 가용성을 제공하고, 읽기 복제본을 활용하여 읽기 작업을 효과적으로 확장함으로써 읽기 성능을 최적화합니다.",
        "Other Options": [
            "이 옵션은 단일 인스턴스에 의존하므로 높은 가용성이 부족하며, 실패 시 위험이 있습니다. 또한 높은 읽기 성능 요구 사항을 충족하지 않습니다.",
            "이 옵션은 높은 가용성을 제공하지만, 높은 읽기 트래픽을 효과적으로 처리하는 데 필수적인 읽기 복제본을 활용하지 않습니다.",
            "이 옵션은 읽기 작업을 확장하는 데 중요한 읽기 복제본을 피하라고 제안합니다. 높은 가용성을 제공하지만, 애플리케이션의 성능 요구 사항을 충족하지 않습니다."
        ]
    },
    {
        "Question Number": "23",
        "Situation": "소매 회사가 고객 주문을 실시간으로 처리하는 시스템을 개발하고 있습니다. 이 솔루션은 새로운 주문이 접수될 때마다 이행 팀에 알림을 보내야 합니다. 회사는 폴링 메커니즘의 필요성을 최소화하여 이벤트 기반 아키텍처를 활용하고자 합니다. 시스템은 확장성과 신뢰성을 위해 AWS 서비스를 활용하도록 설계되었습니다.",
        "Question": "새로운 주문이 접수될 때 이행 팀에 실시간 알림을 가장 잘 제공할 수 있는 솔루션은 무엇입니까?",
        "Options": {
            "1": "새로운 주문 메시지를 보관하기 위해 Amazon SQS 큐를 구현하고, 이행 팀이 이를 폴링합니다.",
            "2": "주문 이벤트를 캡처하고 이행 팀에 알림을 보내는 AWS Lambda 함수를 호출하는 Amazon EventBridge 규칙을 설정합니다.",
            "3": "새로운 주문 파일이 업로드될 때 Amazon SNS 주제를 트리거하는 Amazon S3 이벤트 알림을 구성합니다.",
            "4": "몇 분마다 새로운 주문을 확인하고 이행 팀에 알림을 보내는 예약된 AWS Lambda 함수를 생성합니다."
        },
        "Correct Answer": "주문 이벤트를 캡처하고 이행 팀에 알림을 보내는 AWS Lambda 함수를 호출하는 Amazon EventBridge 규칙을 설정합니다.",
        "Explanation": "Amazon EventBridge를 사용하면 매우 확장 가능하고 이벤트 기반 아키텍처를 구축할 수 있습니다. 새로운 주문과 관련된 이벤트를 캡처하고 Lambda 함수를 트리거하여 실시간 알림을 보낼 수 있어 이행 팀과의 신속한 소통을 보장합니다.",
        "Other Options": [
            "Amazon S3 이벤트 알림을 사용하는 것은 주문이 S3에 파일로 저장되지 않는 한 적합하지 않습니다.",
            "예약된 AWS Lambda 함수는 지연을 초래하며, 즉각적인 이벤트 반응이 아닌 폴링에 의존하므로 진정한 이벤트 기반이 아닙니다.",
            "Amazon SQS 큐를 구현하면 이행 팀이 메시지를 폴링해야 하므로 알림이 지연될 수 있으며, 완전한 이벤트 기반 설계를 활용하지 않습니다."
        ]
    },
    {
        "Question Number": "24",
        "Situation": "회사가 AWS로 중요한 애플리케이션을 마이그레이션하고 있으며, 강력한 재해 복구 계획을 구현해야 합니다. 애플리케이션은 높은 가용성과 복원력을 보장하기 위해 여러 AWS 리전에서 실행됩니다. 회사는 재해 발생 시 다운타임과 데이터 손실을 최소화하고자 합니다. 운영 팀은 보조 리전에서 애플리케이션을 신속하게 복원할 수 있는 복구 절차를 수립해야 합니다. 이들은 이 솔루션을 구현하기 위한 여러 옵션을 고려하고 있습니다.",
        "Question": "회사의 복원력 및 최소 다운타임 요구 사항을 가장 잘 충족하는 복구 절차는 무엇입니까?",
        "Options": {
            "1": "AWS CloudFormation을 사용하여 보조 리전에서 전체 인프라를 복제하고, 실패가 발생할 경우 스택 업데이트를 수동으로 트리거합니다.",
            "2": "Amazon S3 교차 리전 복제를 설정하여 애플리케이션 데이터를 보조 리전으로 지속적으로 복제하여 복구를 위한 데이터 가용성을 보장합니다.",
            "3": "Amazon RDS Multi-Region 읽기 복제본을 배포하여 다른 리전에서 데이터베이스의 백업을 제공하고, 중단 시 신속한 장애 조치를 가능하게 합니다.",
            "4": "Amazon Route 53 헬스 체크 및 DNS 장애 조치를 구현하여 기본 리전이 실패할 경우 트래픽을 보조 리전으로 리디렉션합니다."
        },
        "Correct Answer": "Amazon Route 53 헬스 체크 및 DNS 장애 조치를 구현하여 기본 리전이 실패할 경우 트래픽을 보조 리전으로 리디렉션합니다.",
        "Explanation": "Amazon Route 53 헬스 체크 및 DNS 장애 조치를 사용하면 기본 리전에서 실패가 발생할 경우 트래픽을 보조 리전으로 자동으로 리디렉션할 수 있는 효율적인 방법을 제공합니다. 이를 통해 다운타임을 최소화하고 중요한 애플리케이션의 높은 가용성을 보장합니다.",
        "Other Options": [
            "AWS CloudFormation을 사용하여 인프라를 복제하는 것은 업데이트를 트리거하기 위해 수동 개입이 필요하므로 재해 발생 시 복구 시간이 길어지고 다운타임이 증가할 수 있습니다.",
            "S3 교차 리전 복제는 주로 데이터 복제를 위한 것이지만, 애플리케이션 수준의 가용성을 다루거나 전체 애플리케이션 스택에 대한 자동 장애 조치 메커니즘을 제공하지 않습니다.",
            "RDS Multi-Region 읽기 복제본을 배포하면 데이터 가용성을 보장하지만, 데이터베이스 외의 다른 구성 요소를 포함할 수 있는 전체 애플리케이션 인프라에 대한 완전한 재해 복구 솔루션을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "25",
        "Situation": "한 회사가 Amazon EC2 인스턴스와 컨테이너 이미지를 배포하기 위한 지속적 통합 및 지속적 배포(CI/CD) 파이프라인을 구현하고자 합니다. DevOps 엔지니어는 환경 전반에 걸쳐 일관성과 효율성을 보장하기 위해 EC2 인스턴스와 컨테이너 이미지 빌드 프로세스를 자동화하는 임무를 맡았습니다.",
        "Question": "DevOps 엔지니어가 EC2 인스턴스와 컨테이너 이미지 빌드 프로세스를 효과적으로 자동화하기 위해 어떤 방법을 사용해야 합니까? (두 가지 선택)",
        "Options": {
            "1": "EC2 인스턴스의 정기적인 스냅샷을 예약하여 이미지를 최신 상태로 유지합니다.",
            "2": "EC2 Image Builder를 활용하여 EC2 이미지를 자동으로 생성하고 관리합니다.",
            "3": "AWS CloudFormation을 사용하여 인프라 및 컨테이너 이미지를 정의하고 프로비저닝합니다.",
            "4": "최신 업데이트가 적용되도록 기존 EC2 인스턴스에서 수동으로 AMI를 생성합니다.",
            "5": "AWS CodePipeline을 구현하여 컨테이너 이미지의 빌드 및 배포 프로세스를 조정합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "EC2 Image Builder를 활용하여 EC2 이미지를 자동으로 생성하고 관리합니다.",
            "AWS CodePipeline을 구현하여 컨테이너 이미지의 빌드 및 배포 프로세스를 조정합니다."
        ],
        "Explanation": "EC2 Image Builder를 사용하면 EC2 이미지를 자동으로 생성하고 관리할 수 있어 정의된 기준에 따라 일관되게 빌드됩니다. AWS CodePipeline을 구현하면 컨테이너 이미지의 전체 빌드 및 배포 프로세스를 조정할 수 있어 지속적 통합 및 배포가 가능합니다.",
        "Other Options": [
            "기존 EC2 인스턴스에서 AMI를 수동으로 생성하는 것은 자동화에 효율적인 방법이 아니며 빌드 간 일관성을 보장하지 않습니다.",
            "EC2 인스턴스의 정기적인 스냅샷 예약은 이미지를 빌드하거나 CI/CD 파이프라인을 효과적으로 관리하는 방법을 제공하지 않습니다.",
            "AWS CloudFormation을 사용하는 것은 인프라 프로비저닝에 유용하지만 EC2 이미지 빌드 또는 컨테이너 이미지 프로세스의 자동화에 구체적으로 대응하지 않습니다."
        ]
    },
    {
        "Question Number": "26",
        "Situation": "개발 팀이 AWS CodePipeline을 사용하여 CI/CD 파이프라인을 구현하고 있습니다. 이 파이프라인은 사전 프로덕션 환경에 배포하고 수동 승인을 요구한 후 프로덕션 환경에 배포하는 세 가지 주요 단계로 구성됩니다. 또한 팀은 파이프라인 실행의 일환으로 Lambda 함수 또는 Step Function을 호출하는 외부 작업을 트리거해야 합니다.",
        "Question": "팀이 이러한 요구 사항을 가장 적은 복잡성으로 충족할 수 있는 구성 조합은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "Lambda 함수를 사용하여 파이프라인의 수동 승인 단계를 처리합니다.",
            "2": "배포 작업의 runOrder를 동일한 정수로 설정하여 병렬로 실행합니다.",
            "3": "사전 프로덕션 배포 작업의 일환으로 Lambda 함수를 호출합니다.",
            "4": "수동 승인 작업을 사전 프로덕션 배포 단계 이후에 배치하도록 구성합니다.",
            "5": "프로덕션 배포 단계 이후에 시작되는 Step Function을 생성합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "배포 작업의 runOrder를 동일한 정수로 설정하여 병렬로 실행합니다.",
            "수동 승인 작업을 사전 프로덕션 배포 단계 이후에 배치하도록 구성합니다."
        ],
        "Explanation": "배포 작업의 runOrder를 동일한 정수로 설정하면 여러 작업을 병렬로 실행할 수 있어 파이프라인 실행 시간을 최적화합니다. 또한 수동 승인 작업을 사전 프로덕션 배포 단계 이후에 배치하면 워크플로우에서 적절한 시점에 발생하여 프로덕션으로 진행하기 전에 필요한 검증을 수행할 수 있습니다.",
        "Other Options": [
            "Lambda 함수를 사용하여 수동 승인 단계를 처리하는 것은 CodePipeline이 이미 내장된 수동 승인 작업을 제공하므로 불필요한 복잡성을 추가합니다.",
            "프로덕션 배포 단계 이후에 시작되는 Step Function을 생성하는 것은 파이프라인 실행 중 작업을 수행해야 하는 요구 사항과 일치하지 않으며 추가적인 관리 오버헤드를 초래합니다.",
            "사전 프로덕션 배포 작업의 일환으로 Lambda 함수를 호출하는 것은 사전 프로덕션과 프로덕션 배포 간의 수동 승인 단계를 충족하지 않습니다."
        ]
    },
    {
        "Question Number": "27",
        "Situation": "AWS에 호스팅된 마이크로서비스 애플리케이션의 빌드 프로세스를 개선하는 임무를 맡았습니다. 현재 빌드 프로세스는 느리고 종종 일관되지 않은 빌드 아티팩트를 생성하여 배포 실패로 이어집니다. 신뢰할 수 있고 반복 가능한 빌드를 보장하면서 빌드 시간을 최적화하는 솔루션을 구현해야 합니다.",
        "Question": "AWS CodeBuild를 사용하여 마이크로서비스 애플리케이션의 빌드 프로세스를 가장 잘 향상시킬 수 있는 행동은 무엇입니까?",
        "Options": {
            "1": "각 마이크로서비스에 대해 Docker 이미지를 사용하는 AWS CodeBuild에서 빌드 프로젝트를 구성하여 일관된 빌드 환경을 보장합니다.",
            "2": "의존성을 캐시하여 후속 빌드를 가속화하는 빌드스펙 파일을 사용하여 AWS CodeBuild를 구현합니다.",
            "3": "모든 마이크로서비스의 빌드 명령을 포함하도록 빌드스펙 파일을 설정하여 AWS CodeBuild를 사용하여 모든 마이크로서비스의 빌드를 동시에 실행합니다.",
            "4": "저장소에 대한 모든 커밋 시 빌드를 트리거하는 빌드 파이프라인을 AWS CodePipeline에서 설정합니다."
        },
        "Correct Answer": "의존성을 캐시하여 후속 빌드를 가속화하는 빌드스펙 파일을 사용하여 AWS CodeBuild를 구현합니다.",
        "Explanation": "AWS CodeBuild에서 의존성을 캐시하면 이전에 다운로드한 의존성을 재사용하여 빌드 시간을 단축할 수 있으며, 이는 여러 의존성이 있는 대규모 프로젝트에 특히 유용합니다. 이 전략은 빌드 성능과 일관성을 크게 향상시킬 수 있습니다.",
        "Other Options": [
            "각 마이크로서비스에 대해 Docker 이미지를 사용하는 것은 일관성을 개선할 수 있지만, 빌드 속도나 아티팩트 일관성을 직접적으로 해결하지 않으며 여러 이미지를 관리하는 복잡성을 초래할 수 있습니다.",
            "모든 커밋 시 빌드를 트리거하는 것은 불필요한 빌드를 초래할 수 있으며, 특히 변경 사항이 사소하거나 빌드되는 마이크로서비스와 관련이 없는 경우 비용과 빌드 대기 시간을 증가시킬 수 있습니다.",
            "모든 마이크로서비스의 빌드를 동시에 실행하는 것은 리소스 집약적인 빌드의 경우 리소스 경합을 초래할 수 있으며, 전체 프로세스를 개선하기보다는 오히려 느리게 만들 수 있습니다."
        ]
    },
    {
        "Question Number": "28",
        "Situation": "한 회사가 애플리케이션을 AWS로 마이그레이션하고 있으며, 온프레미스 사용자를 위한 아이덴티티 연합을 구현하고자 합니다. 목표는 사용자가 별도의 IAM 사용자 계정을 생성하지 않고도 AWS 리소스에 접근할 수 있도록 하는 것입니다. 이 회사는 특히 SAML 기반 아이덴티티 공급자를 사용하는 데 관심이 있습니다.",
        "Question": "온프레미스 사용자가 AWS 리소스에 접근하기 위한 아이덴티티 연합을 설정하는 가장 효과적인 방법은 무엇입니까?",
        "Options": {
            "1": "AWS Single Sign-On을 온프레미스 Active Directory와 통합하여 AWS 서비스 전반에 걸쳐 사용자 접근을 관리합니다.",
            "2": "AWS Organizations를 사용하여 여러 계정 간의 접근을 관리하고 각 계정에 대해 별도의 IAM 아이덴티티 공급자를 생성합니다.",
            "3": "모든 온프레미스 사용자에 대해 AWS에서 IAM 사용자를 생성하고 개별적으로 권한을 관리합니다.",
            "4": "AWS IAM 역할을 구성하고 온프레미스 SAML 아이덴티티 공급자와 신뢰 관계를 설정합니다."
        },
        "Correct Answer": "AWS IAM 역할을 구성하고 온프레미스 SAML 아이덴티티 공급자와 신뢰 관계를 설정합니다.",
        "Explanation": "AWS IAM 역할을 SAML 아이덴티티 공급자와 신뢰 관계를 설정하여 구성하면 별도의 IAM 사용자 계정 없이도 AWS 리소스에 원활하게 접근할 수 있으며, 온프레미스 환경의 기존 사용자 아이덴티티를 활용할 수 있습니다.",
        "Other Options": [
            "모든 온프레미스 사용자에 대해 IAM 사용자를 생성하면 관리 오버헤드가 증가하며, 연합을 사용할 수 있을 때는 필요하지 않습니다.",
            "AWS Organizations를 사용하는 것은 아이덴티티 연합을 직접적으로 촉진하지 않으며, 기존 아이덴티티로 AWS 리소스에 접근하는 데 추가 이점 없이 설정을 복잡하게 만듭니다.",
            "AWS Single Sign-On을 Active Directory와 통합하는 것은 유용하지만, 회사가 온프레미스 아이덴티티 공급자로부터 SAML 기반 연합을 직접 활용하고자 할 경우 최선의 솔루션이 아닐 수 있습니다."
        ]
    },
    {
        "Question Number": "29",
        "Situation": "한 조직이 데이터 보호 규정을 준수하는 것에 대해 우려하고 있습니다. 그들은 AWS 서비스를 사용하여 민감한 고객 데이터를 호스팅하고 있으며, 보안 위협 및 규정 위반을 지속적으로 모니터링할 수 있는 솔루션을 구현해야 합니다. DevOps 엔지니어는 이러한 요구 사항을 충족할 적절한 서비스를 선택하는 임무를 맡고 있습니다.",
        "Question": "DevOps 엔지니어가 AWS 환경을 모니터링하고 데이터 보호 규정을 준수하기 위해 어떤 AWS 서비스를 구현해야 합니까?",
        "Options": {
            "1": "AWS Shield를 사용하여 DDoS 보호를 제공하고 애플리케이션 가용성에 영향을 미치는 네트워크 공격으로부터 보호합니다.",
            "2": "AWS CloudTrail을 사용하여 API 활동을 기록하고 AWS 리소스의 변경 사항을 모니터링하여 규정 준수를 감사합니다.",
            "3": "AWS Config를 사용하여 구성 변경 사항을 추적하고 보안 모니터링을 위해 정책에 대한 리소스 준수를 평가합니다.",
            "4": "Amazon Inspector를 사용하여 보안 평가를 수행하고 배포된 애플리케이션 및 서비스의 취약점을 식별합니다."
        },
        "Correct Answer": "AWS Config를 사용하여 구성 변경 사항을 추적하고 보안 모니터링을 위해 정책에 대한 리소스 준수를 평가합니다.",
        "Explanation": "AWS Config는 AWS 리소스 구성에 대한 지속적인 모니터링 및 평가를 제공하도록 설계되어 있어 조직이 내부 정책 및 외부 규정을 준수할 수 있도록 합니다. 시간에 따른 변경 사항을 추적하여 감사 및 규정 준수 목적으로 적합합니다.",
        "Other Options": [
            "AWS CloudTrail은 API 호출을 기록하고 모니터링하는 데 유용하지만, AWS Config가 제공하는 실시간 규정 준수 평가 및 리소스 구성 추적 기능은 제공하지 않습니다.",
            "Amazon Inspector는 애플리케이션 수준에서 보안 취약점을 식별하는 데 중점을 두지만, AWS 리소스 구성의 정책 준수를 모니터링하지 않습니다.",
            "AWS Shield는 DDoS 공격으로부터 보호를 제공하며, 주로 가용성과 네트워크 위협에 대한 보안에 중점을 두고 있어 규정 준수 모니터링 및 감사에는 초점을 맞추지 않습니다."
        ]
    },
    {
        "Question Number": "30",
        "Situation": "한 회사가 확장 가능하고 고가용성의 백엔드 데이터베이스가 필요한 모바일 애플리케이션을 구축하고 있습니다. 이 애플리케이션은 사용자 프로필, 애플리케이션 설정 및 거래 기록을 저장합니다. 개발 팀은 예측 가능한 성능, 자동 확장 및 접근 제어를 위한 AWS Identity and Access Management (IAM)와의 통합을 제공할 수 있는 NoSQL 데이터베이스를 선택해야 합니다. 또한, 일관성 모델의 차이와 데이터를 효과적으로 구조화하는 방법을 이해해야 합니다.",
        "Question": "이 모바일 애플리케이션에 대해 Amazon DynamoDB를 최적의 성능과 데이터 접근 패턴을 보장하면서 활용하는 가장 좋은 방법은 무엇입니까?",
        "Options": {
            "1": "DynamoDB에서 사용자 ID에 대한 해시 키와 거래 타임스탬프에 대한 범위 키로 구성된 복합 기본 키를 가진 단일 테이블을 사용합니다. 비용을 줄이기 위해 읽기 작업에 대해 최종 일관성을 사용하도록 테이블을 구성합니다.",
            "2": "DynamoDB에서 사용자 프로필, 애플리케이션 설정 및 거래 기록을 위한 별도의 테이블을 생성합니다. 데이터 정확성을 보장하기 위해 모든 읽기 작업에 대해 강한 일관성을 사용합니다.",
            "3": "사용자 프로필 테이블에 대해 글로벌 보조 인덱스(GSI)를 구현하여 애플리케이션 설정에 따라 쿼리를 처리합니다. 성능을 향상시키기 위해 모든 읽기 작업에 대해 강한 일관성을 사용합니다.",
            "4": "DynamoDB의 내장 자동 확장 기능을 각 테이블에 활용하여 읽기 용량 단위(RCUs)와 쓰기 용량 단위(WCUs)를 고정 값으로 설정하여 예측 가능한 성능을 유지합니다."
        },
        "Correct Answer": "DynamoDB에서 사용자 ID에 대한 해시 키와 거래 타임스탬프에 대한 범위 키로 구성된 복합 기본 키를 가진 단일 테이블을 사용합니다. 비용을 줄이기 위해 읽기 작업에 대해 최종 일관성을 사용하도록 테이블을 구성합니다.",
        "Explanation": "복합 기본 키를 가진 단일 테이블을 사용하면 DynamoDB에서 사용자 ID 및 거래 타임스탬프에 대한 접근을 위한 효율적인 데이터 검색 및 저장 패턴을 제공합니다. 최종 일관성은 비용을 줄이면서 많은 모바일 애플리케이션에 충분한 성능을 제공합니다.",
        "Other Options": [
            "별도의 테이블을 생성하면 비효율적인 데이터 접근 패턴과 엔티티 간의 관계 관리 복잡성이 증가할 수 있습니다. 이 접근 방식은 또한 단일 테이블 내에서 여러 데이터 유형을 처리하는 DynamoDB의 강점을 활용하지 않습니다.",
            "RCUs와 WCUs에 대해 고정 값을 설정하면 높은 부하 기간 동안 스로틀링이 발생하거나 낮은 사용 기간 동안 불필요한 비용이 발생할 수 있으며, 이는 DynamoDB의 자동 확장 기능을 활용하지 않기 때문입니다.",
            "GSI를 구현하면 쿼리 기능이 향상될 수 있지만, 모든 읽기에 대해 강한 일관성을 사용하는 것은 비용과 지연을 증가시킬 수 있으며, 최종 일관성이 애플리케이션의 요구 사항에 충분하다면 필요하지 않을 수 있습니다."
        ]
    },
    {
        "Question Number": "31",
        "Situation": "조직은 Amazon CloudWatch 메트릭을 데이터 레이크로 스트리밍하여 가시성을 향상시키고자 합니다. 데이터 레이크는 Amazon S3에 호스팅되며, 조직은 Kinesis Data Firehose를 데이터 스트리밍에 사용하고자 합니다. 그들은 CloudWatch에서 메트릭 스트림을 생성하고 메트릭을 Kinesis Data Firehose로 전송할 수 있는 솔루션이 필요합니다.",
        "Question": "CloudWatch 메트릭 스트림을 설정하여 Amazon S3에 저장하기 위해 Kinesis Data Firehose로 메트릭을 전송하는 가장 효과적인 방법은 무엇입니까?",
        "Options": {
            "1": "CloudWatch 메트릭 스트림을 생성하고 Kinesis Data Firehose를 사용하지 않고 직접 Amazon S3로 메트릭을 전송하도록 구성합니다.",
            "2": "CloudWatch를 구성하여 메트릭을 Amazon Kinesis Data Streams로 직접 전송하고, 이후 Amazon S3로 전달하도록 합니다.",
            "3": "CloudWatch 메트릭 스트림을 설정하고 메트릭의 목적지로 Kinesis Data Firehose 배달 스트림을 지정합니다.",
            "4": "AWS CLI를 사용하여 CloudWatch 메트릭 스트림을 생성하고 메트릭을 Amazon Kinesis Data Streams로 푸시한 다음, Lambda 함수를 사용하여 Kinesis Data Firehose로 데이터를 전송합니다."
        },
        "Correct Answer": "CloudWatch 메트릭 스트림을 설정하고 메트릭의 목적지로 Kinesis Data Firehose 배달 스트림을 지정합니다.",
        "Explanation": "이 옵션은 CloudWatch 메트릭 스트림을 생성하고 메트릭을 Kinesis Data Firehose로 라우팅하는 과정을 정확하게 설명합니다. Kinesis Data Firehose는 이러한 유형의 데이터를 처리하도록 설계되었으며, Amazon S3에 저장하고 분석하기 위해 쉽게 전달할 수 있습니다.",
        "Other Options": [
            "이 옵션은 CloudWatch가 메트릭을 직접 Amazon S3로 전송할 수 없기 때문에 잘못되었습니다. 전송을 용이하게 하기 위해 Kinesis Data Firehose와 같은 중개자가 필요합니다.",
            "이 옵션은 CloudWatch와 Kinesis를 포함하지만 Lambda 함수를 사용하여 불필요한 복잡성을 도입합니다. CloudWatch에서 Kinesis Data Firehose로의 직접 스트림이 더 효율적입니다.",
            "이 옵션은 Kinesis Data Streams를 Kinesis Data Firehose 대신 사용하라고 제안하므로 잘못되었습니다. Amazon S3에 저장하는 것이 목표일 때 메트릭의 의도된 목적지가 아닙니다."
        ]
    },
    {
        "Question Number": "32",
        "Situation": "개발 팀은 성능과 확장성을 개선하기 위해 클러스터 모드가 활성화된 Amazon ElastiCache for Redis를 애플리케이션에 사용하고 있습니다. 팀은 Redis 클러스터에 대한 연결을 효율적으로 관리하고 애플리케이션이 읽기 및 쓰기 작업을 위한 적절한 엔드포인트를 동적으로 발견할 수 있도록 해야 합니다. 그들은 클라우드 네이티브 방식으로 이를 달성할 수 있는 최선의 방법을 찾고 있습니다.",
        "Question": "클러스터 모드가 활성화된 Amazon ElastiCache for Redis 클러스터에서 구성 엔드포인트를 사용하는 주요 이점은 무엇입니까?",
        "Options": {
            "1": "각 샤드의 기본 및 읽기 복제본에 대한 엔드포인트 발견을 단순화합니다.",
            "2": "자동 백업을 활성화하여 데이터 내구성을 향상시킵니다.",
            "3": "클러스터 전체에서 모든 쓰기 작업을 위한 단일 엔드포인트를 제공합니다.",
            "4": "정전 시 복제 노드로 자동 장애 조치를 허용합니다."
        },
        "Correct Answer": "각 샤드의 기본 및 읽기 복제본에 대한 엔드포인트 발견을 단순화합니다.",
        "Explanation": "클러스터 모드가 활성화된 Amazon ElastiCache for Redis 클러스터의 구성 엔드포인트는 각 샤드의 기본 및 읽기 엔드포인트 발견을 용이하게 하도록 설계되어 애플리케이션의 연결 관리를 단순화합니다. 이를 통해 애플리케이션은 특정 샤드를 미리 알 필요 없이 요청을 올바른 노드로 쉽게 라우팅할 수 있습니다.",
        "Other Options": [
            "이것은 잘못된 것입니다. 구성 엔드포인트는 쓰기 작업만 처리하지 않으며, 샤드 전반에 걸쳐 적절한 기본 및 읽기 복제본으로 라우팅하는 정보를 제공합니다.",
            "이것은 잘못된 것입니다. 자동 장애 조치는 ElastiCache의 기능이지만, 구성 엔드포인트는 장애 조치를 관리하지 않으며 주로 엔드포인트 발견을 지원합니다.",
            "이것은 잘못된 것입니다. 자동 백업이 데이터 내구성을 향상시키지만, 이는 엔드포인트 발견 관리와 관련이 없습니다."
        ]
    },
    {
        "Question Number": "33",
        "Situation": "글로벌 전자상거래 플랫폼이 AWS로 서비스를 마이그레이션하고 있으며, 웹 애플리케이션이 여러 지역에서 복원력 있고 가용성이 있도록 해야 합니다. 이 플랫폼은 전 세계 고객에게 서비스를 제공하며, DevOps 팀은 지역 정전 중에도 자동으로 확장되고 높은 가용성을 유지하는 솔루션을 설계하는 임무를 맡고 있습니다.",
        "Question": "팀이 애플리케이션의 글로벌 확장성과 복원력을 달성하기 위해 구현해야 할 전략은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "하나의 지역에 단일 Amazon RDS 인스턴스를 구현하고 이를 모든 지역의 애플리케이션 인스턴스에 대한 기본 데이터베이스로 구성합니다.",
            "2": "AWS CloudFormation을 사용하여 애플리케이션 및 그 종속성을 자동으로 배포하는 여러 지역에 스택을 생성합니다.",
            "3": "각 지역에 Amazon Elastic Load Balancer (ELB)를 설정하고 교차 지역 로드 밸런싱을 구성하여 트래픽을 고르게 분산합니다.",
            "4": "여러 AWS 지역에 애플리케이션을 배포하고 Amazon Route 53을 사용하여 지리적 라우팅으로 사용자를 가장 가까운 지역으로 안내합니다.",
            "5": "Amazon S3를 사용하여 교차 지역 복제를 활용하여 모든 정적 자산이 모든 지역에서 사용 가능하도록 합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "여러 AWS 지역에 애플리케이션을 배포하고 Amazon Route 53을 사용하여 지리적 라우팅으로 사용자를 가장 가까운 지역으로 안내합니다.",
            "Amazon S3를 사용하여 교차 지역 복제를 활용하여 모든 정적 자산이 모든 지역에서 사용 가능하도록 합니다."
        ],
        "Explanation": "여러 AWS 지역에 애플리케이션을 배포하고 Route 53 지리적 라우팅을 사용하면 사용자를 가장 가까운 지역으로 안내하여 성능과 가용성을 향상시킬 수 있습니다. 또한, S3의 교차 지역 복제를 사용하면 정적 자산이 전 세계적으로 일관되게 제공되어 원활한 사용자 경험에 필수적입니다.",
        "Other Options": [
            "각 지역에 ELB를 설정하고 교차 지역 로드 밸런싱을 구성하는 것은 직접 지원되지 않습니다. ELB는 단일 지역 내에서만 트래픽을 분산할 수 있습니다. 따라서 이 옵션은 글로벌 확장성 요구 사항을 효과적으로 해결하지 않습니다.",
            "하나의 지역에 단일 Amazon RDS 인스턴스를 구현하면 단일 실패 지점이 생성되며, 전 세계적으로 분산된 애플리케이션에 필요한 복원력을 제공하지 않습니다. 각 지역은 이상적으로 고가용성을 위해 자체 데이터베이스 인스턴스를 가져야 합니다.",
            "여러 지역에 스택을 생성하기 위해 AWS CloudFormation을 사용하는 것은 배포에 대한 좋은 관행이지만, 애플리케이션 복원력 및 글로벌 확장성의 필요성을 직접적으로 해결하지 않습니다. 이 옵션은 더 넓은 전략의 일부여야 합니다."
        ]
    },
    {
        "Question Number": "34",
        "Situation": "한 회사가 여러 계정과 지역에서 리소스 준수를 모니터링하기 위해 AWS Config를 설정했습니다. 그들은 특정 준수 규칙에 대한 자동 수정 기능을 구현하고 AWS Config에서 감지된 비준수에 대한 경고를 구성할 필요가 있습니다. DevOps 팀은 경고가 실행 가능하고 특정 SNS 주제를 대상으로 하도록 보장하고자 합니다.",
        "Question": "DevOps 팀이 특정 AWS Config 규칙에 대한 경고를 분리하고 자동 수정이 올바르게 설정되도록 하려면 어떤 구성을 해야 합니까?",
        "Options": {
            "1": "AWS Config 집계를 설정하여 모든 계정과 지역에서 준수 데이터를 수집합니다. 준수 규칙 평가를 기반으로 특정 SNS 주제를 대상으로 하는 EventBridge 규칙을 생성합니다.",
            "2": "각 계정과 지역에 AWS Config 규칙을 별도로 생성합니다. EventBridge를 사용하여 비준수 이벤트를 SNS 주제로 라우팅하고, 수정 작업을 위해 AWS Lambda 함수를 구성합니다.",
            "3": "AWS Config를 구성하여 단일 계정과 지역의 리소스를 모니터링합니다. EventBridge를 사용하여 준수 알림을 위한 규칙을 생성하고 이를 SNS 주제에 연결합니다.",
            "4": "AWS Organizations를 사용하여 조직 수준에서 AWS Config 규칙을 구현하고 비준수에 대한 SNS 주제를 알리기 위해 CloudWatch 경고를 설정합니다. 수정 작업을 위해 AWS Lambda를 사용합니다."
        },
        "Correct Answer": "AWS Config 집계를 설정하여 모든 계정과 지역에서 준수 데이터를 수집합니다. 준수 규칙 평가를 기반으로 특정 SNS 주제를 대상으로 하는 EventBridge 규칙을 생성합니다.",
        "Explanation": "AWS Config 집계를 사용하면 여러 계정과 지역에서 구성 및 준수 데이터를 수집할 수 있어 대규모로 준수 규칙을 효과적으로 관리할 수 있습니다. EventBridge는 준수 평가를 기반으로 경고를 특정 SNS 주제로 라우팅하여 경고가 실행 가능하도록 보장합니다.",
        "Other Options": [
            "각 계정과 지역에 AWS Config 규칙을 별도로 생성하는 것은 비효율적이며, 준수 데이터를 통합하는 집계기의 기능을 활용하지 않기 때문에 관리하기 어렵습니다.",
            "조직 수준에서 AWS Config 규칙을 구현하는 것은 필요하지 않으며, EventBridge를 통한 타겟 경고를 허용하지 않고 모니터링 범위를 조직 전체 수준으로 제한합니다.",
            "AWS Config를 구성하여 단일 계정과 지역의 리소스를 모니터링하는 것은 여러 계정이나 지역에서 모니터링해야 하는 요구 사항을 충족하지 않으며, 이는 포괄적인 준수 관리에 중요합니다."
        ]
    },
    {
        "Question Number": "35",
        "Situation": "귀 조직은 Amazon S3를 사용하여 애플리케이션 로그를 저장하고 있습니다. 저장 비용을 최적화하기 위해 로그를 지정된 기간 후에 더 저렴한 저장 클래스으로 자동 전환하고 특정 보존 기간 후에 삭제하는 수명 주기 정책을 구현해야 합니다. 또한 CloudWatch Logs가 준수 요구 사항에 따라 특정 기간 동안 유지되도록 해야 합니다.",
        "Question": "다음 접근 방식 중 S3 및 CloudWatch 로그의 수명 주기를 효과적으로 관리하는 데 가장 도움이 되는 것은 무엇입니까?",
        "Options": {
            "1": "S3 및 CloudWatch Logs 수명 주기 정책 설정을 자동화하기 위해 CloudFormation 스택을 생성합니다. S3 수명 주기를 S3 Intelligent-Tiering으로 전환하도록 정의하고 CloudWatch Logs 보존 기간을 30일로 설정합니다.",
            "2": "S3 로그 객체의 연령을 확인하고 삭제하기 전에 90일 동안 S3 Standard-IA로 수동 전환하는 AWS Lambda 함수를 매일 실행합니다. CloudWatch Logs 보존 기간을 180일로 설정합니다.",
            "3": "S3 Object Lambda를 사용하여 로그 객체가 생성될 때마다 사용자 정의 수명 주기 정책을 적용한 다음, 1년 후에 S3에서 로그를 수동으로 삭제합니다. CloudWatch Logs 보존 기간을 30일로 설정합니다.",
            "4": "S3 수명 주기 정책을 설정하여 로그를 30일 후에 S3 Glacier로 전환하고 365일 후에 삭제합니다. CloudWatch Logs를 90일 보존 정책으로 구성합니다."
        },
        "Correct Answer": "S3 수명 주기 정책을 설정하여 로그를 30일 후에 S3 Glacier로 전환하고 365일 후에 삭제합니다. CloudWatch Logs를 90일 보존 정책으로 구성합니다.",
        "Explanation": "이 옵션은 로그를 30일 후에 더 저렴한 저장 클래스(S3 Glacier)로 전환하고 1년 후에 삭제하여 비용 효율적인 저장 관리를 효과적으로 활용합니다. 또한 CloudWatch Logs에 대해 90일의 특정 보존 기간을 설정하여 준수 요구 사항을 준수합니다.",
        "Other Options": [
            "이 옵션은 S3 Object Lambda가 수명 주기 정책을 관리하도록 설계되지 않았으며, 로그를 수동으로 삭제하는 것은 자동화 및 일관성이 부족하여 잠재적인 준수 문제를 초래할 수 있기 때문에 잘못되었습니다.",
            "이 옵션은 Lambda 함수를 사용하여 로그를 수동으로 전환하는 것이 복잡하고 오류가 발생하기 쉬우며, CloudWatch Logs의 보존 기간을 180일로 설정하는 것은 정의된 준수 요구 사항과 일치하지 않기 때문에 잘못되었습니다.",
            "이 옵션은 CloudFormation이 리소스 생성을 자동화할 수 있지만, 본질적으로 수명 주기 정책을 관리하지 않으며, S3 Intelligent-Tiering은 예측 가능한 접근 패턴을 가진 로그에 가장 비용 효율적인 선택이 아닙니다."
        ]
    },
    {
        "Question Number": "36",
        "Situation": "한 회사가 여러 서비스에 대한 트래픽을 라우팅하는 Application Load Balancer (ALB)를 사용하여 웹 애플리케이션을 배포하고 있습니다. 운영 팀은 건강한 인스턴스만 트래픽을 수신하고 비정상적인 인스턴스는 자동으로 교체되도록 보장하고자 합니다. 또한 실시간으로 대상의 건강 상태를 모니터링하고 싶어합니다.",
        "Question": "ALB가 건강한 대상에게만 트래픽을 라우팅하고 실시간 건강 모니터링을 제공하기 위해 가장 효과적인 구성은 무엇입니까?",
        "Options": {
            "1": "ALB 대상 그룹을 구성하여 HTTPS를 사용한 건강 검사를 수행하고 서비스가 건강할 때 200 상태 코드를 반환하는 경로를 지정합니다. 건강 기준을 5로, 비정상 기준을 3으로 설정합니다.",
            "2": "애플리케이션의 도메인을 모니터링하도록 구성된 Route 53 건강 검사를 사용합니다. Route 53 건강 검사 실패에 응답하는 자동 확장 그룹과 함께 ALB를 설정합니다.",
            "3": "ALB 대상 그룹을 구성하여 HTTP를 사용한 건강 검사를 수행하고 애플리케이션의 특정 경로를 확인합니다. 건강 기준을 2로, 비정상 기준을 2로 설정합니다.",
            "4": "TCP 건강 검사를 사용하는 대상 그룹으로 ALB를 설정하고 건강 기준을 3으로 설정합니다. 대상이 비정상 상태가 될 때 알리기 위해 CloudWatch 경고를 구성합니다."
        },
        "Correct Answer": "ALB 대상 그룹을 구성하여 HTTPS를 사용한 건강 검사를 수행하고 서비스가 건강할 때 200 상태 코드를 반환하는 경로를 지정합니다. 건강 기준을 5로, 비정상 기준을 3으로 설정합니다.",
        "Explanation": "건강 검사를 위해 HTTPS를 사용하면 애플리케이션이 접근 가능할 뿐만 아니라 보안도 유지됩니다. 200 상태 코드를 반환하는 경로를 지정하면 서비스가 올바르게 작동하고 있음을 확인할 수 있습니다. 기준을 설정하여 대상을 건강하거나 비정상으로 표시하기 전에 안정성을 보장하여 일시적인 문제를 고려할 수 있습니다.",
        "Other Options": [
            "ALB 대상 그룹을 HTTP 건강 검사로 구성하는 것은 HTTPS를 사용하는 것보다 보안성이 떨어지며, 2로 설정된 기준은 일시적인 문제에 대한 충분한 안정성을 제공하지 않을 수 있습니다.",
            "Route 53 건강 검사는 도메인 가용성을 모니터링할 수 있지만, ALB 뒤의 대상 건강을 직접 관리하지 않기 때문에 트래픽 라우팅에 중요합니다.",
            "TCP 건강 검사는 애플리케이션 계층을 검증하지 않으며, TCP 연결에 응답하는 경우 비정상 인스턴스를 건강한 것으로 표시할 수 있습니다. 이는 제대로 작동하지 않는 인스턴스로 트래픽을 라우팅하는 결과를 초래할 수 있습니다."
        ]
    },
    {
        "Question Number": "37",
        "Situation": "한 회사가 고가용성과 최소한의 다운타임을 요구하는 프로덕션 데이터베이스를 위해 Amazon RDS를 활용하고 있습니다. DevOps 팀은 애플리케이션 가동 시간과 데이터 무결성을 유지하면서 원활한 업그레이드 프로세스를 보장해야 합니다.",
        "Question": "Amazon RDS 업그레이드 중 다운타임을 최소화하기 위해 DevOps 엔지니어가 따라야 할 단계는 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "업그레이드 중 트래픽을 분산하기 위해 기본 RDS 인스턴스의 읽기 복제본을 생성합니다.",
            "2": "기본 인스턴스로 승격하기 전에 애플리케이션 트래픽을 읽기 복제본으로 라우팅합니다.",
            "3": "유지 관리 중 자동 장애 조치를 위해 기본 인스턴스가 Multi-AZ 배포에 있는지 확인합니다.",
            "4": "EngineVersion 속성을 사용하여 읽기 복제본을 업그레이드한 후 이를 기본 인스턴스로 승격합니다.",
            "5": "복제본의 복잡성을 피하기 위해 기본 RDS 인스턴스에서 직접 업그레이드를 수행합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "EngineVersion 속성을 사용하여 읽기 복제본을 업그레이드한 후 이를 기본 인스턴스로 승격합니다.",
            "기본 인스턴스로 승격하기 전에 애플리케이션 트래픽을 읽기 복제본으로 라우팅합니다."
        ],
        "Explanation": "EngineVersion 속성을 사용하여 읽기 복제본을 업그레이드하면 제어된 업그레이드 프로세스가 가능합니다. 업그레이드가 완료되면 읽기 복제본을 기본으로 승격하여 트래픽을 복제본으로 라우팅할 수 있어 다운타임을 최소화합니다.",
        "Other Options": [
            "읽기 복제본을 생성하는 것은 좋은 관행이지만, 업그레이드 없이 단순히 트래픽을 분산하는 것은 업그레이드 중 다운타임을 최소화하는 목표를 달성하지 못합니다.",
            "기본 인스턴스에서 직접 업그레이드를 수행하면 다운타임의 위험이 증가하며, 업그레이드 중 영향을 최소화하기 위해서는 권장되지 않습니다.",
            "Multi-AZ 배포를 통해 고가용성을 제공하지만, 업그레이드 메커니즘을 다루지 않기 때문에 업그레이드 프로세스 중 다운타임을 특별히 최소화하지는 않습니다."
        ]
    },
    {
        "Question Number": "38",
        "Situation": "한 금융 기관이 민감한 데이터를 관리하고 있으며, 애플리케이션이 TLS를 사용하여 안전하게 통신할 수 있도록 해야 합니다. 보안 팀은 모든 내부 서비스와 애플리케이션의 인증서를 관리하기 위해 강력한 공개 키 인프라(PKI)를 사용할 것을 요구합니다. DevOps 엔지니어는 높은 보안 기준을 유지하면서 인증서 관리를 간소화하는 솔루션을 구현하는 임무를 맡고 있습니다.",
        "Question": "TLS 인증서를 안전하고 자동화된 방식으로 관리하기 위한 요구 사항을 가장 잘 충족하는 솔루션은 무엇입니까?",
        "Options": {
            "1": "AWS Certificate Manager를 사용하여 AWS 서비스 및 애플리케이션에 사용할 SSL/TLS 인증서를 프로비저닝, 관리 및 배포합니다.",
            "2": "AWS Secrets Manager를 활용하여 각 애플리케이션 인스턴스에 대해 SSL/TLS 인증서를 수동으로 저장하고 검색합니다.",
            "3": "온프레미스에 제3자 PKI 솔루션을 구현하여 인증서의 생애 주기를 처리하고 AWS 서비스와 통합하여 안전한 액세스를 제공합니다.",
            "4": "각 서비스에 대해 자체 서명된 인증서를 수동으로 생성하고 이를 인프라 전반에 배포하여 통신을 보호합니다."
        },
        "Correct Answer": "AWS Certificate Manager를 사용하여 AWS 서비스 및 애플리케이션에 사용할 SSL/TLS 인증서를 프로비저닝, 관리 및 배포합니다.",
        "Explanation": "AWS Certificate Manager (ACM)는 SSL/TLS 인증서를 프로비저닝, 관리 및 배포하는 과정을 간소화하여 클라우드 환경에서 통신을 안전하게 유지하는 데 필수적입니다. 갱신 및 배포를 자동화하여 관리 부담을 줄이고 보안 기준 준수를 보장합니다.",
        "Other Options": [
            "자체 서명된 인증서를 수동으로 생성하는 것은 많은 수의 서비스를 관리하는 데 실용적이지 않으며, 인증서 배포 및 갱신과 관련된 복잡성과 잠재적인 보안 위험을 초래합니다.",
            "온프레미스에 제3자 PKI 솔루션을 구현하면 불필요한 복잡성이 추가되며, 특히 ACM과 원활하게 작동하는 기본 AWS 서비스를 사용할 때 통합 문제를 초래할 수 있습니다.",
            "AWS Secrets Manager를 사용하여 SSL/TLS 인증서를 저장하는 것은 자동 갱신 및 배포에 필요한 생애 주기 관리 기능을 제공하지 않으며, 이는 안전한 통신을 유지하는 데 필수적입니다."
        ]
    },
    {
        "Question Number": "39",
        "Situation": "클라우드 기반 전자상거래 플랫폼이 주요 제품 출시를 준비하고 있으며, 애플리케이션이 사용자 트래픽의 급증을 처리할 수 있도록 해야 합니다. 배포 프로세스의 일환으로 DevOps 팀은 높은 부하 조건에서 성능을 측정하기 위해 부하 및 스트레스 테스트를 구현하는 임무를 맡고 있습니다. 테스트는 자동화되어 CI/CD 파이프라인에 통합되어 모든 배포와 함께 실행되어야 합니다.",
        "Question": "DevOps 엔지니어가 CI/CD 파이프라인의 일환으로 부하 및 스트레스 테스트를 효과적으로 실행하기 위해 어떤 접근 방식을 취해야 합니까?",
        "Options": {
            "1": "배포 프로세스와 병행하여 부하 테스트를 실행하고 미리 정의된 임계값에 따라 메트릭을 수집하고 알림을 전송하는 AWS Lambda 함수를 구현합니다.",
            "2": "배포 중 애플리케이션 성능 메트릭을 모니터링하고 특정 메트릭이 임계값을 초과할 경우 경고를 생성하기 위해 Amazon CloudWatch를 사용합니다.",
            "3": "테스터가 각 배포 후 성능 벤치마크를 실행하고 결과를 개발 팀에 보고하는 수동 부하 테스트 프로세스를 통합합니다.",
            "4": "배포 단계 후 AWS CodePipeline을 활용하여 Apache JMeter 또는 Gatling과 같은 부하 테스트 도구를 트리거하여 각 배포에 대한 결과를 수집하고 분석합니다."
        },
        "Correct Answer": "배포 단계 후 AWS CodePipeline을 활용하여 Apache JMeter 또는 Gatling과 같은 부하 테스트 도구를 트리거하여 각 배포에 대한 결과를 수집하고 분석합니다.",
        "Explanation": "AWS CodePipeline을 사용하여 배포 단계 후 자동화된 부하 테스트 도구를 트리거하면 일관되고 반복 가능한 테스트 프로세스가 가능해져 개발 팀에 즉각적인 피드백을 제공합니다. 이 통합은 모든 배포와 함께 성능 벤치마크가 검증되도록 하여 고트래픽 시나리오에 필수적입니다.",
        "Other Options": [
            "수동 부하 테스트 프로세스를 통합하는 것은 비효율적이며 인적 오류가 발생할 수 있습니다. 이는 개발자에게 피드백을 지연시키고 자동화된 CI/CD 워크플로우에 잘 맞지 않습니다.",
            "부하 테스트를 위한 AWS Lambda 함수를 구현하는 것은 Lambda의 실행 시간 제한과 높은 사용자 부하를 시뮬레이션하는 복잡성으로 인해 효과적이지 않을 수 있습니다.",
            "Amazon CloudWatch를 사용하여 모니터링하는 것은 유용하지만, 부하 테스트를 적극적으로 수행하지는 않습니다. 배포 후 성능 메트릭에 대한 통찰력을 제공할 뿐, 부하를 시뮬레이션하지는 않습니다."
        ]
    },
    {
        "Question Number": "40",
        "Situation": "금융 기관은 AWS 리소스의 모니터링 및 감사가 의무화된 다양한 규정을 준수해야 합니다. 그들은 다양한 AWS 서비스를 보유하고 있으며, 내부 정책 및 외부 규정에 따라 리소스가 준수하는지 확인해야 합니다. 준수 팀은 AWS 리소스의 보안 설정과 관련하여 미리 정의된 규칙 집합에 대한 준수를 자동으로 확인할 수 있는 솔루션을 요청했습니다.",
        "Question": "운영 오버헤드를 최소화하여 준수 모니터링을 보장하기 위해 DevOps 엔지니어가 구현할 수 있는 솔루션은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "모든 IAM 역할에 MFA가 활성화되어 있는지 확인하고 위반 사항을 준수 팀에 알리기 위해 AWS Config 규칙을 생성합니다.",
            "2": "AWS Config의 준수 상태를 쿼리하고 준수 팀에 보고서를 보내기 위해 반복적인 AWS Lambda 함수를 설정합니다.",
            "3": "AWS CloudTrail을 배포하고 AWS 리소스 변경 사항을 모니터링하기 위해 Amazon CloudWatch에 사용자 대시보드를 설정하며, 매주 수동으로 준수를 확인합니다.",
            "4": "AWS Config를 사용하여 EC2 인스턴스가 최신 보안 패치를 사용하고 있는지 확인하는 사용자 정의 규칙을 생성하고 문제를 수동으로 해결합니다.",
            "5": "AWS Config를 구현하여 S3 버킷이 공개인지 평가하고 비준수 버킷을 자동으로 수정하는 관리 규칙을 사용합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "모든 IAM 역할에 MFA가 활성화되어 있는지 확인하고 위반 사항을 준수 팀에 알리기 위해 AWS Config 규칙을 생성합니다.",
            "AWS Config를 구현하여 S3 버킷이 공개인지 평가하고 비준수 버킷을 자동으로 수정하는 관리 규칙을 사용합니다."
        ],
        "Explanation": "두 옵션 모두 AWS Config의 자동 준수 확인 및 수정 기능을 활용하여 운영 오버헤드를 최소화합니다. 첫 번째 옵션은 IAM 역할에 중점을 두고, 두 번째 옵션은 S3 버킷 정책을 다루어 주요 보안 영역 전반에 걸쳐 포괄적인 준수 모니터링을 제공합니다.",
        "Other Options": [
            "이 옵션은 준수 확인을 위해 수동 개입이 필요하므로 운영 오버헤드가 증가하고 효과적인 준수 모니터링에 필요한 자동화를 제공하지 않습니다.",
            "이 옵션은 보안을 다루지만 준수 문제를 수동으로 해결해야 하므로 AWS Config의 자동화 기능을 활용하지 않아 운영 오버헤드가 더 높아집니다.",
            "이 옵션은 AWS Config를 활용하지만 자동 수정 프로세스를 제공하지 않아 준수 팀의 추가 운영 작업을 생성합니다."
        ]
    },
    {
        "Question Number": "41",
        "Situation": "한 회사는 AWS에 호스팅된 웹 애플리케이션의 보안 태세를 강화하려고 합니다. 그들은 일반적인 웹 공격으로부터 보호하기 위해 AWS Web Application Firewall (WAF)을 구현했지만, 강력한 방어 심층 전략을 보장하고자 합니다. 보안 팀은 AWS 환경 전반에 걸쳐 잠재적 위협을 효과적으로 모니터링하고 대응하기 위해 추가 AWS 서비스를 통합해야 합니다.",
        "Question": "웹 애플리케이션의 보안을 강화하기 위해 포괄적인 방어 심층 전략을 제공하는 AWS 서비스 조합은 무엇입니까?",
        "Options": {
            "1": "애플리케이션 계층 보호를 위해 AWS WAF를 구현하고, 위협 탐지를 위해 GuardDuty를 사용하며, 네트워크 계층 보안을 위해 보안 그룹 및 네트워크 ACL을 구성합니다.",
            "2": "인증서 관리를 위해 AWS Certificate Manager를 설정하고, API 호출 로깅을 위해 CloudTrail을 활성화하며, 성능 모니터링을 위해 Amazon CloudWatch를 활용합니다.",
            "3": "SSL/TLS 인증서를 위해 AWS Certificate Manager를 배포하고, 구성 변경 모니터링을 위해 AWS Config 규칙을 활성화하며, 조사 분석을 위해 Amazon Detective를 사용합니다.",
            "4": "준수를 관리하기 위해 AWS Config를 활용하고, 중앙 집중식 보안 경고를 위해 Security Hub를 통합하며, 고급 네트워크 필터링을 위해 AWS Network Firewall을 적용합니다."
        },
        "Correct Answer": "애플리케이션 계층 보호를 위해 AWS WAF를 구현하고, 위협 탐지를 위해 GuardDuty를 사용하며, 네트워크 계층 보안을 위해 보안 그룹 및 네트워크 ACL을 구성합니다.",
        "Explanation": "이 서비스 조합은 계층화된 보안을 제공합니다. AWS WAF는 웹 공격으로부터 보호하고, GuardDuty는 악의적인 활동을 지속적으로 모니터링하며, 보안 그룹 및 네트워크 ACL은 네트워크 수준에서 인바운드 및 아웃바운드 트래픽을 제어하여 강력한 방어 심층 접근 방식을 만듭니다.",
        "Other Options": [
            "이 옵션은 AWS Certificate Manager와 Amazon Detective와 같은 중요한 보안 조치를 포함하지만, 방어 심층 전략에 필수적인 실시간 위협 탐지 및 능동적 네트워크 보안을 위한 구성 요소가 부족합니다.",
            "이 조합은 어느 정도의 보안을 제공하지만 애플리케이션 계층 보호를 다루지 않습니다. AWS WAF가 없으면 애플리케이션 계층의 취약점이 노출될 수 있으며, 이는 포괄적인 보안 전략에서 중요합니다.",
            "AWS Certificate Manager와 CloudTrail을 설정하는 것은 유익하지만, 이 옵션은 능동적 보안 접근 방식보다는 로깅 및 모니터링에 더 중점을 두고 있습니다. 직접적인 위협 방어를 위한 WAF 또는 GuardDuty와 같은 중요한 구성 요소가 부족합니다."
        ]
    },
    {
        "Question Number": "42",
        "Situation": "한 회사는 마이크로서비스 아키텍처를 위해 여러 AWS CloudFormation 스택을 관리하고 있습니다. 그들은 업데이트 중 특정 리소스가 보호되도록 하기를 원합니다. 그들은 CloudFormation 스택의 업데이트를 제어하기 위해 스택 정책 사용을 고려하고 있습니다.",
        "Question": "업데이트 관리를 위해 AWS CloudFormation에서 스택 정책 사용에 대해 회사가 염두에 두어야 할 사항은 무엇입니까?",
        "Options": {
            "1": "스택 정책은 CloudFormation 템플릿을 사용하여 생성된 리소스에만 적용됩니다.",
            "2": "스택 정책은 언제든지 삭제할 수 있으며, 삭제 후에는 제한 없이 업데이트할 수 있습니다.",
            "3": "스택 정책은 스택 내 모든 리소스를 보호하며 기본 거부를 무시하기 위해 명시적인 허용이 필요합니다.",
            "4": "스택 정책에 지정된 리소스만 보호되며, 다른 리소스는 제한 없이 업데이트할 수 있습니다."
        },
        "Correct Answer": "스택 정책은 스택 내 모든 리소스를 보호하며 기본 거부를 무시하기 위해 명시적인 허용이 필요합니다.",
        "Explanation": "스택 정책은 적용되면 기본적으로 스택 내 모든 리소스를 보호합니다. 특정 작업이나 리소스에 대해 명시적인 허용이 지정되지 않는 한 업데이트를 거부합니다. 이는 스택 업데이트 중 중요한 리소스를 보호하는 데 필수적입니다.",
        "Other Options": [
            "스택 정책은 적용된 후 삭제할 수 없으며, 명시적으로 수정될 때까지 효력을 유지하여 리소스의 지속적인 보호를 보장합니다.",
            "스택 정책은 정책에 지정된 리소스뿐만 아니라 스택 내 모든 리소스에 적용됩니다. 따라서 명시적으로 허용되지 않는 한 모든 리소스가 보호됩니다.",
            "스택 정책은 리소스가 어떻게 생성되었는지와 관계없이 스택 내 모든 리소스에 적용됩니다. 사용된 CloudFormation 템플릿에 의존하지 않습니다."
        ]
    },
    {
        "Question Number": "43",
        "Situation": "조직은 AWS Control Tower를 통해 관리되는 여러 AWS 계정을 보유하고 있습니다. 그들은 AWS Config를 구현하여 계정 전반의 준수를 모니터링하고 있습니다. 보안 팀은 사용되지 않는 IAM 사용자 자격 증명에 대해 특히 우려하고 있으며, 특정 기간 동안 사용되지 않은 액세스 키나 비밀번호가 없는지 확인하고자 합니다. 또한, AWS Config 준수 팩을 사용하여 AWS Control Tower에 계정을 등록하는 것의 의미를 평가하고자 합니다.",
        "Question": "조직이 사용되지 않는 자격 증명을 가진 IAM 사용자를 식별하고 보안 정책 준수를 보장하기 위해 어떤 AWS Config 관리 규칙을 사용해야 합니까?",
        "Options": {
            "1": "iam-user-credentials-check",
            "2": "iam-user-keys-rotation-check",
            "3": "iam-user-credential-age-check",
            "4": "iam-user-unused-credentials-check"
        },
        "Correct Answer": "iam-user-unused-credentials-check",
        "Explanation": "iam-user-unused-credentials-check AWS Config 관리 규칙은 특정 일수 이내에 사용되지 않은 비밀번호나 액세스 키를 가진 IAM 사용자를 확인하므로, 사용되지 않는 자격 증명을 식별하는 데 올바른 선택입니다.",
        "Other Options": [
            "iam-user-credentials-check는 기존의 AWS Config 관리 규칙이 아니므로 사용되지 않는 IAM 사용자 자격 증명을 모니터링하는 데 사용할 수 없습니다.",
            "iam-user-credential-age-check는 사용되지 않는 자격 증명에 특별히 초점을 맞추지 않으며, 자격 증명의 사용 상태보다는 자격 증명의 연령을 추적하는 데 더 중점을 둡니다.",
            "iam-user-keys-rotation-check는 액세스 키가 정기적으로 회전되도록 보장하기 위해 설계되었지만, 키가 사용되었는지 여부에 대한 문제를 다루지 않습니다."
        ]
    },
    {
        "Question Number": "44",
        "Situation": "데이터 분석 회사는 다양한 출처에서 실시간 데이터 스트림을 처리하기 위해 Amazon Kinesis를 사용하고 있습니다. 그들은 서로 다른 애플리케이션이 동일한 데이터를 동시에 처리할 수 있고 지연 시간이 최소화된 솔루션이 필요합니다. 팀은 요구 사항을 충족하기 위해 Amazon Kinesis Data Streams와 Amazon Simple Queue Service (SQS)를 사용하는 것을 고려하고 있습니다.",
        "Question": "팀이 데이터 스트림을 효과적으로 처리하기 위해 사용해야 할 두 가지 서비스는 무엇입니까? (두 개 선택)",
        "Options": {
            "1": "단일 큐에서 데이터 재사용 없이 메시지를 저장하고 전달하기 위해 Amazon SQS를 구현합니다.",
            "2": "여러 소비자를 위한 실시간 데이터 처리를 위해 Amazon Kinesis Data Streams를 활용합니다.",
            "3": "낮은 지연 시간으로 스트리밍 데이터에 대해 SQL 쿼리를 실행하기 위해 Amazon Kinesis Data Analytics를 사용합니다.",
            "4": "다양한 출처에서 Amazon Redshift로 스트리밍 데이터를 로드하기 위해 Amazon Kinesis Data Firehose를 활용합니다.",
            "5": "최대 14일의 보존 기간으로 여러 큐 처리를 허용하기 위해 Amazon SQS를 배포합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "여러 소비자를 위한 실시간 데이터 처리를 위해 Amazon Kinesis Data Streams를 활용합니다.",
            "낮은 지연 시간으로 스트리밍 데이터에 대해 SQL 쿼리를 실행하기 위해 Amazon Kinesis Data Analytics를 사용합니다."
        ],
        "Explanation": "Amazon Kinesis Data Streams는 여러 소비자가 동일한 데이터를 실시간으로 처리할 수 있도록 하여 회사의 동시 데이터 처리 요구 사항에 부합합니다. 또한, Kinesis Data Analytics는 팀이 스트리밍 데이터에 대해 표준 SQL 쿼리를 실행할 수 있게 하여 최소한의 지연 시간으로 통찰력을 제공합니다.",
        "Other Options": [
            "Amazon SQS는 데이터 재사용이 필요한 시나리오에 적합하지 않으며, 여러 소비자가 동일한 데이터를 동시에 처리할 수 있도록 허용하지 않습니다.",
            "Amazon Kinesis Data Firehose는 데이터를 저장 솔루션으로 로드하는 데 유용하지만, 여러 애플리케이션이 실시간으로 동일한 데이터를 처리하는 요구 사항을 충족하지 않습니다.",
            "여러 큐에 대해 Amazon SQS를 사용하는 것은 가능하지만, 서로 다른 소비자가 동일한 데이터를 낮은 지연 시간으로 처리하는 필요를 충족하지 않습니다."
        ]
    },
    {
        "Question Number": "45",
        "Situation": "금융 서비스 회사는 AWS 서비스를 사용하여 실시간 거래를 처리합니다. 이 회사는 Amazon Kinesis Data Streams를 사용하여 거래 로그를 수집하고 있으며, 이러한 로그를 실시간으로 분석하여 이상 및 성능 지표를 파악해야 합니다. 데이터 엔지니어링 팀은 거래 데이터를 쉽게 시각화하고 발생하는 문제에 신속하게 대응할 수 있는 솔루션을 설정하는 임무를 맡고 있습니다. 그들은 거래가 처리되는 동안 이상을 효과적으로 감지할 수 있기를 원합니다.",
        "Question": "데이터 엔지니어링 팀이 실시간으로 거래 로그를 분석하고 이상을 시각화하기 위해 구현해야 할 솔루션은 무엇입니까?",
        "Options": {
            "1": "거래 로그를 실시간으로 처리하고 결과를 Amazon QuickSight로 직접 출력하는 Kinesis Data Analytics 애플리케이션을 생성합니다.",
            "2": "AWS Glue를 활용하여 Kinesis Data Streams의 거래 로그를 크롤링하고, 데이터를 변환한 후 결과를 Amazon Redshift에 저장하여 QuickSight로 시각화합니다.",
            "3": "Kinesis Data Streams에 의해 트리거된 AWS Lambda 함수를 설정하여 로그를 처리한 후, 처리된 데이터를 Amazon QuickSight로 전송하여 시각화합니다.",
            "4": "Kinesis Data Firehose를 구성하여 거래 로그를 버퍼링하고 Amazon S3 버킷으로 전달한 후, Amazon Athena를 사용하여 데이터를 쿼리하고 Amazon QuickSight로 시각화합니다."
        },
        "Correct Answer": "거래 로그를 실시간으로 처리하고 결과를 Amazon QuickSight로 직접 출력하는 Kinesis Data Analytics 애플리케이션을 생성합니다.",
        "Explanation": "Kinesis Data Analytics 애플리케이션을 생성하면 팀이 데이터를 실시간으로 처리할 수 있어 거래가 수집되는 즉시 이상을 즉각적으로 감지할 수 있습니다. Amazon QuickSight로 직접 출력함으로써 추가 단계 없이 데이터를 시각화할 수 있어 실시간 분석을 위한 가장 효율적인 솔루션이 됩니다.",
        "Other Options": [
            "AWS Lambda를 사용하여 로그를 처리할 수 있지만, 데이터를 시각화하기 위해 추가 단계가 필요하므로 이상 감지에 지연이 발생할 수 있습니다.",
            "Kinesis Data Firehose와 S3는 실행 가능한 솔루션을 제공하지만, 이 방법은 버퍼링 및 Athena로 쿼리할 때의 잠재적 지연으로 인해 실시간이 아닙니다.",
            "AWS Glue를 사용하는 것은 더 많은 복잡성을 수반하며, Kinesis Data Analytics에 비해 스트리밍 데이터의 실시간 처리를 위해 필요하지 않습니다."
        ]
    },
    {
        "Question Number": "46",
        "Situation": "한 미디어 스트리밍 회사가 Amazon ECS를 사용하여 컨테이너화된 애플리케이션을 관리하고 있습니다. 최근 사용자 트래픽의 증가로 인해 자동 스케일링에 문제가 발생하여 비디오 로딩 시간이 지연되었습니다. 운영 팀은 성능 저하 없이 향후 트래픽을 처리할 수 있도록 스케일링 실패의 근본 원인을 진단하는 임무를 맡고 있습니다.",
        "Question": "이 시나리오에서 실패한 자동 스케일링 이벤트를 분석하는 가장 효과적인 접근 방식은 무엇입니까?",
        "Options": {
            "1": "ECS 서비스 업데이트와 관련된 API 호출 실패를 식별하기 위해 CloudTrail 로그를 검토합니다.",
            "2": "피크 로드 동안 작업의 적절한 스케일링을 방해할 수 있는 잘못된 구성 사항이 있는지 ECS 작업 정의를 확인합니다.",
            "3": "트래픽 급증 동안 컨테이너의 리소스 사용량을 이해하기 위해 ECS 서비스에 대한 Amazon CloudWatch 메트릭을 검사합니다.",
            "4": "AWS Config를 활용하여 ECS 서비스가 원하는 구성 설정에 대한 준수 여부를 평가합니다."
        },
        "Correct Answer": "트래픽 급증 동안 컨테이너의 리소스 사용량을 이해하기 위해 ECS 서비스에 대한 Amazon CloudWatch 메트릭을 검사합니다.",
        "Explanation": "Amazon CloudWatch 메트릭을 분석하면 트래픽 증가 동안 ECS 컨테이너의 리소스 사용량에 대한 통찰력을 제공하여 실제 로드에 따라 스케일링 정책이 적절히 트리거되고 있는지 확인하는 데 중요합니다. 또한 스케일링 실패를 초래하는 리소스 제약이 있는지 판단하는 데 도움이 됩니다.",
        "Other Options": [
            "CloudTrail 로그를 검토하면 API 호출에 대한 정보를 제공할 수 있지만, 성능 메트릭보다는 서비스 상호작용에 초점을 맞추기 때문에 자동 스케일링 실패의 원인을 직접적으로 나타내지 않을 수 있습니다.",
            "ECS 작업 정의를 확인하는 것은 구성을 이해하는 데 중요하지만, 높은 트래픽 동안 스케일링 문제를 일으키는 성능 메트릭에 대한 즉각적인 통찰력을 제공하지 않습니다.",
            "AWS Config를 사용하는 것은 준수 검사를 위해 유용하지만, 실시간 성능 문제를 해결하거나 자동 스케일링 동작에 영향을 미치는 운영 메트릭에 대한 통찰력을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "47",
        "Situation": "DevOps 엔지니어로서 CI/CD 파이프라인에서 API 키 및 데이터베이스 자격 증명과 같은 민감한 정보를 관리하는 책임이 있습니다. 팀은 배포를 위해 AWS CodePipeline을 사용하고 있으며, 빌드 및 배포 과정에서 비밀이 안전하게 저장되고 접근될 수 있도록 보장하고자 합니다. 비밀 처리에 대한 모범 사례를 고려할 때, 어떤 방법을 구현해야 합니까?",
        "Question": "다음 방법 중 어떤 것이 CI/CD 파이프라인 과정에서 민감한 정보가 안전하게 관리되도록 가장 잘 보장합니까?",
        "Options": {
            "1": "민감한 정보를 애플리케이션의 구성 파일에 일반 텍스트로 저장하고 빌드 과정에서 해당 파일을 사용합니다.",
            "2": "AWS S3를 활용하여 비밀을 암호화된 객체로 저장하고 AWS CLI를 사용하여 빌드 과정에서 다운로드합니다.",
            "3": "AWS Secrets Manager를 사용하여 비밀을 저장하고 CodePipeline이 빌드 및 배포 단계에서 런타임에 안전하게 이를 검색하도록 구성합니다.",
            "4": "비밀을 빌드 사양 파일의 환경 변수에 저장하고 파이프라인 단계에서 직접 참조합니다."
        },
        "Correct Answer": "AWS Secrets Manager를 사용하여 비밀을 저장하고 CodePipeline이 빌드 및 배포 단계에서 런타임에 안전하게 이를 검색하도록 구성합니다.",
        "Explanation": "AWS Secrets Manager를 사용하면 민감한 정보가 안전하게 저장되고 애플리케이션 및 서비스에서 프로그래밍 방식으로 접근할 수 있어 세밀한 접근 제어와 비밀의 자동 회전을 제공합니다.",
        "Other Options": [
            "환경 변수에 비밀을 저장하면 로그에 노출되거나 적절히 처리되지 않을 경우 무단 사용자에게 노출될 수 있어 이 접근 방식은 덜 안전합니다.",
            "민감한 정보를 구성 파일에 일반 텍스트로 저장하는 것은 상당한 보안 위험을 초래합니다. 이러한 파일은 리포지토리나 빌드 환경에 접근할 수 있는 누구나 접근할 수 있습니다.",
            "AWS S3를 사용하여 비밀을 암호화된 객체로 저장하는 것은 옵션이지만, 접근 및 검색 관리를 위한 추가 단계가 필요하여 AWS Secrets Manager를 사용하는 것보다 효율성이 떨어집니다."
        ]
    },
    {
        "Question Number": "48",
        "Situation": "한 회사의 애플리케이션이 최근 사용자 트래픽 급증으로 인해 성능 문제와 지연이 발생했습니다. DevOps 팀은 사용자가 애플리케이션에 접근할 때 느린 응답 및 간헐적인 타임아웃을 보고한 사건에 대해 통보받았습니다. 이러한 문제를 해결하기 위해 팀은 현재 로드 및 성능 메트릭에 따라 인프라 구성을 동적으로 수정할 수 있는 솔루션을 구현해야 합니다. 이 솔루션은 다운타임을 최소화하고 원활한 사용자 경험을 보장해야 합니다.",
        "Question": "DevOps 엔지니어가 이 시나리오에 대한 솔루션을 설정하기 위해 함께 사용할 옵션의 조합은 무엇입니까? (두 개 선택)",
        "Options": {
            "1": "AWS CloudFormation StackSets를 활용하여 트래픽 급증에 대응하여 여러 지역에 인프라를 자동으로 복제합니다.",
            "2": "Amazon RDS 읽기 복제를 배포하여 기본 데이터베이스 인스턴스에서 읽기 트래픽을 분산시켜 전체 애플리케이션 성능을 향상시킵니다.",
            "3": "Amazon CloudWatch 경고를 설정하여 애플리케이션 성능 메트릭을 모니터링하고 특정 임계값에 따라 인프라를 수정하는 AWS Lambda 함수를 트리거합니다.",
            "4": "AWS Elastic Load Balancing을 구현하여 들어오는 애플리케이션 트래픽을 여러 대상에 분산시켜 단일 인스턴스가 요청으로 과부하되지 않도록 합니다.",
            "5": "AWS Auto Scaling을 사용하여 CPU 사용량 메트릭에 따라 Auto Scaling 그룹의 EC2 인스턴스 수를 동적으로 조정하여 증가된 트래픽을 처리합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "AWS Auto Scaling을 사용하여 CPU 사용량 메트릭에 따라 Auto Scaling 그룹의 EC2 인스턴스 수를 동적으로 조정하여 증가된 트래픽을 처리합니다.",
            "Amazon CloudWatch 경고를 설정하여 애플리케이션 성능 메트릭을 모니터링하고 특정 임계값에 따라 인프라를 수정하는 AWS Lambda 함수를 트리거합니다."
        ],
        "Explanation": "정답은 AWS Auto Scaling을 활용하여 트래픽 수요에 따라 EC2 인스턴스 수를 자동으로 관리하여 최적의 성능을 보장합니다. 또한 Amazon CloudWatch 경고를 사용하면 성능 메트릭에 실시간으로 반응하여 인프라를 자동으로 조정할 수 있어 트래픽 급증 동안 원활한 사용자 경험을 유지하는 데 중요합니다.",
        "Other Options": [
            "AWS Elastic Load Balancing을 구현하는 것은 트래픽 분산에 유용하지만, 부하에 따라 인스턴스 수를 조정하지 않기 때문에 동적 스케일링에는 필수적이지 않습니다.",
            "Amazon RDS 읽기 복제를 배포하면 읽기 성능을 개선할 수 있지만, 트래픽 변화에 대응하여 애플리케이션 계층의 동적 스케일링 필요성을 해결하지 않습니다.",
            "AWS CloudFormation StackSets를 활용하는 것은 즉각적인 조정에는 적합하지 않으며, 트래픽이나 성능 변화에 동적으로 반응하지 않는 배포 프로세스가 필요합니다."
        ]
    },
    {
        "Question Number": "49",
        "Situation": "소프트웨어 개발 팀이 AWS에서 마이크로서비스 아키텍처로 전환하여 배포 효율성과 확장성을 향상시키고자 합니다. 그들은 여러 환경에서 아티팩트 생성 및 배포를 자동화할 수 있는 방법이 필요합니다. 팀은 각 환경이 쉽게 구성될 수 있으며, 필요할 경우 변경 사항을 신속하게 롤백할 수 있도록 보장하고자 합니다. DevOps 엔지니어로서, CI/CD의 모범 사례를 유지하면서 이러한 요구를 충족하는 솔루션을 설계해야 합니다.",
        "Question": "마이크로서비스 아키텍처에서 환경별 구성 및 롤백 기능을 보장하면서 아티팩트 생성 및 배포 프로세스를 자동화하기 위해 어떤 접근 방식을 취해야 합니까?",
        "Options": {
            "1": "AWS CodePipeline을 구현하여 전체 CI/CD 프로세스를 자동화합니다. AWS CodeBuild를 사용하여 아티팩트를 생성하고 이를 Amazon S3에 저장합니다. AWS CloudFormation 템플릿을 사용하여 환경별 설정을 구성하고 AWS CodeDeploy를 사용하여 배포하여 쉽게 롤백할 수 있도록 합니다.",
            "2": "AWS CodePipeline을 활용하여 CI/CD 워크플로를 관리하고 AWS CodeBuild를 통합하여 아티팩트를 생성합니다. 아티팩트를 Amazon ECR에 저장하고 Amazon ECS를 사용하여 배포하며, AWS Systems Manager를 통해 환경 구성을 관리하여 신뢰할 수 있는 롤백을 가능하게 합니다.",
            "3": "AWS CodePipeline과 Jenkins를 결합하여 CI/CD 프로세스를 자동화합니다. Jenkins를 사용하여 아티팩트를 생성하고 이를 Amazon ECR에 푸시합니다. AWS Lambda를 사용하여 환경 구성을 관리하고 아티팩트를 배포하지만, 이 접근 방식은 쉽게 롤백할 수 없습니다.",
            "4": "AWS CodeBuild를 설정하여 아티팩트를 생성하고 이를 S3 버킷에 직접 푸시합니다. 환경별 구성을 위해 AWS CloudFormation을 사용하고 AWS Elastic Beanstalk를 사용하여 배포하지만, 이 방법은 간소화된 롤백 프로세스가 부족합니다."
        },
        "Correct Answer": "AWS CodePipeline을 활용하여 CI/CD 워크플로를 관리하고 AWS CodeBuild를 통합하여 아티팩트를 생성합니다. 아티팩트를 Amazon ECR에 저장하고 Amazon ECS를 사용하여 배포하며, AWS Systems Manager를 통해 환경 구성을 관리하여 신뢰할 수 있는 롤백을 가능하게 합니다.",
        "Explanation": "이 옵션은 워크플로 관리에 AWS CodePipeline, 아티팩트 생성에 AWS CodeBuild, 배포에 Amazon ECS를 통합한 포괄적인 CI/CD 솔루션을 제공합니다. 아티팩트를 Amazon ECR에 저장하면 효율적인 버전 관리를 제공하며, AWS Systems Manager로 환경 구성을 관리하면 쉽게 조정하고 롤백할 수 있는 기능을 제공하여 마이크로서비스 아키텍처의 모범 사례에 부합합니다.",
        "Other Options": [
            "이 옵션은 환경 구성을 위해 AWS Lambda를 사용하는 것을 포함하므로 롤백 기능이 간소화되지 않아 버전 관리 및 롤백 프로세스가 복잡해집니다.",
            "이 옵션은 구성을 위해 AWS CloudFormation을 사용하는 것을 제안하지만, AWS CodePipeline이 제공하는 응집력 있는 CI/CD 워크플로가 부족하고 쉽게 롤백할 수 있는 메커니즘을 촉진하지 않습니다.",
            "이 접근 방식은 아티팩트 생성을 위해 단일 AWS 서비스에 집중하므로 CI/CD 관리를 위한 AWS CodePipeline의 전체 기능을 활용하지 않으며, 효과적인 롤백 전략이 부족합니다."
        ]
    },
    {
        "Question Number": "50",
        "Situation": "한 회사가 AWS CodeArtifact를 사용하여 라이브러리 및 패키지를 포함한 소프트웨어 아티팩트를 관리하고 저장하고 있습니다. 그들은 조직 내 특정 개발자만이 리포지토리에 접근하고 새로운 아티팩트를 게시할 수 있도록 보장하고자 합니다. DevOps 엔지니어는 CodeArtifact 리포지토리에 대한 접근을 효과적으로 제어하기 위해 AWS Identity and Access Management (IAM) 권한을 구성하는 임무를 맡고 있습니다.",
        "Question": "DevOps 엔지니어가 보안 모범 사례를 유지하면서 개발자가 CodeArtifact 리포지토리에 접근할 수 있도록 IAM 권한을 구성하기 위해 어떤 접근 방식을 취해야 합니까?",
        "Options": {
            "1": "개발자를 위한 전용 IAM 그룹을 생성하고 CodeArtifact 리포지토리에 대한 접근을 허용하는 정책을 연결하며, 정책이 그들의 역할에 필요한 작업만 허용하도록 범위를 설정합니다.",
            "2": "AWS Organizations를 사용하여 전체 조직에 대한 CodeArtifact 접근을 제한하는 서비스 제어 정책(SCP)을 생성합니다.",
            "3": "각 개발자에게 CodeArtifact에 대한 개별 IAM 권한을 할당하여 아티팩트를 관리하는 데 유연성을 제공하는 광범위한 권한을 부여합니다.",
            "4": "모든 개발자를 위한 단일 IAM 사용자를 설정하여 CodeArtifact에 대한 전체 접근을 허용하고, 제한 없이 아티팩트를 관리하고 게시할 수 있도록 합니다."
        },
        "Correct Answer": "개발자를 위한 전용 IAM 그룹을 생성하고 CodeArtifact 리포지토리에 대한 접근을 허용하는 정책을 연결하며, 정책이 그들의 역할에 필요한 작업만 허용하도록 범위를 설정합니다.",
        "Explanation": "전용 IAM 그룹을 생성하고 범위가 설정된 정책을 사용하면 권한이 있는 사용자만 CodeArtifact에 접근할 수 있도록 보장하여 최소 권한 원칙을 따릅니다. 이는 권한 관리가 용이하게 하며, 개발자가 과도한 권한 없이 필요한 접근을 할 수 있도록 보장합니다.",
        "Other Options": [
            "모든 개발자를 위한 단일 IAM 사용자를 설정하는 것은 모든 자격 증명을 여러 사용자에게 노출시켜 보안 관행을 저해하며, 개별 사용자 작업을 추적하고 권한을 효과적으로 관리하기 어렵게 만듭니다.",
            "개별 IAM 권한을 할당하는 것은 너무 많은 유연성을 제공하고 무단 접근이나 리포지토리에 대한 의도치 않은 변경의 위험을 증가시켜 최소 권한 원칙을 위반합니다.",
            "AWS Organizations를 사용하여 전체 조직에 대한 CodeArtifact 접근을 제한하는 SCP를 생성하면 모든 개발자가 리포지토리에 접근할 수 없게 되어 특정 개발자가 아티팩트를 관리할 수 있도록 하는 목표에 반합니다."
        ]
    },
    {
        "Question Number": "51",
        "Situation": "한 회사는 EC2 인스턴스의 CPU 사용률이 특정 임계값을 초과할 때 즉시 알림을 받기를 원합니다. DevOps 엔지니어는 Amazon CloudWatch를 사용하여 모니터링 솔루션을 설정하는 임무를 맡고 있습니다. 이 솔루션은 CPU 사용률을 모니터링하고 해당 메트릭을 기반으로 경고를 트리거하는 사용자 정의 메트릭을 포함해야 합니다.",
        "Question": "CPU 사용률에 대한 필요한 모니터링 및 경고를 효과적으로 구현하기 위해 어떤 접근 방식을 취해야 합니까?",
        "Options": {
            "1": "매 분마다 EC2 CPU 사용률을 확인하고 임계값을 초과할 경우 Amazon SNS를 통해 알림을 보내는 AWS Lambda 함수를 설정합니다.",
            "2": "CloudWatch의 기본 EC2 메트릭을 사용하고 평균 CPU 사용률 메트릭에 경고를 설정하여 임계값을 초과할 때 알림을 받도록 합니다.",
            "3": "CPU 사용률에 대한 CloudWatch 사용자 정의 메트릭을 생성하고 메트릭이 정의된 임계값을 초과할 때 트리거되는 CloudWatch 경고를 구성합니다.",
            "4": "EC2 인스턴스에서 로그를 수집하기 위해 CloudWatch Logs 그룹을 구현하고 CPU 사용률 경고를 위한 메트릭 필터를 생성합니다."
        },
        "Correct Answer": "CPU 사용률에 대한 CloudWatch 사용자 정의 메트릭을 생성하고 메트릭이 정의된 임계값을 초과할 때 트리거되는 CloudWatch 경고를 구성합니다.",
        "Explanation": "사용자 정의 메트릭을 생성하면 애플리케이션의 요구에 맞춘 모니터링이 가능합니다. 이 설정은 CPU 사용률에 대한 정의된 임계값에 따라 알림을 트리거하는 CloudWatch 경고를 가능하게 하여 성능 문제에 대한 즉각적인 인식을 보장합니다.",
        "Other Options": [
            "기본 EC2 메트릭을 사용하는 것은 유효한 접근 방식이지만, 사용자 정의 메트릭이 제공하는 유연성과 특수성이 부족합니다. 사용자 정의 메트릭은 애플리케이션의 성능 요구 사항에 더 세밀하게 조정될 수 있습니다.",
            "CloudWatch Logs 그룹과 메트릭 필터는 CPU 사용률을 직접 모니터링하는 데 가장 효율적인 방법이 아니며, 로그 데이터 분석에 더 적합합니다.",
            "CPU 사용률을 확인하기 위해 Lambda 함수를 사용하는 것은 가능하지만, 실시간 모니터링을 위해 설계된 기본 CloudWatch 경고를 사용하는 것에 비해 불필요한 복잡성과 지연을 초래합니다."
        ]
    },
    {
        "Question Number": "52",
        "Situation": "한 회사가 데이터 집약적인 애플리케이션을 AWS로 마이그레이션하고 있으며, 작업 부하에 적합한 Amazon EBS 볼륨 유형을 선택해야 합니다. 이 애플리케이션은 생산 환경에서 높은 IOPS와 낮은 대기 시간이 필요하며, 아카이브 데이터 처리에 비용 효율적인 솔루션도 필요합니다. 팀은 GP2와 IO2 볼륨 유형을 모두 고려하고 있습니다.",
        "Question": "회사가 높은 성능을 요구하는 생산 작업 부하와 낮은 비용을 요구하는 아카이브 작업 부하에 어떤 EBS 볼륨 유형을 사용해야 합니까?",
        "Options": {
            "1": "생산 작업 부하에는 GP2를 사용하고, 아카이브 데이터에는 비용 효율성 때문에 자기 볼륨을 사용합니다.",
            "2": "생산 작업 부하에는 높은 IOPS와 낮은 대기 시간 때문에 IO2를 사용하고, 아카이브 데이터에는 비용 절감을 위해 자기 볼륨을 사용합니다.",
            "3": "두 작업 부하 모두에 GP2를 사용합니다. GP2는 IO2보다 낮은 비용으로 충분한 성능을 제공합니다.",
            "4": "아카이브 작업 부하에는 높은 IOPS와 낮은 대기 시간을 제공하는 IO2를 사용하고, 생산 작업 부하에는 GP2를 사용합니다."
        },
        "Correct Answer": "생산 작업 부하에는 높은 IOPS와 낮은 대기 시간 때문에 IO2를 사용하고, 아카이브 데이터에는 비용 절감을 위해 자기 볼륨을 사용합니다.",
        "Explanation": "IO2 볼륨은 높은 IOPS와 낮은 대기 시간이 필요한 고성능 애플리케이션을 위해 설계되어 생산 작업 부하에 이상적입니다. 자기 볼륨은 성능 특성이 느리지만 낮은 비용 때문에 아카이브 작업 부하에 적합합니다.",
        "Other Options": [
            "GP2는 IO2와 같은 수준의 지속적인 IOPS 및 대기 시간 성능을 제공하지 않으므로 높은 성능을 요구하는 생산 작업 부하에 적합하지 않습니다.",
            "아카이브 작업 부하에 IO2를 사용하는 것은 비용 효율적이지 않으며, 느린 아카이브 프로세스에는 불필요한 고성능을 위해 설계되었습니다.",
            "GP2는 생산 작업 부하의 높은 성능 요구 사항을 충족하지 못하며, 자기 볼륨은 대기 시간이 더 길고 처리량이 낮기 때문에 생산 사용에 최적이 아닙니다."
        ]
    },
    {
        "Question Number": "53",
        "Situation": "한 회사가 AWS에서 보안 태세를 강화하기 위해 인프라의 잠재적 취약점을 식별하고 모범 사례 준수를 보장하고자 합니다. DevOps 팀은 AWS 리소스의 보안을 자동으로 평가하고 실행 가능한 통찰력을 제공하는 솔루션을 구현하는 임무를 맡고 있습니다.",
        "Question": "DevOps 팀이 AWS 리소스를 정기적으로 보안 취약점 및 준수 문제를 스캔하기 위해 어떤 AWS 서비스를 사용해야 합니까?",
        "Options": {
            "1": "AWS CloudTrail을 사용하여 계정 활동 및 API 사용을 모니터링합니다.",
            "2": "Amazon Inspector를 사용하여 애플리케이션의 취약점 및 모범 사례에 대한 준수를 평가합니다.",
            "3": "AWS Config를 사용하여 구성 변경 사항 및 규칙 준수를 추적합니다.",
            "4": "IAM Access Analyzer를 사용하여 권한을 검토하고 과도한 접근 권한을 식별합니다."
        },
        "Correct Answer": "Amazon Inspector를 사용하여 애플리케이션의 취약점 및 모범 사례에 대한 준수를 평가합니다.",
        "Explanation": "Amazon Inspector는 애플리케이션의 취약점을 자동으로 평가하고 보안 모범 사례에 대한 준수 보고서를 제공하도록 특별히 설계되었습니다. 이는 AWS에서 실행되는 애플리케이션의 잠재적 보안 문제를 식별하는 데 도움을 줍니다.",
        "Other Options": [
            "AWS Config는 AWS 리소스의 구성을 추적하고 정의된 준수 규칙에 대해 평가하는 데 주로 사용되지만, 애플리케이션의 취약점을 특별히 스캔하지는 않습니다.",
            "IAM Access Analyzer는 권한 분석 및 리소스에 대한 과도한 접근 권한 식별에 중점을 두지만, 취약성 평가를 수행하지는 않습니다.",
            "AWS CloudTrail은 API 호출 및 계정 활동을 기록하지만 AWS 리소스의 보안 태세나 준수 상태를 평가하지는 않습니다."
        ]
    },
    {
        "Question Number": "54",
        "Situation": "성장하는 전자상거래 회사가 여러 계정에 걸쳐 애플리케이션 배포를 관리하기 위해 AWS를 활용하고 있습니다. 이 회사는 보안 및 준수를 유지하면서 원활한 애플리케이션 업데이트를 보장하는 단일 계정 및 다중 계정 배포 전략을 지원하는 CI/CD 파이프라인을 구축하고자 합니다.",
        "Question": "단일 계정 및 다중 계정 배포 전략을 모두 지원하는 CI/CD 파이프라인을 가장 잘 구현하는 단계의 조합은 무엇입니까? (두 개 선택)",
        "Options": {
            "1": "단일 계정 내 인스턴스에 배포하기 위해 AWS CodeDeploy를 사용하고, 다중 계정 배포는 수동으로 관리합니다.",
            "2": "AWS Organizations를 활용하여 여러 계정에 대한 접근을 제어하고, 서비스 제어 정책을 사용하여 배포 권한을 관리합니다.",
            "3": "AWS CodeBuild를 Amazon S3와 통합하여 아티팩트 저장 및 검색을 수행하고, 안전한 접근 제어를 보장합니다.",
            "4": "AWS CloudFormation StackSets를 사용하여 여러 계정 및 리전에서 인프라를 관리합니다.",
            "5": "각 계정에서 AWS CodePipeline을 구현하여 코드 변경 사항의 배포를 자동화합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "AWS CloudFormation StackSets를 사용하여 여러 계정 및 리전에서 인프라를 관리합니다.",
            "AWS Organizations를 활용하여 여러 계정에 대한 접근을 제어하고, 서비스 제어 정책을 사용하여 배포 권한을 관리합니다."
        ],
        "Explanation": "AWS CloudFormation StackSets를 사용하면 여러 계정 및 리전에서 배포를 일관되게 관리할 수 있어 다중 계정 환경에 이상적입니다. AWS Organizations와 서비스 제어 정책을 활용하면 권한을 중앙에서 관리하여 모든 계정에서 보안 및 준수의 추가 계층을 제공합니다.",
        "Other Options": [
            "각 계정에서 AWS CodePipeline을 구현하면 배포를 자동화할 수 있지만, 다중 계정 관리를 위한 통합 접근 방식을 본질적으로 제공하지 않으므로 이 시나리오에 중요합니다.",
            "AWS CodeBuild를 Amazon S3와 통합하는 것은 아티팩트 관리에 좋은 방법이지만, 다중 계정 배포 전략이나 거버넌스의 필요성을 해결하지는 않습니다.",
            "AWS CodeDeploy를 사용한 배포는 단일 계정 내에서 효과적이지만, 다중 계정 배포를 수동 프로세스에 의존하면 잠재적인 오류가 발생하고 자동화가 부족합니다."
        ]
    },
    {
        "Question Number": "55",
        "Situation": "소프트웨어 개발 팀이 AWS CodeArtifact를 사용하여 여러 프로젝트의 패키지와 종속성을 관리하고 있습니다. 그들은 도메인 내에 여러 리포지토리를 설정했으며 개발자에 대한 접근 제어를 간소화하려고 합니다. 모든 AWS 계정의 개발자가 중간 리포지토리에서 패키지를 중복하지 않고 필요한 리포지토리에 접근할 수 있도록 해야 합니다.",
        "Question": "DevOps 엔지니어가 이 다중 계정 설정에서 접근 제어를 효과적으로 관리하기 위해 무엇을 해야 합니까?",
        "Options": {
            "1": "모든 패키지를 보유할 단일 리포지토리를 구성하고 모든 개발자 계정에 대해 해당 리포지토리에 대한 접근을 허용하는 정책을 설정합니다.",
            "2": "각 리포지토리에 개별 정책을 설정하여 개발자 계정의 IAM 역할만 접근할 수 있도록 하여 도메인 수준 정책을 우회합니다.",
            "3": "AWS Organizations를 사용하여 계정 간 권한을 관리하고 각 계정이 CodeArtifact 도메인과 상호 작용하지 않는 별도의 권한을 갖도록 합니다.",
            "4": "CodeArtifact 도메인에 특정 IAM 역할에 대해 모든 필요한 리포지토리에 대한 접근을 허용하는 정책을 생성합니다."
        },
        "Correct Answer": "CodeArtifact 도메인에 특정 IAM 역할에 대해 모든 필요한 리포지토리에 대한 접근을 허용하는 정책을 생성합니다.",
        "Explanation": "도메인 정책을 생성하면 더 높은 수준에서 접근을 정의할 수 있어, 모든 필요한 리포지토리에 대해 지정된 IAM 역할이 서로 다른 계정에서 접근할 수 있도록 하여 각 리포지토리에 대한 접근 구성의 중복을 방지할 수 있습니다.",
        "Other Options": [
            "각 리포지토리에 개별 정책을 설정하면 관리 오버헤드와 복잡성이 증가하여 여러 리포지토리 간에 일관된 접근 제어를 유지하기 어려워질 수 있습니다.",
            "AWS Organizations를 사용하여 별도의 권한을 관리하는 것은 CodeArtifact 리포지토리에 대한 접근 관리의 필요성을 직접적으로 해결하지 않으며 비효율적인 권한 관리로 이어질 수 있습니다.",
            "모든 패키지를 보유할 단일 리포지토리를 구성하는 것은 더 큰 팀이나 프로젝트에 실용적이지 않을 수 있으며, 이는 병목 현상을 초래하고 조직 및 관리의 이점을 활용하지 못하게 할 수 있습니다."
        ]
    },
    {
        "Question Number": "56",
        "Situation": "한 스타트업이 새로운 마이크로서비스 기반 애플리케이션을 개발하고 있으며 소프트웨어 개발 생명 주기(SDLC)가 효율적이고 자동화되도록 해야 합니다. 팀은 테스트, 빌드 및 배포 프로세스를 통합하는 CI/CD 파이프라인을 구현하고자 합니다. 그들은 수동 개입을 줄이면서 빠른 반복과 배포를 촉진하는 것을 목표로 하고 있습니다.",
        "Question": "DevOps 엔지니어가 애플리케이션의 마이크로서비스에 대한 자동화된 CI/CD 파이프라인을 구현하면서 SDLC의 모든 단계를 보장하기 위해 어떤 접근 방식을 취해야 합니까?",
        "Options": {
            "1": "AWS CodePipeline을 설정하여 애플리케이션의 빌드, 테스트 및 배포 단계를 자동화합니다. AWS CodeBuild를 사용하여 마이크로서비스를 빌드하고 AWS CodeDeploy를 사용하여 Amazon ECS에 배포합니다. 파이프라인 실행 중 알림 및 모니터링을 처리하기 위해 AWS Lambda 함수를 통합합니다.",
            "2": "CI/CD 파이프라인을 관리하기 위해 커스텀 Jenkins 서버를 만들고 이를 AWS 서비스와 통합합니다. Jenkins 플러그인을 사용하여 마이크로서비스의 빌드 및 테스트를 용이하게 하고, 각 빌드 후 수동으로 Amazon EC2 인스턴스에 배포합니다.",
            "3": "AWS CodeCommit과 AWS CodePipeline을 사용하여 GitOps 접근 방식을 구현합니다. 애플리케이션 구성을 Git 리포지토리에 저장하고 CodePipeline을 활용하여 리포지토리의 변경 사항에 따라 배포 프로세스를 자동화하여 환경 간 일관된 배포를 보장합니다.",
            "4": "AWS Elastic Beanstalk를 사용하여 마이크로서비스를 배포하고 빌드 및 테스트 단계를 수동으로 구성합니다. EC2 인스턴스에서 크론 작업을 설정하여 정해진 간격으로 빌드를 트리거하고 배포를 시작하여 업데이트가 적용되도록 합니다."
        },
        "Correct Answer": "AWS CodePipeline을 설정하여 애플리케이션의 빌드, 테스트 및 배포 단계를 자동화합니다. AWS CodeBuild를 사용하여 마이크로서비스를 빌드하고 AWS CodeDeploy를 사용하여 Amazon ECS에 배포합니다. 파이프라인 실행 중 알림 및 모니터링을 처리하기 위해 AWS Lambda 함수를 통합합니다.",
        "Explanation": "AWS CodePipeline, CodeBuild 및 CodeDeploy를 사용하면 전체 CI/CD 프로세스를 자동화하기 위한 완전 관리 솔루션을 제공합니다. 이 접근 방식은 빌드, 테스트 및 배포 단계를 원활하게 통합하면서 수동 개입을 줄일 수 있습니다. Lambda 함수는 모니터링 및 알림으로 파이프라인을 향상시켜 포괄적인 솔루션을 보장합니다.",
        "Other Options": [
            "AWS Elastic Beanstalk를 사용하는 것은 배포를 단순화할 수 있지만, 빌드 및 테스트 단계를 수동으로 구성하면 자동화가 줄어들고 일관되지 않은 배포로 이어질 수 있습니다. EC2 인스턴스에서의 예약된 크론 작업은 완전 통합된 파이프라인에 비해 CI/CD 프로세스를 관리하는 비효율적인 방법입니다.",
            "커스텀 Jenkins 서버를 만드는 것은 복잡성을 추가하고 추가 관리 오버헤드를 요구합니다. Jenkins는 강력하지만 CodePipeline과 같은 네이티브 AWS 서비스를 활용하지 않으며 덜 자동화되고 오류가 발생하기 쉬운 프로세스로 이어질 수 있습니다.",
            "CodeCommit과 CodePipeline을 사용한 GitOps 접근 방식은 유효한 전략이지만, 첫 번째 옵션만큼 SDLC의 모든 단계를 철저히 다루지 않을 수 있습니다. 이는 리포지토리 변경에 크게 의존하며, 추가 구성 없이는 빌드 및 테스트 단계를 완전히 캡슐화하지 못할 수 있습니다."
        ]
    },
    {
        "Question Number": "57",
        "Situation": "한 금융 서비스 회사가 AWS에서 마이크로서비스 아키텍처를 운영하고 있으며, Amazon ECS를 사용하여 컨테이너화된 애플리케이션을 관리하고 있습니다. 최근 사용자들이 간헐적인 애플리케이션 실패를 보고했으며, 원인을 파악해야 합니다. 로그에 따르면 애플리케이션이 Amazon RDS에 호스팅된 데이터베이스에 접근할 때 타임아웃이 발생하고 있습니다. 이 문제의 가능한 원인은 무엇입니까? (두 가지 선택)",
        "Question": "이 문제의 가능한 원인은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "RDS 인스턴스와 연결된 보안 그룹이 ECS 작업에서의 수신 트래픽을 허용하지 않습니다.",
            "2": "RDS 인스턴스가 허용된 최대 연결 수에 도달했습니다.",
            "3": "ECS 작업 정의에 RDS에 접근하기 위한 올바른 IAM 역할이 누락되어 있습니다.",
            "4": "RDS의 데이터베이스 엔진이 애플리케이션 버전과 호환되지 않습니다.",
            "5": "Amazon RDS 인스턴스가 ECS 클러스터와 다른 AWS 리전 내에 있습니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "RDS 인스턴스와 연결된 보안 그룹이 ECS 작업에서의 수신 트래픽을 허용하지 않습니다.",
            "RDS 인스턴스가 허용된 최대 연결 수에 도달했습니다."
        ],
        "Explanation": "보안 그룹은 ECS 작업에서의 수신 트래픽을 허용해야 애플리케이션과 데이터베이스 간의 통신이 가능해집니다. 또한, RDS 인스턴스가 허용된 최대 연결 수에 도달하면 새로운 연결이 거부되어 애플리케이션에서 타임아웃이 발생합니다.",
        "Other Options": [
            "ECS 작업 정의에 올바른 IAM 역할이 누락된 것은 RDS 인스턴스에 대한 연결에 직접적인 영향을 미치지 않으며, IAM 역할은 접근 관리에 사용되고 네트워크 연결에는 사용되지 않습니다.",
            "Amazon RDS 인스턴스가 다른 AWS 리전에 있는 경우 일반적으로 지연 시간이 증가하지만, 네트워킹 문제 없이는 타임아웃을 초래하지 않습니다. 그러나 이 시나리오는 더 즉각적인 원인을 제시합니다.",
            "데이터베이스 엔진 호환성 문제는 타임아웃을 초래할 가능성이 낮으며, 대신 연결 시도 중 오류를 초래할 수 있습니다."
        ]
    },
    {
        "Question Number": "58",
        "Situation": "한 금융 서비스 회사가 AWS로 워크로드를 마이그레이션하고 데이터 저장 요구를 위해 EBS 볼륨을 활용하고 있습니다. 이 회사는 비용을 효과적으로 관리하면서 성능 최적화에 집중하고 있습니다. 그들은 높은 IOPS와 높은 처리량이 모두 필요한 다양한 워크로드를 가지고 있습니다. DevOps 엔지니어는 AWS 모범 사례를 고려하여 성능을 극대화하는 스토리지 솔루션을 설계하는 임무를 맡고 있습니다.",
        "Question": "DevOps 엔지니어가 IOPS와 처리량 모두에 대해 EBS 볼륨 성능을 최적화하기 위해 구현해야 하는 전략은 무엇입니까?",
        "Options": {
            "1": "높은 IOPS 워크로드의 성능을 향상시키기 위해 256KB의 스트라이프 크기를 가진 RAID 0 구성에서 여러 GP2 EBS 볼륨을 활용하고, 증분 스냅샷을 구현하여 스냅샷 관리를 단순화합니다.",
            "2": "높은 처리량을 달성하기 위해 RAID 0 설정에서 여러 IO2 EBS 볼륨을 결합하고, 더 나은 RPO와 RTO를 위해 빈번한 전체 스냅샷을 보장하는 스냅샷 정책을 유지합니다.",
            "3": "여러 GP2 EBS 볼륨을 생성하고 이를 단일 EC2 인스턴스에 연결하여 전체 처리량을 증가시키며, 성능을 극대화하기 위해 사용 전에 볼륨을 미리 워밍업합니다.",
            "4": "1TB 크기의 GP2 EBS 볼륨을 사용하여 버스트 풀 기능을 효과적으로 활용하고, 복구 시간 목표를 개선하기 위해 정기적인 증분 스냅샷을 구현합니다."
        },
        "Correct Answer": "높은 IOPS 워크로드의 성능을 향상시키기 위해 256KB의 스트라이프 크기를 가진 RAID 0 구성에서 여러 GP2 EBS 볼륨을 활용하고, 증분 스냅샷을 구현하여 스냅샷 관리를 단순화합니다.",
        "Explanation": "RAID 0 구성에서 여러 GP2 볼륨을 사용하면 스트라이핑을 활용하여 IOPS와 처리량을 증가시킬 수 있습니다. 256KB 스트라이프 크기는 성능에 최적이며, 증분 스냅샷을 활용하면 비용을 관리하고 복구 시간을 개선하는 데 도움이 됩니다.",
        "Other Options": [
            "여러 GP2 볼륨을 생성하고 이를 단일 EC2 인스턴스에 연결하는 것은 RAID 0 구성만큼의 성능 이점을 제공하지 않으며, IOPS를 효과적으로 최적화하지 않습니다. 새로운 볼륨에 대한 미리 워밍업도 더 이상 필요하지 않습니다.",
            "여러 IO2 볼륨을 RAID 0 설정에서 결합하는 것은 GP2 볼륨이 많은 워크로드에 대해 충분한 성능을 달성할 수 있으므로 불필요합니다. IO2 볼륨은 비용이 더 많이 들며, 특히 스냅샷 관리를 고려할 때 이 시나리오에 추가적인 이점을 제공하지 않을 수 있습니다.",
            "1TB 크기의 GP2 EBS 볼륨을 사용하는 것은 버스트 풀 기능을 활용하는 데 가장 효과적인 전략이 아닐 수 있으며, 특히 더 작은 볼륨이 워크로드에 더 적합한 경우에는 더욱 그렇습니다. 크기가 성능을 직접적으로 증가시키지 않으며, 빈번한 증분 스냅샷이 전체 스냅샷보다 더 유리합니다."
        ]
    },
    {
        "Question Number": "59",
        "Situation": "개발 팀이 AWS Serverless Application Framework (SAM)를 사용하여 서버리스 애플리케이션을 관리하고 있습니다. 그들은 AWS CodeDeploy를 사용하여 Lambda 함수를 배포하고, 테스트 목적으로 애플리케이션 구성 요소를 로컬에서 실행할 수 있도록 해야 합니다. 애플리케이션은 DynamoDB와 API Gateway를 아키텍처의 일부로 사용합니다.",
        "Question": "DevOps 엔지니어가 CodeDeploy를 사용하여 Lambda 함수를 배포하고 로컬 테스트를 용이하게 하기 위해 어떤 조치를 취해야 합니까? (두 가지 선택)",
        "Options": {
            "1": "Lambda 함수에 대한 SAM 템플릿에서 CodeDeploy 애플리케이션 및 배포 그룹을 정의합니다.",
            "2": "필요한 리소스를 생성하고 애플리케이션을 배포하는 CloudFormation 스택을 구현합니다.",
            "3": "SAM CLI를 사용하여 DynamoDB 및 API Gateway 구성 요소를 포함하여 애플리케이션을 로컬에서 실행합니다.",
            "4": "SAM을 활용하여 CodeDeploy와 통합되는 CloudFormation 템플릿을 자동으로 생성합니다.",
            "5": "CodeDeploy에 필요한 종속성을 포함하는 Lambda 레이어를 생성합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Lambda 함수에 대한 SAM 템플릿에서 CodeDeploy 애플리케이션 및 배포 그룹을 정의합니다.",
            "SAM CLI를 사용하여 DynamoDB 및 API Gateway 구성 요소를 포함하여 애플리케이션을 로컬에서 실행합니다."
        ],
        "Explanation": "SAM 템플릿에서 CodeDeploy 애플리케이션 및 배포 그룹을 정의하는 것은 CodeDeploy를 사용하여 Lambda 함수를 배포하는 데 필수적입니다. 또한 SAM CLI를 사용하면 개발자가 서버리스 애플리케이션을 로컬에서 실행하고 테스트할 수 있어 실제 AWS 환경을 시뮬레이션할 수 있습니다. 이에는 DynamoDB와 API Gateway의 통합이 포함됩니다.",
        "Other Options": [
            "CloudFormation 스택을 구현하는 것은 SAM이 이미 이 프로세스를 추상화하므로 필요하지 않습니다. SAM은 별도의 CloudFormation 템플릿 없이 서버리스 리소스의 배포를 처리합니다.",
            "Lambda 레이어를 생성하는 것은 CodeDeploy 배포와 직접적인 관련이 없습니다. 레이어는 종속성을 관리하는 데 유용할 수 있지만, CodeDeploy를 사용한 배포 프로세스를 용이하게 하지는 않습니다.",
            "SAM이 CloudFormation 템플릿을 생성할 수 있지만, 질문의 초점은 CodeDeploy를 통한 배포와 로컬 테스트에 있으므로 이 옵션은 덜 관련성이 있습니다."
        ]
    },
    {
        "Question Number": "60",
        "Situation": "글로벌 미디어 회사가 사용자 생성 콘텐츠를 저장하고 실시간 처리 기능을 제공하는 새로운 애플리케이션을 개발하고 있습니다. 개발 팀은 신뢰할 수 있고 확장 가능하며 비용 효율적인 스토리지 솔루션을 요구하는 애플리케이션 아키텍처를 위해 AWS를 활용하고 있습니다. 팀은 이미지, 비디오 및 문서를 포함한 애플리케이션 데이터에 대한 다양한 스토리지 옵션을 논의하고 있습니다. 그들은 데이터 검색이 용이하고 높은 가용성을 보장하면서 지연 시간을 최소화할 수 있는 스토리지 패턴을 선택해야 합니다.",
        "Question": "사용자 생성 콘텐츠에 대한 저지연 액세스를 제공하면서 확장성과 내구성을 보장하는 데 가장 적합한 스토리지 옵션은 무엇입니까?",
        "Options": {
            "1": "Amazon S3와 라이프사이클 정책을 사용하여 자주 접근하지 않는 데이터를 Amazon Glacier로 아카이브합니다.",
            "2": "Amazon S3에서 버전 관리를 활성화하여 동일한 콘텐츠의 여러 복사본을 유지합니다.",
            "3": "Amazon Elastic File System (Amazon EFS)을 사용하여 여러 EC2 인스턴스에서 동시 액세스를 허용합니다.",
            "4": "Amazon Elastic Block Store (Amazon EBS) 볼륨을 EC2 인스턴스에 연결하여 데이터에 직접 액세스합니다."
        },
        "Correct Answer": "Amazon Elastic File System (Amazon EFS)을 사용하여 여러 EC2 인스턴스에서 동시 액세스를 허용합니다.",
        "Explanation": "Amazon Elastic File System (Amazon EFS)은 여러 EC2 인스턴스가 데이터를 동시 액세스할 수 있도록 하는 확장 가능하고 완전 관리되는 파일 스토리지 서비스를 제공합니다. 이는 사용자 생성 콘텐츠에 대한 저지연 액세스가 필요하고 높은 가용성과 내구성을 요구하는 애플리케이션에 이상적인 선택입니다. EFS는 높은 처리량과 낮은 지연 시간을 위해 설계되어 콘텐츠의 실시간 처리를 위한 적합한 솔루션입니다.",
        "Other Options": [
            "Amazon S3와 라이프사이클 정책은 자주 접근하지 않는 데이터를 더 저렴한 스토리지로 전환하여 비용 최적화를 위해 설계되었으며, 이는 실시간 액세스 요구 사항에 적합하지 않습니다.",
            "Amazon Elastic Block Store (Amazon EBS) 볼륨은 개별 EC2 인스턴스에 연결되어 있으며 동시 액세스를 지원하지 않으므로 다중 인스턴스 아키텍처에서 확장성을 제한하고 지연 시간을 증가시킵니다.",
            "Amazon S3에서 버전 관리를 활성화하는 것은 데이터 복구 및 이전 버전 유지에 유용하지만, 실시간 애플리케이션에 적합한 저지연 액세스를 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "61",
        "Situation": "한 회사가 사용자 데이터에 대한 지속적인 저장소가 필요한 새로운 애플리케이션을 배포하고 있습니다. 이들은 여러 EC2 인스턴스에서 접근할 수 있는 확장 가능한 파일 저장 솔루션을 제공하기 위해 Amazon EFS를 사용하고 있습니다. DevOps 엔지니어는 각 애플리케이션 인스턴스가 EFS 파일 시스템의 특정 하위 디렉터리만 접근할 수 있도록 하면서 EFS에 접근하는 IAM 역할에 대해 최소 권한 원칙을 구현해야 합니다. 엔지니어는 이 요구 사항을 충족하기 위해 접근 지점을 구성해야 합니다.",
        "Question": "각 애플리케이션 인스턴스가 Amazon EFS 파일 시스템에서 자신의 하위 디렉터리에 제한된 접근 권한을 갖도록 하면서 최소 권한 원칙을 준수하기 위한 최선의 접근 방식은 무엇입니까?",
        "Options": {
            "1": "각 애플리케이션 인스턴스가 전체 EFS 파일 시스템에 접근할 수 있도록 권한을 관리하는 맞춤형 애플리케이션을 배포하고 애플리케이션 논리에 따라 접근을 제한합니다.",
            "2": "각 애플리케이션 인스턴스에 대해 루트 디렉터리를 해당 인스턴스의 하위 디렉터리로 지정하는 EFS 접근 지점을 생성하고 특정 접근 지점에만 접근을 허용하는 IAM 정책을 연결합니다.",
            "3": "EFS 파일 시스템에 대한 전체 접근을 허용하는 단일 IAM 역할을 생성하고 이를 모든 애플리케이션 인스턴스에 연결하여 애플리케이션 인스턴스가 모든 하위 디렉터리에 접근할 수 있도록 합니다.",
            "4": "모든 애플리케이션 인스턴스에 대해 단일 EFS 접근 지점을 사용하고 EFS 파일 시스템 내의 모든 하위 디렉터리에 대한 접근을 허용하는 IAM 정책을 설정합니다."
        },
        "Correct Answer": "각 애플리케이션 인스턴스에 대해 루트 디렉터리를 해당 인스턴스의 하위 디렉터리로 지정하는 EFS 접근 지점을 생성하고 특정 접근 지점에만 접근을 허용하는 IAM 정책을 연결합니다.",
        "Explanation": "각 애플리케이션 인스턴스에 대해 개별 EFS 접근 지점을 사용하면 각 인스턴스에 대한 특정 하위 디렉터리 접근을 정의할 수 있으며, IAM 정책은 권한을 추가로 제한할 수 있어 최소 권한 원칙을 준수할 수 있습니다.",
        "Other Options": [
            "모든 애플리케이션 인스턴스에 대해 단일 EFS 접근 지점을 사용하면 모든 하위 디렉터리가 모든 인스턴스에 노출되어 최소 권한 원칙을 위반하고 무단 접근으로 이어질 수 있습니다.",
            "권한을 관리하기 위해 맞춤형 애플리케이션을 배포하면 불필요한 복잡성이 추가되며 EFS 접근 지점과 IAM 정책의 내장 기능을 효과적으로 활용하지 못합니다.",
            "EFS 파일 시스템에 대한 전체 접근을 허용하는 단일 IAM 역할을 생성하면 모든 애플리케이션 인스턴스가 전체 파일 시스템에 무제한 접근할 수 있게 되어 보안이 compromised되며, 이는 최소 권한 원칙에 부합하지 않습니다."
        ]
    },
    {
        "Question Number": "62",
        "Situation": "한 회사가 빌드 및 배포 프로세스를 자동화하기 위해 버전 관리 시스템(VCS)과 통합된 CI/CD 파이프라인을 구현하고 있습니다. DevOps 엔지니어는 VCS에서 이루어진 변경 사항이 애플리케이션 환경에서 적절한 배포 작업을 트리거하도록 해야 합니다. 다음 전략 중 어떤 것이 이 통합을 달성하는 데 가장 효과적입니까?",
        "Question": "DevOps 엔지니어가 CI/CD 파이프라인이 버전 관리 시스템과 긴밀하게 통합되도록 보장하기 위해 어떤 전략을 구현해야 합니까?",
        "Options": {
            "1": "버전 관리 시스템에서 웹훅을 구성하여 코드 커밋 시 파이프라인 실행을 트리거합니다.",
            "2": "CI/CD 파이프라인에서 버전 관리 시스템의 변경 사항을 폴링하기 위해 예약 작업을 설정합니다.",
            "3": "버전 관리 시스템에서 각 코드 커밋 후 수동으로 파이프라인 실행을 트리거합니다.",
            "4": "타사 도구를 사용하여 버전 관리 시스템의 변경 사항을 CI/CD 파이프라인과 동기화합니다."
        },
        "Correct Answer": "버전 관리 시스템에서 웹훅을 구성하여 코드 커밋 시 파이프라인 실행을 트리거합니다.",
        "Explanation": "웹훅을 구성하면 CI/CD 파이프라인이 버전 관리 시스템의 변경 사항에 자동으로 반응할 수 있어, 수동 개입 없이 실시간 업데이트 및 배포가 가능해져 효율성을 높이고 인적 오류의 위험을 줄입니다.",
        "Other Options": [
            "예약 작업을 설정하면 지연이 발생하고 배포에 지연이 생길 수 있으며, 코드 변경에 즉시 반응하지 않습니다.",
            "파이프라인을 수동으로 트리거하는 것은 비효율적이고 오류가 발생하기 쉬우며, 인적 개입이 필요하고 배포 지연으로 이어질 수 있습니다.",
            "타사 도구를 사용하는 것은 불필요한 복잡성을 추가하고 추가적인 실패 지점을 도입할 수 있어 프로세스를 덜 신뢰할 수 있게 만듭니다."
        ]
    },
    {
        "Question Number": "63",
        "Situation": "한 회사가 AWS에 새로운 마이크로서비스 애플리케이션을 배포하고 있으며, 포괄적인 모니터링 및 로깅을 갖추기를 원합니다. 다양한 AWS 서비스에서 로그와 메트릭을 집계하고 성능 및 문제 해결을 위해 데이터를 쉽게 분석할 수 있는 솔루션이 필요합니다. 그들은 로깅 인프라를 직접 관리하는 것을 피하고 싶어합니다.",
        "Question": "DevOps 엔지니어가 AWS에 배포된 애플리케이션의 로그와 메트릭을 효과적으로 수집하고 분석하기 위해 어떤 솔루션을 구현해야 합니까?",
        "Options": {
            "1": "AWS X-Ray를 활용하여 애플리케이션을 통한 요청을 추적하고 성능을 모니터링합니다. 추적 데이터를 기반으로 성능 병목 현상을 식별하기 위한 경고를 설정합니다.",
            "2": "Amazon CloudWatch Logs를 설정하여 애플리케이션 및 AWS Lambda 함수의 로그를 수집합니다. CloudWatch Metrics를 사용하여 애플리케이션 성능을 추적하고 특정 임계값에 대한 사용자 정의 경고를 설정합니다.",
            "3": "EC2 인스턴스에 타사 로깅 솔루션을 배포하여 애플리케이션의 로그와 메트릭을 수집합니다. AWS 서비스에 의존하지 않고 로그를 저장하고 분석하기 위해 중앙 집중식 데이터베이스를 사용합니다.",
            "4": "AWS CloudTrail을 구성하여 애플리케이션에서 수행된 API 호출을 기록하고 Amazon S3를 사용하여 로그의 장기 저장을 수행합니다. Amazon Athena를 사용하여 쿼리 기능을 통해 로그를 분석합니다."
        },
        "Correct Answer": "Amazon CloudWatch Logs를 설정하여 애플리케이션 및 AWS Lambda 함수의 로그를 수집합니다. CloudWatch Metrics를 사용하여 애플리케이션 성능을 추적하고 특정 임계값에 대한 사용자 정의 경고를 설정합니다.",
        "Explanation": "Amazon CloudWatch Logs 및 Metrics를 사용하면 로그 집계 및 애플리케이션 성능 모니터링을 위한 완전 관리형 솔루션을 제공합니다. 이를 통해 실시간 모니터링, 경고 및 문제 해결이 가능해져 추가 인프라를 관리하지 않고도 포괄적인 가시성을 확보할 수 있습니다.",
        "Other Options": [
            "EC2 인스턴스에 타사 로깅 솔루션을 배포하면 추가 관리가 필요하고 복잡성이 증가할 수 있습니다. 이는 AWS의 관리형 서비스인 로깅 및 모니터링을 활용하지 않으므로 더 원활한 통합을 제공하지 않습니다.",
            "AWS CloudTrail을 구성하는 것은 API 호출 기록에 중점을 두며, 보안 및 감사 목적에는 유용하지만 포괄적인 모니터링에 필요한 애플리케이션 수준의 로그나 성능 메트릭을 제공하지 않습니다.",
            "AWS X-Ray는 주로 마이크로서비스 애플리케이션에서 요청을 추적하고 성능 병목 현상을 식별하는 데 사용됩니다. 그러나 다양한 서비스에서 로그를 집계하거나 완전한 모니터링 솔루션을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "64",
        "Situation": "한 회사가 AWS에서 고가용성과 복원력이 필요한 웹 애플리케이션을 운영하고 있습니다. 그들은 Elastic Load Balancer (ELB)를 사용하여 여러 EC2 인스턴스에 트래픽을 분산시키고 있습니다. 그러나 백엔드 EC2 인스턴스 중 하나가 실패할 때 ELB가 효과적으로 트래픽을 재배치하지 못하고 불건전한 인스턴스로 계속 요청을 보내어 다운타임이 발생하는 것을 발견했습니다. DevOps 엔지니어는 ELB가 백엔드 인스턴스 실패를 감지하고 그에 따라 트래픽을 재배치할 수 있도록 해야 합니다.",
        "Question": "DevOps 엔지니어가 백엔드 인스턴스 실패로부터 로드 밸런서가 자동으로 복구할 수 있도록 보장하기 위해 어떤 구성을 구현해야 합니까?",
        "Options": {
            "1": "Auto Scaling 그룹을 사용하여 로드 밸런서 수정 없이 불건전한 인스턴스를 새로운 인스턴스로 교체합니다.",
            "2": "인스턴스 크기를 늘려 더 많은 트래픽을 처리하고 실패 가능성을 줄입니다.",
            "3": "로드 밸런서에서 헬스 체크를 활성화하여 불건전한 인스턴스를 자동으로 등록 해제합니다.",
            "4": "인스턴스 건강을 모니터링하고 필요에 따라 트래픽을 재배치하는 수동 프로세스를 구현합니다."
        },
        "Correct Answer": "로드 밸런서에서 헬스 체크를 활성화하여 불건전한 인스턴스를 자동으로 등록 해제합니다.",
        "Explanation": "로드 밸런서에서 헬스 체크를 활성화하면 백엔드 인스턴스의 상태를 자동으로 모니터링할 수 있습니다. 인스턴스가 헬스 체크를 통과하지 못하면 ELB는 자동으로 등록 해제하고 트래픽 전송을 중단하여 애플리케이션의 고가용성과 복원력을 보장합니다.",
        "Other Options": [
            "인스턴스 크기를 늘리는 것은 성능을 개선할 수 있지만 자동 헬스 감지 및 트래픽 재배치의 필요성을 해결하지 않습니다. 불건전한 인스턴스는 제대로 모니터링되지 않으면 여전히 다운타임을 초래할 수 있습니다.",
            "인스턴스 건강을 모니터링하는 수동 프로세스를 구현하는 것은 비효율적이며 백엔드 실패에 대한 응답 지연을 초래할 수 있어 애플리케이션에 불필요한 다운타임을 초래할 수 있습니다.",
            "Auto Scaling 그룹을 사용하는 것은 인스턴스 가용성을 관리하는 좋은 방법이지만, 로드 밸런서에서 헬스 체크가 없으면 불건전한 인스턴스에서 트래픽을 자동으로 재배치하지 않습니다."
        ]
    },
    {
        "Question Number": "65",
        "Situation": "한 회사가 CI/CD 파이프라인을 개선하여 버전 관리 시스템과의 통합을 강화하고 있습니다. 개발 팀은 GitHub를 버전 관리에 사용하고 있으며 스테이징 및 프로덕션 환경에 대한 배포 프로세스를 자동화하고 싶어합니다. DevOps 엔지니어는 배포가 두 환경에서 일관되고 반복 가능하도록 하면서 버전 관리 모범 사례를 통합해야 합니다. 이 목표를 달성하기 위한 최선의 접근 방식은 무엇입니까?",
        "Question": "DevOps 엔지니어가 CI/CD 파이프라인에서 버전 관리를 사용하여 배포 프로세스를 자동화하려면 어떻게 해야 합니까?",
        "Options": {
            "1": "스테이징 및 프로덕션을 위한 별도의 Git 브랜치를 생성합니다. 각 브랜치를 체크아웃하고 애플리케이션을 배포하는 사용자 정의 셸 스크립트를 사용합니다. 이 스크립트는 배포가 필요할 때마다 수동으로 트리거됩니다.",
            "2": "GitHub Actions를 구성하여 변경 사항이 메인 브랜치에 푸시될 때마다 배포 워크플로를 트리거합니다. 환경 변수를 사용하여 스테이징 및 프로덕션에 대한 구성 설정을 관리합니다. 프로덕션 배포 전에 수동 승인 단계를 구현합니다.",
            "3": "AWS CodePipeline을 활용하여 GitHub 리포지토리에서 최신 코드를 가져오는 다단계 파이프라인을 생성합니다. AWS CodeDeploy를 통합하여 스테이징 및 프로덕션 환경 모두에 대한 배포 프로세스를 처리하며 내장된 승인 프로세스를 제공합니다.",
            "4": "Jenkins 파이프라인을 설정하여 GitHub 리포지토리의 변경 사항을 5분마다 폴링합니다. 스테이징에 자동으로 배포하고 프로덕션에 배포하기 위해 별도의 수동 트리거가 필요합니다. 두 환경 모두에 대해 공유 구성 파일을 사용합니다."
        },
        "Correct Answer": "AWS CodePipeline을 활용하여 GitHub 리포지토리에서 최신 코드를 가져오는 다단계 파이프라인을 생성합니다. AWS CodeDeploy를 통합하여 스테이징 및 프로덕션 환경 모두에 대한 배포 프로세스를 처리하며 내장된 승인 프로세스를 제공합니다.",
        "Explanation": "AWS CodePipeline을 활용하면 GitHub와 원활하게 통합되고 여러 환경에서 자동화된 배포를 허용하는 강력한 솔루션을 제공합니다. 프로덕션 배포에 대한 승인 프로세스를 지원하여 품질과 규정을 보장합니다.",
        "Other Options": [
            "GitHub Actions를 구성하는 것은 유효한 접근 방식이지만, AWS CodePipeline의 포괄적인 기능, 즉 내장된 승인 및 다른 AWS 서비스와의 통합이 부족할 수 있으며, 이는 신뢰할 수 있는 배포 전략에 필수적입니다.",
            "Jenkins를 사용하는 것은 추가적인 유지 관리 오버헤드를 초래하고 폴링에 의존하게 되어 배포 지연을 초래할 수 있으며, 프로덕션 환경에 대한 구조화된 승인 프로세스를 본질적으로 제공하지 않습니다.",
            "스테이징 및 프로덕션을 위한 별도의 Git 브랜치를 생성하는 것은 버전 관리를 복잡하게 만들고 간소화된 배포 프로세스를 촉진하지 않습니다. 수동 스크립트 트리거의 필요성은 인적 오류와 불일치의 위험을 증가시킵니다."
        ]
    },
    {
        "Question Number": "66",
        "Situation": "한 금융 서비스 조직이 애플리케이션과 데이터베이스를 지원하기 위해 새로운 AWS 인프라를 구현하고 있습니다. 보안 준수 요구 사항의 일환으로, AWS 리소스에 접근하는 모든 인간 및 기계 신원이 적절하게 인증되고 권한이 부여되도록 해야 합니다. 이 조직은 다단계 인증(MFA)과 같은 강력한 보안 조치를 시행하면서 사용자와 애플리케이션에 대한 임시 접근을 허용하는 솔루션을 구현하고자 합니다.",
        "Question": "이 시나리오에서 인간 및 기계 신원에 대한 권한을 관리하고 접근을 제어하는 가장 효과적인 방법은 무엇입니까?",
        "Options": {
            "1": "AWS Organizations를 구현하여 계정을 관리하고 서비스 제어 정책을 사용하여 접근을 제한합니다. MFA를 요구하지 않고 사용자에게 IAM 역할을 할당합니다.",
            "2": "AWS Identity and Access Management (IAM) 역할과 AWS Security Token Service (STS)를 활용하여 사용자와 애플리케이션에 대한 임시 자격 증명을 부여합니다. AWS Management Console에 접근하는 모든 IAM 사용자에게 MFA를 요구합니다.",
            "3": "AWS Single Sign-On을 사용하여 AWS 계정 및 애플리케이션에 대한 접근을 관리하고, 사용자가 기업 자격 증명으로 로그인할 수 있도록 하며 MFA를 시행하지 않습니다.",
            "4": "AWS에 접근해야 하는 각 개인 및 애플리케이션에 대해 IAM 사용자를 생성합니다. 장기 액세스 키를 할당하고 복잡한 비밀번호를 요구하는 비밀번호 정책을 시행합니다."
        },
        "Correct Answer": "AWS Identity and Access Management (IAM) 역할과 AWS Security Token Service (STS)를 활용하여 사용자와 애플리케이션에 대한 임시 자격 증명을 부여합니다. AWS Management Console에 접근하는 모든 IAM 사용자에게 MFA를 요구합니다.",
        "Explanation": "IAM 역할과 AWS STS를 활용하면 임시 보안 자격 증명을 발급할 수 있어 장기 액세스 키와 관련된 위험을 줄여 보안을 강화합니다. 또한 MFA를 시행하면 권한이 부여된 사용자만 민감한 리소스에 접근할 수 있도록 보장하여 보안 및 준수에 대한 모범 사례에 부합합니다.",
        "Other Options": [
            "장기 액세스 키가 있는 IAM 사용자를 생성하는 것은 자격 증명 유출의 위험을 증가시키고 보안 모범 사례에 부합하지 않습니다. 또한 접근 제어를 더 잘 관리할 수 있는 임시 권한 부여를 허용하지 않습니다.",
            "AWS Organizations를 사용하는 것은 계정 관리를 도울 수 있지만, IAM 역할에 MFA를 요구하지 않고 서비스 제어 정책에 의존하는 것은 보안 태세를 약화시킵니다. 이는 강력한 인증 메커니즘을 시행하지 않기 때문입니다.",
            "AWS Single Sign-On은 접근 관리를 간소화할 수 있지만 MFA를 시행하지 않으면 추가 인증 계층 없이 사용자가 로그인할 수 있어 민감한 환경에서 보안 위험을 초래합니다."
        ]
    },
    {
        "Question Number": "67",
        "Situation": "한 회사가 다양한 작업 부하를 처리하기 위해 AWS Lambda 함수를 활용하고 있으며, 관찰 가능성을 개선하고자 합니다. 특히 성능 문제를 추적하고 애플리케이션의 동작을 세부적으로 이해하는 데 관심이 있습니다. DevOps 팀은 이러한 Lambda 함수의 실행에 대한 자세한 통찰력을 제공하는 모니터링 솔루션을 구현하는 임무를 맡고 있습니다.",
        "Question": "DevOps 팀이 AWS X-Ray를 사용하여 AWS Lambda 함수의 세부 모니터링을 달성하기 위해 어떤 접근 방식을 취해야 합니까?",
        "Options": {
            "1": "AWS CloudWatch 알람을 구성하여 Lambda 실행 오류를 알리고 성능 통찰력을 위해 내장 메트릭을 활용합니다.",
            "2": "AWS X-Ray SDK를 사용하여 Lambda 함수를 계측하고 서브세그먼트를 생성하여 요청 및 응답의 자세한 추적을 가능하게 합니다.",
            "3": "Lambda 실행 환경에 사이드카 컨테이너로 AWS X-Ray Daemon을 배포하여 추적을 캡처하고 분석합니다.",
            "4": "AWS CloudTrail을 구현하여 Lambda 함수가 수행한 API 호출을 기록하고 이 데이터를 성능 모니터링에 사용합니다."
        },
        "Correct Answer": "AWS X-Ray SDK를 사용하여 Lambda 함수를 계측하고 서브세그먼트를 생성하여 요청 및 응답의 자세한 추적을 가능하게 합니다.",
        "Explanation": "AWS X-Ray SDK를 사용하면 DevOps 팀이 Lambda 함수를 직접 계측할 수 있어 실행 흐름과 성능 문제에 대한 자세한 통찰력을 제공하는 서브세그먼트를 생성할 수 있습니다.",
        "Other Options": [
            "AWS X-Ray Daemon을 사이드카 컨테이너로 배포하는 것은 Lambda 함수에 적용할 수 없으며, Lambda 함수의 실행 환경에서는 사이드카 컨테이너를 지원하지 않습니다.",
            "AWS CloudTrail은 API 호출을 기록하지만 Lambda 함수의 성능 및 동작에 대한 통찰력을 제공하지 않으므로 세부 모니터링에 적합하지 않습니다.",
            "AWS CloudWatch 알람은 오류에 대해 알릴 수 있지만, AWS X-Ray가 제공하는 실행 흐름 이해를 위한 자세한 추적 및 서브세그먼트 기능을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "68",
        "Situation": "기술 스타트업의 DevOps 엔지니어로서, 새로운 마이크로서비스 애플리케이션의 배포 프로세스를 개선하는 임무를 맡고 있습니다. 팀은 다운타임을 최소화하고 프로덕션에 버그를 도입할 위험을 줄이기 위해 다양한 배포 전략을 고려하고 있습니다. 고가용성을 유지하면서 점진적인 롤아웃을 허용하는 배포 방법을 선택해야 합니다.",
        "Question": "이 시나리오에서 애플리케이션 업데이트 중 위험을 최소화하는 데 가장 적합한 배포 방법은 무엇입니까?",
        "Options": {
            "1": "블루/그린 배포 방법을 사용하여 두 개의 동일한 환경 간에 트래픽을 전환하여 다운타임을 제로로 보장합니다.",
            "2": "카나리 배포 전략을 구현하여 전체 사용자 기반에 롤아웃하기 전에 소규모 사용자 집합에 업데이트를 배포합니다.",
            "3": "롤링 배포 전략을 채택하여 인스턴스를 하나씩 업데이트하면서 애플리케이션을 계속 사용할 수 있도록 합니다.",
            "4": "변경 사항을 배포할 수 있지만 필요할 때만 활성화되는 기능 토글 시스템을 선택합니다."
        },
        "Correct Answer": "카나리 배포 전략을 구현하여 전체 사용자 기반에 롤아웃하기 전에 소규모 사용자 집합에 업데이트를 배포합니다.",
        "Explanation": "카나리 배포 전략을 사용하면 먼저 소규모 사용자 그룹에 변경 사항을 롤아웃하고 성능을 모니터링하며 피드백을 수집한 후, 나머지 사용자 기반에 점진적으로 변경 사항을 배포할 수 있습니다. 이는 위험을 최소화하고 모든 사용자에게 영향을 미치기 전에 문제를 식별하는 데 도움이 됩니다.",
        "Other Options": [
            "블루/그린 배포 방법은 다운타임 제로를 달성하는 데 효과적이지만, 두 개의 별도 환경을 유지해야 하므로 작은 애플리케이션에는 필요하지 않을 수 있으며 자원 소모가 더 클 수 있습니다.",
            "롤링 배포 전략은 인스턴스를 하나씩 업데이트하므로, 특히 새로운 버전이 중단 변경 사항을 도입할 경우 일관성 문제와 잠재적인 문제가 발생할 수 있습니다.",
            "기능 토글은 코드를 배포하되 즉시 활성화하지 않도록 허용하지만, 이 접근 방식은 롤아웃 과정에서 위험을 본질적으로 최소화하지 않으며, 새로운 코드는 여전히 프로덕션 환경에 존재합니다."
        ]
    },
    {
        "Question Number": "69",
        "Situation": "한 전자상거래 회사가 피크 트래픽 시간 동안 간헐적인 중단을 경험하고 있습니다. 이들은 특정 복구 시간 목표(RTO) 및 복구 지점 목표(RPO)를 준수하면서 애플리케이션이 실패 시 신속하게 복구할 수 있도록 해야 합니다. 개발 팀은 장애 조치 및 복구 프로세스를 처리하기 위한 자동화된 솔루션을 찾고 있습니다.",
        "Question": "다음 접근 방식 중 전자상거래 애플리케이션의 RTO 및 RPO 요구 사항을 충족하는 가장 효과적인 자동 복구 솔루션은 무엇입니까?",
        "Options": {
            "1": "건강 검사를 통해 자동으로 불량 인스턴스를 교체하는 오토 스케일링 그룹을 구성합니다. RPO를 충족하기 위해 매시간 Amazon S3에 데이터를 백업하지만 RTO는 수동 개입에 의존합니다.",
            "2": "주 인스턴스가 애플리케이션을 호스팅하고 보조 인스턴스는 주 인스턴스가 실패할 때만 시작되는 액티브-패시브 아키텍처를 설정합니다. 데이터베이스 복제를 위해 Amazon RDS를 사용하고 장애 조치를 수동으로 시작합니다.",
            "3": "트래픽에 따라 자동으로 확장되는 단일 환경을 가진 AWS Elastic Beanstalk를 활용합니다. 복구를 위해 데이터베이스의 주기적인 스냅샷을 구현하지만 자동 장애 조치 메커니즘은 없습니다.",
            "4": "Route 53을 사용하여 DNS 장애 조치를 통해 여러 AWS 리전에서 액티브-액티브 아키텍처를 구현합니다. 리전 간에 데이터가 실시간으로 복제되도록 하여 실패 시 즉각적인 복구를 가능하게 합니다."
        },
        "Correct Answer": "Route 53을 사용하여 DNS 장애 조치를 통해 여러 AWS 리전에서 액티브-액티브 아키텍처를 구현합니다. 리전 간에 데이터가 실시간으로 복제되도록 하여 실패 시 즉각적인 복구를 가능하게 합니다.",
        "Explanation": "액티브-액티브 아키텍처는 가장 높은 수준의 가용성과 복원력을 제공하여 한 리전이 다운되더라도 애플리케이션이 계속 운영될 수 있도록 합니다. 실시간 데이터 복제는 데이터 손실을 방지하여 엄격한 RPO 요구 사항을 충족하며, Route 53은 즉각적인 트래픽 리디렉션을 가능하게 하여 RTO 요구 사항을 효과적으로 해결합니다.",
        "Other Options": [
            "액티브-패시브 아키텍처는 장애 조치를 위한 수동 개입이 필요하므로 복구에 지연이 발생하여 요구되는 RTO를 충족하지 못할 수 있습니다. 또한 애플리케이션 호스팅을 위해 단일 인스턴스에만 의존하는 것은 단일 실패 지점을 생성할 수 있습니다.",
            "오토 스케일링 그룹은 불량 인스턴스를 교체하는 데 도움이 되지만, 리전 간의 자동 장애 조치 요구 사항이나 실시간 데이터 가용성을 보장하지 않으므로 엄격한 RTO 및 RPO를 충족하는 데 부족합니다.",
            "단일 환경을 가진 AWS Elastic Beanstalk는 높은 가용성을 위한 중복성과 자동 장애 조치 기능이 부족합니다. 스냅샷은 데이터 백업을 제공하지만 실시간 복구를 지원하지 않아 RPO 및 RTO 요구 사항을 충족하는 데 불충분합니다."
        ]
    },
    {
        "Question Number": "70",
        "Situation": "한 회사가 Amazon CloudWatch를 사용하여 애플리케이션 성능을 모니터링하고 실시간으로 이상 징후를 식별하고 있습니다. 모니터링 전략의 일환으로 DevOps 엔지니어는 애플리케이션 지연 시간의 비정상적인 급증에 대해 팀에 사전 경고를 제공하기 위해 이상 탐지 알람을 설정해야 합니다. 팀은 이러한 알람이 정상 동작에서 통계적으로 유의미한 편차가 있을 때만 발생하도록 하기를 원합니다.",
        "Question": "DevOps 엔지니어가 CloudWatch에서 이상 탐지 알람을 효과적으로 구현하기 위해 어떤 접근 방식을 사용해야 합니까?",
        "Options": {
            "1": "CloudWatch 대시보드를 설정하여 지연 시간 메트릭을 시각화하고, 시각적 검토를 통해 매일 데이터를 수동으로 검토하여 이상 징후를 식별합니다.",
            "2": "CloudWatch Anomaly Detection을 사용하여 지연 시간 메트릭의 역사적 데이터 패턴을 기반으로 알람을 생성하고, 서비스가 통계 분석에 따라 알람 임계값을 자동으로 조정하도록 합니다.",
            "3": "지연 시간 메트릭에 대한 정적 임계값을 기반으로 CloudWatch 알람을 생성하여, 임계값이 정상 운영 범위보다 약간 높게 설정되어 잠재적인 이상 징후를 포착하도록 합니다.",
            "4": "지연 시간 메트릭을 분석하고 정의된 기간 동안 평균 지연 시간에서 편차를 감지할 때마다 팀에 알림을 보내는 사용자 지정 Lambda 함수를 구현합니다."
        },
        "Correct Answer": "CloudWatch Anomaly Detection을 사용하여 지연 시간 메트릭의 역사적 데이터 패턴을 기반으로 알람을 생성하고, 서비스가 통계 분석에 따라 알람 임계값을 자동으로 조정하도록 합니다.",
        "Explanation": "CloudWatch Anomaly Detection은 기계 학습을 활용하여 역사적 메트릭을 분석하고 정상 동작에 대한 동적 기준선을 설정합니다. 이 방법은 잘못된 경고를 줄이고, 중요한 편차에 대해서만 알림이 발생하도록 하여 이상 징후에 대한 보다 효과적인 모니터링 전략을 제공합니다.",
        "Other Options": [
            "정적 임계값을 기반으로 CloudWatch 알람을 생성하면 정상 운영 동작의 변화에 적응하지 않기 때문에 빈번한 잘못된 경고나 놓치는 이상 징후가 발생할 수 있습니다.",
            "사용자 지정 Lambda 함수를 구현하면 지연 시간 메트릭에 대한 통찰력을 제공할 수 있지만, 불필요한 복잡성을 추가하고 이상 탐지를 위해 설계된 CloudWatch의 내장 기능을 활용하지 못할 수 있습니다.",
            "CloudWatch 대시보드를 설정하여 수동 검토하는 것은 비효율적이며 인적 오류에 취약합니다. 이는 실시간 알림을 제공하지 않으며, 팀이 메트릭을 지속적으로 모니터링해야 하므로 이상 징후에 대한 대응이 지연될 수 있습니다."
        ]
    },
    {
        "Question Number": "71",
        "Situation": "DevOps 엔지니어가 AWS에 호스팅된 마이크로서비스 애플리케이션을 위한 CI/CD 파이프라인을 구현하는 임무를 맡고 있습니다. 이 파이프라인은 코드 통합, 자동화된 테스트 및 여러 환경에 대한 배포를 용이하게 해야 합니다. 코드 변경 사항이 자동으로 빌드되고 테스트되며 스테이징 환경에 배포된 후 프로덕션으로 승격되도록 해야 합니다.",
        "Question": "엔지니어가 이러한 요구 사항을 충족하는 효과적인 CI/CD 파이프라인을 설계하기 위해 어떤 접근 방식을 취해야 합니까?",
        "Options": {
            "1": "EC2에서 Jenkins 서버를 생성하여 빌드 및 배포 프로세스를 관리하고, 리포지토리의 코드 변경 사항에 따라 스테이징 및 프로덕션 환경에 대한 배포를 트리거하도록 구성합니다.",
            "2": "AWS AppSync를 사용하여 마이크로서비스의 배포를 관리하는 GitOps 접근 방식을 구현하여 리포지토리의 변경 사항이 프로덕션 환경에 자동으로 반영되도록 합니다.",
            "3": "AWS Lambda 함수를 사용하여 빌드 및 배포 프로세스를 처리하고, 리포지토리에서 코드 변경이 감지될 때마다 CloudWatch Events를 통해 이를 트리거합니다.",
            "4": "AWS CodePipeline을 활용하여 빌드, 테스트 및 배포 단계를 조정하고, 빌드 프로세스에 AWS CodeBuild를 통합하고 스테이징 및 프로덕션 환경에 대한 배포에 AWS CodeDeploy를 사용합니다."
        },
        "Correct Answer": "AWS CodePipeline을 활용하여 빌드, 테스트 및 배포 단계를 조정하고, 빌드 프로세스에 AWS CodeBuild를 통합하고 스테이징 및 프로덕션 환경에 대한 배포에 AWS CodeDeploy를 사용합니다.",
        "Explanation": "AWS CodePipeline을 사용하면 애플리케이션 빌드를 위한 CodeBuild 및 다양한 AWS 서비스와 쉽게 통합할 수 있는 완전 관리형 CI/CD 솔루션을 제공합니다. 이 접근 방식은 코드 통합에서 배포까지 원활한 워크플로를 보장하며, 자동화 및 신뢰성에 대한 모범 사례를 준수합니다.",
        "Other Options": [
            "Jenkins 서버를 생성하면 추가적인 유지 관리 및 관리 오버헤드가 필요합니다. Jenkins를 사용하여 CI/CD를 구현할 수 있지만, CodePipeline만큼 AWS 서비스와 원활하게 통합되지 않아 주어진 요구 사항에 대해 덜 효율적입니다.",
            "빌드 및 배포를 위해 AWS Lambda를 사용하는 것은 이상적이지 않습니다. Lambda는 단기 함수에 맞게 설계되었으며, 빌드 프로세스는 일반적으로 Lambda가 효과적으로 처리하지 못할 수 있는 더 복잡한 워크플로를 포함합니다. 또한 상태 및 로그 관리에 어려움이 있을 수 있습니다.",
            "AWS AppSync를 사용한 GitOps 접근 방식은 API 구축 및 데이터 관리에 주로 설계되었기 때문에 CI/CD 파이프라인 관리에는 적합하지 않습니다. 이 접근 방식은 자동화된 빌드 및 테스트 요구 사항을 충족하지 않습니다."
        ]
    },
    {
        "Question Number": "72",
        "Situation": "사용자 데이터를 관리하기 위해 Amazon DynamoDB를 사용하는 글로벌 애플리케이션을 설계하고 있습니다. 이 애플리케이션은 전 세계 사용자에게 높은 가용성과 낮은 지연 시간을 보장하기 위해 여러 지역에 데이터를 복제해야 합니다. 또한 사용자 행동에 의해 트리거되는 실시간 데이터 처리 및 분석을 처리하기 위해 DynamoDB Streams를 활용하고자 합니다. 팀은 읽기 및 쓰기 작업을 효율적으로 관리하면서 데이터 중복을 피해야 합니다.",
        "Question": "DynamoDB Streams를 사용하여 지역 간 복제 및 실시간 데이터 처리를 위한 요구 사항을 충족하기 위해 어떤 전략을 구현해야 합니까?",
        "Options": {
            "1": "DynamoDB Global Tables를 사용하여 자동 지역 간 복제를 수행하고, 스트림 레코드를 처리하기 위해 Lambda 함수를 트리거하는 CloudWatch Events 규칙을 설정합니다.",
            "2": "테이블에서 DynamoDB Streams를 활성화하고 스트림을 처리하기 위해 Lambda 함수를 구성하며, 쓰기 작업을 위한 버퍼로 SQS를 사용합니다.",
            "3": "테이블에서 DynamoDB Streams를 활성화하되 SQS를 사용하지 않고, 대신 Lambda 함수를 직접 호출하여 스트림 이벤트를 처리합니다.",
            "4": "AWS CLI 명령을 사용하여 지역 간에 하나의 DynamoDB 테이블에서 다른 테이블로 레코드를 수동으로 복사하고 모니터링을 위해 CloudWatch Alarm을 생성합니다."
        },
        "Correct Answer": "DynamoDB Global Tables를 사용하여 자동 지역 간 복제를 수행하고, 스트림 레코드를 처리하기 위해 Lambda 함수를 트리거하는 CloudWatch Events 규칙을 설정합니다.",
        "Explanation": "DynamoDB Global Tables를 사용하면 수동 개입 없이 데이터의 자동 및 원활한 지역 간 복제를 가능하게 합니다. 이 접근 방식은 높은 가용성과 낮은 지연 시간을 보장합니다. 또한 CloudWatch Events 규칙을 설정하여 Lambda 함수를 트리거하면 스트림 레코드를 효율적으로 실시간 처리할 수 있습니다.",
        "Other Options": [
            "DynamoDB Streams를 활성화하고 Lambda 함수를 SQS와 함께 버퍼로 사용하는 것은 쓰기를 관리하는 좋은 접근 방식이지만, 요구되는 지역 간 복제를 직접 제공하지 않습니다.",
            "AWS CLI 명령을 사용하여 레코드를 수동으로 복사하는 것은 실시간 데이터 복제에 비효율적이며 운영 오버헤드 및 데이터 불일치 가능성을 초래할 수 있습니다.",
            "SQS 없이 DynamoDB Streams를 활성화하면 스트림 이벤트의 급증이 있을 경우 Lambda 함수의 스로틀링이 증가할 수 있으며, 지역 간 복제 필요성을 해결하지 못합니다."
        ]
    },
    {
        "Question Number": "73",
        "Situation": "DevOps 엔지니어는 프로덕션 환경의 모든 EC2 인스턴스가 특정 구성 규칙 및 인벤토리 관리와의 준수를 유지하도록 하는 임무를 맡고 있습니다. 엔지니어는 구성 변경 사항을 추적하는 프로세스를 자동화하고 정의된 기준선에서의 모든 편차가 자동으로 수정되도록 하는 솔루션을 구현해야 합니다. 이 솔루션은 또한 AWS 계정 내 리소스의 현재 상태에 대한 가시성을 제공해야 합니다.",
        "Question": "엔지니어가 이러한 목표를 달성하기 위한 가장 효과적인 접근 방식은 무엇입니까?",
        "Options": {
            "1": "AWS Systems Manager State Manager를 구현하여 EC2 인스턴스의 원하는 구성을 정의하고 이러한 구성을 주기적으로 적용합니다. AWS Config를 사용하여 준수를 모니터링하지만 감지된 비준수 문제에 대해서는 수동 개입에 의존합니다.",
            "2": "AWS Config를 활용하여 EC2 인스턴스의 원하는 구성 상태를 설명하는 규칙 집합을 정의합니다. AWS Config를 활성화하여 구성 변경 사항을 지속적으로 모니터링하고 기록하며 AWS Lambda 함수를 설정하여 비준수 리소스를 자동으로 수정합니다.",
            "3": "AWS Systems Manager Inventory를 활용하여 EC2 인스턴스에서 메타데이터를 수집하고 AWS Config를 사용하여 구성 규칙에 대한 준수를 평가합니다. 준수 문제가 발생할 때 관리자를 경고하는 알림 시스템을 설정합니다.",
            "4": "AWS Config 규칙을 설정하여 EC2 인스턴스의 준수를 모니터링하고 AWS CloudTrail과 통합하여 구성 변경 사항을 기록합니다. 식별된 비준수 리소스를 수정하기 위해 수동 스크립트를 사용합니다."
        },
        "Correct Answer": "AWS Config를 활용하여 EC2 인스턴스의 원하는 구성 상태를 설명하는 규칙 집합을 정의합니다. AWS Config를 활성화하여 구성 변경 사항을 지속적으로 모니터링하고 기록하며 AWS Lambda 함수를 설정하여 비준수 리소스를 자동으로 수정합니다.",
        "Explanation": "AWS Config를 활용하여 규칙을 정의하고 구성 변경 사항을 모니터링 및 기록하도록 활성화하면 강력한 준수 메커니즘이 보장됩니다. 이를 AWS Lambda와 결합하여 자동 수정이 가능하게 하면 비준수를 즉시 해결할 수 있어 가시성과 자동화 요구 사항을 효과적으로 충족합니다.",
        "Other Options": [
            "구성 관리를 위해 AWS Systems Manager State Manager를 구현하는 것은 좋은 관행이지만, 비준수 문제를 해결하기 위해 수동 개입에 의존하는 것은 자동화 및 즉각적인 수정 요구 사항을 충족하지 않습니다.",
            "AWS Config 규칙을 설정하는 것은 유효한 접근 방식이지만, 수동 스크립트를 사용하여 수정하는 것은 비효율적이며 엔지니어가 준수 관리에 필요로 하는 원하는 자동화를 제공하지 않습니다.",
            "AWS Systems Manager Inventory를 활용하는 것은 메타데이터 수집에 유용하지만, 비준수 문제에 대한 수정 메커니즘을 본질적으로 제공하지 않습니다. 알림에만 의존하는 것은 자동 수정 요구 사항을 충족하지 않습니다."
        ]
    },
    {
        "Question Number": "74",
        "Situation": "DevOps 엔지니어는 AWS에서 코드로서의 인프라(IaC)를 사용하여 인프라를 관리하는 임무를 맡고 있습니다. 팀은 현재 리소스 프로비저닝을 위해 CloudFormation을 사용하고 있지만, 추가적인 유연성과 모듈성을 제공할 수 있는 대안을 고려하고 있습니다. 조직은 복잡한 애플리케이션을 더 잘 관리하고 여러 프로그래밍 언어를 지원하는 솔루션을 구현하는 것을 목표로 하고 있습니다.",
        "Question": "엔지니어가 AWS에서 코드로서의 인프라를 관리하면서 향상된 유연성과 여러 프로그래밍 언어 지원을 제공하기 위해 고려해야 할 도구는 무엇입니까?",
        "Options": {
            "1": "여러 공급자와 프로그래밍 언어를 지원하는 Terraform",
            "2": "모듈성을 위한 중첩 스택을 가진 AWS CloudFormation",
            "3": "친숙한 프로그래밍 언어로 개발할 수 있는 AWS CDK",
            "4": "Chef와 Puppet을 사용하여 구성 관리를 중심으로 하는 AWS OpsWorks"
        },
        "Correct Answer": "친숙한 프로그래밍 언어로 개발할 수 있는 AWS CDK",
        "Explanation": "AWS CDK(Cloud Development Kit)는 TypeScript, Python, Java 및 C#과 같은 친숙한 프로그래밍 언어를 사용하여 클라우드 리소스를 정의하도록 설계되었습니다. 이는 더 높은 수준의 추상화를 제공하며 개발자가 프로그래밍 구조를 사용할 수 있게 하여 복잡한 인프라를 관리하기 쉽게 만듭니다.",
        "Other Options": [
            "중첩 스택을 가진 AWS CloudFormation은 모듈성을 위한 유효한 옵션이지만 여러 프로그래밍 언어를 지원하지 않습니다. 주로 JSON 또는 YAML을 사용하여 정의되며, 이는 다른 도구에 비해 유연성을 제한할 수 있습니다.",
            "Terraform은 강력한 도구이며 여러 공급자를 지원하지만, AWS CDK처럼 AWS 서비스와 원활하게 통합되지 않습니다. AWS CDK는 AWS 환경을 위해 특별히 설계되었습니다.",
            "AWS OpsWorks는 인프라 프로비저닝보다 구성 관리에 중점을 두고 있습니다. 애플리케이션 배포를 위해 Chef와 Puppet을 사용하며, 유연하고 프로그래밍 방식으로 인프라를 정의하는 데 이상적이지 않습니다."
        ]
    },
    {
        "Question Number": "75",
        "Situation": "소매 회사는 신뢰성과 가용성을 향상시키기 위해 중요한 애플리케이션을 AWS로 마이그레이션하고 있습니다. 비즈니스 이해관계자들은 지역 중단 및 예기치 않은 트래픽 급증을 견딜 수 있는 복원력 있는 아키텍처의 필요성을 강조했습니다. DevOps 엔지니어는 이러한 비즈니스 요구 사항을 특정 기술적 복원력 기능으로 변환하는 임무를 맡고 있습니다.",
        "Question": "엔지니어가 애플리케이션의 기술적 복원력을 보장하기 위해 구현해야 할 조치는 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "로드 변동 관리를 위해 단일 EC2 인스턴스에 애플리케이션을 배포하고 자동 확장 그룹을 설정합니다.",
            "2": "계획된 및 비계획된 중단 동안 데이터베이스 가용성을 높이기 위해 Amazon RDS를 Multi-AZ 배포로 구성합니다.",
            "3": "여러 가용 영역에 걸쳐 AWS Elastic Load Balancing을 구현하여 트래픽을 분산하고 장애 조치 기능을 제공합니다.",
            "4": "정적 콘텐츠를 캐시하고 엣지 위치에서 제공하여 트래픽 급증 시 지연 시간을 최소화하기 위해 Amazon CloudFront를 CDN으로 설정합니다.",
            "5": "비용을 줄이고 높은 가용성을 보장하기 위해 모든 애플리케이션 트래픽을 처리하는 AWS Lambda 함수를 사용합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "여러 가용 영역에 걸쳐 AWS Elastic Load Balancing을 구현하여 트래픽을 분산하고 장애 조치 기능을 제공합니다.",
            "Amazon RDS를 Multi-AZ 배포로 구성하여 계획된 및 비계획된 중단 동안 데이터베이스 가용성을 높입니다."
        ],
        "Explanation": "여러 가용 영역에 걸쳐 AWS Elastic Load Balancing을 구현하면 들어오는 트래픽이 건강한 인스턴스 간에 분산되어 하나 이상의 인스턴스가 사용할 수 없게 될 경우 장애 조치 기능을 제공합니다. Amazon RDS를 Multi-AZ 배포로 구성하면 데이터베이스가 높은 가용성을 유지하고 장애를 견딜 수 있어 비즈니스의 복원력 요구 사항을 충족합니다.",
        "Other Options": [
            "모든 애플리케이션 트래픽을 처리하기 위해 AWS Lambda 함수를 사용하는 것은 로드 밸런서가 제공하는 필요한 제어 및 장애 조치 기능을 제공하지 않을 수 있습니다. Lambda는 확장성을 향상시키지만 전통적인 애플리케이션의 높은 가용성 요구 사항을 직접적으로 해결하지 않습니다.",
            "Amazon CloudFront를 설정하는 것은 콘텐츠 전달 및 지연 시간 감소에 유익하지만, 비즈니스의 복원력 요구 사항을 충족하는 데 중요한 백엔드 애플리케이션 복원력이나 데이터베이스 가용성을 해결하지 않습니다.",
            "단일 EC2 인스턴스에 애플리케이션을 배포하고 자동 확장 그룹을 설정하는 것은 진정한 복원력을 제공하지 않습니다. 자동 확장은 로드 변동을 관리할 수 있지만, 단일 인스턴스에 의존하는 것은 인스턴스 장애 시 다운타임의 위험을 초래합니다."
        ]
    }
]