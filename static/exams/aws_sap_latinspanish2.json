[
    {
        "Question Number": "1",
        "Situation": "Una empresa de medios está desarrollando una aplicación que requiere acceso compartido a archivos para múltiples instancias de EC2. La aplicación procesará archivos multimedia que cambian con frecuencia y necesitan ser accesibles con semántica de sistema de archivos POSIX. La empresa está considerando usar Amazon EFS para este propósito y quiere asegurar la disponibilidad y durabilidad de los datos en caso de fallos regionales.",
        "Question": "¿Qué configuración debería implementar la empresa para asegurar alta disponibilidad y recuperación rápida de su sistema de archivos Amazon EFS en múltiples Regiones de AWS?",
        "Options": {
            "1": "Crear un sistema de archivos Amazon EFS y habilitar la replicación a otro sistema de archivos Amazon EFS en una Región de AWS diferente.",
            "2": "Configurar una instancia de EC2 para gestionar las transferencias de archivos entre el sistema de archivos EFS principal y un sistema de archivos EFS secundario en una región diferente.",
            "3": "Usar Amazon S3 para almacenamiento de archivos y configurar una política de ciclo de vida de S3 para archivar archivos multimedia más antiguos.",
            "4": "Desplegar el sistema de archivos Amazon EFS en una única Zona de Disponibilidad y usar AWS Backup para crear copias de seguridad regulares."
        },
        "Correct Answer": "Crear un sistema de archivos Amazon EFS y habilitar la replicación a otro sistema de archivos Amazon EFS en una Región de AWS diferente.",
        "Explanation": "Habilitar la replicación para un sistema de archivos Amazon EFS permite la sincronización automática y continua de datos entre los sistemas de archivos principal y secundario a través de diferentes regiones. Esto proporciona alta disponibilidad y cumple con los objetivos de punto de recuperación y tiempo de recuperación requeridos por la empresa.",
        "Other Options": [
            "Desplegar el sistema de archivos Amazon EFS en una única Zona de Disponibilidad no proporciona la durabilidad y disponibilidad necesarias en caso de un fallo regional, ya que está limitado a una zona.",
            "Usar Amazon S3 no es adecuado para aplicaciones que requieren semántica de sistema de archivos compatible con POSIX, que son necesarias para la aplicación de procesamiento multimedia.",
            "Configurar una instancia de EC2 para gestionar las transferencias de archivos añade complejidad innecesaria y no proporciona la replicación automatizada y continua que ofrece EFS."
        ]
    },
    {
        "Question Number": "2",
        "Situation": "Una empresa de medios opera una plataforma de streaming de video utilizando recursos de AWS, incluyendo múltiples instancias de EC2 para procesar cargas de video y un Elastic Load Balancer (ELB) para distribuir el tráfico entrante. Los usuarios han reportado almacenamiento en búfer intermitente y tiempos de carga lentos durante las horas pico de uso. El arquitecto de soluciones necesita idear una estrategia para mejorar el rendimiento de la aplicación mientras optimiza costos.",
        "Question": "¿Cuál de las siguientes estrategias mejoraría el rendimiento de la plataforma de streaming de video durante las horas pico de uso?",
        "Options": {
            "1": "Aumentar los tipos de instancias de la flota de EC2 a tamaños más grandes y asignar direcciones IP elásticas adicionales para manejar más solicitudes de usuarios simultáneamente.",
            "2": "Migrar las tareas de procesamiento de video a un servicio administrado como AWS Lambda y usar S3 para almacenar archivos de video con acceso directo de los usuarios.",
            "3": "Implementar Auto Scaling para las instancias de EC2 basado en métricas de utilización de CPU y configurar una distribución de CloudFront para almacenar en caché el contenido de video más cerca de los usuarios.",
            "4": "Desplegar una única instancia de EC2 más grande para manejar todas las tareas de procesamiento de video y asegurar que la instancia tenga un volumen EBS adjunto con IOPS provisionados."
        },
        "Correct Answer": "Implementar Auto Scaling para las instancias de EC2 basado en métricas de utilización de CPU y configurar una distribución de CloudFront para almacenar en caché el contenido de video más cerca de los usuarios.",
        "Explanation": "Implementar Auto Scaling permite que la aplicación ajuste dinámicamente el número de instancias de EC2 según la demanda real, lo que ayuda a gestionar eficazmente los picos de tráfico. Además, usar CloudFront como una red de entrega de contenido (CDN) reduce la latencia al almacenar en caché el contenido de video más cerca de los usuarios, mejorando significativamente los tiempos de carga y reduciendo los problemas de almacenamiento en búfer.",
        "Other Options": [
            "Aumentar los tipos de instancias puede proporcionar más recursos, pero no aborda la escalabilidad necesaria durante las horas pico y podría llevar a costos más altos sin asegurar un rendimiento óptimo.",
            "Desplegar una única instancia de EC2 más grande crea un único punto de fallo y no escala eficazmente durante el uso pico. Esta opción tampoco utiliza los beneficios del balanceo de carga o la redundancia.",
            "Migrar a AWS Lambda puede no ser adecuado para tareas de procesamiento de video que requieren tiempos de ejecución más largos, ya que Lambda tiene un límite de tiempo de espera. Además, esta opción no aborda los problemas de rendimiento inmediatos relacionados con las solicitudes de los usuarios."
        ]
    },
    {
        "Question Number": "3",
        "Situation": "Una empresa gestiona una gran flota de instancias de Amazon EC2 que son parte de una infraestructura de aplicación dinámica. La infraestructura necesita ser mantenida de manera eficiente mientras se asegura el cumplimiento de las políticas de seguridad y las mejores prácticas operativas. La empresa está considerando implementar una solución de gestión de configuraciones para automatizar tareas operativas, como parches, monitoreo y gestión de inventarios.",
        "Question": "¿Cuál de los siguientes servicios de AWS cumpliría mejor con los requisitos de la empresa para la gestión de configuraciones en este escenario?",
        "Options": {
            "1": "Implementar AWS CloudFormation para gestionar la infraestructura como código y automatizar el despliegue de instancias de EC2.",
            "2": "Usar AWS Systems Manager para automatizar tareas operativas en las instancias de EC2 y asegurar el cumplimiento de las políticas de seguridad.",
            "3": "Aprovechar Amazon CloudWatch para monitorear el rendimiento de la aplicación y generar alertas basadas en métricas.",
            "4": "Utilizar AWS Config para rastrear configuraciones de recursos y asegurar el cumplimiento de las políticas de la empresa."
        },
        "Correct Answer": "Usar AWS Systems Manager para automatizar tareas operativas en las instancias de EC2 y asegurar el cumplimiento de las políticas de seguridad.",
        "Explanation": "AWS Systems Manager proporciona un conjunto completo de herramientas para la gestión de configuraciones, permitiendo la automatización de tareas operativas, gestión de parches y monitoreo de cumplimiento. Está diseñado específicamente para gestionar eficientemente grandes flotas de instancias.",
        "Other Options": [
            "AWS CloudFormation se centra en aprovisionar y gestionar recursos de AWS como código en lugar de automatizar tareas operativas continuas, lo que lo hace menos adecuado para las necesidades de la empresa en este contexto.",
            "AWS Config se utiliza principalmente para rastrear configuraciones de recursos y cumplimiento, pero no automatiza tareas operativas como parches o monitoreo, que son cruciales en este escenario.",
            "Amazon CloudWatch es principalmente un servicio de monitoreo que rastrea métricas y registros, pero no proporciona las capacidades de gestión de configuraciones requeridas para automatizar tareas operativas y asegurar el cumplimiento."
        ]
    },
    {
        "Question Number": "4",
        "Situation": "Una empresa de servicios financieros está analizando sus gastos en la nube en AWS. Tienen una mezcla de proyectos a corto plazo y operaciones a largo plazo. La empresa quiere optimizar costos mientras asegura que tiene la flexibilidad para adaptarse a las cambiantes necesidades del negocio. Están particularmente interesados en minimizar costos para sus cargas de trabajo en estado estable y están considerando varios modelos de precios.",
        "Question": "¿Qué modelo de precios debería recomendar el arquitecto de soluciones para optimizar costos para la empresa mientras mantiene flexibilidad para proyectos a corto plazo?",
        "Options": {
            "1": "Comprar Instancias Reservadas para todas las instancias de Amazon EC2 para garantizar la tarifa por hora más baja durante un período de uno o tres años.",
            "2": "Utilizar Planes de Ahorro que ofrecen flexibilidad entre diferentes familias de instancias y regiones mientras proporcionan ahorros significativos en comparación con los precios bajo demanda.",
            "3": "Usar Instancias Bajo Demanda exclusivamente para evitar cualquier compromiso a largo plazo y mantener la máxima flexibilidad.",
            "4": "Aprovechar Instancias Spot para todas las cargas de trabajo para lograr el precio más bajo posible sin ningún tipo de compromiso."
        },
        "Correct Answer": "Utilizar Planes de Ahorro que ofrecen flexibilidad entre diferentes familias de instancias y regiones mientras proporcionan ahorros significativos en comparación con los precios bajo demanda.",
        "Explanation": "Los Planes de Ahorro proporcionan un modelo de precios flexible que permite a la empresa optimizar costos al comprometerse a una cierta cantidad de uso durante un período de uno o tres años. Este modelo admite varios tipos de instancias y regiones, lo que lo hace ideal tanto para cargas de trabajo en estado estable como fluctuantes.",
        "Other Options": [
            "Comprar Instancias Reservadas garantizaría precios más bajos, pero a costa de flexibilidad, lo cual no es adecuado para una empresa con proyectos tanto a corto como a largo plazo.",
            "Usar Instancias Bajo Demanda exclusivamente puede proporcionar la máxima flexibilidad, pero no optimiza los costos de manera efectiva, lo que lleva a gastos más altos en comparación con los Planes de Ahorro.",
            "Aprovechar Instancias Spot ofrece los precios más bajos, pero introduce el riesgo de interrupciones, lo que lo hace inadecuado para cargas de trabajo en estado estable que requieren confiabilidad."
        ]
    },
    {
        "Question Number": "5",
        "Situation": "Una empresa de servicios financieros está planeando implementar una nueva solución de almacenamiento de datos para sus aplicaciones locales que requieren alta disponibilidad y acceso rápido a datos utilizados con frecuencia. La empresa está considerando usar AWS Storage Gateway y necesita elegir entre Volúmenes en Caché y Volúmenes Almacenados. Quieren asegurarse de tener acceso de baja latencia a su conjunto de datos completo mientras utilizan almacenamiento en la nube para copias de seguridad.",
        "Question": "¿Cuál de las siguientes configuraciones debería elegir la empresa para satisfacer mejor sus requisitos de acceso de baja latencia a todo el conjunto de datos mientras también aprovecha el almacenamiento en la nube para copias de seguridad?",
        "Options": {
            "1": "Desplegar el Gateway de Volumen en una configuración híbrida donde los datos se acceden directamente desde Amazon S3 sin almacenamiento local.",
            "2": "Usar una combinación de Volúmenes en Caché y Volúmenes Almacenados para permitir el almacenamiento local de datos de acceso frecuente y mantener copias de seguridad en Amazon S3.",
            "3": "Configurar el Gateway de Volumen para usar Volúmenes en Caché, donde los datos se almacenan en Amazon S3 y los datos de acceso frecuente se retienen localmente.",
            "4": "Configurar el Gateway de Volumen para usar Volúmenes Almacenados, permitiendo que todos los datos se almacenen localmente primero y se respalden de manera asíncrona en Amazon S3."
        },
        "Correct Answer": "Configurar el Gateway de Volumen para usar Volúmenes Almacenados, permitiendo que todos los datos se almacenen localmente primero y se respalden de manera asíncrona en Amazon S3.",
        "Explanation": "Los Volúmenes Almacenados proporcionan acceso de baja latencia a todo el conjunto de datos al almacenar todos los datos localmente, lo cual es crucial para aplicaciones que requieren un rendimiento rápido. Además, los datos pueden respaldarse de manera asíncrona en Amazon S3, cumpliendo con el requisito de copias de seguridad en la nube.",
        "Other Options": [
            "Los Volúmenes en Caché solo retienen datos de acceso frecuente localmente, lo que no cumple con el requisito de acceso de baja latencia a todo el conjunto de datos.",
            "Usar una combinación de Volúmenes en Caché y Volúmenes Almacenados es innecesario y podría complicar la arquitectura, ya que los Volúmenes Almacenados por sí solos cumplen con los requisitos de manera efectiva.",
            "Desplegar el Gateway de Volumen en una configuración híbrida sin almacenamiento local no proporciona acceso de baja latencia y no es adecuado para aplicaciones que necesitan disponibilidad inmediata de datos."
        ]
    },
    {
        "Question Number": "6",
        "Situation": "Una empresa de servicios financieros está buscando automatizar su gestión de configuración a través de múltiples cuentas y regiones de AWS para asegurar el cumplimiento y reducir errores manuales. Quieren una solución que se integre bien con los servicios existentes de AWS y que soporte tanto entornos de Linux como de Windows. La solución también debería proporcionar control de versiones y capacidades de auditoría.",
        "Question": "¿Qué servicio de AWS debería recomendar el arquitecto de soluciones para habilitar la automatización de la gestión de configuración?",
        "Options": {
            "1": "AWS CloudFormation con StackSets para gestión entre cuentas",
            "2": "AWS Config con AWS Systems Manager para verificaciones de cumplimiento",
            "3": "AWS OpsWorks con Chef para gestión de configuración",
            "4": "AWS Systems Manager con State Manager y características de Automatización"
        },
        "Correct Answer": "AWS Systems Manager con State Manager y características de Automatización",
        "Explanation": "AWS Systems Manager proporciona un conjunto completo de herramientas para la gestión de configuración, incluyendo el State Manager para hacer cumplir estados deseados y Automatización para ejecutar scripts en instancias. Este servicio soporta tanto entornos de Linux como de Windows y ofrece capacidades de control de versiones y auditoría, lo que lo hace ideal para las necesidades de la empresa.",
        "Other Options": [
            "AWS CloudFormation se utiliza principalmente para la provisión y gestión de infraestructura, no específicamente para la gestión y automatización de configuración continua, que es lo que se requiere en este caso.",
            "AWS Config se centra en el cumplimiento y monitoreo de recursos en lugar de la automatización de la gestión de configuración. Aunque puede trabajar con Systems Manager, no maneja el aspecto de automatización directamente.",
            "AWS OpsWorks es un servicio de gestión de configuración que utiliza Chef, pero está menos integrado con otros servicios de AWS en comparación con Systems Manager, lo que lo convierte en una opción menos óptima para este requisito específico."
        ]
    },
    {
        "Question Number": "7",
        "Situation": "Una empresa de servicios financieros está implementando una nueva aplicación de alta disponibilidad que requiere múltiples instancias de Amazon EC2 para acceder a datos compartidos simultáneamente. La aplicación está diseñada para manejar cargas de trabajo de alto I/O y utilizará Amazon EBS para almacenamiento. El arquitecto necesita asegurarse de que los volúmenes de EBS puedan ser compartidos entre múltiples instancias de EC2 para mejorar el tiempo de actividad y la disponibilidad de la aplicación.",
        "Question": "¿Cuál de las siguientes configuraciones debería implementar el Solutions Architect para cumplir con los requisitos de la aplicación? (Seleccione Dos)",
        "Options": {
            "1": "Adjuntar un solo volumen SSD de IOPS Provisionados a cada instancia de EC2 para minimizar problemas de latencia.",
            "2": "Usar Amazon EBS Multi-Attach para conectar un solo volumen SSD de IOPS Provisionados a múltiples instancias de EC2 dentro de la misma Zona de Disponibilidad.",
            "3": "Usar Amazon EBS Multi-Attach para conectar múltiples volúmenes HDD Optimizados para Rendimiento a una sola instancia de EC2.",
            "4": "Desplegar múltiples volúmenes estándar de Amazon EBS a cada instancia de EC2 y configurarlos para replicar datos entre instancias manualmente.",
            "5": "Implementar Amazon EFS para proporcionar un sistema de archivos compartido que pueda ser accedido por múltiples instancias de EC2 simultáneamente."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Usar Amazon EBS Multi-Attach para conectar un solo volumen SSD de IOPS Provisionados a múltiples instancias de EC2 dentro de la misma Zona de Disponibilidad.",
            "Implementar Amazon EFS para proporcionar un sistema de archivos compartido que pueda ser accedido por múltiples instancias de EC2 simultáneamente."
        ],
        "Explanation": "Usar Amazon EBS Multi-Attach permite que un solo volumen SSD de IOPS Provisionados sea adjuntado a múltiples instancias de EC2, proporcionando alta disponibilidad y rendimiento para cargas de trabajo que requieren acceso concurrente de lectura y escritura. Además, Amazon EFS ofrece una solución de almacenamiento de archivos escalable que puede ser accedida por múltiples instancias, lo que también es adecuado para aplicaciones de alta disponibilidad.",
        "Other Options": [
            "Desplegar múltiples volúmenes estándar de EBS y replicar datos manualmente es ineficiente y no proporciona la alta disponibilidad requerida ni la simplicidad para el acceso concurrente.",
            "Usar EBS Multi-Attach con múltiples volúmenes HDD Optimizados para Rendimiento adjuntos a una sola instancia de EC2 no cumple con el requisito de compartir un volumen entre múltiples instancias.",
            "Adjuntar un solo volumen SSD de IOPS Provisionados a cada instancia de EC2 no permite el acceso compartido y no mejora el tiempo de actividad o la disponibilidad entre instancias."
        ]
    },
    {
        "Question Number": "8",
        "Situation": "Una empresa de servicios financieros está planeando migrar sus aplicaciones locales a AWS. La empresa quiere evaluar su cartera de aplicaciones existente y rastrear el progreso de la migración a través de diferentes servicios de AWS. Necesita una herramienta centralizada para visualizar el estado de la migración y recibir recomendaciones para los servicios óptimos de AWS durante el proceso de migración.",
        "Question": "¿Cuál de las siguientes herramientas son adecuadas para la evaluación y seguimiento de la migración? (Seleccione Dos)",
        "Options": {
            "1": "AWS Cost Explorer",
            "2": "AWS CloudTrail",
            "3": "AWS Migration Hub",
            "4": "AWS Config",
            "5": "AWS Application Discovery Service"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "AWS Migration Hub",
            "AWS Application Discovery Service"
        ],
        "Explanation": "AWS Migration Hub proporciona un lugar central para rastrear el progreso de las migraciones de aplicaciones a través de AWS y entornos locales. Permite a los usuarios visualizar el estado de la migración y obtener información sobre dónde optimizar recursos. AWS Application Discovery Service ayuda a identificar dependencias de aplicaciones y utilización de recursos, lo cual es esencial para evaluar la cartera existente durante la migración.",
        "Other Options": [
            "AWS CloudTrail se utiliza principalmente para rastrear llamadas a la API y cambios en cuentas de AWS por razones de seguridad y cumplimiento, no específicamente para la evaluación o seguimiento de migraciones.",
            "AWS Cost Explorer se centra en analizar y gestionar los costos de AWS en lugar de ayudar en el proceso de migración o evaluar carteras de aplicaciones.",
            "AWS Config se utiliza principalmente para la gestión de configuración de recursos y monitoreo de cumplimiento en AWS, y no proporciona funcionalidades específicas de evaluación o seguimiento de migraciones."
        ]
    },
    {
        "Question Number": "9",
        "Situation": "Una firma de servicios financieros opera una aplicación crítica que procesa transacciones en tiempo real. La aplicación está alojada en AWS y está diseñada para mantener alta disponibilidad para sus usuarios. Sin embargo, la firma está preocupada por posibles interrupciones debido a desastres naturales u otros eventos catastróficos. Quieren implementar una estrategia de recuperación ante desastres que minimice el tiempo de inactividad y la pérdida de datos, asegurando al mismo tiempo el cumplimiento de los requisitos regulatorios. La firma tiene opciones para diferentes estrategias de recuperación ante desastres y busca orientación sobre el mejor enfoque.",
        "Question": "¿Qué estrategia de recuperación ante desastres debería implementar la firma para lograr un tiempo de inactividad y pérdida de datos mínimos para su aplicación crítica?",
        "Options": {
            "1": "Utilizar una estrategia de luz piloto, manteniendo una versión mínima de la aplicación en otra región que pueda escalarse rápidamente en caso de falla.",
            "2": "Adoptar una estrategia de múltiples sitios con configuración activa-activa, donde la aplicación se ejecute simultáneamente en múltiples regiones de AWS para garantizar alta disponibilidad.",
            "3": "Implementar una estrategia de espera cálida donde una versión reducida de la aplicación se ejecute en otra región de AWS, lista para asumir en caso de falla.",
            "4": "Usar AWS Elastic Disaster Recovery para replicar continuamente la aplicación y restaurarla rápidamente en un nuevo entorno en caso de un desastre."
        },
        "Correct Answer": "Usar AWS Elastic Disaster Recovery para replicar continuamente la aplicación y restaurarla rápidamente en un nuevo entorno en caso de un desastre.",
        "Explanation": "AWS Elastic Disaster Recovery proporciona una forma eficiente y automatizada de replicar continuamente sus aplicaciones, asegurando que pueda restaurarlas rápidamente en un nuevo entorno con un tiempo de inactividad y pérdida de datos mínimos. Este enfoque se alinea perfectamente con los requisitos de la firma para alta disponibilidad y cumplimiento.",
        "Other Options": [
            "Implementar una estrategia de espera cálida implica mantener una versión reducida de la aplicación. Si bien puede proporcionar un tiempo de recuperación reducido, puede no cumplir completamente con el requisito de tiempo de inactividad y pérdida de datos mínimos en comparación con la replicación continua.",
            "Una estrategia de múltiples sitios con configuración activa-activa puede ser compleja y costosa, ya que requiere ejecutar instancias a gran escala en múltiples regiones. Si bien proporciona alta disponibilidad, puede no ser la solución más eficiente para todos los escenarios, especialmente para una firma que busca minimizar costos.",
            "Utilizar una estrategia de luz piloto implica mantener una versión mínima de la aplicación que puede escalarse. Esta estrategia puede llevar a tiempos de recuperación más largos, lo que puede no alinearse con la necesidad de la firma de minimizar el tiempo de inactividad en situaciones críticas."
        ]
    },
    {
        "Question Number": "10",
        "Situation": "Una empresa de servicios financieros está experimentando un crecimiento rápido y necesita asegurarse de que su aplicación web pueda manejar cargas de tráfico variables mientras minimiza costos. La aplicación se ejecuta en instancias de Amazon EC2 y debe mantener alta disponibilidad y rendimiento. El Arquitecto de Soluciones debe diseñar una arquitectura que permita la escalabilidad dinámica basada en patrones de tráfico y utilice de manera óptima los recursos a través de múltiples zonas de disponibilidad.",
        "Question": "¿Cuál de las siguientes acciones debería implementar el Arquitecto de Soluciones para cumplir con los requisitos de la empresa? (Seleccione Dos)",
        "Options": {
            "1": "Utilizar grupos de colocación para asegurar que todas las instancias de EC2 se encuentren en la misma zona de disponibilidad para baja latencia.",
            "2": "Usar instancias Spot de Amazon EC2 para reducir costos mientras se asegura que haya suficiente capacidad disponible durante los picos de demanda.",
            "3": "Desplegar la aplicación a través de múltiples tipos de instancias de EC2 dentro de un grupo de Auto Scaling para optimizar rendimiento y costo.",
            "4": "Implementar Amazon EC2 Auto Scaling con una política de escalado de seguimiento de objetivos basada en la utilización promedio de CPU.",
            "5": "Configurar un Amazon Elastic Load Balancer (ELB) con sesiones persistentes para mantener la información de sesión de los usuarios."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Implementar Amazon EC2 Auto Scaling con una política de escalado de seguimiento de objetivos basada en la utilización promedio de CPU.",
            "Usar instancias Spot de Amazon EC2 para reducir costos mientras se asegura que haya suficiente capacidad disponible durante los picos de demanda."
        ],
        "Explanation": "Implementar Amazon EC2 Auto Scaling con una política de escalado de seguimiento de objetivos permite que la aplicación ajuste dinámicamente la capacidad según la carga actual, asegurando alta disponibilidad y rendimiento. Usar instancias Spot de EC2 ayuda a optimizar costos al utilizar la capacidad excedente en la nube de AWS, lo cual es una excelente manera de gestionar gastos sin sacrificar rendimiento.",
        "Other Options": [
            "Usar un ELB con sesiones persistentes puede llevar a una distribución desigual del tráfico y no es ideal para arquitecturas escalables, especialmente bajo cargas variables, ya que puede causar que algunas instancias se sobrecarguen mientras que otras permanezcan subutilizadas.",
            "Desplegar a través de múltiples tipos de instancias es una buena práctica para optimizar la utilización de recursos, pero no aborda directamente los requisitos de escalado tan efectivamente como usar Auto Scaling con seguimiento de objetivos.",
            "Utilizar grupos de colocación puede mejorar el rendimiento de la red al asegurar baja latencia entre instancias, pero no proporciona inherentemente escalabilidad dinámica ni optimización de costos, que son críticos para gestionar cargas variables."
        ]
    },
    {
        "Question Number": "11",
        "Situation": "Su organización está gestionando múltiples cuentas de AWS para facilitar diferentes equipos y proyectos. Sin embargo, hay preocupaciones respecto a la gobernanza, gestión de costos y seguridad a través de estas cuentas. La dirección está buscando una manera de implementar un modelo de gobernanza que asegure cumplimiento, facturación centralizada y gestión de acceso efectiva para todas las cuentas. (Seleccione Dos)",
        "Question": "¿Cuál de las siguientes acciones ayudará a establecer un robusto modelo de gobernanza multi-cuenta en AWS?",
        "Options": {
            "1": "Gestionar manualmente la facturación de cada cuenta para mantener visibilidad de los gastos.",
            "2": "Usar un proveedor de identidad externo para la gestión de acceso federado entre cuentas.",
            "3": "Implementar AWS Organizations para gestionar cuentas de manera centralizada y aplicar políticas de control de servicio.",
            "4": "Habilitar AWS CloudTrail en todas las cuentas para el registro centralizado de la actividad de API.",
            "5": "Crear una cuenta de AWS separada para cada equipo y permitir acceso sin restricciones a todos los servicios de AWS."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Implementar AWS Organizations para gestionar cuentas de manera centralizada y aplicar políticas de control de servicio.",
            "Habilitar AWS CloudTrail en todas las cuentas para el registro centralizado de la actividad de API."
        ],
        "Explanation": "Implementar AWS Organizations le permite gestionar múltiples cuentas de manera centralizada y aplicar políticas de control de servicio para hacer cumplir la gobernanza en todas las cuentas. Habilitar AWS CloudTrail asegura que tenga un registro centralizado de la actividad de API, lo cual es crucial para el cumplimiento y la auditoría.",
        "Other Options": [
            "Crear una cuenta de AWS separada para cada equipo con acceso sin restricciones presenta riesgos de seguridad significativos y no hace cumplir ningún modelo de gobernanza.",
            "Usar un proveedor de identidad externo para la gestión de acceso federado puede ser beneficioso, pero no es un modelo de gobernanza independiente y carece del control más amplio que proporciona AWS Organizations.",
            "Gestionar manualmente la facturación de cada cuenta es ineficiente y no proporciona la vista centralizada de costos que AWS Organizations puede ofrecer."
        ]
    },
    {
        "Question Number": "12",
        "Situation": "Una aplicación de salud procesa datos de pacientes y se comunica con varios servicios de terceros para análisis e informes. Actualmente, todos los servicios están fuertemente acoplados, lo que causa problemas de latencia y dificulta la implementación de cambios. El Arquitecto de Soluciones necesita identificar oportunidades para desacoplar los componentes de la aplicación para mejorar el rendimiento y la mantenibilidad.",
        "Question": "¿Cuál de las siguientes soluciones desacoplaría mejor los componentes de la aplicación mientras mejora el rendimiento y la mantenibilidad?",
        "Options": {
            "1": "Migrar la aplicación a Amazon ECS, asegurando que cada servicio se comunique directamente con los otros utilizando llamadas HTTP para mantener un acoplamiento fuerte.",
            "2": "Refactorizar la aplicación para que se ejecute completamente en AWS Lambda, utilizando llamadas sincrónicas a todos los servicios de terceros para el procesamiento de datos en tiempo real.",
            "3": "Implementar Amazon SQS para encolar solicitudes entre la aplicación y los servicios de terceros, permitiendo que procesen mensajes de manera independiente.",
            "4": "Usar Amazon API Gateway para crear APIs RESTful para cada componente, permitiendo escalado y comunicación independientes entre los servicios."
        },
        "Correct Answer": "Usar Amazon API Gateway para crear APIs RESTful para cada componente, permitiendo escalado y comunicación independientes entre los servicios.",
        "Explanation": "Usar Amazon API Gateway para crear APIs RESTful permite que cada componente se comunique de manera independiente y escale según sea necesario. Este enfoque desacopla efectivamente los servicios, permitiendo actualizaciones y mantenimiento más fáciles sin afectar a toda la aplicación.",
        "Other Options": [
            "Implementar Amazon SQS es una buena práctica para desacoplar, pero puede no aprovechar completamente las capacidades de escalado independiente y gestión de API tan efectivamente como lo hace API Gateway.",
            "Refactorizar la aplicación para que se ejecute completamente en AWS Lambda con llamadas sincrónicas introduce un riesgo de latencia y acoplamiento fuerte, contradiciendo el objetivo de desacoplar los componentes.",
            "Migrar la aplicación a Amazon ECS y usar llamadas HTTP entre servicios mantiene un acoplamiento fuerte y no aborda la necesidad de escalado independiente o mejor mantenibilidad."
        ]
    },
    {
        "Question Number": "13",
        "Situation": "Una empresa necesita migrar sus cargas de trabajo de transferencia de archivos existentes a AWS utilizando el Protocolo de Transferencia de Archivos Secure Shell (SFTP). Quieren asegurarse de que los usuarios puedan seguir utilizando sus clientes SFTP existentes sin ningún cambio. Además, la empresa desea autenticar a los usuarios utilizando una combinación de identidades gestionadas por el servicio y su proveedor de identidad corporativa. Los archivos transferidos deben almacenarse en un bucket de Amazon S3. El arquitecto de soluciones tiene la tarea de implementar una solución que cumpla con estos requisitos mientras minimiza la sobrecarga operativa.",
        "Question": "¿Cuál de las siguientes soluciones debería implementar el arquitecto de soluciones para satisfacer los requisitos de la empresa?",
        "Options": {
            "1": "Desplegar una instancia de EC2 que ejecute una aplicación de servidor SFTP y configurarla para usar roles de IAM para la autenticación. Configurar un script para transferir archivos a un bucket de Amazon S3 después de cada carga.",
            "2": "Crear un servidor SFTP de AWS Transfer Family y configurarlo para usar identidades gestionadas por el servicio para la autenticación. Mapear el dominio al punto final del servidor y seleccionar el bucket de Amazon S3 apropiado para el almacenamiento.",
            "3": "Implementar un servidor SFTP de AWS Transfer Family con un proveedor de identidad personalizado para la autenticación de usuarios. Configurar el servidor para transferir archivos directamente a un sistema de archivos Amazon EFS para almacenamiento.",
            "4": "Configurar una función Lambda para manejar solicitudes SFTP y autenticar a los usuarios utilizando el SDK de AWS. Almacenar los archivos transferidos en una base de datos Amazon RDS."
        },
        "Correct Answer": "Crear un servidor SFTP de AWS Transfer Family y configurarlo para usar identidades gestionadas por el servicio para la autenticación. Mapear el dominio al punto final del servidor y seleccionar el bucket de Amazon S3 apropiado para el almacenamiento.",
        "Explanation": "Usar AWS Transfer Family permite una integración fluida de las cargas de trabajo SFTP con una sobrecarga de gestión mínima. Soporta identidades gestionadas por el servicio para la autenticación e integra directamente con Amazon S3 para el almacenamiento de archivos, cumpliendo con todos los requisitos de la empresa.",
        "Other Options": [
            "Desplegar una instancia de EC2 para SFTP introduce una complejidad adicional de gestión y no aprovecha las características integradas de AWS Transfer Family para cargas de trabajo SFTP.",
            "Usar un proveedor de identidad personalizado con AWS Transfer Family es innecesario ya que las identidades gestionadas por el servicio son suficientes para las necesidades de la empresa, y transferir archivos a un sistema de archivos EFS no se alinea con su requisito de usar S3.",
            "Implementar una función Lambda para manejar SFTP es excesivamente complejo y no es adecuado para transferencias de archivos de alta frecuencia. Además, RDS no es apropiado para el almacenamiento de archivos, ya que está diseñado para datos estructurados."
        ]
    },
    {
        "Question Number": "14",
        "Situation": "Una organización de salud necesita gestionar de manera segura el acceso y los permisos de los usuarios para sus empleados que requieren diferentes niveles de acceso a los datos de pacientes almacenados en AWS. La organización quiere asegurarse de que el control de acceso se gestione de manera centralizada y pueda integrarse fácilmente con el Active Directory de Microsoft existente en las instalaciones. El arquitecto de soluciones debe implementar una solución que permita tanto la autenticación federada como el control de acceso granular. (Seleccione Dos)",
        "Question": "¿Cuál de los siguientes servicios debería implementar el arquitecto de soluciones para cumplir con los requisitos?",
        "Options": {
            "1": "Implementar AWS Directory Service para conectar el Active Directory local con los recursos de AWS.",
            "2": "Aprovechar AWS Single Sign-On para un acceso sin problemas a múltiples cuentas y aplicaciones de AWS.",
            "3": "Configurar AWS Secrets Manager para almacenar y gestionar de forma segura las claves de acceso para las aplicaciones.",
            "4": "Usar AWS IAM Identity Center para gestionar el acceso y los permisos de los usuarios a través de las cuentas de AWS.",
            "5": "Utilizar Amazon Cognito para gestionar identidades de usuario y sincronizar datos de usuario entre dispositivos."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Usar AWS IAM Identity Center para gestionar el acceso y los permisos de los usuarios a través de las cuentas de AWS.",
            "Implementar AWS Directory Service para conectar el Active Directory local con los recursos de AWS."
        ],
        "Explanation": "AWS IAM Identity Center simplifica la gestión del acceso de los usuarios y proporciona una forma centralizada de gestionar los permisos para los usuarios a través de múltiples cuentas de AWS. AWS Directory Service permite la integración con el Active Directory local, habilitando la autenticación federada y un mejor control de acceso para los usuarios que necesitan acceso a los recursos de AWS.",
        "Other Options": [
            "Amazon Cognito se utiliza principalmente para gestionar identidades de usuario para aplicaciones web y móviles, lo cual no es la principal preocupación en este escenario donde se requiere acceso federado a los recursos de AWS.",
            "AWS Secrets Manager está diseñado para gestionar secretos como claves API y contraseñas, pero no proporciona gestión de acceso de usuarios ni control de permisos.",
            "AWS Single Sign-On simplifica el acceso a múltiples cuentas de AWS, pero no aborda directamente la integración con el Active Directory existente en las instalaciones, que es crucial para este escenario."
        ]
    },
    {
        "Question Number": "15",
        "Situation": "Un equipo de TI está buscando automatizar el despliegue de su aplicación a una flota de instancias de Amazon EC2 utilizando AWS CodeDeploy. Quieren asegurarse de que el proceso de despliegue esté controlado y que puedan revertir fácilmente a una versión anterior si es necesario.",
        "Question": "¿Qué configuración de despliegue debería usar el equipo de TI para asegurarse de que implementen gradualmente la nueva versión al 20% de las instancias cada 5 minutos hasta que todas las instancias hayan sido actualizadas?",
        "Options": {
            "1": "CodeDeployDefault.ECSCanary10Percent5Minutes",
            "2": "CodeDeployDefault.OneAtATime",
            "3": "CodeDeployDefault.AllAtOnce",
            "4": "CodeDeployDefault.HalfAtATime"
        },
        "Correct Answer": "CodeDeployDefault.ECSCanary10Percent5Minutes",
        "Explanation": "La configuración ECSCanary10Percent5Minutes permite que el despliegue avance de manera canaria, donde el 10% de las instancias se actualizan cada 5 minutos. Esta configuración permite un despliegue gradual mientras se monitorea la salud de la aplicación antes de implementarla en todas las instancias.",
        "Other Options": [
            "HalfAtATime actualizaría la mitad de las instancias a la vez, lo que no cumple con el requisito de un despliegue gradual del 20%.",
            "AllAtOnce desplegaría la nueva versión a todas las instancias simultáneamente, lo que no permite un despliegue controlado y monitoreo.",
            "OneAtATime actualizaría una instancia a la vez, lo que no es eficiente para el requisito de desplegar rápidamente al 20% de las instancias."
        ]
    },
    {
        "Question Number": "16",
        "Situation": "Una empresa está implementando instancias de EC2 dentro de una Nube Privada Virtual (VPC) y necesita asegurarse de que las instancias con direcciones IP públicas puedan resolver nombres de host DNS públicos. La configuración de la VPC requiere ajustes específicos para habilitar esta función.",
        "Question": "¿Qué dos configuraciones deben establecerse para garantizar que las instancias de EC2 en una VPC puedan resolver nombres de host DNS públicos? (Seleccione Dos)",
        "Options": {
            "1": "Establecer enableDnsSupport en true.",
            "2": "Establecer enableDnsHostnames en false.",
            "3": "Establecer enableDnsSupport en false.",
            "4": "Establecer enableDnsSupport en true para direcciones IP privadas.",
            "5": "Establecer enableDnsHostnames en true."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Establecer enableDnsSupport en true.",
            "Establecer enableDnsHostnames en true."
        ],
        "Explanation": "Para que las instancias de EC2 en una VPC resuelvan nombres de host DNS públicos, ambos atributos, enableDnsSupport y enableDnsHostnames, deben establecerse en true. enableDnsSupport permite que las instancias utilicen el servidor DNS proporcionado por Amazon, y enableDnsHostnames asegura que las instancias con direcciones IP públicas reciban nombres DNS públicos correspondientes.",
        "Other Options": [
            "Establecer enableDnsHostnames en false impediría que las instancias recibieran nombres de host DNS públicos, lo cual es necesario para la resolución.",
            "Establecer enableDnsSupport en false desactivaría el servidor DNS proporcionado por Amazon, impidiendo cualquier resolución DNS, incluidos los nombres de host públicos.",
            "Establecer enableDnsSupport en true para direcciones IP privadas no aborda el requisito de resolver nombres de host DNS públicos, ya que no impacta la resolución de direcciones IP públicas."
        ]
    },
    {
        "Question Number": "17",
        "Situation": "Una organización de atención médica está migrando sus datos de pacientes a AWS. Dada la naturaleza sensible de esta información, la organización debe cumplir con las regulaciones de HIPAA y asegurarse de que los datos se conserven durante un mínimo de seis años. La organización está evaluando sus opciones para almacenar, gestionar y proteger estos datos de acuerdo con los requisitos regulatorios.",
        "Question": "¿Qué servicio o característica de AWS debería utilizar la organización para garantizar el cumplimiento de los requisitos de retención y sensibilidad de datos mientras simplifica la gestión de sus datos sensibles de pacientes?",
        "Options": {
            "1": "Implementar Amazon RDS con copias de seguridad automatizadas y instantáneas para almacenar datos de pacientes, asegurando que se conserven durante el tiempo necesario.",
            "2": "Utilizar AWS Backup para gestionar políticas de respaldo para todos los recursos de AWS, incluyendo la aplicación de períodos de retención para los datos de pacientes.",
            "3": "Usar Amazon S3 con Object Lock para hacer cumplir las políticas de retención y prevenir la eliminación de datos de pacientes durante el período requerido.",
            "4": "Almacenar datos de pacientes en Amazon DynamoDB con Time to Live (TTL) habilitado para eliminar automáticamente registros después de seis años."
        },
        "Correct Answer": "Usar Amazon S3 con Object Lock para hacer cumplir las políticas de retención y prevenir la eliminación de datos de pacientes durante el período requerido.",
        "Explanation": "Amazon S3 con Object Lock está diseñado específicamente para cumplir con los requisitos de retención de datos al prevenir la eliminación de objetos durante un período de tiempo especificado, lo que lo hace adecuado para el cumplimiento de las regulaciones de HIPAA. Permite a la organización de atención médica asegurarse de que los datos de pacientes no se eliminen antes de que finalice el período de retención obligatorio.",
        "Other Options": [
            "Implementar Amazon RDS con copias de seguridad automatizadas e instantáneas es una buena práctica para la gestión de bases de datos, pero no proporciona el mismo nivel de aplicación de retención que Object Lock en S3, lo que podría llevar a riesgos de cumplimiento.",
            "Almacenar datos de pacientes en Amazon DynamoDB con TTL habilitado permite la eliminación automática, lo que contradice el requisito de conservar datos sensibles durante un mínimo de seis años.",
            "Utilizar AWS Backup es beneficioso para gestionar copias de seguridad en los servicios de AWS, pero no aplica inherentemente políticas de retención de la misma manera que S3 Object Lock, lo cual es crucial para el cumplimiento de las regulaciones de sensibilidad de datos."
        ]
    },
    {
        "Question Number": "18",
        "Situation": "Una empresa de servicios financieros necesita analizar su gasto mensual en AWS para identificar áreas de optimización de costos. La empresa utiliza varios servicios de AWS, incluyendo EC2, S3 y RDS, y tiene una estructura de facturación compleja. Quieren profundizar en sus Informes de Costos y Uso de AWS (CUR) para comprender mejor sus patrones de uso, identificar anomalías y asignar costos con precisión a diferentes departamentos. El equipo no está seguro de cómo utilizar eficazmente el CUR para lograr estos objetivos.",
        "Question": "¿Cuál de los siguientes enfoques es la mejor manera para que la empresa investigue sus Informes de Costos y Uso de AWS a un nivel granular?",
        "Options": {
            "1": "Utilizar AWS Cost Explorer para visualizar tendencias de uso y filtrar por servicio, cuenta vinculada y etiquetas para identificar impulsores de costos específicos y anomalías.",
            "2": "Configurar una función Lambda programada que procese el Informe de Costos y Uso diariamente para generar archivos CSV para cada departamento, lo que facilita el seguimiento de costos.",
            "3": "Descargar el Informe de Costos y Uso a un bucket de S3 y analizar los datos utilizando Amazon Athena para consultas ad-hoc y asignación de costos entre diferentes departamentos.",
            "4": "Usar AWS Budgets para crear alertas basadas en umbrales de uso de servicios específicos, permitiendo al equipo reaccionar a cambios en los costos antes de que se vuelvan significativos."
        },
        "Correct Answer": "Descargar el Informe de Costos y Uso a un bucket de S3 y analizar los datos utilizando Amazon Athena para consultas ad-hoc y asignación de costos entre diferentes departamentos.",
        "Explanation": "Descargar el Informe de Costos y Uso a un bucket de S3 y usar Amazon Athena proporciona la capacidad de realizar análisis detallados y consultas ad-hoc sobre los datos, permitiendo una comprensión más granular de los costos y patrones de uso. Este método permite a la empresa investigar de manera eficiente áreas específicas de interés y asignar costos con precisión entre departamentos.",
        "Other Options": [
            "Si bien AWS Cost Explorer es útil para visualizar tendencias y comprender patrones de uso a alto nivel, carece de las capacidades de consulta detallada de Athena para un análisis profundo de los Informes de Costos y Uso.",
            "Configurar una función Lambda programada para generar archivos CSV puede ser útil, pero puede no proporcionar el mismo nivel de detalle y flexibilidad para el análisis que consultar los datos en bruto en Athena.",
            "AWS Budgets es efectivo para monitorear el gasto en relación con los umbrales, pero no proporciona las perspectivas detalladas que la empresa necesita para profundizar en la asignación de costos y patrones de uso."
        ]
    },
    {
        "Question Number": "19",
        "Situation": "Una empresa de servicios financieros está implementando una aplicación web en una VPC en AWS. La aplicación requiere un control estricto sobre el tráfico entrante y saliente para cumplir con los estándares regulatorios. El arquitecto de soluciones necesita implementar medidas de seguridad para definir los flujos de tráfico permitidos, asegurándose de que el tráfico legítimo no sea bloqueado. El arquitecto debe utilizar tanto grupos de seguridad como ACLs de red de manera efectiva para gestionar estos flujos. (Selecciona Dos)",
        "Question": "¿Qué acciones debe tomar el arquitecto de soluciones para cumplir con los requisitos?",
        "Options": {
            "1": "Configurar una ACL de red para denegar todo el tráfico entrante excepto para conexiones establecidas.",
            "2": "Implementar una regla de ACL de red para permitir tráfico entrante desde un bloque CIDR específico.",
            "3": "Configurar un grupo de seguridad para permitir todo el tráfico saliente a cualquier destino.",
            "4": "Crear un grupo de seguridad que permita tráfico HTTP y HTTPS desde direcciones IP específicas.",
            "5": "Habilitar registros de flujo en las ACLs de red para monitorear todo el tráfico y analizar patrones."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Crear un grupo de seguridad que permita tráfico HTTP y HTTPS desde direcciones IP específicas.",
            "Implementar una regla de ACL de red para permitir tráfico entrante desde un bloque CIDR específico."
        ],
        "Explanation": "Las respuestas correctas implican utilizar grupos de seguridad para permitir tráfico específico de HTTP y HTTPS desde direcciones IP de confianza, asegurando que solo se procesen solicitudes legítimas. Además, implementar una regla de ACL de red para permitir tráfico entrante desde un bloque CIDR específico complementa esto al proporcionar control sobre flujos de tráfico más amplios mientras se mantiene el cumplimiento de seguridad.",
        "Other Options": [
            "Configurar una ACL de red para denegar todo el tráfico entrante excepto para conexiones establecidas es demasiado restrictivo y puede bloquear tráfico legítimo que no forma parte de una conexión establecida.",
            "Habilitar registros de flujo en las ACLs de red para monitorear todo el tráfico y analizar patrones no controla directamente los flujos de tráfico y es más una solución de monitoreo que una medida de seguridad.",
            "Configurar un grupo de seguridad para permitir todo el tráfico saliente a cualquier destino no es una buena práctica de seguridad y podría exponer la aplicación a riesgos innecesarios."
        ]
    },
    {
        "Question Number": "20",
        "Situation": "Una empresa de servicios financieros está migrando sus aplicaciones a AWS y necesita asegurar una trazabilidad integral de las acciones de los usuarios y las interacciones de los servicios a través de su infraestructura en la nube. Quiere implementar una solución que les permita rastrear y analizar actividades con fines de seguridad y cumplimiento. La empresa está utilizando múltiples servicios de AWS, incluidos Amazon S3, Amazon RDS y AWS Lambda, y requiere un mecanismo de registro centralizado que capture todos los eventos relevantes.",
        "Question": "¿Cuál de las siguientes soluciones proporciona el mejor enfoque para lograr una trazabilidad integral de usuarios y servicios en el entorno de AWS?",
        "Options": {
            "1": "Habilitar AWS CloudTrail en todas las cuentas y regiones para capturar llamadas a la API y actividades de los usuarios para todos los servicios de AWS, y configurar Amazon CloudWatch Logs para monitorear y analizar los registros.",
            "2": "Implementar Amazon CloudWatch Events para capturar eventos de los servicios de AWS y usar AWS Lambda para procesar estos eventos, pero no habilitar AWS CloudTrail para el seguimiento de llamadas a la API.",
            "3": "Implementar Amazon GuardDuty para monitorear continuamente actividades maliciosas y comportamientos no autorizados, confiando únicamente en él para el registro de eventos de seguridad en el entorno de AWS.",
            "4": "Usar AWS Config para rastrear cambios de configuración en los recursos de AWS y configurar notificaciones de SNS para cambios específicos, sin una solución de registro centralizada para las acciones de los usuarios."
        },
        "Correct Answer": "Habilitar AWS CloudTrail en todas las cuentas y regiones para capturar llamadas a la API y actividades de los usuarios para todos los servicios de AWS, y configurar Amazon CloudWatch Logs para monitorear y analizar los registros.",
        "Explanation": "Habilitar AWS CloudTrail proporciona una vista integral de todas las llamadas a la API realizadas por usuarios y servicios, lo cual es esencial para la trazabilidad. Junto con Amazon CloudWatch Logs, permite el monitoreo y análisis en tiempo real de los registros, asegurando el cumplimiento y la seguridad.",
        "Other Options": [
            "Implementar Amazon GuardDuty por sí solo no proporciona una trazabilidad integral de todas las acciones de los usuarios y las interacciones de los servicios, ya que se centra principalmente en la detección de amenazas y puede omitir el registro detallado de las actividades de los usuarios.",
            "Usar AWS Config está limitado a rastrear cambios de configuración y no captura acciones de los usuarios o llamadas a la API, que son críticas para la trazabilidad integral y el cumplimiento.",
            "Implementar Amazon CloudWatch Events sin habilitar AWS CloudTrail limita la capacidad de rastrear llamadas a la API y actividades de los usuarios, haciéndolo insuficiente para una trazabilidad integral de las acciones en el entorno de AWS."
        ]
    },
    {
        "Question Number": "21",
        "Situation": "Una empresa de medios está utilizando Amazon S3 para almacenar su contenido de video, al que acceden usuarios de todo el mundo. Quieren asegurarse de que solo los usuarios autorizados puedan acceder a los videos mientras mantienen las URL intactas para facilitar su uso. Además, necesitan proporcionar acceso seguro a múltiples videos sin generar URL individuales para cada uno. El arquitecto de soluciones debe diseñar una solución que cumpla con estos requisitos.",
        "Question": "¿Cuál es el mejor enfoque para que el arquitecto de soluciones implemente la firma de URL para el contenido de video de la empresa de medios?",
        "Options": {
            "1": "Configurar políticas de bucket de S3 para permitir acceso público a los videos pero restringir el acceso según direcciones IP.",
            "2": "Crear un sistema de autenticación personalizado que genere URL únicas para cada solicitud de video, permitiendo el acceso solo a usuarios autenticados.",
            "3": "Configurar CloudFront para usar URL firmadas y cookies firmadas, permitiendo a los usuarios acceder a múltiples videos con una sola cookie firmada mientras se mantiene el control sobre el acceso.",
            "4": "Usar AWS Lambda para generar URL pre-firmadas para cada video y enviarlas a los usuarios, asegurando que tengan una vida útil limitada."
        },
        "Correct Answer": "Configurar CloudFront para usar URL firmadas y cookies firmadas, permitiendo a los usuarios acceder a múltiples videos con una sola cookie firmada mientras se mantiene el control sobre el acceso.",
        "Explanation": "Usar URL firmadas y cookies firmadas de CloudFront permite a la empresa de medios controlar el acceso a múltiples archivos de video de manera eficiente sin cambiar las URL, proporcionando una experiencia más amigable para el usuario mientras se asegura la seguridad.",
        "Other Options": [
            "Usar AWS Lambda para generar URL pre-firmadas para cada video puede llevar a un número excesivo de URL generadas, complicando el acceso para los usuarios que necesitan ver múltiples videos.",
            "Configurar políticas de bucket de S3 para acceso público basado en direcciones IP podría exponer el contenido a usuarios no autorizados si el rango de IP no se controla estrictamente.",
            "Crear un sistema de autenticación personalizado agrega complejidad innecesaria y carga de gestión, haciéndolo menos eficiente que usar las características existentes de CloudFront."
        ]
    },
    {
        "Question Number": "22",
        "Situation": "Una empresa minorista está recopilando datos de ventas en tiempo real desde sus sistemas de punto de venta (POS) ubicados en tiendas de todo el país. Quieren analizar estos datos para obtener información sobre los comportamientos y tendencias de compra de los clientes. Para lograr esto, están considerando utilizar un servicio que pueda cargar datos en streaming de manera confiable en su lago de datos para un análisis posterior.",
        "Question": "¿Qué servicio de AWS debería recomendar el arquitecto de soluciones para capturar y cargar datos en streaming en Amazon S3 con una gestión mínima?",
        "Options": {
            "1": "Amazon Kinesis Data Firehose",
            "2": "Amazon SQS",
            "3": "AWS Lambda",
            "4": "Amazon Kinesis Data Streams"
        },
        "Correct Answer": "Amazon Kinesis Data Firehose",
        "Explanation": "Amazon Kinesis Data Firehose está diseñado específicamente para cargar datos en streaming en servicios como Amazon S3 sin necesidad de gestión continua, lo que lo hace ideal para este caso de uso. Puede manejar la transformación de datos y la carga directamente en el lago de datos, proporcionando capacidades de análisis en tiempo real.",
        "Other Options": [
            "Amazon Kinesis Data Streams requiere más gestión y configuración, ya que está diseñado para proporcionar capacidades de procesamiento en tiempo real, lo que requiere el uso de clientes de Kinesis para leer y procesar los datos.",
            "AWS Lambda es un servicio de computación sin servidor que se puede utilizar para procesar datos, pero no está diseñado específicamente para cargar datos en streaming en un lago de datos, lo que lo hace menos adecuado para este escenario.",
            "Amazon SQS es un servicio de colas de mensajes que permite a microservicios desacoplados comunicarse, pero no proporciona las capacidades para cargar datos en streaming directamente en lagos de datos u otros servicios de análisis."
        ]
    },
    {
        "Question Number": "23",
        "Situation": "Una empresa de servicios financieros está implementando un pipeline de CI/CD para su arquitectura de microservicios alojada en AWS. Requieren una estrategia de despliegue que minimice el tiempo de inactividad y permita una rápida reversión en caso de fallos. La aplicación debe soportar pruebas automatizadas e integración con herramientas de monitoreo existentes. La empresa está particularmente preocupada por asegurar una experiencia de usuario fluida durante los despliegues.",
        "Question": "¿Qué estrategia de despliegue debería recomendar el arquitecto de soluciones para cumplir con los requisitos de la empresa de minimizar el tiempo de inactividad y permitir rápidas reversiónes?",
        "Options": {
            "1": "Utilizar una estrategia de despliegue en rolling con AWS CodeDeploy. Actualizar instancias en lotes mientras se mantiene una parte de la versión anterior en funcionamiento. Esto permite una transición gradual, pero puede complicar los procesos de reversión.",
            "2": "Implementar una estrategia de despliegue blue/green utilizando AWS Elastic Beanstalk. Crear dos entornos idénticos, uno para la versión actual y otro para la nueva versión. Dirigir el tráfico al nuevo entorno tras pruebas exitosas, y cambiar fácilmente de vuelta si surgen problemas.",
            "3": "Utilizar una estrategia de despliegue all-at-once con AWS CodeDeploy. Desplegar la nueva versión a todas las instancias simultáneamente y monitorear problemas. Revertir si es necesario, pero esperar un posible tiempo de inactividad durante el despliegue.",
            "4": "Adoptar una estrategia de despliegue canary con AWS Lambda. Desplegar la nueva versión a un pequeño subconjunto de usuarios inicialmente y monitorear las respuestas antes de implementarla a toda la base de usuarios."
        },
        "Correct Answer": "Implementar una estrategia de despliegue blue/green utilizando AWS Elastic Beanstalk. Crear dos entornos idénticos, uno para la versión actual y otro para la nueva versión. Dirigir el tráfico al nuevo entorno tras pruebas exitosas, y cambiar fácilmente de vuelta si surgen problemas.",
        "Explanation": "Una estrategia de despliegue blue/green permite un cambio fluido entre versiones de la aplicación, minimizando el tiempo de inactividad y proporcionando un mecanismo de reversión fácil si ocurren problemas después del despliegue. Este enfoque asegura que la experiencia del usuario permanezca ininterrumpida durante las actualizaciones.",
        "Other Options": [
            "Una estrategia de despliegue all-at-once puede llevar a un tiempo de inactividad significativo ya que todas las instancias se actualizan simultáneamente. Si bien la reversión es posible, el potencial de interrupción para el usuario hace que este enfoque sea menos adecuado para las necesidades de la empresa.",
            "Una estrategia de despliegue en rolling actualiza instancias en lotes, lo que puede ayudar a reducir el tiempo de inactividad. Sin embargo, complica los procesos de reversión ya que algunos usuarios pueden seguir en la versión anterior mientras que otros están en la nueva versión, lo que lleva a un comportamiento inconsistente.",
            "Una estrategia de despliegue canary es beneficiosa para probar nuevas versiones con un pequeño subconjunto primero. Sin embargo, no proporciona una opción de reversión completa tan efectivamente como blue/green, y puede requerir configuración y monitoreo adicionales para las funciones de Lambda."
        ]
    },
    {
        "Question Number": "24",
        "Situation": "Una empresa está desarrollando una aplicación de microservicios que requiere un servicio de colas de mensajes confiable. Están considerando usar Amazon SQS para este propósito. Una de las principales limitaciones que necesitan tener en cuenta es el tamaño máximo de los mensajes que se pueden enviar a través de SQS.",
        "Question": "¿Cuál es el tamaño máximo de un mensaje que se puede enviar a través de Amazon SQS?",
        "Options": {
            "1": "128,000 bytes",
            "2": "512,000 bytes",
            "3": "262,144 bytes",
            "4": "256,000 bytes"
        },
        "Correct Answer": "262,144 bytes",
        "Explanation": "El tamaño máximo de mensaje para Amazon SQS es de 262,144 bytes (256 KB). Este límite se aplica al tamaño de cada mensaje individual que se puede enviar a la cola de SQS, asegurando que los mensajes se mantengan livianos y que la transmisión sea eficiente.",
        "Other Options": [
            "128,000 bytes es incorrecto porque está muy por debajo del límite real de tamaño máximo de mensaje de 262,144 bytes.",
            "256,000 bytes es incorrecto porque también está por debajo del límite máximo de tamaño de mensaje de 262,144 bytes, que es 256 KB.",
            "512,000 bytes es incorrecto porque excede el límite máximo de tamaño de mensaje de 262,144 bytes, lo que lo convierte en una opción no válida para SQS."
        ]
    },
    {
        "Question Number": "25",
        "Situation": "Una empresa está utilizando Amazon Redshift para análisis de datos y desea mejorar su estrategia de recuperación ante desastres. Tienen el requisito de respaldar automáticamente sus datos en otra región de AWS. El clúster de Redshift está cifrado con KMS y quieren asegurarse de que las instantáneas se puedan copiar entre regiones mientras cumplen con los requisitos de cumplimiento.",
        "Question": "¿Cuál es el proceso correcto para habilitar instantáneas entre regiones para un clúster de Amazon Redshift cifrado con KMS?",
        "Options": {
            "1": "Habilitar instantáneas automatizadas y especificar la región de destino en la configuración del clúster.",
            "2": "Crear un permiso para que Redshift use una clave maestra de cliente KMS en la región de destino antes de habilitar la copia de instantáneas.",
            "3": "Copiar manualmente las instantáneas a la región de destino utilizando la Consola de Administración de AWS.",
            "4": "Cambiar la configuración del clúster para usar S3 para respaldos en lugar de cifrado con KMS."
        },
        "Correct Answer": "Crear un permiso para que Redshift use una clave maestra de cliente KMS en la región de destino antes de habilitar la copia de instantáneas.",
        "Explanation": "Para habilitar instantáneas entre regiones para clústeres de Amazon Redshift cifrados con KMS, debes crear un permiso que permita a Amazon Redshift usar una clave maestra de cliente KMS (CMK) en la región de destino. Este paso es esencial para garantizar que el clúster pueda acceder a la clave de cifrado necesaria para las instantáneas en la otra región.",
        "Other Options": [
            "Simplemente habilitar instantáneas automatizadas y especificar la región de destino no es suficiente, ya que necesitas manejar el permiso de KMS para el cifrado.",
            "Copiar instantáneas manualmente no es una solución factible o automatizada para copias de seguridad continuas; la funcionalidad de instantáneas entre regiones está diseñada para ser automatizada.",
            "Cambiar la configuración del clúster para usar S3 para respaldos no se aplica a la copia de instantáneas de Redshift y no cumple con el requisito de instantáneas automatizadas entre regiones."
        ]
    },
    {
        "Question Number": "26",
        "Situation": "Una empresa global desea implementar una estrategia de múltiples cuentas utilizando AWS Organizations para gestionar sus diversas unidades de negocio. La empresa también planea aprovechar AWS Control Tower para gobernanza y cumplimiento. El arquitecto de soluciones necesita diseñar una solución que permita la gestión centralizada, la facturación y el cumplimiento en todas las cuentas, mientras permite que las unidades de negocio individuales tengan autonomía sobre sus propios recursos.",
        "Question": "¿Cuál de las siguientes soluciones debería implementar el arquitecto de soluciones para cumplir mejor con los requisitos?",
        "Options": {
            "1": "Crear múltiples OUs dentro de la organización de AWS para cada unidad de negocio, aplicando SCPs a nivel de OU para gestionar el cumplimiento y la gestión centralizada.",
            "2": "Configurar una única organización de AWS con todas las cuentas en la OU raíz y habilitar políticas de control de servicio (SCPs) para cada cuenta para hacer cumplir el cumplimiento.",
            "3": "Implementar AWS Control Tower para crear un marco de gobernanza y colocar todas las cuentas en una única OU con SCPs estrictos aplicados a nivel de cuenta.",
            "4": "Utilizar AWS Control Tower para configurar una zona de aterrizaje con cuentas preconfiguradas e implementar SCPs en la OU raíz para hacer cumplir el cumplimiento en todas las unidades de negocio."
        },
        "Correct Answer": "Crear múltiples OUs dentro de la organización de AWS para cada unidad de negocio, aplicando SCPs a nivel de OU para gestionar el cumplimiento y la gestión centralizada.",
        "Explanation": "Crear múltiples OUs permite una mejor organización y gestión de cuentas que corresponden a diferentes unidades de negocio, mientras que aplicar SCPs a nivel de OU proporciona una forma flexible de hacer cumplir el cumplimiento adaptado a las necesidades de cada unidad.",
        "Other Options": [
            "Configurar todas las cuentas en la OU raíz sin OUs específicas para cada unidad de negocio puede llevar a una complejidad de gestión y a una aplicación del cumplimiento menos efectiva, ya que no habría políticas adaptadas para unidades individuales.",
            "Si bien utilizar AWS Control Tower para configurar una zona de aterrizaje es beneficioso, aplicar SCPs solo en la OU raíz puede limitar la granularidad de la gestión del cumplimiento en diferentes unidades de negocio.",
            "Colocar todas las cuentas en una única OU con SCPs estrictos aplicados a nivel de cuenta puede obstaculizar la autonomía de las unidades de negocio individuales y complicar la gobernanza, ya que no permite políticas específicas adaptadas a las necesidades de cada unidad."
        ]
    },
    {
        "Question Number": "27",
        "Situation": "Una empresa de servicios financieros está desplegando una nueva aplicación en AWS que procesa datos sensibles de clientes. La empresa necesita asegurarse de que la aplicación cumpla con estrictos requisitos de cumplimiento de seguridad mientras minimiza el riesgo de acceso no autorizado a sus recursos.",
        "Question": "¿Qué estrategia debería implementar la empresa para mejorar la seguridad de su entorno de AWS mientras asegura el cumplimiento con las regulaciones de la industria?",
        "Options": {
            "1": "Habilitar AWS CloudTrail para registrar todas las llamadas a la API y configurar AWS Config para monitorear el cumplimiento de las políticas de seguridad en todos los recursos.",
            "2": "Crear un bucket de Amazon S3 para almacenar datos sensibles y habilitar el acceso público para permitir la recuperación sin problemas por parte de la aplicación.",
            "3": "Implementar una función de AWS Lambda que se ejecute periódicamente para eliminar roles de IAM y claves de acceso no utilizadas para reducir la superficie de ataque.",
            "4": "Configurar un host bastión dentro de una subred pública que permita el acceso SSH a recursos en subredes privadas mientras se deshabilita todo el tráfico entrante."
        },
        "Correct Answer": "Habilitar AWS CloudTrail para registrar todas las llamadas a la API y configurar AWS Config para monitorear el cumplimiento de las políticas de seguridad en todos los recursos.",
        "Explanation": "Habilitar AWS CloudTrail te permite registrar todas las llamadas a la API realizadas en tu cuenta de AWS, proporcionando un rastro de auditoría completo para fines de cumplimiento. Además, AWS Config ayuda a rastrear cambios en los recursos y evaluar el cumplimiento de las políticas de seguridad definidas, lo que lo convierte en una estrategia efectiva para mejorar la seguridad y cumplir con los requisitos regulatorios.",
        "Other Options": [
            "Configurar un host bastión puede mejorar la seguridad para el acceso SSH, pero no aborda el monitoreo general de cumplimiento o registro, que son críticos para aplicaciones sensibles.",
            "Si bien implementar una función Lambda para eliminar roles de IAM y claves de acceso no utilizadas puede reducir la superficie de ataque, no proporciona la auditoría completa y el monitoreo de cumplimiento necesarios para el procesamiento de datos sensibles.",
            "Crear un bucket de S3 con acceso público socava directamente la seguridad al exponer datos sensibles, lo que contradice el objetivo de mejorar la seguridad y el cumplimiento en el entorno de AWS."
        ]
    },
    {
        "Question Number": "28",
        "Situation": "Una empresa de servicios financieros está planeando migrar sus aplicaciones locales a AWS. Están particularmente preocupados por la seguridad de sus datos durante el proceso de migración. La empresa utiliza una combinación de AWS Database Migration Service (DMS) y AWS Application Migration Service (AWS MGN) para manejar la migración. Quieren asegurarse de que los datos sensibles permanezcan seguros durante el tránsito y en reposo.",
        "Question": "¿Cuál de los siguientes métodos debería implementar la empresa para mejorar la seguridad de los datos durante el proceso de migración? (Seleccione Dos)",
        "Options": {
            "1": "Asegurarse de que todas las instancias de migración se lancen en una subred pública para permitir un acceso más fácil durante la migración.",
            "2": "Habilitar AWS CloudTrail para rastrear las llamadas a la API realizadas por los servicios de migración para fines de cumplimiento y auditoría.",
            "3": "Utilizar AWS Key Management Service (KMS) para gestionar las claves de cifrado para los datos en reposo en el entorno de AWS de destino.",
            "4": "Configurar políticas de buckets de S3 para permitir acceso sin restricciones a las herramientas de migración para almacenar datos temporales.",
            "5": "Implementar cifrado en tránsito utilizando TLS para DMS y AWS MGN para proteger datos sensibles durante la migración."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Implementar cifrado en tránsito utilizando TLS para DMS y AWS MGN para proteger datos sensibles durante la migración.",
            "Utilizar AWS Key Management Service (KMS) para gestionar las claves de cifrado para los datos en reposo en el entorno de AWS de destino."
        ],
        "Explanation": "Implementar cifrado en tránsito utilizando TLS asegura que los datos que se mueven entre el entorno local y AWS estén protegidos contra la interceptación. Además, utilizar AWS KMS para gestionar las claves de cifrado para los datos en reposo asegura que los datos sensibles almacenados en AWS estén seguros, cumpliendo con las mejores prácticas para la protección de datos.",
        "Other Options": [
            "Lanzar instancias de migración en una subred pública las expone a Internet público, aumentando el riesgo de acceso no autorizado a datos sensibles durante la migración. Se recomienda utilizar subredes privadas con medidas de seguridad adecuadas.",
            "Si bien habilitar AWS CloudTrail es una buena práctica para rastrear actividades, no mejora directamente la seguridad de los datos durante la migración. Se centra en el registro en lugar de proteger los datos en sí.",
            "Permitir acceso sin restricciones en las políticas de buckets de S3 puede llevar a accesos no autorizados y violaciones de datos. Es crucial implementar acceso de menor privilegio para restringir quién puede acceder a los datos durante la migración."
        ]
    },
    {
        "Question Number": "29",
        "Situation": "Una empresa de servicios financieros está implementando cifrado del lado del servidor con claves proporcionadas por el cliente (SSE-C) para asegurar datos sensibles almacenados en Amazon S3. La aplicación realizará llamadas a la API REST para cargar y recuperar objetos cifrados, y es crucial asegurarse de que los encabezados HTTP correctos se incluyan en cada solicitud para mantener la integridad y seguridad de los datos. El equipo de desarrollo necesita entender los encabezados requeridos para el cifrado SSE-C al usar URLs prefirmadas.",
        "Question": "¿Cuál de los siguientes encabezados de solicitud HTTP debe incluirse al usar URLs prefirmadas para cifrado del lado del servidor con claves proporcionadas por el cliente (SSE-C) en Amazon S3?",
        "Options": {
            "1": "x-amz-server-side-encryption-customer-algorithm, x-amz-server-side-encryption-customer-key, x-amz-server-side-encryption-customer-key-MD5",
            "2": "x-amz-server-side-encryption-customer-key, x-amz-server-side-encryption-customer-key-MD5",
            "3": "x-amz-server-side-encryption-customer-algorithm, x-amz-server-side-encryption-customer-key",
            "4": "x-amz-server-side-encryption-customer-algorithm"
        },
        "Correct Answer": "x-amz-server-side-encryption-customer-algorithm",
        "Explanation": "Al usar URLs prefirmadas para SSE-C en Amazon S3, el único encabezado HTTP requerido es 'x-amz-server-side-encryption-customer-algorithm' para especificar el algoritmo de cifrado. Los otros encabezados no son necesarios al usar URLs prefirmadas, ya que la clave del cliente y su hash MD5 no se incluyen en la solicitud inicial.",
        "Other Options": [
            "Esta opción es incorrecta porque incluye encabezados innecesarios que no son requeridos para URLs prefirmadas; solo el encabezado del algoritmo es obligatorio.",
            "Esta opción es incorrecta ya que carece del encabezado necesario para especificar el algoritmo de cifrado al usar URLs prefirmadas.",
            "Esta opción es incorrecta porque no incluye el encabezado de algoritmo requerido para SSE-C al usar URLs prefirmadas."
        ]
    },
    {
        "Question Number": "30",
        "Situation": "Una empresa de servicios financieros está desplegando una aplicación de múltiples capas en AWS, que incluye una capa web, una capa de aplicación y una capa de base de datos. La empresa necesita una estrategia integral de registro y monitoreo para asegurar el cumplimiento de los requisitos regulatorios, solucionar problemas y optimizar el rendimiento. La aplicación utilizará instancias de Amazon EC2 para las capas web y de aplicación y Amazon RDS para la base de datos. La empresa busca implementar una solución que minimice la sobrecarga operativa mientras maximiza la seguridad y el control de acceso.",
        "Question": "¿Qué estrategia de registro y monitoreo debería adoptar la empresa para cumplir con sus requisitos?",
        "Options": {
            "1": "Desplegar una solución de registro de código abierto en instancias de EC2 que recoja y centralice registros. Usar Amazon CloudWatch para monitoreo básico y configurar un trabajo cron para copias de seguridad regulares de los datos de registro a S3 para fines de cumplimiento.",
            "2": "Implementar Amazon CloudWatch para monitoreo de aplicaciones e infraestructura, y usar AWS CloudTrail para registrar todas las llamadas a la API. Configurar métricas personalizadas y alarmas para notificar al equipo de operaciones sobre posibles problemas. Integrar Amazon GuardDuty para monitoreo de seguridad y detección de amenazas.",
            "3": "Aprovechar Amazon CloudWatch Logs para agregar registros de aplicaciones de instancias de EC2 y RDS. Configurar AWS Lambda para procesar registros y enviar alertas a través de Amazon SNS para eventos críticos. Usar AWS Systems Manager para gestionar y automatizar tareas operativas.",
            "4": "Utilizar AWS X-Ray para rastrear solicitudes a través de la aplicación, combinado con Amazon CloudWatch para monitorear el rendimiento del sistema. Emplear AWS Config para rastrear cambios de configuración y AWS CloudTrail para registrar llamadas a la API, asegurando auditorías completas."
        },
        "Correct Answer": "Implementar Amazon CloudWatch para monitoreo de aplicaciones e infraestructura, y usar AWS CloudTrail para registrar todas las llamadas a la API. Configurar métricas personalizadas y alarmas para notificar al equipo de operaciones sobre posibles problemas. Integrar Amazon GuardDuty para monitoreo de seguridad y detección de amenazas.",
        "Explanation": "Esta opción proporciona una estrategia integral de registro y monitoreo que cumple con el cumplimiento regulatorio, permite la solución de problemas y optimiza el rendimiento. Amazon CloudWatch permite monitoreo y alertas en tiempo real, AWS CloudTrail asegura una auditoría completa de las llamadas a la API, y Amazon GuardDuty añade una capa esencial de monitoreo de seguridad.",
        "Other Options": [
            "Si bien usar AWS X-Ray para rastrear y Amazon CloudWatch para monitorear es beneficioso, carece de las capacidades integrales de monitoreo de seguridad y detección de amenazas proporcionadas por Amazon GuardDuty, así como del registro de API enfocado que ofrece AWS CloudTrail.",
            "Agregar registros con Amazon CloudWatch Logs y procesarlos a través de AWS Lambda proporciona algunas capacidades de monitoreo, pero no ofrece el extenso registro de API y las características de seguridad que son esenciales para el cumplimiento regulatorio.",
            "Desplegar una solución de registro de código abierto podría llevar a una mayor sobrecarga operativa y desafíos de mantenimiento, y no aprovecha al máximo los servicios administrados de AWS para monitoreo y registro, que están diseñados para asegurar la seguridad, el cumplimiento y la facilidad de uso."
        ]
    },
    {
        "Question Number": "31",
        "Situation": "Una empresa de servicios financieros está evaluando su estrategia de recuperación ante desastres para sus aplicaciones críticas alojadas en AWS. Quieren asegurar un tiempo de inactividad y pérdida de datos mínimos en caso de un desastre. La empresa ha definido un Objetivo de Tiempo de Recuperación (RTO) de 4 horas y un Objetivo de Punto de Recuperación (RPO) de 1 hora para sus aplicaciones. Están considerando diferentes estrategias de respaldo y replicación para cumplir con estos objetivos.",
        "Question": "¿Cuál de las siguientes estrategias permitirá a la empresa cumplir mejor con sus requisitos de RTO y RPO?",
        "Options": {
            "1": "Utilizar Amazon S3 para almacenamiento con versionado habilitado y configurar un despliegue multi-AZ para Amazon RDS.",
            "2": "Implementar replicación entre regiones para todos los datos y usar AWS Elastic Beanstalk para el despliegue de aplicaciones.",
            "3": "Usar AWS Backup para crear copias de seguridad diarias de todos los recursos y desplegar aplicaciones en instancias de Amazon EC2 en una sola Zona de Disponibilidad.",
            "4": "Programar instantáneas horarias de Amazon RDS y usar AWS Lambda para automatizar la conmutación por error de la base de datos a una región secundaria."
        },
        "Correct Answer": "Utilizar Amazon S3 para almacenamiento con versionado habilitado y configurar un despliegue multi-AZ para Amazon RDS.",
        "Explanation": "Utilizar Amazon S3 con versionado proporciona un almacenamiento de datos confiable con control de versiones, lo que ayuda a minimizar la pérdida de datos y cumplir con el RPO de 1 hora. Mientras tanto, un despliegue multi-AZ para Amazon RDS asegura alta disponibilidad y capacidades de conmutación por error rápidas, alineándose con el RTO de 4 horas.",
        "Other Options": [
            "Implementar replicación entre regiones puede llevar a un aumento en la latencia y costos, y aunque puede proporcionar durabilidad, puede no abordar suficientemente los requisitos de RTO y RPO tan efectivamente como el despliegue multi-AZ.",
            "Programar instantáneas horarias puede no ser lo suficientemente frecuente para cumplir con el RPO de 1 hora, y aunque la automatización para la conmutación por error es beneficiosa, puede no garantizar el tiempo de recuperación rápido necesario para cumplir con el RTO.",
            "Crear copias de seguridad diarias no cumple con el RPO de 1 hora, ya que las copias de seguridad no capturarían los cambios de datos realizados dentro de esa hora, y desplegar aplicaciones en una sola Zona de Disponibilidad no proporciona la resiliencia necesaria para cumplir con el RTO."
        ]
    },
    {
        "Question Number": "32",
        "Situation": "Una empresa está planeando migrar una gran base de datos local a AWS. La base de datos tiene aproximadamente 10 TB de tamaño y requiere un tiempo de inactividad mínimo durante la migración. El equipo está considerando varios servicios de AWS para facilitar esta migración mientras asegura la integridad y seguridad de los datos.",
        "Question": "¿Qué servicio y estrategia de AWS debería usar el equipo para migrar la base de datos con un tiempo de inactividad mínimo?",
        "Options": {
            "1": "AWS DataSync con AWS Schema Conversion Tool (SCT)",
            "2": "AWS Snowball con AWS Database Migration Service (DMS)",
            "3": "AWS Transfer Family con Amazon RDS Migration Readiness Review",
            "4": "AWS Direct Connect con exportación e importación de datos manual"
        },
        "Correct Answer": "AWS Snowball con AWS Database Migration Service (DMS)",
        "Explanation": "AWS Snowball permite la transferencia eficiente de grandes cantidades de datos a AWS. Al usar AWS Database Migration Service (DMS) en conjunto, el equipo puede realizar replicación continua durante la transferencia de datos, asegurando un tiempo de inactividad mínimo y manteniendo la integridad de los datos a lo largo del proceso de migración.",
        "Other Options": [
            "AWS DataSync se utiliza principalmente para transferir archivos en lugar de bases de datos, y aunque el AWS Schema Conversion Tool (SCT) es útil para la conversión de esquemas, no aborda los requisitos para una migración a gran escala con tiempo de inactividad mínimo.",
            "AWS Direct Connect es útil para establecer una conexión de red dedicada, pero no facilita la migración de grandes bases de datos directamente. La exportación e importación de datos manual probablemente resultaría en un tiempo de inactividad significativo y no es ideal para esta situación.",
            "AWS Transfer Family está diseñado para transferir archivos utilizando protocolos como SFTP o FTP y no se aplica a migraciones de bases de datos. Además, una revisión de preparación para la migración de Amazon RDS es un paso preparatorio en lugar de una estrategia de migración."
        ]
    },
    {
        "Question Number": "33",
        "Situation": "Una empresa de tecnología está implementando un sistema que requiere acceso temporal a recursos de AWS para usuarios que se autentican utilizando una aplicación web. La aplicación necesita proporcionar a los usuarios acceso limitado en el tiempo a servicios específicos de AWS sin crear usuarios permanentes de AWS IAM. La arquitectura debe asegurar que la solución sea escalable y no introduzca un único punto de falla. Se te ha encomendado la tarea de seleccionar el enfoque adecuado para gestionar el acceso de los usuarios, considerando la seguridad y la manejabilidad.",
        "Question": "¿Qué enfoque debería implementarse para proporcionar acceso temporal a recursos de AWS mientras se minimiza el riesgo de un único punto de falla?",
        "Options": {
            "1": "Usar AWS Security Token Service (STS) para generar credenciales temporales que se pueden proporcionar a los usuarios al autenticarse, y asegurar que las credenciales tengan permisos limitados.",
            "2": "Implementar un modelo tradicional de validación de tokens (TVM) para gestionar el acceso de los usuarios, permitiendo permisos específicos de servicio y entrega de credenciales a los usuarios.",
            "3": "Usar Amazon Cognito para gestionar la autenticación de usuarios y emitir credenciales temporales a través de AWS STS, proporcionando una solución escalable y segura sin un único punto de falla.",
            "4": "Desplegar una instancia de EC2 ejecutando un código personalizado para el modelo de validación de tokens (TVM) para gestionar la autenticación de usuarios y el acceso, asegurando que las credenciales se entreguen de manera segura."
        },
        "Correct Answer": "Usar Amazon Cognito para gestionar la autenticación de usuarios y emitir credenciales temporales a través de AWS STS, proporcionando una solución escalable y segura sin un único punto de falla.",
        "Explanation": "Amazon Cognito proporciona una solución robusta para la autenticación de usuarios e integra sin problemas con AWS STS para emitir credenciales temporales. Este enfoque evita el único punto de falla asociado con una implementación personalizada de TVM y ofrece escalabilidad y seguridad para gestionar el acceso de los usuarios.",
        "Other Options": [
            "Usar AWS STS solo proporciona credenciales temporales, pero no gestiona la autenticación de usuarios directamente. Este enfoque carece de las características adicionales proporcionadas por Amazon Cognito, como la gestión de grupos de usuarios y seguridad mejorada.",
            "Implementar un modelo tradicional de validación de tokens (TVM) puede introducir un único punto de falla, especialmente si se aloja en EC2. Además, el TVM se considera obsoleto en comparación con soluciones modernas como Amazon Cognito.",
            "Desplegar una instancia de EC2 para un TVM personalizado añade complejidad y carga operativa, aumentando el riesgo de falla. Este método no proporciona el mismo nivel de escalabilidad y seguridad que Amazon Cognito en la gestión del acceso de los usuarios."
        ]
    },
    {
        "Question Number": "34",
        "Situation": "Una empresa minorista está planeando lanzar una nueva aplicación de comercio electrónico que requiere alta disponibilidad y la capacidad de escalar automáticamente según el tráfico. La aplicación experimentará patrones de tráfico impredecibles, especialmente durante promociones y ventas navideñas. La empresa quiere asegurarse de que su estrategia de implementación minimice el tiempo de inactividad y proporcione experiencias de usuario sin interrupciones.",
        "Question": "¿Qué estrategia de implementación debería implementar la empresa para garantizar alta disponibilidad y escalabilidad para su aplicación de comercio electrónico?",
        "Options": {
            "1": "Desplegar la aplicación en una sola instancia de EC2 con un gran volumen de EBS y configurar una alarma de CloudWatch para enviar notificaciones sobre escalamiento.",
            "2": "Utilizar un entorno de Elastic Beanstalk con múltiples instancias de EC2 detrás de un balanceador de carga, configurando el escalado automático basado en métricas de utilización de CPU.",
            "3": "Usar funciones de AWS Lambda para manejar todas las solicitudes entrantes, asegurando que no haya instancias de EC2 que gestionar y escalar automáticamente.",
            "4": "Implementar un clúster de Amazon ECS con múltiples instancias de contenedores, utilizando Fargate para gestionar el escalado y la implementación de la aplicación."
        },
        "Correct Answer": "Utilizar un entorno de Elastic Beanstalk con múltiples instancias de EC2 detrás de un balanceador de carga, configurando el escalado automático basado en métricas de utilización de CPU.",
        "Explanation": "Usar Elastic Beanstalk con múltiples instancias de EC2 asegura que la aplicación pueda manejar cargas de tráfico variables. El balanceador de carga distribuye el tráfico entrante, y el escalado automático ajusta el número de instancias según la utilización de CPU, lo que conduce a alta disponibilidad y uso eficiente de recursos.",
        "Other Options": [
            "Desplegar la aplicación en una sola instancia de EC2 no proporciona alta disponibilidad, ya que introduce un único punto de falla. Las alarmas de CloudWatch pueden notificar sobre las necesidades de escalado, pero no pueden escalar automáticamente sin múltiples instancias desde el principio.",
            "Si bien usar AWS Lambda puede proporcionar escalado automático y eliminar la gestión del servidor, puede no ser adecuado para todos los tipos de solicitudes, particularmente para cargas de trabajo que requieren conexiones persistentes o sesiones con estado.",
            "Amazon ECS con Fargate es una opción válida para gestionar contenedores, pero podría introducir una complejidad innecesaria para una nueva aplicación que puede ser gestionada de manera efectiva con el modelo de implementación más simple de Elastic Beanstalk."
        ]
    },
    {
        "Question Number": "35",
        "Situation": "Una empresa está desarrollando una arquitectura de microservicios para mejorar la escalabilidad y mantenibilidad. La arquitectura requiere que los servicios permanezcan independientes y puedan evolucionar por separado sin un acoplamiento estrecho. El equipo de desarrollo está considerando varios servicios de AWS para implementar dependencias débilmente acopladas entre microservicios.",
        "Question": "¿Cuál es la solución MÁS adecuada que el Arquitecto de Soluciones debería recomendar para habilitar dependencias débilmente acopladas entre microservicios?",
        "Options": {
            "1": "Desplegar funciones de AWS Lambda con puntos finales de API Gateway directos para cada microservicio, asegurando que estén estrechamente integrados y puedan llamarse entre sí directamente.",
            "2": "Utilizar Amazon SNS para publicar eventos desde un microservicio que pueden ser suscritos por otros microservicios, permitiendo una arquitectura desacoplada impulsada por eventos.",
            "3": "Implementar Amazon SQS para comunicación asíncrona entre servicios, permitiendo que procesen mensajes de manera independiente sin dependencias directas.",
            "4": "Usar AWS AppSync para establecer una API GraphQL que conecte todos los microservicios, asegurando comunicación sincrónica y acceso compartido a datos."
        },
        "Correct Answer": "Utilizar Amazon SNS para publicar eventos desde un microservicio que pueden ser suscritos por otros microservicios, permitiendo una arquitectura desacoplada impulsada por eventos.",
        "Explanation": "Utilizar Amazon SNS proporciona un mecanismo robusto para implementar dependencias débilmente acopladas al permitir que los microservicios se comuniquen a través de eventos publicados. Este enfoque permite que los servicios operen de manera independiente y escalen sin estar estrechamente integrados, fomentando una arquitectura impulsada por eventos.",
        "Other Options": [
            "Implementar Amazon SQS para comunicación asíncrona es beneficioso, pero se centra principalmente en el encolado de mensajes en lugar de un modelo impulsado por eventos, que es más adecuado para dependencias débilmente acopladas.",
            "Usar AWS AppSync establece una API GraphQL que promueve la comunicación sincrónica, lo que puede crear un acoplamiento más estrecho entre los servicios, en contra del objetivo de mantener la independencia.",
            "Desplegar funciones de AWS Lambda con puntos finales de API Gateway directos conduce a un acoplamiento estrecho, ya que los servicios se llamarían directamente entre sí, dificultando su evolución de manera independiente."
        ]
    },
    {
        "Question Number": "36",
        "Situation": "Una empresa está planeando migrar sus aplicaciones locales a AWS. Tienen una mezcla de aplicaciones heredadas que están estrechamente acopladas entre sí y algunas aplicaciones más nuevas, nativas de la nube. Las aplicaciones son críticas para las operaciones comerciales, y la empresa quiere minimizar el tiempo de inactividad durante el proceso de migración. El Arquitecto de Soluciones necesita determinar el enfoque de migración óptimo para estas cargas de trabajo.",
        "Question": "¿Cuál de las siguientes estrategias de migración debería recomendar el Arquitecto de Soluciones para asegurar un tiempo de inactividad mínimo mientras se migran las aplicaciones a AWS?",
        "Options": {
            "1": "Retirar las aplicaciones heredadas y migrar los datos a Amazon RDS, mientras se reemplaza la funcionalidad empresarial con aplicaciones nativas de la nube.",
            "2": "Lift-and-shift de las aplicaciones heredadas a AWS utilizando el Servicio de Migración de Aplicaciones de AWS, asegurando que permanezcan operativas durante el proceso de migración.",
            "3": "Reubicar las aplicaciones heredadas en instancias de Amazon EC2 mientras se refactorizan gradualmente las aplicaciones más nuevas para su contenedorización utilizando Amazon ECS.",
            "4": "Refactorizar todas las aplicaciones en microservicios y desplegarlas como funciones de AWS Lambda para aprovechar la arquitectura sin servidor."
        },
        "Correct Answer": "Lift-and-shift de las aplicaciones heredadas a AWS utilizando el Servicio de Migración de Aplicaciones de AWS, asegurando que permanezcan operativas durante el proceso de migración.",
        "Explanation": "El enfoque lift-and-shift utilizando el Servicio de Migración de Aplicaciones de AWS permite a la empresa migrar rápidamente sus aplicaciones heredadas con un tiempo de inactividad mínimo. Este método permite que las aplicaciones se ejecuten en AWS sin cambios significativos, asegurando la continuidad del negocio durante la transición.",
        "Other Options": [
            "Reubicar las aplicaciones heredadas mientras se refactorizan gradualmente las aplicaciones más nuevas puede introducir riesgos de tiempo de inactividad y complejidad, ya que los sistemas heredados estrechamente acoplados no son fácilmente adaptables a una migración escalonada.",
            "Refactorizar todas las aplicaciones en microservicios y desplegarlas como funciones de AWS Lambda es un enfoque ambicioso que puede requerir una re-arquitectura extensa, lo que podría llevar a un tiempo de inactividad potencial durante la transición.",
            "Retirar las aplicaciones heredadas y migrar los datos a Amazon RDS mientras se reemplaza la funcionalidad empresarial con aplicaciones nativas de la nube puede resultar en un tiempo de inactividad significativo y una interrupción del negocio a medida que la organización se aleja de los sistemas heredados críticos."
        ]
    },
    {
        "Question Number": "37",
        "Situation": "Una startup está desarrollando una aplicación de microservicios que se ejecutará en AWS. La aplicación tendrá múltiples servicios, cada uno responsable de una capacidad empresarial específica. La startup está considerando varias opciones para desplegar sus contenedores y quiere asegurarse de elegir una solución que ofrezca alta escalabilidad, balanceo de carga automático y un mínimo de sobrecarga operativa.",
        "Question": "¿Cuál de las siguientes opciones satisface mejor los requisitos de la startup para desplegar su aplicación de microservicios de manera rentable y eficiente?",
        "Options": {
            "1": "Desplegar los microservicios en AWS Fargate con Amazon ECS. Esta opción sin servidor permite a la startup ejecutar contenedores sin gestionar la infraestructura subyacente. Configurar el escalado automático de servicios y utilizar las características de balanceo de carga integradas de ECS para distribuir el tráfico.",
            "2": "Desplegar los microservicios en Amazon ECS con el tipo de lanzamiento EC2. Configurar el escalado automático para manejar cargas variables y usar Elastic Load Balancer para la distribución del tráfico. Gestionar las instancias EC2 subyacentes y asegurarse de que estén adecuadamente mantenidas.",
            "3": "Desplegar los microservicios en Amazon EKS. Utilizar Kubernetes para gestionar el despliegue y la escalabilidad de los servicios. Configurar un Cluster Autoscaler para escalado dinámico y usar servicios de Kubernetes para el balanceo de carga. Esta opción requiere gestionar el entorno de Kubernetes.",
            "4": "Desplegar los microservicios en AWS Lambda. Descomponer cada microservicio en funciones sin servidor que pueden escalar automáticamente según la demanda. Usar API Gateway para el balanceo de carga y la gestión del tráfico, eliminando la necesidad de orquestación de contenedores."
        },
        "Correct Answer": "Desplegar los microservicios en AWS Fargate con Amazon ECS. Esta opción sin servidor permite a la startup ejecutar contenedores sin gestionar la infraestructura subyacente. Configurar el escalado automático de servicios y utilizar las características de balanceo de carga integradas de ECS para distribuir el tráfico.",
        "Explanation": "Desplegar los microservicios en AWS Fargate con Amazon ECS permite a la startup ejecutar sus contenedores en un entorno sin servidor, eliminando la necesidad de gestionar las instancias EC2 subyacentes. Esta opción proporciona escalado automático y balanceo de carga integrado, lo que la hace ideal para sus necesidades mientras minimiza la sobrecarga operativa y los costos.",
        "Other Options": [
            "Desplegar los microservicios en Amazon ECS con el tipo de lanzamiento EC2 requiere que la startup gestione las instancias EC2 subyacentes, lo que añade sobrecarga operativa y complejidad. Aunque puede escalar, no iguala la facilidad de gestión que proporciona Fargate.",
            "Desplegar los microservicios en Amazon EKS requiere gestionar un entorno de Kubernetes, lo que puede ser complejo para startups sin experiencia en orquestación de contenedores. Si bien ofrece escalabilidad, no proporciona el mismo nivel de simplicidad operativa que Fargate.",
            "Desplegar los microservicios en AWS Lambda no es adecuado ya que requiere descomponer la aplicación en funciones individuales, lo que puede llevar a una mayor complejidad en la gestión de funciones y posibles problemas de inicio en frío, a diferencia del enfoque en contenedores preferido por la startup."
        ]
    },
    {
        "Question Number": "38",
        "Situation": "Una gran empresa de comercio electrónico ha estado experimentando picos inesperados en los costos de AWS debido al aumento del uso de varios servicios en la nube. Para gestionar esta situación, la empresa necesita implementar una estrategia integral de concienciación sobre gastos y uso. El arquitecto de soluciones tiene la tarea de proponer una solución que permita a la empresa monitorear, analizar y controlar su gasto en AWS de manera efectiva.",
        "Question": "¿Cuál de las siguientes opciones proporciona la mejor estrategia para desarrollar controles de concienciación sobre gastos y uso en AWS?",
        "Options": {
            "1": "Implementar AWS Budgets para establecer presupuestos personalizados de costos y uso. Usar AWS CloudTrail para registrar el uso de servicios y revisar los registros regularmente para identificar patrones de gasto anómalos.",
            "2": "Utilizar AWS Trusted Advisor para obtener información sobre optimización de costos y uso de servicios. Combinar esto con el seguimiento manual de las facturas de AWS para obtener una visión integral.",
            "3": "Aprovechar AWS Organizations para consolidar la facturación a través de múltiples cuentas. Implementar AWS Cost Explorer con informes predefinidos para obtener información sobre el gasto entre equipos.",
            "4": "Desplegar Amazon CloudWatch para monitorear el uso de servicios y configurar alarmas para umbrales específicos. Usar AWS Cost Explorer para analizar tendencias de gasto y crear informes."
        },
        "Correct Answer": "Implementar AWS Budgets para establecer presupuestos personalizados de costos y uso. Usar AWS CloudTrail para registrar el uso de servicios y revisar los registros regularmente para identificar patrones de gasto anómalos.",
        "Explanation": "Esta opción combina de manera efectiva la gestión proactiva del presupuesto con el registro detallado del uso de servicios, permitiendo a la empresa establecer límites financieros e investigar gastos irregulares, lo cual es crucial para mantener la concienciación sobre gastos.",
        "Other Options": [
            "Si bien desplegar Amazon CloudWatch puede ayudar a monitorear el uso, no aborda directamente la necesidad de gestión del presupuesto y puede llevar a medidas reactivas en lugar de un control proactivo de costos.",
            "Utilizar AWS Trusted Advisor proporciona información útil para la optimización de costos, pero depender únicamente del seguimiento manual de facturas es ineficiente y puede llevar a una concienciación tardía sobre problemas de costos.",
            "Aprovechar AWS Organizations puede ayudar en la consolidación de la facturación, pero sin incorporar una estrategia de presupuesto o un monitoreo detallado del uso, puede no proporcionar los controles necesarios para la concienciación sobre gastos."
        ]
    },
    {
        "Question Number": "39",
        "Situation": "Una empresa de servicios financieros está ejecutando una aplicación crítica en instancias de Amazon EC2 en una única Zona de Disponibilidad. La aplicación está experimentando cortes ocasionales debido a la falta de disponibilidad de la infraestructura subyacente. Se ha encargado al arquitecto de soluciones diseñar una arquitectura altamente disponible que pueda manejar la conmutación por error sin afectar el rendimiento de la aplicación.",
        "Question": "¿Cuál de las siguientes soluciones remediaría mejor el único punto de falla en esta arquitectura?",
        "Options": {
            "1": "Desplegar la aplicación en múltiples instancias de EC2 en diferentes Zonas de Disponibilidad y usar un Elastic Load Balancer para distribuir el tráfico.",
            "2": "Configurar una pila de CloudFormation que recree automáticamente la aplicación en una Zona de Disponibilidad diferente en caso de falla.",
            "3": "Crear una réplica de lectura de Amazon RDS en una Zona de Disponibilidad diferente para manejar la conmutación por error en la capa de base de datos.",
            "4": "Implementar Amazon Route 53 con una política de enrutamiento de conmutación por error para dirigir el tráfico a una instancia secundaria de la aplicación en otra región."
        },
        "Correct Answer": "Desplegar la aplicación en múltiples instancias de EC2 en diferentes Zonas de Disponibilidad y usar un Elastic Load Balancer para distribuir el tráfico.",
        "Explanation": "Desplegar la aplicación en múltiples instancias de EC2 en diferentes Zonas de Disponibilidad y usar un Elastic Load Balancer asegura que si una Zona de Disponibilidad se vuelve no disponible, el tráfico aún pueda ser dirigido a instancias en las otras Zonas de Disponibilidad, proporcionando así alta disponibilidad y minimizando el tiempo de inactividad.",
        "Other Options": [
            "Crear una réplica de lectura de Amazon RDS en una Zona de Disponibilidad diferente solo aborda la capa de base de datos y no proporciona alta disponibilidad para toda la aplicación, que aún podría fallar si la instancia principal de la aplicación se vuelve no disponible.",
            "Implementar Amazon Route 53 con una política de enrutamiento de conmutación por error podría redirigir el tráfico a una instancia secundaria, pero este enfoque no gestiona activamente el balanceo de carga ni proporciona conmutación por error en tiempo real para la aplicación, lo que podría llevar a un tiempo de inactividad potencial de la aplicación.",
            "Configurar una pila de CloudFormation para recrear la aplicación en una Zona de Disponibilidad diferente introduce complejidad y puede no proporcionar capacidades de conmutación por error inmediatas, lo que podría dejar la aplicación vulnerable durante el proceso de recreación."
        ]
    },
    {
        "Question Number": "40",
        "Situation": "Una empresa de servicios financieros está diseñando una nueva aplicación de múltiples niveles alojada en AWS. Esta aplicación maneja datos sensibles de clientes y debe cumplir con estrictos requisitos de confiabilidad. La arquitectura consiste en una capa web basada en Amazon EC2, un balanceador de carga y una base de datos Amazon RDS en el backend. La empresa quiere asegurar alta disponibilidad y tolerancia a fallos para la aplicación a través de múltiples Zonas de Disponibilidad. También están considerando cómo manejar la posible pérdida de datos y asegurar que la aplicación pueda recuperarse rápidamente de las interrupciones. ¿Qué estrategias debería implementar la empresa?",
        "Question": "¿Cuál de las siguientes estrategias ayudará a cumplir con los requisitos de confiabilidad? (Seleccione dos)",
        "Options": {
            "1": "Desplegar la capa web en instancias de Amazon EC2 en múltiples Zonas de Disponibilidad con un Elastic Load Balancer.",
            "2": "Utilizar implementaciones Multi-AZ de Amazon RDS para la base de datos del backend para asegurar soporte de conmutación por error.",
            "3": "Implementar una única instancia de EC2 para la capa web para reducir costos y complejidad.",
            "4": "Utilizar S3 para copias de seguridad de la base de datos RDS para permitir una rápida recuperación de datos.",
            "5": "Configurar un grupo de Auto Scaling para la capa web para manejar picos de tráfico y asegurar disponibilidad."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Desplegar la capa web en instancias de Amazon EC2 en múltiples Zonas de Disponibilidad con un Elastic Load Balancer.",
            "Utilizar implementaciones Multi-AZ de Amazon RDS para la base de datos del backend para asegurar soporte de conmutación por error."
        ],
        "Explanation": "La primera respuesta correcta asegura que la capa web esté distribuida a través de múltiples Zonas de Disponibilidad, proporcionando redundancia y alta disponibilidad. La segunda respuesta correcta garantiza que la base de datos RDS pueda conmutar automáticamente a una instancia de reserva en otra Zona de Disponibilidad, asegurando un tiempo de inactividad y pérdida de datos mínimos.",
        "Other Options": [
            "Esta opción carece de redundancia y crearía un único punto de falla, lo que no cumple con los requisitos de confiabilidad.",
            "Si bien las copias de seguridad son importantes, no proporcionan capacidades de conmutación por error inmediatas, que son esenciales para cumplir con los requisitos de alta disponibilidad.",
            "Esta opción ayuda con la gestión del tráfico, pero no aborda la necesidad de alta disponibilidad a través de las Zonas de Disponibilidad para la capa web."
        ]
    },
    {
        "Question Number": "41",
        "Situation": "Una empresa está migrando sus datos locales a AWS y quiere optimizar los costos de transferencia de datos durante el proceso de migración. Están considerando las diferentes opciones disponibles para transferir grandes cantidades de datos a Amazon S3 y están preocupados por los costos asociados con las tarifas de transferencia de datos.",
        "Question": "¿Cuál de las siguientes estrategias minimizaría mejor los costos de transferencia de datos al migrar grandes volúmenes de datos a Amazon S3?",
        "Options": {
            "1": "Utilizar Amazon Direct Connect para la transferencia continua de datos a S3.",
            "2": "Subir los datos directamente a S3 utilizando la AWS CLI a través de Internet.",
            "3": "Transferir datos primero a Amazon EC2 y luego copiarlos a S3.",
            "4": "Usar AWS Snowball para transferir datos físicamente a AWS."
        },
        "Correct Answer": "Usar AWS Snowball para transferir datos físicamente a AWS.",
        "Explanation": "Utilizar AWS Snowball permite la transferencia física de grandes conjuntos de datos a AWS, lo que minimiza los costos de transferencia de datos asociados con la transferencia de grandes volúmenes de datos a través de Internet. Snowball es especialmente rentable para migraciones a gran escala, evitando costosos cargos por ancho de banda.",
        "Other Options": [
            "Subir los datos directamente a S3 utilizando la AWS CLI a través de Internet puede incurrir en costos significativos de transferencia de datos, especialmente con grandes cantidades de datos, ya que depende del ancho de banda de Internet público.",
            "Transferir datos primero a Amazon EC2 y luego copiarlos a S3 no aborda la preocupación principal de reducir los costos de transferencia de datos y puede introducir cargos adicionales por la transferencia de datos desde la instancia de EC2.",
            "Utilizar Amazon Direct Connect puede reducir los costos de transferencia de datos continuos para transferencias grandes consistentes, pero requiere una configuración que puede ser costosa y llevar tiempo, lo que la hace menos ideal para migraciones masivas iniciales."
        ]
    },
    {
        "Question Number": "42",
        "Situation": "Una empresa de servicios financieros está diseñando una capa de caché para su aplicación de trading de alta frecuencia. Requieren una solución de caché que pueda manejar grandes conjuntos de datos de manera eficiente y permitir una escalabilidad rápida basada en la demanda fluctuante. El equipo también prefiere una arquitectura sencilla sin complejidades como cifrado o persistencia de datos. Dadas estas necesidades, el arquitecto de soluciones necesita elegir una solución de caché apropiada.",
        "Question": "¿Qué solución de caché debería elegir el arquitecto de soluciones para cumplir con los requisitos de la empresa?",
        "Options": {
            "1": "Elegir Memcached ya que ofrece una arquitectura simple y soporta el uso de múltiples núcleos para nodos grandes.",
            "2": "Optar por una solución de caché basada en disco que pueda persistir datos y proporcione cifrado.",
            "3": "Usar Redis por sus estructuras de datos avanzadas y características de persistencia, incluso si no son necesarias.",
            "4": "Implementar Amazon ElastiCache con Redis y configurarlo para alta disponibilidad."
        },
        "Correct Answer": "Elegir Memcached ya que ofrece una arquitectura simple y soporta el uso de múltiples núcleos para nodos grandes.",
        "Explanation": "Memcached es la opción ideal para este escenario ya que proporciona un modelo de caché simple, no requiere cifrado y utiliza eficazmente múltiples núcleos, lo que permite un rendimiento óptimo en el manejo de nodos grandes. Además, soporta la escalabilidad hacia afuera y hacia adentro según la demanda.",
        "Other Options": [
            "Redis, aunque poderoso, introduce complejidad que es innecesaria dado los requisitos de simplicidad de la empresa y la falta de necesidad de sus características avanzadas.",
            "Implementar Redis con alta disponibilidad añadiría complejidad innecesaria y potencial costo, ya que la empresa busca una solución sencilla sin necesidad de persistencia o configuraciones avanzadas.",
            "Una solución de caché basada en disco no es adecuada ya que contradice los requisitos de simplicidad y escalabilidad rápida, y la empresa declaró explícitamente que no necesita persistencia de datos."
        ]
    },
    {
        "Question Number": "43",
        "Situation": "Una empresa de servicios financieros procesa datos sensibles de clientes y debe cumplir con estrictos requisitos regulatorios en materia de protección de datos. Necesitan implementar cifrado tanto para los datos en reposo como para los datos en tránsito. La empresa busca una solución efectiva que garantice la confidencialidad e integridad de sus datos a lo largo de su ciclo de vida.",
        "Question": "¿Cuál de las siguientes soluciones de cifrado debería implementar la empresa para cumplir con los requisitos de datos en reposo y datos en tránsito?",
        "Options": {
            "1": "Implementar AWS Secrets Manager para cifrar información sensible y usar AWS Direct Connect para la transferencia segura de datos entre las instalaciones y AWS.",
            "2": "Usar AWS Key Management Service (KMS) para crear y gestionar claves de cifrado para objetos de Amazon S3 y habilitar SSL/TLS para datos transmitidos a través de Internet.",
            "3": "Configurar el cifrado del lado del servidor de Amazon S3 con una solución de gestión de claves personalizada y establecer una VPN para la transmisión segura de datos.",
            "4": "Utilizar Amazon RDS con almacenamiento cifrado y habilitar conexiones cifradas usando autenticación IAM para datos transmitidos entre la aplicación y la base de datos."
        },
        "Correct Answer": "Usar AWS Key Management Service (KMS) para crear y gestionar claves de cifrado para objetos de Amazon S3 y habilitar SSL/TLS para datos transmitidos a través de Internet.",
        "Explanation": "Usar AWS Key Management Service (KMS) permite a la empresa gestionar las claves de cifrado de manera efectiva mientras asegura que los datos en reposo en Amazon S3 estén cifrados. Además, habilitar SSL/TLS garantiza que los datos en tránsito estén cifrados, cumpliendo así con los requisitos regulatorios de protección de datos.",
        "Other Options": [
            "Si bien usar Amazon RDS con almacenamiento cifrado proporciona cifrado para datos en reposo, la autenticación IAM no cifra directamente los datos en tránsito; simplemente autoriza el acceso, lo que hace que esta opción sea incompleta para las necesidades de la empresa.",
            "AWS Secrets Manager está diseñado para gestionar secretos en lugar de cifrar datos en reposo o datos en tránsito de manera integral. AWS Direct Connect, aunque es seguro, no proporciona cifrado por sí mismo, lo que no cumple completamente con el requisito.",
            "El cifrado del lado del servidor de Amazon S3 puede asegurar datos en reposo, pero usar una solución de gestión de claves personalizada puede introducir complejidad y posibles problemas de cumplimiento. Una VPN puede asegurar datos en tránsito, pero no garantiza el cifrado de datos en tránsito a través de Internet."
        ]
    },
    {
        "Question Number": "44",
        "Situation": "Una empresa de servicios financieros está planeando migrar sus aplicaciones de un centro de datos local a AWS utilizando AWS Application Migration Service (AWS MGN). La empresa tiene múltiples aplicaciones heredadas que requieren un tiempo de inactividad mínimo durante la transición. Han especificado que desean un enfoque que automatice el proceso de migración y reduzca el riesgo de errores comúnmente asociados con migraciones manuales.",
        "Question": "¿Cuál de las siguientes estrategias utiliza mejor AWS Application Migration Service (AWS MGN) para este escenario y asegura una migración lift-and-shift fluida mientras optimiza la aplicación para la nube?",
        "Options": {
            "1": "La empresa debería primero refactorizar sus aplicaciones para que sean nativas de la nube antes de usar AWS MGN, lo que permitirá una migración más fluida y una mejor optimización en el entorno de AWS.",
            "2": "La empresa debería usar el enfoque de instantánea sin agente de AWS MGN para crear una instantánea única de cada servidor, luego transferir manualmente las aplicaciones a AWS, permitiendo una rápida migración lift-and-shift.",
            "3": "La empresa debería instalar el agente de AWS MGN en cada servidor de origen para replicar datos continuamente, permitiendo un tiempo de inactividad mínimo durante el cambio mientras asegura que las aplicaciones se migren en su estado original.",
            "4": "La empresa debería utilizar el enfoque de migración híbrida de AWS MGN ejecutando tanto los servidores locales como el entorno de AWS juntos durante un período prolongado, asegurando que las aplicaciones estén sincronizadas antes del cambio final."
        },
        "Correct Answer": "La empresa debería instalar el agente de AWS MGN en cada servidor de origen para replicar datos continuamente, permitiendo un tiempo de inactividad mínimo durante el cambio mientras asegura que las aplicaciones se migren en su estado original.",
        "Explanation": "Usar el agente de AWS MGN en cada servidor de origen permite la replicación continua de datos, reduciendo el tiempo de inactividad y minimizando los riesgos asociados con los procesos de migración manual. Esto asegura que las aplicaciones puedan ser migradas en su estado original y ayuda a mantener la continuidad del negocio durante la migración.",
        "Other Options": [
            "Usar un enfoque de instantánea sin agente solo crea una instantánea única, que puede no capturar cambios en curso y podría resultar en pérdida de datos o inconsistencias durante el proceso de migración.",
            "Refactorizar aplicaciones antes de usar AWS MGN no es necesario para una migración lift-and-shift. AWS MGN está diseñado específicamente para facilitar migraciones sin requerir cambios en las aplicaciones mismas.",
            "Utilizar un enfoque de migración híbrida puede complicar el proceso de migración y aumentar la duración de tener dos entornos funcionando simultáneamente, lo cual no es ideal para minimizar el tiempo de inactividad durante la migración lift-and-shift."
        ]
    },
    {
        "Question Number": "45",
        "Situation": "Una organización está experimentando problemas intermitentes de conectividad a un bucket de Amazon S3 desde varias aplicaciones que se ejecutan en instancias de EC2 a través de múltiples Zonas de Disponibilidad. Las aplicaciones están desplegadas en una Nube Privada Virtual (VPC) y utilizan puntos finales de VPC para acceder directamente al bucket de S3. La organización quiere identificar la causa raíz de los problemas de conectividad.",
        "Question": "¿Qué enfoque ayudará a la organización a solucionar los problemas de conectividad al bucket de S3 utilizando herramientas de AWS?",
        "Options": {
            "1": "Utilizar AWS Trusted Advisor para analizar la configuración del bucket de S3 e identificar cualquier configuración incorrecta.",
            "2": "Ejecutar las reglas de AWS Config para asegurar que las instancias de EC2 cumplan con las mejores prácticas para el acceso a S3.",
            "3": "Usar Amazon CloudWatch Logs para revisar los registros de la aplicación en busca de mensajes de error de tiempo de espera o conexión relacionados con el acceso a S3.",
            "4": "Habilitar los registros de flujo de VPC para las subredes que alojan las instancias de EC2 para monitorear el flujo de tráfico hacia y desde el bucket de S3."
        },
        "Correct Answer": "Habilitar los registros de flujo de VPC para las subredes que alojan las instancias de EC2 para monitorear el flujo de tráfico hacia y desde el bucket de S3.",
        "Explanation": "Habilitar los registros de flujo de VPC permite a la organización capturar información sobre el tráfico IP que va hacia y desde las instancias de EC2. Estos datos pueden ayudar a identificar si los problemas de conectividad se deben a configuraciones de red incorrectas, reglas de grupos de seguridad u otros factores que afectan el flujo de tráfico hacia el bucket de S3.",
        "Other Options": [
            "Usar Amazon CloudWatch Logs para revisar los registros de la aplicación puede proporcionar algunas ideas, pero no ofrece visibilidad sobre los problemas relacionados con la red que afectan directamente el acceso a S3.",
            "AWS Trusted Advisor proporciona principalmente recomendaciones de mejores prácticas y puede no diagnosticar directamente problemas de conectividad con recursos específicos como los buckets de S3.",
            "Ejecutar las reglas de AWS Config ayuda a asegurar el cumplimiento, pero no proporciona análisis de tráfico en tiempo real o registros que ayudarían a solucionar problemas de conectividad."
        ]
    },
    {
        "Question Number": "46",
        "Situation": "Una empresa de servicios financieros necesita asegurarse de que sus datos críticos se respalden regularmente y puedan restaurarse rápidamente en caso de un desastre. Actualmente utilizan Amazon S3 para almacenamiento, pero no están seguros sobre la mejor estrategia de respaldo para cumplir con sus objetivos de tiempo de recuperación (RTO) y objetivos de punto de recuperación (RPO).",
        "Question": "¿Qué estrategia de respaldo proporcionaría el método más eficiente y confiable para garantizar que los datos estén protegidos y puedan restaurarse rápidamente mientras se minimizan los costos?",
        "Options": {
            "1": "Utilizar Amazon Glacier para el almacenamiento a largo plazo de datos de respaldo y restaurar bajo demanda según sea necesario.",
            "2": "Crear un proceso de respaldo manual que copie datos de S3 a un servidor local cada noche.",
            "3": "Implementar AWS Backup para automatizar los horarios de respaldo y las políticas de retención para Amazon S3.",
            "4": "Configurar la replicación entre regiones para los buckets de S3 para garantizar la disponibilidad y redundancia de los datos."
        },
        "Correct Answer": "Implementar AWS Backup para automatizar los horarios de respaldo y las políticas de retención para Amazon S3.",
        "Explanation": "AWS Backup está diseñado para gestionar centralmente los respaldos a través de los servicios de AWS, permitiendo horarios de respaldo automatizados y políticas de retención. Esto asegura que los respaldos cumplan con los requisitos de RTO y RPO de manera efectiva mientras se minimizan los costos operativos y la sobrecarga asociada con procesos manuales.",
        "Other Options": [
            "Un proceso de respaldo manual introduce el riesgo de error humano, es intensivo en mano de obra y puede no garantizar respaldos oportunos, lo que podría violar los requisitos de RTO y RPO.",
            "Usar Amazon Glacier es adecuado para almacenamiento a largo plazo, pero no está optimizado para restauraciones rápidas, lo que podría llevar a retrasos inaceptables en la recuperación de datos críticos.",
            "La replicación entre regiones es efectiva para la disponibilidad y durabilidad de los datos, pero no aborda específicamente los horarios de respaldo o las políticas de retención, que son esenciales para cumplir con los objetivos de RTO y RPO."
        ]
    },
    {
        "Question Number": "47",
        "Situation": "Una empresa de comercio electrónico global está diseñando una aplicación web altamente disponible que debe cumplir con estrictos requisitos de tiempo de actividad mientras también acomoda la fluctuación en la demanda de los usuarios. La aplicación está alojada en AWS y debe ser resistente a fallos tanto regionales como de zona de disponibilidad. La empresa requiere una arquitectura que pueda escalar automáticamente los recursos según los patrones de tráfico.",
        "Question": "¿Qué combinación de estrategias de diseño debería implementar la empresa para lograr alta disponibilidad y escalabilidad para la aplicación? (Seleccione Dos)",
        "Options": {
            "1": "Usar Elastic Load Balancing con verificaciones de salud para distribuir el tráfico entre instancias en una sola Zona de Disponibilidad.",
            "2": "Aprovechar AWS Global Accelerator para mejorar la disponibilidad y el rendimiento de la aplicación a nivel global.",
            "3": "Implementar Amazon CloudFront como una red de entrega de contenido (CDN) para almacenar en caché contenido estático.",
            "4": "Utilizar un grupo de Auto Scaling con múltiples instancias de EC2 en múltiples Zonas de Disponibilidad.",
            "5": "Desplegar la aplicación en múltiples regiones de AWS y usar Amazon Route 53 para la conmutación por error de DNS."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Utilizar un grupo de Auto Scaling con múltiples instancias de EC2 en múltiples Zonas de Disponibilidad.",
            "Desplegar la aplicación en múltiples regiones de AWS y usar Amazon Route 53 para la conmutación por error de DNS."
        ],
        "Explanation": "Utilizar un grupo de Auto Scaling en múltiples Zonas de Disponibilidad asegura que la aplicación pueda escalar automáticamente según la demanda mientras mantiene alta disponibilidad. Desplegar en múltiples regiones de AWS con Route 53 para la conmutación por error de DNS proporciona una resiliencia adicional contra interrupciones regionales, contribuyendo a una arquitectura robusta.",
        "Other Options": [
            "Implementar Amazon CloudFront es beneficioso para el rendimiento, pero no aborda directamente los requisitos de alta disponibilidad y escalabilidad para los servicios de backend de la aplicación.",
            "Usar Elastic Load Balancing dentro de una sola Zona de Disponibilidad no proporciona la redundancia necesaria; si esa zona falla, la aplicación se volverá no disponible.",
            "Si bien AWS Global Accelerator puede mejorar el rendimiento y la disponibilidad, no proporciona inherentemente una arquitectura de alta disponibilidad sin servicios adicionales desplegados en múltiples regiones o zonas."
        ]
    },
    {
        "Question Number": "48",
        "Situation": "Una empresa está diseñando su entorno de AWS para mejorar la seguridad y controlar el acceso a sus recursos. El entorno consta de múltiples VPCs, cada una alojando diferentes aplicaciones. La empresa quiere implementar la segmentación de red de manera efectiva para aislar cargas de trabajo mientras permite conectividad específica entre VPCs.",
        "Question": "¿Qué enfoque proporcionará la MEJOR segmentación de red mientras permite una comunicación controlada entre las VPCs?",
        "Options": {
            "1": "Desplegar todas las aplicaciones en una sola VPC y utilizar ACLs de red para segmentar el tráfico según las necesidades de la aplicación.",
            "2": "Implementar AWS Transit Gateway para conectar múltiples VPCs mientras se mantiene el aislamiento y el control sobre el flujo de tráfico.",
            "3": "Crear VPCs separadas para cada aplicación y establecer conexiones de emparejamiento de VPC para permitir tráfico específico entre ellas.",
            "4": "Usar una sola VPC con múltiples subredes para todas las aplicaciones, configurando grupos de seguridad para controlar el tráfico entre ellas."
        },
        "Correct Answer": "Implementar AWS Transit Gateway para conectar múltiples VPCs mientras se mantiene el aislamiento y el control sobre el flujo de tráfico.",
        "Explanation": "Usar AWS Transit Gateway permite una conectividad centralizada entre múltiples VPCs, habilitando una comunicación controlada mientras se mantiene el aislamiento de cada VPC. Este enfoque simplifica la gestión y proporciona mejor escalabilidad en comparación con el emparejamiento directo de VPC.",
        "Other Options": [
            "Usar una sola VPC con múltiples subredes carece de aislamiento entre aplicaciones, aumentando el riesgo de acceso no intencionado y complicando la gestión de seguridad.",
            "Crear VPCs separadas con emparejamiento de VPC es un buen enfoque, pero puede llevar a configuraciones complejas a medida que aumenta el número de VPCs, y no escala tan eficientemente como Transit Gateway.",
            "Desplegar todas las aplicaciones en una sola VPC con ACLs de red no proporciona un aislamiento adecuado y puede llevar a desafíos de gestión a medida que el control del tráfico se vuelve excesivamente complicado."
        ]
    },
    {
        "Question Number": "49",
        "Situation": "Una corporación multinacional está aprovechando AWS Direct Connect para establecer una conexión de red dedicada desde su centro de datos local a sus VPCs de AWS. Requieren un alto rendimiento y baja latencia para sus aplicaciones que funcionan en múltiples regiones. La corporación tiene la intención de conectarse a una variedad de servicios de AWS como EC2 y S3, y también tiene requisitos de seguridad para garantizar que sus datos en tránsito estén cifrados. Dadas sus necesidades arquitectónicas, están evaluando sus opciones para configurar las conexiones de Direct Connect y las interfaces virtuales.",
        "Question": "¿Qué configuración satisfará mejor los requisitos de la corporación para un alto rendimiento, baja latencia y conexiones seguras a los servicios de AWS utilizando Direct Connect?",
        "Options": {
            "1": "Establecer una puerta de enlace de Direct Connect en una región pública. Configurar múltiples interfaces virtuales públicas para acceder a servicios como S3 y EC2 sin crear una VPN, que no cifra el tráfico.",
            "2": "Configurar una única conexión de Direct Connect con una interfaz virtual privada para conectarse a múltiples VPCs. Utilizar AWS Transit Gateway para el enrutamiento y confiar en AWS Shield para la protección contra DDoS sin implementar cifrado adicional.",
            "3": "Desplegar dos conexiones de Direct Connect en la misma ubicación, cada una con una interfaz virtual pública. Utilizar estas conexiones únicamente para acceder a servicios de AWS como S3 y EC2 sin emplear medidas de seguridad adicionales.",
            "4": "Crear dos conexiones de Direct Connect en diferentes ubicaciones. Utilizar interfaces virtuales privadas para conectarse a la puerta de enlace de Direct Connect, que puede enrutar el tráfico a las VPCs. Implementar una conexión VPN sobre la interfaz virtual pública para acceso seguro a S3 y EC2."
        },
        "Correct Answer": "Crear dos conexiones de Direct Connect en diferentes ubicaciones. Utilizar interfaces virtuales privadas para conectarse a la puerta de enlace de Direct Connect, que puede enrutar el tráfico a las VPCs. Implementar una conexión VPN sobre la interfaz virtual pública para acceso seguro a S3 y EC2.",
        "Explanation": "Esta opción cumple con todos los requisitos al utilizar dos conexiones de Direct Connect para alta disponibilidad y baja latencia, conectándose a múltiples VPCs a través de una puerta de enlace de Direct Connect, y asegurando que los datos en tránsito estén cifrados a través de una conexión VPN sobre la interfaz pública.",
        "Other Options": [
            "Esta opción solo proporciona una única conexión de Direct Connect, que no garantiza alta disponibilidad y puede llevar a un único punto de falla. Si bien utilizar una interfaz virtual privada es apropiado, confiar únicamente en AWS Transit Gateway sin cifrado no cumple con los requisitos de seguridad.",
            "Esta opción no satisface el requisito de cifrado ya que utiliza interfaces virtuales públicas sin una VPN. Además, no proporciona la alta disponibilidad necesaria para una arquitectura robusta, ya que está limitada a una puerta de enlace de Direct Connect en una región.",
            "Utilizar dos conexiones de Direct Connect en la misma ubicación no proporciona redundancia en diferentes áreas geográficas, lo cual es crítico para la alta disponibilidad. Además, confiar solo en interfaces virtuales públicas sin cifrado compromete la seguridad de los datos."
        ]
    },
    {
        "Question Number": "50",
        "Situation": "Una empresa de retail está planeando lanzar una nueva plataforma de comercio electrónico que experimentará un alto tráfico durante eventos de ventas y requerirá diferentes patrones de acceso para las interacciones con los clientes. La plataforma necesita soportar tanto operaciones de lectura intensiva para la navegación de productos como operaciones de escritura intensiva para el procesamiento de pedidos. Considerando la escalabilidad, la rentabilidad y el rendimiento, necesitas diseñar una arquitectura adecuada.",
        "Question": "¿Qué diseño arquitectónico apoyaría mejor los variados patrones de acceso y los altos requisitos de escalabilidad de la plataforma de comercio electrónico?",
        "Options": {
            "1": "Configurar una base de datos SQL tradicional en instancias de EC2 y escalar manualmente los recursos durante los picos de tráfico.",
            "2": "Utilizar Amazon RDS para todas las operaciones de base de datos y desplegar réplicas de lectura para manejar el alto tráfico de lectura.",
            "3": "Usar Amazon Aurora con una configuración de multi-maestro para soportar tanto operaciones de lectura como de escritura de manera uniforme a través de múltiples instancias.",
            "4": "Implementar Amazon DynamoDB con modo de capacidad bajo demanda para manejar cargas de trabajo variables y un bucket de Amazon S3 separado para activos estáticos."
        },
        "Correct Answer": "Implementar Amazon DynamoDB con modo de capacidad bajo demanda para manejar cargas de trabajo variables y un bucket de Amazon S3 separado para activos estáticos.",
        "Explanation": "Amazon DynamoDB con modo de capacidad bajo demanda ajusta automáticamente su rendimiento según el tráfico, lo que lo hace ideal para cargas de trabajo variables típicas de plataformas de comercio electrónico. Además, usar Amazon S3 para activos estáticos ayuda a descargar la entrega de imágenes y archivos, mejorando el rendimiento y reduciendo la carga en la base de datos.",
        "Other Options": [
            "Si bien Amazon RDS con réplicas de lectura puede manejar operaciones de lectura intensiva, puede no escalar de manera efectiva durante picos de tráfico repentinos. También requiere intervención manual para escalar operaciones de escritura, lo que puede llevar a cuellos de botella en el rendimiento.",
            "Amazon Aurora con una configuración de multi-maestro proporciona alta disponibilidad, pero puede ser complejo y costoso de gestionar, especialmente para una nueva plataforma de comercio electrónico. Esta opción puede no ser necesaria dado los requisitos para patrones de acceso variados.",
            "Usar una base de datos SQL tradicional en instancias de EC2 carece de la escalabilidad y gestión automatizada que ofrecen las arquitecturas modernas nativas de la nube. Requiere un esfuerzo manual significativo para escalar y puede no manejar el alto tráfico de manera eficiente."
        ]
    },
    {
        "Question Number": "51",
        "Situation": "Una empresa ha desplegado una aplicación sin servidor utilizando funciones de AWS Lambda que necesitan acceder a recursos dentro de una VPC privada. La aplicación está experimentando un aumento en los errores de invocación, específicamente EC2ThrottledException, a medida que el tráfico ha aumentado. El arquitecto de soluciones necesita asegurarse de que la función Lambda pueda escalar de manera efectiva sin alcanzar los límites.",
        "Question": "¿Qué debería hacer el arquitecto de soluciones para resolver los errores de invocación mientras mantiene la escalabilidad de la función Lambda?",
        "Options": {
            "1": "Mover la función Lambda fuera de la VPC para mejorar la escalabilidad.",
            "2": "Crear una VPC más grande con más subredes para acomodar la función Lambda.",
            "3": "Aumentar el número de ENIs disponibles y asegurar suficientes direcciones IP en la subred.",
            "4": "Usar múltiples funciones Lambda para distribuir la carga entre diferentes VPCs."
        },
        "Correct Answer": "Aumentar el número de ENIs disponibles y asegurar suficientes direcciones IP en la subred.",
        "Explanation": "Al aumentar el número de Interfaces de Red Elásticas (ENIs) disponibles y asegurarse de que haya suficientes direcciones IP disponibles en la subred, la función Lambda puede escalar de manera efectiva dentro de la VPC, reduciendo los errores de invocación relacionados con la limitación.",
        "Other Options": [
            "Mover la función Lambda fuera de la VPC comprometería su capacidad para acceder a los recursos de la VPC privada, lo cual es esencial para el funcionamiento de la aplicación.",
            "Usar múltiples funciones Lambda en diferentes VPCs complicaría la arquitectura y podría introducir latencia adicional y sobrecarga de gestión sin resolver las limitaciones de ENI.",
            "Crear una VPC más grande con más subredes no aborda directamente el problema de las ENIs insuficientes o las direcciones IP dentro de las subredes existentes, y puede no ser una solución viable."
        ]
    },
    {
        "Question Number": "52",
        "Situation": "Una empresa está buscando optimizar sus costos de AWS mientras asegura tener visibilidad sobre sus patrones de gasto. El equipo de finanzas ha sido encargado de identificar cualquier posible exceso de gasto y asegurar que se cumplan los presupuestos futuros. Quieren utilizar herramientas de AWS que les ayuden a monitorear el uso y los costos de manera efectiva sin incurrir en cargos adicionales.",
        "Question": "¿Qué combinación de herramientas de AWS proporcionaría al equipo de finanzas la mejor visión general de los patrones de gasto, ayudaría a identificar el exceso de gasto y les permitiría establecer presupuestos para el uso futuro?",
        "Options": {
            "1": "Utilizar AWS Cost Explorer para visualizar las tendencias de uso y costo, y configurar AWS Budgets para monitorear y alertar sobre los umbrales del presupuesto.",
            "2": "Aprovechar AWS Budgets exclusivamente para rastrear los límites de gasto mientras se confía en los registros de AWS CloudTrail para el análisis de uso.",
            "3": "Implementar AWS Trusted Advisor para verificar recomendaciones de optimización de costos y utilizar el AWS Pricing Calculator para estimar los costos de proyectos futuros.",
            "4": "Desplegar AWS Trusted Advisor e integrarlo con AWS Config para monitorear continuamente el cumplimiento relacionado con la gestión de costos."
        },
        "Correct Answer": "Utilizar AWS Cost Explorer para visualizar las tendencias de uso y costo, y configurar AWS Budgets para monitorear y alertar sobre los umbrales del presupuesto.",
        "Explanation": "Esta combinación de AWS Cost Explorer y AWS Budgets proporciona una solución integral para monitorear y gestionar costos. Cost Explorer permite un análisis visual de los patrones de gasto, mientras que Budgets permite un seguimiento proactivo del gasto en relación con límites predefinidos, asegurando que el equipo de finanzas pueda identificar el exceso de gasto de manera temprana.",
        "Other Options": [
            "Si bien AWS Trusted Advisor proporciona recomendaciones útiles para la optimización de costos, no ofrece el mismo nivel de análisis histórico detallado que AWS Cost Explorer. El AWS Pricing Calculator es útil para estimar costos, pero no ayuda a monitorear los costos en curso de manera efectiva.",
            "Usar AWS Budgets por sí solo no proporciona visibilidad sobre las tendencias de gasto. Los registros de AWS CloudTrail rastrean las llamadas a la API, pero no ofrecen una vista general de costo o uso, lo que lo hace menos efectivo para el cumplimiento del presupuesto y la identificación de excesos de gasto.",
            "AWS Trusted Advisor ofrece información, pero no proporciona monitoreo continuo para el cumplimiento de la gestión de costos. AWS Config se centra en el cumplimiento de la configuración de recursos en lugar de la gestión de costos, lo que hace que esta combinación sea menos efectiva para los objetivos del equipo de finanzas."
        ]
    },
    {
        "Question Number": "53",
        "Situation": "Una empresa de servicios financieros está construyendo un sistema de procesamiento de transacciones en tiempo real utilizando AWS Lambda, Kinesis Data Streams y Amazon DynamoDB. Se espera que el sistema maneje altos volúmenes de transacciones por segundo, requiriendo un procesamiento de datos eficiente y una latencia mínima. Los desarrolladores quieren optimizar el comportamiento de agrupamiento de sus funciones Lambda para asegurarse de que procesen registros rápidamente mientras maximizan el rendimiento. Están particularmente preocupados por la configuración de los parámetros MaximumBatchingWindowInSeconds y BatchSize para su mapeo de origen de eventos de Kinesis.",
        "Question": "¿Cuál de las siguientes configuraciones optimizaría mejor el comportamiento de agrupamiento para el procesamiento de Lambda de los flujos de datos de Kinesis en este escenario?",
        "Options": {
            "1": "Establecer MaximumBatchingWindowInSeconds en 0 segundos y BatchSize en 1000 registros para asegurar una latencia mínima y un rendimiento máximo.",
            "2": "Establecer MaximumBatchingWindowInSeconds en 500 milisegundos y BatchSize en 500 registros para equilibrar latencia y rendimiento.",
            "3": "Establecer MaximumBatchingWindowInSeconds en 300 segundos y BatchSize en 300 registros para maximizar la ventana de agrupamiento.",
            "4": "Establecer MaximumBatchingWindowInSeconds en 100 milisegundos y BatchSize en 10 registros para reducir el tiempo de procesamiento."
        },
        "Correct Answer": "Establecer MaximumBatchingWindowInSeconds en 0 segundos y BatchSize en 1000 registros para asegurar una latencia mínima y un rendimiento máximo.",
        "Explanation": "Establecer MaximumBatchingWindowInSeconds en 0 segundos permite que Lambda procese los registros inmediatamente a medida que llegan, lo cual es crucial para el procesamiento de transacciones en tiempo real. Un BatchSize de 1000 registros maximiza el rendimiento al permitir que la función maneje un mayor número de registros en cada invocación. Esta configuración es óptima para escenarios de alto volumen como el procesamiento de transacciones.",
        "Other Options": [
            "Establecer MaximumBatchingWindowInSeconds en 500 milisegundos y BatchSize en 500 registros puede introducir una latencia innecesaria, ya que la función esperaría medio segundo antes de procesar, lo que podría retrasar el procesamiento de los registros entrantes.",
            "Establecer MaximumBatchingWindowInSeconds en 300 segundos es excesivo para el procesamiento en tiempo real, ya que retrasa significativamente el procesamiento de registros. Un BatchSize de 300 registros puede no utilizar completamente las capacidades de rendimiento del flujo de Kinesis en escenarios de alto volumen.",
            "Establecer MaximumBatchingWindowInSeconds en 100 milisegundos y BatchSize en 10 registros no aprovecha el rendimiento disponible de Kinesis. Esta configuración probablemente llevaría a una subutilización de recursos y a un aumento de la latencia."
        ]
    },
    {
        "Question Number": "54",
        "Situation": "Una aplicación móvil experimenta problemas de latencia al recuperar datos de varios microservicios desplegados en AWS. La aplicación utiliza AWS API Gateway para gestionar las solicitudes y respuestas de la API. Actualmente, la configuración de API Gateway emplea funciones Lambda para el procesamiento en el backend, pero los usuarios están reportando tiempos de respuesta lentos. La arquitectura está diseñada para manejar una base de usuarios global con diversas condiciones de red, y el equipo de desarrollo quiere optimizar el rendimiento sin comprometer la seguridad o aumentar significativamente los costos.",
        "Question": "¿Cuál es la forma más efectiva de mejorar el rendimiento de la configuración de API Gateway para esta aplicación móvil?",
        "Options": {
            "1": "Desplegar un Elastic Load Balancer (ELB) dedicado frente al API Gateway para distribuir las solicitudes entrantes de manera más uniforme entre los microservicios, mejorando los tiempos de respuesta.",
            "2": "Utilizar la función de caché integrada de API Gateway para almacenar datos de acceso frecuente para la aplicación móvil, minimizando las llamadas a Lambda y reduciendo la latencia general.",
            "3": "Implementar CloudFront frente al API Gateway para almacenar en caché las respuestas y reducir la latencia para usuarios globales, mientras se utilizan encabezados de control de caché personalizados para contenido dinámico.",
            "4": "Aumentar la configuración de tiempo de espera del API Gateway para permitir tiempos de procesamiento más largos para las solicitudes, asegurando que todas las respuestas se devuelvan incluso si tardan más en procesarse."
        },
        "Correct Answer": "Implementar CloudFront frente al API Gateway para almacenar en caché las respuestas y reducir la latencia para usuarios globales, mientras se utilizan encabezados de control de caché personalizados para contenido dinámico.",
        "Explanation": "Implementar CloudFront frente al API Gateway permite almacenar en caché las respuestas, lo que reduce significativamente la latencia para usuarios en diferentes regiones. Esto es particularmente beneficioso para una base de usuarios global, ya que aprovecha las ubicaciones de borde para entregar contenido rápidamente sin tener que acceder repetidamente a los servicios backend, optimizando así el rendimiento de manera efectiva.",
        "Other Options": [
            "Aumentar la configuración de tiempo de espera del API Gateway no aborda la causa raíz de la latencia y puede llevar a tiempos de espera más largos para los usuarios sin garantizar respuestas más rápidas.",
            "Desplegar un Elastic Load Balancer (ELB) dedicado frente al API Gateway es innecesario y puede introducir complejidad y costos adicionales, ya que API Gateway ya está diseñado para manejar solicitudes de manera eficiente.",
            "Utilizar la función de caché integrada de API Gateway es beneficioso, pero puede no ser tan efectivo como aprovechar CloudFront para una base de usuarios global, especialmente para contenido dinámico que requiere estrategias de caché sofisticadas."
        ]
    },
    {
        "Question Number": "55",
        "Situation": "Una empresa de servicios financieros está buscando conectar su centro de datos local a múltiples VPC de AWS en diferentes regiones utilizando AWS Direct Connect. Requieren una solución que permita una conexión privada mientras se mantiene la flexibilidad en el enrutamiento del tráfico a varias VPC en diferentes cuentas. El arquitecto debe asegurarse de que la solución cumpla con las mejores prácticas de AWS para Direct Connect y conectividad de VPC.",
        "Question": "¿Cuál de las siguientes configuraciones debería implementar el Arquitecto de Soluciones para cumplir con los requisitos de la empresa?",
        "Options": {
            "1": "Crear una conexión de Direct Connect y una puerta de enlace de Direct Connect. Adjuntar la puerta de enlace a las puertas de enlace privadas virtuales de las VPC en diferentes cuentas y regiones. Crear interfaces virtuales privadas para la puerta de enlace de Direct Connect para cada VPC.",
            "2": "Crear una conexión de Direct Connect con una interfaz virtual pública para acceder a los servicios de AWS. Configurar emparejamiento de VPC entre las VPC para habilitar la comunicación.",
            "3": "Utilizar AWS Transit Gateway para crear un hub de enrutamiento centralizado. Conectar el centro de datos local al Transit Gateway con una conexión de Direct Connect y configurar adjuntos de VPC para múltiples VPC en diferentes cuentas.",
            "4": "Establecer una conexión de Direct Connect y crear interfaces virtuales privadas directamente para cada VPC sin usar una puerta de enlace de Direct Connect, permitiendo un enrutamiento directo."
        },
        "Correct Answer": "Crear una conexión de Direct Connect y una puerta de enlace de Direct Connect. Adjuntar la puerta de enlace a las puertas de enlace privadas virtuales de las VPC en diferentes cuentas y regiones. Crear interfaces virtuales privadas para la puerta de enlace de Direct Connect para cada VPC.",
        "Explanation": "Utilizar una puerta de enlace de Direct Connect permite la conectividad privada a múltiples VPC en diferentes cuentas y regiones, cumpliendo con las mejores prácticas para Direct Connect. Permite la creación de interfaces virtuales privadas adaptadas para cada VPC, asegurando un enrutamiento seguro y eficiente.",
        "Other Options": [
            "Esta opción sugiere incorrectamente usar una interfaz virtual pública, que no es adecuada para la conectividad privada a VPC en diferentes cuentas y regiones. Las puertas de enlace de Direct Connect están diseñadas específicamente para interfaces virtuales privadas.",
            "Si bien usar un Transit Gateway simplifica el enrutamiento, esta opción no aborda directamente el requisito de una interfaz virtual privada para conectarse a múltiples VPC en diferentes cuentas. Aún se necesita una puerta de enlace de Direct Connect para conexiones privadas.",
            "Esta opción es incorrecta ya que elude el uso de una puerta de enlace de Direct Connect. Las puertas de enlace de Direct Connect son necesarias para crear interfaces virtuales privadas a múltiples VPC, especialmente cuando están en diferentes cuentas."
        ]
    },
    {
        "Question Number": "56",
        "Situation": "Una empresa está implementando una aplicación de múltiples capas en AWS que requiere actualizaciones y parches regulares para garantizar la seguridad y el cumplimiento. La aplicación se ejecuta en una flota de instancias de Amazon EC2 gestionadas por grupos de Auto Scaling. La empresa busca un proceso robusto para automatizar el parcheo de sus instancias mientras minimiza el tiempo de inactividad y asegura que la aplicación permanezca disponible durante las actualizaciones.",
        "Question": "¿Cuál de las siguientes opciones debería implementar el Arquitecto de Soluciones para diseñar un proceso efectivo de parches y actualizaciones? (Seleccione Dos)",
        "Options": {
            "1": "Aprovechar AWS Elastic Beanstalk para gestionar el entorno de la aplicación y aplicar parches como parte del proceso de implementación.",
            "2": "Usar AWS OpsWorks Stacks para definir una receta de Chef personalizada que maneje específicamente el parcheo y las actualizaciones para las instancias de EC2.",
            "3": "Utilizar AWS Systems Manager Patch Manager para automatizar el parcheo de las instancias de EC2 durante ventanas de mantenimiento especificadas.",
            "4": "Crear una alarma de Amazon CloudWatch que active una función Lambda para ejecutar el proceso de parcheo en todas las instancias de EC2 simultáneamente.",
            "5": "Implementar un gancho de ciclo de vida de Auto Scaling para pausar el proceso de terminación de instancias durante la fase de parcheo para asegurar que no se pierdan instancias."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Utilizar AWS Systems Manager Patch Manager para automatizar el parcheo de las instancias de EC2 durante ventanas de mantenimiento especificadas.",
            "Aprovechar AWS Elastic Beanstalk para gestionar el entorno de la aplicación y aplicar parches como parte del proceso de implementación."
        ],
        "Explanation": "Utilizar AWS Systems Manager Patch Manager permite la automatización de procesos de parcheo basados en ventanas de mantenimiento definidas, asegurando que las instancias sean parchadas de manera controlada. Además, AWS Elastic Beanstalk proporciona soporte integrado para gestionar actualizaciones de aplicaciones, permitiendo que los parches se integren en el proceso de implementación sin problemas, minimizando así el tiempo de inactividad.",
        "Other Options": [
            "Crear una alarma de Amazon CloudWatch que active una función Lambda para parchear todas las instancias de EC2 simultáneamente puede llevar a un posible tiempo de inactividad y interrupción del servicio. Este enfoque carece de control sobre el proceso de parcheo y puede no asegurar alta disponibilidad durante las actualizaciones.",
            "Implementar un gancho de ciclo de vida de Auto Scaling para pausar el proceso de terminación de instancias no facilita directamente el proceso de parcheo. Simplemente retrasa la terminación de instancias pero no automatiza el parcheo en sí.",
            "Usar AWS OpsWorks Stacks para definir una receta de Chef personalizada para el parcheo es una opción viable, pero introduce complejidad y requiere mantenimiento continuo de las recetas de Chef. Puede no ser el enfoque más eficiente o directo en comparación con el uso de Patch Manager."
        ]
    },
    {
        "Question Number": "57",
        "Situation": "Una plataforma de comercio electrónico está planeando usar Amazon DynamoDB para almacenar datos de sesión de usuario debido a su escalabilidad y rendimiento de baja latencia. El arquitecto de soluciones tiene la tarea de asegurar que la arquitectura pueda manejar picos repentinos de tráfico durante eventos de ventas. El arquitecto necesita elegir una configuración adecuada de capacidad de lectura y escritura para la tabla de DynamoDB para cumplir con estos requisitos.",
        "Question": "¿Cuál de las siguientes configuraciones debería implementar el arquitecto de soluciones para asegurar un rendimiento óptimo durante el tráfico pico mientras minimiza costos durante la operación normal?",
        "Options": {
            "1": "Capacidad provisionada con autoescalado habilitado para ajustarse según los patrones de tráfico.",
            "2": "Modo de capacidad bajo demanda para escalar automáticamente hacia arriba y hacia abajo según el tráfico sin intervención manual.",
            "3": "Usar una capa de caché frente a DynamoDB para manejar todas las solicitudes de lectura y provisionar baja capacidad de escritura.",
            "4": "Capacidad provisionada con una alta capacidad de lectura y escritura fija establecida para manejar cargas pico en todo momento."
        },
        "Correct Answer": "Modo de capacidad bajo demanda para escalar automáticamente hacia arriba y hacia abajo según el tráfico sin intervención manual.",
        "Explanation": "El modo de capacidad bajo demanda está diseñado para manejar cargas de trabajo impredecibles y escala automáticamente hacia arriba y hacia abajo según el tráfico real. Esto lo hace ideal para manejar picos repentinos de tráfico mientras permite ahorros de costos durante la operación normal.",
        "Other Options": [
            "La capacidad provisionada con autoescalado podría funcionar, pero requiere una configuración y monitoreo cuidadosos para asegurar que responda lo suficientemente rápido a los picos, lo que podría llevar a limitaciones si no se configura correctamente.",
            "La capacidad provisionada con una alta capacidad de lectura y escritura fija incurre en costos innecesarios durante períodos de bajo tráfico, ya que los recursos están reservados independientemente del uso real.",
            "Usar una capa de caché puede reducir la carga de lectura en DynamoDB, pero no aborda el problema de la capacidad de escritura. Podría complicar la arquitectura sin proporcionar una solución completa para manejar picos de tráfico."
        ]
    },
    {
        "Question Number": "58",
        "Situation": "Una organización de salud está ejecutando múltiples aplicaciones en AWS que procesan datos sensibles de pacientes. Necesitan asegurarse de que sus datos cumplan con las regulaciones y que cualquier incidente de seguridad se remedie rápidamente. La organización ha identificado que varios roles de IAM tienen permisos excesivos y quieren implementar una solución para rectificar este problema sin causar interrupciones en el servicio.",
        "Question": "¿Qué técnica de remediación debería implementar el arquitecto de soluciones para abordar los permisos excesivos de IAM mientras asegura un impacto mínimo en las aplicaciones?",
        "Options": {
            "1": "Implementar AWS CloudTrail para registrar todas las acciones de IAM y luego revisar los registros antes de realizar cualquier cambio de permisos para asegurar que no ocurra ninguna interrupción.",
            "2": "Programar una revisión de los permisos de IAM cada seis meses para identificar y reducir los permisos excesivos sin cambios inmediatos.",
            "3": "Crear nuevos roles de IAM con el menor privilegio y hacer una transición gradual de las aplicaciones para usar estos roles mientras se monitorean posibles problemas de acceso.",
            "4": "Eliminar inmediatamente todos los permisos excesivos de los roles de IAM existentes, asegurando que ningún rol tenga más permisos de los necesarios."
        },
        "Correct Answer": "Crear nuevos roles de IAM con el menor privilegio y hacer una transición gradual de las aplicaciones para usar estos roles mientras se monitorean posibles problemas de acceso.",
        "Explanation": "Crear nuevos roles de IAM con el menor privilegio permite a la organización mantener la continuidad del servicio mientras se reduce el riesgo de permisos excesivos. La transición gradual asegura que cualquier problema de acceso pueda ser detectado y resuelto sin afectar las aplicaciones.",
        "Other Options": [
            "Eliminar inmediatamente los permisos excesivos podría llevar a fallos en las aplicaciones si los roles pierden acceso crítico. Este enfoque no permite pruebas ni monitoreo antes de realizar cambios.",
            "Si bien AWS CloudTrail es útil para el registro y la auditoría, depender únicamente de los registros para revisar los permisos retrasa el proceso de remediación y no reduce activamente el riesgo de permisos excesivos.",
            "Programar una revisión cada seis meses no proporciona una remediación oportuna de los riesgos de seguridad. Se necesita acción inmediata para abordar el problema de los permisos excesivos."
        ]
    },
    {
        "Question Number": "59",
        "Situation": "Una empresa de medios necesita almacenar grandes archivos de video que se acceden con frecuencia durante las primeras semanas de su lanzamiento, pero una vez que el interés inicial disminuye, el acceso a estos archivos cae significativamente. La empresa planea mantener estos archivos de video durante un mínimo de tres años y busca minimizar los costos de almacenamiento.",
        "Question": "¿Cuál de las siguientes clases de almacenamiento de S3 proporcionaría la solución más rentable para almacenar estos archivos de video mientras cumple con los requisitos de acceso y retención?",
        "Options": {
            "1": "Amazon S3 Intelligent-Tiering para mover automáticamente los archivos entre niveles de acceso según los patrones de uso.",
            "2": "Amazon S3 Standard durante el período de retención, ya que ofrece el mejor rendimiento para datos de acceso frecuente.",
            "3": "Amazon S3 One Zone-IA durante los primeros meses, luego hacer la transición a Amazon S3 Standard-IA.",
            "4": "Amazon S3 Standard durante los primeros 30 días, luego hacer la transición a Amazon S3 Glacier para almacenamiento a largo plazo."
        },
        "Correct Answer": "Amazon S3 Intelligent-Tiering para mover automáticamente los archivos entre niveles de acceso según los patrones de uso.",
        "Explanation": "Amazon S3 Intelligent-Tiering es ideal para este escenario, ya que ajusta automáticamente la clase de almacenamiento según la frecuencia de acceso de los archivos de video, optimizando costos mientras asegura que estén disponibles cuando se necesiten. Esta clase se adapta a los patrones de acceso fluctuantes de los archivos de video durante el período de retención especificado.",
        "Other Options": [
            "Amazon S3 Standard durante los primeros 30 días, luego hacer la transición a Amazon S3 Glacier no es óptimo porque, aunque Glacier es rentable para almacenamiento a largo plazo, no está diseñado para acceso frecuente, lo que puede llevar a costos de recuperación más altos y retrasos cuando los videos aún están en demanda.",
            "Amazon S3 One Zone-IA durante los primeros meses, luego hacer la transición a Amazon S3 Standard-IA es incorrecto porque One Zone-IA es menos duradero que otras clases. Si hay una pérdida de disponibilidad en esa zona, los archivos de video podrían ser irrecuperables, lo que lo hace inadecuado para almacenamiento de medios críticos.",
            "Amazon S3 Standard durante el período de retención no es rentable en este caso, ya que no proporciona la optimización de costos necesaria para los períodos de acceso poco frecuente después de las semanas iniciales, lo que lleva a costos de almacenamiento generales más altos."
        ]
    },
    {
        "Question Number": "60",
        "Situation": "Una startup está buscando aprovechar los servicios administrados de AWS para construir una nueva aplicación que requiere un backend robusto para el procesamiento y almacenamiento de datos. El equipo quiere minimizar la sobrecarga operativa y enfocarse en el desarrollo de la aplicación en lugar de la gestión de la infraestructura. Están considerando varios servicios administrados de AWS para satisfacer sus necesidades.",
        "Question": "¿Qué combinación de servicios administrados de AWS debería utilizar la startup para cumplir eficientemente con los requisitos de su aplicación? (Seleccione Dos)",
        "Options": {
            "1": "Desplegar Amazon ECS para la orquestación de contenedores y Amazon RDS para servicios de bases de datos relacionales.",
            "2": "Utilizar Amazon EC2 para todo el alojamiento de aplicaciones y Amazon EBS para necesidades de almacenamiento.",
            "3": "Aprovechar AWS Elastic Beanstalk para la gestión de aplicaciones y Amazon CloudFront para la entrega de contenido.",
            "4": "Implementar AWS Lambda para computación sin servidor y Amazon DynamoDB para almacenamiento de bases de datos NoSQL.",
            "5": "Usar Amazon RDS para la gestión de bases de datos y Amazon S3 para almacenamiento de objetos."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Usar Amazon RDS para la gestión de bases de datos y Amazon S3 para almacenamiento de objetos.",
            "Implementar AWS Lambda para computación sin servidor y Amazon DynamoDB para almacenamiento de bases de datos NoSQL."
        ],
        "Explanation": "Usar Amazon RDS permite a la startup beneficiarse de un servicio de base de datos relacional completamente administrado, reduciendo tareas administrativas como copias de seguridad y gestión de parches. Amazon S3 proporciona almacenamiento de objetos escalable para datos no estructurados. AWS Lambda facilita la computación sin servidor, permitiendo al equipo ejecutar código sin aprovisionar servidores, mientras que DynamoDB ofrece una base de datos NoSQL completamente administrada que se escala automáticamente según la demanda, perfecta para aplicaciones modernas.",
        "Other Options": [
            "Utilizar Amazon EC2 para todo el alojamiento de aplicaciones introduce una sobrecarga operativa significativa, ya que la startup tendría que gestionar los servidores subyacentes, lo que va en contra de su objetivo de minimizar la gestión de infraestructura.",
            "Aprovechar AWS Elastic Beanstalk es una buena opción para la gestión de aplicaciones, pero emparejarlo con Amazon CloudFront no aborda efectivamente sus necesidades de almacenamiento de datos o procesamiento de backend.",
            "Desplegar Amazon ECS para la orquestación de contenedores es una elección válida, pero depender únicamente de Amazon RDS no aprovecha completamente las ventajas de una arquitectura sin servidor que AWS Lambda y DynamoDB pueden ofrecer."
        ]
    },
    {
        "Question Number": "61",
        "Situation": "Una empresa de servicios financieros está migrando su arquitectura de aplicaciones a AWS. Tienen el requisito de almacenar grandes volúmenes de datos de transacciones de manera segura y con alta durabilidad. Además, necesitan asegurarse de que los datos se repliquen en diferentes regiones para fines de recuperación ante desastres. Están considerando varios servicios de almacenamiento de AWS para cumplir con estos requisitos.",
        "Question": "¿Cuál de las siguientes estrategias debería recomendar el Arquitecto de Soluciones para asegurar un almacenamiento seguro y altamente duradero de los datos de transacciones con replicación entre regiones?",
        "Options": {
            "1": "Usar Amazon S3 con versionado habilitado y configurar la replicación entre regiones (CRR) para replicar automáticamente objetos a otro bucket de S3 en una región diferente.",
            "2": "Implementar Amazon ElastiCache con persistencia de datos habilitada y configurar grupos de replicación entre regiones para asegurar que los datos en caché estén disponibles durante una falla.",
            "3": "Utilizar Amazon RDS con implementaciones Multi-AZ para proporcionar alta disponibilidad y conmutación por error automática, y habilitar réplicas de lectura en otra región para recuperación ante desastres.",
            "4": "Usar Amazon EFS para almacenamiento de archivos y habilitar la replicación entre regiones para asegurar que los sistemas de archivos se repliquen a otra región para recuperación ante desastres."
        },
        "Correct Answer": "Usar Amazon S3 con versionado habilitado y configurar la replicación entre regiones (CRR) para replicar automáticamente objetos a otro bucket de S3 en una región diferente.",
        "Explanation": "Amazon S3 proporciona una solución de almacenamiento altamente duradera con una durabilidad del 99.999999999%. Habilitar el versionado permite mantener múltiples versiones de un objeto, y la replicación entre regiones (CRR) replica automáticamente objetos a una región diferente, asegurando que los datos estén seguros y disponibles en caso de una falla regional.",
        "Other Options": [
            "Si bien Amazon RDS con implementaciones Multi-AZ proporciona alta disponibilidad y capacidades de conmutación por error, no admite inherentemente la replicación entre regiones para recuperación ante desastres. Esta opción no cumpliría con el requisito de replicación entre regiones.",
            "Amazon ElastiCache se utiliza principalmente para almacenamiento en caché y no está diseñado para almacenamiento duradero a largo plazo de datos de transacciones. Aunque admite replicación, no garantiza el mismo nivel de durabilidad requerido para los datos de transacciones.",
            "Amazon EFS no admite la replicación entre regiones de forma nativa. Si bien es una buena opción para almacenamiento de archivos, no puede cumplir con el requisito de asegurar que los archivos se repliquen a otra región para recuperación ante desastres."
        ]
    },
    {
        "Question Number": "62",
        "Situation": "Una empresa de servicios financieros está migrando sus aplicaciones de computación de alto rendimiento (HPC) a AWS. Estas aplicaciones requieren capacidades de red de baja latencia y alto rendimiento para lograr un rendimiento óptimo en múltiples instancias de EC2. La empresa está considerando usar el Elastic Fabric Adapter (EFA) para mejorar el rendimiento de las comunicaciones entre instancias. Quieren asegurarse de que su estrategia de migración aproveche al máximo las capacidades de EFA.",
        "Question": "¿Qué debería hacer la empresa para asegurarse de que EFA se utilice de manera efectiva para sus aplicaciones HPC en AWS?",
        "Options": {
            "1": "Seleccionar tipos de instancias de EC2 que admitan EFA, habilitar EFA durante el lanzamiento de la instancia y configurar sus aplicaciones para utilizar las capacidades de red mejoradas.",
            "2": "Usar Amazon ECS para ejecutar versiones en contenedores de sus aplicaciones HPC sin habilitar EFA, confiando únicamente en la red estándar de EC2.",
            "3": "Lanzar instancias de EC2 que no estén optimizadas para el rendimiento de red y configurarlas para usar el Elastic Network Adapter (ENA) por defecto.",
            "4": "Desplegar instancias de EC2 con EFA habilitado pero restringir a las aplicaciones el uso de las características de red mejoradas para evitar problemas de compatibilidad."
        },
        "Correct Answer": "Seleccionar tipos de instancias de EC2 que admitan EFA, habilitar EFA durante el lanzamiento de la instancia y configurar sus aplicaciones para utilizar las capacidades de red mejoradas.",
        "Explanation": "Al seleccionar tipos de instancias de EC2 que admitan EFA y habilitar EFA durante el lanzamiento de la instancia, la empresa puede beneficiarse de las capacidades de red de baja latencia y alto rendimiento que proporciona EFA, las cuales son esenciales para el rendimiento de las aplicaciones HPC.",
        "Other Options": [
            "Lanzar instancias de EC2 que no estén optimizadas para el rendimiento de red y usar el Elastic Network Adapter (ENA) por defecto no aprovecharía las capacidades de EFA, lo que llevaría a un rendimiento subóptimo para las aplicaciones HPC.",
            "Desplegar instancias de EC2 con EFA habilitado pero restringir a las aplicaciones el uso de características de red mejoradas anularía los beneficios de EFA, ya que las aplicaciones no podrían aprovechar la red de baja latencia y alto rendimiento.",
            "Usar Amazon ECS para ejecutar versiones en contenedores de aplicaciones HPC sin habilitar EFA no maximizaría el rendimiento de la red, ya que la red estándar de EC2 carece de las mejoras proporcionadas por EFA."
        ]
    },
    {
        "Question Number": "63",
        "Situation": "Una empresa de servicios financieros está planeando migrar su aplicación existente en las instalaciones a AWS. La aplicación está construida sobre un marco .NET, utiliza una base de datos Microsoft SQL Server y experimenta fluctuaciones significativas de carga a lo largo del mes. La empresa requiere una arquitectura escalable que pueda manejar cargas de trabajo variables sin requerir intervención manual significativa. Además, la aplicación necesita mantener alta disponibilidad y capacidades de recuperación ante desastres. El equipo está explorando opciones que les permitan aprovechar los servicios administrados siempre que sea posible y asegurar un tiempo de inactividad mínimo durante la transición.",
        "Question": "¿Cuál de los siguientes diseños arquitectónicos apoyaría mejor los requisitos de la empresa durante la migración a AWS?",
        "Options": {
            "1": "Migrar la aplicación .NET a instancias de Amazon EC2 gestionadas por un grupo de Auto Scaling. Usar Amazon RDS con SQL Server, pero configurarlo sin implementación Multi-AZ. Crear un Elastic Load Balancer para distribuir el tráfico y ajustar manualmente las instancias de EC2 según sea necesario para manejar los cambios de carga.",
            "2": "Adoptar AWS Elastic Beanstalk para gestionar la aplicación .NET y configurar un Application Load Balancer para distribuir el tráfico. Usar Amazon RDS con SQL Server para las necesidades de base de datos y configurar Multi-AZ para alta disponibilidad y conmutación por error automática. Implementar AWS Auto Scaling para manejar cargas de trabajo fluctuantes.",
            "3": "Utilizar AWS Fargate para ejecutar la aplicación .NET como un servicio en contenedores, junto con Amazon Aurora para las necesidades de base de datos SQL. Implementar un Network Load Balancer para la gestión del tráfico y escalado manual basado en patrones de carga observados.",
            "4": "Desplegar la aplicación .NET en Amazon ECS con tipo de lanzamiento EC2 para gestionar los contenedores. Usar Amazon RDS con SQL Server y configurar Multi-AZ para alta disponibilidad. Implementar un Application Load Balancer para enrutar el tráfico y aprovechar CloudWatch para monitoreo y escalado."
        },
        "Correct Answer": "Adoptar AWS Elastic Beanstalk para gestionar la aplicación .NET y configurar un Application Load Balancer para distribuir el tráfico. Usar Amazon RDS con SQL Server para las necesidades de base de datos y configurar Multi-AZ para alta disponibilidad y conmutación por error automática. Implementar AWS Auto Scaling para manejar cargas de trabajo fluctuantes.",
        "Explanation": "Esta opción proporciona un servicio completamente administrado a través de AWS Elastic Beanstalk, que simplifica el despliegue, la gestión y el escalado de la aplicación .NET. También incluye Amazon RDS con Multi-AZ para alta disponibilidad, asegurando la integridad de los datos y una recuperación rápida en caso de falla, mientras que AWS Auto Scaling asegura la adaptabilidad durante cargas de trabajo fluctuantes.",
        "Other Options": [
            "Esta opción carece de la configuración Multi-AZ para Amazon RDS, que es crucial para la alta disponibilidad y la recuperación ante desastres. Además, depender de ajustes manuales para las instancias de EC2 no cumple con el requisito de intervención manual mínima durante los cambios de carga.",
            "Ejecutar la aplicación .NET en AWS Fargate puede no utilizar la arquitectura existente de manera eficiente, particularmente si la aplicación no está diseñada para la contenedorización. Además, Amazon Aurora no es un reemplazo directo de SQL Server, lo que puede complicar el proceso de migración.",
            "Usar Amazon ECS con tipo de lanzamiento EC2 añade sobrecarga en la gestión de las instancias de EC2 subyacentes, lo que va en contra del enfoque de servicio administrado deseado por la empresa. Aunque Multi-AZ está incluido para RDS, la complejidad de la orquestación de contenedores puede no cumplir con los requisitos para una migración sin problemas."
        ]
    },
    {
        "Question Number": "64",
        "Situation": "Una empresa de servicios financieros está migrando su aplicación a AWS y quiere asegurarse de que puede aprovechar tecnologías avanzadas como el aprendizaje automático y el análisis de datos sin requerir una amplia experiencia interna. El objetivo es automatizar el despliegue y hacer que la tecnología sea accesible para sus equipos de desarrollo, mientras se adhiere a la normativa de cumplimiento.",
        "Question": "¿Cuál de las siguientes soluciones permitirá mejor a la empresa delegar tareas complejas de aprendizaje automático y análisis a AWS, asegurando el cumplimiento y la accesibilidad para sus equipos de desarrollo?",
        "Options": {
            "1": "Utilizar Amazon Elastic MapReduce (EMR) para análisis y requerir que el equipo de desarrollo gestione manualmente la infraestructura subyacente para asegurar el cumplimiento.",
            "2": "Implementar AWS Glue para la preparación de datos y tareas de ETL, pero requerir que los desarrolladores manejen de forma independiente el entrenamiento y despliegue de modelos de aprendizaje automático.",
            "3": "Adoptar AWS Lambda para funciones sin servidor para ejecutar inferencias de aprendizaje automático, pero hacer que los desarrolladores mantengan sus propios modelos de aprendizaje automático en instancias de EC2.",
            "4": "Utilizar Amazon SageMaker para construir, entrenar y desplegar modelos de aprendizaje automático, mientras se usa AWS CloudFormation para gestionar la infraestructura como código."
        },
        "Correct Answer": "Utilizar Amazon SageMaker para construir, entrenar y desplegar modelos de aprendizaje automático, mientras se usa AWS CloudFormation para gestionar la infraestructura como código.",
        "Explanation": "Esta opción proporciona una solución integral que abstrae la complejidad del aprendizaje automático mientras permite a la empresa mantener el cumplimiento. Amazon SageMaker permite un desarrollo y despliegue de modelos simplificado, mientras que AWS CloudFormation asegura que la infraestructura se pueda gestionar de manera eficiente y consistente.",
        "Other Options": [
            "Si bien Amazon EMR es una herramienta poderosa para el análisis de datos, requerir que el equipo de desarrollo gestione manualmente la infraestructura subyacente contradice el objetivo de delegar tareas complejas y añade una carga operativa innecesaria.",
            "AWS Glue es una excelente opción para tareas de ETL, pero pedir a los desarrolladores que manejen de forma independiente el entrenamiento y despliegue de modelos de aprendizaje automático crea silos de experiencia y complica los esfuerzos de cumplimiento.",
            "AWS Lambda puede ser utilizado para inferencias, pero hacer que los desarrolladores gestionen sus propios modelos de aprendizaje automático en instancias de EC2 introduce complejidad y reduce la accesibilidad a tecnologías avanzadas."
        ]
    },
    {
        "Question Number": "65",
        "Situation": "Una empresa multinacional está buscando optimizar el rendimiento de su aplicación web, que atiende a usuarios a nivel global. La aplicación está alojada en la región us-east-1, y la empresa está preocupada por la latencia para los usuarios ubicados en Europa y Asia. El arquitecto de soluciones necesita implementar una solución que asegure baja latencia y alta disponibilidad para usuarios de todo el mundo.",
        "Question": "¿Cuál de las siguientes soluciones abordará mejor los requisitos de la empresa para la optimización del rendimiento global?",
        "Options": {
            "1": "Implementar Amazon CloudFront como una red de entrega de contenido (CDN) para almacenar en caché contenido estático en ubicaciones de borde más cercanas a los usuarios, mientras se habilita también la entrega de contenido dinámico.",
            "2": "Utilizar AWS Global Accelerator para dirigir el tráfico de usuarios al punto de aplicación más cercano, optimizando el rendimiento y mejorando la disponibilidad a través de un enrutamiento inteligente.",
            "3": "Utilizar AWS Lambda@Edge para ejecutar código personalizado en ubicaciones de borde de AWS, permitiendo el procesamiento de datos en tiempo real y la generación de respuestas cerca del usuario.",
            "4": "Desplegar la aplicación web en múltiples regiones de AWS y usar Amazon Route 53 para geo-enrutamiento para dirigir a los usuarios a la región más cercana, asegurando una latencia mínima."
        },
        "Correct Answer": "Utilizar AWS Global Accelerator para dirigir el tráfico de usuarios al punto de aplicación más cercano, optimizando el rendimiento y mejorando la disponibilidad a través de un enrutamiento inteligente.",
        "Explanation": "AWS Global Accelerator mejora el rendimiento de la aplicación dirigiendo el tráfico de usuarios al punto más óptimo según la ubicación del usuario y la salud de los puntos finales. Mejora la disponibilidad y reduce la latencia, lo que lo convierte en una opción adecuada para la optimización del rendimiento global.",
        "Other Options": [
            "Si bien implementar Amazon CloudFront es un buen enfoque para almacenar en caché contenido estático y reducir la latencia, no optimiza específicamente el enrutamiento de contenido dinámico ni asegura alta disponibilidad a través de múltiples puntos finales de aplicación.",
            "Desplegar la aplicación web en múltiples regiones de AWS con Amazon Route 53 para geo-enrutamiento es beneficioso, pero puede introducir complejidad en la gestión de múltiples despliegues y no proporciona el mismo nivel de enrutamiento inteligente que AWS Global Accelerator.",
            "Usar AWS Lambda@Edge puede mejorar el rendimiento para casos de uso específicos al ejecutar lógica personalizada en ubicaciones de borde, pero no optimiza inherentemente el enrutamiento del tráfico de usuarios al punto de aplicación más cercano como lo hace AWS Global Accelerator."
        ]
    },
    {
        "Question Number": "66",
        "Situation": "Una empresa emergente está lanzando un nuevo servicio de transmisión de video en línea. Se espera que el servicio tenga una base de usuarios fluctuante, con un promedio de 5,000 usuarios concurrentes y picos que alcanzan los 50,000 usuarios concurrentes durante eventos populares. La empresa quiere asegurarse de que solo pague por los recursos que necesita y desea implementar una infraestructura rentable mientras mantiene una experiencia de transmisión de alta calidad. Están considerando diferentes soluciones de almacenamiento para contenido de video y capacidades de transmisión.",
        "Question": "¿Cuál de los siguientes diseños de arquitectura proporcionará la solución más rentable para entregar contenido de video en streaming mientras se ajusta dinámicamente a la demanda de los usuarios?",
        "Options": {
            "1": "Usar Amazon S3 para almacenar archivos de video e implementar AWS Elemental Media Services para procesar y escalar las transmisiones de video, asegurando una entrega óptima durante los picos.",
            "2": "Utilizar Amazon Elastic Transcoder para convertir archivos de video y almacenarlos en Amazon S3, luego usar funciones de AWS Lambda para atender las solicitudes directamente desde S3 sin usar una red de entrega de contenido.",
            "3": "Almacenar archivos de video directamente en Amazon EFS y montarlo en una flota de instancias de Amazon EC2. Usar estas instancias para transmitir contenido directamente a los usuarios sin ninguna capa de caché.",
            "4": "Usar Amazon S3 para almacenar archivos de video, junto con Amazon CloudFront para la entrega de contenido. Implementar un grupo de Auto Scaling de instancias de Amazon EC2 para atender las solicitudes con un balanceador de carga al frente para manejar el tráfico entrante."
        },
        "Correct Answer": "Usar Amazon S3 para almacenar archivos de video e implementar AWS Elemental Media Services para procesar y escalar las transmisiones de video, asegurando una entrega óptima durante los picos.",
        "Explanation": "Esta opción aprovecha Amazon S3 para almacenamiento rentable y AWS Elemental Media Services para un procesamiento y escalado eficientes, lo que asegura una entrega de alta calidad durante los picos de uso. Esta arquitectura se ajusta dinámicamente según la demanda, lo que la convierte en una solución rentable para la transmisión de video.",
        "Other Options": [
            "Esta opción depende de instancias de EC2 y un balanceador de carga, lo que puede llevar a costos más altos debido a la necesidad de recursos siempre activos, especialmente durante períodos de bajo uso cuando puede no ser necesario tener múltiples instancias de EC2 en funcionamiento.",
            "Usar Amazon EFS para almacenamiento de video no es ideal para transmisión debido a posibles problemas de latencia, y puede ser más costoso que S3. Esta opción no incluye una capa de caché que podría mejorar el rendimiento y reducir costos.",
            "Si bien Amazon Elastic Transcoder es útil para convertir formatos de video, atender solicitudes directamente desde S3 sin una CDN puede llevar a una mayor latencia y costos, especialmente durante los picos cuando una CDN podría mejorar el rendimiento y reducir la carga en el bucket de S3."
        ]
    },
    {
        "Question Number": "67",
        "Situation": "Una gran empresa de comercio electrónico está experimentando un aumento en el tráfico debido a un evento promocional. Están preocupados por posibles ataques de Denegación de Servicio Distribuida (DDoS) que podrían interrumpir sus servicios en línea. La empresa quiere implementar una solución que proporcione una protección robusta contra varios ataques DDoS, asegurando al mismo tiempo un impacto mínimo en el rendimiento de su aplicación. También necesitan ser notificados de cualquier actividad sospechosa que pueda afectar sus recursos.",
        "Question": "¿Cuál de las siguientes soluciones satisfará mejor los requisitos de la empresa para la protección DDoS y la notificación?",
        "Options": {
            "1": "Implementar AWS Shield Advanced para una protección DDoS integral y utilizar AWS WAF para crear reglas que filtren el tráfico. Habilitar el registro para un análisis detallado de ataques y configurar notificaciones a través de Amazon SNS.",
            "2": "Usar AWS Shield Standard para una protección DDoS básica e implementar Route 53 para el enrutamiento DNS. Crear una solución de monitoreo personalizada para rastrear patrones de tráfico y alertar al equipo.",
            "3": "Habilitar AWS Shield Advanced para una protección DDoS mejorada y configurar CloudFront para almacenar en caché contenido. Configurar alarmas de Amazon CloudWatch para el monitoreo de actividad y notificaciones.",
            "4": "Activar AWS Shield Standard para una protección DDoS automática e integrar Elastic Load Balancing para la distribución de tráfico. Confiar en AWS CloudTrail para el monitoreo y la respuesta a incidentes."
        },
        "Correct Answer": "Implementar AWS Shield Advanced para una protección DDoS integral y utilizar AWS WAF para crear reglas que filtren el tráfico. Habilitar el registro para un análisis detallado de ataques y configurar notificaciones a través de Amazon SNS.",
        "Explanation": "AWS Shield Advanced proporciona una protección mejorada contra ataques DDoS sofisticados, y cuando se combina con AWS WAF, permite la creación de reglas personalizadas para filtrar el tráfico malicioso. Además, habilitar el registro proporciona información sobre los patrones de ataque, y usar Amazon SNS permite notificaciones en tiempo real al equipo, cumpliendo efectivamente con los requisitos de la empresa.",
        "Other Options": [
            "Si bien habilitar AWS Shield Advanced es una buena opción, configurar CloudFront por sí solo no proporciona la protección DDoS integral necesaria, y sin registro y notificación, carece de capacidades críticas de monitoreo.",
            "AWS Shield Standard ofrece protección básica pero no proporciona las notificaciones detalladas ni las capacidades de detección avanzada que la empresa requiere. Una solución de monitoreo personalizada puede no ser tan efectiva como los servicios integrados de AWS.",
            "AWS Shield Standard proporciona protección automática, pero sin las características avanzadas de AWS Shield Advanced y AWS WAF, la solución carece de la personalización y las capacidades de registro necesarias para alertar al equipo sobre amenazas potenciales."
        ]
    },
    {
        "Question Number": "68",
        "Situation": "Una empresa global de juegos en línea quiere asegurar alta disponibilidad y un bajo tiempo de recuperación para su infraestructura de juegos multijugador. Actualmente están operando en una sola región de AWS, pero quieren mejorar su estrategia de recuperación ante desastres. La empresa necesita una solución que les permita lograr 4 9s (99.99%) de disponibilidad con un tiempo de recuperación rápido, utilizando recursos en una región secundaria.",
        "Question": "¿Cuál de las siguientes arquitecturas puede implementar la empresa para lograr 4 9s de disponibilidad y asegurar un tiempo de recuperación muy corto mientras utiliza solo una región activa?",
        "Options": {
            "1": "Implementar un grupo de Auto Scaling en una región y configurar un mecanismo de conmutación por error que active otro grupo de Auto Scaling en una región secundaria solo cuando la región primaria falle.",
            "2": "Utilizar Amazon S3 para el almacenamiento de datos del juego en una región y replicar los datos a una región secundaria utilizando replicación entre regiones, manteniendo los servidores de juego activos solo en la región primaria.",
            "3": "Configurar una instancia de Amazon RDS con implementaciones Multi-AZ en la región primaria y una réplica de lectura en otra región para asegurar la disponibilidad de datos y una conmutación por error rápida.",
            "4": "Desplegar los servidores de juego en una sola región de AWS y usar Amazon Route 53 con verificaciones de estado para redirigir el tráfico a una región de espera cuando la región primaria falle."
        },
        "Correct Answer": "Utilizar Amazon S3 para el almacenamiento de datos del juego en una región y replicar los datos a una región secundaria utilizando replicación entre regiones, manteniendo los servidores de juego activos solo en la región primaria.",
        "Explanation": "Al utilizar Amazon S3 para el almacenamiento de datos del juego y habilitar la replicación entre regiones, la empresa puede asegurar que los datos estén siempre disponibles en una región secundaria. Esto permite una recuperación rápida en caso de una falla en la región primaria mientras mantiene los recursos utilizados de manera eficiente en una región activa.",
        "Other Options": [
            "Desplegar servidores de juego en una sola región de AWS con verificaciones de estado de Route 53 no garantiza el tiempo de recuperación necesario ni la disponibilidad de datos en la región secundaria, ya que los servidores de juego no estarían operativos hasta que ocurra la conmutación por error.",
            "Implementar un grupo de Auto Scaling en una región con un mecanismo de conmutación por error a otra región no proporcionaría la disponibilidad deseada de 4 9s, ya que el grupo secundario estaría inactivo hasta ser activado por una falla.",
            "Configurar una instancia de Amazon RDS con implementaciones Multi-AZ asegura alta disponibilidad, pero no permite una recuperación rápida utilizando recursos de una región secundaria, ya que la réplica de lectura no se utiliza activamente para escrituras."
        ]
    },
    {
        "Question Number": "69",
        "Situation": "Una empresa de servicios financieros está buscando optimizar su gasto en AWS y mejorar la visibilidad de costos en múltiples departamentos. La empresa quiere implementar una estrategia de etiquetado que les permita asignar costos de manera efectiva y generar informes basados en esas etiquetas. Están considerando varias opciones para etiquetar sus recursos de AWS.",
        "Question": "¿Qué enfoque debería recomendar el Arquitecto de Soluciones para asegurar una asignación y reporte de costos efectivos a través del etiquetado?",
        "Options": {
            "1": "Crear un script que etiquete los recursos según su fecha de creación y aplique automáticamente una etiqueta predeterminada para el entorno. Usar AWS Lambda para ejecutar este script regularmente para el reporte de costos.",
            "2": "Etiquetar manualmente los recursos mensualmente antes de generar informes de costos. Usar Amazon QuickSight para visualizar costos basados en las etiquetas creadas durante este proceso manual.",
            "3": "Usar AWS Config para hacer cumplir el cumplimiento del etiquetado de recursos y etiquetar automáticamente los recursos según su tipo. Generar informes de asignación de costos basados en estas etiquetas asignadas automáticamente utilizando AWS Budgets.",
            "4": "Implementar una política de etiquetado consistente en todas las cuentas de AWS, asegurando que cada recurso esté etiquetado con identificadores clave para el departamento, proyecto y entorno. Utilizar AWS Cost Explorer para analizar costos basados en estas etiquetas."
        },
        "Correct Answer": "Implementar una política de etiquetado consistente en todas las cuentas de AWS, asegurando que cada recurso esté etiquetado con identificadores clave para el departamento, proyecto y entorno. Utilizar AWS Cost Explorer para analizar costos basados en estas etiquetas.",
        "Explanation": "Una política de etiquetado consistente permite una categorización adecuada de los costos entre departamentos, proyectos y entornos. Usar AWS Cost Explorer permite el análisis de costos basado en estas etiquetas, proporcionando información clara sobre el gasto y ayudando a optimizar los presupuestos de manera efectiva.",
        "Other Options": [
            "Usar AWS Config para hacer cumplir el cumplimiento puede no abordar completamente la necesidad de una estrategia de etiquetado proactiva. Las etiquetas asignadas automáticamente pueden no alinearse con las necesidades comerciales específicas para la asignación de costos.",
            "Etiquetar manualmente los recursos puede llevar a inconsistencias y errores, dificultando la confianza en las etiquetas para un reporte de costos preciso. Además, este enfoque no es escalable ni eficiente para la gestión continua.",
            "Etiquetar recursos según su fecha de creación no proporciona un contexto significativo para la asignación de costos. Las etiquetas predeterminadas pueden no representar con precisión el propósito del recurso, lo que lleva a un análisis de costos incompleto o engañoso."
        ]
    },
    {
        "Question Number": "70",
        "Situation": "Una corporación multinacional opera en varias regiones y necesita establecer una conexión segura y confiable entre su centro de datos local y su entorno de AWS. La empresa requiere baja latencia y alta capacidad de ancho de banda para la transferencia de datos, al mismo tiempo que asegura que la conexión permanezca resiliente en caso de una falla. Además, la empresa necesita evitar cualquier dependencia de internet público para esta conectividad.",
        "Question": "¿Qué servicio de AWS proporciona la mejor solución para establecer una conexión dedicada, de alto ancho de banda y baja latencia entre el centro de datos local y AWS, mientras también ofrece opciones de redundancia en caso de una falla de conexión primaria?",
        "Options": {
            "1": "AWS Direct Connect con una copia de seguridad de Red Privada Virtual (VPN).",
            "2": "AWS Direct Connect con una conexión redundante en una ubicación diferente.",
            "3": "AWS Site-to-Site VPN con múltiples túneles VPN para redundancia.",
            "4": "AWS Transit Gateway conectado a múltiples conexiones VPN para conmutación por error."
        },
        "Correct Answer": "AWS Direct Connect con una conexión redundante en una ubicación diferente.",
        "Explanation": "AWS Direct Connect proporciona una conexión de red dedicada que ofrece menor latencia y mayor ancho de banda en comparación con soluciones basadas en internet. Al establecer una conexión redundante en una ubicación diferente, la empresa asegura alta disponibilidad y resiliencia contra fallas de conexión, lo cual es crítico para sus operaciones.",
        "Other Options": [
            "AWS Site-to-Site VPN es una opción viable para conexiones seguras; sin embargo, depende de internet público, lo que puede introducir latencia y limitaciones de ancho de banda. Aunque múltiples túneles VPN pueden ofrecer redundancia, no igualan la naturaleza dedicada de Direct Connect.",
            "AWS Transit Gateway puede conectar múltiples conexiones VPN, pero aún depende de internet público para esas conexiones. Esta configuración puede no proporcionar la baja latencia y el alto ancho de banda que la empresa requiere para sus operaciones.",
            "AWS Direct Connect con una copia de seguridad de VPN puede mejorar la seguridad, pero en caso de una falla de conexión primaria, la conexión VPN aún dependerá de internet público, lo que podría llevar a problemas de latencia y puede no cumplir con los requisitos de la empresa para una conexión dedicada."
        ]
    },
    {
        "Question Number": "71",
        "Situation": "Una empresa de servicios financieros ha experimentado una interrupción significativa en su arquitectura multi-región alojada en AWS. El equipo de operaciones ahora tiene la tarea de identificar la causa raíz y asegurar que los procedimientos de recuperación se implementen de manera efectiva. Quieren simular un escenario de falla para validar sus procesos de respuesta a emergencias y mejorar su plan de recuperación ante desastres. (Seleccione Dos.)",
        "Question": "¿Cuáles de las siguientes actividades debería implementar el arquitecto de soluciones para ejercitar la comprensión de las acciones de recuperación durante esta simulación?",
        "Options": {
            "1": "Crear un runbook para operaciones diarias e incluir procedimientos para manejar fallas simuladas para guiar al equipo.",
            "2": "Configurar un proceso de respaldo automatizado utilizando AWS Backup para proteger datos críticos antes de realizar las simulaciones.",
            "3": "Realizar una restauración completa de la aplicación desde la última copia de seguridad en un entorno de prueba para validar el proceso de recuperación.",
            "4": "Realizar un ejercicio de mesa con las partes interesadas clave para revisar el plan de respuesta a incidentes y los pasos de recuperación.",
            "5": "Desplegar una función de AWS Lambda que pueda revertir automáticamente los cambios realizados en el entorno de producción durante la simulación."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Realizar un ejercicio de mesa con las partes interesadas clave para revisar el plan de respuesta a incidentes y los pasos de recuperación.",
            "Realizar una restauración completa de la aplicación desde la última copia de seguridad en un entorno de prueba para validar el proceso de recuperación."
        ],
        "Explanation": "Realizar un ejercicio de mesa permite al equipo discutir y refinar el plan de respuesta a incidentes sin el riesgo de interrupciones reales. Realizar una restauración completa desde una copia de seguridad valida el proceso de recuperación real, asegurando que la aplicación pueda ser restaurada de manera efectiva en caso de una falla real.",
        "Other Options": [
            "Si bien configurar un proceso de respaldo automatizado es importante, no prueba directamente las acciones de recuperación ni el plan de respuesta a incidentes durante la simulación.",
            "Desplegar una función de AWS Lambda para revertir cambios es útil para gestionar cambios, pero no simula efectivamente el proceso de recuperación en un escenario de falla.",
            "Crear un runbook para operaciones diarias es valioso para guiar al equipo, pero no reemplaza la necesidad de ejercicios prácticos para probar las acciones de recuperación."
        ]
    },
    {
        "Question Number": "72",
        "Situation": "Una empresa de servicios financieros requiere una solución segura para gestionar claves de cifrado de datos sensibles y certificados SSL/TLS en toda su infraestructura. La empresa quiere asegurarse de que todas las claves de cifrado sean gestionadas de manera centralizada, rotadas regularmente e integradas con sus aplicaciones para el cumplimiento de la seguridad de datos. El arquitecto de soluciones necesita implementar las mejores prácticas para la gestión de claves y el despliegue de certificados.",
        "Question": "¿Cuál de las siguientes soluciones es la más apropiada para gestionar claves de cifrado y certificados en este escenario?",
        "Options": {
            "1": "Desplegar una solución de gestión de claves local y gestionar manualmente los certificados SSL/TLS para aplicaciones alojadas en AWS.",
            "2": "Utilizar AWS Key Management Service (AWS KMS) para la gestión de claves, y AWS Certificate Manager (ACM) para aprovisionar y gestionar certificados SSL/TLS para las aplicaciones.",
            "3": "Utilizar AWS Secrets Manager para la gestión de claves y AWS CloudFormation para desplegar certificados SSL/TLS automáticamente.",
            "4": "Implementar funciones de AWS Lambda para rotar claves de cifrado y gestionar certificados SSL/TLS directamente en el código de la aplicación."
        },
        "Correct Answer": "Utilizar AWS Key Management Service (AWS KMS) para la gestión de claves, y AWS Certificate Manager (ACM) para aprovisionar y gestionar certificados SSL/TLS para las aplicaciones.",
        "Explanation": "AWS Key Management Service (AWS KMS) proporciona una forma centralizada de crear y gestionar claves criptográficas, incluyendo rotación automática de claves e integración con otros servicios de AWS. AWS Certificate Manager (ACM) simplifica la gestión de certificados SSL/TLS, incluyendo renovaciones automáticas, lo que se alinea perfectamente con los requisitos de seguridad de la empresa.",
        "Other Options": [
            "Esta opción introduce complejidad y riesgo innecesarios, ya que gestionar una solución de gestión de claves local no aprovecha las características de seguridad integradas de AWS, y la gestión manual de certificados puede llevar a posibles descuidos y vulnerabilidades de seguridad.",
            "AWS Secrets Manager está diseñado para gestionar secretos como claves API y credenciales de bases de datos, pero no está optimizado para la gestión de claves de cifrado. Además, usar CloudFormation para certificados SSL/TLS no proporciona el mismo nivel de automatización y mantenimiento que AWS Certificate Manager.",
            "Si bien AWS Lambda puede ser utilizado para varias tareas de automatización, no es una solución adecuada para la rotación de claves y la gestión de certificados. Este enfoque añade una sobrecarga y complejidad innecesarias, careciendo de las características de gestión centralizada que proporcionan AWS KMS y ACM."
        ]
    },
    {
        "Question Number": "73",
        "Situation": "Una empresa de servicios financieros está desarrollando una función de AWS Lambda que necesita acceder a una base de datos alojada en una VPC privada. Se espera que la función escale en respuesta a cargas altas durante los períodos de transacciones pico. Sin embargo, el equipo está encontrando errores frecuentes de EC2ThrottledException, lo que indica que la función de Lambda no puede escalar adecuadamente.",
        "Question": "¿Qué debería recomendar el arquitecto de soluciones para optimizar el rendimiento de la función de Lambda y asegurar que escale efectivamente dentro del entorno de la VPC?",
        "Options": {
            "1": "Ajustar la configuración de concurrencia de la función de Lambda y asegurarse de que haya suficientes direcciones IP y ENIs disponibles en las subredes de la VPC.",
            "2": "Aumentar el número de ENIs disponibles en la VPC modificando la configuración de la VPC para permitir más interfaces de red elásticas.",
            "3": "Desplegar la función de Lambda fuera de la VPC para permitir que escale libremente sin las limitaciones impuestas por las configuraciones de la VPC.",
            "4": "Configurar una instancia EC2 dedicada para manejar las solicitudes en lugar de usar una función de Lambda dentro de la VPC."
        },
        "Correct Answer": "Ajustar la configuración de concurrencia de la función de Lambda y asegurarse de que haya suficientes direcciones IP y ENIs disponibles en las subredes de la VPC.",
        "Explanation": "Ajustar la configuración de concurrencia de la función de Lambda permite manejar más solicitudes simultáneamente. Asegurarse de que haya suficientes direcciones IP y ENIs disponibles en las subredes de la VPC previene la limitación y los errores de invocación, permitiendo que la función escale adecuadamente a medida que aumenta la demanda.",
        "Other Options": [
            "Aumentar el número de ENIs disponibles por sí solo puede no abordar los problemas subyacentes relacionados con la concurrencia y los límites de escalado de la función de Lambda. Es esencial gestionar tanto los ENIs como la configuración de concurrencia.",
            "Desplegar la función de Lambda fuera de la VPC eliminaría la necesidad de configuraciones relacionadas con la VPC y permitiría la escalabilidad, pero no permitiría el acceso a la base de datos alojada dentro de la VPC privada, que es un requisito.",
            "Configurar una instancia EC2 dedicada requeriría gestionar la infraestructura del servidor, lo que va en contra del modelo sin servidor que ofrece Lambda. Este enfoque no aborda los problemas de escalabilidad de la función de Lambda dentro de la VPC."
        ]
    },
    {
        "Question Number": "74",
        "Situation": "Una empresa minorista está desarrollando una nueva aplicación que manejará la gestión de inventarios, pedidos de clientes y análisis en tiempo real. La aplicación requiere una arquitectura altamente escalable que pueda ajustarse automáticamente a cargas variables y utilizar servicios diseñados específicamente para tareas como almacenamiento de datos, computación y análisis. El arquitecto de soluciones necesita seleccionar los servicios de AWS que mejor se adapten a estos requisitos mientras asegura un rendimiento óptimo y rentabilidad.",
        "Question": "¿Cuál de los siguientes enfoques debería tomar el arquitecto de soluciones para asegurar que la aplicación utilice los servicios de AWS adecuados para cada tarea?",
        "Options": {
            "1": "Utilizar AWS Lambda para computación sin servidor, Amazon RDS para datos estructurados y Amazon Redshift para análisis.",
            "2": "Seleccionar Amazon EFS para almacenamiento de archivos, Amazon Lightsail para necesidades básicas de computación y Amazon QuickSight para inteligencia empresarial.",
            "3": "Aprovechar instancias de Amazon EC2 para todos los requisitos de computación y usar Amazon S3 para almacenamiento de datos.",
            "4": "Implementar Amazon ECS para gestión de contenedores, usar Amazon DynamoDB para almacenamiento de datos NoSQL y AWS Glue para transformación de datos."
        },
        "Correct Answer": "Utilizar AWS Lambda para computación sin servidor, Amazon RDS para datos estructurados y Amazon Redshift para análisis.",
        "Explanation": "Este enfoque utiliza de manera efectiva servicios diseñados específicamente que se alinean con los requisitos de la aplicación. AWS Lambda permite la computación sin servidor, que es altamente escalable y rentable para cargas variables. Amazon RDS es ideal para la gestión de datos estructurados, mientras que Amazon Redshift está optimizado para análisis en tiempo real, haciendo de esta combinación la mejor opción.",
        "Other Options": [
            "Usar instancias de Amazon EC2 para todos los requisitos de computación puede llevar a una sobreaprovisionamiento y costos más altos, ya que no aprovecha las opciones sin servidor que pueden escalar automáticamente con la demanda.",
            "Implementar Amazon ECS y AWS Glue puede ser adecuado para ciertos casos de uso, pero no aborda de manera óptima todos los requisitos, particularmente en lo que respecta a la gestión de datos estructurados y análisis en tiempo real tan efectivamente como la respuesta correcta.",
            "Seleccionar Amazon EFS y Amazon Lightsail no proporciona la escalabilidad y optimizaciones específicas necesarias para una robusta aplicación de gestión de inventarios y análisis, haciéndola menos adecuada en comparación con la respuesta correcta."
        ]
    },
    {
        "Question Number": "75",
        "Situation": "Una plataforma de comercio electrónico global requiere sincronización de datos en tiempo real a través de múltiples regiones geográficas para asegurar que los clientes tengan una experiencia fluida sin importar su ubicación. La arquitectura incluye un catálogo de productos en línea y una base de datos transaccional que debe permanecer consistente. El arquitecto de soluciones necesita configurar la base de datos para soportar replicación de alta disponibilidad y baja latencia a través de las regiones de AWS.",
        "Question": "¿Cuál de las siguientes opciones debería implementar el arquitecto de soluciones para lograr una replicación de datos efectiva mientras asegura alta disponibilidad y baja latencia?",
        "Options": {
            "1": "Implementar Amazon RDS con despliegues Multi-AZ en cada región y replicar datos manualmente entre regiones usando AWS Data Pipeline.",
            "2": "Desplegar Amazon RDS con réplicas de lectura entre regiones y habilitar copias de seguridad automáticas para recuperación ante desastres.",
            "3": "Usar Amazon DynamoDB con tablas globales para proporcionar datos completamente replicados en múltiples regiones a través de la plataforma.",
            "4": "Configurar Amazon Aurora con réplicas entre regiones para acceso de baja latencia y capacidades de conmutación por error automáticas."
        },
        "Correct Answer": "Usar Amazon DynamoDB con tablas globales para proporcionar datos completamente replicados en múltiples regiones a través de la plataforma.",
        "Explanation": "Las tablas globales de Amazon DynamoDB permiten datos completamente replicados en múltiples regiones, proporcionando acceso de baja latencia a usuarios en diferentes ubicaciones geográficas. Esta arquitectura cumple con el requisito de sincronización de datos en tiempo real y alta disponibilidad sin intervención manual.",
        "Other Options": [
            "Desplegar Amazon RDS con réplicas de lectura entre regiones proporciona cierta capacidad de replicación, pero no logra el mismo acceso de baja latencia y capacidades de conmutación por error automáticas que las tablas globales de DynamoDB.",
            "Implementar Amazon RDS con despliegues Multi-AZ ofrece alta disponibilidad dentro de una región, pero no aborda la replicación entre regiones y requiere sincronización manual de datos, lo que puede llevar a una mayor complejidad y latencia.",
            "Configurar Amazon Aurora con réplicas entre regiones es una solución válida para alta disponibilidad, pero puede no proporcionar la misma facilidad de uso y sincronización en tiempo real que las tablas globales de DynamoDB, especialmente para una plataforma de comercio electrónico con datos dinámicos."
        ]
    }
]