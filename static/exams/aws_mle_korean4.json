[
    {
        "Question Number": "1",
        "Situation": "ML 엔지니어가 Amazon SageMaker에서 딥 러닝 모델의 훈련이 예상대로 수렴하지 않고 있음을 관찰하고 있습니다. 모델은 변동하는 손실 값을 보이며 에포크 동안 안정화되지 않습니다. 엔지니어는 모델 성능을 개선하기 위해 수렴 문제의 잠재적 원인을 식별해야 합니다.",
        "Question": "모델 훈련 과정에서 수렴 문제를 해결하기 위해 엔지니어가 가장 먼저 조사해야 할 것은 무엇인가요?",
        "Options": {
            "1": "훈련 전에 적용된 데이터 전처리 단계.",
            "2": "모델 훈련에 사용된 훈련 데이터의 양.",
            "3": "옵티마이저의 선택과 학습률 설정.",
            "4": "선택된 모델 아키텍처의 복잡성."
        },
        "Correct Answer": "옵티마이저의 선택과 학습률 설정.",
        "Explanation": "옵티마이저의 선택과 학습률 설정은 모델이 효과적으로 수렴하는지 여부를 결정하는 중요한 요소입니다. 부적절한 학습률은 느린 수렴을 초래하거나 모델이 완전히 발산하게 만들 수 있습니다. 따라서 수렴 문제를 해결할 때 가장 먼저 조사해야 할 영역입니다.",
        "Other Options": [
            "훈련 데이터의 양은 모델 성능에 영향을 미칠 수 있지만, 수렴 문제는 최적화 과정에 더 직접적으로 영향을 받습니다. 따라서 수렴 문제를 조사할 첫 번째 영역은 아닙니다.",
            "모델 아키텍처의 복잡성은 중요하지만, 일반적으로 최적화 및 학습률 설정이 적절한지 확인한 후에 고려되는 사항입니다. 적절히 최적화된 간단한 모델도 잘 수렴할 수 있습니다.",
            "데이터 전처리는 모델 성능에 중요하지만 일반적으로 수렴 문제의 주요 원인은 아닙니다. 전처리 단계가 올바르게 적용되었다면, 옵티마이저 설정이 더 즉각적인 관심사입니다."
        ]
    },
    {
        "Question Number": "2",
        "Situation": "한 금융 서비스 회사가 기계 학습 모델을 확장 가능한 방식으로 배포하면서 효율적인 자원 활용과 배포 파이프라인의 용이한 관리를 보장하고자 합니다.",
        "Question": "회사가 기계 학습 워크플로를 효과적으로 배포하고 관리하기 위해 어떤 전략을 채택해야 할까요?",
        "Options": {
            "1": "서버를 관리하지 않고 ML 추론을 실행하기 위해 AWS Lambda 함수를 구현합니다.",
            "2": "Amazon ECS를 사용하여 컨테이너화된 애플리케이션을 관리하고 ML 모델을 배포합니다.",
            "3": "Amazon S3를 활용하여 모델을 저장하고 배치 처리 작업을 트리거합니다.",
            "4": "Amazon SageMaker를 활용하여 컨테이너에서 ML 모델의 배포를 자동화합니다."
        },
        "Correct Answer": "Amazon SageMaker를 활용하여 컨테이너에서 ML 모델의 배포를 자동화합니다.",
        "Explanation": "Amazon SageMaker는 기계 학습 모델을 구축, 훈련 및 배포하기 위한 포괄적인 도구 모음을 제공합니다. 전체 워크플로를 자동화하고 컨테이너화를 지원하여 회사의 요구에 최적의 선택입니다.",
        "Other Options": [
            "Amazon ECS는 컨테이너화된 애플리케이션을 관리하는 데 적합하지만, SageMaker와 같이 기계 학습 워크플로를 위해 특별히 설계된 도구와 자동화 기능을 제공하지 않습니다.",
            "AWS Lambda는 추론을 실행할 수 있지만 복잡한 ML 워크플로를 처리하거나 모델 버전을 관리하는 데 설계되지 않아 SageMaker에 비해 확장 가능한 ML 배포에 덜 적합합니다.",
            "Amazon S3는 모델을 저장하고 작업을 트리거할 수 있지만, 기계 학습 워크플로의 효과적인 관리를 위한 오케스트레이션 및 배포 기능을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "3",
        "Situation": "운영 중인 기계 학습 모델이 시간이 지남에 따라 성능 저하의 징후를 보이고 있습니다. ML 엔지니어는 데이터 드리프트가 모델 정확도에 영향을 미칠 수 있다고 의심하며 이 문제를 효율적으로 모니터링하고 해결하기 위한 조치를 구현하고자 합니다. 엔지니어는 어떤 접근 방식을 취해야 할까요?",
        "Question": "배포된 기계 학습 모델에서 데이터 드리프트를 모니터링하고 관리하기 위한 최선의 전략은 무엇인가요?",
        "Options": {
            "1": "성능 메트릭에 따라 모델 재훈련을 자동화하기 위해 AWS Lambda를 활용합니다.",
            "2": "Amazon SageMaker Model Monitor를 사용하여 데이터 품질을 평가하고 드리프트를 감지합니다.",
            "3": "Amazon QuickSight를 구현하여 시간에 따른 모델 성능을 시각화합니다.",
            "4": "Amazon Kinesis를 활용하여 즉각적인 모델 업데이트를 위한 실시간 데이터를 스트리밍합니다."
        },
        "Correct Answer": "Amazon SageMaker Model Monitor를 사용하여 데이터 품질을 평가하고 드리프트를 감지합니다.",
        "Explanation": "Amazon SageMaker Model Monitor는 데이터 드리프트를 감지하고 입력 데이터 및 모델 예측의 품질을 모니터링하기 위해 특별히 설계되었습니다. 데이터 분포의 변화를 통찰하여 모델이 재훈련되거나 조정되어야 할 시점을 식별하는 데 도움을 줍니다.",
        "Other Options": [
            "Amazon QuickSight를 시각화에 구현하는 것은 데이터 드리프트 모니터링을 직접적으로 해결하지 않습니다. 성능에 대한 통찰을 제공할 수 있지만, 드리프트를 나타내는 데이터 분포의 변화를 구체적으로 감지하는 기능이 부족합니다.",
            "성능 메트릭에 따라 재훈련을 자동화하기 위해 AWS Lambda를 사용하는 것은 본질적으로 데이터 드리프트를 모니터링하지 않습니다. 성능 메트릭만으로 충분하다고 가정하는데, 이는 입력 데이터의 근본적인 변화를 포착하지 못할 수 있습니다.",
            "Amazon Kinesis를 활용하여 스트리밍 데이터를 수집하는 것은 실시간 데이터 수집에 유용하지만, 데이터 드리프트를 직접적으로 모니터링하지 않습니다. 이는 데이터 수집에 중점을 두고 있으며 기존 모델의 드리프트 분석보다는 수집에 초점을 맞추고 있습니다."
        ]
    },
    {
        "Question Number": "4",
        "Situation": "소매 회사가 예측 분석 모델을 배포하기 위한 기계 학습(ML) 워크플로를 간소화하려고 합니다. 이 회사는 모델 훈련 및 배포 프로세스를 자동화하여 확장성과 효율성을 보장하고 수동 개입을 최소화하고자 합니다.",
        "Question": "회사가 ML 워크플로의 오케스트레이션을 자동화하기 위해 어떤 AWS 서비스를 사용해야 합니까? (두 가지 선택)",
        "Options": {
            "1": "AWS Lambda를 사용하여 오케스트레이션 없이 ML 워크플로의 개별 단계를 실행합니다.",
            "2": "Amazon SageMaker Model Registry를 활용하여 모델 버전을 관리하고 배포를 자동화합니다.",
            "3": "AWS Step Functions를 활용하여 다양한 AWS 서비스의 워크플로를 조정합니다.",
            "4": "모델 훈련 후 Amazon EC2 인스턴스에 수동으로 모델을 배포합니다.",
            "5": "Amazon SageMaker Pipelines를 사용하여 엔드 투 엔드 ML 워크플로를 자동화합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon SageMaker Pipelines를 사용하여 엔드 투 엔드 ML 워크플로를 자동화합니다.",
            "Amazon SageMaker Model Registry를 활용하여 모델 버전을 관리하고 배포를 자동화합니다."
        ],
        "Explanation": "Amazon SageMaker Pipelines는 데이터 처리, 모델 훈련 및 배포의 오케스트레이션을 허용하여 엔드 투 엔드 ML 워크플로를 자동화하는 포괄적인 방법을 제공합니다. 또한 Amazon SageMaker Model Registry는 모델 버전을 관리하고 자동 배포를 용이하게 하여 최신 모델이 프로덕션에서 사용되도록 보장합니다.",
        "Other Options": [
            "Amazon EC2 인스턴스에 모델을 수동으로 배포하는 것은 자동화나 오케스트레이션을 제공하지 않으며, 이는 ML 프로젝트에서 효율적인 워크플로 관리에 필수적입니다.",
            "AWS Step Functions는 워크플로를 조정할 수 있지만, SageMaker Pipelines처럼 ML 워크플로를 효과적으로 타겟팅하지는 않습니다. SageMaker Pipelines는 그 목적을 위해 설계되었습니다.",
            "개별 단계를 실행하기 위해 AWS Lambda를 사용하는 것은 복잡한 ML 워크플로를 관리하는 데 필요한 오케스트레이션을 제공하지 않으며, Lambda는 서버리스 컴퓨팅 작업에 더 적합합니다."
        ]
    },
    {
        "Question Number": "5",
        "Situation": "기계 학습 팀이 AWS에 여러 모델을 배포하고 성능 및 인프라 건강을 효과적으로 모니터링할 수 있도록 하기를 원합니다. 그들은 AWS 서비스를 사용하여 모니터링 프로세스를 자동화하고 이상 징후나 시스템 실패 시 팀에 경고를 보내는 것을 고려하고 있습니다.",
        "Question": "기계 학습 모델의 인프라를 모니터링하고 특정 이벤트에 따라 경고를 트리거하는 데 사용할 수 있는 AWS 서비스는 무엇입니까?",
        "Options": {
            "1": "AWS Lambda를 사용하여 모델 엔드포인트에 대한 주기적인 검사를 실행하고 알림을 보냅니다.",
            "2": "Amazon Inspector를 활용하여 기계 학습 인프라의 보안 및 규정 준수를 평가합니다.",
            "3": "Amazon CloudWatch를 활용하여 메트릭을 기반으로 경고를 생성하고 Amazon EventBridge와 통합하여 이벤트 기반 알림을 설정합니다.",
            "4": "EC2 인스턴스에서 실행되는 사용자 정의 스크립트를 구현하여 모델을 모니터링하고 이메일을 통해 경고를 보냅니다."
        },
        "Correct Answer": "Amazon CloudWatch를 활용하여 메트릭을 기반으로 경고를 생성하고 Amazon EventBridge와 통합하여 이벤트 기반 알림을 설정합니다.",
        "Explanation": "Amazon CloudWatch는 AWS 리소스 및 애플리케이션 모니터링을 위해 특별히 설계되었습니다. 다양한 메트릭을 기반으로 경고를 생성할 수 있으며, Amazon EventBridge와 통합하여 이벤트에 대한 자동 응답을 설정하여 이상 징후가 발생할 때 적시에 알림과 조치를 보장합니다.",
        "Other Options": [
            "AWS Lambda는 서버리스 기능에 유용하지만, 자체적으로 포괄적인 모니터링 기능을 제공하지 않으며, 추가 구성 없이 이벤트 트리거와 직접 통합되지 않습니다.",
            "EC2에서 사용자 정의 스크립트를 사용하는 것은 가능하지만, 상당한 운영 오버헤드가 필요하며 AWS의 내장 모니터링 및 알림 기능을 활용하지 않으므로 비효율적입니다.",
            "Amazon Inspector는 주로 보안 평가 및 규정 준수 점검에 중점을 두고 있으며, 인프라 성능이나 모델 건강을 실시간으로 모니터링하는 데는 적합하지 않습니다."
        ]
    },
    {
        "Question Number": "6",
        "Situation": "소매 회사가 고객 구매 행동을 예측하기 위해 기계 학습 모델을 배포했습니다. 최적의 성능을 보장하고 데이터 기반 결정을 내리기 위해 회사는 모델의 성능 메트릭을 효과적으로 모니터링할 수 있는 솔루션을 설정하고자 합니다.",
        "Question": "회사가 기계 학습 모델의 중요한 성능 메트릭을 시각화하는 대시보드를 만들기 위해 어떤 AWS 서비스 조합을 사용해야 합니까?",
        "Options": {
            "1": "모델 훈련을 위해 Amazon SageMaker를 활용하고 배치 처리 작업을 위해 AWS Batch를 사용합니다.",
            "2": "워크플로를 오케스트레이션하기 위해 AWS Step Functions를 활용하고 데이터 저장을 위해 Amazon S3를 사용합니다.",
            "3": "데이터 변환을 위해 AWS Glue를 사용하고 로그 쿼리를 위해 Amazon Athena를 활용합니다.",
            "4": "시각화를 위해 Amazon QuickSight를 사용하고 로깅 및 메트릭 수집을 위해 Amazon CloudWatch를 사용합니다."
        },
        "Correct Answer": "시각화를 위해 Amazon QuickSight를 사용하고 로깅 및 메트릭 수집을 위해 Amazon CloudWatch를 사용합니다.",
        "Explanation": "Amazon QuickSight를 사용하면 성능 메트릭을 시각화하는 대화형 대시보드를 생성할 수 있으며, Amazon CloudWatch는 모델 성능을 시간에 따라 추적하는 데 필요한 로깅 및 모니터링 기능을 제공합니다. 이 조합은 회사의 모니터링 및 시각화 요구를 효과적으로 지원합니다.",
        "Other Options": [
            "AWS Glue와 Amazon Athena를 사용하는 것은 실시간 성능 모니터링에 적합하지 않습니다; Glue는 ETL 작업을 위한 것이고 Athena는 데이터를 쿼리하는 데 사용되며, 메트릭 모니터링을 위해 특별히 설계된 것이 아닙니다.",
            "훈련을 위해 Amazon SageMaker를 사용하는 것은 모니터링 대시보드의 필요성을 해결하지 않으며, AWS Batch는 배치 처리용으로 실시간 메트릭 시각화에는 적합하지 않습니다.",
            "AWS Step Functions를 오케스트레이션에 활용하고 Amazon S3를 저장소로 사용하는 것은 모델 성능 메트릭을 효과적으로 시각화하고 모니터링하는 데 필요한 도구를 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "7",
        "Situation": "한 금융 서비스 회사가 고객 지원 시스템을 자동화하려고 합니다. 이들은 매일 수천 건의 문의를 받고 있으며, 들어오는 메시지를 분류하고 자동 응답을 제공할 수 있는 솔루션을 구현하고 싶어합니다. 팀은 이 요구 사항을 충족하기 위해 다양한 AWS AI 서비스를 고려하고 있습니다.",
        "Question": "고객 문의를 분류하고 자동 응답을 제공하는 데 가장 효과적인 AWS 서비스는 무엇입니까?",
        "Options": {
            "1": "Amazon Rekognition을 사용하여 이미지 분석 및 고객 제출물에서 관련 콘텐츠를 식별합니다.",
            "2": "Amazon Lex를 사용하여 고객 문의를 이해하고 응답할 수 있는 대화형 인터페이스를 구축합니다.",
            "3": "자연어 처리를 위한 Amazon Comprehend를 사용하여 텍스트 데이터에서 인사이트를 추출합니다.",
            "4": "오디오 문의를 텍스트로 변환하여 추가 처리를 위한 Amazon Transcribe를 사용합니다."
        },
        "Correct Answer": "Amazon Lex를 사용하여 고객 문의를 이해하고 응답할 수 있는 대화형 인터페이스를 구축합니다.",
        "Explanation": "Amazon Lex는 음성과 텍스트를 사용하여 대화형 인터페이스를 생성하도록 특별히 설계되어 있어, 고객 지원 맥락에서 문의를 분류하고 자동 응답을 제공하는 데 이상적입니다.",
        "Other Options": [
            "Amazon Comprehend는 텍스트 분석에 유용하지만 대화형 인터페이스를 생성하거나 사용자에게 직접 응답을 제공하지 않습니다.",
            "Amazon Rekognition은 이미지 및 비디오 분석에 중점을 두고 있어 텍스트 기반 문의를 분류하는 데는 적용되지 않습니다.",
            "Amazon Transcribe는 오디오를 텍스트로 변환하는 데 효과적이지만 대화 또는 문의 분류의 필요를 해결하지 않습니다."
        ]
    },
    {
        "Question Number": "8",
        "Situation": "한 금융 서비스 회사가 Amazon SageMaker를 사용하여 실시간 예측을 위한 머신러닝 모델을 배포하고 있습니다. 모델이 출시된 후, 팀은 추론 비용이 예상보다 높다는 것을 알게 됩니다. 그들은 성능을 유지하면서 비용을 줄이기 위해 인스턴스 사용을 최적화하고 싶어합니다. 팀은 SageMaker 엔드포인트에 대한 인스턴스 유형 및 크기를 분석하고 추천하기 위해 AWS 도구를 사용하는 것을 고려하고 있습니다.",
        "Question": "팀이 SageMaker 엔드포인트 인스턴스 유형 및 크기를 최적화하기 위한 추천을 받기 위해 어떤 AWS 도구를 사용해야 합니까?",
        "Options": {
            "1": "AWS Lambda Cost Explorer",
            "2": "Amazon CloudWatch Logs Insights",
            "3": "Amazon SageMaker Inference Recommender",
            "4": "AWS Trusted Advisor Performance Recommendations"
        },
        "Correct Answer": "Amazon SageMaker Inference Recommender",
        "Explanation": "Amazon SageMaker Inference Recommender는 SageMaker 엔드포인트에 사용되는 인스턴스 유형 및 크기를 최적화하기 위한 추천을 제공하도록 특별히 설계되어 있어 팀의 요구에 가장 적합한 선택입니다.",
        "Other Options": [
            "AWS Lambda Cost Explorer는 AWS Lambda 함수와 관련된 비용을 분석하는 데 중점을 두고 있으며 SageMaker 엔드포인트에 대한 특정 추천을 제공하지 않습니다.",
            "AWS Trusted Advisor Performance Recommendations는 AWS 서비스에 대한 일반적인 지침을 제공하지만 SageMaker에 대한 맞춤형 인스턴스 추천을 제공하지 않습니다.",
            "Amazon CloudWatch Logs Insights는 로그 데이터를 쿼리하고 분석하는 데 사용되며 인스턴스 유형이나 크기를 최적화하기 위한 인사이트나 추천을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "9",
        "Situation": "한 금융 서비스 회사가 머신러닝 목적으로 대량의 거래 데이터를 Amazon S3 버킷에 수집하고 있습니다. 이들은 데이터 지연 및 불일치하는 데이터 형식으로 인해 전처리 단계에서 실패를 겪고 있습니다. 회사는 신뢰할 수 있는 데이터 수집 및 저장을 보장하고, 볼륨에 따라 확장할 수 있는 효과적인 솔루션이 필요합니다.",
        "Question": "데이터 수집을 관리하고 형식 불일치를 해결하면서 확장성을 보장하는 데 가장 적합한 AWS 서비스 조합은 무엇입니까?",
        "Options": {
            "1": "AWS Data Pipeline을 활용하여 온프레미스 시스템에서 Amazon RDS로 데이터 이동을 예약합니다.",
            "2": "Amazon S3 Select를 사용하여 S3에서 직접 데이터를 필터링하고 AWS Batch를 사용하여 전체 데이터 세트를 처리합니다.",
            "3": "AWS Glue를 사용하여 데이터를 크롤링하고 Amazon Redshift에 저장하여 분석합니다.",
            "4": "Amazon Kinesis Data Streams를 구현하여 데이터를 수집하고 AWS Lambda를 사용하여 S3에 저장하기 전에 처리합니다."
        },
        "Correct Answer": "Amazon Kinesis Data Streams를 구현하여 데이터를 수집하고 AWS Lambda를 사용하여 S3에 저장하기 전에 처리합니다.",
        "Explanation": "Amazon Kinesis Data Streams를 사용하면 대량의 데이터를 실시간으로 수집할 수 있으며, AWS Lambda를 활용하여 S3에 저장하기 전에 데이터를 전처리하고 형식을 지정할 수 있습니다. 이 조합은 확장성을 보장하고 데이터 지연 및 형식 불일치 문제를 효과적으로 해결합니다.",
        "Other Options": [
            "AWS Glue를 사용하여 데이터를 크롤링하고 Amazon Redshift에 저장하는 것은 실시간 수집에 이상적이지 않으며, AWS Glue는 연속 데이터 스트림보다 배치 처리에 더 적합합니다.",
            "Amazon S3 Select는 데이터를 제자리에서 필터링하도록 설계되었지만, 이 시나리오에서 필수적인 대규모 데이터 수집 및 전처리 솔루션을 제공하지 않습니다.",
            "AWS Data Pipeline을 활용하여 예약된 데이터 이동은 실시간 데이터 처리 요구에 덜 효율적이며 즉각적인 수집 및 형식 문제를 해결하지 못할 수 있습니다."
        ]
    },
    {
        "Question Number": "10",
        "Situation": "한 금융 서비스 회사가 Amazon SageMaker를 활용하여 사기 거래를 탐지하기 위한 머신러닝 모델을 개발하고 배포하고 있습니다. 이 회사는 배포된 모델이 산업 규정을 준수하고 전체 생애 주기 동안 엄격한 보안 기준을 유지하도록 해야 합니다.",
        "Question": "ML 엔지니어가 교육 및 배포 중 머신러닝 모델의 준수를 보장하고 보안을 강화하기 위해 어떤 SageMaker 기능을 활용해야 합니까?",
        "Options": {
            "1": "SageMaker Model Monitor를 사용하여 시간에 따라 데이터 품질 및 모델 성능 지표를 추적합니다.",
            "2": "SageMaker Pipelines를 활용하여 엔드 투 엔드 워크플로를 자동화하고 모델 버전을 관리합니다.",
            "3": "SageMaker Data Wrangler를 구현하여 모델 교육 전에 데이터를 전처리하고 시각화합니다.",
            "4": "SageMaker PrivateLink를 활성화하여 회사의 VPC에서 SageMaker 서비스에 대한 안전한 연결을 설정합니다."
        },
        "Correct Answer": "SageMaker PrivateLink를 활성화하여 회사의 VPC에서 SageMaker 서비스에 대한 안전한 연결을 설정합니다.",
        "Explanation": "SageMaker PrivateLink는 회사의 가상 사설 클라우드(VPC)에서 SageMaker에 대한 안전하고 개인적인 연결을 제공하여 데이터가 공용 인터넷을 통과하지 않도록 하여 보안과 산업 규정 준수를 강화합니다.",
        "Other Options": [
            "SageMaker Model Monitor는 데이터 품질 및 모델 성능을 추적하는 데 중요하지만, 모델 교육 및 배포 중 연결 및 데이터 처리의 보안 및 준수 측면을 구체적으로 다루지는 않습니다.",
            "SageMaker Data Wrangler는 데이터 전처리 및 시각화에 유용하지만, 배포된 머신러닝 모델의 보안이나 준수에 직접적으로 기여하지는 않습니다.",
            "SageMaker Pipelines는 워크플로를 자동화하고 버전을 관리하는 데 도움이 되지만, 산업 규정 준수를 위한 보안 기능을 본질적으로 제공하지는 않습니다."
        ]
    },
    {
        "Question Number": "11",
        "Situation": "머신러닝 팀이 고객 이탈을 예측하는 모델을 교육하기 위한 데이터셋을 준비하고 있습니다. 데이터셋에는 숫자, 텍스트 및 이미지 데이터가 포함되어 있지만 클래스 불균형과 잠재적인 노이즈로 어려움을 겪고 있습니다. ML 엔지니어는 모델 성능을 향상시키기 위해 효과적인 데이터 준비 전략을 구현해야 합니다.",
        "Question": "ML 엔지니어가 클래스 불균형을 효과적으로 해결하고 모델의 정확성을 향상시키기 위해 우선적으로 어떤 데이터 준비 전략을 선택해야 합니까?",
        "Options": {
            "1": "정규화를 구현하여 데이터셋의 숫자 특성의 스케일을 조정합니다.",
            "2": "텍스트 전처리 기술을 적용하여 불용어를 제거하고 모델에 사용되는 텍스트 데이터의 품질을 향상시킵니다.",
            "3": "합성 이미지를 생성하여 교육 데이터셋을 증강하고 이미지 분류 작업을 위한 더 다양한 샘플을 제공합니다.",
            "4": "SMOTE와 같은 재샘플링 기법을 활용하여 숫자 데이터셋의 클래스를 균형 있게 만듭니다."
        },
        "Correct Answer": "SMOTE와 같은 재샘플링 기법을 활용하여 숫자 데이터셋의 클래스를 균형 있게 만듭니다.",
        "Explanation": "SMOTE(합성 소수 클래스 오버샘플링 기법)와 같은 재샘플링 기법을 활용하면 소수 클래스에 대한 합성 예제를 생성하여 클래스 불균형 문제를 효과적으로 해결하고 고객 이탈 예측에서 모델 성능을 향상시킬 수 있습니다.",
        "Other Options": [
            "이미지 분류 작업을 위한 합성 이미지를 생성하는 것은 유용하지만, 데이터셋에 존재하는 클래스 불균형 문제를 직접적으로 해결하지는 않으며, 이는 모델의 정확성에 중요합니다.",
            "텍스트 전처리 기술을 적용하는 것은 텍스트 데이터의 품질을 향상시키는 데 중요하지만, 이 시나리오에서 우선적으로 해결해야 할 클래스 불균형 문제를 구체적으로 다루지는 않습니다.",
            "정규화는 숫자 특성의 스케일을 조정하는 데 필수적이지만, 클래스 불균형 문제를 직접적으로 해결하지 않으며, 이는 모델의 학습 능력에 상당한 영향을 미칠 수 있습니다."
        ]
    },
    {
        "Question Number": "12",
        "Situation": "머신러닝 엔지니어가 TensorFlow로 구축된 딥러닝 모델을 조정하고 있습니다. 모델의 성능이 정체되어 있으며, 엔지니어는 모델 아키텍처의 레이어 수를 조정하는 것을 고려하고 있습니다. 이 하이퍼파라미터 변경이 모델의 성능에 어떤 영향을 미칠 수 있는지 이해하고 싶어합니다.",
        "Question": "딥러닝 모델에서 레이어 수를 증가시키면 일반적으로 성능에 어떤 영향을 미칩니까?",
        "Options": {
            "1": "레이어 수가 모델의 학습 능력에 영향을 미치지 않으므로 성능에 영향을 주지 않습니다.",
            "2": "일정 시점까지는 복잡한 패턴을 학습할 수 있는 능력이 증가하여 일반적으로 성능이 향상됩니다.",
            "3": "모델이 기본 데이터 분포를 포착하기에는 너무 단순해지기 때문에 성능이 일반적으로 감소합니다.",
            "4": "항상 과적합을 초래하여 보지 못한 데이터에서 성능이 나빠집니다."
        },
        "Correct Answer": "일정 시점까지는 복잡한 패턴을 학습할 수 있는 능력이 증가하여 일반적으로 성능이 향상됩니다.",
        "Explanation": "딥러닝 모델에서 레이어 수를 증가시키면 데이터의 더 복잡한 특징을 학습할 수 있는 능력이 향상되어 교육 데이터에서 성능이 개선될 수 있습니다. 그러나 모델이 너무 복잡해져서 교육 데이터에 과적합되면 이러한 개선이 정체되거나 감소할 수 있습니다.",
        "Other Options": [
            "이것은 잘못된 것입니다. 레이어 수를 증가시키면 모델의 용량이 향상될 수 있으며, 구조가 너무 단순해지지 않는 한 감소하지 않습니다.",
            "이 옵션은 잘못되었습니다. 레이어 수는 모델의 학습 능력에 직접적인 영향을 미치며, 더 많은 레이어가 더 복잡한 패턴을 포착할 수 있습니다.",
            "이 옵션은 잘못되었습니다. 레이어 수는 모델의 학습 능력에 중요한 요소이며, 성능에 영향을 미칩니다."
        ]
    },
    {
        "Question Number": "13",
        "Situation": "소매 회사는 기계 학습 모델을 위한 데이터 수집 및 전처리 프로세스를 자동화하려고 합니다. 이들은 AWS 서비스를 사용하여 실시간 데이터 수집 및 처리를 처리할 수 있는 효율적인 파이프라인을 만들고자 합니다. 회사는 기존 AWS 리소스와 잘 통합되고 데이터 양이 증가함에 따라 확장할 수 있는 솔루션이 필요합니다.",
        "Question": "소매 회사의 기계 학습 워크플로우를 자동화하기 위해 데이터 수집 및 오케스트레이션에 가장 적합한 AWS 서비스 조합은 무엇입니까?",
        "Options": {
            "1": "Amazon EC2와 AWS Glue",
            "2": "AWS Step Functions와 Amazon Kinesis Data Streams",
            "3": "AWS Lambda와 Amazon S3",
            "4": "Amazon SageMaker와 AWS Batch"
        },
        "Correct Answer": "AWS Step Functions와 Amazon Kinesis Data Streams",
        "Explanation": "AWS Step Functions는 워크플로우를 오케스트레이션하고 작업의 순서를 관리할 수 있으며, Amazon Kinesis Data Streams는 실시간 데이터 수집을 가능하게 하여 이 조합이 확장 가능한 방식으로 데이터 처리를 자동화하는 데 이상적입니다.",
        "Other Options": [
            "AWS Lambda와 Amazon S3는 서버리스 처리 및 저장에 적합하지만, 실시간 데이터 수집에서 복잡한 워크플로우에 필요한 오케스트레이션 기능을 제공하지 않습니다.",
            "Amazon EC2와 AWS Glue는 데이터의 배치 처리 및 변환을 처리할 수 있지만, Kinesis가 제공하는 실시간 수집 기능이 부족하여 회사의 필요에 덜 적합합니다.",
            "Amazon SageMaker와 AWS Batch는 데이터 수집 및 오케스트레이션보다는 모델 훈련 및 배치 추론에 중점을 두고 있어 초기 데이터 처리 단계에 필수적인 기능이 아닙니다."
        ]
    },
    {
        "Question Number": "14",
        "Situation": "데이터 엔지니어링 팀은 AWS에서 ML 모델의 배포를 자동화하는 임무를 맡고 있습니다. 이들은 컴퓨팅 리소스를 프로비저닝하고 서로 다른 스택 간의 통신을 보장하기 위해 필요한 인프라를 설정해야 합니다. 팀은 이를 달성하기 위해 AWS CloudFormation 또는 AWS CDK를 사용하는 것을 고려하고 있습니다.",
        "Question": "팀이 컴퓨팅 리소스의 프로비저닝을 효과적으로 자동화하고 스택 간의 종속성을 관리하기 위해 어떤 접근 방식을 활용해야 합니까?",
        "Options": {
            "1": "리소스 오케스트레이션을 위한 AWS Lambda",
            "2": "워크플로우 관리를 위한 AWS Step Functions",
            "3": "모델의 직접 배포를 위한 AWS EC2 인스턴스",
            "4": "모듈화를 위한 AWS CloudFormation과 중첩 스택"
        },
        "Correct Answer": "모듈화를 위한 AWS CloudFormation과 중첩 스택",
        "Explanation": "AWS CloudFormation은 리소스를 자동으로 프로비저닝할 수 있으며, 중첩 스택을 통해 종속성을 관리할 수 있어 복잡한 ML 워크플로우를 배포하는 데 이상적입니다. 이 접근 방식은 리소스의 더 나은 조직 및 모듈화를 촉진하여 확장 가능한 ML 애플리케이션에 필수적입니다.",
        "Other Options": [
            "AWS Lambda는 주로 서버리스 함수 및 이벤트 기반 아키텍처에 사용되며, 컴퓨팅 리소스를 직접 프로비저닝하거나 복잡한 인프라 스택을 관리하는 데 사용되지 않습니다.",
            "AWS EC2 인스턴스는 ML 모델을 실행하는 데 사용할 수 있지만, 자동 배포를 위한 오케스트레이션 기능이나 인프라 관리 기능을 제공하지 않습니다.",
            "AWS Step Functions는 워크플로우를 관리하고 서비스를 조정하는 데 탁월하지만, ML 워크플로우에 필요한 기본 컴퓨팅 리소스의 프로비저닝을 자동화하지는 않습니다."
        ]
    },
    {
        "Question Number": "15",
        "Situation": "ML 엔지니어가 Amazon SageMaker를 사용하여 분류 모델을 작업하고 있으며, 모델 출력이 해석 가능하고 공정한지 확인하고자 합니다. 엔지니어는 SageMaker Clarify를 사용하여 모델의 예측을 분석할 계획입니다.",
        "Question": "모델 출력을 해석하기 위해 어떤 SageMaker Clarify 기능을 활용해야 합니까? (두 가지 선택)",
        "Options": {
            "1": "편향 탐지",
            "2": "특징 중요도",
            "3": "데이터 레이블링",
            "4": "모델 평가",
            "5": "하이퍼파라미터 튜닝"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "편향 탐지",
            "특징 중요도"
        ],
        "Explanation": "편향 탐지는 모델의 예측에서 잠재적인 편향을 식별하는 데 도움이 되며, 특징 중요도는 모델의 결정을 이끄는 특징을 드러냅니다. 두 가지 모두 모델 출력을 해석하고 AI 애플리케이션의 공정성을 보장하는 데 중요합니다.",
        "Other Options": [
            "데이터 레이블링은 훈련을 위한 데이터셋을 준비하는 데 사용되며, 모델 출력 해석에 대한 통찰력을 제공하지 않습니다.",
            "하이퍼파라미터 튜닝은 모델 성능을 최적화하는 방법이지만, 모델이 생성한 출력을 해석하는 것과는 관련이 없습니다.",
            "모델 평가는 모델의 전반적인 성능을 평가하지만, 모델의 예측 해석을 구체적으로 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "16",
        "Situation": "기계 학습 엔지니어가 실시간 예측 시스템을 위한 데이터 수집 프로세스를 자동화해야 합니다. 목표는 데이터 파이프라인이 신뢰할 수 있고 확장 가능하며 장애를 우아하게 처리할 수 있도록 하는 것입니다.",
        "Question": "엔지니어가 장애 내성과 다른 AWS 서비스와의 쉬운 통합을 보장하면서 자동화된 데이터 수집 워크플로를 조정하기 위해 어떤 AWS 서비스를 사용해야 합니까?",
        "Options": {
            "1": "AWS Glue for Data Cataloging and ETL",
            "2": "Amazon Kinesis Data Firehose for Streaming Data",
            "3": "AWS Step Functions for Workflow Orchestration",
            "4": "AWS Lambda for Real-Time Data Processing"
        },
        "Correct Answer": "AWS Step Functions for Workflow Orchestration",
        "Explanation": "AWS Step Functions는 워크플로를 조정하고 데이터 파이프라인의 다양한 단계를 관리하도록 설계되었습니다. 여러 AWS 서비스의 통합을 허용하고, 워크플로의 시각적 모니터링을 제공하며, 장애 내성을 강화하는 오류 처리 및 재시도 메커니즘을 포함합니다.",
        "Other Options": [
            "AWS Lambda는 이벤트에 응답하여 코드를 실행하는 데 주로 사용되며, 다단계 데이터 수집 워크플로에 필요한 완전한 조정을 제공하지 않을 수 있습니다.",
            "Amazon Kinesis Data Firehose는 스트리밍 데이터 전송에 적합하지만, 여러 단계와 의존성을 가진 복잡한 워크플로를 관리하기 위한 조정 기능을 제공하지 않습니다.",
            "AWS Glue는 ETL 프로세스와 데이터 카탈로깅에 적합하지만, 엔드 투 엔드 데이터 수집 워크플로를 자동화하는 데 필요한 조정 기능이 부족합니다."
        ]
    },
    {
        "Question Number": "17",
        "Situation": "금융 서비스 회사가 사기 탐지에 사용되는 기계 학습 모델의 효율성을 개선하기 위해 노력하고 있습니다. 팀은 정확성을 손상시키지 않으면서 모델 훈련에 소요되는 시간을 줄이기 위한 다양한 기술을 탐색하고 있습니다.",
        "Question": "팀이 모델 훈련 시간을 효과적으로 줄이기 위해 구현할 수 있는 방법은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "분산 훈련을 활용하여 여러 머신을 이용해 더 빠른 처리를 합니다.",
            "2": "복잡한 모델을 사용하여 데이터의 더 많은 특징과 패턴을 포착합니다.",
            "3": "성능 향상이 멈출 때 훈련을 중단하기 위해 조기 중지를 구현합니다.",
            "4": "모델 정확성을 향상시키기 위해 훈련 데이터셋의 크기를 늘립니다.",
            "5": "최고의 성능을 위해 그리드 검색을 사용하여 하이퍼파라미터를 최적화합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "성능 향상이 멈출 때 훈련을 중단하기 위해 조기 중지를 구현합니다.",
            "분산 훈련을 활용하여 여러 머신을 이용해 더 빠른 처리를 합니다."
        ],
        "Explanation": "조기 중지를 구현하면 모델의 검증 세트에서 성능 향상이 멈출 때 훈련 과정을 종료할 수 있어 시간과 자원을 절약할 수 있습니다. 분산 훈련을 활용하면 작업 부하를 여러 머신에 분산시켜 훈련 과정을 크게 가속화할 수 있습니다.",
        "Other Options": [
            "훈련 데이터셋의 크기를 늘리면 모델 정확성을 향상시킬 수 있지만, 훈련 시간이 길어질 수 있어 훈련 시간을 줄이는 목표와는 반대입니다.",
            "복잡한 모델을 사용하면 더 많은 계산 자원과 긴 훈련 시간이 필요하므로 훈련 기간을 줄이는 목표와 일치하지 않습니다.",
            "하이퍼파라미터 최적화는 모델 성능을 향상시킬 수 있지만, 종종 추가적인 시간과 계산이 필요하여 훈련 시간을 직접 줄이는 데 기여하지 않습니다."
        ]
    },
    {
        "Question Number": "18",
        "Situation": "의료 기관이 훈련 및 추론에 상당한 계산 자원을 요구하는 기계 학습 모델을 배포하려고 합니다. 그들은 높은 GPU 작업 부하를 처리할 수 있는 적절한 컴퓨팅 환경을 선택해야 하며, 비용과 향후 모델 반복을 위한 확장성도 고려해야 합니다.",
        "Question": "조직이 GPU 가속 기계 학습 작업의 최적 성능을 보장하면서 자원 확장의 유연성을 유지하기 위해 어떤 AWS 서비스를 활용해야 합니까?",
        "Options": {
            "1": "AWS Lambda",
            "2": "Amazon SageMaker Notebooks",
            "3": "Amazon EC2 T3 Instances",
            "4": "Amazon EC2 P4 Instances"
        },
        "Correct Answer": "Amazon EC2 P4 Instances",
        "Explanation": "Amazon EC2 P4 Instances는 고성능 기계 학습 훈련 및 추론을 위해 특별히 설계되어 있으며, 자원 집약적인 작업에 이상적인 강력한 GPU 기능을 제공합니다. 이는 조직의 요구에 가장 적합한 선택입니다.",
        "Other Options": [
            "AWS Lambda는 서버리스 컴퓨팅 서비스로, 특히 높은 GPU 자원이 필요한 장기 실행 기계 학습 작업에 최적화되어 있지 않습니다.",
            "Amazon EC2 T3 Instances는 일반 용도로 설계되어 있으며, 고성능 기계 학습 작업에 필요한 GPU 사양이 부족하여 이 시나리오에 적합하지 않습니다.",
            "Amazon SageMaker Notebooks는 개발 환경을 제공하지만 모델 배포를 위한 컴퓨팅 서비스가 아니며, 단독으로 사용하면 훈련 및 추론을 위한 특정 고성능 요구 사항을 충족하지 못합니다."
        ]
    },
    {
        "Question Number": "19",
        "Situation": "ML 엔지니어가 새로 개발된 추천 시스템의 그림자 변형을 기존의 프로덕션 변형과 비교하여 성능을 평가하는 임무를 맡았습니다. 목표는 그림자 모델이 완전히 전환되기 전에 더 나은 사용자 참여 지표를 제공할 수 있는지를 판단하는 것입니다.",
        "Question": "다음 중 그림자 변형의 성능을 프로덕션 변형과 비교하는 데 가장 적합한 지표는 무엇입니까?",
        "Options": {
            "1": "추천 항목에 대한 클릭률 (CTR)",
            "2": "모델 훈련에 소요된 시간",
            "3": "훈련 데이터셋 크기",
            "4": "모델에서 사용된 특성의 수"
        },
        "Correct Answer": "추천 항목에 대한 클릭률 (CTR)",
        "Explanation": "추천 항목에 대한 클릭률 (CTR)은 사용자 참여의 직접적인 측정값이며, 모델이 프로덕션과 유사한 환경에서 얼마나 효과적으로 작동하는지를 반영합니다. 이를 통해 엔지니어는 그림자 모델이 기존 프로덕션 변형보다 가치를 제공하는지를 평가할 수 있습니다.",
        "Other Options": [
            "모델 훈련에 소요된 시간은 모델이 실제 환경에서 얼마나 잘 작동하는지를 반영하지 않습니다. 이는 사용자 참여보다는 모델 훈련 효율성을 평가하는 데 더 관련이 있습니다.",
            "모델에서 사용된 특성의 수는 성능 지표가 아니며, 모델 복잡성에 영향을 미칠 수 있지만, 모델이 사용자를 얼마나 잘 참여시키는지를 직접적으로 나타내지 않습니다.",
            "훈련 데이터셋 크기는 모델 훈련에 중요하지만, 사용자 상호작용이나 참여 지표 측면에서 모델의 성능에 대한 통찰을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "20",
        "Situation": "금융 서비스 회사는 기계 학습 모델이 규정을 준수하고 전체 생애 주기 동안 보안을 유지하도록 해야 합니다. 이들은 ML 시스템의 성능과 접근을 추적하기 위해 강력한 모니터링 및 로깅 솔루션을 구현하고자 합니다.",
        "Question": "회사가 규정 준수 및 보안을 위해 기계 학습 시스템을 효과적으로 모니터링하고 로깅하기 위해 어떤 전략을 구현해야 합니까?",
        "Options": {
            "1": "SageMaker에서 로깅을 활성화하여 훈련 작업 세부정보를 캡처하고 저장합니다.",
            "2": "Amazon CloudWatch를 구현하여 훈련 및 추론에 대한 메트릭을 수집하고 추적합니다.",
            "3": "AWS Config를 사용하여 ML 리소스의 구성을 모니터링합니다.",
            "4": "AWS CloudTrail을 활용하여 ML 서비스에 대한 API 호출을 로깅합니다."
        },
        "Correct Answer": "AWS CloudTrail을 활용하여 ML 서비스에 대한 API 호출을 로깅합니다.",
        "Explanation": "AWS CloudTrail은 기계 학습 서비스를 포함한 AWS 서비스에 대한 API 호출을 기록하는 포괄적인 로깅 솔루션을 제공합니다. 이를 통해 회사는 ML 모델에 접근한 사람과 수행된 작업을 추적하여 보안 규정을 준수할 수 있습니다.",
        "Other Options": [
            "Amazon CloudWatch는 성능 및 운영 메트릭 모니터링에 유용하지만, 규정 준수를 위한 API 호출의 세부 로깅을 제공하지 않습니다.",
            "AWS Config는 리소스 구성을 추적하는 데 효과적이지만, ML 시스템에서의 접근 및 수행된 작업을 모니터링하기 위한 필요한 로깅을 제공하지 않습니다.",
            "SageMaker에서 로깅을 활성화하면 훈련 작업 세부정보를 캡처하지만, 포괄적인 규정 준수 모니터링에 필요한 API 호출 로깅의 더 넓은 범위를 포함하지 않습니다."
        ]
    },
    {
        "Question Number": "21",
        "Situation": "ML 엔지니어가 인기 있는 프레임워크를 사용하여 이미지 분류를 위한 딥 러닝 모델을 개발하고 있습니다. 엔지니어는 훈련 프로세스를 간소화하고 SageMaker의 분산 훈련 및 모델 튜닝 기능을 활용하기 위해 Amazon SageMaker의 스크립트 모드를 활용하기로 결정했습니다.",
        "Question": "엔지니어가 SageMaker의 스크립트 모드 내에서 이미지 분류 모델을 효과적으로 훈련하기 위해 사용할 수 있는 프레임워크는 무엇입니까?",
        "Options": {
            "1": "Scikit-learn",
            "2": "Keras",
            "3": "XGBoost",
            "4": "TensorFlow"
        },
        "Correct Answer": "TensorFlow",
        "Explanation": "TensorFlow는 Amazon SageMaker의 스크립트 모드에서 널리 지원되는 프레임워크로, 이미지 분류와 같은 딥 러닝 작업을 위한 효율적인 모델 훈련 및 배포를 가능하게 합니다.",
        "Other Options": [
            "Keras는 TensorFlow 위에서 실행되는 고급 API이지만, TensorFlow와 같은 방식으로 스크립트 모드에서 직접 지원되지 않습니다. Keras는 모델 구축에 사용할 수 있지만, SageMaker의 스크립트 모드에서 TensorFlow와 같은 수준의 통합 및 지원을 제공하지 않습니다.",
            "Scikit-learn은 주로 전통적인 기계 학습 작업에 사용되며, 이미지 분류와 같은 딥 러닝 응용 프로그램에 최적화되어 있지 않습니다. SageMaker에서 사용할 수 있지만, 딥 러닝 작업에 가장 적합한 선택은 아닙니다.",
            "XGBoost는 그래디언트 부스팅을 위해 설계되었으며 주로 구조화된 데이터 문제에 사용됩니다. 이미지 분류 작업에는 TensorFlow와 같은 딥 러닝 프레임워크가 필요하므로 적합하지 않습니다."
        ]
    },
    {
        "Question Number": "22",
        "Situation": "데이터 과학자가 AWS에서 여러 사용자가 애플리케이션에 안전하게 접근하고 상호작용할 수 있도록 하는 머신러닝 애플리케이션을 구현하고 있습니다. 그들은 특정 리소스와 애플리케이션 내의 작업에 접근할 수 있는 권한이 있는 인원만 접근할 수 있도록 보장해야 하며, 조직의 보안 정책을 준수해야 합니다.",
        "Question": "데이터 과학자가 머신러닝 애플리케이션의 권한을 효과적으로 관리하기 위해 어떤 IAM 구성을 구현해야 합니까?",
        "Options": {
            "1": "모든 머신러닝 서비스에 대한 모든 작업을 허용하는 공개 IAM 역할을 생성하고 외부 사용자와 공유합니다.",
            "2": "모든 S3 버킷에 대한 접근을 허용하는 IAM 정책을 생성하고 이를 애플리케이션 IAM 역할에 연결합니다.",
            "3": "모든 AWS 서비스에 대한 전체 접근 권한을 가진 단일 IAM 역할을 생성하고 이를 모든 사용자에게 할당합니다.",
            "4": "각 사용자 역할에 필요한 최소 권한을 부여하는 IAM 정책을 생성하고 이를 해당 IAM 역할에 연결합니다."
        },
        "Correct Answer": "각 사용자 역할에 필요한 최소 권한을 부여하는 IAM 정책을 생성하고 이를 해당 IAM 역할에 연결합니다.",
        "Explanation": "이 접근 방식은 최소 권한 원칙을 따르며, 사용자가 자신의 역할에 필요한 리소스에만 접근할 수 있도록 보장하여 보안과 준수를 강화합니다.",
        "Other Options": [
            "이 옵션은 모든 사용자가 모든 AWS 서비스에 무제한으로 접근할 수 있게 하여 애플리케이션을 심각한 보안 위험에 노출시키며, 이는 모범 사례에 위배됩니다.",
            "모든 S3 버킷에 대한 접근을 허용하는 것은 편리해 보일 수 있지만, 최소 권한 원칙을 따르지 않으며 무단 데이터 접근이나 조작으로 이어질 수 있습니다.",
            "공개 IAM 역할을 생성하는 것은 외부 사용자에게 머신러닝 서비스에 대한 무제한 접근을 허용하여 보안을 저해하며, 이는 심각한 준수 위반입니다."
        ]
    },
    {
        "Question Number": "23",
        "Situation": "한 회사가 AWS 서비스를 사용하여 엣지 장치에 머신러닝 모델을 배포하고 있습니다. ML 엔지니어는 이러한 장치에서 성능을 최적화하면서 최소한의 리소스를 활용하도록 모델을 보장하고 싶어합니다. 엔지니어는 이 목표를 효과적으로 달성하기 위한 다양한 방법을 고려하고 있습니다.",
        "Question": "엣지 장치에 배포하기 위해 머신러닝 모델을 최적화할 수 있는 AWS 서비스는 무엇입니까?",
        "Options": {
            "1": "AWS DeepRacer",
            "2": "AWS Lambda",
            "3": "AWS Greengrass",
            "4": "Amazon SageMaker Neo"
        },
        "Correct Answer": "Amazon SageMaker Neo",
        "Explanation": "Amazon SageMaker Neo는 엣지 장치에 배포하기 위해 머신러닝 모델을 최적화하도록 설계되어 있으며, 성능을 향상시키고 리소스 요구 사항을 줄여 실행할 수 있도록 합니다. 훈련된 모델을 대상 하드웨어에 최적화된 형식으로 컴파일하여 이 시나리오에 가장 적합한 선택입니다.",
        "Other Options": [
            "AWS Greengrass는 AWS 기능을 엣지 장치로 확장하는 서비스이지만, 성능을 위해 모델을 특별히 최적화하지는 않습니다. AWS Lambda 함수의 로컬 실행과 IoT 장치 관리를 허용합니다.",
            "AWS Lambda는 이벤트에 응답하여 코드를 실행하는 서버리스 컴퓨팅 서비스이지만, 엣지 배포를 위한 머신러닝 모델 최적화를 위해 특별히 설계되지 않았습니다. 이벤트 기반 아키텍처에 더 적합합니다.",
            "AWS DeepRacer는 강화 학습 모델을 훈련하고 자율주행 차량을 경주하기 위한 서비스로, 엣지 배포를 위한 머신러닝 모델 최적화와는 관련이 없습니다. 특정 응용 프로그램에 초점을 맞추고 있습니다."
        ]
    },
    {
        "Question Number": "24",
        "Situation": "머신러닝 팀은 Amazon SageMaker에서 모델을 훈련하기 위해 구조화된 데이터와 비구조화된 데이터 유형을 포함하는 다양한 데이터 세트를 준비하는 임무를 맡고 있습니다. 팀은 이 데이터를 SageMaker Data Wrangler에 효율적으로 수집하고 나중에 사용할 수 있도록 기능이 효율적으로 저장되도록 하기를 원합니다. 그들은 수동 개입을 최소화하고 데이터 준비를 최적화할 수 있는 다양한 접근 방식을 고려하고 있습니다.",
        "Question": "Amazon SageMaker Data Wrangler에 구조화된 데이터와 비구조화된 데이터를 수집하고 준비하는 가장 효과적인 방법은 무엇입니까?",
        "Options": {
            "1": "Amazon S3를 사용하여 데이터 세트를 업로드한 다음, 이를 SageMaker Data Wrangler에 가져오고 Feature Store를 수동으로 구성합니다.",
            "2": "SageMaker Data Wrangler와 Feature Store에 가져오기 전에 데이터를 처리하는 AWS Batch 작업을 생성합니다.",
            "3": "AWS Glue를 사용하여 데이터를 카탈로그하고 데이터를 SageMaker Data Wrangler와 Feature Store에 자동으로 수집하는 데이터 파이프라인을 생성합니다.",
            "4": "Amazon Kinesis Data Stream을 설정하여 데이터를 SageMaker Data Wrangler에 지속적으로 전송하여 실시간 기능 추출을 수행합니다."
        },
        "Correct Answer": "AWS Glue를 사용하여 데이터를 카탈로그하고 데이터를 SageMaker Data Wrangler와 Feature Store에 자동으로 수집하는 데이터 파이프라인을 생성합니다.",
        "Explanation": "AWS Glue를 사용하여 카탈로그를 만들고 데이터 파이프라인을 생성하면 구조화된 데이터와 비구조화된 데이터를 효율적으로 처리할 수 있는 자동화된 데이터 수집이 가능합니다. 이 접근 방식은 수동 단계를 최소화하고 데이터가 SageMaker Data Wrangler와 SageMaker Feature Store에서 쉽게 사용할 수 있도록 보장하여 기능 엔지니어링과 모델 훈련을 간소화합니다.",
        "Other Options": [
            "데이터를 Amazon S3에 업로드하고 수동으로 SageMaker Data Wrangler에 가져오는 것은 노동 집약적이며 데이터 준비와 기능 저장의 불일치로 이어질 수 있습니다.",
            "Amazon Kinesis Data Stream을 사용하는 것은 다양한 데이터 세트를 SageMaker Data Wrangler에 배치 수집하기보다는 실시간 데이터 처리에 더 적합하여 팀의 요구에 덜 최적입니다.",
            "AWS Batch 작업을 생성하는 것은 AWS Glue로 더 효율적으로 처리할 수 있는 작업에 불필요한 복잡성을 도입합니다. AWS Glue는 데이터 카탈로그 및 ETL 프로세스를 위해 특별히 설계된 기능을 제공합니다."
        ]
    },
    {
        "Question Number": "25",
        "Situation": "기계 학습 엔지니어가 웹 애플리케이션에 대한 실시간 예측을 제공하는 훈련된 모델을 배포하는 임무를 맡았습니다. 모델은 들어오는 요청량에 따라 자동으로 확장되어야 하며, 배포는 운영 오버헤드를 최소화해야 합니다. 이러한 요구 사항을 고려하여 엔지니어는 배포를 위한 최상의 엔드포인트 유형을 평가하고 있습니다.",
        "Question": "실시간 예측을 위한 자동 확장 및 최소 운영 오버헤드를 충족하기 위해 엔지니어가 선택해야 할 엔드포인트 유형은 무엇입니까?",
        "Options": {
            "1": "Amazon SageMaker Asynchronous Endpoint",
            "2": "Amazon SageMaker Serverless Endpoint",
            "3": "Amazon SageMaker Real-Time Endpoint",
            "4": "Amazon SageMaker Batch Transform"
        },
        "Correct Answer": "Amazon SageMaker Serverless Endpoint",
        "Explanation": "Amazon SageMaker Serverless Endpoints는 자동 확장 및 최소 관리가 필요한 작업 부하를 위해 특별히 설계되었습니다. 사용하지 않을 때는 0으로 확장할 수 있어 비용을 줄이고, 수요에 따라 자동으로 확장되므로 변동하는 트래픽을 가진 실시간 예측 작업에 이상적입니다.",
        "Other Options": [
            "Amazon SageMaker Real-Time Endpoints는 리소스 프로비저닝이 필요하여 변동하는 부하에서 관리 오버헤드와 비용이 증가할 수 있습니다.",
            "Amazon SageMaker Batch Transform은 배치 처리를 위해 설계되었으며, 개별 요청에 응답하기보다는 대량의 데이터 세트를 한 번에 처리하므로 실시간 예측에 적합하지 않습니다.",
            "Amazon SageMaker Asynchronous Endpoints는 요청을 지연된 방식으로 처리할 수 있는 시나리오를 위해 설계되어 즉각적인 응답이 필요한 애플리케이션에는 적합하지 않습니다."
        ]
    },
    {
        "Question Number": "26",
        "Situation": "금융 서비스 회사가 실시간 사기 탐지를 위한 기계 학습 모델을 구현하고 있습니다. 시스템이 비용 효율적이면서 낮은 대기 시간과 높은 성능을 유지할 수 있도록 다양한 배포 전략을 평가해야 합니다.",
        "Question": "회사가 ML 워크플로의 성능과 비용을 최적화하기 위해 고려해야 할 전략은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "서버리스 모델 추론을 위해 AWS Lambda를 구현하여 확장성을 보장합니다.",
            "2": "모든 사용자의 대기 시간을 최소화하기 위해 다중 AZ 아키텍처를 채택합니다.",
            "3": "비용 최적화를 위해 배치 처리 작업에 스팟 인스턴스를 활용합니다.",
            "4": "비용을 줄이기 위해 실시간 추론에 온디맨드 인스턴스를 활용합니다.",
            "5": "일관된 낮은 대기 시간 예측을 위해 Amazon SageMaker의 실시간 엔드포인트를 사용합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "서버리스 모델 추론을 위해 AWS Lambda를 구현하여 확장성을 보장합니다.",
            "일관된 낮은 대기 시간 예측을 위해 Amazon SageMaker의 실시간 엔드포인트를 사용합니다."
        ],
        "Explanation": "AWS Lambda를 구현하면 수요에 따라 자동으로 확장할 수 있는 서버리스 아키텍처를 제공하여, 트래픽이 적은 기간 동안 비용을 절감하고 피크 시간 동안 높은 가용성을 유지할 수 있습니다. Amazon SageMaker의 실시간 엔드포인트를 사용하는 것은 낮은 대기 시간 예측을 위해 특별히 설계되어 사기 탐지 시스템이 효율적으로 작동하고 실시간 요구 사항을 충족하도록 보장합니다.",
        "Other Options": [
            "온디맨드 인스턴스는 유연성에 유리할 수 있지만, AWS Lambda와 같은 서버리스 옵션에 비해 항상 가장 비용 효율적인 선택이 아닐 수 있습니다.",
            "다중 AZ 아키텍처는 주로 중복성과 높은 가용성을 제공하며 성능이나 비용 최적화에 중점을 두지 않으므로 낮은 대기 시간 요구를 직접적으로 해결하지 않을 수 있습니다.",
            "스팟 인스턴스는 낮은 비용으로 배치 처리에 적합하지만, 항상 가용성을 보장하지 않으므로 실시간 추론 작업에 대한 대기 시간 문제를 초래할 수 있습니다."
        ]
    },
    {
        "Question Number": "27",
        "Situation": "소매 회사가 기계 학습을 사용하여 재고 관리를 개선하려고 합니다. 그들은 다양한 제품에 대한 수요를 예측하여 재고 수준을 최적화하고 과잉 재고를 줄이기를 원합니다. 데이터 과학 팀은 이 작업을 위해 다양한 ML 알고리즘을 고려하고 있습니다.",
        "Question": "과거 판매 데이터와 계절적 추세를 기반으로 제품 수요를 예측하는 데 가장 적합한 기계 학습 알고리즘은 무엇입니까?",
        "Options": {
            "1": "Support Vector Machines (SVM) - 고차원 공간에서 분류 문제에 효과적입니다.",
            "2": "Random Forest - 과적합에 강하고 데이터의 비선형 관계를 처리할 수 있습니다.",
            "3": "Linear Regression - 제품 특성과 연속 수요 값 간의 관계를 모델링할 수 있습니다.",
            "4": "K-means Clustering - 판매 패턴에 따라 유사한 제품을 그룹화하여 더 나은 분석을 제공합니다."
        },
        "Correct Answer": "Random Forest - 과적합에 강하고 데이터의 비선형 관계를 처리할 수 있습니다.",
        "Explanation": "Random Forest는 회귀 및 분류 작업을 모두 처리할 수 있는 강력한 앙상블 학습 방법입니다. 제품 수요와 같은 연속적인 결과를 예측하는 데 특히 효과적이며, 데이터의 복잡한 상호작용과 비선형 패턴을 포착할 수 있어 이 시나리오에 적합합니다.",
        "Other Options": [
            "Support Vector Machines (SVM)는 주로 분류 작업에 사용되므로 연속 값인 수요 예측에는 덜 적합합니다.",
            "Linear Regression은 선형 관계에 적합하지만 계절적 추세와 비선형 패턴을 효과적으로 포착하지 못할 수 있어 정확한 수요 예측에 중요합니다.",
            "K-means Clustering은 데이터를 그룹화하는 데 사용되는 비지도 학습 알고리즘으로, 예측을 제공하지 않으므로 이 경우의 주요 요구 사항인 수요 예측을 직접적으로 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "28",
        "Situation": "머신 러닝 엔지니어가 머신 러닝 모델을 배포하기 위한 CI/CD 파이프라인을 구축하는 임무를 맡았습니다. 모델은 배포 전에 올바르게 작동하는지 확인하기 위해 자동화된 테스트가 필요합니다. 엔지니어는 개별 함수에 대한 단위 테스트, 구성 요소 상호 작용에 대한 통합 테스트, 데이터 수집부터 모델 예측까지의 전체 워크플로우를 검증하는 엔드 투 엔드 테스트 등 다양한 수준의 테스트를 구현해야 합니다. 테스트 프레임워크는 팀에서 사용하는 기존 CI/CD 도구와 호환되어야 합니다.",
        "Question": "다음 중 머신 러닝 모델의 CI/CD 파이프라인에서 자동화된 테스트 생성을 가장 잘 지원하는 접근 방식은 무엇입니까?",
        "Options": {
            "1": "정식 테스트를 구현하지 않고 오류를 추적하기 위해 간단한 로깅 메커니즘을 사용합니다.",
            "2": "배포 전에 철저한 검증을 보장하기 위해 모든 테스트를 수동으로 수행합니다.",
            "3": "CI/CD 도구와 통합되는 전용 머신 러닝 테스트 프레임워크를 활용합니다.",
            "4": "ML 모델에 대한 대부분의 테스트 요구를 충족하므로 단위 테스트만 구현합니다."
        },
        "Correct Answer": "CI/CD 도구와 통합되는 전용 머신 러닝 테스트 프레임워크를 활용합니다.",
        "Explanation": "CI/CD 도구와 통합되는 전용 머신 러닝 테스트 프레임워크를 사용하면 자동화된 포괄적인 테스트가 가능하여 단위, 통합 및 엔드 투 엔드 테스트가 배포 파이프라인의 일환으로 원활하게 실행됩니다. 이 접근 방식은 신뢰성을 높이고 배포 프로세스를 가속화합니다.",
        "Other Options": [
            "모든 테스트를 수동으로 수행하는 것은 비효율적이며 인적 오류에 취약하여 자동화가 핵심인 CI/CD 파이프라인에 적합하지 않습니다.",
            "단위 테스트만 구현하는 것은 완전한 테스트 전략을 제공하지 않으며, 전체 워크플로우가 올바르게 작동하는지 확인하기 위해 통합 및 엔드 투 엔드 테스트도 중요합니다.",
            "오류를 추적하기 위해 간단한 로깅 메커니즘을 사용하는 것은 적절한 테스트 프레임워크를 구성하지 않으며, 배포 전에 ML 모델의 기능성과 신뢰성을 보장하지 못합니다."
        ]
    },
    {
        "Question Number": "29",
        "Situation": "금융 서비스 회사가 AWS에 머신 러닝 모델을 배포하고 있습니다. 모델이 안전하고 산업 규정을 준수하도록 하려면, 회사는 ML 시스템을 공용 접근으로부터 격리하면서 구성 요소 간의 안전한 통신을 허용하는 강력한 네트워크 아키텍처를 설정해야 합니다.",
        "Question": "AWS에서 머신 러닝 시스템을 안전하게 격리하는 가장 좋은 접근 방식은 무엇입니까?",
        "Options": {
            "1": "머신 러닝 모델을 공용 VPC에 배포하고 보안 그룹을 사용하여 사용 편의를 위해 무제한 접근을 허용합니다.",
            "2": "공용 및 사설 서브넷이 있는 가상 사설 클라우드(VPC)를 생성하고 보안 그룹을 구성하여 접근을 제한합니다.",
            "3": "사설 서브넷만 있는 VPC를 설정하고 인터넷 접근이 없도록 하여 ML 시스템을 완전히 격리합니다.",
            "4": "공용 서브넷에서 AWS Lambda를 활용하여 모든 ML 요청을 처리하고 사설 서브넷의 모델에 연결합니다."
        },
        "Correct Answer": "공용 및 사설 서브넷이 있는 가상 사설 클라우드(VPC)를 생성하고 보안 그룹을 구성하여 접근을 제한합니다.",
        "Explanation": "공용 및 사설 서브넷이 있는 가상 사설 클라우드(VPC)를 생성하면 민감한 ML 시스템이 사설 서브넷에 위치할 수 있는 안전한 아키텍처를 제공하며, 여전히 공용 서브넷을 통해 제한된 접근을 가능하게 합니다. 보안 그룹은 인바운드 및 아웃바운드 트래픽을 효과적으로 제어하도록 구성할 수 있습니다.",
        "Other Options": [
            "공용 서브넷에서 AWS Lambda를 사용하여 ML 요청을 처리하는 것은 인프라를 공용 인터넷에 노출시켜 보안 위험을 초래할 수 있으므로 안전하지 않습니다.",
            "모델을 공용 VPC에 배포하면 무단 접근이 가능해져 민감한 ML 애플리케이션을 보호하기 위한 모범 사례에 위배됩니다.",
            "사설 서브넷만 있는 VPC를 설정하면 외부 접근이 차단되지만 ML 시스템에 필요한 통신 및 모니터링 기능이 저해될 수 있습니다."
        ]
    },
    {
        "Question Number": "30",
        "Situation": "데이터 과학 팀이 구독 서비스의 고객 이탈을 예측하기 위해 머신 러닝 모델을 개발하고 테스트하고 있습니다. 그들은 실험이 재현 가능하고 각 실행과 관련된 구성, 데이터 세트 및 결과를 추적할 수 있도록 해야 합니다. 팀은 이 프로세스를 용이하게 하기 위해 AWS 서비스를 활용할 계획입니다.",
        "Question": "어떤 솔루션이 팀이 머신 러닝 모델 개발에서 재현 가능한 실험을 수행하는 데 도움이 될까요? (두 가지 선택)",
        "Options": {
            "1": "다양한 구성으로 모델 배포를 자동화하기 위해 AWS Lambda를 구현합니다.",
            "2": "모델 버전 및 메타데이터 관리를 위해 Amazon SageMaker Model Registry를 사용합니다.",
            "3": "모델 훈련에 사용되는 데이터 세트를 저장하고 버전 관리하기 위해 Amazon S3를 활용합니다.",
            "4": "모델 훈련 실행 및 매개변수를 추적하기 위해 Amazon SageMaker Experiments를 사용합니다.",
            "5": "모델 배포를 위한 CI/CD 프로세스를 관리하기 위해 AWS CodePipeline을 활용합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "모델 훈련 실행 및 매개변수를 추적하기 위해 Amazon SageMaker Experiments를 사용합니다.",
            "모델 훈련에 사용되는 데이터 세트를 저장하고 버전 관리하기 위해 Amazon S3를 활용합니다."
        ],
        "Explanation": "Amazon SageMaker Experiments를 사용하면 팀이 하이퍼파라미터, 메트릭 및 구성을 포함한 훈련 실행을 체계적으로 추적할 수 있어 재현 가능성에 매우 중요합니다. Amazon S3에 데이터 세트를 버전 관리하여 저장하면 어떤 실험에 사용된 정확한 데이터 세트를 검색할 수 있어 실험을 반복 가능하고 검증할 수 있게 합니다.",
        "Other Options": [
            "AWS Lambda는 주로 서버리스 컴퓨팅 기능에 사용되며 실험이나 데이터 세트를 추적하는 데 직접적으로 기여하지 않으므로 모델 개발에서 재현 가능성에 덜 적합합니다.",
            "AWS CodePipeline은 CI/CD 프로세스에 중점을 두고 있으며, 배포에는 유용하지만 모델 훈련 및 실험 추적의 재현 가능성 요구를 해결하지 않습니다.",
            "Amazon SageMaker Model Registry는 훈련 후 모델 관리를 위해 유용하지만 훈련 실험의 재현 가능성에는 특별히 도움이 되지 않습니다."
        ]
    },
    {
        "Question Number": "31",
        "Situation": "머신 러닝 팀이 모델 배포 프로세스를 간소화할 방법을 모색하고 있습니다. 그들은 머신 러닝 모델의 테스트 및 배포를 자동화하기 위해 지속적 통합 및 지속적 배포(CI/CD) 관행을 구현하고자 합니다. 특히 데이터셋, 모델 아티팩트의 버전 관리를 용이하게 하고 전체 배포 워크플로우를 조정하는 도구에 관심이 많습니다. 팀은 필요할 경우 이전 모델 버전으로 신속하게 롤백할 수 있고 모델과 관련 데이터셋의 변경 이력을 유지할 수 있어야 합니다.",
        "Question": "다음 중 머신 러닝 워크플로우를 위한 CI/CD 파이프라인 구현에 가장 적합한 AWS 서비스는 무엇입니까?",
        "Options": {
            "1": "AWS CodePipeline",
            "2": "Amazon SageMaker Model Registry",
            "3": "Amazon S3",
            "4": "AWS Lambda"
        },
        "Correct Answer": "AWS CodePipeline",
        "Explanation": "AWS CodePipeline은 애플리케이션, 특히 머신 러닝 워크플로우의 빌드, 테스트 및 릴리스 프로세스를 자동화하는 지속적 통합 및 지속적 배포 서비스입니다. 다양한 AWS 서비스 및 도구와 통합할 수 있어 ML 환경에서 CI/CD 파이프라인을 조정하는 데 이상적입니다.",
        "Other Options": [
            "Amazon S3는 데이터를 저장하는 데 주로 사용되는 스토리지 서비스로, CI/CD 워크플로우를 조정하는 데는 사용되지 않습니다. 모델 아티팩트와 데이터셋을 저장할 수 있지만 CI/CD에 필요한 자동화 기능을 제공하지 않습니다.",
            "AWS Lambda는 이벤트에 응답하여 코드를 실행하는 서버리스 컴퓨팅 서비스입니다. CI/CD 파이프라인의 일부가 될 수 있지만 전체 배포 프로세스를 관리하는 데 필요한 조정을 제공하지 않습니다.",
            "Amazon SageMaker Model Registry는 모델 버전 및 배포 관리를 위해 유용하지만, AWS CodePipeline이 제공하는 더 넓은 조정 기능이 부족하여 완전한 CI/CD 솔루션으로는 작동하지 않습니다."
        ]
    },
    {
        "Question Number": "32",
        "Situation": "데이터 과학 팀이 구독 서비스의 고객 이탈을 예측하기 위한 머신 러닝 모델을 개발하고 있습니다. 훈련 중에 모델이 진동하고 안정적인 솔루션으로 수렴하지 못해 검증 데이터에서 성능이 저조하다는 것을 발견했습니다.",
        "Question": "모델 훈련 중 수렴 문제를 해결하기 위해 팀이 구현할 수 있는 전략은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "과적합을 방지하기 위해 조기 중단을 구현합니다.",
            "2": "훈련 프로세스를 안정화하기 위해 배치 정규화를 사용합니다.",
            "3": "수렴 속도를 높이기 위해 학습률을 증가시킵니다.",
            "4": "학습률을 조정하는 최적화 알고리즘으로 변경합니다.",
            "5": "문제를 단순화하기 위해 데이터셋의 크기를 줄입니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "훈련 프로세스를 안정화하기 위해 배치 정규화를 사용합니다.",
            "학습률을 조정하는 최적화 알고리즘으로 변경합니다."
        ],
        "Explanation": "배치 정규화는 각 레이어의 입력을 정규화하여 학습 프로세스를 안정화하는 데 도움을 주며, 진동과 관련된 문제를 완화할 수 있습니다. 또한, Adam과 같은 적응형 학습률 최적화 알고리즘을 사용하면 훈련 중 기울기에 따라 학습률을 조정하여 모델이 더 효과적으로 수렴할 수 있습니다.",
        "Other Options": [
            "학습률을 증가시키면 실제로 수렴 문제를 악화시키고 불안정성을 초래할 수 있습니다.",
            "조기 중단을 구현하는 것은 과적합을 방지하는 데 유용하지만 훈련 중 수렴 문제를 직접적으로 해결하지는 않습니다.",
            "데이터셋의 크기를 줄이면 문제를 단순화할 수 있지만 중요한 정보를 잃을 수 있어 모델 성능에 부정적인 영향을 미칠 수 있습니다."
        ]
    },
    {
        "Question Number": "33",
        "Situation": "머신 러닝 엔지니어가 분류 모델을 위한 데이터셋을 준비하는 임무를 맡고 있습니다. 데이터셋에는 숫자, 텍스트 및 이미지 데이터가 포함되어 있으며, 엔지니어는 모델이 클래스 불균형 및 데이터 부족에 강력해야 함을 보장해야 합니다.",
        "Question": "엔지니어가 클래스 불균형을 해결하고 훈련을 위한 데이터셋의 품질을 개선하는 데 가장 도움이 될 전략은 무엇입니까?",
        "Options": {
            "1": "다수 클래스에 대해 무작위 언더샘플링을 구현하고 훈련 중 텍스트 데이터셋을 무시합니다.",
            "2": "소수 클래스에 대해 오버샘플링 기법을 사용하고 이미지 데이터셋에 데이터 증강을 적용합니다.",
            "3": "숫자 특성에 대한 합성 데이터를 생성하고 텍스트 데이터셋에서 이상치를 제거합니다.",
            "4": "소수 클래스에 대한 별도의 데이터셋을 생성하고 원본 데이터셋과 병합하되 전처리를 하지 않습니다."
        },
        "Correct Answer": "소수 클래스에 대해 오버샘플링 기법을 사용하고 이미지 데이터셋에 데이터 증강을 적용합니다.",
        "Explanation": "SMOTE와 같은 오버샘플링 기법은 소수 클래스의 표현을 효과적으로 증가시켜 클래스 불균형 문제를 해결할 수 있습니다. 또한, 이미지에 대한 데이터 증강은 기존 데이터의 다양한 변형을 생성하는 데 도움을 주어 모델의 일반화를 개선할 수 있습니다.",
        "Other Options": [
            "숫자 특성에 대한 합성 데이터를 생성하는 것은 도움이 될 수 있지만, 텍스트 데이터셋에서 이상치를 제거하면 중요한 정보를 잃을 수 있어 데이터셋 품질이 저하될 수 있습니다.",
            "다수 클래스에 대해 무작위 언더샘플링을 구현하면 정보 손실과 덜 유익한 모델이 될 수 있으며, 텍스트 데이터셋을 완전히 무시하는 것은 귀중한 데이터를 간과하는 것입니다.",
            "전처리 없이 소수 클래스에 대한 별도의 데이터셋을 생성하면 데이터 분포가 일관되지 않게 되고 불균형 문제를 효과적으로 해결하지 못할 수 있습니다."
        ]
    },
    {
        "Question Number": "34",
        "Situation": "한 회사가 감정 분석을 위한 자연어 처리(NLP) 모델을 개발하고 있습니다. 그들은 모델의 크기를 최적화하면서 높은 성능을 유지하고 싶어합니다. 어떤 요소가 ML 모델의 전체 크기에 가장 큰 영향을 미칠 가능성이 높습니까?",
        "Question": "ML 모델 개발 중 크기에 가장 큰 영향을 미치는 요소는 무엇입니까?",
        "Options": {
            "1": "실행된 훈련 과정의 기간.",
            "2": "데이터셋에 사용된 훈련 예제의 수.",
            "3": "훈련 중 적용된 최적화 알고리즘의 선택.",
            "4": "모델 자체의 아키텍처와 복잡성."
        },
        "Correct Answer": "모델 자체의 아키텍처와 복잡성.",
        "Explanation": "모델 자체의 아키텍처와 복잡성은 매개변수의 수를 직접 결정하며, 이는 모델의 크기에 영향을 미칩니다. 더 복잡한 아키텍처는 더 많은 매개변수를 필요로 하여 결과적으로 더 큰 모델 크기로 이어집니다.",
        "Other Options": [
            "훈련 예제의 수는 모델의 성능과 일반화에 영향을 미치지만, 모델 크기 자체에는 큰 영향을 미치지 않습니다.",
            "최적화 알고리즘의 선택은 모델이 학습하는 효율성에 영향을 미치지만, 모델의 크기를 본질적으로 변경하지는 않습니다.",
            "훈련 과정의 기간은 수렴과 성능에 영향을 미칠 수 있지만, 모델의 크기를 결정하지는 않습니다."
        ]
    },
    {
        "Question Number": "35",
        "Situation": "한 소매 회사가 사용자 경험을 개인화하기 위한 추천 시스템을 개발하고 있지만, 불공정한 추천으로 이어질 수 있는 데이터셋의 잠재적 편향에 대해 우려하고 있습니다. ML 엔지니어는 모델 훈련에 사용되는 데이터가 선택 편향 및 측정 편향과 같은 편향이 없도록 하고 싶어합니다. 그들은 데이터 준비 단계에서 이러한 편향을 식별하고 완화하기 위해 AWS 도구를 고려하고 있습니다.",
        "Question": "추천 모델 훈련 전에 데이터셋의 편향을 식별하고 완화하는 데 가장 적합한 AWS 도구는 무엇입니까?",
        "Options": {
            "1": "Amazon SageMaker Clarify를 사용하여 데이터셋의 편향을 분석하고 보고서를 생성합니다.",
            "2": "AWS Glue를 구현하여 데이터를 변환하고 잠재적인 편향을 제거합니다.",
            "3": "Amazon SageMaker Data Wrangler를 활용하여 데이터 분포를 시각화하고 이상치를 제거합니다.",
            "4": "Amazon QuickSight를 활용하여 데이터의 트렌드를 강조하는 대시보드를 생성합니다."
        },
        "Correct Answer": "Amazon SageMaker Clarify를 사용하여 데이터셋의 편향을 분석하고 보고서를 생성합니다.",
        "Explanation": "Amazon SageMaker Clarify는 기계 학습 데이터셋과 모델에서 편향을 감지하고 완화하는 데 특별히 설계되었습니다. 이 도구는 데이터셋의 잠재적 편향을 분석하고 모델 훈련 전에 이러한 문제를 이해하고 해결하는 데 도움이 되는 보고서를 생성합니다.",
        "Other Options": [
            "AWS Glue는 데이터 준비 및 변환을 촉진하는 데이터 통합 서비스입니다. 데이터 정리 및 ETL 프로세스에 유용하지만, 편향 감지 또는 완화에 특별히 초점을 맞추고 있지는 않습니다.",
            "Amazon SageMaker Data Wrangler는 데이터 시각화 및 특성 엔지니어링을 돕는 데이터 준비 도구이지만, 데이터셋에서 편향을 식별하는 전용 기능을 제공하지 않습니다.",
            "Amazon QuickSight는 데이터 시각화 및 보고 기능을 제공하는 비즈니스 인텔리전스 서비스입니다. 기계 학습 데이터셋에서 편향을 감지하거나 완화하는 것을 목표로 하지 않습니다."
        ]
    },
    {
        "Question Number": "36",
        "Situation": "한 금융 기관이 신용 점수, 고객 분석 및 위험 평가를 위한 여러 기계 학습 모델을 배포했습니다. 이 기관은 승인된 사용자와 애플리케이션만이 이러한 ML 시스템과 상호작용할 수 있도록 엄격한 접근 제어가 필요합니다. ML 엔지니어는 IAM 정책과 역할을 적절하게 구성하는 임무를 맡고 있습니다.",
        "Question": "ML 엔지니어가 최소 권한 원칙을 준수하면서 ML 모델에 대한 안전한 접근을 보장하기 위한 최선의 접근 방식은 무엇입니까?",
        "Options": {
            "1": "모든 ML 리소스에 대한 전체 접근 권한을 가진 단일 IAM 사용자를 할당하고 팀 전체에 자격 증명을 공유합니다.",
            "2": "모든 AWS 서비스에 접근할 수 있는 권한을 가진 IAM 역할을 사용한 다음, 부서에 따라 해당 역할을 사용자에게 할당합니다.",
            "3": "모든 ML 리소스에 대한 접근을 허용하는 광범위한 IAM 역할을 생성하고 접근이 필요한 모든 사용자에게 부여합니다.",
            "4": "각 사용자 역할에 대해 특정 권한이 정의된 IAM 정책을 작성하여 필요한 ML 리소스와 작업에만 접근을 허용합니다."
        },
        "Correct Answer": "각 사용자 역할에 대해 특정 권한이 정의된 IAM 정책을 작성하여 필요한 ML 리소스와 작업에만 접근을 허용합니다.",
        "Explanation": "이 접근 방식은 사용자가 자신의 역할에 필요한 리소스와 작업에만 접근할 수 있도록 하여 최소 권한 원칙을 준수함으로써 보안을 개선하고 잠재적 위험을 최소화합니다.",
        "Other Options": [
            "모든 ML 리소스에 대한 접근을 허용하는 광범위한 IAM 역할을 생성하는 것은 최소 권한 원칙을 위반하여 민감한 데이터에 대한 무단 접근을 허용할 수 있는 보안 위험을 초래합니다.",
            "모든 ML 리소스에 대한 전체 접근 권한을 가진 단일 IAM 사용자를 할당하는 것은 안전하지 않으며, 자격 증명이 유출되거나 악용될 경우 조직에 위험을 초래합니다.",
            "모든 AWS 서비스에 접근할 수 있는 권한을 가진 IAM 역할을 사용하는 것은 지나치게 관대하며, 필요한 ML 리소스에 대한 접근을 제한하지 않아 의도하지 않은 작업이나 노출로 이어질 수 있습니다."
        ]
    },
    {
        "Question Number": "37",
        "Situation": "데이터 과학자가 머신러닝 모델의 성능을 평가하고 있으며, 훈련 데이터셋에서는 매우 잘 작동하지만 보지 못한 검증 데이터에서는 성능이 저조하다는 것을 발견했습니다. 과학자는 모델이 새로운 데이터에 일반화할 수 있는 능력에 대해 우려하고 있습니다.",
        "Question": "과학자가 모델에서 잠재적인 과적합을 식별하고 해결하기 위해 어떤 기술을 사용해야 합니까?",
        "Options": {
            "1": "모델 평가를 위해 단일 훈련-테스트 분할을 사용합니다.",
            "2": "모델의 복잡성을 증가시킵니다.",
            "3": "훈련 데이터셋의 크기를 줄입니다.",
            "4": "모델 성능을 평가하기 위해 교차 검증을 사용합니다."
        },
        "Correct Answer": "모델 성능을 평가하기 위해 교차 검증을 사용합니다.",
        "Explanation": "교차 검증은 모델의 성능이 데이터의 특정 하위 집합에 의존하지 않도록 보장하여 새로운 데이터에 대한 일반화 능력에 대한 보다 신뢰할 수 있는 추정치를 제공합니다. 이 방법은 과학자가 데이터의 여러 폴드에서 성능을 비교하여 과적합을 식별할 수 있게 합니다.",
        "Other Options": [
            "모델의 복잡성을 증가시키면 훈련 데이터를 암기하게 되어 일반 패턴을 학습하는 대신 과적합이 악화될 수 있습니다.",
            "훈련 데이터셋의 크기를 줄이는 것은 과적합을 직접적으로 해결하지 않으며, 사용 가능한 데이터에서 학습할 수 있는 능력이 떨어지는 모델로 이어질 수 있습니다.",
            "단일 훈련-테스트 분할을 사용하면 모델 성능 평가가 제한되어 과적합을 식별하기 어려워지며, 다양한 데이터 하위 집합에서 모델 동작에 대한 포괄적인 뷰를 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "38",
        "Situation": "머신러닝 엔지니어가 데이터 추출, 전처리, 모델 훈련 및 평가를 포함한 복잡한 ML 워크플로우를 조정하는 임무를 맡고 있습니다. 팀은 AWS 서비스와 원활하게 통합되고 파이프라인 구성 요소의 모니터링 및 관리가 용이한 솔루션을 선호합니다.",
        "Question": "이 ML 워크플로우를 AWS에서 배포하고 관리하기 위해 가장 적합한 오케스트레이터는 무엇입니까?",
        "Options": {
            "1": "Apache Airflow를 사용하여 사용자 정의 연산자를 통해 ML 워크플로우를 생성하고 관리합니다.",
            "2": "ML 워크플로우를 자동화하기 위해 자체 호스팅된 Jenkins 서버를 구현합니다.",
            "3": "Kubernetes와 Kubeflow를 활용하여 전체 ML 워크플로우를 관리합니다.",
            "4": "AWS Step Functions를 활용하여 ML 워크플로우의 다양한 단계를 조정합니다."
        },
        "Correct Answer": "AWS Step Functions를 활용하여 ML 워크플로우의 다양한 단계를 조정합니다.",
        "Explanation": "AWS Step Functions는 작업의 순서를 관리하고 내장된 오류 처리, 재시도 및 상태 관리를 제공하여 복잡한 워크플로우를 조정하도록 설계되어, AWS에서 ML 워크플로우에 이상적인 선택입니다.",
        "Other Options": [
            "Apache Airflow를 사용하면 추가 인프라 관리가 필요하며, Step Functions와 같은 기본 솔루션에 비해 AWS 서비스와 원활하게 통합되지 않을 수 있습니다.",
            "Kubernetes와 Kubeflow는 강력한 도구이지만 상당한 운영 오버헤드와 복잡성을 수반하며, AWS에서 더 간단한 ML 워크플로우에는 필요하지 않을 수 있습니다.",
            "자체 호스팅된 Jenkins 서버는 작업을 자동화할 수 있지만, AWS Step Functions가 제공하는 오케스트레이션 기능과 모니터링 기능이 부족하여 복잡한 ML 워크플로우에는 덜 적합합니다."
        ]
    },
    {
        "Question Number": "39",
        "Situation": "한 회사가 실시간 추론 기능이 필요한 머신러닝 모델을 배포하고 있습니다. 최적의 성능을 보장하면서 비용을 관리하기 위해 적절한 Amazon EC2 인스턴스 유형을 선택해야 합니다. 이 모델은 사용자에게 예측을 제공하기 위해 높은 CPU 처리량과 낮은 대기 시간이 필요합니다.",
        "Question": "회사가 실시간 추론 작업에 대해 최상의 성능을 달성하기 위해 어떤 인스턴스 유형을 선택해야 합니까?",
        "Options": {
            "1": "비용 최적화와 버스트 성능을 위해 T4g 인스턴스를 사용합니다.",
            "2": "메모리 최적화되어 데이터 집약적 애플리케이션에 적합한 R5 인스턴스를 선택합니다.",
            "3": "다양한 작업에 균형 잡힌 일반 용도의 M5 인스턴스를 선택합니다.",
            "4": "추론 애플리케이션을 위한 높은 CPU 성능을 제공하는 C5 인스턴스를 선택합니다."
        },
        "Correct Answer": "추론 애플리케이션을 위한 높은 CPU 성능을 제공하는 C5 인스턴스를 선택합니다.",
        "Explanation": "C5 인스턴스는 컴퓨팅 집약적인 작업을 위해 특별히 설계되었으며, 코어당 높은 성능을 제공하여 낮은 대기 시간과 높은 처리량이 필요한 실시간 추론 작업에 이상적입니다.",
        "Other Options": [
            "T4g 인스턴스는 버스트 성능에 중점을 두며 실시간 추론에 필요한 일관된 높은 CPU 처리량을 제공하지 않을 수 있습니다.",
            "R5 인스턴스는 메모리 집약적인 애플리케이션에 더 적합하며, 주로 CPU 성능이 필요한 작업에는 최적이 아닙니다.",
            "M5 인스턴스는 균형 잡힌 리소스 구성을 제공하지만, 높은 CPU 성능을 요구하는 작업에는 C5가 더 적합한 선택입니다."
        ]
    },
    {
        "Question Number": "40",
        "Situation": "머신 러닝 엔지니어가 AWS에서 실시간 추천 시스템을 배포하는 임무를 맡았습니다. 이 시스템은 다양한 트래픽 부하를 처리해야 하며, 피크 시간과 비피크 시간 동안 성능이 일관되게 유지되어야 합니다. 엔지니어는 애플리케이션의 리소스를 효과적으로 관리하기 위해 다양한 스케일링 정책을 평가하고 있습니다.",
        "Question": "변동하는 트래픽 동안 애플리케이션 성능을 보장하면서 리소스 활용을 최적화하기 위해 엔지니어가 선택해야 할 스케일링 정책은 무엇입니까?",
        "Options": {
            "1": "Scheduled Scaling",
            "2": "Step Scaling",
            "3": "Target Tracking Scaling",
            "4": "Simple Scaling"
        },
        "Correct Answer": "Target Tracking Scaling",
        "Explanation": "Target Tracking Scaling은 CPU 활용도나 요청 수와 같은 특정 메트릭에 따라 실행 중인 인스턴스 수를 자동으로 조정하여, 애플리케이션이 다양한 트래픽 부하 동안 효과적으로 성능을 유지할 수 있도록 합니다.",
        "Other Options": [
            "Step Scaling은 미리 정의된 임계값이 필요하며, 갑작스러운 트래픽 급증에 덜 반응할 수 있어 성능 문제를 초래할 수 있습니다.",
            "Scheduled Scaling은 알려진 사용 패턴에 기반하므로 예상치 못한 트래픽 변화에 효과적으로 대응하지 못할 수 있으며, 이로 인해 리소스 부족이나 과잉 프로비저닝이 발생할 수 있습니다.",
            "Simple Scaling은 단일 메트릭에 따라 스케일 인 또는 스케일 아웃을 위한 기본 정책을 포함하므로, 더 복잡한 트래픽 패턴을 고려하지 않아 동적 워크로드에 덜 효율적입니다."
        ]
    },
    {
        "Question Number": "41",
        "Situation": "ML 엔지니어가 AWS 서비스를 사용하여 실시간 데이터 수집 파이프라인을 설정하는 임무를 맡았습니다. 엔지니어는 다양한 소스에서 스트리밍 데이터를 캡처하기 위해 Amazon Kinesis Data Streams를 사용하기로 선택했습니다. Kinesis 스트림이 생성된 후, 엔지니어는 데이터를 스트림으로 전송하려고 시도하지만 예상대로 데이터가 수집되지 않는 문제에 직면합니다.",
        "Question": "Kinesis Data Stream으로의 데이터 수집 실패의 가장 가능성이 높은 이유는 무엇입니까?",
        "Options": {
            "1": "Kinesis Data Stream으로 전송되는 데이터 형식이 지원되지 않습니다.",
            "2": "Kinesis Data Stream에 데이터를 쓰는 데 사용되는 IAM 역할에 필요한 권한이 부족합니다.",
            "3": "Kinesis Data Stream이 만료된 보존 기간으로 구성되어 있습니다.",
            "4": "Kinesis Data Stream이 들어오는 데이터 속도를 처리하기에 충분한 샤드로 프로비저닝되지 않았습니다."
        },
        "Correct Answer": "Kinesis Data Stream이 들어오는 데이터 속도를 처리하기에 충분한 샤드로 프로비저닝되지 않았습니다.",
        "Explanation": "Kinesis Data Stream에 충분한 샤드가 없으면 스로틀링이 발생하고 데이터 수집 실패로 이어질 수 있습니다. 각 샤드는 처리할 수 있는 데이터 양에 제한이 있으며, 들어오는 데이터 속도가 이 한도를 초과하면 데이터가 제대로 수집되지 않습니다.",
        "Other Options": [
            "보존 기간이 만료되면 현재 수집에는 영향을 미치지 않으며, 이는 수집 후 데이터가 스트림에 얼마나 오래 유지되는지에만 영향을 미칩니다.",
            "권한이 중요하지만, IAM 역할에 권한이 부족하면 오류는 수집 실패가 아니라 접근 거부와 관련이 있어 다른 문제를 나타냅니다.",
            "데이터 형식이 지원되지 않는 경우, 오류는 일반적으로 데이터를 처리하는 동안 발생하며, 스트림에 수집되는 것을 방지하지는 않습니다."
        ]
    },
    {
        "Question Number": "42",
        "Situation": "소매 회사가 전자 상거래 플랫폼에서 개인화된 제품 추천을 제공하여 고객 경험을 향상시키고자 합니다. 회사는 예산이 제한되어 있으며, 최소한의 머신 러닝 전문 지식으로 구현할 수 있는 솔루션을 선호합니다.",
        "Question": "회사가 최소한의 노력으로 추천 시스템을 신속하게 배포하기 위해 사용해야 할 AWS 서비스는 무엇입니까?",
        "Options": {
            "1": "Amazon Comprehend",
            "2": "AWS DeepRacer",
            "3": "Amazon SageMaker",
            "4": "Amazon Personalize"
        },
        "Correct Answer": "Amazon Personalize",
        "Explanation": "Amazon Personalize는 머신 러닝을 사용하여 개인화된 추천을 제공하도록 특별히 설계되어 있으며, 깊은 머신 러닝 전문 지식이 필요하지 않습니다. 이 서비스는 사전 구축된 알고리즘을 통해 기업이 애플리케이션에 개인화를 쉽게 통합할 수 있도록 하며, 이 특정 사용 사례에 최적화되어 있습니다.",
        "Other Options": [
            "Amazon SageMaker는 머신 러닝 모델을 구축, 훈련 및 배포하기 위한 도구를 제공하는 종합 서비스이지만, Amazon Personalize에 비해 더 많은 머신 러닝 지식과 노력이 필요하므로 이 시나리오에 덜 적합합니다.",
            "AWS DeepRacer는 주로 사용자가 경주 시뮬레이션을 통해 강화 학습에 대해 배울 수 있도록 하는 교육 도구입니다. 추천 시스템을 구축하는 데 적합하지 않으며, 자율 주행 자동차 모델 훈련에 중점을 두고 있습니다.",
            "Amazon Comprehend는 텍스트를 분석하고 통찰력을 도출하는 자연어 처리 서비스입니다. 텍스트 분석에 유용하지만, 개인화된 제품 추천을 생성하는 기능을 제공하지 않아 회사의 필요와는 관련이 없습니다."
        ]
    },
    {
        "Question Number": "43",
        "Situation": "머신 러닝 엔지니어가 Amazon SageMaker를 사용하여 분류 모델 훈련을 위한 데이터셋을 준비하고 있습니다. 데이터셋은 고양이와 개의 이미지로 구성되어 있지만, 고양이 이미지(800)의 수가 개 이미지(200)보다 훨씬 많습니다. 엔지니어는 이 클래스 불균형으로 인해 모델에 잠재적인 편향이 발생할 수 있다고 우려하고 있습니다. 모델 훈련 전에 데이터셋의 편향을 평가하기 위해 엔지니어가 집중해야 할 지표는 무엇인가요?",
        "Question": "데이터셋의 클래스 불균형을 평가하는 데 가장 효과적인 지표는 무엇인가요?",
        "Options": {
            "1": "평균 제곱 오차 (MSE)",
            "2": "제곱근 평균 제곱 오차 (RMSE)",
            "3": "클래스 불균형 (CI)",
            "4": "혼동 행렬 (CM)"
        },
        "Correct Answer": "클래스 불균형 (CI)",
        "Explanation": "클래스 불균형 (CI)은 서로 다른 클래스 간의 샘플 비율을 직접 측정하여 모델의 편향된 예측으로 이어질 수 있는 중요한 불균형을 식별하는 데 도움을 줍니다.",
        "Other Options": [
            "평균 제곱 오차 (MSE)는 예측값과 실제값 간의 평균 제곱 차이를 평가하는 회귀 지표로, 클래스 분포를 평가하지 않습니다.",
            "제곱근 평균 제곱 오차 (RMSE)도 예측값과 관측값 간의 차이를 측정하는 회귀 평가 지표로, 클래스 불균형을 감지하는 데 적합하지 않습니다.",
            "혼동 행렬 (CM)은 분류 모델의 성능 측정 도구로, 진양성, 위양성, 진음성 및 위음성 값을 보여주지만, 모델 훈련 전에 클래스 불균형을 직접적으로 정량화하지는 않습니다."
        ]
    },
    {
        "Question Number": "44",
        "Situation": "금융 기관이 실시간으로 사기 거래를 탐지하기 위해 머신 러닝 모델을 배포하고 있습니다. 모델이 민감한 데이터에 안전하게 접근하고 규제 요구 사항을 준수할 수 있도록 하기 위해, 회사는 ML 리소스에 대한 네트워크 접근을 위한 적절한 통제를 구현해야 합니다.",
        "Question": "보안 기준을 준수하면서 머신 러닝 리소스에 대한 네트워크 접근을 가장 잘 제어하는 솔루션은 무엇인가요?",
        "Options": {
            "1": "Amazon S3 버킷 정책",
            "2": "AWS VPN",
            "3": "AWS PrivateLink",
            "4": "AWS IAM 역할"
        },
        "Correct Answer": "AWS PrivateLink",
        "Explanation": "AWS PrivateLink는 AWS 서비스에 접근하기 위한 안전하고 개인적인 연결 옵션을 제공하며, 트래픽을 AWS 네트워크 내에서 유지합니다. 이는 공용 인터넷에 대한 노출을 최소화하고 민감한 ML 리소스의 보안을 강화하여 네트워크 접근을 제어하는 데 가장 좋은 선택입니다.",
        "Other Options": [
            "Amazon S3 버킷 정책은 S3 버킷에 대한 접근을 제어하지만, 다른 서비스에 호스팅된 ML 리소스에 대한 네트워크 수준의 보안을 제공하지 않습니다. 이는 데이터 접근에 관한 것이지 네트워크 통신을 보호하는 것은 아닙니다.",
            "AWS VPN은 온프레미스 네트워크와 AWS 간의 안전한 연결을 생성하지만, 특정 AWS 서비스나 리소스에 직접 접근할 때 AWS PrivateLink와 같은 수준의 세부적인 제어 및 보안을 제공하지 않을 수 있습니다.",
            "AWS IAM 역할은 AWS 리소스에 대한 권한 및 접근을 관리하지만, 네트워크 접근 제어를 구체적으로 다루지는 않습니다. 이는 사용자와 서비스가 필요한 권한을 갖도록 보장하지만, 네트워크 계층을 암호화하거나 보호하지는 않습니다."
        ]
    },
    {
        "Question Number": "45",
        "Situation": "소매 회사가 소셜 미디어 댓글, 이메일 응답, 제품 리뷰 등 다양한 채널을 통해 받은 고객 피드백을 분석하여 고객 서비스를 향상시키고자 합니다. 회사는 이 피드백을 긍정적, 부정적, 중립적 감정으로 분류하는 것을 목표로 하고 있습니다. ML 엔지니어가 자동화된 솔루션을 구현하는 임무를 맡았습니다.",
        "Question": "ML 엔지니어가 고객 피드백 감정을 분석하고 분류하기 위해 사용할 수 있는 AWS AI 서비스는 무엇인가요? (두 개 선택)",
        "Options": {
            "1": "Amazon Rekognition을 사용하여 소셜 미디어 이미지를 감정 분석합니다.",
            "2": "Amazon Bedrock을 활용하여 피드백 분류를 위한 맞춤형 모델을 구축합니다.",
            "3": "Amazon Lex를 구현하여 피드백 수집을 위한 챗봇을 만듭니다.",
            "4": "모든 피드백을 분석하기 전에 영어로 변환하기 위해 Amazon Translate를 사용합니다.",
            "5": "Amazon Comprehend를 활용하여 텍스트의 감정 분석을 수행합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon Comprehend를 활용하여 텍스트의 감정 분석을 수행합니다.",
            "Amazon Bedrock을 활용하여 피드백 분류를 위한 맞춤형 모델을 구축합니다."
        ],
        "Explanation": "Amazon Comprehend는 자연어 처리를 위해 특별히 설계되어 텍스트를 정확하게 분석하여 감정을 판단할 수 있습니다. 또한, Amazon Bedrock은 특정 요구 사항과 맥락에 따라 피드백을 분류할 수 있는 맞춤형 모델을 생성할 수 있게 해줍니다.",
        "Other Options": [
            "Amazon Rekognition은 주로 이미지 및 비디오 분석에 사용되므로 고객 피드백의 텍스트 기반 감정을 분석하는 데 적합하지 않습니다.",
            "Amazon Translate는 피드백을 공통 언어로 번역하는 데 도움이 될 수 있지만, 감정을 직접적으로 분류하지 않으며 피드백이 이미 영어로 되어 있다면 필요하지 않습니다.",
            "Amazon Lex는 대화형 인터페이스를 구축하기 위한 서비스로, 기존 피드백의 감정을 분석하거나 분류하는 데 사용되지 않습니다."
        ]
    },
    {
        "Question Number": "46",
        "Situation": "ML 엔지니어가 다양한 형식으로 저장된 대규모 데이터셋을 필요로 하는 머신러닝 모델을 위한 데이터를 준비하고 있습니다. 엔지니어는 효율적인 데이터 접근 및 훈련을 위해 Amazon SageMaker와 원활하게 통합될 수 있는 적절한 AWS 데이터 저장 솔루션을 선택해야 합니다.",
        "Question": "엔지니어가 대규모 데이터셋을 저장하면서 최적의 성능과 SageMaker와의 쉬운 통합을 보장하기 위해 선택해야 할 AWS 서비스는 무엇입니까?",
        "Options": {
            "1": "Amazon S3를 통한 확장 가능한 객체 저장",
            "2": "SMB 프로토콜을 사용하는 Amazon FSx for Windows File Server",
            "3": "NoSQL 데이터베이스 저장을 위한 Amazon DynamoDB",
            "4": "공유 파일 저장을 위한 Amazon Elastic File System (EFS)"
        },
        "Correct Answer": "Amazon S3를 통한 확장 가능한 객체 저장",
        "Explanation": "Amazon S3는 확장성, 내구성 및 비용 효율성 덕분에 대규모 데이터셋을 저장하는 데 가장 적합한 옵션입니다. 또한 Amazon SageMaker와의 쉬운 통합을 제공하여 모델 훈련을 위한 데이터 접근을 원활하게 합니다.",
        "Other Options": [
            "Amazon FSx for Windows File Server는 SMB 프로토콜을 사용하여 파일 공유가 필요한 Windows 워크로드를 위해 주로 설계되었습니다. 머신러닝 데이터셋에 필요한 규모와 성능에 최적화되어 있지 않습니다.",
            "Amazon Elastic File System (EFS)는 공유 접근을 위한 관리형 파일 저장 서비스이지만, 대규모 저장을 위해 S3보다 일반적으로 더 비쌉니다. 또한 분산 훈련을 위한 성능 수준이 S3와 동일하지 않을 수 있습니다.",
            "Amazon DynamoDB는 고속 트랜잭션 및 키-값 데이터 저장을 위해 설계된 NoSQL 데이터베이스 서비스입니다. 파일 기반 저장이 종종 필요한 머신러닝의 맥락에서 대규모 데이터셋을 저장하는 데 적합하지 않습니다."
        ]
    },
    {
        "Question Number": "47",
        "Situation": "머신러닝 엔지니어가 Amazon SageMaker에 배포된 ML 모델의 최적 성능과 가용성을 보장하기 위해 모니터링 작업을 수행하고 있습니다. 엔지니어는 모델 예측의 이상 징후를 분석하기 위해 경고를 설정하고 로그를 분석하고자 합니다.",
        "Question": "다음 접근 방식 중 어떤 것이 엔지니어가 배포된 ML 모델의 효과적인 모니터링 및 문제 해결을 달성하는 데 가장 도움이 될까요?",
        "Options": {
            "1": "Amazon QuickSight를 활용하여 SageMaker 엔드포인트에서 직접 데이터를 가져와 모델의 성능 지표를 시각화하고 결과를 매일 분석합니다.",
            "2": "Amazon EC2 인스턴스를 사용하여 SageMaker에서 직접 모델의 성능 지표를 분석하고 필요에 따라 경고를 생성하는 스크립트를 실행하는 맞춤형 모니터링 솔루션을 설정합니다.",
            "3": "Amazon CloudWatch Logs를 구성하여 SageMaker에서 모델 추론 로그를 수집하고, 예측 지연이 지정된 임계값을 초과할 때 팀에 알리기 위해 CloudWatch Alarms를 설정합니다.",
            "4": "AWS Lambda를 사용하여 주기적으로 모델의 예측 정확성을 확인하고 결과를 Amazon RDS에 기록한 후, 시간에 따른 정확성을 시각화하는 대시보드를 생성합니다."
        },
        "Correct Answer": "Amazon CloudWatch Logs를 구성하여 SageMaker에서 모델 추론 로그를 수집하고, 예측 지연이 지정된 임계값을 초과할 때 팀에 알리기 위해 CloudWatch Alarms를 설정합니다.",
        "Explanation": "Amazon CloudWatch Logs를 사용하여 추론 로그를 수집하면 모델 성능의 실시간 모니터링 및 문제 해결이 가능합니다. 이를 CloudWatch Alarms와 결합하면 지연 문제가 발생할 경우 즉각적인 알림을 받을 수 있어 서비스 품질 유지를 위해 중요합니다.",
        "Other Options": [
            "AWS Lambda를 사용하여 주기적으로 예측 정확성을 확인하는 것은 실시간 모니터링에 덜 효율적이며 성능 문제에 대한 로깅 및 경고를 직접적으로 해결하지 않습니다.",
            "EC2에서 맞춤형 솔루션을 설정하면 복잡성과 유지 관리 오버헤드가 발생하며, SageMaker 모델 모니터링을 위한 CloudWatch의 내장 기능을 고려할 때 불필요합니다.",
            "Amazon QuickSight를 활용한 시각화는 분석에 유용하지만 효과적인 모니터링 및 문제 해결에 필요한 즉각적인 경고 및 로깅 기능을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "48",
        "Situation": "금융 서비스 회사가 민감한 고객 데이터를 처리하며, 머신러닝 모델에 사용되는 모든 데이터가 저장 및 처리 중에 암호화되도록 하기를 원합니다. ML 엔지니어는 이 사용 사례에 가장 적합한 데이터 암호화 기술을 선택하는 임무를 맡고 있습니다.",
        "Question": "머신러닝 목적으로 데이터를 암호화하기 위해 사용할 수 있는 기술은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "데이터 저장을 위해 Amazon S3 서버 측 암호화를 활용합니다.",
            "2": "처리 전에 Amazon DynamoDB에서 데이터 마스킹을 구현합니다.",
            "3": "정지 상태에서 데이터 암호화를 위해 AWS Key Management Service (KMS)를 사용합니다.",
            "4": "TLS를 사용하여 전송 중인 데이터에 대해 종단 간 암호화를 활용합니다.",
            "5": "훈련에 사용되기 전에 데이터에 해싱 알고리즘을 적용합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "정지 상태에서 데이터 암호화를 위해 AWS Key Management Service (KMS)를 사용합니다.",
            "데이터 저장을 위해 Amazon S3 서버 측 암호화를 활용합니다."
        ],
        "Explanation": "AWS Key Management Service (KMS)를 사용하면 암호화 키를 안전하게 관리할 수 있어 정지 상태에서 데이터를 암호화하는 데 이상적입니다. 또한 Amazon S3 서버 측 암호화는 데이터를 S3에 기록할 때 자동으로 암호화하고 접근할 때 복호화하여 데이터가 저장 중에 안전하게 유지되도록 합니다.",
        "Other Options": [
            "데이터 마스킹은 데이터를 익명화하는 데 유용하지만, 민감한 정보를 보호하기 위해 필요한 암호화는 제공하지 않습니다.",
            "TLS는 전송 중인 데이터에 대한 안전한 통신을 제공하지만, 이 시나리오에서 중요한 요구 사항인 정지 상태의 데이터 암호화는 해결하지 않습니다.",
            "해싱은 일방향 방법이며, 머신러닝 모델 훈련을 위해 데이터가 가역적이어야 하는 경우에는 적합하지 않습니다."
        ]
    },
    {
        "Question Number": "49",
        "Situation": "한 회사가 모델 생애 주기의 다양한 단계에 대해 가변적인 컴퓨팅 리소스를 요구하는 머신 러닝 모델을 배포하고 있습니다. 그들은 성능과 가용성을 보장하면서 비용을 최소화하고자 합니다. 팀은 Amazon SageMaker 배포를 위해 AWS에서 제공하는 다양한 구매 옵션을 평가하고 있습니다.",
        "Question": "팀이 가변 작업 부하에 대한 비용과 유연성을 균형 있게 맞추기 위해 고려해야 할 구매 옵션은 무엇입니까?",
        "Options": {
            "1": "예정 인스턴스(Reserved Instances) - 예측 가능한 작업 부하에 적합",
            "2": "온디맨드 인스턴스(On-Demand Instances) - 유연성과 가용성 제공",
            "3": "스팟 인스턴스(Spot Instances) - 비용 효율적인 컴퓨팅",
            "4": "SageMaker 절약 계획(Savings Plans) - 장기 절약을 위한 옵션"
        },
        "Correct Answer": "스팟 인스턴스(Spot Instances) - 비용 효율적인 컴퓨팅",
        "Explanation": "스팟 인스턴스는 사용되지 않는 EC2 용량을 상당히 낮은 비용으로 활용할 수 있게 해 주며, 이는 중단을 감내할 수 있는 가변 작업 부하에 이상적입니다. 이 옵션은 인프라 비용을 효과적으로 최적화하는 데 도움이 됩니다.",
        "Other Options": [
            "온디맨드 인스턴스는 유연하고 가용성을 제공하지만, 일반적으로 스팟 인스턴스보다 더 비쌉니다. 따라서 가변 작업 부하에서 비용 최적화에는 덜 적합합니다.",
            "예정 인스턴스는 장기간 사용을 약속할 수 있는 예측 가능한 작업 부하에 적합하지만, 가변 작업 부하에 필요한 유연성을 제공하지 않습니다.",
            "SageMaker 절약 계획은 약속된 사용에 대한 절약을 제공하지만, 약속이 필요하므로 팀의 가변적인 작업 부하와 일치하지 않을 수 있습니다."
        ]
    },
    {
        "Question Number": "50",
        "Situation": "한 ML 엔지니어가 Virtual Private Cloud (VPC) 내에서 Amazon SageMaker에 머신 러닝 모델을 배포하는 임무를 맡고 있습니다. 모델은 S3 버킷 및 RDS 데이터베이스와 같은 필요한 리소스에 접근할 수 있도록 하면서 다른 서비스와 안전하게 격리되어야 합니다. 엔지니어는 VPC 아키텍처를 효과적으로 설계해야 합니다.",
        "Question": "ML 엔지니어가 머신 러닝 모델이 안전하게 실행되고 필요한 리소스에 접근할 수 있도록 하면서 공용 인터넷에 노출되지 않도록 하기 위해 구현해야 할 아키텍처 요소는 무엇입니까?",
        "Options": {
            "1": "보안 그룹이 있는 프라이빗 서브넷(Private Subnet with Security Groups)",
            "2": "NAT 게이트웨이(NAT Gateway)",
            "3": "인터넷 게이트웨이(Internet Gateway)",
            "4": "네트워크 ACL이 있는 퍼블릭 서브넷(Public Subnet with Network ACLs)"
        },
        "Correct Answer": "보안 그룹이 있는 프라이빗 서브넷(Private Subnet with Security Groups)",
        "Explanation": "보안 그룹이 있는 프라이빗 서브넷은 ML 모델이 공용 인터넷 접근 없이 안전한 환경에서 운영될 수 있도록 하며, 정의된 보안 규칙을 통해 S3 및 RDS와 같은 필요한 리소스와 통신할 수 있게 해줍니다.",
        "Other Options": [
            "인터넷 게이트웨이는 VPC 내 리소스에 대한 공용 접근을 제공하여 ML 모델을 인터넷에 노출시키고 보안 위험을 증가시킵니다.",
            "NAT 게이트웨이는 프라이빗 서브넷의 인스턴스가 인터넷으로 아웃바운드 트래픽을 시작할 수 있도록 하지만, ML 모델을 인바운드 인터넷 트래픽으로부터 보호하지 않으므로 필요한 격리를 제공하지 않습니다.",
            "네트워크 ACL이 있는 퍼블릭 서브넷은 외부 접근을 허용하므로 ML 시스템을 안전하게 격리하는 데 적합하지 않으며, 인터넷으로부터의 잠재적 공격에 노출됩니다."
        ]
    },
    {
        "Question Number": "51",
        "Situation": "한 소매 회사가 고객 이탈을 예측하기 위한 머신 러닝 모델을 개발하고 있습니다. 모델이 올바르게 작동하고 특정 고객 세그먼트에 대한 편향을 나타내지 않는지 평가해야 합니다.",
        "Question": "머신 러닝 엔지니어가 모델의 성능을 평가하고 잠재적 편향을 감지하기 위해 사용해야 할 평가 지표는 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "재현율(Recall)과 특이도(Specificity)",
            "2": "F1 점수(F1 Score)와 정밀도(Precision)",
            "3": "평균 제곱 오차(Mean Squared Error)와 R-제곱(R-squared)",
            "4": "ROC-AUC와 혼동 행렬(Confusion Matrix)",
            "5": "평균 절대 오차(Mean Absolute Error)와 편향-분산 균형(Bias-Variance Tradeoff)"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "F1 점수(F1 Score)와 정밀도(Precision)",
            "재현율(Recall)과 특이도(Specificity)"
        ],
        "Explanation": "F1 점수와 정밀도는 특히 한 클래스(예: 이탈 vs. 비이탈)가 과소 대표되는 불균형 데이터 세트에서 정밀도와 재현율의 균형을 맞추는 데 중요한 지표입니다. 재현율과 특이도는 편향을 감지하는 맥락에서도 중요하며, 모델이 다양한 클래스에 대한 민감도를 제공하여 고객 세그먼트에 따른 예측의 잠재적 편향을 식별하는 데 도움이 됩니다.",
        "Other Options": [
            "ROC-AUC와 혼동 행렬은 전체 성능 평가에 유용하지만, 이탈 예측의 맥락에서 편향 감지나 위양성 및 위음성 간의 균형에 대한 직접적인 통찰을 제공하지 않습니다.",
            "평균 절대 오차와 편향-분산 균형은 이탈 예측과 같은 분류 작업보다는 회귀 작업에 더 적합합니다.",
            "평균 제곱 오차와 R-제곱은 일반적으로 회귀 모델 평가에 사용되는 지표로, 이 시나리오에서 분류 성능을 평가하는 데 덜 관련이 있습니다."
        ]
    },
    {
        "Question Number": "52",
        "Situation": "소매 회사가 사용자 행동 및 선호도에 기반하여 제품을 추천하는 추천 시스템을 구현하여 고객 경험을 향상시키고자 합니다. 이들은 사용자 구매 이력, 제품 속성 및 고객 리뷰를 포함한 다양한 유형의 데이터에 접근할 수 있습니다. 회사는 선택한 머신 러닝 모델이 사용자 상호작용의 복잡성을 효과적으로 포착하고 정확한 추천을 제공하는지 확인하고자 합니다.",
        "Question": "회사가 효과적인 추천 시스템을 개발하기 위해 고려해야 할 접근 방식은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "리뷰를 기반으로 제품 평점을 예측하기 위해 선형 회귀 모델을 활용합니다.",
            "2": "복잡한 사용자-아이템 관계를 포착하기 위해 신경 협업 필터링 모델을 사용합니다.",
            "3": "사용자-아이템 상호작용을 분석하기 위해 협업 필터링 알고리즘을 활용합니다.",
            "4": "제품 속성과 사용자 인구 통계에 기반하여 결정 트리 모델을 구현합니다.",
            "5": "이전에 구매한 제품과 유사한 제품을 추천하기 위해 콘텐츠 기반 필터링 기법을 적용합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "사용자-아이템 상호작용을 분석하기 위해 협업 필터링 알고리즘을 활용합니다.",
            "복잡한 사용자-아이템 관계를 포착하기 위해 신경 협업 필터링 모델을 사용합니다."
        ],
        "Explanation": "협업 필터링 알고리즘은 사용자 상호작용의 패턴을 분석하여 사용자 선호도를 예측하는 데 효과적입니다. 마찬가지로, 신경 협업 필터링 모델은 사용자와 아이템 간의 복잡한 관계를 포착하여 딥 러닝 기법을 활용하여 추천의 품질을 향상시킵니다.",
        "Other Options": [
            "결정 트리 모델은 주로 구조화된 데이터에 초점을 맞추기 때문에 사용자-아이템 관계에서 발견되는 미묘한 상호작용을 포착하지 못할 수 있습니다.",
            "선형 회귀는 여러 사용자 상호작용을 기반으로 복잡한 추천을 만드는 것보다는 연속적인 결과를 예측하는 데 주로 적합합니다.",
            "콘텐츠 기반 필터링은 아이템의 속성만을 기반으로 하며, 방대한 사용자 상호작용 데이터를 활용하지 않기 때문에 추천의 효과를 제한할 수 있습니다."
        ]
    },
    {
        "Question Number": "53",
        "Situation": "전자상거래 플랫폼이 개인화된 제품 추천을 제공하기 위해 머신 러닝 모델을 운영하고 있습니다. 이 모델은 AWS Lambda를 사용하여 배포되며, 개발 팀은 피크 트래픽 시간 동안 지연 시간이 증가하는 것을 발견했습니다. 그들은 지연의 원인을 이해하고 기본 아키텍처를 수정하지 않고 성능을 최적화할 수 있는 솔루션이 필요합니다.",
        "Question": "팀이 Lambda 함수의 성능에 대한 통찰력을 얻고 지연 문제를 해결하기 위해 어떤 AWS 서비스를 사용해야 합니까?",
        "Options": {
            "1": "AWS X-Ray를 사용하여 요청 흐름을 시각화하고 성능 병목 현상을 식별합니다.",
            "2": "Amazon CloudWatch Logs Insights를 사용하여 로그를 분석하고 지연 원인을 파악합니다.",
            "3": "AWS Config를 사용하여 성능에 영향을 미치는 구성 변경을 모니터링합니다.",
            "4": "Amazon CloudWatch Custom Metrics를 사용하여 특정 함수에 대한 맞춤형 메트릭을 생성합니다."
        },
        "Correct Answer": "AWS X-Ray를 사용하여 요청 흐름을 시각화하고 성능 병목 현상을 식별합니다.",
        "Explanation": "AWS X-Ray는 개발자가 프로덕션 애플리케이션을 분석하고 디버깅할 수 있도록 설계되었으며, 요청 흐름, 지연 문제 및 서비스 종속성에 대한 통찰력을 제공하여 Lambda 함수의 성능 병목 현상을 식별하는 데 이상적입니다.",
        "Other Options": [
            "Amazon CloudWatch Logs Insights는 로그 데이터를 쿼리하고 분석하는 데 유용하지만, 요청 흐름 및 지연 원인에 대한 세부 정보를 AWS X-Ray만큼 제공하지 않습니다.",
            "Amazon CloudWatch Custom Metrics는 맞춤형 메트릭을 허용하지만, 지연 문제를 효과적으로 해결하는 데 필요한 포괄적인 시각화 및 추적 기능을 제공하지 않습니다.",
            "AWS Config는 구성 변경 및 준수를 기록하고 모니터링하는 데 중점을 두며, Lambda 함수의 성능 모니터링이나 지연 문제 해결을 직접적으로 다루지 않습니다."
        ]
    },
    {
        "Question Number": "54",
        "Situation": "금융 서비스 회사가 컨테이너를 사용하여 머신 러닝(ML) 모델을 배포하려고 합니다. 이 회사는 여러 개의 모델을 컨테이너화했으며, Amazon SageMaker를 사용하여 배포 및 오케스트레이션을 고려하고 있습니다. ML 엔지니어는 이러한 컨테이너 이미지를 효과적으로 저장하고 배포를 관리할 수 있는 가장 효율적인 방법을 선택해야 합니다.",
        "Question": "ML 엔지니어가 SageMaker에서 컨테이너화된 ML 모델을 효과적으로 배포하고 관리하면서 확장성과 업데이트 용이성을 보장하기 위해 어떤 솔루션을 선택해야 합니까?",
        "Options": {
            "1": "AWS Lambda를 사용하여 배포를 위한 컨테이너화된 모델을 실행합니다.",
            "2": "컨테이너 이미지를 Amazon Elastic Container Registry (ECR)에 업로드하고 SageMaker를 사용하여 배포합니다.",
            "3": "Amazon Elastic Compute Cloud (EC2) 인스턴스를 사용하여 모델을 수동으로 배포합니다.",
            "4": "레지스트리를 사용하지 않고 로컬 머신에서 SageMaker로 모델을 직접 배포합니다."
        },
        "Correct Answer": "컨테이너 이미지를 Amazon Elastic Container Registry (ECR)에 업로드하고 SageMaker를 사용하여 배포합니다.",
        "Explanation": "컨테이너 이미지를 Amazon Elastic Container Registry (ECR)에 업로드하면 버전 관리, 컨테이너 이미지의 용이한 관리 및 Amazon SageMaker와의 원활한 통합을 통해 배포가 가능합니다. 이 접근 방식은 오케스트레이션 및 확장을 간소화하여 가장 효율적인 솔루션이 됩니다.",
        "Other Options": [
            "AWS Lambda를 사용하는 것은 상당한 계산 자원을 요구하는 모델에는 적합하지 않을 수 있으며, Lambda는 실행 시간 및 메모리에 제한이 있어 성능을 저해할 수 있습니다.",
            "로컬 머신에서 SageMaker로 모델을 직접 배포하는 것은 컨테이너 레지스트리가 제공하는 버전 관리 및 중앙 집중식 관리의 이점을 우회하므로 실행 가능한 옵션이 아닙니다.",
            "EC2 인스턴스를 사용한 수동 배포는 SageMaker가 제공하는 자동화 및 오케스트레이션 기능이 부족하여 효율성이 떨어지고 확장 가능한 환경에서 관리하기 어려워집니다."
        ]
    },
    {
        "Question Number": "55",
        "Situation": "ML 엔지니어가 사용자 리뷰를 텍스트 데이터로 포함하는 이진 분류 작업을 위한 데이터셋을 준비하고 있습니다. 데이터셋은 불균형이 심각하여 90%의 리뷰가 긍정적으로 레이블이 지정되고 10%만 부정적으로 레이블이 지정되어 있습니다. 엔지니어는 모델 훈련 전에 데이터셋을 평가하기 위해 적절한 사전 훈련 편향 지표를 식별해야 합니다.",
        "Question": "ML 엔지니어가 모델 훈련 전에 데이터셋의 편향을 평가하기 위해 주로 어떤 지표를 사용해야 합니까?",
        "Options": {
            "1": "예측 정확도를 측정하기 위한 평균 제곱 오차 (MSE).",
            "2": "모델의 정밀도와 재현율을 이해하기 위한 F1 점수.",
            "3": "레이블의 분포를 평가하기 위한 클래스 불균형 (CI).",
            "4": "오류 분석을 위한 제곱근 평균 제곱 오차 (RMSE)."
        },
        "Correct Answer": "레이블의 분포를 평가하기 위한 클래스 불균형 (CI).",
        "Explanation": "클래스 불균형 (CI)은 데이터셋의 레이블 분포가 모델의 학습 및 일반화 능력에 상당한 영향을 미치기 때문에 이 시나리오에서 매우 중요합니다. 클래스 불균형을 식별하고 해결하는 것은 편향을 줄이고 모델 성능을 향상시키는 데 도움이 될 수 있으며, 특히 이진 분류 작업에서 더욱 그렇습니다.",
        "Other Options": [
            "평균 제곱 오차 (MSE)는 데이터셋 자체의 편향을 평가하는 데 적합하지 않으며, 일반적으로 회귀 작업을 평가하는 데 사용되는 성능 지표입니다.",
            "F1 점수는 모델 훈련 후 계산되는 성능 지표로, 정밀도와 재현율의 균형을 맞추는 데 사용되지만, 훈련 전에 데이터셋에 존재하는 편향을 직접적으로 다루지는 않습니다.",
            "제곱근 평균 제곱 오차 (RMSE)도 회귀 작업을 위한 성능 지표이며, 분류 데이터셋의 레이블 분포에 대한 통찰력을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "56",
        "Situation": "한 금융 서비스 회사가 머신 러닝 모델을 프로덕션에 배포하기 위한 CI/CD 파이프라인을 구현하고 있습니다. 그들은 보안에 대해 우려하고 있으며, 민감한 데이터와 지적 재산을 보호하기 위해 CI/CD 프로세스 전반에 걸쳐 모범 사례를 준수하고자 합니다.",
        "Question": "회사가 머신 러닝 모델을 위한 CI/CD 파이프라인에서 구현해야 할 보안 모범 사례는 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "모든 파이프라인 리소스에 대해 최소 권한 액세스를 가진 IAM 역할을 사용합니다.",
            "2": "무단 액세스를 감지하기 위해 모든 파이프라인 활동의 로깅 및 모니터링을 활성화합니다.",
            "3": "모든 개발자가 자격 증명 관리를 단순화하기 위해 단일 액세스 키를 사용합니다.",
            "4": "민감한 자격 증명을 소스 코드 저장소에 평문으로 저장합니다.",
            "5": "빌드 과정에서 코드 및 종속성에 대한 자동 보안 스캔을 구현합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "모든 파이프라인 리소스에 대해 최소 권한 액세스를 가진 IAM 역할을 사용합니다.",
            "빌드 과정에서 코드 및 종속성에 대한 자동 보안 스캔을 구현합니다."
        ],
        "Explanation": "최소 권한 액세스를 가진 IAM 역할을 구현하면 CI/CD 파이프라인의 각 구성 요소가 기능을 수행하는 데 필요한 권한만 가지게 되어 무단 작업의 위험을 최소화합니다. 빌드 과정에서 자동 보안 스캔을 구현하면 배포 전에 코드와 종속성의 취약점을 식별하여 전반적인 보안을 강화할 수 있습니다.",
        "Other Options": [
            "민감한 자격 증명을 평문으로 저장하는 것은 보안 위험이 크며, 소스 코드 저장소에 접근할 수 있는 누구에게나 민감한 정보를 노출합니다.",
            "로깅 및 모니터링을 활성화하는 것은 중요하지만, 자동 보안 스캔 및 최소 권한 액세스를 구현하는 것과 같은 사전 예방적 조치는 아닙니다. 따라서 이 맥락에서 구현해야 할 모범 사례 중 하나가 아닙니다.",
            "모든 개발자가 단일 액세스 키를 사용하는 것은 보안을 약화시키며, 파이프라인 내에서 수행된 작업에 대한 책임을 복잡하게 만듭니다."
        ]
    },
    {
        "Question Number": "57",
        "Situation": "ML 엔지니어가 AWS에서 배포된 머신 러닝 모델을 관리하고 있으며, 모델 운영과 관련된 리소스 사용 및 비용을 모니터링하기 위한 효과적인 비용 추적 및 할당 기술을 구현하고자 합니다.",
        "Question": "엔지니어가 배포된 ML 모델의 리소스에 대한 효율적인 비용 추적 및 할당을 보장하기 위해 어떤 조치를 취해야 합니까?",
        "Options": {
            "1": "비용 고려 없이 성능 지표를 추적하기 위해 CloudWatch 경고를 구현합니다.",
            "2": "지출을 시각화하기 위해 AWS Cost Explorer를 활성화하지만 리소스 태깅은 무시합니다.",
            "3": "리소스 사용을 모니터링하지 않고 비용 한도를 설정하기 위해 AWS Budgets를 사용합니다.",
            "4": "ML 모델과 관련된 모든 AWS 리소스에 태그를 추가하여 비용을 정확하게 할당합니다."
        },
        "Correct Answer": "ML 모델과 관련된 모든 AWS 리소스에 태그를 추가하여 비용을 정확하게 할당합니다.",
        "Explanation": "AWS 리소스에 태그를 추가하면 특정 프로젝트나 부서에 비용을 정확하게 할당할 수 있어 더 나은 예산 관리와 재무 관리를 촉진합니다. 이 관행은 머신 러닝 모델과 관련된 지출을 효과적으로 추적하고 분석하는 데 도움이 됩니다.",
        "Other Options": [
            "AWS Cost Explorer는 전체 지출을 시각화하는 데 유용하지만, 리소스 태깅을 무시하면 비용을 특정 리소스나 프로젝트에 할당할 수 없어 효과적인 비용 추적을 저해합니다.",
            "AWS Budgets로 비용 한도를 설정하는 것은 유용하지만, 리소스 사용을 모니터링하지 않으면 엔지니어가 리소스가 비용에 어떻게 기여하는지에 대한 중요한 통찰력을 놓칠 수 있어 비효율적인 재무 관리로 이어질 수 있습니다.",
            "CloudWatch 경고를 구현하는 것은 성능 추적에 중요하지만, 비용을 고려하지 않으면 엔지니어가 리소스 소비와 관련된 중요한 재정적 영향을 간과할 수 있습니다."
        ]
    },
    {
        "Question Number": "58",
        "Situation": "ML 엔지니어가 모바일 애플리케이션에서 실시간 예측을 위한 머신러닝 모델을 배포하는 임무를 맡았습니다. 현재 모델은 높은 정확도를 가지고 있지만 모바일 장치에 효율적으로 배포하기에는 너무 큽니다. 엔지니어는 성능에 큰 영향을 미치지 않으면서 모델 크기를 줄여야 합니다.",
        "Question": "ML 엔지니어가 모바일 배포를 위해 모델 크기를 효과적으로 줄이기 위해 어떤 전략을 구현해야 합니까?",
        "Options": {
            "1": "전체 모델 성능과 강건성을 개선하기 위해 훈련 데이터셋 크기를 늘립니다.",
            "2": "데이터셋의 추가 패턴을 포착할 수 있는 더 복잡한 모델 아키텍처를 사용합니다.",
            "3": "모델 양자화 기법을 적용하여 가중치의 정밀도를 줄이고 추론 속도를 개선합니다.",
            "4": "데이터의 복잡한 상호작용을 포착하는 더 많은 기능을 추가하기 위해 특성 공학을 구현합니다."
        },
        "Correct Answer": "모델 양자화 기법을 적용하여 가중치의 정밀도를 줄이고 추론 속도를 개선합니다.",
        "Explanation": "모델 양자화 기법은 모델의 가중치의 수치 정밀도를 줄여 모델 크기를 크게 줄이고 추론 속도를 개선하여 성능에 큰 영향을 미치지 않으면서 모바일 배포에 더 적합하게 만듭니다.",
        "Other Options": [
            "더 많은 기능을 추가하기 위해 특성 공학을 구현하는 것은 모델 크기와 복잡성을 증가시켜 모바일 배포를 위한 모델 크기를 줄이는 목표에 반하는 결과를 초래할 수 있습니다.",
            "더 복잡한 모델 아키텍처를 사용하는 것도 모델 크기를 증가시키고 추론 시간을 느리게 할 수 있어 모바일 장치의 제약에 적합하지 않을 수 있습니다.",
            "훈련 데이터셋 크기를 늘리는 것은 모델 성능을 개선할 수 있지만, 모바일 배포에 중요한 모델 크기 문제를 직접적으로 해결하지는 않습니다."
        ]
    },
    {
        "Question Number": "59",
        "Situation": "데이터 엔지니어링 팀이 프로덕션 환경에 배포된 여러 머신러닝 모델의 성능을 모니터링하는 임무를 맡았습니다. 그들은 지연 문제를 신속하게 식별하고 해결하며 다양한 부하에서 모델이 어떻게 작동하는지 이해해야 합니다. 팀은 ML 모델의 성능 메트릭과 로그에 대한 통찰력을 얻기 위해 다양한 AWS 서비스를 고려하고 있습니다.",
        "Question": "팀이 서버리스 ML 추론 애플리케이션의 성능 및 지연에 대한 자세한 통찰력을 얻기 위해 어떤 AWS 서비스를 사용해야 합니까?",
        "Options": {
            "1": "Amazon SageMaker Model Monitor",
            "2": "Amazon CloudWatch Logs Insights",
            "3": "Amazon CloudWatch Lambda Insights",
            "4": "AWS X-Ray"
        },
        "Correct Answer": "Amazon CloudWatch Lambda Insights",
        "Explanation": "Amazon CloudWatch Lambda Insights는 서버리스 ML 추론 애플리케이션에 일반적으로 사용되는 AWS Lambda 함수에 대한 전문 메트릭과 통찰력을 제공합니다. 이는 팀이 성능을 모니터링하고 지연 문제를 해결하며 리소스 사용을 효과적으로 최적화하는 데 도움을 줍니다.",
        "Other Options": [
            "Amazon CloudWatch Logs Insights는 로그 데이터를 쿼리하고 분석하는 데 주로 사용되며, 서버리스 애플리케이션에 필요한 특정 성능 메트릭을 제공하지 않을 수 있습니다.",
            "AWS X-Ray는 분산 시스템에서 요청을 추적하기 위해 설계되었지만, ML 추론과 직접 관련된 Lambda 함수를 모니터링하는 데 필요한 특정 성능 통찰력을 제공하지 않을 수 있습니다.",
            "Amazon SageMaker Model Monitor는 시간에 따라 ML 모델의 품질을 모니터링하는 데 중점을 두지만, 서버리스 애플리케이션에 대한 실시간 성능 통찰력을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "60",
        "Situation": "소매 회사의 데이터 과학 팀이 과거 거래 데이터를 기반으로 고객 구매를 예측하기 위한 머신러닝 모델을 구축할 준비를 하고 있습니다. 팀은 데이터 전처리 및 분석을 위한 용이한 접근을 보장하면서 대량의 구조화된 데이터와 비구조화된 데이터를 안전하게 저장해야 합니다. 그들은 비용, 확장성 및 접근성을 최적화하기 위해 다양한 AWS 스토리지 옵션을 고려하고 있습니다.",
        "Question": "팀이 구조화된 데이터와 비구조화된 데이터를 안전하게 저장하고 데이터 준비 작업을 위한 용이한 접근을 제공하기 위해 어떤 AWS 스토리지 솔루션이 가장 적합합니까?",
        "Options": {
            "1": "세분화된 접근 제어 및 수명 주기 정책이 있는 Amazon S3.",
            "2": "프로비저닝된 처리량 모델이 있는 Amazon DynamoDB.",
            "3": "수평 확장을 위한 읽기 복제본이 있는 Amazon RDS.",
            "4": "데이터 처리를 위한 높은 처리량 모드가 있는 Amazon EFS."
        },
        "Correct Answer": "세분화된 접근 제어 및 수명 주기 정책이 있는 Amazon S3.",
        "Explanation": "Amazon S3는 확장성, 내구성 및 비용 효율성을 위해 설계되어 구조화된 데이터와 비구조화된 데이터를 저장하는 데 이상적입니다. 세분화된 접근 제어 및 수명 주기 정책을 허용하여 팀이 데이터 보존을 효과적으로 관리하면서 데이터 전처리 작업을 위한 안전한 접근을 보장할 수 있습니다.",
        "Other Options": [
            "Amazon RDS는 주로 구조화된 데이터와 트랜잭션 워크로드에 적합합니다. 비구조화된 데이터에는 최선의 선택이 아닐 수 있으며, 읽기 복제본을 제공하지만 다양한 데이터의 대량 저장을 위해 S3만큼 유연하게 확장되지 않을 수 있습니다.",
            "Amazon EFS는 데이터에 대한 공유 접근을 제공하는 파일 스토리지 서비스입니다. 그러나 대규모 저장소에 대해 S3보다 더 비쌀 수 있으며, 일반적으로 대규모 데이터 저장 및 분석보다는 파일 기반 워크로드에 더 적합합니다.",
            "Amazon DynamoDB는 구조화된 데이터와 고가용성 사용 사례에 적합한 NoSQL 데이터베이스입니다. 그러나 대량의 비구조화된 데이터를 저장하기 위해 설계되지 않았으며, 데이터 과학 팀의 필요에 대해 비용 모델이 효율적이지 않을 수 있습니다."
        ]
    },
    {
        "Question Number": "61",
        "Situation": "소매 회사가 Amazon SageMaker Neo를 사용하여 엣지 장치에서 실시간 재고 추적을 위한 머신러닝 모델을 배포하고 있습니다. 팀은 모델이 다양한 하드웨어 플랫폼에서 효율적으로 실행되면서 높은 성능을 유지하도록 하고자 합니다.",
        "Question": "ML 엔지니어가 SageMaker Neo를 사용하여 엣지 장치에 맞게 모델을 최적화하기 위해 어떤 방법을 사용해야 합니까?",
        "Options": {
            "1": "특정 대상 하드웨어에 맞게 SageMaker Neo로 모델을 컴파일하고 저지연성으로 최적화합니다.",
            "2": "Amazon Elastic Inference를 사용하여 엣지 장치에 GPU 리소스를 연결하여 모델 추론을 수행합니다.",
            "3": "SageMaker에서 모델을 TensorFlow SavedModel로 내보내고 엣지 배포를 위해 수동으로 최적화합니다.",
            "4": "SageMaker에서 대량 배치 크기를 사용하여 엣지 장치의 성능을 향상시킵니다."
        },
        "Correct Answer": "특정 대상 하드웨어에 맞게 SageMaker Neo로 모델을 컴파일하고 저지연성으로 최적화합니다.",
        "Explanation": "SageMaker Neo는 다양한 하드웨어 플랫폼에 맞게 최적화된 머신러닝 모델을 컴파일할 수 있게 해주며, 이는 특히 엣지 장치에서의 지연 시간과 자원 활용 측면에서 상당한 성능 향상을 제공합니다.",
        "Other Options": [
            "Amazon Elastic Inference는 클라우드에서 딥러닝 추론의 성능을 향상시키기 위해 사용되며, 엣지 장치 최적화를 위해 특별히 설계되지 않았으므로 이 시나리오에 적합하지 않습니다.",
            "대량 배치 크기로 훈련하면 훈련 속도가 향상될 수 있지만, 엣지 장치에 배포하기 위해 모델을 직접 최적화하지는 않으므로 여기서 주요 관심사가 아닙니다.",
            "모델을 TensorFlow SavedModel로 내보내는 것은 엣지 장치에 대한 성능 최적화를 보장하지 않으며, 효과적인 배포 및 최적화를 위해 추가 단계가 필요합니다."
        ]
    },
    {
        "Question Number": "62",
        "Situation": "소매 회사가 역사적 데이터를 기반으로 고객 구매 행동을 예측하기 위한 머신러닝 모델을 개발하고 있습니다. 데이터셋이 크고 모델 훈련에 상당한 시간이 소요됩니다. 데이터 과학 팀은 모델 성능을 저하시키지 않으면서 훈련 프로세스를 최적화할 전략을 찾고 있습니다.",
        "Question": "모델 훈련 시간을 줄이면서 효율적인 수렴을 보장하기 위한 가장 효과적인 방법은 무엇입니까?",
        "Options": {
            "1": "최적화를 위해 배치 경량 하강법에만 의존하기",
            "2": "성능이 정체되면 훈련을 중단하기 위해 조기 중단 구현하기",
            "3": "일관성을 위해 단일 스레드 처리 접근 방식 사용하기",
            "4": "정확성을 높이기 위해 데이터셋 크기 증가시키기"
        },
        "Correct Answer": "성능이 정체되면 훈련을 중단하기 위해 조기 중단 구현하기",
        "Explanation": "조기 중단은 모델의 성능을 검증 세트에서 모니터링하고 성능이 지정된 반복 횟수 동안 개선되지 않으면 훈련을 중단하는 기술입니다. 이는 과적합을 방지하고 불필요한 훈련 시간을 줄이는 데 도움이 됩니다. 이는 훈련 프로세스를 효과적으로 최적화하기 위해 널리 사용되는 전략입니다.",
        "Other Options": [
            "단일 스레드 처리 접근 방식을 사용하면 계산 효율성이 제한되고 훈련 프로세스가 느려져 훈련 시간을 줄이는 데 비효율적인 전략이 됩니다.",
            "데이터셋 크기를 증가시키면 일반적으로 모델 훈련에 더 많은 시간이 필요하므로, 더 큰 데이터셋은 보통 처리 시간이 길어져 훈련 시간을 줄이는 효과적인 방법이 아닙니다.",
            "배치 경량 하강법에만 의존하는 것은 미니 배치 경량 하강법이나 확률적 경량 하강법과 같은 다른 최적화 방법에 비해 덜 효율적일 수 있으며, 이는 더 빠르게 수렴하고 전체 훈련 시간을 줄일 수 있습니다."
        ]
    },
    {
        "Question Number": "63",
        "Situation": "금융 서비스 회사가 실시간 신용 점수를 위한 머신러닝 모델을 배포하려고 합니다. ML 엔지니어는 AWS에서 제공하는 미리 구축된 Docker 컨테이너를 사용할지 아니면 배포를 위해 맞춤형 컨테이너를 생성할지를 결정해야 합니다. 이 결정은 모델의 배포 용이성, 성능 및 유지 관리에 영향을 미칠 것입니다.",
        "Question": "ML 엔지니어가 제공된 컨테이너와 맞춤형 컨테이너 중에서 선택할 때 고려해야 할 요소는 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "기존 CI/CD 워크플로와의 통합",
            "2": "컨테이너 이미지의 저장 비용",
            "3": "컨테이너화에 대한 개발 팀의 친숙함",
            "4": "데이터 프라이버시 규정 및 준수",
            "5": "확장성 및 성능 요구 사항"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "확장성 및 성능 요구 사항",
            "컨테이너화에 대한 개발 팀의 친숙함"
        ],
        "Explanation": "제공된 컨테이너와 맞춤형 컨테이너 중에서 선택할 때, 확장성 및 성능 요구 사항은 매우 중요합니다. 모델이 다양한 부하를 효율적으로 처리해야 하기 때문입니다. 또한, 개발 팀의 컨테이너화에 대한 친숙함은 배포 및 유지 관리의 속도와 용이성에 영향을 미치므로 고려해야 할 중요한 요소입니다.",
        "Other Options": [
            "데이터 프라이버시 규정 및 준수는 중요한 고려 사항이지만, 제공된 컨테이너와 맞춤형 컨테이너 중에서 선택하는 데 직접적인 영향을 미치지 않으며, 오히려 해당 컨테이너 내에서 데이터가 어떻게 관리되는지가 중요합니다.",
            "컨테이너 이미지의 저장 비용은 성능 및 확장성에 비해 덜 중요합니다. 제공된 컨테이너와 맞춤형 컨테이너 모두 유사한 저장 비용을 가질 수 있으므로 이 요소는 주요 고려 사항이 아닙니다.",
            "기존 CI/CD 워크플로와의 통합은 관련이 있지만, ML 모델의 성공적인 배포에 필수적인 확장성 및 성능의 즉각적인 요구 사항에 비해 부차적입니다."
        ]
    },
    {
        "Question Number": "64",
        "Situation": "데이터 과학 팀이 Amazon S3에 저장된 대규모 데이터 세트를 사용하여 머신 러닝 모델을 구축할 준비를 하고 있습니다. 그들은 훈련 단계 동안 데이터에 빠르고 효율적으로 접근할 수 있도록 해야 합니다.",
        "Question": "팀이 머신 러닝 워크플로우를 위해 Amazon S3에서 데이터 추출 프로세스를 최적화하기 위해 어떤 AWS 서비스나 기능을 활용해야 합니까?",
        "Options": {
            "1": "Amazon S3 크로스 리전 복제를 사용하여 데이터 가용성을 향상시킵니다.",
            "2": "Amazon S3 라이프사이클 정책을 사용하여 데이터를 아카이빙하여 비용을 절감합니다.",
            "3": "Amazon S3 표준 스토리지를 사용하여 데이터 접근 시 낮은 대기 시간을 보장합니다.",
            "4": "Amazon S3 전송 가속을 사용하여 S3에서 데이터 전송 속도를 높입니다."
        },
        "Correct Answer": "Amazon S3 전송 가속을 사용하여 S3에서 데이터 전송 속도를 높입니다.",
        "Explanation": "Amazon S3 전송 가속은 Amazon S3로의 파일 전송 속도를 높이기 위해 특별히 설계되었으며, 대규모 데이터 세트에 대한 빠른 접근이 필요한 머신 러닝 워크플로우의 데이터 추출 프로세스를 최적화하는 데 이상적인 선택입니다.",
        "Other Options": [
            "Amazon S3 표준 스토리지를 사용하는 것은 전송 속도를 본질적으로 최적화하지 않으며, 데이터가 낮은 대기 시간으로 저장되도록 보장하지만 데이터 전송 속도에 대해서는 구체적으로 다루지 않습니다.",
            "Amazon S3 라이프사이클 정책은 객체의 나이에 따라 전환하거나 삭제하여 저장 비용을 관리하는 데 중점을 두며, 훈련 과정 중 데이터 추출 속도에는 영향을 미치지 않습니다.",
            "Amazon S3 크로스 리전 복제는 데이터 가용성과 중복성을 향상시키는 데 유용하지만 머신 러닝을 위한 데이터 추출 시 데이터 접근 속도를 직접적으로 향상시키지는 않습니다."
        ]
    },
    {
        "Question Number": "65",
        "Situation": "머신 러닝 엔지니어가 이미지 분류를 위한 여러 모델을 개발하고 검증하는 임무를 맡고 있습니다. 엔지니어는 AWS 서비스를 사용하면서 실험이 재현 가능하고 시간이 지남에 따라 추적될 수 있도록 해야 합니다.",
        "Question": "다음 중 어떤 접근 방식이 엔지니어가 AWS 서비스를 사용하여 재현 가능한 실험을 수행하고 모델 성능을 추적하는 데 가장 적합합니까?",
        "Options": {
            "1": "Amazon EC2 인스턴스에서 Jupyter 노트북을 설정하여 모델을 개발하고 매개변수와 결과를 CSV 파일에 수동으로 기록합니다.",
            "2": "Amazon SageMaker Experiments를 사용하여 다양한 훈련 실행, 모델 및 매개변수를 조직하고 추적합니다. 데이터 접근을 위해 이미지를 Amazon S3에 저장합니다.",
            "3": "AWS CodePipeline을 사용하여 모델 훈련 및 로깅을 자동화하는 맞춤형 솔루션을 구현하고, 엔지니어의 머신에서 데이터 세트를 로컬로 관리합니다.",
            "4": "AWS Lambda 함수를 활용하여 중앙 집중식 추적 시스템 없이 모델 훈련 및 로깅을 트리거하고, 결과를 Amazon DynamoDB에 저장합니다."
        },
        "Correct Answer": "Amazon SageMaker Experiments를 사용하여 다양한 훈련 실행, 모델 및 매개변수를 조직하고 추적합니다. 데이터 접근을 위해 이미지를 Amazon S3에 저장합니다.",
        "Explanation": "Amazon SageMaker Experiments는 실험, 매개변수 및 결과를 추적하도록 특별히 설계되어 재현성을 보장합니다. 이미지를 Amazon S3에 저장하면 다양한 실험에서 사용된 데이터 세트에 쉽게 접근할 수 있습니다.",
        "Other Options": [
            "Amazon EC2 인스턴스에서 Jupyter 노트북을 사용하는 것은 구조화된 추적 시스템이 부족하여 실험을 재현하고 결과를 효율적으로 관리하기 어렵습니다.",
            "AWS Lambda 함수는 복잡한 모델 훈련 워크플로우를 관리하는 데 이상적이지 않으며, 중앙 집중식 추적 시스템이 없으면 재현성이 저해됩니다.",
            "AWS CodePipeline은 프로세스를 자동화할 수 있지만 머신 러닝 실험을 위해 특별히 설계되지 않았으며 재현성에 필요한 세부 추적 기능을 제공하지 않을 수 있습니다."
        ]
    }
]