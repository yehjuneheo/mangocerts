[
    {
        "Question Number": "1",
        "Situation": "あなたの組織は、異なる環境（開発、テスト、本番）のために複数のAWSアカウントにまたがるCI/CDパイプラインを実装しています。コードの変更が自動的にビルド、テスト、デプロイされることを確実にし、手動の介入を最小限に抑え、最大限のセキュリティを確保したいと考えています。どのデプロイメントパターンを使用すべきですか？",
        "Question": "マルチアカウントAWS環境でSDLCを自動化するために最も適したデプロイメントパターンはどれですか？",
        "Options": {
            "1": "1つのアカウントに共有リポジトリを持つAWS CodePipelineを使用し、他のアカウントにアーティファクトを手動でデプロイします。",
            "2": "各アカウントに独立してデプロイメントをトリガーする別々のCI/CDパイプラインを作成します。",
            "3": "本番アカウントに単一のCI/CDパイプラインを実装し、すべての下位環境に直接デプロイします。",
            "4": "管理アカウントに集中型CI/CDパイプラインを設定し、デプロイメントのためにクロスアカウントロールを使用します。"
        },
        "Correct Answer": "管理アカウントに集中型CI/CDパイプラインを設定し、デプロイメントのためにクロスアカウントロールを使用します。",
        "Explanation": "管理アカウントに集中型CI/CDパイプラインを設定することで、複数のアカウントにわたるデプロイメントのガバナンスと管理が効率化されます。クロスアカウントロールを使用することで、他のアカウントにリソースをデプロイするための安全で認可されたアクセスが確保され、セキュリティとコンプライアンスの維持に重要です。",
        "Other Options": [
            "各アカウントに別々のCI/CDパイプラインを作成すると、デプロイメントの実践が一貫しなくなり、管理のオーバーヘッドが増加し、デプロイメントプロセスの制御が難しくなります。",
            "1つのアカウントに共有リポジトリを持つAWS CodePipelineを使用し、他のアカウントにアーティファクトを手動でデプロイすることは、手動のステップを導入し、エラーや不整合を引き起こす可能性があり、自動化の利点を無効にします。",
            "本番アカウントに単一のCI/CDパイプラインを実装し、下位環境に直接デプロイすることは、セキュリティと安定性を損なう可能性があり、本番環境の変更が他の環境に影響を与える可能性があります。"
        ]
    },
    {
        "Question Number": "2",
        "Situation": "ある会社がユーザーのトラフィックに基づいて動的にスケーリングする必要がある新しいウェブアプリケーションをデプロイしています。このアプリケーションはAmazon EC2インスタンス上にホストされており、会社は高可用性とコスト効率を確保したいと考えています。彼らは、インスタンスを効果的に管理するために特定のスケーリングポリシーを持つAuto Scalingグループ（ASG）を使用する予定です。",
        "Question": "会社は、ASGがAWSの起動構成とAuto Scalingグループの制限に従って正しくスケールすることを確実にするために、どのような構成を実装すべきですか？",
        "Options": {
            "1": "ASGを最小サイズ2、希望サイズ4、最大サイズ6に設定します。インスタンスパラメータを定義するために起動テンプレートを使用します。毎週月曜日から金曜日の午前9時に容量を増やすスケジュールスケーリングポリシーを実装します。",
            "2": "最小サイズ0、希望サイズ2、最大サイズ4のASGを作成します。コスト管理を改善するためにインスタンスタイプのミックスを持つ起動構成を利用します。アプリケーションの負荷メトリックに基づく動的スケーリングポリシーを設定します。",
            "3": "最小サイズ1、希望サイズ5、最大サイズ10のASGを確立します。古いAMIと小さいインスタンスタイプを含む起動構成を使用します。ネットワークトラフィックが20%未満に下がった場合にスケールインするスケーリングポリシーを作成します。",
            "4": "ASGの最小サイズを1、希望サイズを3、最大サイズを5に設定します。最新のAMIとインスタンスタイプを持つ起動構成を使用します。CPU使用率メトリックが70%を超えた場合にスケーリングアクションをトリガーするスケーリングポリシーを作成します。"
        },
        "Correct Answer": "ASGの最小サイズを1、希望サイズを3、最大サイズを5に設定します。最新のAMIとインスタンスタイプを持つ起動構成を使用します。CPU使用率メトリックが70%を超えた場合にスケーリングアクションをトリガーするスケーリングポリシーを作成します。",
        "Explanation": "このオプションは、ASGがトラフィックを処理するのに十分なインスタンスを持ち、CPU使用率に基づくスケーリングアクションのためのバッファを提供します。この構成は、動的スケーリングのためのAWSのベストプラクティスに従い、最新のリソースを利用します。",
        "Other Options": [
            "このオプションはASGの最小サイズを高く設定しすぎており、トラフィックが少ないときに不必要なコストが発生する可能性があります。最小サイズ2は、低使用時にゼロまでスケールダウンできるアプリケーションには理想的ではありません。",
            "このオプションには古いAMIと小さいインスタンスタイプが含まれており、アプリケーションに必要なパフォーマンスを提供できない可能性があります。さらに、CPU使用率を考慮せずにネットワークトラフィックに基づいてスケーリングすることは、ピーク負荷時にリソースを効果的に管理できない可能性があります。",
            "このオプションは最小サイズを0に設定しており、突然の需要がある場合に問題が発生する可能性があります。これはスケーリングアウトの遅延を引き起こす可能性があります。動的スケーリングポリシーは有益ですが、高可用性のためには最小サイズ1から始めることが推奨されます。"
        ]
    },
    {
        "Question Number": "3",
        "Situation": "ある会社がAWSで実行されているウェブサービスによって生成されたアプリケーションログを監視するためにAmazon CloudWatchを使用しています。DevOpsチームは、アプリケーションのエラーを示す特定のログイベントからCloudWatchメトリックを作成する任務を負っています。彼らは、重要なエラーイベントが効果的に監視され、発生時にアラームがトリガーされることを確実にする必要があります。チームは、ログイベントに「ERROR」というキーワードが含まれていることを確認しました。",
        "Question": "DevOpsエンジニアは、ログ内の「ERROR」というキーワードの出現を追跡するCloudWatchメトリックを作成するために何をすべきですか？",
        "Options": {
            "1": "すべてのログイベントをキャプチャするCloudWatchメトリックフィルターを設定し、その後CloudWatchダッシュボードで手動で「ERROR」を検索します。",
            "2": "「ERROR」を認識するパターンを持つCloudWatchメトリックフィルターを作成し、チームに通知するためにCloudWatchアラームに関連付けます。",
            "3": "「ERROR」を含むログイベントを転送するためにAmazon SNSトピックを構成し、SNS通知から手動でCloudWatchメトリックを作成します。",
            "4": "ログを処理し、「ERROR」という単語の出現ごとにカスタムCloudWatchメトリックを公開するLambda関数を実装します。"
        },
        "Correct Answer": "「ERROR」を認識するパターンを持つCloudWatchメトリックフィルターを作成し、チームに通知するためにCloudWatchアラームに関連付けます。",
        "Explanation": "特定のパターンを持つCloudWatchメトリックフィルターを作成することで、「ERROR」というキーワードを含むログイベントの自動追跡が可能になります。このアプローチにより、リアルタイムの監視が可能になり、メトリックに基づいてアラームを設定することができ、プロアクティブなインシデント管理に不可欠です。",
        "Other Options": [
            "すべてのログイベントをキャプチャするメトリックフィルターを設定することは、「ERROR」の出現を効率的に追跡するための特定のメカニズムを提供せず、エラーを特定するために手動の介入が必要になり、自動監視の目的を無効にします。",
            "Lambda関数を実装することは、プロセスに不必要な複雑さとレイテンシを追加します。エラーを追跡することは可能ですが、CloudWatchメトリックフィルターがすぐに利用できる場合、ログイベントから直接メトリックを作成する最も効率的な方法ではありません。",
            "ログイベントのためにSNSトピックを構成することは、追加の設定とメンテナンスを必要とします。このアプローチは、ログから直接メトリックを作成せず、通知と監視の遅延を引き起こすことになります。"
        ]
    },
    {
        "Question Number": "4",
        "Situation": "ある企業は、複数のAWSアカウントを管理するためにAWS Organizationsを導入しました。彼らは、メンバーアカウントで使用できるサービスを制限するためにサービスコントロールポリシー（SCP）を使用してガバナンスを強化したいと考えています。企業は、これらのポリシーがメンバーアカウント内のすべてのユーザー、特にルートユーザーに対して効果的に適用されることを確認する必要があります。",
        "Question": "サービスコントロールポリシー（SCP）に関する次の2つの文は正しいですか？（2つ選択）",
        "Options": {
            "1": "SCPはメンバーアカウント内の特定のサービスへのアクセスを制限できます。",
            "2": "SCPはメンバーアカウントに対してすべてのAWSサービスを有効にするために使用できます。",
            "3": "SCPは組織の管理アカウントには適用されません。",
            "4": "SCPはメンバーアカウント内のすべてのユーザー、特にルートユーザーに適用されます。",
            "5": "SCPはメンバーアカウント内のサービスリンクロールに影響を与えます。"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "SCPはメンバーアカウント内のすべてのユーザー、特にルートユーザーに適用されます。",
            "SCPは組織の管理アカウントには適用されません。"
        ],
        "Explanation": "サービスコントロールポリシー（SCP）は、組織内のすべてのアカウントに対して最大の利用可能な権限を定義するために使用できます。これらはメンバーアカウント内のすべてのユーザーに適用され、ルートユーザーも含まれますが、サービスリンクロールには影響を与えません。さらに、SCPは管理アカウント自体には適用されないため、管理アカウントは組織全体のポリシーを管理する能力を保持します。",
        "Other Options": [
            "SCPはメンバーアカウント内のサービスリンクロールに影響を与えます。これは不正確です。なぜなら、SCPはサービスリンクロールに影響を与えず、これらは組織内で定義されたSCPとは独立して動作するからです。",
            "SCPはメンバーアカウントに対してすべてのAWSサービスを有効にするために使用できます。これは不正確です。なぜなら、SCPは権限を制限するために設計されており、すべてのサービスを有効にすることは、ガバナンスの目的に反するからです。",
            "SCPはメンバーアカウント内の特定のサービスへのアクセスを制限できます。この文は真実のように見えますが、SCPは権限を制限するだけであり、サービスへのアクセスを付与するものではないという完全な文脈を提供していません。"
        ]
    },
    {
        "Question Number": "5",
        "Situation": "ある金融サービス会社は、Amazon S3バケットに保存されている個人識別情報（PII）や支払い詳細などの機密データの保護について懸念しています。彼らは、規制基準に準拠するために、AWS環境全体で機密データの発見を自動化する必要があります。DevOpsエンジニアは、手動の監視と運用のオーバーヘッドを最小限に抑えながら、これを大規模に実現するためのソリューションを実装する任務を負っています。",
        "Question": "DevOpsエンジニアが機密データの発見を自動化するために実装すべきオプションの組み合わせはどれですか？（2つ選択）",
        "Options": {
            "1": "AWS Configルールを設定してS3バケットポリシーを監視し、機密データを露出させる可能性のある変更について警告します。",
            "2": "Amazon Macieを設定して、定期的にAmazon S3バケットに保存されている機密データを自動的に分類および発見します。",
            "3": "Amazon MacieをAWS Lambdaと連携させて、S3バケットで機密データが検出されたときに警告をトリガーします。",
            "4": "AWS Security Hubを展開して、さまざまなAWSサービスからの機密データに関する発見を集約し、コンプライアンスの包括的なビューを提供します。",
            "5": "AWS Glue Data Catalogを実装して、S3やRDSを含む複数のデータストア全体で機密データを整理および発見します。"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon Macieを設定して、定期的にAmazon S3バケットに保存されている機密データを自動的に分類および発見します。",
            "Amazon MacieをAWS Lambdaと連携させて、S3バケットで機密データが検出されたときに警告をトリガーします。"
        ],
        "Explanation": "Amazon Macieは、特にS3内の機密データの発見と分類を自動化するために特別に設計されています。Macieをスケジュールで実行するように設定することで、企業は継続的なコンプライアンス監視を確保できます。さらに、MacieをAWS Lambdaと統合することで、チームは発見に基づいて自動応答や警告を設定し、データ保護戦略を強化できます。",
        "Other Options": [
            "AWS Configルールを設定することは構成のコンプライアンスを監視するのに役立ちますが、機密データを直接発見または分類するものではありません。これは、変更とコンプライアンスの追跡に重点を置いています。",
            "AWS Glue Data Catalogは主にメタデータリポジトリであり、データを整理および発見するのに役立ちますが、Macieのように機密データの分類および監視機能を本質的に提供するものではありません。",
            "AWS Security HubはさまざまなAWSセキュリティサービスからの発見を集約しますが、機密データの発見を自動化するものではありません。これは、直接的なデータ分類よりもセキュリティ姿勢管理に重点を置いています。"
        ]
    },
    {
        "Question Number": "6",
        "Situation": "ある企業は、AWS上でホストされているアプリケーションに断続的なパフォーマンスの問題を抱えています。このアプリケーションは、Amazon EC2インスタンスとAmazon RDSをデータベースとして使用しています。運用チームは、EC2インスタンスの高いCPU使用率やRDSの遅いクエリパフォーマンスに関する警告を受け取っています。アプリケーションのパフォーマンスを最適化するために、チームはこれらのイベントに応じて自動的に構成変更を実装する必要があります。",
        "Question": "EC2およびRDSからのパフォーマンス警告に基づいて自動的に構成変更を実装するための最も効果的なソリューションは何ですか？",
        "Options": {
            "1": "Amazon RDS Performance Insightsを設定して遅いクエリを監視します。パフォーマンスしきい値が超えたときにデータベース構成を最適化するAWS Lambda関数を作成します。",
            "2": "EC2のCPU使用率とRDSのパフォーマンスメトリクスの両方に対してAmazon CloudWatchアラームを作成します。AWS Step Functionsを使用して、アラームの状態に基づいてEC2インスタンスタイプとRDSパラメータを調整するLambda関数を呼び出すワークフローを調整します。",
            "3": "EC2インスタンスのCPU使用率に対してAmazon CloudWatchアラームを設定します。アラームがトリガーされたときにインスタンスタイプを大きなサイズに変更するAWS Lambda関数を作成します。",
            "4": "AWS Systems Managerを利用して、EC2およびRDSのCloudWatchアラームに基づいて自動アクションを実行します。パフォーマンスの問題が検出されたときにEC2インスタンスをスケールし、RDS構成を変更するランブックを設定します。"
        },
        "Correct Answer": "EC2のCPU使用率とRDSのパフォーマンスメトリクスの両方に対してAmazon CloudWatchアラームを作成します。AWS Step Functionsを使用して、アラームの状態に基づいてEC2インスタンスタイプとRDSパラメータを調整するLambda関数を呼び出すワークフローを調整します。",
        "Explanation": "このアプローチは、CloudWatchアラームを使用してパフォーマンスメトリクスを監視し、Step Functionsを使用して応答の調整を管理します。これにより、検出されたパフォーマンスの問題に基づいてEC2およびRDSの構成を自動的に調整することができます。",
        "Other Options": [
            "このオプションはEC2インスタンスのサイズ変更のみを扱っており、RDSのパフォーマンス問題を考慮していないため、両方のサービスに対する調整された応答を提供しません。",
            "RDS Performance Insightsは監視に役立ちますが、このオプションはEC2インスタンスのスケーリングに対処しておらず、両方のサービスにわたるパフォーマンス最適化への包括的なアプローチを提供していません。",
            "AWS Systems Managerはタスクを自動化できますが、このオプションはStep Functionsが提供する調整機能が欠けており、複数のアラームとアクションを効率的に処理するために必要です。"
        ]
    },
    {
        "Question Number": "7",
        "Situation": "ある企業が複数のAWSアカウントを管理しており、Amazon VPCサブネットやAmazon RDSデータベースなどの特定のリソースをこれらのアカウント間で共有したいと考えています。リソースは現在、彼らのアカウントの1つにあり、AWS Resource Access Manager (RAM)を使用してこの共有を促進したいと考えています。DevOpsエンジニアとして、共有するリソースを含むリソース共有を同じアカウント内で作成する必要があります。",
        "Question": "同じAWSアカウント内で指定されたリソースのためにAWS RAMを使用してリソース共有を作成する正しいアプローチは何ですか？",
        "Options": {
            "1": "AWS RAMコンソールに移動し、新しいリソース共有を作成し、共有するリソースを選択し、それにアクセスできるアカウントを指定します。共有が有効になっていることを確認してください。",
            "2": "AWS CloudFormationを利用して、RAMを使用してリソース共有を定義するスタックを作成し、テンプレート内でリソースとアカウントを指定します。",
            "3": "AWS CLIを使用して、リソースARNとアカウントIDを指定してリソース共有を作成します。共有リソースのために適切な権限を含めることを確認してください。",
            "4": "AWS Management Consoleにアクセスし、リソースの設定に移動し、VPCまたはRDSインスタンスのリソースポリシーを変更して各アカウントに手動でアクセスを付与します。"
        },
        "Correct Answer": "AWS RAMコンソールに移動し、新しいリソース共有を作成し、共有するリソースを選択し、それにアクセスできるアカウントを指定します。共有が有効になっていることを確認してください。",
        "Explanation": "AWS RAMを使用してリソース共有を作成する正しいアプローチは、AWS RAMコンソールにアクセスすることです。ここで、新しいリソース共有を簡単に作成し、共有したい特定のリソースを選択し、どのアカウントがアクセスできるかを指定できます。共有の有効化も、共有プロセスを有効にするために重要です。",
        "Other Options": [
            "AWS CLIを使用してリソース共有を作成することは可能ですが、より複雑なコマンド構文が必要であり、コンソール内での共有作成において最も簡単な方法ではありません。",
            "VPCまたはRDSインスタンスのリソースポリシーを手動で変更することはAWS RAMを利用せず、マルチアカウント設定でのリソース共有には効果的な方法ではありません。",
            "AWS CloudFormationを使用してリソース共有を作成することは不要です。AWS RAMはコンソールを通じて直接管理できるため、このオプションはタスクに対して必要以上に複雑です。"
        ]
    },
    {
        "Question Number": "8",
        "Situation": "ある金融サービス会社が、機密の顧客データを扱う新しいWebアプリケーションをAWS上に展開しています。彼らは、アプリケーションを複数のアベイラビリティゾーンおよびリージョンに分散させることで、高可用性とフォールトトレランスを確保することを目指しています。DevOpsチームは、ダウンタイムを最小限に抑え、潜在的な障害に対して最大限の回復力を持つソリューションを実装する任務を負っています。",
        "Question": "ダウンタイムを最小限に抑えつつ、アプリケーションが複数のアベイラビリティゾーンおよびリージョンで高可用性を維持するために、次の構成のうちどれが最も適切ですか？",
        "Options": {
            "1": "Amazon ECSを利用して、各リージョンにロードバランサーを配置したマルチリージョン設定でアプリケーションを実行します。Route 53をレイテンシーベースのルーティングで構成し、トラフィックを最寄りのリージョンに誘導して高可用性と迅速なフェイルオーバーを確保します。",
            "2": "AWS Lambdaを使用してアプリケーションを構築し、複数のリージョンに展開します。Amazon API Gatewayを利用して受信リクエストを処理し、適切なLambda関数にルーティングして地理的冗長性を確保します。",
            "3": "アプリケーションを単一のアベイラビリティゾーンに設定し、AWS Global Acceleratorを使用して異なる場所のユーザーに対するパフォーマンスと可用性を向上させ、同じゾーン内に単一のデータベースインスタンスを使用します。",
            "4": "アプリケーションを単一のリージョン内の複数のアベイラビリティゾーンにあるEC2インスタンスに展開します。アプリケーションロードバランサーを使用してインスタンス間でトラフィックを分散させます。オートスケーリングを実装してインスタンスの健康状態とキャパシティを管理します。"
        },
        "Correct Answer": "Amazon ECSを利用して、各リージョンにロードバランサーを配置したマルチリージョン設定でアプリケーションを実行します。Route 53をレイテンシーベースのルーティングで構成し、トラフィックを最寄りのリージョンに誘導して高可用性と迅速なフェイルオーバーを確保します。",
        "Explanation": "Amazon ECSを使用してマルチリージョン設定でアプリケーションを展開することで、1つのリージョンでの障害に対処できる堅牢なアーキテクチャが実現され、トラフィックが自動的に別のリージョンにリダイレクトされます。これによりダウンタイムが最小限に抑えられ、障害時でもアプリケーションが利用可能な状態を維持します。",
        "Other Options": [
            "単一のリージョン内の複数のアベイラビリティゾーンにアプリケーションを展開することは可用性を向上させますが、地理的冗長性を提供しません。リージョン全体がダウンした場合、アプリケーションは利用できなくなります。",
            "複数のリージョンでAWS Lambdaを使用することはある程度の冗長性を提供できますが、状態を持つアプリケーションや継続的な接続を必要とするアプリケーションには効果的ではなく、レイテンシーの増加や地域展開の管理の複雑さを引き起こす可能性があります。",
            "AWS Global Acceleratorを使用して単一のアベイラビリティゾーンにアプリケーションを設定することは高可用性を保証しません。アプリケーションはその単一のアベイラビリティゾーンに依存しているため、失敗した場合、グローバルアクセラレーターがあってもアプリケーションはダウンします。"
        ]
    },
    {
        "Question Number": "9",
        "Situation": "あなたは現在、ネストされたスタックの1つの失敗によりUPDATE_ROLLBACK_FAILED状態にあるAWS CloudFormationスタックを管理しています。この問題を解決し、既存のリソースを失わずに済ませる必要があります。さらに、AWS Lambdaによってバックアップされたカスタムリソースがあり、スタックには操作のための特定の権限が必要です。",
        "Question": "カスタムリソースが正しく動作できるようにしながら、CloudFormationスタックのUPDATE_ROLLBACK_FAILED状態を処理する最良のアプローチは何ですか？",
        "Options": {
            "1": "失敗したリソースのエラーを手動で解決し、その後CloudFormationコンソールを使用してロールバックプロセスを続行します。",
            "2": "ロールバックの問題を回避するために、スタック全体を削除し、最初から再作成します。",
            "3": "CloudFormationスタックにサービスロールを設定して必要な権限を提供し、失敗したリソースに対処せずに更新を再試行します。",
            "4": "ロールバック中に失敗したリソースをスキップし、スタックの残りの部分のロールバックを続行します。"
        },
        "Correct Answer": "失敗したリソースのエラーを手動で解決し、その後CloudFormationコンソールを使用してロールバックプロセスを続行します。",
        "Explanation": "UPDATE_ROLLBACK_FAILED状態を効果的に処理するためには、失敗の原因となったリソースのエラーを手動で解決し、その後CloudFormationコンソールまたはCLIを使用してロールバックプロセスを続行する必要があります。これにより、既存のリソースを失うことなくスタックを安定した状態に戻すことができます。",
        "Other Options": [
            "ロールバック中に失敗したリソースをスキップすることは根本的な問題に対処せず、スタック内のさらなる不整合を引き起こす可能性があります。",
            "失敗したリソースを解決せずにサービスロールを設定することは他の操作を成功させる可能性がありますが、スタックの現在の状態を解決することにはならず、後でさらなる複雑さを引き起こす可能性があります。",
            "スタック全体を削除することは、リソースや現在使用中の構成を失う可能性があるため、推奨される方法ではありません。より良い選択肢がある場合は特に避けるべきです。"
        ]
    },
    {
        "Question Number": "10",
        "Situation": "金融サービス会社は、アプリケーションのスケーラビリティを管理するためにAmazon EC2 Auto Scalingを使用しています。彼らは、アプリケーションの需要に基づいて適切な数のインスタンスが稼働していることを確認したいと考えています。また、会社はAmazon CloudWatchを使用してアプリケーションのパフォーマンスメトリクスを監視しています。彼らは、コストを最小限に抑えながら負荷の変動に応じて反応する効率的なスケーリングポリシーを設定したいと考えています。",
        "Question": "会社はAuto Scalingソリューションを最適化するためにどのような設定手順を踏むべきですか？（2つ選択してください）",
        "Options": {
            "1": "過去の利用メトリクスに基づいて予測スケーリングを有効にする。",
            "2": "コスト効果のないインスタンスタイプを使用するようにAuto Scalingを設定する。",
            "3": "CPU利用率を監視し、スケーリングアクションをトリガーするCloudWatchアラームを作成する。",
            "4": "既知の使用パターンに基づいてスケジュールされたスケーリングアクションを実装する。",
            "5": "クールダウン期間を最小に設定して、より迅速なスケーリングを可能にする。"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "CPU利用率を監視し、スケーリングアクションをトリガーするCloudWatchアラームを作成する。",
            "既知の使用パターンに基づいてスケジュールされたスケーリングアクションを実装する。"
        ],
        "Explanation": "CPU利用率を監視するCloudWatchアラームを作成することで、Auto Scalingグループは負荷の変化に迅速に反応できます。スケジュールされたスケーリングアクションを実装することで、予測可能な使用パターンを活用し、必要なときにリソースが利用可能であることを確保しつつ、コストを効果的に管理できます。",
        "Other Options": [
            "クールダウン期間を最小に設定すると、急速なスケーリングアクションが発生し、不安定さや複数のスケーリングイベントが短期間に発生することによる不必要なコストが生じる可能性があります。",
            "コスト効果のないインスタンスタイプを使用するようにAuto Scalingを設定すると、追加の利益を提供せずに運用コストが増加し、最適化の目標に反することになります。",
            "過去の利用メトリクスに基づいて予測スケーリングを有効にすることは、特にパターンが時間とともに変化する場合、すべてのワークロードのニーズに必ずしも適合しないため、特定のアラームやスケジュールされたアクションを設定するよりも信頼性が低くなります。"
        ]
    },
    {
        "Question Number": "11",
        "Situation": "金融サービス会社は、AWS CloudFormationを使用してクラウドリソースを管理するInfrastructure as Code（IaC）アプローチを採用しています。彼らは、デプロイ前にCloudFormationテンプレートに加えられた変更を追跡し承認するための変更管理プロセスを実装できるソリューションを必要としています。会社は、すべての変更がアーキテクチャチームによってレビューされ承認されることを確保したいと考えています。",
        "Question": "このシナリオでCloudFormationテンプレートの変更管理を最も効果的に促進するアプローチはどれですか？",
        "Options": {
            "1": "AWS Configルールを有効にしてCloudFormationスタックの変更を監視し、すべての更新についてアーキテクチャチームに通知する。",
            "2": "AWS CloudFormation StackSetsを使用して、承認なしで複数のアカウントとリージョンで変更を管理する。",
            "3": "CloudFormationスタックの更新をデプロイする前に手動承認ステップを含むAWS CodePipelineを実装する。",
            "4": "CloudFormationテンプレート用のGitリポジトリを作成し、レビューと承認プロセスのためにプルリクエストを活用する。"
        },
        "Correct Answer": "CloudFormationスタックの更新をデプロイする前に手動承認ステップを含むAWS CodePipelineを実装する。",
        "Explanation": "AWS CodePipelineを使用することで、手動承認ステップを統合した構造化されたデプロイプロセスが可能になり、CloudFormationテンプレートへのすべての変更が適用される前にアーキテクチャチームによってレビューされ承認されることが保証されます。これは、変更管理のベストプラクティスに沿っています。",
        "Other Options": [
            "AWS CloudFormation StackSetsを使用することは、複数のアカウントやリージョンでスタックを管理するのに適していますが、変更のレビューと承認プロセスを内蔵していないため、記載されたシナリオには適していません。",
            "Gitリポジトリを作成し、プルリクエストを活用することはバージョン管理とコラボレーションの良いプラクティスですが、CloudFormationスタックのデプロイプロセスと直接統合されていないため、デプロイに遅延や追加の手動ステップが生じる可能性があります。",
            "AWS Configルールを有効にすることで変更を監視することは可能ですが、承認ワークフローを含む積極的な変更管理プロセスを提供しないため、デプロイ前の承認要件を満たすことができません。"
        ]
    },
    {
        "Question Number": "12",
        "Situation": "ソフトウェア開発チームは、Amazon ECSにデプロイされたアプリケーションのCI/CDプロセスを管理するためにAWS CodePipelineを使用しています。彼らは、デプロイをより効率的に処理するためにAWS CodeDeployを統合したいと考えています。チームは、さまざまなデプロイステージのためにLambda関数を呼び出すフックを使用する計画です。また、パイプライン実行中にAWS Service Catalogに新しいバージョンの製品を検証してプッシュするプロセスを含めたいと考えています。チームは、CodeDeployがCloudFormationスタックを直接デプロイできず、AWS Service CatalogのデプロイアクションがCodeDeployでサポートされていないことを認識しています。",
        "Question": "チームは、CodePipeline実行中にAWS Service Catalogで製品バージョンを検証および更新するソリューションを実装するために何をすべきですか？",
        "Options": {
            "1": "AWS CloudFormationを設定して、CodePipeline実行中にAWS Service Catalogへの更新を自動化する。",
            "2": "AWS Service Catalog APIを呼び出し、製品バージョンを管理するためにLambda関数をCodePipelineアクションとして追加する。",
            "3": "製品バージョン管理のためにAWS Service Catalog APIを呼び出すCodeDeployデプロイフックを使用する。",
            "4": "AWS Service Catalogにプッシュする前に製品バージョンを検証するためにパイプラインに手動承認ステップを作成する。"
        },
        "Correct Answer": "AWS Service Catalog APIを呼び出し、製品バージョンを管理するためにLambda関数をCodePipelineアクションとして追加する。",
        "Explanation": "CodePipelineのアクションとしてLambda関数を追加することで、チームはAWS Service Catalog APIを呼び出して、CI/CDワークフローの一部として新しい製品バージョンを効果的に検証しプッシュできます。",
        "Other Options": [
            "CodeDeployデプロイフックを使用することはここでは適用されません。なぜなら、CodeDeployはAWS Service Catalogのデプロイアクションをサポートしておらず、フックはこの要件には適していないからです。",
            "このタスクのためにAWS CloudFormationを設定することは実現不可能です。なぜなら、CodeDeployはCloudFormationスタックをデプロイできないため、このオプションは無効です。",
            "手動承認ステップを作成することは、製品バージョンを検証してプッシュするプロセスを自動化せず、デプロイパイプラインの効率化というチームの目標に反します。"
        ]
    },
    {
        "Question Number": "13",
        "Situation": "ある組織がAWS CloudFormationを使用してインフラストラクチャをコードとして管理しています。チームは、異なる環境に簡単にカスタマイズできる再利用可能なテンプレートを作成したいと考えていますが、コードの重複は避けたいと考えています。また、特定の条件下でのみリソースが作成されることを保証し、異なるスタック間で出力を共有する必要があります。",
        "Question": "再利用性、条件付きリソース作成、およびスタック間の出力共有の目標を達成するために、AWS CloudFormationのどの機能の組み合わせが最も適しているでしょうか？",
        "Options": {
            "1": "内蔵関数を利用してスタック間でリソースを直接参照し、シンプルさのためにすべての値をハードコーディングし、複雑さを最小限に抑えるためにパラメータの使用を避ける。",
            "2": "ネストスタックを活用して共通リソースをカプセル化し、擬似パラメータを使用してアカウントIDなどの値を動的に取得し、親スタックと子スタック間でリソースを共有するための出力を定義する。",
            "3": "異なる環境向けにテンプレートをカスタマイズするためにパラメータを使用し、スタック間で重要なリソース情報を共有するための出力を定義し、入力値に基づいてリソース作成を制御するために条件を利用する。",
            "4": "各環境のために別々のCloudFormationテンプレートを作成し、テンプレートに値をハードコーディングし、条件なしでリソースの静的値を定義するためにマッピングを使用する。"
        },
        "Correct Answer": "異なる環境向けにテンプレートをカスタマイズするためにパラメータを使用し、スタック間で重要なリソース情報を共有するための出力を定義し、入力値に基づいてリソース作成を制御するために条件を利用する。",
        "Explanation": "このオプションは、カスタマイズのためのパラメータの使用、スタック間での情報共有のための出力、リソース作成を管理するための条件を効果的に組み合わせており、CloudFormationテンプレートにおける再利用性とモジュール性の要件に完全に一致しています。",
        "Other Options": [
            "このオプションは、各環境のために別々のテンプレートを作成することを提案しており、再利用性の目標に矛盾しています。値をハードコーディングすることは柔軟性を制限し、メンテナンスをより困難にします。また、マッピングは必要な動的カスタマイズを提供しません。",
            "ネストスタックを活用することは再利用性を促進する可能性がありますが、このオプションは、テンプレートをカスタマイズし、特定の基準に基づいてリソース作成を制御するために必要なパラメータと条件の必要性を見落としています。",
            "このオプションは、パラメータを避けて値をハードコーディングすることを誤って提案しており、CloudFormationテンプレートの柔軟性と保守性を大幅に低下させます。さらに、内蔵関数はスタック間でリソースを共有する際に出力の必要性を置き換えることはできません。"
        ]
    },
    {
        "Question Number": "14",
        "Situation": "あるソフトウェア会社が、コンテナ化を使用してレガシーアプリケーションをAWSに移行しています。このアプリケーションは、非常に可用性が高く、回復力のある方法でデプロイする必要がある複数のマイクロサービスで構成されています。会社は、オーケストレーションにAmazon ECSを利用し、サービスが自動的に障害から回復できるようにしたいと考えています。DevOpsエンジニアとして、これらの要件を満たすソリューションを設計する必要があります。",
        "Question": "Amazon ECSにデプロイされたコンテナ化されたマイクロサービスが回復力を持ち、障害から自動的に回復できるようにするために、どのアプローチを取るべきでしょうか？",
        "Options": {
            "1": "Amazon EKSを使用してマイクロサービスを自己修復機能を有効にしてデプロイします。Kubernetes Horizontal Pod Autoscalerを設定して、CPU使用率メトリクスに基づいてポッドの数を管理します。",
            "2": "各サービスの前にApplication Load Balancerを配置してAmazon ECSにマイクロサービスをデプロイします。ヘルスチェックを設定して、健康なタスクのみにトラフィックを向け、各サービスの希望数を最大期待負荷に設定します。",
            "3": "EC2起動タイプでAmazon ECSにマイクロサービスをデプロイします。Auto Scalingグループを使用してインスタンスを管理し、サービスが互いに見つけられるようにサービス発見メカニズムを持つタスク定義を設定します。",
            "4": "Fargate起動タイプでAmazon ECSにマイクロサービスを実行します。ロールアップデートのために最小健康パーセントを100、最大パーセントを200に設定して、デプロイ中にダウンタイムが発生しないようにします。"
        },
        "Correct Answer": "各サービスの前にApplication Load Balancerを配置してAmazon ECSにマイクロサービスをデプロイします。ヘルスチェックを設定して、健康なタスクのみにトラフィックを向け、各サービスの希望数を最大期待負荷に設定します。",
        "Explanation": "Amazon ECSにApplication Load Balancerを配置してマイクロサービスをデプロイすることで、トラフィック管理が向上し、健康なタスクのみにトラフィックが送信されることが保証されます。ヘルスチェックは、健康でないタスクを自動的に置き換えるのに役立ち、回復力を提供します。希望数を最大期待負荷に設定することで、トラフィックの急増に対応するための十分なキャパシティが確保されます。",
        "Other Options": [
            "Fargateで最小健康パーセントを100に設定すると、デプロイ中にタスクを停止できないため、リソースの枯渇や更新の効果的なデプロイの失敗につながる可能性があります。",
            "EC2起動タイプでAuto Scalingグループを使用することは有効なアプローチですが、管理オーバーヘッドが増加します。タスク定義は適切に設定する必要があり、サービス発見メカニズムは複雑さを加える可能性がありますが、回復力を大幅に向上させることはありません。",
            "Amazon EKSを使用すると自己修復機能が提供されますが、このシナリオには不必要な複雑さをもたらす可能性があります。Application Load Balancerを使用したECSは、回復力と自動回復の要件を満たすよりシンプルなソリューションです。"
        ]
    },
    {
        "Question Number": "15",
        "Situation": "DevOpsエンジニアがAWS上のマイクロサービスアーキテクチャのデプロイ自動化を設定する任務を負っています。会社はAWS CodeDeployを使用してアプリケーションのデプロイを管理しています。エンジニアは、複数のEC2インスタンス間でシームレスなアプリケーション更新を促進するために、デプロイエージェントが正しく構成されていることを確認する必要があります。",
        "Question": "AWS CodeDeployのデプロイエージェントを構成するために、エンジニアはどのアクションの組み合わせを取るべきでしょうか？（2つ選択）",
        "Options": {
            "1": "CodeDeployエージェントインストールスクリプトを含むCloudFormationテンプレートを作成し、関連するすべてのEC2インスタンスにデプロイします。",
            "2": "各EC2インスタンスでサービスとしてCodeDeployエージェントを実行するように設定し、インスタンス起動時に自動的に開始されるようにします。",
            "3": "デプロイグループの一部となるすべてのEC2インスタンスに最新バージョンのCodeDeployエージェントをインストールします。",
            "4": "各デプロイ後に各EC2インスタンスでCodeDeployエージェントを手動で更新して互換性を確保します。",
            "5": "AWS Systems Managerを使用して、デプロイグループ内のすべてのEC2インスタンスにわたってCodeDeployエージェントのインストールと構成を自動化します。"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "デプロイグループの一部となるすべてのEC2インスタンスに最新バージョンのCodeDeployエージェントをインストールします。",
            "AWS Systems Managerを使用して、デプロイグループ内のすべてのEC2インスタンスにわたってCodeDeployエージェントのインストールと構成を自動化します。"
        ],
        "Explanation": "すべてのEC2インスタンスにCodeDeployエージェントをインストールすることで、各インスタンスがデプロイを受け取り、実行できるようになります。AWS Systems Managerを使用してこのプロセスを自動化することで、効率が向上し、特に大規模な環境において人的エラーの可能性が減少します。",
        "Other Options": [
            "CloudFormationテンプレートを作成することは良いプラクティスですが、エージェントを手動でインストールする場合は必要ありません。さらに、すべてのインスタンスに最新バージョンのエージェントがインストールされることを保証しません。",
            "CodeDeployエージェントをサービスとして実行するように設定することは重要ですが、最初にすべてのインスタンスにエージェントが正しくインストールされる必要性には対処していません。",
            "CodeDeployエージェントを手動で更新することはスケーラブルなソリューションではなく、特に多数のEC2インスタンスがある環境では運用オーバーヘッドが増加します。"
        ]
    },
    {
        "Question Number": "16",
        "Situation": "ある企業が重要なEC2インスタンスのバックアップ戦略を実施しています。彼らは、バックアップを簡単に識別できるようにタグ付けし、これらのスナップショットの保持を効率的に管理する信頼性の高いスナップショットシステムを作成したいと考えています。DevOpsエンジニアは、スナップショットが定期的に作成され、期限切れのスナップショットが自動的に削除されることを確認し、データを失わないようにする必要があります。次のうち、最も効果的な解決策はどれですか？",
        "Question": "DevOpsエンジニアは、EC2インスタンスの効率的なスナップショット管理とデータ復旧を確保するためにどのアプローチを使用すべきですか？",
        "Options": {
            "1": "AWS Backupを利用して、EC2インスタンスのスナップショットを毎時、毎日、毎週スケジュールするバックアッププランを作成します。バックアップタグを活用してこれらのバックアップの保持を管理し、期限切れのスナップショットを自動的に削除します。",
            "2": "EC2インスタンス上にcronジョブを作成し、AWS CLIを使用して他のインスタンスのスナップショットを定期的に作成し、関連するメタデータで手動でこれらのスナップショットにタグを付けます。古いスナップショットを削除するための別のスクリプトを実装します。",
            "3": "定期的にトリガーされるLambda関数を実装し、EC2インスタンスのスナップショットを作成し、'retain until'や'instanceId'などのカスタムメタデータでタグを付けます。同じ関数を使用して、期限切れのタグに基づいてスナップショットを削除します。",
            "4": "EC2インスタンスをプロビジョニングするCloudFormationテンプレートを設定し、組み込みのスナップショットポリシーを持たせます。これらのポリシーを構成して、スナップショットに自動的にタグを付け、定義された保持戦略に基づいてライフサイクルを管理します。"
        },
        "Correct Answer": "定期的にトリガーされるLambda関数を実装し、EC2インスタンスのスナップショットを作成し、'retain until'や'instanceId'などのカスタムメタデータでタグを付けます。同じ関数を使用して、期限切れのタグに基づいてスナップショットを削除します。",
        "Explanation": "Lambda関数を使用することで、スナップショットの作成と削除を管理する自動化されたサーバーレスソリューションを提供します。タグ付けの柔軟性を持ち、手動介入なしで必要な期間だけスナップショットを保持することができます。",
        "Other Options": [
            "スナップショットポリシーのためのCloudFormationテンプレートを設定することは複雑であり、Lambda関数と同じレベルの自動化と柔軟性を提供しない可能性があります。また、より多くの管理オーバーヘッドが必要です。",
            "AWS Backupはバックアップ管理のための堅牢なソリューションを提供しますが、よりシンプルなLambdaソリューションが要件を満たす場合、追加のコストと複雑さをもたらす可能性があります。",
            "EC2インスタンス上でcronジョブを使用すると、スナップショットの管理がそのインスタンスの稼働時間に依存し、信頼性の問題を引き起こす可能性があります。このアプローチは、サーバーレスソリューションに比べて手動であり、効率が低くなります。"
        ]
    },
    {
        "Question Number": "17",
        "Situation": "ある企業がデータベースのワークロードをAWSに移行しており、MySQL互換のアプリケーションにAmazon Auroraを使用することを検討しています。DevOpsエンジニアは、パフォーマンスを最適化しながらデータの耐久性、可用性、およびセキュリティを確保する必要があります。",
        "Question": "これらの要件を最もよくサポートするAmazon Auroraの機能はどれですか？（2つ選択）",
        "Options": {
            "1": "ユーザーが開始するスナップショットがS3に保存され、数秒以内に復元可能です。",
            "2": "コストを削減するために、単一のアベイラビリティゾーンに1つのバックアップコピーのみが維持されます。",
            "3": "データストレージは耐障害性があり、自己修復機能を持ち、データ損失を透過的に処理します。",
            "4": "データベースのパフォーマンスに影響を与えない自動、継続的、増分バックアップ。",
            "5": "最小限のダウンタイムで最大15のレプリカのいずれかに自動フェイルオーバーします。"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "最小限のダウンタイムで最大15のレプリカのいずれかに自動フェイルオーバーします。",
            "データベースのパフォーマンスに影響を与えない自動、継続的、増分バックアップ。"
        ],
        "Explanation": "Amazon Auroraはレプリカへの自動フェイルオーバーを提供し、停電時の高可用性と最小限のダウンタイムを実現します。さらに、自動、継続的、増分バックアップにより、データが一貫してバックアップされ、データベースのパフォーマンスに影響を与えないため、運用効率を維持するために重要です。",
        "Other Options": [
            "このオプションは不正確です。Auroraは異なるアベイラビリティゾーンに複数のバックアップコピーを維持しており、単一のゾーンに1つだけではありません。これにより、耐久性と可用性が向上します。",
            "このオプションは不正確です。スナップショット機能を説明していますが、Auroraが提供するバックアップの自動化された性質を強調していません。これは運用の継続性にとって重要です。",
            "このオプションは誤解を招く可能性があります。Auroraは自己修復機能を提供しますが、データの可用性とパフォーマンスを確保するために最も重要なのは、自動フェイルオーバーと継続的バックアップの組み合わせです。"
        ]
    },
    {
        "Question Number": "18",
        "Situation": "ある企業がAmazon EC2インスタンス上で高トラフィックのWebアプリケーションを実行しており、アプリケーションロードバランサー（ALB）の背後にあります。DevOpsチームは、アプリケーションのパフォーマンスを監視し、リアルタイムで潜在的な問題を特定する必要があります。彼らは特に、アプリケーションエラーや全体的なシステムの健康に関連するメトリクスを追跡し、発生する可能性のある問題に迅速に対応できるようにしたいと考えています。",
        "Question": "DevOpsチームがALBのアプリケーションエラーとシステムの健康を効果的に追跡するために監視すべきCloudWatchメトリクスはどれですか？",
        "Options": {
            "1": "CPUUtilization",
            "2": "ApproximateNumberOfMessagesDelayed",
            "3": "NetworkIn",
            "4": "HTTPCode_ELB_5XX_Count"
        },
        "Correct Answer": "HTTPCode_ELB_5XX_Count",
        "Explanation": "HTTPCode_ELB_5XX_Countは、アプリケーションロードバランサーによって返される5xxサーバーエラーの数を追跡するために特別に設計されたCloudWatchメトリクスです。このメトリクスを監視することで、チームはサーバーエラーを引き起こしている可能性のあるアプリケーションの問題を特定し、根本的な問題を迅速に解決することができます。",
        "Other Options": [
            "CPUUtilizationはEC2インスタンスが使用しているCPU容量の割合を測定しますが、ALBに関連するアプリケーションエラーや健康状態を直接示すものではありません。",
            "ApproximateNumberOfMessagesDelayedはAmazon SQSで使用されるメトリクスであり、ALBのアプリケーションパフォーマンスやエラーの監視には関係ありません。",
            "NetworkInはEC2インスタンスへの受信ネットワークトラフィックの量を追跡しますが、負荷を理解するのに役立つものの、アプリケーションエラーや全体的な健康状態に関する洞察を提供するものではありません。"
        ]
    },
    {
        "Question Number": "19",
        "Situation": "金融サービス会社は、AWSにいくつかのアプリケーションを展開しています。コンプライアンスとセキュリティのベストプラクティスを確保するために、同社はAWS Configルールを設定して、非準拠のリソースを自動的に修正したいと考えています。DevOpsチームは、これらの非準拠リソースを特定するだけでなく、手動介入なしでコンプライアンスに戻すための是正措置を講じるソリューションを実装する必要があります。",
        "Question": "次のうち、AWS Configにおける非準拠リソースの最も効果的な自動修正を提供する構成はどれですか？",
        "Options": {
            "1": "非準拠が検出されたときに新しいリソースを展開するためにAWS CloudFormation StackSetsを使用するAWS Configルールを設定し、すべてのリソースが再プロビジョニングされるようにします。",
            "2": "非準拠のリソースが検出されたときにDevOpsチームにAmazon SNSを介して通知するAWS Configルールを設定し、手動で問題を修正できるようにします。",
            "3": "AWS Systems Manager Automationドキュメントに定義された是正措置を持つAWS Configルールを作成して、非準拠リソースを自動的に修正します。",
            "4": "非準拠リソースをAmazon S3バケットに記録するAWS Lambda関数をトリガーするAWS Configルールを実装し、後で分析と手動修正を行います。"
        },
        "Correct Answer": "AWS Systems Manager Automationドキュメントに定義された是正措置を持つAWS Configルールを作成して、非準拠リソースを自動的に修正します。",
        "Explanation": "AWS Systems Manager Automationドキュメントに定義された是正措置を持つAWS Configルールを作成することで、非準拠の即時かつ自動的な修正が可能になり、手動介入なしでリソースが継続的にコンプライアンスを維持できるようになります。",
        "Other Options": [
            "AWS Configルールを設定してDevOpsチームにAmazon SNSを介して通知することは自動修正を提供せず、手動介入が必要であり、これは自動化の目的に反します。",
            "非準拠リソースをAmazon S3バケットに記録するAWS Lambda関数をトリガーするAWS Configルールを実装することは、後で分析のために問題をキャプチャするだけで、是正措置を講じることはありません。",
            "AWS CloudFormation StackSetsを使用してリソースを再プロビジョニングするAWS Configルールを設定することは、修正の実行可能なソリューションではなく、リソースのダウンタイムを引き起こす可能性があり、既存リソースの非準拠に直接対処するものではありません。"
        ]
    },
    {
        "Question Number": "20",
        "Situation": "ある会社はAWS上にマイクロサービスアーキテクチャを展開しており、監視のためにAmazon CloudWatchを使用しています。DevOpsエンジニアは、パフォーマンスのボトルネックやエラーレートを特定するために、マイクロサービスによって生成されたログデータを分析する必要があります。エンジニアは特に、特定の基準に基づいてログを迅速にフィルタリングできるクエリを実行するためにCloudWatch Logs Insightsを使用することに興味を持っています。",
        "Question": "DevOpsエンジニアが'service-logs'ロググループ内の'タイムアウト'という単語を含むすべてのエラーメッセージを見つけるために使用すべきCloudWatch Logs Insightsクエリはどれですか？",
        "Options": {
            "1": "fields @timestamp, @message | filter @logStream = 'service-logs' and @message like 'timeout' | sort @timestamp desc | limit 20",
            "2": "fields @timestamp, @message | filter @logGroup = 'service-logs' and @message like 'timeout' | sort @timestamp desc | limit 20",
            "3": "fields @timestamp, @message | filter @logStream like 'service-logs' and @message = 'timeout' | sort @timestamp desc | limit 20",
            "4": "fields @timestamp, @message | filter @logGroup = 'service-logs' and @message = 'timeout' | sort @timestamp asc | limit 20"
        },
        "Correct Answer": "fields @timestamp, @message | filter @logGroup = 'service-logs' and @message like 'timeout' | sort @timestamp desc | limit 20",
        "Explanation": "正しいクエリは、ロググループ'service-logs'に基づいてログをフィルタリングするための適切な構文を使用し、'タイムアウト'という単語を含むメッセージを特定します。また、結果をタイムスタンプの降順でソートし、最近のエラーを分析するのに適しています。",
        "Other Options": [
            "このオプションは、@logStreamの代わりに@logGroupを誤って使用しており、指定されたロググループから結果を得ることができません。また、メッセージをフィルタリングするために不正な演算子'='を使用しています。",
            "このオプションは、'like'の代わりに'='を誤って使用しており、'タイムアウト'という単語を含むメッセージを見つけることができず、正確な一致を探してしまいます。",
            "このオプションは、@logStreamに対して'like'を誤って使用しており、無効であり、ログを返しません。さらに、'タイムアウト'に対して部分一致ではなく正確な一致を使用しています。"
        ]
    },
    {
        "Question Number": "21",
        "Situation": "金融サービス会社は、インフラをAWSに移行しており、リソースを効率的に管理およびプロビジョニングするためにInfrastructure as Code (IaC)を実装したいと考えています。チームは、インフラ全体の展開を繰り返し可能でバージョン管理された方法で自動化できるように、さまざまなツールを評価しています。彼らは特に、AWSサービスとよく統合され、モジュラー構成をサポートするツールに興味を持っています。",
        "Question": "次のうち、AWS上でのInfrastructure as Codeに対する会社の要件を最もよくサポートするツールはどれですか？",
        "Options": {
            "1": "Terraformは、IaCに対するプラットフォームに依存しないアプローチを提供し、チームがHCL言語を使用してAWSリソースを管理できるようにしますが、AWSサービスとの統合はそれほどシームレスではありません。",
            "2": "AWS OpsWorksは、ChefまたはPuppetを使用した構成管理を提供しますが、AWSリソースを直接定義するための堅牢なIaCソリューションを提供しません。",
            "3": "AWS CloudFormationは、チームがJSONまたはYAMLテンプレートを使用してインフラをコードとして定義できるようにし、バージョン管理と簡単な複製を可能にします。",
            "4": "AWS CDKは、開発者が親しみのあるプログラミング言語を使用してクラウドインフラを定義できるようにし、より高い抽象レベルを提供しますが、学習曲線が急になる可能性があります。"
        },
        "Correct Answer": "AWS CloudFormationは、チームがJSONまたはYAMLテンプレートを使用してインフラをコードとして定義できるようにし、バージョン管理と簡単な複製を可能にします。",
        "Explanation": "AWS CloudFormationは、AWSリソースをコードとして管理するために特別に設計されています。チームは宣言型テンプレートを使用してAWSリソースを作成、更新、管理でき、インフラがバージョン管理され、簡単に複製できることを保証します。これは、会社の信頼できるIaCソリューションの要件に完全に一致します。",
        "Other Options": [
            "Terraformはプラットフォームに依存しない強力なIaCソリューションを提供しますが、AWS CloudFormationと比較してAWSサービスとの統合はそれほどシームレスではありません。",
            "AWS OpsWorksはアプリケーションの構成管理に重点を置いており、CloudFormationやTerraformと同じレベルのインフラプロビジョニング機能を提供しないため、会社のニーズにはあまり適していません。",
            "AWS CDKはプログラミング言語を使用してインフラを定義することを可能にしますが、開発者にとっては有益かもしれませんが、チームの目標には必要ない複雑さや学習曲線をもたらす可能性があります。"
        ]
    },
    {
        "Question Number": "22",
        "Situation": "ある金融サービス会社がAWS Elastic Beanstalkを使用してウェブアプリケーションをデプロイしています。彼らはアプリケーションの新しいバージョンをリリースする準備をしており、デプロイ中のダウンタイムとリスクを最小限に抑えたいと考えています。DevOpsチームは、スムーズな移行を確保するためにさまざまなデプロイ戦略を検討しています。彼らは、新しいバージョンへのトラフィックを徐々にシフトさせる一方で、問題が発生した場合に迅速にロールバックできる能力を確保したいと考えています。",
        "Question": "ロールバックが必要な場合に現在のバージョンを維持しながら新しいバージョンをデプロイできる、AWS Elastic Beanstalkにおける最も適切なデプロイ戦略は何ですか？",
        "Options": {
            "1": "新しいバージョンをグリーン/ブルーのデプロイメント戦略を使用してデプロイし、新しいバージョンのための並行環境を作成し、徹底的なテストの後にのみトラフィックを切り替えます。",
            "2": "追加バッチを使用したローリングアップデートで、環境内のインスタンスを徐々に置き換え、パフォーマンスを監視できるスムーズな移行を可能にします。",
            "3": "新しいインスタンスを別の環境で起動する不変デプロイメント戦略を実装し、新しい環境が安定していることが確認されたらCNAMEを切り替えてトラフィックを新しい環境に向けます。",
            "4": "トラフィックスプリッティング手法を使用して、ユーザーリクエストの一部を新しいバージョンに送信し、残りの大部分は古いバージョンを使用し続けることで、リアルタイムのパフォーマンス評価を可能にします。"
        },
        "Correct Answer": "新しいインスタンスを別の環境で起動する不変デプロイメント戦略を実装し、新しい環境が安定していることが確認されたらCNAMEを切り替えてトラフィックを新しい環境に向けます。",
        "Explanation": "不変デプロイメント戦略は、新しいインスタンスが新しい環境で作成されることを保証し、既存のアプリケーションに影響を与えるリスクを最小限に抑えます。新しいバージョンが安定していることが確認されたら、CNAMEを切り替えることでダウンタイムなしで迅速かつスムーズな移行が可能になり、必要に応じて簡単にロールバックできます。",
        "Other Options": [
            "追加バッチを使用したローリングアップデートは、インスタンスが徐々に置き換えられるためリスクを伴う可能性があり、問題が発生した場合、ロールバックプロセスがより複雑で時間がかかることがあります。",
            "新しいバージョンをグリーン/ブルー戦略を使用してデプロイすることも良い選択肢ですが、移行が確認されるまで二つの別々の環境を同時に維持する必要があるため、リソースを多く消費します。",
            "トラフィックスプリッティングは新しいバージョンへの徐々の露出を可能にしますが、不変デプロイメントほどの隔離レベルを提供しないため、重大な問題が発生した場合のロールバックが難しくなります。"
        ]
    },
    {
        "Question Number": "23",
        "Situation": "ある会社がAmazon SQSを使用してマイクロサービス間のメッセージキューイングを管理しています。彼らには、メッセージの可視性を変更する能力、キュー属性を設定すること、効率的なメッセージ取得を確保することなど、いくつかの要件があります。DevOpsエンジニアは、これらの要件を満たしつつ、コスト効率とパフォーマンスを確保するためにSQSの設定を最適化する任務を負っています。",
        "Question": "DevOpsエンジニアが提供された要件に基づいてメッセージ処理と可視性を最適化するために使用すべきSQSアクションの組み合わせはどれですか？",
        "Options": {
            "1": "メッセージの可視性タイムアウトを12時間に変更し、受信メッセージの待機時間を20秒に設定し、処理後にメッセージを即座に削除します。",
            "2": "ロングポーリングのためのキュー属性を設定し、メッセージの可視性タイムアウトを最大12時間に変更し、消費後にメッセージが削除されることを確保します。",
            "3": "ショートポーリングを有効にするためにキュー属性を設定し、メッセージの可視性タイムアウトを1時間に変更し、非ゼロの遅延でメッセージを送信します。",
            "4": "特定のIAMロールがメッセージを送信できるようにadd-permissionアクションを使用し、ロングポーリングのためにキュー属性を設定し、遅延パラメータをゼロに設定してメッセージを送信します。"
        },
        "Correct Answer": "ロングポーリングのためのキュー属性を設定し、メッセージの可視性タイムアウトを最大12時間に変更し、消費後にメッセージが削除されることを確保します。",
        "Explanation": "このオプションは、SQSのベストプラクティスに正しく沿っており、ロングポーリングを利用してCPU使用率を減少させ、拡張されたメッセージ可視性タイムアウトを許可し、処理後にメッセージが迅速に削除されることを確保し、パフォーマンスとコストの両方を最適化します。",
        "Other Options": [
            "このオプションは、処理後にメッセージを即座に削除することを提案しており、正しく処理されない場合にメッセージの損失を引き起こす可能性があります。さらに、ロングポーリングの設定なしで可視性タイムアウトを12時間に設定することは、リソース使用を効果的に最適化しない可能性があります。",
            "このオプションは、権限と遅延設定に焦点を当てていますが、可視性タイムアウトとメッセージ削除プロセスを十分に扱っておらず、効率的なSQSメッセージ処理には重要です。",
            "このオプションはショートポーリングを有効にすることを提案していますが、コストの増加や非効率的なメッセージ取得を引き起こす可能性があるため最適ではありません。可視性タイムアウトも1時間に設定されており、最大要件を満たしていません。"
        ]
    },
    {
        "Question Number": "24",
        "Situation": "ある会社がAWS環境をレビューして、セキュリティのベストプラクティスに準拠していることを確認しています。彼らは、公開されたAWSアクセスキー、S3バケットの公開アクセス、および不安定なウェブトラフィックなど、クラウドセキュリティの脅威に関連する潜在的な脆弱性に気づきました。DevOpsチームは、全体的なセキュリティ姿勢を強化するために、これらの脅威を特定し、修正する任務を負っています。",
        "Question": "DevOpsチームがAWS環境における最も重要なクラウドセキュリティの脅威に対処するために優先すべき行動はどれですか？",
        "Options": {
            "1": "すべてのアプリケーションにAWS Identity and Access Management (IAM)ロールを実装し、コード内でAWSアクセスキーの使用を避けます。",
            "2": "すべてのS3バケットがプライベートであり、公開アクセスを許可しないことを確認するためにAWS Configルールを設定します。",
            "3": "S3バケットのバージョン管理とロギングを有効にして、バケットに保存された機密データへのアクセスを監視します。",
            "4": "AWS Shieldを使用してDDoS攻撃から保護し、すべてのウェブトラフィックがCloudFrontを通じてルーティングされることを確保します。"
        },
        "Correct Answer": "すべてのアプリケーションにAWS Identity and Access Management (IAM)ロールを実装し、コード内でAWSアクセスキーの使用を避けます。",
        "Explanation": "公開されたAWSアクセスキーは、無許可のアクセスや潜在的なデータ侵害を引き起こす重大なセキュリティリスクです。IAMロールを実装することで、アプリケーションはコード内に機密のアクセスキーを埋め込むことなく、必要なAWSリソースに安全にアクセスできるようになり、露出のリスクを減少させます。",
        "Other Options": [
            "S3バケットのバージョン管理とロギングを有効にすることは監視のための良いプラクティスですが、公開されたアクセスキーによって引き起こされる即時のリスクには直接対処していません。これはAWS環境内での無許可の行動につながる可能性があります。",
            "DDoS攻撃から保護するためにAWS Shieldを使用することは有益ですが、アクセスキーの不安定さや公開S3バケットアクセスに関連するリスクを軽減するものではなく、これらはセキュリティコンプライアンスにとってより緊急の懸念です。",
            "S3バケットがプライベートであることを確認するためにAWS Configルールを設定することは重要ですが、公開されたAWSアクセスキーに対処することがより直接的なリスク軽減を提供します。アクセスキーはS3アクセスだけでなく、より広範なセキュリティ脆弱性につながる可能性があります。"
        ]
    },
    {
        "Question Number": "25",
        "Situation": "DevOpsチームは、LinuxおよびWindowsインスタンスを含む複数のリージョンにわたる大規模なEC2インスタンスの管理を担当しています。彼らは、SSHアクセスやバスティオンホストに依存せずに、パッチ適用や一般的なメンテナンスタスクを効率的に自動化できるソリューションを実装したいと考えています。",
        "Question": "これらの要件を満たすために、チームはどのAWS Systems Managerの機能の組み合わせを利用すべきですか？（2つ選択してください）",
        "Options": {
            "1": "SSM Automationを利用して、インスタンスの再起動やパッチ適用などの定期的なタスクのワークフローを作成します。",
            "2": "Resource Groupsを活用して、タグに基づいてインスタンスを整理し、管理を容易にします。",
            "3": "SSM Run Commandを使用して、EC2インスタンス上でスクリプトを実行し、パッチ適用やメンテナンスタスクを行います。",
            "4": "SSM Session Managerを実装して、SSHを必要とせずにインタラクティブなシェルセッションを確立します。",
            "5": "必要に応じてEC2インスタンスで手動更新をトリガーするLambda関数を作成します。"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "SSM Run Commandを使用して、EC2インスタンス上でスクリプトを実行し、パッチ適用やメンテナンスタスクを行います。",
            "SSM Automationを利用して、インスタンスの再起動やパッチ適用などの定期的なタスクのワークフローを作成します。"
        ],
        "Explanation": "SSM Run CommandはEC2インスタンス上でスクリプトを実行することを可能にし、パッチ適用やメンテナンスタスクに最適です。SSM Automationはこれらのタスクのワークフローを作成する方法を提供し、チームが手動介入なしで操作を自動化できるようにします。",
        "Other Options": [
            "Resource Groupsを活用することでインスタンスを整理することはできますが、パッチ適用やメンテナンスタスクを直接自動化するものではありません。",
            "SSM Session Managerはインタラクティブなシェルセッションを可能にしますが、パッチ適用やメンテナンスタスクを直接自動化するものではありません。",
            "手動更新のためにLambda関数を作成することは、特に自動化やリモート管理のために設計されたSSM機能を使用するよりも効率的ではありません。"
        ]
    },
    {
        "Question Number": "26",
        "Situation": "DevOpsチームは、AWS OpsWorksにデプロイされた複数のアプリケーションを管理しています。彼らは高可用性を確保するためにインスタンスの自動回復を設定しました。しかし、特定の条件下で自動的に回復しないインスタンスがあり、彼らは自動回復の設定が効果的であることを確認し、その限界を理解したいと考えています。",
        "Question": "AWS OpsWorksの自動回復機能に関して、次のうちどの文が正しいですか？",
        "Options": {
            "1": "OpsWorksは、自動回復プロセス中に必要に応じてインスタンスのオペレーティングシステムを自動的にアップグレードします。",
            "2": "OpsWorksは、手動介入なしで深刻な破損や起動失敗エラーのあるインスタンスを回復できます。",
            "3": "OpsWorksの自動回復プロセスは、主にピーク負荷時のパフォーマンスを向上させるために設計されています。",
            "4": "OpsWorksが5分以上通信を失った場合、インスタンスは不健康と見なされ、自動回復プロセスがトリガーされます。"
        },
        "Correct Answer": "OpsWorksが5分以上通信を失った場合、インスタンスは不健康と見なされ、自動回復プロセスがトリガーされます。",
        "Explanation": "OpsWorksがインスタンスとの通信を5分以上失った場合、そのインスタンスは不健康と見なされ、自動回復プロセスが開始され、アプリケーションの可用性が確保されます。",
        "Other Options": [
            "この文は誤りです。OpsWorksは自動回復プロセス中にインスタンスのオペレーティングシステムを自動的にアップグレードしません。OSのアップグレードには手動介入が必要です。",
            "この文は誤りです。OpsWorksは、深刻な破損や起動失敗エラーのあるインスタンスを手動介入なしで回復することはできません。これらの問題には異なるトラブルシューティングアプローチが必要です。",
            "この文は誤りです。自動回復プロセスはパフォーマンスを向上させるために設計されているのではなく、不健康なインスタンスから回復するための障害応答メカニズムです。"
        ]
    },
    {
        "Question Number": "27",
        "Situation": "ソフトウェア開発チームは、AWSにデプロイされる新しいアプリケーションに取り組んでいます。彼らはビルド、テスト、デプロイプロセスを自動化するためにCI/CDパイプラインを実装しています。チームは、ビルドプロセス中に生成されたすべてのアーティファクトが安全に保存され、そのライフサイクル全体で管理できることを確認する必要があります。目標は、内部ポリシーに準拠しつつ、効率とコストを最適化することです。彼らはこれらのアーティファクトを管理するためにさまざまなAWSサービスを検討しています。",
        "Question": "コンプライアンスとコスト最適化を確保しながら、アーティファクトライフサイクルを効果的に管理するために、DevOpsエンジニアはどの戦略を推奨すべきですか？",
        "Options": {
            "1": "AWS CodeCommitを利用してすべてのビルドアーティファクトを保存し、内部ポリシーに準拠するために静止データの暗号化を有効にします。",
            "2": "AWS Systems Manager Parameter Storeを活用してビルドアーティファクトを保存し、パラメータのバージョン管理を使用して時間の経過に伴う変更を追跡します。",
            "3": "バージョン管理を有効にしたAmazon S3を使用してビルドアーティファクトを保存し、ライフサイクルポリシーを実装して古いアーティファクトをS3 Glacierに移行し、コストを削減します。",
            "4": "Dockerイメージを保存するためにAWS Elastic Container Registry (ECR)を実装し、デプロイ前に脆弱性を特定するためにイメージスキャンを設定します。"
        },
        "Correct Answer": "バージョン管理を有効にしたAmazon S3を使用してビルドアーティファクトを保存し、ライフサイクルポリシーを実装して古いアーティファクトをS3 Glacierに移行し、コストを削減します。",
        "Explanation": "バージョン管理を有効にしたAmazon S3を使用することで、ビルドアーティファクトを安全に保存でき、ライフサイクルポリシーを使用して古いアーティファクトをS3 Glacierに移行することで、コストを削減しつつコンプライアンスとアクセス可能性を維持できます。",
        "Other Options": [
            "AWS CodeCommitは主にソースコードのバージョン管理のために設計されており、アーティファクトの保存には最適化されていません。暗号化を提供できますが、ビルドアーティファクトのライフサイクル管理には最適ではありません。",
            "AWS Elastic Container Registry (ECR)はDockerイメージの管理に適していますが、非コンテナ化アプリケーションや他のタイプのビルドアーティファクトのアーティファクトライフサイクル管理には対応していません。",
            "AWS Systems Manager Parameter Storeは構成データやシークレットの保存を目的としており、ビルドアーティファクトには設計されていません。大きなバイナリファイルのライフサイクル管理には適していません。"
        ]
    },
    {
        "Question Number": "28",
        "Situation": "ある企業がAmazon API Gatewayを通じて新しいバージョンのAPIを展開しました。この新しいバージョンには、まだテスト中の機能が含まれています。スムーズな移行を確保し、リスクを最小限に抑えるために、企業はカナリアリリース戦略を採用しました。DevOpsエンジニアの目標は、APIキャッシングを設定してパフォーマンスを向上させることですが、変更がカナリアリリースにのみ表示されるようにすることです。",
        "Question": "DevOpsエンジニアがAPIキャッシングとカナリアリリースを設定するために取るべきステップの組み合わせはどれですか？（2つ選択）",
        "Options": {
            "1": "カナリアステージでキャッシュヒット比率を監視するためにCloudWatchアラームを作成し、それに応じてキャッシング戦略を調整します。",
            "2": "API Gatewayでステージ変数を設定して、カナリアステージと本番ステージ間のトラフィック分配を制御します。",
            "3": "API Gatewayの設定でカナリアステージのキャッシングを有効にし、キャッシュ容量を128 MBに設定します。",
            "4": "カナリアリリース用にカスタムドメイン名を実装し、トラフィックを分離するために異なるベースパスを設定します。",
            "5": "API Gatewayでメソッドリクエストを設定してキャッシングを有効にし、キャッシュキーのパラメータを指定します。"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "API Gatewayの設定でカナリアステージのキャッシングを有効にし、キャッシュ容量を128 MBに設定します。",
            "API Gatewayでメソッドリクエストを設定してキャッシングを有効にし、キャッシュキーのパラメータを指定します。"
        ],
        "Explanation": "カナリアステージでキャッシングを有効にすることで、バックエンドサービスへの呼び出し回数が減少し、APIの応答性が直接向上します。また、メソッドリクエストを設定してキャッシングを有効にし、キャッシュキーのパラメータを指定することで、APIへのリクエストに最適化されたキャッシングメカニズムが確保され、カナリアリリース戦略にとって重要です。",
        "Other Options": [
            "カナリアリリース用にカスタムドメイン名を実装することは、トラフィックを分離するために主に機能するため、キャッシングや応答性を本質的に向上させるものではありません。",
            "トラフィック分配を制御するためにステージ変数を設定することはカナリアリリースにとって重要ですが、APIキャッシングとは直接関係がありません。",
            "キャッシュヒット比率を監視するためにCloudWatchアラームを作成することは、キャッシング戦略を調整するのに役立ちますが、即時のパフォーマンス向上に必要なキャッシングメカニズム自体を設定するものではありません。"
        ]
    },
    {
        "Question Number": "29",
        "Situation": "ある企業がAWS CloudFormationを使用してリソースをプロビジョニングし、インフラストラクチャを管理しています。彼らは複雑なスタックを持っており、いくつかのEC2インスタンス、RDSデータベース、S3バケットが含まれています。しかし、インスタンスが必要な依存関係なしに起動されることが多く、アプリケーションのデプロイに遅延や失敗を引き起こしています。EC2インスタンスが作成されるときに、必要なパッケージがインストールされ、サービスが実行されていることを確認したいと考えています。",
        "Question": "すべてのインスタンスが適切に構成され、CloudFormationが各インスタンスの状態を通知されることを保証するために、企業はどのAWS CloudFormationの機能を使用すべきですか？",
        "Options": {
            "1": "AWS Lambdaを使用してEC2インスタンスで初期化スクリプトを実行し、cfn-signalを使用してCloudFormationに初期化の完了を通知します。cfn-hupを組み込んでインスタンスに動的に更新を適用します。",
            "2": "EC2ユーザーデータスクリプトを実装して、インスタンス起動中にパッケージのインストールとサービスの開始を処理します。cfn-signalを使用してCloudFormationにインスタンスの状態を通知し、cfn-hupに依存してさらなる更新を行います。",
            "3": "cfn-initを使用してEC2インスタンスにパッケージをインストールし、サービスを開始します。cfn-signalを使用してプロセスの成功または失敗を示し、WaitConditionを利用してCloudFormationがシグナルを待つようにします。",
            "4": "必要な依存関係をすべて含むカスタムAMIを作成し、CloudFormationを使用してデプロイします。デプロイが完了したときにcfn-signalを使用してCloudFormationに通知し、cfn-hupを使用して更新を確認します。"
        },
        "Correct Answer": "cfn-initを使用してEC2インスタンスにパッケージをインストールし、サービスを開始します。cfn-signalを使用してプロセスの成功または失敗を示し、WaitConditionを利用してCloudFormationがシグナルを待つようにします。",
        "Explanation": "CloudFormationでインスタンスの初期化を管理する最も効果的な方法は、cfn-initを使用することで、リソースプロビジョニングプロセスの一部としてパッケージのインストールとサービスの開始を可能にします。cfn-signalと組み合わせることで、これらの操作の成功または失敗をCloudFormationが認識できるようになり、スタックの整合性と準備状態を維持します。",
        "Other Options": [
            "初期化にAWS Lambdaを使用することは理想的ではありません。cfn-initはCloudFormation内でこの目的のために特別に設計されており、cfn-signalを通じて統合されたシグナルを提供します。このアプローチは、別のサービスを導入することでスタックを複雑にする可能性もあります。",
            "カスタムAMIを作成することは効果的ですが、動的な更新の柔軟性やプロビジョニング中のインスタンスの状態をシグナルする能力を提供しません。cfn-hupのみに依存することは、初期構成要件に対処していません。",
            "ユーザーデータスクリプトを使用するとパッケージをインストールできますが、CloudFormationのシグナルメカニズムとスムーズに統合されません。cfn-signalを使用することはできますが、cfn-initが提供する構造化されたアプローチやバージョン管理が欠けています。"
        ]
    },
    {
        "Question Number": "30",
        "Situation": "ある企業が継続的インテグレーションとデプロイメントを必要とするマイクロサービスベースのアプリケーションを開発しています。開発チームは、テストを実行し、アーティファクトを生成し、AWSサービスとシームレスに統合できるビルドツールを必要としています。彼らはこの目的のためにAWS CodeBuildを使用することを検討しています。チームは、ビルド環境が手動の介入なしに最新の依存関係と構成を自動的に使用するように設定されることを望んでいます。",
        "Question": "開発チームがAWS CodeBuildを適切に構成して最新の依存関係を自動的に生成するアーティファクトを確保するための最良のアプローチは何ですか？",
        "Options": {
            "1": "CodePipelineを作成して、すべてのコミットでCodeBuildをトリガーし、アーティファクト生成の前に手動承認ステップを含めます。",
            "2": "AWS Systems Manager Parameter Storeを利用して依存関係のバージョンを管理し、それをbuildspec.ymlファイルで参照します。",
            "3": "スケジュールされたAWS Lambda関数を実装して、CodeBuildプロジェクト内のbuildspec.ymlファイルを最新の依存関係のバージョンで更新します。",
            "4": "buildspec.ymlファイルを使用してビルドコマンドを定義し、依存関係のバージョン用の環境変数を設定します。"
        },
        "Correct Answer": "AWS Systems Manager Parameter Storeを利用して依存関係のバージョンを管理し、それをbuildspec.ymlファイルで参照します。",
        "Explanation": "AWS Systems Manager Parameter Storeを使用することで、チームは依存関係のバージョンを中央で管理および更新できます。buildspec.ymlでのこの参照により、手動でビルド構成を更新することなく、常に最新のバージョンが使用されることが保証されます。",
        "Other Options": [
            "buildspec.ymlファイルを使用してビルドコマンドを定義することは重要ですが、依存関係のバージョンの環境変数を設定することは、最新のバージョンに自動的に更新されることを保証するものではありません。",
            "手動承認ステップを含むCodePipelineを作成すると遅延が生じ、依存関係の更新プロセスを自動化しないため、主要な要件を満たしません。",
            "スケジュールされたAWS Lambda関数を実装することで更新を自動化できますが、不要な複雑さを加え、buildspec.ymlファイルの更新に追加のメンテナンスが必要になります。"
        ]
    },
    {
        "Question Number": "31",
        "Situation": "DevOpsエンジニアは、組織内の複数のAWSアカウントを管理する責任があります。エンジニアは、一貫したセキュリティとコンプライアンスコントロールを持つ自動アカウントプロビジョニングを可能にするソリューションを実装する必要があります。このソリューションは、すべてのアカウントにわたる中央管理と可視性を提供し、会社のポリシーの遵守を確保する必要があります。組織は、運用効率を達成するために手動プロセスを最小限に抑えることを目指しています。",
        "Question": "コンプライアンスと中央管理を確保しながら、自動アカウントプロビジョニングを達成する最も効率的な方法はどれですか？",
        "Options": {
            "1": "AWS Systems Managerを設定してアカウント作成プロセスを自動化し、AWS Service Catalogを使用して各アカウントのコンプライアンスとリソースを管理します。",
            "2": "AWS Control Towerを実装して、安全なマルチアカウントAWS環境を作成します。事前に設定されたガードレールを利用してコンプライアンスを強制し、自動アカウントプロビジョニングを行います。",
            "3": "AWS CloudFormation StackSetsを活用して、手動で作成した後に複数のアカウントにわたって設定を展開し、リソースプロビジョニングの一貫性を確保します。",
            "4": "AWS Organizationsを使用してアカウントを手動で作成し、その後各アカウントでAWS Configルールを設定してセキュリティと運用基準のコンプライアンスを維持します。"
        },
        "Correct Answer": "AWS Control Towerを実装して、安全なマルチアカウントAWS環境を作成します。事前に設定されたガードレールを利用してコンプライアンスを強制し、自動アカウントプロビジョニングを行います。",
        "Explanation": "AWS Control Towerは、安全なマルチアカウントAWS環境を設定し、管理するための効率的なアプローチを提供します。組織のポリシーに準拠することを保証するブループリントとガードレールを使用してアカウントプロビジョニングプロセスを自動化し、手動の労力を大幅に削減します。",
        "Other Options": [
            "AWS Organizationsを使用してアカウントを手動で作成するのは非効率的であり、各アカウントに対して多大な手動の労力を必要とします。その後にAWS Configルールを設定しても、自動化されたプロビジョニングのソリューションにはなりません。",
            "AWS CloudFormation StackSetsを活用するには手動でアカウントを作成する必要があり、プロセスを自動化しないため、運用効率と中央管理の要件に反します。",
            "AWS Systems Managerを設定してアカウント作成を自動化することは、AWS Control Towerほど効果的にコンプライアンスと中央管理を保証するものではありません。AWS Control Towerはマルチアカウントガバナンスのために特別に設計されています。"
        ]
    },
    {
        "Question Number": "32",
        "Situation": "ある企業がAWS上にマイクロサービスアーキテクチャを展開しており、アプリケーションの効果的な監視とログ記録を確保して、問題を迅速に検出し、コンプライアンスを維持する必要があります。",
        "Question": "企業がアプリケーションを効果的に監視し、ログを記録するために役立つオプションの組み合わせはどれですか？（2つ選択）",
        "Options": {
            "1": "Amazon CloudWatch Alarmsを設定して、異常なパフォーマンスメトリクスをチームに通知します。",
            "2": "Amazon CloudWatch Logsを実装して、複数のマイクロサービスからのログデータを集中管理します。",
            "3": "AWS X-Rayを展開して、パフォーマンス分析のためにマイクロサービス間のリクエストをトレースします。",
            "4": "Amazon S3のバージョニングを有効にして、アプリケーションログの変更を追跡します。",
            "5": "AWS Lambdaを使用して、リアルタイムでログを処理し、特定のイベントに基づいてアラートを送信します。"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon CloudWatch Logsを実装して、複数のマイクロサービスからのログデータを集中管理します。",
            "Amazon CloudWatch Alarmsを設定して、異常なパフォーマンスメトリクスをチームに通知します。"
        ],
        "Explanation": "Amazon CloudWatch Logsを実装することで、企業はすべてのマイクロサービスからのログを集中管理し、問題の分析やトラブルシューティングを容易にします。Amazon CloudWatch Alarmsを設定することで、パフォーマンスメトリクスを監視し、異常をチームに通知し、潜在的な問題に迅速に対応できるようにします。",
        "Other Options": [
            "AWS Lambdaを使用したログ処理は、初期のログ収集には最適ではなく、中央ログ管理よりもイベント駆動型処理に適しています。",
            "Amazon S3のバージョニングはファイルの異なるバージョンを維持するのに役立ちますが、アプリケーションのリアルタイム監視やログ記録機能を提供しません。",
            "AWS X-Rayはリクエストをトレースするのに有益ですが、ログデータを集中管理したり、メトリクスを効果的に監視する主な目的には役立ちません。"
        ]
    },
    {
        "Question Number": "33",
        "Situation": "あなたはAWS Organizationsの下で複数のAWSアカウントを管理しており、メンバーアカウントをある組織から別の組織に移行する必要があります。サービスの中断を避けるために、プロセスが正しく実行されることを確認したいです。",
        "Question": "AWSアカウントをOrganization AからOrganization Bに成功裏に移動するために、どのステップを取るべきですか？",
        "Options": {
            "1": "メンバーアカウントからOrganization Aの管理アカウントにすべてのIAMロールを移行してから、Organization Bに移動します。",
            "2": "メンバーアカウントをOrganization Aから削除し、Organization Bから招待を送信し、メンバーアカウントからその招待を受け入れます。",
            "3": "メンバーアカウントのリソースを削除してからOrganization Bに移動し、その後Organization Bから招待を送信します。",
            "4": "メンバーアカウントのすべてのサービスを無効にし、Organization Aから削除してからOrganization Bから招待を送信しません。"
        },
        "Correct Answer": "メンバーアカウントをOrganization Aから削除し、Organization Bから招待を送信し、メンバーアカウントからその招待を受け入れます。",
        "Explanation": "AWSアカウントを組織間で成功裏に移動するには、まず現在の組織からアカウントを削除し、その後新しい組織から招待を送信し、メンバーアカウントがその招待を受け入れる必要があります。",
        "Other Options": [
            "アカウントを移動する前にリソースを削除する必要はなく、データ損失を引き起こす可能性があります。正しいプロセスは、アカウントを削除し、リソースを削除することなく招待を送信することです。",
            "サービスを無効にすることは、組織間でアカウントを移動するための要件ではありません。正しい手順は、アカウントを削除し、招待を管理することに焦点を当てています。",
            "IAMロールの移行は、組織間でアカウントを移動するプロセスの一部ではありません。焦点は、招待プロセスとその受け入れに置くべきです。"
        ]
    },
    {
        "Question Number": "34",
        "Situation": "あなたは組織のために複数のAWSアカウントを管理しており、これらのアカウントのいくつかを新しく作成したAWS Organizationに移行する計画を立てています。すべてのアカウントがReserved Instances (RIs)およびSavings Plansの割引を享受できるようにしながら、割引の共有を管理する必要があります。",
        "Question": "AWS Organizationにアカウントを移行する際、Reserved Instances (RIs)およびSavings Plansの割引共有の管理に関して、次のうちどの記述が正確ですか？",
        "Options": {
            "1": "移行された各アカウントに対してOrganizationAccountAccessRoleを手動で作成する必要があり、管理アカウントはOrganizationレベルで割引の共有を制御できます。",
            "2": "管理アカウントは個別のアカウントに対してReserved Instancesの割引を無効にできますが、全体のOrganizationに対しては無効にできません。",
            "3": "Savings Plansの割引は、管理アカウントでの設定なしにすべてのアカウントに自動的に共有されます。",
            "4": "すべてのアカウントは自動的にReserved Instancesの割引を受け取りますが、管理アカウントは割引共有設定を制御できません。"
        },
        "Correct Answer": "移行された各アカウントに対してOrganizationAccountAccessRoleを手動で作成する必要があり、管理アカウントはOrganizationレベルで割引の共有を制御できます。",
        "Explanation": "AWS Organizationにアカウントを移行するには、OrganizationAccountAccessRoleを手動で作成する必要があります。さらに、管理アカウントはOrganization全体でReserved InstancesおよびSavings Plansの割引の共有を制御する権限を持ち、すべてのアカウントがこれらの割引を享受できるようにします。",
        "Other Options": [
            "このオプションは不正確です。管理アカウントはOrganization全体のReserved Instancesの割引を無効にできるため、個別のアカウントだけではありません。",
            "この記述は不正確です。管理アカウントは割引共有設定を制御できるため、記載されている内容とは異なります。",
            "このオプションは不正確です。Savings Plansの割引は適用される場合がありますが、共有のための設定が必要であり、自動的には共有されません。"
        ]
    },
    {
        "Question Number": "35",
        "Situation": "DevOpsチームは、マルチティアのウェブアプリケーションをプロビジョニングするためのAWS CloudFormationテンプレートを設計しています。彼らは、テンプレートがデプロイメント環境とリージョンに基づいて特定の値を取得できる柔軟性を持つことを確認する必要があります。さらに、パラメータ入力に基づいてリソースを条件付きで作成したいと考えています。",
        "Question": "DevOpsチームはCloudFormationテンプレートでどの組み込み関数を使用すべきですか？（2つ選択）",
        "Options": {
            "1": "Fn::GetAZs",
            "2": "Fn::Select",
            "3": "Fn::If",
            "4": "Fn::Base64",
            "5": "Fn::Join"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Fn::GetAZs",
            "Fn::If"
        ],
        "Explanation": "Fn::GetAZsは、スタックがデプロイされているリージョンのアベイラビリティゾーンを動的に取得するために使用でき、異なる環境に適応可能です。Fn::Ifは、入力パラメータに基づいて条件付きでリソースを作成することを可能にし、リソースプロビジョニングに柔軟性を提供します。",
        "Other Options": [
            "Fn::Joinは文字列を連結するために使用されますが、デプロイメントコンテキストに特有の値の条件付きロジックや動的取得を提供しません。",
            "Fn::Base64は主にユーザーデータのエンコードに使用され、リソースを条件付きで作成したり、環境に基づいて値を取得したりする目的には適していません。",
            "Fn::Selectはリストから値を選択するのに便利ですが、アベイラビリティゾーンの動的取得や条件付きリソース作成の要件には対応していません。"
        ]
    },
    {
        "Question Number": "36",
        "Situation": "ある組織はAWS CodePipelineを使用してデプロイメントプロセスを自動化しています。彼らは、失敗を優雅に処理し、以前のアクションの結果に基づいて次のパイプラインをトリガーする必要があります。しかし、条件付きアクションやパイプラインの直接呼び出しに制限があることに直面しています。",
        "Question": "組織はCodePipelineの失敗を管理し、必要に応じて別のパイプラインをトリガーするためにどのアプローチを取るべきですか？",
        "Options": {
            "1": "AWS EventBridgeによってパイプラインの失敗時にトリガーされるLambda関数を実装します。この関数は失敗の種類を確認し、必要に応じて別のCodePipelineを呼び出すことができます。",
            "2": "AWS Step Functionsを利用してCodePipelineのワークフローをオーケストレーションし、アクションの成功または失敗に基づいて条件付き分岐を可能にします。",
            "3": "CloudWatch Eventsを設定してCodePipelineの状態を監視し、失敗を処理し別のパイプラインを開始できるLambda関数を呼び出します。",
            "4": "CodePipeline内にカスタムアクションを作成し、特定のアクションの失敗時に別のCodePipelineを直接呼び出します。"
        },
        "Correct Answer": "AWS EventBridgeによってパイプラインの失敗時にトリガーされるLambda関数を実装します。この関数は失敗の種類を確認し、必要に応じて別のCodePipelineを呼び出すことができます。",
        "Explanation": "AWS EventBridgeを使用してパイプラインの失敗をキャッチすることで、組織は失敗のコンテキストに基づいて別のパイプラインを条件付きで呼び出すカスタムロジックをLambda関数に実装できます。この方法は、CodePipeline自体が条件付きアクションをサポートしていないため、失敗を処理するために必要な柔軟性を提供します。",
        "Other Options": [
            "AWS Step FunctionsはCodePipelineのワークフローを直接オーケストレーションして失敗条件を処理することはできません。CodePipelineは条件付きアクションのネイティブサポートがなく、他のパイプラインを直接呼び出すこともできません。",
            "CodePipeline内にカスタムアクションを作成しても機能しません。CodePipelineは別のCodePipelineを直接呼び出すことができないため、このアプローチの効果が制限されます。",
            "CloudWatch Events単独では、パイプラインアクションに基づく条件付きロジックを管理する能力を提供しません。失敗に適切に応答するためには、EventBridgeと連携したLambda関数が必要です。"
        ]
    },
    {
        "Question Number": "37",
        "Situation": "DevOpsエンジニアは、相互依存するリソースを含む複数のAWS CloudFormationスタックを管理しています。リソースが正しくプロビジョニングされ、エラーが発生しないように、スタックは特定の順序で作成する必要があります。エンジニアは、CloudFormationサービスがリソース間の依存関係を理解しつつ、スタック作成の管理を簡素化する必要があります。",
        "Question": "エンジニアは、リソースの依存関係とスタック作成を効果的に管理するために、どのアプローチを取るべきですか？",
        "Options": {
            "1": "CloudFormationを使用せずに、各スタックを手動で順番に作成し、リソースが段階的にプロビジョニングされることを確認して、自動依存関係解決を避ける。",
            "2": "CloudFormation StackSetsを使用して、複数のアカウントとリージョン間の依存関係を管理し、StackSet機能に依存してリソースの作成と順序を自動的に処理させる。",
            "3": "AWS SDKを使用して、正しい順序で各リソースの作成をトリガーするLambda関数を設定し、より多くの制御を得るためにCloudFormationの依存関係管理システムをバイパスする。",
            "4": "CloudFormationテンプレートのDependsOn属性を利用して、リソースの作成順序を指定し、依存リソースがその前提条件が完全にプロビジョニングされた後にのみ作成されることを保証する。"
        },
        "Correct Answer": "CloudFormationテンプレートのDependsOn属性を利用して、リソースの作成順序を指定し、依存リソースがその前提条件が完全にプロビジョニングされた後にのみ作成されることを保証する。",
        "Explanation": "DependsOn属性を使用することで、エンジニアは単一のCloudFormationスタック内でリソースの作成順序を明示的に定義でき、プロビジョニングプロセス中にすべての依存関係が尊重されることを保証します。この方法は、CloudFormationの組み込みの依存関係管理機能を効果的に活用します。",
        "Other Options": [
            "スタックを手動で順番に作成することは非効率的であり、人為的なエラーが発生しやすいです。これは、リソース管理と依存関係解決を自動化するために設計されたCloudFormationの目的に反します。",
            "Lambda関数を使用してリソース作成を管理することは制御を提供しますが、複雑さを引き起こし、CloudFormationの組み込みの依存関係処理の利点を排除するため、リソースが適切に管理されない可能性があります。",
            "CloudFormation StackSetsを使用することは、複数のアカウントとリージョン間でスタックを管理するのに適していますが、単一スタックのリソース作成内の依存関係を管理する特定のニーズには対応していません。"
        ]
    },
    {
        "Question Number": "38",
        "Situation": "ある組織は、Amazon RDSデータベースに重要なユーザーデータを保存するステートフルアプリケーションに依存しています。可用性とレジリエンスを高めるために、組織はレプリケーションとフェイルオーバー方法を含む災害復旧戦略を実装する必要があります。アプリケーションは、障害が発生した場合に最小限のダウンタイムとデータ損失を必要とします。",
        "Question": "DevOpsエンジニアは、災害時にアプリケーションが迅速に回復し、最小限のデータ損失で済むようにするために、どのソリューションを実装すべきですか？",
        "Options": {
            "1": "Amazon RDS Multi-AZデプロイメントを有効にして、データを異なるアベイラビリティゾーンのスタンバイインスタンスに同期的にレプリケートします。プライマリインスタンスが失敗した場合にスタンバイインスタンスへの自動フェイルオーバーを構成します。",
            "2": "別のリージョンにAmazon RDSリードレプリカを設定して、クロスリージョンレプリケーションを行います。プライマリインスタンスが失敗した場合に高可用性を確保するためにリードレプリカを使用します。",
            "3": "AWS Lambdaを使用して、プライマリRDSインスタンスから異なるリージョンのセカンダリRDSインスタンスに定期的にデータをコピーするカスタムソリューションを実装します。このインスタンスを必要に応じてフェイルオーバーに使用します。",
            "4": "Amazon RDSデータベースのバックアップを毎時作成し、Amazon S3に保存します。障害が発生した場合、最新のバックアップからデータベースを復元してダウンタイムを最小限に抑えます。"
        },
        "Correct Answer": "Amazon RDS Multi-AZデプロイメントを有効にして、データを異なるアベイラビリティゾーンのスタンバイインスタンスに同期的にレプリケートします。プライマリインスタンスが失敗した場合にスタンバイインスタンスへの自動フェイルオーバーを構成します。",
        "Explanation": "Amazon RDS Multi-AZデプロイメントを有効にすることで、自動フェイルオーバー機能とスタンバイインスタンスへの同期データレプリケーションが提供されます。これにより、災害時のダウンタイムとデータ損失が最小限に抑えられ、可用性とレジリエンスを必要とするステートフルアプリケーションにとって最良の選択肢となります。",
        "Other Options": [
            "別のリージョンにリードレプリカを設定することは主にリードスケーリングのためであり、Multi-AZデプロイメントと同じレベルの可用性や自動フェイルオーバーを提供しません。また、リード操作に追加のレイテンシを引き起こします。",
            "毎時バックアップを作成し、Amazon S3に保存することは、災害復旧シナリオ中により大きなダウンタイムを引き起こす可能性があります。データベースは最新のバックアップから復元される必要があり、最後のバックアップ以降のデータ損失の可能性があります。",
            "AWS Lambdaを使用してデータを定期的にコピーするカスタムソリューションは、複雑さとデータレプリケーションの遅延を引き起こす可能性があります。また、ダウンタイムとデータ損失を最小限に抑えるために重要な同期レプリケーションや自動フェイルオーバーを保証しません。"
        ]
    },
    {
        "Question Number": "39",
        "Situation": "あなたは、アイデンティティ管理とロール引き受けのためにカスタムプロキシを使用しているAWS環境を管理しています。企業のユーザーはFed Proxyドメインを介して認証し、LDAPと連携してグループを取得し、その後AWS STSからロール情報を要求します。ユーザーがロールを選択すると、Fed ProxyはSTS:AssumeRoleを呼び出してコンソールアクセスを取得します。",
        "Question": "カスタムプロキシを通じてユーザーがAWS Management Consoleにアクセスできるようにするための2つの重要なステップは何ですか？（2つ選択してください）",
        "Options": {
            "1": "Fed Proxyはユーザー認証後にSTSにロールリストリクエストを送信します。",
            "2": "Fed Proxyはコンソールにアクセスする各企業ユーザーのために新しいIAMユーザーを生成します。",
            "3": "Fed Proxyはユーザーを認証し、LDAPディレクトリからグループを取得します。",
            "4": "Fed Proxyはユーザーが適切なロールを選択した後にSTS:AssumeRoleを送信します。",
            "5": "STPはコンソールセッション中の各ユーザーの活動の詳細なログを返します。"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Fed Proxyはユーザーを認証し、LDAPディレクトリからグループを取得します。",
            "Fed Proxyはユーザーが適切なロールを選択した後にSTS:AssumeRoleを送信します。"
        ],
        "Explanation": "Fed Proxyを介したユーザーの認証とLDAPからのグループの取得は、ユーザーのアイデンティティを検証し、適切なロールアクセスを確保するために不可欠です。また、STS:AssumeRoleを送信することは、選択されたロールに基づいてユーザーがAWSリソースにコンソールアクセスを得るために重要です。",
        "Other Options": [
            "このオプションは不正確です。各企業ユーザーのために新しいIAMユーザーを生成することは、プロキシを介したアクセス管理の実用的または効率的な方法ではありません。代わりに、ロール引き受けが使用されます。",
            "このオプションは不正確です。STPがユーザー活動の詳細なログを返すことは、コンソールアクセスを得るプロセスのコア機能ではなく、監査やコンプライアンスに関連しています。",
            "このオプションは不正確です。ロールリクエストはユーザー認証後に行う必要があり、重要ではありますが、認証とロール引き受けのステップほど重要ではありません。"
        ]
    },
    {
        "Question Number": "40",
        "Situation": "ある金融サービス会社が、AWSリソースとアプリケーションを監視するためにAmazon CloudWatchを使用しています。彼らは、CloudWatchログをS3バケットにエクスポートして長期保存と分析を行う必要があります。また、会社はKinesis Data Firehoseを使用してCloudWatchメトリクスをデータレイクにストリーミングするソリューションを設定したいと考えています。DevOpsチームは、これらの設定が正しく実装されるようにする責任を負っています。",
        "Question": "ログのエクスポートとメトリクスのストリーミングの要件を満たすために、DevOpsチームはどの設定を実装すべきですか？",
        "Options": {
            "1": "ロググループと同じリージョンにS3バケットを作成します。このバケットにログをエクスポートするようにCloudWatch Logsを設定します。S3への書き込み権限を持つIAMロールを使用してKinesis Data Firehose配信ストリームを設定します。",
            "2": "ロググループとは異なるリージョンにS3バケットを作成します。ログをコピーするためにS3クロスリージョンレプリケーションを有効にします。CloudWatchを設定して、Kinesis Data Firehose配信ストリームにメトリクスをストリーミングします。",
            "3": "ロググループと同じリージョンにS3バケットを作成します。S3クロスリージョンレプリケーションを使用してログを異なるリージョンにコピーします。CloudWatchを信頼するIAMロールを使用してKinesis Data Firehose配信ストリームを設定します。",
            "4": "ロググループと同じリージョンにS3バケットを作成します。このバケットに直接ログをエクスポートするようにCloudWatch Logsを設定します。CloudWatchを信頼するロールを使用してKinesis Data Firehoseにメトリクスをストリーミングします。"
        },
        "Correct Answer": "ロググループと同じリージョンにS3バケットを作成します。このバケットに直接ログをエクスポートするようにCloudWatch Logsを設定します。CloudWatchを信頼するロールを使用してKinesis Data Firehoseにメトリクスをストリーミングします。",
        "Explanation": "正しい設定は、S3バケットがCloudWatchロググループと同じリージョンに作成されることを保証します。これはログをエクスポートするための要件です。さらに、適切なIAMロールを持つKinesis Data Firehose配信ストリームを使用することで、メトリクスを問題なくストリーミングできます。",
        "Other Options": [
            "このオプションは、異なるリージョンにS3バケットを作成することを誤って提案しており、ログエクスポートには不要なクロスリージョンレプリケーションに依存しています。",
            "このオプションは、バケットがロググループと同じリージョンにある場合、ログに対してクロスリージョンレプリケーションを使用することを提案しているため不正確です。また、Kinesis Data Firehoseの信頼関係を誤って省略しています。",
            "このオプションは、S3バケットが同じリージョンにある場合、ログに対してクロスリージョンレプリケーションを使用することを誤って強調しており、メトリクスをストリーミングするためのIAMロールがCloudWatchを信頼する必要があることを指定していません。"
        ]
    },
    {
        "Question Number": "41",
        "Situation": "ある小売会社が、Amazon Elastic Container Service (Amazon ECS)を利用してコンテナ化されたアプリケーションのデプロイを管理しています。開発チームは、ダウンタイムを最小限に抑え、デプロイ失敗時に迅速にロールバックできるデプロイ戦略を探しています。現在のデプロイ方法は、更新中にサービスの中断を引き起こしています。DevOpsエンジニアは、チームの要件を最もよく満たすデプロイ方法を推奨する必要があります。",
        "Question": "ECSアプリケーションのためにダウンタイムを最小限に抑え、迅速なロールバックを促進するために、DevOpsエンジニアはどのデプロイ戦略を推奨すべきですか？",
        "Options": {
            "1": "カナリアデプロイメント戦略を実装して、新しいバージョンへのトラフィックを徐々に移行します。",
            "2": "ローリングデプロイメント戦略を選択して、アプリケーションのインスタンスを段階的に更新します。",
            "3": "シャドウデプロイメント戦略を選択して、新しいバージョンを現在のバージョンと並行して実行し、ユーザーに影響を与えません。",
            "4": "ブルー/グリーンデプロイメント戦略を使用して、2つの別々の環境間でトラフィックを移行します。"
        },
        "Correct Answer": "ブルー/グリーンデプロイメント戦略を使用して、2つの別々の環境間でトラフィックを移行します。",
        "Explanation": "ブルー/グリーンデプロイメント戦略では、2つの別々の環境（ブルーとグリーン）を維持できます。新しいバージョンをグリーン環境にデプロイし、ブルー環境がまだトラフィックを処理している間に行います。新しいバージョンが検証されると、トラフィックをグリーン環境に切り替えることができ、ダウンタイムを最小限に抑えることができます。問題が発生した場合は、簡単にブルー環境に戻すことができ、迅速なロールバックが可能です。",
        "Other Options": [
            "カナリアデプロイメント戦略は、新しいバージョンを小さなユーザーのサブセットに徐々に導入し、完全な展開を行う前にリスクを軽減しますが、ブルー/グリーンデプロイメントほどダウンタイムを最小限に抑えることはできません。",
            "ローリングデプロイメント戦略は、インスタンスを段階的に更新しますが、更新プロセス中に問題が発生した場合、一時的なサービス中断を引き起こす可能性があるため、ゼロダウンタイムの要件にはあまり適していません。",
            "シャドウデプロイメント戦略は、新しいバージョンを現在のバージョンと並行して実行しますが、ユーザートラフィックを処理しないため、ライブ更新中の即時ロールバックやダウンタイムの最小化には適していません。"
        ]
    },
    {
        "Question Number": "42",
        "Situation": "ある組織が最近、AWS Control Towerを実装して、アカウントファクトリーを使用して複数のAWSアカウントを管理しています。彼らは、すべてのアカウントが組織のポリシーに準拠し、ポリシー違反が迅速に検出され、是正されることを確保したいと考えています。DevOpsチームは、この目的を達成するためのガードレールを設定する責任を負っています。",
        "Question": "AWS Control Towerにおけるポリシー違反を検出し、是正するためのガードレールを実装するための最良の方法論はどれですか？",
        "Options": {
            "1": "AWS Configルールを活用して、アカウントリソースを継続的に監視し、非準拠の問題を特定します。",
            "2": "リソースプロビジョニング中にコンプライアンスを強制するためにCloudFormationフックを使用するプロアクティブな監視システムを設定します。",
            "3": "AWSサービスコントロールポリシー（SCP）を利用して、非準拠のアクションをブロックする予防的なガードレールを強制します。",
            "4": "CloudFormationテンプレートを使用してリソースをデプロイし、ポリシー違反を自動的に是正するGitOpsアプローチを実装します。"
        },
        "Correct Answer": "AWS Configルールを活用して、アカウントリソースを継続的に監視し、非準拠の問題を特定します。",
        "Explanation": "AWS Configは、AWSリソースの構成を継続的に監視および評価する方法を提供します。AWS Configルールを使用することで、ポリシー違反を検出し、是正措置を講じることができ、AWS Control Towerにおける効果的な検出ガードレールメカニズムとなります。",
        "Other Options": [
            "AWSサービスコントロールポリシー（SCP）は非準拠のアクションを防ぐことができますが、既存の違反を検出するメカニズムを提供しないため、記載されたシナリオにはあまり適していません。",
            "GitOpsアプローチはデプロイを効率化できますが、ポリシー違反の検出や既存の問題に対する是正戦略を本質的に扱うものではありません。",
            "CloudFormationフックはリソースプロビジョニング中のカスタマイズに使用できますが、コンプライアンスの継続的な監視機能を提供せず、ポリシー違反を検出し是正するためには必要です。"
        ]
    },
    {
        "Question Number": "43",
        "Situation": "ある企業がAWS上にアプリケーションを展開し、膨大なログデータを生成しています。アプリケーションのパフォーマンスを効果的に監視し、問題をトラブルシュートするために、DevOpsエンジニアはCloudWatch Logsを使用してログソリューションを設定する任務を負っています。要件には、エンジニアが特定のログイベントをCloudWatchメトリクスに変換するメトリックフィルターを作成し、ログデータが特定の期間保持されるようにする必要があると記載されています。",
        "Question": "次の設定のうち、DevOpsエンジニアがログデータのメトリックフィルターを正常に作成し、ロググループの適切な保持設定を行うことを可能にするのはどれですか？",
        "Options": {
            "1": "CloudWatch Logsにロググループを作成し、関連するログデータを抽出するフィルターパターンを持つメトリックフィルターを定義し、ロググループの保持ポリシーを30日間に設定します。メトリックフィルターがすべての受信ログイベントに適用されることを確認してください。",
            "2": "CloudWatch Logsにロググループを作成し、データポイントを抽出するメトリックフィルターを設定し、保持を7日間に設定します。設定後、既存のログデータにフィルターを適用するように設定します。",
            "3": "CloudWatch Logsにロググループを設定し、メトリクスを抽出するための特定のパターンを持つメトリックフィルターを作成し、ログを90日間保持するように設定します。メトリックフィルターは受信ログにのみ適用されます。",
            "4": "CloudWatch Logsにメトリックフィルターを作成し、ログイベントに一致するフィルターパターンを持ち、メトリック名と名前空間を定義し、保持を1年に設定します。これにより、既存のログデータがメトリック計算に含まれることが保証されます。"
        },
        "Correct Answer": "CloudWatch Logsにロググループを作成し、関連するログデータを抽出するフィルターパターンを持つメトリックフィルターを定義し、ロググループの保持ポリシーを30日間に設定します。メトリックフィルターがすべての受信ログイベントに適用されることを確認してください。",
        "Explanation": "ロググループを作成し、フィルターパターンを持つメトリックフィルターを定義することで、関連するログデータをCloudWatchメトリクスに抽出できます。保持ポリシーを30日間に設定することでデータ保持の要件を満たし、受信ログにメトリックフィルターを適用することで継続的な監視が確保されます。",
        "Other Options": [
            "このオプションは、メトリックフィルターが既存のログデータに適用できると誤って述べていますが、メトリックフィルターは作成後に生成されたログにのみ機能します。",
            "このオプションはメトリックフィルターを作成し、保持ポリシーを設定する点では正しいですが、フィルターがすべての受信ログイベントに適用されることを明記していないため、継続的な監視には必要です。",
            "このオプションは、既存のログデータがメトリック計算に含まれる可能性があると誤って示唆していますが、メトリックフィルターは作成後の新しいログイベントにのみ機能します。"
        ]
    },
    {
        "Question Number": "44",
        "Situation": "ある企業が、高い計算能力、高スループット、最小限のレイテンシを必要とするハイパフォーマンスコンピューティングアプリケーションを実行するために、異なるAmazon EC2インスタンスファミリーを評価しています。このアプリケーションは、集中的なグラフィカル処理のためにGPUの利用があるとさらに効果的です。DevOpsエンジニアとして、これらの要件を満たす最も適切なEC2インスタンスファミリーと世代を推奨する必要があります。",
        "Question": "次のEC2インスタンスファミリーと世代のうち、ハイパフォーマンスコンピューティングアプリケーションのニーズを最もよく満たすものはどれですか？",
        "Options": {
            "1": "インスタンスストアボリュームサポートを持つ第2世代のR5インスタンス",
            "2": "基本的なパフォーマンス機能を持つ第1世代のT3インスタンス",
            "3": "強化されたネットワーキング機能を持つ第4世代のG4adインスタンス",
            "4": "専用EBS最適化を持つ第3世代のC5インスタンス"
        },
        "Correct Answer": "強化されたネットワーキング機能を持つ第4世代のG4adインスタンス",
        "Explanation": "G4adインスタンスは、グラフィカルおよび計算ワークロードのためのGPUサポートを提供し、ハイパフォーマンスコンピューティングアプリケーションに最適です。また、強化されたネットワーキング機能により、高スループットと低レイテンシが確保され、アプリケーションの要件に完璧に合致します。",
        "Other Options": [
            "C5インスタンスは計算ワークロードに最適化されていますが、アプリケーションのグラフィカル処理ニーズに必要なGPU機能が欠けています。",
            "R5インスタンスはメモリ集約型アプリケーション向けに設計されており、ハイパフォーマンスコンピューティングタスクに必要なGPUサポートを提供していません。",
            "T3インスタンスは汎用でバースト可能なワークロードに適していますが、集中的な計算タスクに必要なパフォーマンス機能を提供していません。"
        ]
    },
    {
        "Question Number": "45",
        "Situation": "あなたは、AWS上で動作し、機密の顧客データを処理するアプリケーションのセキュリティとコンプライアンスを担当しています。このアプリケーションは、静止データと転送中のデータの両方が暗号化されていることを確実にする必要があります。さらに、暗号化キーへのアクセスを制御し、規制基準に準拠するための堅牢なキー管理戦略を確立する必要があります。",
        "Question": "このシナリオにおけるデータ暗号化とキー管理の要件を最もよく満たすアプローチはどれですか？",
        "Options": {
            "1": "機密データに対して暗号化なしのEC2インスタンスストレージを利用し、転送中のデータにはネットワークセキュリティ対策に依存する。",
            "2": "AWS Secrets Managerを使用して暗号化キーを保存し、IAMポリシーに依存してそれらのキーへのアクセスを保護する。",
            "3": "サードパーティのライブラリを使用してクライアント側の暗号化を実装し、アプリケーション内に平文で暗号化キーを保存する。",
            "4": "AWS Key Management Service (KMS)を使用して暗号化キーを管理し、S3を使用してサーバー側の暗号化でデータを暗号化する。"
        },
        "Correct Answer": "AWS Key Management Service (KMS)を使用して暗号化キーを管理し、S3を使用してサーバー側の暗号化でデータを暗号化する。",
        "Explanation": "AWS Key Management Service (KMS)を使用することで、暗号化キーを中央で安全に管理できます。S3によるサーバー側の暗号化は、静止データが自動的に暗号化されることを保証し、コンプライアンスとセキュリティ要件を効果的に満たします。",
        "Other Options": [
            "サードパーティのライブラリを使用したクライアント側の暗号化は、AWSサービスとの統合がうまくいかない可能性があり、平文で暗号化キーを保存することはセキュリティを損なうリスクがあります。",
            "暗号化キーにAWS Secrets Managerを使用することは、このシナリオには最適ではありません。なぜなら、Secrets Managerは主にシークレットの管理のために設計されており、暗号化キー専用ではなく、KMSと同じレベルのキー管理機能を提供しない可能性があるからです。",
            "暗号化なしのEC2インスタンスストレージを利用することは、静止データに対して非常に安全ではなく、転送中のデータに対してネットワークセキュリティのみに依存することは要件を完全には満たしていません。"
        ]
    },
    {
        "Question Number": "46",
        "Situation": "ある企業がAWS上でAmazon ECSを使用してマイクロサービスアーキテクチャを展開しており、監視とログ収集にはAmazon CloudWatchに依存しています。セキュリティチームは、現在ログ収集のために構成されているIAMロールと権限について懸念を示しています。彼らは、認可されたサービスのみがCloudWatchにログを書き込むことができ、機密ログデータが不正アクセスから保護されていることを確認する必要があります。あなたは、これらの要件を満たす安全で効率的なログ収集ソリューションを実装する任務を負っています。",
        "Question": "次の構成のうち、AWSでの安全なログ収集を最も確実に保証し、機密ログデータへのアクセスを制限するのはどれですか？",
        "Options": {
            "1": "既存のIAMロールを変更してCloudWatch Logsのために広範な権限を含め、すべてのサービスが制限なしにCloudWatchにログを記録できるようにします。",
            "2": "各ECSタスクにCloudWatchエージェントを設定し、CloudWatch Logsへの完全なアクセス権を持つ一般的なIAMロールを割り当てます。",
            "3": "ECSタスク専用にCloudWatch Logsに書き込む権限を持つ専用のIAMロールを作成し、機密データを保護するためにCloudWatch Logsの暗号化を有効にします。",
            "4": "AWS Lambdaを使用してログを処理し、すべてのECSタスクからCloudWatch Logsに書き込む権限を持つIAMロールを割り当てます。"
        },
        "Correct Answer": "ECSタスク専用にCloudWatch Logsに書き込む権限を持つ専用のIAMロールを作成し、機密データを保護するためにCloudWatch Logsの暗号化を有効にします。",
        "Explanation": "ECSタスク専用の特定の権限を持つ専用のIAMロールを作成することで、認可されたサービスのみがCloudWatchにログを書き込むことができることが保証されます。CloudWatch Logsの暗号化を有効にすることで、機密ログデータに対する追加のセキュリティ層が追加され、この構成が最良の選択となります。",
        "Other Options": [
            "既存のIAMロールを変更して広範な権限を含めることは、ログデータへの不正アクセスのリスクを高め、最小権限の原則に違反します。",
            "各ECSタスクにCloudWatchエージェントを設定し、完全なアクセス権を持つ一般的なIAMロールを割り当てることは、ログを不必要なリスクにさらし、セキュリティのベストプラクティスに従っていません。",
            "AWS Lambdaを使用してログを処理し、すべてのECSタスクからCloudWatch Logsに書き込む権限を持つIAMロールを割り当てることは、ログデータへの広範なアクセスを許可することで複雑さと潜在的なセキュリティ問題を引き起こします。"
        ]
    },
    {
        "Question Number": "47",
        "Situation": "ある企業がAWS上でホストされているウェブアプリケーションのパフォーマンス問題に直面しています。このアプリケーションは、EC2インスタンスを使用して自動的にスケールするように設計されています。ピークトラフィック時に、ユーザーは応答時間が遅くなり、一部のリクエストが失敗します。DevOpsエンジニアは、高可用性とパフォーマンスを確保するために、スケーリングの問題を特定し、修正する必要があります。",
        "Question": "エンジニアがスケーリングの問題を効果的に解決するために取るべきステップの組み合わせはどれですか？（2つ選択）",
        "Options": {
            "1": "アプリケーションコードを最適化して、各リクエストの処理時間を短縮します。",
            "2": "Amazon Elastic Load Balancingを構成して、トラフィックを健康なインスタンスに自動的にルーティングします。",
            "3": "AWS Global Acceleratorを有効にして、複数のリージョンにトラフィックを分散させます。",
            "4": "Auto Scalingグループを調整して、より低いCPU閾値でインスタンスを追加します。",
            "5": "Amazon CloudWatchアラームを実装して、CPUとメモリの使用状況を監視します。"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon CloudWatchアラームを実装して、CPUとメモリの使用状況を監視します。",
            "Auto Scalingグループを調整して、より低いCPU閾値でインスタンスを追加します。"
        ],
        "Explanation": "Amazon CloudWatchアラームを実装することで、エンジニアはEC2インスタンスのパフォーマンスメトリクスを積極的に監視でき、重大なパフォーマンス低下が発生する前にタイムリーな介入が可能になります。Auto Scalingグループを調整して、より低いCPU閾値でインスタンスを追加することで、ピーク負荷時にアプリケーションが迅速にスケールアウトし、応答時間を改善し、リクエストの失敗を減少させます。",
        "Other Options": [
            "AWS Global Acceleratorを有効にすることは、単一リージョン内のスケーリング問題に直接関係ありません。これは、グローバルユーザーを持つアプリケーションのパフォーマンスと可用性を向上させますが、Auto Scalingグループ内のスケーリング問題を解決するものではありません。",
            "アプリケーションコードを最適化することは常に有益ですが、ピークトラフィック時に不十分なEC2インスタンスによって引き起こされる即時のスケーリング問題には対処しません。負荷を処理するためにスケーリングアクションを優先する必要があります。",
            "Amazon Elastic Load Balancingを構成することはトラフィックを分散させるために重要ですが、パフォーマンス問題が発生したときにインスタンスの数をスケールアウトする問題を直接解決するものではありません。これはスケーリングを補完しますが、代替にはなりません。"
        ]
    },
    {
        "Question Number": "48",
        "Situation": "ある企業がAWS Control Towerを使用してマルチアカウント戦略を実装し、アカウント管理とガバナンスを簡素化しようとしています。彼らは、Account Factoryを活用して自動化されたアカウントプロビジョニングを行い、企業ポリシーに準拠し、各アカウントのカスタム構成を可能にしたいと考えています。DevOpsエンジニアは、セットアップが効率的であり、複数のアカウントにわたるスケーリングのベストプラクティスに沿っていることを確認する必要があります。",
        "Question": "DevOpsエンジニアがAWS Control TowerとAccount Factoryを使用してカスタマイズされたアカウントプロビジョニングプロセスを実装するために最も効果的なアプローチはどれですか？",
        "Options": {
            "1": "Account Factory Customizationを実装して、カスタムブループリントを使用してアカウントプロビジョニングを調整し、各アカウントが特定の要件を満たしつつ、AWS Control Towerのベストプラクティスに準拠することを保証します。",
            "2": "AWS Service Catalogを活用してアカウントプロビジョニングのための製品を作成し、Account Factoryをバイパスすることで、アカウント構成とガバナンスの不整合を引き起こす可能性があります。",
            "3": "Account Factoryを利用して新しいアカウントをプロビジョニングし、AWS Organizationsサービスで設定された組織のポリシーに準拠する標準ブループリントを各アカウントに適用します。",
            "4": "Account Factoryの外でアカウントをプロビジョニングするカスタムCloudFormationテンプレートを作成し、完全な柔軟性を提供しますが、ガバナンス機能が低下します。"
        },
        "Correct Answer": "Account Factory Customizationを実装して、カスタムブループリントを使用してアカウントプロビジョニングを調整し、各アカウントが特定の要件を満たしつつ、AWS Control Towerのベストプラクティスに準拠することを保証します。",
        "Explanation": "カスタムブループリントを使用したAccount Factory Customizationを実装することで、DevOpsエンジニアは特定の組織のニーズに合わせてアカウントプロビジョニングプロセスを効果的に調整し、AWS Control Towerによって提供されるガバナンスとコンプライアンスに従うことができます。このアプローチは、カスタマイズとベストプラクティスの遵守のバランスを保証します。",
        "Other Options": [
            "標準ブループリントを使用したAccount Factoryの利用は、特定の組織要件に必要なカスタマイズレベルを提供せず、プロビジョニングプロセスの効果を制限します。",
            "Account Factoryの外でカスタムCloudFormationテンプレートを作成することは、AWS Control Towerを使用することによるガバナンスとコンプライアンスの利点を損なう可能性があり、アカウント管理の不整合を引き起こすことがあります。",
            "アカウントプロビジョニングのためにAWS Service Catalogを使用してAccount Factoryをバイパスすることは、標準化と監視の欠如を引き起こし、AWS Control Towerによって提供される集中管理戦略の利点を損なう可能性があります。"
        ]
    },
    {
        "Question Number": "49",
        "Situation": "あなたは、頻繁な設定変更とアプリケーション設定のデプロイが必要なAWS上のマイクロサービスアーキテクチャを管理しています。チームは、アプリケーションのコードとは別にアプリケーションの設定を管理できるソリューションを必要としており、これによりアプリケーションを再デプロイすることなく設定を更新できるようにします。変更を追跡し、必要に応じて設定をロールバックする能力を維持したいと考えています。",
        "Question": "このシナリオで動的アプリケーション設定を管理するのに最適なサービスはどれですか？",
        "Options": {
            "1": "AWS OpsWorks",
            "2": "AWS Systems Manager",
            "3": "AWS AppConfig",
            "4": "AWS Config"
        },
        "Correct Answer": "AWS AppConfig",
        "Explanation": "AWS AppConfigは、コードとは別にアプリケーションの設定を管理するために特別に設計されています。設定の動的更新、変更の追跡、以前の設定へのロールバックを可能にし、マイクロサービスアーキテクチャに最適です。",
        "Other Options": [
            "AWS Systems Managerは設定管理機能を提供しますが、動的アプリケーション設定ではなく、AWSリソースの状態管理により重点を置いています。",
            "AWS OpsWorksは、ChefまたはPuppetを使用してアプリケーションのデプロイと管理に焦点を当てた設定管理サービスですが、動的アプリケーション設定管理に関してはAWS AppConfigほど効果的ではありません。",
            "AWS Configは主にリソースの設定追跡とコンプライアンス監査に使用され、動的アプリケーション設定の管理には不適切です。"
        ]
    },
    {
        "Question Number": "50",
        "Situation": "ある会社は、ピーク時にAWS Lambda関数へのトラフィックが増加しています。彼らは、AWS Application Auto Scalingを使用して、より重い負荷の下でLambda関数のパフォーマンスを向上させたいと考えています。さらに、同じ実行環境内で独立して動作する外部拡張機能があり、Lambda関数の処理が完了した後も継続して動作しなければなりません。",
        "Question": "外部拡張機能が継続的に動作できるようにしながら、Lambda関数のパフォーマンスを向上させるためにDevOpsエンジニアはどのアプローチを取るべきですか？",
        "Options": {
            "1": "AWS Application Auto Scalingを実装してLambda関数の同時実行制限を増加させ、外部拡張機能を共有アクセスのために別のLambdaレイヤーで動作するように設定します。",
            "2": "AWS Application Auto Scalingを設定してLambda関数のプロビジョニング同時実行を調整し、外部拡張機能をLambda関数と通信する別のAWS Fargateタスクとしてデプロイします。",
            "3": "AWS Application Auto Scalingを利用してLambda関数の予約同時実行を有効にし、外部拡張機能がAmazon ECSによって管理される別のコンテナ化サービスで独立して動作することを保証します。",
            "4": "AWS Application Auto Scalingを設定してLambda関数の同時実行制限のスケーリングを管理し、外部拡張機能がLambdaデプロイメントパッケージ内にバンドルされることを保証します。"
        },
        "Correct Answer": "AWS Application Auto Scalingを利用してLambda関数の予約同時実行を有効にし、外部拡張機能がAmazon ECSによって管理される別のコンテナ化サービスで独立して動作することを保証します。",
        "Explanation": "AWS Application Auto Scalingを利用して予約同時実行を有効にすることで、Lambda関数は増加する負荷を効果的に処理でき、外部拡張機能をAmazon ECSのような別のコンテナ化サービスで管理することで独立して動作し続けることができます。",
        "Other Options": [
            "Lambda関数の同時実行制限を増加させ、外部拡張機能をLambdaレイヤー内で設定することは、関数の呼び出しが完了した後に拡張機能が独立して動作することを許可しません。",
            "Lambda関数の同時実行のスケーリングを管理し、拡張機能をデプロイメントパッケージ内にバンドルすることは、拡張機能が独立して動作する能力を制限し、リソース管理の利点を活用しません。",
            "プロビジョニング同時実行のためにAWS Application Auto Scalingを設定することはパフォーマンスを向上させますが、外部拡張機能をFargateタスクとしてデプロイすることは、ECS内で別のサービスとして効果的に管理できる場合にアーキテクチャを不必要に複雑にします。"
        ]
    },
    {
        "Question Number": "51",
        "Situation": "ある会社は異なる部門のために複数のAWSアカウントを持ち、これらのアカウントとリージョン全体でインフラストラクチャをコードとして管理するためにAWS CloudFormation StackSetsを使用しています。DevOpsエンジニアは、CloudFormationテンプレートの変更がすべてのアカウントとリージョンに一貫して信頼性高く伝播されることを確保する必要があります。手動介入を最小限に抑えます。",
        "Question": "この要件をどのように実装すべきですか？（2つ選択）",
        "Options": {
            "1": "AWS Organizationsを使用して、CloudFormation StackSetsへの変更を特定のアカウントのみに制限するサービスコントロールポリシーを作成し、認可されたアカウントのみが変更できるようにします。",
            "2": "CloudFormationテンプレートの変更時にトリガーされるAWS Lambda関数を設定し、すべてのターゲットアカウントとリージョンでStackSetを自動的に更新します。",
            "3": "クロスアカウントアクセスのために必要なIAMロールと権限を持つCloudFormation StackSetを作成します。StackSetを使用して、すべてのターゲットアカウントとリージョンに変更をデプロイします。",
            "4": "CloudFormation Guardを利用して、デプロイ前にテンプレートを検証し、すべてのアカウントで会社のポリシーと基準に準拠していることを確認します。",
            "5": "AWS Management Consoleを使用して、各アカウントとリージョンにCloudFormationテンプレートを手動でデプロイし、すべての変更が正しく適用されることを確認します。"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "クロスアカウントアクセスのために必要なIAMロールと権限を持つCloudFormation StackSetを作成します。StackSetを使用して、すべてのターゲットアカウントとリージョンに変更をデプロイします。",
            "CloudFormationテンプレートの変更時にトリガーされるAWS Lambda関数を設定し、すべてのターゲットアカウントとリージョンでStackSetを自動的に更新します。"
        ],
        "Explanation": "CloudFormation StackSetsを使用することで、複数のアカウントとリージョンにわたってCloudFormationテンプレートを一貫してデプロイできます。正しいオプションは、StackSetsの機能を活用して変更を包括的に伝播し、Lambdaを介してプロセスを自動化し、手動介入を最小限に抑えます。",
        "Other Options": [
            "CloudFormation Guardを使用して検証することは良いプラクティスですが、アカウントとリージョン間での変更の伝播という要件には直接対応していません。これは、デプロイメントよりもコンプライアンスチェックに重点を置いています。",
            "各アカウントとリージョンにテンプレートを手動でデプロイすることは非効率的でエラーが発生しやすく、かなりの手動作業を必要とし、StackSetsの自動化機能を活用していません。",
            "AWS Organizationsを通じてサービスコントロールポリシーを実装することはガバナンスに役立ちますが、CloudFormationの変更をアカウントとリージョン間で伝播させることを促進するものではなく、ここでの主な要件です。"
        ]
    },
    {
        "Question Number": "52",
        "Situation": "ソフトウェア開発チームは、AWS CodeBuildを利用してCodeCommitに保存されているアプリケーションのビルドプロセスを自動化しています。彼らは最新のビルドステータスを反映したビルドバッジを組み込み、公開URLを通じてアクセスできるようにしたいと考えています。さらに、プルリクエスト（PR）のビルドをトリガーし、ビルド結果に基づいてPRを更新する機能も必要です。DevOpsエンジニアは、これらの要件が効率的に満たされるようにする必要があります。",
        "Question": "DevOpsエンジニアは、AWSサービスを使用してビルドバッジを実装し、PRビルドプロセスを自動化するにはどうすればよいですか？",
        "Options": {
            "1": "各ブランチでCodeBuildのビルドバッジを有効にするが、PRビルドとその結果を処理するために手動プロセスに依存する。",
            "2": "AWS Lambdaを利用して各コミットのビルドバッジを手動で作成し、CloudWatch Eventsを使用してPRのビルドをトリガーするが、PRのステータスは更新しない。",
            "3": "ビルドステータスを表示するためのスタンドアロンWebアプリケーションを作成し、CodePipelineを使用してPRビルドを管理するが、PRの自動更新は行わない。",
            "4": "CodeBuildプロジェクトを設定してビルドバッジを生成し、EventBridgeを使用して新しいPRのビルドをトリガーし、ビルドステータスでPRを更新する。"
        },
        "Correct Answer": "CodeBuildプロジェクトを設定してビルドバッジを生成し、EventBridgeを使用して新しいPRのビルドをトリガーし、ビルドステータスでPRを更新する。",
        "Explanation": "このオプションは、AWSサービスを効果的に活用して要件に直接対応しています。CodeBuildを設定してビルドバッジを作成し、EventBridgeを使用してビルドのトリガーとPRの更新を自動化することで、効率的でスムーズなワークフローを確保します。",
        "Other Options": [
            "このオプションはビルドバッジを手動で作成するアプローチを提案しており、非効率的で自動化の目標に反します。さらに、ビルド後にPRのステータスを更新することが含まれていません。",
            "このオプションはビルドバッジを有効にしますが、PRビルドを処理するために手動プロセスに依存しており、自動化とPRステータスの動的更新の要件を満たしていません。",
            "このオプションはステータスを表示するための別のアプリケーションを構築することを提案しており、不要な複雑さを加え、ビルドプロセスとPR更新を自動化するためのAWSサービスの組み込み機能を活用していません。"
        ]
    },
    {
        "Question Number": "53",
        "Situation": "医療機関がアプリケーションをAWSに移行しており、機密患者データへのアクセスが効果的に管理されることを確保する必要があります。彼らは、ユーザーの役割やデータの特定の属性に基づいてアクセスを許可するセキュリティモデルを実装したいと考えています。この組織はAWS IAMを使用してアイデンティティ管理を行っており、コンプライアンス基準を満たし、無許可のアクセスリスクを最小限に抑えるソリューションを採用する必要があります。DevOpsエンジニアは、このアクセス制御メカニズムの実装を任されています。",
        "Question": "組織のAWSリソースに対して、役割ベースおよび属性ベースのアクセス制御パターンを最も適切に実装するソリューションはどれですか？",
        "Options": {
            "1": "各ユーザーグループのためにIAMロールを定義し、組織単位に基づいてリソースへのアクセスを制限するアカウントレベルのポリシーを管理するためにAWS Organizationsを実装します。",
            "2": "特定の権限を持つIAMロールを作成し、部門やセキュリティクリアランスなどのユーザー属性に基づいてアクセスを制限するリソースベースのポリシーを適用します。",
            "3": "AWS SSOを使用してユーザーグループを作成し、役割に基づいて権限を付与し、AWS Resource Access Managerを活用してアカウント間でリソースを共有します。",
            "4": "ユーザーの役割と属性の両方を利用して、機密リソースへのアクセス制限を強制する詳細なアクセス制御ポリシーを使用してAWS IAMを実装します。"
        },
        "Correct Answer": "ユーザーの役割と属性の両方を利用して、機密リソースへのアクセス制限を強制する詳細なアクセス制御ポリシーを使用してAWS IAMを実装します。",
        "Explanation": "このオプションは、ユーザー属性や役割に基づいて条件を指定できる詳細なアクセス制御ポリシーを作成するAWS IAMの能力を活用することで、包括的なアプローチを可能にします。これにより、医療分野のコンプライアンス要件に適した堅牢なセキュリティモデルが確保されます。",
        "Other Options": [
            "このオプションはリソースベースのポリシーに焦点を当てていますが、組織のニーズにとって重要な属性ベースのアクセス制御を強制するAWS IAMの機能を完全には活用していません。",
            "このオプションはアカウントレベルでの権限管理を効果的に行っていますが、ユーザー属性に基づく特定のリソースに対する詳細なアクセス制御の必要性には対応していません。",
            "このオプションは属性ベースのアクセス制御を統合しておらず、AWS SSOは主にグループベースの権限を扱うため、ユーザー属性に基づくアクセス制御に必要な詳細さが欠けています。"
        ]
    },
    {
        "Question Number": "54",
        "Situation": "クラウドソリューションアーキテクトは、大規模アプリケーションのためにAWS CloudFormationスタックを管理する任務を負っています。アーキテクトは、スタックの変更中に特定の重要なリソースが誤って更新されないように保護する必要があります。また、アーキテクトは、より良い組織のためにネストスタックの使用を検討していますが、ベストプラクティスに従いたいと考えています。",
        "Question": "アーキテクトは、リソース保護を強化し、ネストスタックを効果的に管理するためにどのアプローチを取るべきですか？",
        "Options": {
            "1": "非重要リソースのみの更新を明示的に許可するスタックポリシーを定義します。ネストスタックの前にルートスタックが更新されることを確認します。",
            "2": "すべてのリソースの更新をデフォルトで拒否し、指定されたリソースの更新を許可するスタックポリシーを作成します。常にルートスタックを更新する前にネストスタックを更新します。",
            "3": "特定の重要なリソースを除くすべてのリソースの更新を許可するスタックポリシーを実装します。すべてのネストスタックが変更された後に親スタックを更新します。",
            "4": "指定された重要なリソースのみの更新を許可するスタックポリシーを設定します。ネストスタックの前にルートスタックの更新が行われることを確認します。"
        },
        "Correct Answer": "非重要リソースのみの更新を明示的に許可するスタックポリシーを定義します。ネストスタックの前にルートスタックが更新されることを確認します。",
        "Explanation": "非重要リソースのみの更新を明示的に許可するスタックポリシーを定義することで、アーキテクトは更新中に重要なリソースが保護されることを確保します。さらに、最初にルートスタックを更新することは、ネストスタックに関するベストプラクティスに沿っています。",
        "Other Options": [
            "このオプションは不正解です。すべてのリソースの更新を拒否するスタックポリシーを作成することは制限が厳しすぎて、非重要リソースの必要な更新を妨げる可能性があります。",
            "このオプションは不正解です。重要なリソースを除くすべてのリソースの更新を許可するスタックポリシーを実装することは十分な保護を提供せず、誤って変更される可能性があります。",
            "このオプションは不正解です。ネストスタックをルートスタックの前に更新することを提案しており、これはベストプラクティスではなく、依存関係の問題を引き起こす可能性があります。"
        ]
    },
    {
        "Question Number": "55",
        "Situation": "あなたは、従業員が既存の企業認証情報を使用してAWSリソースにアクセスできるようにするための企業アイデンティティフェデレーションソリューションを実装しています。あなたの会社はSAMLベースのアイデンティティプロバイダー（IdP）を使用しており、ソリューションがセキュリティとアクセス管理のベストプラクティスに準拠していることを確認したいと考えています。",
        "Question": "次の構成のうち、管理オーバーヘッドを最小限に抑えつつ、セキュリティを維持しながら一時的なAWS認証情報の使用を最もサポートするものはどれですか？",
        "Options": {
            "1": "短命のセッションにはSTS:AssumeRoleを使用し、長命のアクセスにはGetFederationTokenを使用します。",
            "2": "すべてのユーザーにGetFederationTokenを発行するカスタムフェデレーションプロキシを実装します。",
            "3": "一時的なアクセスのためにSAMLアサーションをIAMロールに直接マッピングするように構成します。",
            "4": "AWS Directory ServiceをSAMLと共に使用し、ロールの引き受けのみを構成します。"
        },
        "Correct Answer": "一時的なアクセスのためにSAMLアサーションをIAMロールに直接マッピングするように構成します。",
        "Explanation": "SAMLアサーションをIAMロールに直接マッピングすることで、既存の企業認証情報を活用しながらAWSリソースへのシームレスな一時的アクセスが可能になります。この方法は、ユーザーが必要な権限のみを持つことを保証し、別々のトークン生成の必要を排除することでアクセス管理を簡素化するため、セキュリティのベストプラクティスをサポートします。",
        "Other Options": [
            "AWS Directory ServiceをSAMLと共に使用し、ロールの引き受けのみを構成することは、短命の認証情報の利点を十分に活用せず、ロールを別々に管理する際の管理オーバーヘッドの増加を招く可能性があります。",
            "すべてのユーザーにGetFederationTokenを発行するカスタムフェデレーションプロキシを実装すると、アーキテクチャが複雑になり、トークンの有効期限や権限の追加管理が必要になるため、管理の手間が増えます。",
            "短命のセッションにはSTS:AssumeRoleを使用し、長命のアクセスにはGetFederationTokenを使用することは、2つの異なるアクセス方法を管理する際に不必要な複雑さを生じさせ、混乱や管理オーバーヘッドの増加を招く可能性があります。"
        ]
    },
    {
        "Question Number": "56",
        "Situation": "ある金融サービス会社が、トランザクショナルデータベースをAWSに移行しています。彼らは、高速で信頼性が高く、コスト効果のあるデータベースソリューションを必要としており、高可用性と耐障害性も確保する必要があります。会社は、データが増加するにつれて自動バックアップ、時点復元、シームレスなスケーリングを可能にするソリューションを実装する必要があります。セキュリティも大きな懸念事項であり、データベースは転送中および静止中の暗号化をサポートしなければなりません。これらの要件を考慮して、会社はAmazon Auroraをデータベースソリューションとして検討しています。",
        "Question": "DevOpsエンジニアとして、Amazon Auroraを使用するための会社の要件を最も満たす構成はどれですか？",
        "Options": {
            "1": "アクセスを簡素化するためにVPCの外にAmazon Aurora MySQL互換エディションのデータベースインスタンスを作成します。自動バックアップと時点復元を無効にし、暗号化メカニズムを実装しません。",
            "2": "バックアップと復元オプションなしでVPC内にAmazon Aurora PostgreSQL互換エディションのデータベースを設定します。データベースが暗号化されておらず、SSLを使用しないことを確認します。アプリケーションは安全な内部ネットワークで実行されます。",
            "3": "自動バックアップを有効にしたVPC内にAmazon Aurora MySQL互換エディションのデータベースを展開します。転送中のデータを安全にするためにSSLを構成し、KMSを使用して静止中の暗号化を有効にします。Auroraレプリカを使用して、パフォーマンスに影響を与えずに読み取りトラフィックを処理します。",
            "4": "Multi-AZデプロイメントのAmazon Aurora MySQL互換エディションのデータベースを使用しますが、バックアップや復元オプションは構成しません。アクセスを容易にするためにデータベースインスタンスをパブリックサブネットに保持します。"
        },
        "Correct Answer": "自動バックアップを有効にしたVPC内にAmazon Aurora MySQL互換エディションのデータベースを展開します。転送中のデータを安全にするためにSSLを構成し、KMSを使用して静止中の暗号化を有効にします。Auroraレプリカを使用して、パフォーマンスに影響を与えずに読み取りトラフィックを処理します。",
        "Explanation": "このオプションは、Amazon AuroraデータベースがVPC内で安全に展開され、自動バックアップと時点復元が可能であることを保証します。また、SSLを利用してデータの送信を安全にし、KMSを使用して静止中の暗号化を実施し、信頼性、セキュリティ、パフォーマンスのすべての要件を満たします。",
        "Other Options": [
            "このオプションは、MySQLの代わりにPostgreSQL互換エディションを使用しており、トランザクショナルデータベースにとって重要なバックアップおよび復元機能が欠けているため、不正解です。",
            "このオプションは、データベースをVPCの外に展開することを指定しており、セキュリティのベストプラクティスに準拠していません。さらに、自動バックアップと暗号化を無効にすることで、データ損失とセキュリティの重大なリスクを生じさせます。",
            "このオプションは、データベースインスタンスをパブリックサブネットに保持することで、潜在的なセキュリティ脅威にさらすことになります。さらに、バックアップと復元オプションを無効にすることは、トランザクショナルデータベースには推奨されません。"
        ]
    },
    {
        "Question Number": "57",
        "Situation": "ある金融サービス会社が、オンラインバンキングプラットフォームのトラフィックパターンが変動しています。プラットフォームは、ピーク使用時に高可用性とパフォーマンスを維持し、低トラフィック期間中のコストを最小限に抑える必要があります。会社は、アプリケーションロードバランサー（ALB）の背後にあるAmazon EC2インスタンスを使用して、受信リクエストを処理しています。DevOpsエンジニアは、リアルタイムのトラフィック変化に効果的に対応するオートスケーリングソリューションを実装する任務を負っています。",
        "Question": "エンジニアがレジリエントなアーキテクチャを実現するために実装すべきオートスケーリングおよびロードバランシング戦略はどれですか？",
        "Options": {
            "1": "オートスケーリンググループのサイズを固定し、スケーリングアクションなしでトラフィックを処理するためにネットワークロードバランサー（NLB）を使用し、インスタンスが常に利用可能であることを保証します。",
            "2": "オートスケーリンググループをCloudWatchメトリクス（CPU使用率やリクエスト数など）に基づく動的スケーリングポリシーを使用するように構成し、ALBと統合してインスタンス間でトラフィックを均等に分配します。",
            "3": "ビジネス時間中にEC2インスタンスの数を増やし、オフ時間中に減らすためにスケジュールされたスケーリングアクションを利用し、トラフィック分配のためにALBに依存します。",
            "4": "オートスケーリングなしで単一のEC2インスタンスを実装し、すべてのトラフィックをルーティングするためにALBを使用し、リクエストを処理するために常に1つのインスタンスが利用可能であることを保証します。"
        },
        "Correct Answer": "オートスケーリンググループをCloudWatchメトリクス（CPU使用率やリクエスト数など）に基づく動的スケーリングポリシーを使用するように構成し、ALBと統合してインスタンス間でトラフィックを均等に分配します。",
        "Explanation": "このオプションは、リアルタイムのトラフィックパターンに応じて調整する動的なスケーリングアプローチを提供し、CloudWatchメトリクスを利用してEC2インスタンスを追加または削除するタイミングを判断し、高可用性と効率的なリソース使用を確保します。",
        "Other Options": [
            "このオプションは、トラフィックパターンに基づくスケーリングを許可しないため、リソースの過少供給または過剰供給を引き起こし、パフォーマンスの低下や不必要なコストを招く可能性があります。",
            "スケジュールされたスケーリングは予測可能なトラフィックパターンには効果的ですが、リアルタイムのトラフィックの変化には対応できず、予期しないピーク時にパフォーマンスの問題を引き起こす可能性があります。",
            "オートスケーリングなしで単一のインスタンスに依存することは、単一障害点を生じさせます。そのインスタンスがダウンすると、プラットフォームは利用できなくなり、高可用性が損なわれます。"
        ]
    },
    {
        "Question Number": "58",
        "Situation": "サーバーレスアプリケーションは、AWS Lambda関数を使用してAmazon Kinesisストリームからの受信イベントを処理しています。アプリケーションはトラフィックの増加を経験し、Lambda関数の呼び出しが急増しています。",
        "Question": "アプリケーションがデフォルトのAWS Lambdaサービス制限を遵守しながら、増加した負荷に対応できるようにするためには何をすべきですか？",
        "Options": {
            "1": "AWS Step Functionsを有効にしてLambda関数をオーケストレーションし、同時実行数を増やします。",
            "2": "Lambda関数内にスロットリングメカニズムを実装して、同時実行数を管理します。",
            "3": "地域内のAWS Lambdaに許可される最大同時実行数のサービスクォータの増加をリクエストします。",
            "4": "アプリケーションを再設計して、AWS Lambdaの代わりにAmazon ECSを使用し、より良い同時実行処理を行います。"
        },
        "Correct Answer": "地域内のAWS Lambdaに許可される最大同時実行数のサービスクォータの増加をリクエストします。",
        "Explanation": "AWS Lambdaの同時実行のデフォルト制限は、地域ごとに1000です。増加した負荷に効果的に対応するためには、サービスクォータの増加リクエストを行い、この制限を引き上げることで、スロットリングなしでより多くの同時実行を可能にします。",
        "Other Options": [
            "スロットリングメカニズムを実装することで負荷を管理することは可能ですが、同時実行数の実際の制限を増やすことはできず、イベント処理の遅延を引き起こす可能性があります。",
            "アプリケーションを再設計してAmazon ECSを使用することで、より良い同時実行処理が可能になるかもしれませんが、サーバーレスモデルから逸脱し、クォータの増加で十分な場合に不必要な複雑さを加えます。",
            "AWS Step Functionsを有効にすることでLambda関数のオーケストレーションが助けられますが、同時実行制限を直接増やすことはできず、イベント処理に追加のレイテンシをもたらす可能性があります。"
        ]
    },
    {
        "Question Number": "59",
        "Situation": "ある金融サービス会社が、複数のアベイラビリティゾーン（AZ）で高可用性と低レイテンシを必要とするWebアプリケーションをAWSクラウドにデプロイしています。DevOpsチームは、ピーク時にダウンタイムを最小限に抑え、ユーザー体験を向上させるために、地域間でトラフィックが効率的にバランスされるようにアプリケーションを構成する必要があります。",
        "Question": "DevOpsチームは、クロスAZサービスのロードバランシングを最も効果的に構成するために何をすべきですか？",
        "Options": {
            "1": "各AZにアプリケーションロードバランサー（ALB）をデプロイし、WebアプリケーションのEC2インスタンスをそれぞれのALBに登録して、クロスゾーンロードバランシングを有効にします。",
            "2": "AWS Global Acceleratorを使用したネットワークロードバランサー（NLB）を使用して、複数の地域にトラフィックを分散し、高可用性とレジリエンスを確保します。",
            "3": "Amazon Route 53の加重ルーティングポリシーを構成して、複数のAZにトラフィックを誘導し、オートスケーリンググループを使用してインスタンスのヘルスとスケーリングを管理します。",
            "4": "Amazon CloudFrontディストリビューションを実装してコンテンツをキャッシュし、ユーザーリクエストを最寄りの地域にルーティングし、動的コンテンツのためにアプリケーションロードバランサーと統合します。"
        },
        "Correct Answer": "各AZにアプリケーションロードバランサー（ALB）をデプロイし、WebアプリケーションのEC2インスタンスをそれぞれのALBに登録して、クロスゾーンロードバランシングを有効にします。",
        "Explanation": "各アベイラビリティゾーンにアプリケーションロードバランサーをデプロイし、EC2インスタンスを登録することで、DevOpsチームは異なるAZの複数のインスタンスにアプリケーショントラフィックを分散させ、トラフィックの急増時に高可用性とフォールトトレランスを確保できます。",
        "Other Options": [
            "AWS Global Acceleratorを使用したネットワークロードバランサーは、HTTP/HTTPSよりもTCP/UDPトラフィックに適しているため、AZ間でアプリケーションレベルのロードバランシングを必要とするWebアプリケーションには最適ではありません。",
            "Amazon CloudFrontディストリビューションを実装することは主にコンテンツ配信とキャッシュに焦点を当てており、複数のAZにわたる動的Webアプリケーションリクエストのトラフィックを効果的にバランスさせることはできません。",
            "Amazon Route 53の加重ルーティングポリシーを構成することは主にDNSレベルのトラフィック管理のためであり、Webアプリケーションのためにアプリケーションロードバランサーが提供するアクティブなヘルスチェックやインテリジェントなトラフィック分配機能を提供しません。"
        ]
    },
    {
        "Question Number": "60",
        "Situation": "ある金融サービス会社が、高可用性と低レイテンシを必要とする新しいアプリケーションをデプロイしています。このアプリケーションは、耐障害性を確保し、潜在的な障害から迅速に回復するために、複数のAWSリージョンにホストされます。会社は現在、Amazon EC2インスタンスとAmazon RDSをデータベースニーズに使用しています。彼らは、自動フェイルオーバーを可能にし、ユーザーのダウンタイムを最小限に抑える戦略を実装したいと考えています。",
        "Question": "地域の障害が発生した場合にダウンタイムを最小限に抑えながら、アプリケーションに最高の可用性を提供するための構成はどれですか？",
        "Options": {
            "1": "アプリケーションの前にAmazon CloudFrontディストリビューションを設定してコンテンツをキャッシュします。Route 53を使用して静的コンテンツのためにS3バケットにトラフィックを誘導し、データベースのために単一のマルチAZデプロイメントを持つAmazon RDSを実装します。",
            "2": "アプリケーションを3つのAWSリージョンにデプロイし、Amazon Route 53を使用してフェイルオーバールーティングポリシーを適用し、プライマリリージョンが利用できない場合にスタンバイリージョンにトラフィックをリダイレクトします。データベースにはクロスリージョンレプリカを持つAmazon RDSを利用します。",
            "3": "AWS Global Acceleratorを利用して2つのAWSリージョンにアプリケーションをデプロイします。Route 53をレイテンシベースのルーティングで構成して、ユーザーリクエストを最寄りのリージョンに誘導し、データベースにはクロスリージョンリードレプリカを使用します。",
            "4": "単一のリージョンにAmazon Elastic Load Balancerを実装してトラフィックを複数のEC2インスタンスに分配し、そのリージョン内でデータベースの可用性を確保するためにマルチAZデプロイメントを持つAmazon RDSを構成します。"
        },
        "Correct Answer": "アプリケーションを3つのAWSリージョンにデプロイし、Amazon Route 53を使用してフェイルオーバールーティングポリシーを適用し、プライマリリージョンが利用できない場合にスタンバイリージョンにトラフィックをリダイレクトします。データベースにはクロスリージョンレプリカを持つAmazon RDSを利用します。",
        "Explanation": "アプリケーションを3つのAWSリージョンにデプロイし、Route 53のフェイルオーバールーティングを使用し、Amazon RDSのクロスリージョンレプリカを利用することで、1つのリージョンが障害を起こした場合でも、トラフィックがシームレスにスタンバイリージョンにリダイレクトされ、ダウンタイムを最小限に抑え、高可用性を維持できます。",
        "Other Options": [
            "AWS Global Acceleratorとレイテンシベースのルーティングを使用して2つのAWSリージョンにアプリケーションをデプロイすることは有益ですが、フェイルオーバールーティングを使用して3つのリージョンにデプロイするのと同じレベルの冗長性とフェイルオーバー機能を提供しません。",
            "CloudFrontディストリビューションを設定し、トラフィックをS3バケットに誘導することは、アプリケーションの可用性を1つのリージョンに制限し、自動フェイルオーバーや地域的な障害に対する耐障害性を提供しません。",
            "Elastic Load BalancerとマルチAZ RDSデプロイメントを使用して単一のリージョンを利用することは、そのリージョン内での可用性を提供しますが、地域的な障害に対する保護を提供せず、高可用性には重要です。"
        ]
    },
    {
        "Question Number": "61",
        "Situation": "ある金融サービス会社が、可用性と回復力を高めるためにアプリケーションをAWSに移行しています。彼らは、障害が発生した場合に自動的にフェイルオーバーを処理し、最小限のダウンタイムを確保できるソリューションを必要としています。会社は、高可用性を実現するために、複数のAWSリージョンでアプリケーションを実行することを期待しています。彼らは、データベースのレプリケーションとフェイルオーバーのためのさまざまな戦略を検討しています。これらの要件を満たすために、どの戦略を実装すべきでしょうか？",
        "Question": "次のうち、マルチリージョンのフェイルオーバーと最小限のダウンタイムを提供する最も回復力のあるデータベース戦略はどれですか？",
        "Options": {
            "1": "1つのリージョンにAmazon RDSのマルチAZデプロイメントを作成し、別のリージョンで手動バックアップを使用します。",
            "2": "Amazon Auroraをクロスリージョンレプリケーションで実装し、自動フェイルオーバーを設定します。",
            "3": "1つのリージョンに単一のAmazon RDSインスタンスをデプロイし、別のリージョンにリードレプリカを配置します。",
            "4": "Amazon DynamoDBを使用してグローバルテーブルを作成し、複数のリージョンで自動レプリケーションを確保します。"
        },
        "Correct Answer": "Amazon Auroraをクロスリージョンレプリケーションで実装し、自動フェイルオーバーを設定します。",
        "Explanation": "Amazon Auroraのクロスリージョンレプリケーションは、自動フェイルオーバーを可能にし、複数のリージョンで高可用性を提供し、回復力と最小限のダウンタイムの要件を効果的に満たします。",
        "Other Options": [
            "単一のAmazon RDSインスタンスをリードレプリカとともにデプロイすることは、自動フェイルオーバーを提供せず、手動介入に依存するため、最小限のダウンタイムの要件に反します。",
            "Amazon DynamoDBのグローバルテーブルは自動レプリケーションを提供しますが、特に複雑なトランザクションやリレーショナル機能を必要とするデータベースワークロードには適さない場合があります。",
            "1つのリージョンにAmazon RDSのマルチAZデプロイメントを作成することは、そのリージョン内の障害に対してのみ保護を提供し、別のリージョンへのフェイルオーバー機能を提供しないため、マルチリージョンの要件を満たしていません。"
        ]
    },
    {
        "Question Number": "62",
        "Situation": "ある組織が、AWS環境内で発生するAPIコールやイベントをログするためにAWS CloudTrailを実装しました。彼らは、そのログに基づいて疑わしい活動を自動的に検出し、そのような活動が検出された場合にセキュリティチームに通知したいと考えています。DevOpsエンジニアは、この要件に対して効果的なソリューションを確立する必要があります。",
        "Question": "AWS CloudTrailログに基づいて疑わしい活動をタイムリーに検出し通知するために、エンジニアはどのアプローチを取るべきですか？",
        "Options": {
            "1": "定期的にCloudTrailログをチェックして異常を検出し、見つかった場合にセキュリティチームにアラートを送信するスケジュールされたAWS Lambda関数を作成します。",
            "2": "Amazon GuardDutyを有効にしてCloudTrailログを分析し、検出された問題をセキュリティチームに通知します。",
            "3": "特定のパターンをCloudTrailログで探し、セキュリティチームに通知を送信するAWS Lambda関数をトリガーするAmazon CloudWatch Logsのサブスクリプションフィルターを設定します。",
            "4": "AWS Configルールを使用してCloudTrailログの変更を監視し、非準拠の変更が検出された場合にアラートを送信します。"
        },
        "Correct Answer": "特定のパターンをCloudTrailログで探し、セキュリティチームに通知を送信するAWS Lambda関数をトリガーするAmazon CloudWatch Logsのサブスクリプションフィルターを設定します。",
        "Explanation": "CloudWatch Logsのサブスクリプションフィルターを使用することで、特定のAPIコールパターンをリアルタイムで検出し、自動化されたLambda関数を通じて即座に対応できます。このアプローチは、疑わしい活動に関するセキュリティチームへのタイムリーで直接的な通知を提供します。",
        "Other Options": [
            "スケジュールされたLambda関数を作成することは、サブスクリプションフィルターを使用するよりもタイムリーではなく、指定された間隔でのみログをチェックするため、インシデントへの対応が遅れる可能性があります。",
            "AWS Configルールは主にコンプライアンス監視に使用され、CloudTrailログ内のAPIコール異常のリアルタイム検出機能を提供しません。",
            "GuardDutyは脅威検出に効果的ですが、追加のサービスであり、CloudTrailログに特化しているわけではなく、カスタムイベント通知の即時性を提供しない可能性があります。"
        ]
    },
    {
        "Question Number": "63",
        "Situation": "DevOpsチームは、アプリケーションログをリアルタイムで監視し、迅速に問題を特定して対応する責任があります。彼らは、さまざまなソースからログを取り込み、処理し、アラートや分析のために利用可能にするソリューションを実装する必要があります。チームは、これを達成するためにAWSサービスを利用することを決定しました。",
        "Question": "リアルタイムのログ取り込みに最も効率的でスケーラブルなソリューションを提供するアーキテクチャはどれですか？",
        "Options": {
            "1": "Amazon CloudWatch Logsを設定して、ソースから直接ログを取り込みます。CloudWatch Log Groupを作成し、アラート用にAmazon SNSトピックにログを送信するサブスクリプションフィルターを構成します。",
            "2": "カスタムログシッパーを実行するAmazon EC2インスタンスをデプロイし、ファイルシステムからログファイルを読み取り、Amazon S3にアップロードします。Amazon Athenaを使用してS3に保存されたログをクエリします。",
            "3": "アプリケーションインスタンスから直接ログファイルをアップロードしてAmazon S3を使用してログを取り込みます。S3イベントによってトリガーされるAWS Lambda関数を使用してログを処理し、Amazon DynamoDBに保存します。",
            "4": "Amazon Kinesis Data Streamsを使用して、複数のソースからリアルタイムでログを取り込みます。AWS Lambdaを設定してログを処理し、Amazon S3に保存し、Amazon Elasticsearch Serviceで検索と分析を行います。"
        },
        "Correct Answer": "Amazon Kinesis Data Streamsを使用して、複数のソースからリアルタイムでログを取り込みます。AWS Lambdaを設定してログを処理し、Amazon S3に保存し、Amazon Elasticsearch Serviceで検索と分析を行います。",
        "Explanation": "Amazon Kinesis Data Streamsを使用することで、さまざまなソースからの高スループットのリアルタイムログ取り込みを効果的に処理できます。ログのボリュームが増加してもスケーラビリティを確保し、AWS Lambdaとのシームレスな統合により、Amazon S3およびAmazon Elasticsearch Serviceを介してアラートや分析のために即座にアクセスできるようになります。",
        "Other Options": [
            "このオプションは、CloudWatch Logsのリアルタイム処理能力に制限されており、複数のソースからのログを効果的にスケールまたは処理する柔軟性が欠けています。",
            "このアプローチは、S3へのファイルアップロードに依存しており、レイテンシを引き起こし、真のリアルタイムではありません。さらに、DynamoDBはログデータに特化した他のサービスと比較して、ログの保存とクエリには適していません。",
            "EC2インスタンスを使用してログを送信することは、追加の管理オーバーヘッドとスケーリング時のボトルネックを引き起こす可能性があり、Kinesisが提供するリアルタイム取り込み機能が欠けています。"
        ]
    },
    {
        "Question Number": "64",
        "Situation": "ある企業がAWS SAMを使用してサーバーレスアプリケーションを開発しており、デプロイメントパイプラインが効率的で、アプリケーションのインフラストラクチャに変更をデプロイする際のエラーの可能性を減らすことを望んでいます。チームは現在、SAM CLIコマンドを使用してアプリケーションを手動でデプロイしており、これが環境間の不一致を引き起こし、リリースサイクルを遅くしています。",
        "Question": "次の戦略のうち、複数の環境間での一貫性を確保しながらサーバーレスアプリケーションのデプロイを自動化するために最も効果的なものはどれですか？",
        "Options": {
            "1": "SAM CLIコマンドを自動化するシェルスクリプトを書き、AWS Lambdaを使用してアプリケーションをパッケージ化しデプロイするために毎日実行するようにスケジュールします。",
            "2": "AWS CloudFormation StackSetsを設定して、AWS SAMを利用してインフラストラクチャをコードとして複数のアカウントとリージョンにサーバーレスアプリケーションをデプロイします。",
            "3": "AWS CodeBuildを利用して、各デプロイメントのビルドプロジェクトで手動でSAM CLIコマンドを実行し、デプロイ前にSAMアプリケーションが正しくパッケージ化されていることを確認します。",
            "4": "AWS CodePipelineを使用してCI/CDパイプラインを作成し、AWS SAMアプリケーションをパッケージ化するビルドステージを含め、AWS CloudFormationを使用してデプロイします。"
        },
        "Correct Answer": "AWS CodePipelineを使用してCI/CDパイプラインを作成し、AWS SAMアプリケーションをパッケージ化するビルドステージを含め、AWS CloudFormationを使用してデプロイします。",
        "Explanation": "AWS CodePipelineを使用してCI/CDパイプラインを作成することで、一貫した自動化されたデプロイメントプロセスが可能になり、人為的エラーの可能性が減少し、すべての変更が制御された方法でデプロイされることが保証されます。このアプローチは、インフラストラクチャをコードとして効果的に管理するためにAWS SAMおよびCloudFormationとよく統合されます。",
        "Other Options": [
            "AWS CodeBuildを使用して手動でSAM CLIコマンドを実行することは、手動プロセスによるエラーのリスクを引き起こし、効率的または自動化されたデプロイメントパイプラインを提供しません。",
            "AWS CloudFormation StackSetsは主に複数のアカウントとリージョンにリソースをデプロイするために使用されますが、単一のアプリケーションデプロイには必要ない場合があり、このシナリオにはあまり適していません。",
            "SAM CLIコマンドを自動化するシェルスクリプトを書くことは最適な解決策ではなく、管理が難しく、バージョン管理やロールバック機能などのCI/CDパイプラインの堅牢な機能が欠けています。"
        ]
    },
    {
        "Question Number": "65",
        "Situation": "金融サービス会社がマイクロサービスベースのアプリケーションを開発しており、継続的インテグレーションと継続的デプロイメント（CI/CD）が必要です。このアプリケーションは、複数のサービスで構成されており、コンテナ化されてリポジトリに保存されています。会社は、各サービスが適切にバージョン管理され、アーティファクトがデプロイメントのために簡単にアクセスできることを確保したいと考えています。DevOpsエンジニアは、これらのリソースを効率的に管理できるコード、イメージ、アーティファクトリポジトリの設定を任されています。",
        "Question": "エンジニアは、コード、イメージ、アーティファクトのストレージとバージョン管理を最も効果的に自動化するために、どのソリューションを実装すべきですか？",
        "Options": {
            "1": "ソースコードにはAWS CodeCommitを、DockerイメージにはAmazon ECRを、ソフトウェアアーティファクトの管理にはAWS CodeArtifactを使用します。",
            "2": "ソースコードにはGitHubを、DockerイメージにはAWS S3を、ソフトウェアアーティファクトの管理にはAWS CodePipelineを使用します。",
            "3": "ソースコードにはAWS CodeCommitを、DockerイメージにはAmazon ECRを、ソフトウェアアーティファクトの管理にはAWS S3を使用します。",
            "4": "ソースコードにはAWS CodeCommitを、DockerイメージにはAWS S3を、ソフトウェアアーティファクトの管理にはAWS CodeDeployを使用します。"
        },
        "Correct Answer": "ソースコードにはAWS CodeCommitを、DockerイメージにはAmazon ECRを、ソフトウェアアーティファクトの管理にはAWS CodeArtifactを使用します。",
        "Explanation": "このソリューションは、コード、イメージ、アーティファクトを扱うために特別に設計されたAWSサービスを効果的に活用しています。AWS CodeCommitは、安全でスケーラブルなソース管理サービスを提供し、Amazon ECRはDockerイメージの簡単な保存と取得を可能にする完全管理型のDockerコンテナレジストリです。また、AWS CodeArtifactは、複数のパッケージ形式をサポートする完全管理型のアーティファクトリポジトリサービスであり、ソフトウェアアーティファクトの管理に最適です。",
        "Other Options": [
            "ソースコードにGitHubを使用すると外部依存関係が生じ、CodeCommitと比較して他のAWSサービスとの統合がスムーズでない可能性があります。さらに、DockerイメージにAWS S3を使用するのは最適ではなく、ECRはその目的のために特別に設計されています。",
            "AWS S3はDockerイメージの保存には適しておらず、Amazon ECRが提供するバージョン管理やライフサイクルポリシーのような機能が欠けています。CodeDeployは主にデプロイメントのためのものであり、アーティファクト管理にはあまり効果的ではありません。",
            "ソフトウェアアーティファクトの管理にS3を使用すると、AWS CodeArtifactが提供するバージョン管理や依存関係管理に必要な機能が不足し、アーティファクトの管理に非効率をもたらす可能性があります。"
        ]
    },
    {
        "Question Number": "66",
        "Situation": "ある企業がアプリケーションをAWSに移行しており、信頼性とスケーラビリティを向上させるためのデプロイメント戦略を評価しています。DevOpsチームは、アプリケーションの整合性を維持しながら、開発と運用プロセスを効率化するために、可変デプロイメントパターンと不変デプロイメントパターンを検討しています。",
        "Question": "SDLC自動化の文脈における可変デプロイメントパターンと不変デプロイメントパターンの違いを最もよく説明しているのは次のうちどれですか？",
        "Options": {
            "1": "可変デプロイメントパターンはマイクロサービスアーキテクチャに好まれ、不変デプロイメントパターンはモノリシックアプリケーションに最適です。",
            "2": "不変デプロイメントパターンは既存のインスタンスを更新することを可能にし、可変デプロイメントパターンはすべてのデプロイメントに対して新しいインスタンスを作成します。",
            "3": "可変デプロイメントパターンと不変デプロイメントパターンの両方は、各デプロイメントプロセスに対して手動の介入を必要とします。",
            "4": "可変デプロイメントパターンは既存のインスタンスを更新することを可能にし、不変デプロイメントパターンはすべてのデプロイメントに対して新しいインスタンスを作成します。"
        },
        "Correct Answer": "可変デプロイメントパターンは既存のインスタンスを更新することを可能にし、不変デプロイメントパターンはすべてのデプロイメントに対して新しいインスタンスを作成します。",
        "Explanation": "可変デプロイメントパターンは既存のインスタンスに直接変更を加えることを可能にし、時間の経過とともに不整合が生じる可能性があります。それに対して、不変デプロイメントパターンは各デプロイメントが新しいインスタンスを作成することを保証し、エラーのリスクを減少させ、明確なバージョン履歴を提供します。",
        "Other Options": [
            "この記述は不正確です。可変デプロイメントパターンと不変デプロイメントパターンの定義を逆にしています。可変デプロイメントは既存のインスタンスを変更し、不変デプロイメントは各更新のためにまったく新しいインスタンスを作成します。",
            "この記述は不正確です。デプロイメントパターンを誤って特徴付けています。可変デプロイメントパターンはマイクロサービスアーキテクチャを好むわけではなく、さまざまなアーキテクチャで使用できますが、不変パターンが軽減できるリスクをもたらす可能性があります。",
            "この記述は不正確です。可変デプロイメントパターンと不変デプロイメントパターンの両方は、かなりの程度まで自動化でき、現代のCI/CDパイプラインにおける手動の介入の必要性を減少させます。"
        ]
    },
    {
        "Question Number": "67",
        "Situation": "ある組織が、オンプレミスのサーバーとAWS EC2インスタンスで構成されるハイブリッドクラウド環境を管理しています。この組織は、すべてのEC2インスタンスがインスタンスプロファイルロールを割り当てることなく、AWS Systems Managerに管理インスタンスとして自動的に登録されることを確保する必要があります。また、すべての管理インスタンスで一貫した構成を維持したいと考えています。AWS Systems Managerのデフォルトホスト構成を使用して、これを達成するための最良の方法は何ですか？",
        "Question": "DevOpsエンジニアは、EC2インスタンスをSystems Managerに自動的に登録するためにデフォルトホスト構成を有効にするために、次のどのアクションを取るべきですか？",
        "Options": {
            "1": "希望するAWSリージョンでDHMCを有効にし、すべてのEC2インスタンスでIMDSv2が有効になっていることを確認します。",
            "2": "SSM用のEC2インスタンスプロファイルロールを設定し、各インスタンスを自動的にSSMエージェントを更新するように構成します。",
            "3": "オンプレミスのサーバー用にハイブリッドアクティベーションを展開し、すべてのインスタンスに対してアクティベーションコードとIDを使用してSSMエージェントを構成します。",
            "4": "各EC2インスタンスにSSMエージェントを手動でインストールし、その後IAMロールを使用してSystems Managerに登録します。"
        },
        "Correct Answer": "希望するAWSリージョンでDHMCを有効にし、すべてのEC2インスタンスでIMDSv2が有効になっていることを確認します。",
        "Explanation": "希望するAWSリージョンでデフォルトホスト構成（DHMC）を有効にすることで、特定のインスタンスプロファイルロールを必要とせずにEC2インスタンスをSystems Managerに自動的に登録でき、IMDSv2を使用してセキュリティを強化することができます。これは、Systems ManagerでEC2インスタンスを管理するための最も効率的な方法です。",
        "Other Options": [
            "このオプションは不正解です。SSMエージェントを手動でインストールし、IAMロールを使用することは、追加の構成なしで登録プロセスを自動化するために設計されたDHMCを利用していません。",
            "このオプションは不正解です。ハイブリッドアクティベーションを展開することは、EC2インスタンスには不要であり、DHMCを通じて自動的に登録できます。ハイブリッドアクティベーションは、オンプレミスのサーバーにより関連性があります。",
            "このオプションは不正解です。EC2インスタンスを使用する際にEC2インスタンスプロファイルロールを設定する必要はなく、DHMCを使用することで自動登録のためのインスタンスプロファイルロールの要件が排除されます。"
        ]
    },
    {
        "Question Number": "68",
        "Situation": "金融機関のセキュリティチームは、IAMユーザーのログインイベントを記録するAWS CloudTrailログの整合性を確保する任務を負っています。彼らはus-east-1リージョンでCloudTrailを有効にし、ログファイルが配信後に改ざんされていないことを確認したいと考えています。セキュリティ体制を強化するために、これらのログファイルの整合性に関する保証を提供するAWSの機能を利用する必要があります。",
        "Question": "セキュリティチームは、CloudTrailログファイルの整合性を検証するために次のどの方法を使用すべきですか？",
        "Options": {
            "1": "AWS Lambda関数を定期的に実行してCloudTrailログのタイムスタンプを現在の時間と照合し、変更されていないことを確認します。",
            "2": "CloudTrailログファイル整合性検証を実装し、SHA-256ハッシュとRSAデジタル署名を利用して、ログファイルが配信後に変更されていないことを確認します。",
            "3": "CloudTrailログが保存されているバケットでAmazon S3バージョニングを有効にし、変更が検出された場合にログの以前のバージョンを復元できるようにします。",
            "4": "AWS Configルールを設定してCloudTrailログファイルの変更を監視し、変更が検出された場合にチームに通知します。"
        },
        "Correct Answer": "CloudTrailログファイル整合性検証を実装し、SHA-256ハッシュとRSAデジタル署名を利用して、ログファイルが配信後に変更されていないことを確認します。",
        "Explanation": "CloudTrailログファイル整合性検証は、ログファイルが配信後に改ざんされていないことを確認する方法を提供します。この機能は、SHA-256をハッシュ化に、RSAを署名に使用し、ログファイルの真正性と整合性を確保します。",
        "Other Options": [
            "AWS Configルールはリソースの変更を監視できますが、配信後のCloudTrailログの整合性を直接検証するものではないため、このオプションは特定のユースケースには適していません。",
            "AWS Lambda関数を使用してタイムスタンプを確認することは、ログファイルの整合性を検証するための堅牢な解決策を提供せず、ログが変更されたかどうかを確認するものではなく、単に最近のものであることを確認するだけです。",
            "Amazon S3バージョニングを有効にすることで、チームはログの以前のバージョンを復元できますが、ログの整合性を検証する方法を本質的に提供するものではなく、これはコンプライアンスとセキュリティにとって重要です。"
        ]
    },
    {
        "Question Number": "69",
        "Situation": "ある会社が、ユーザーがアップロードしたファイルをAmazon S3に保存するサーバーレスアプリケーションを開発しています。このアプリケーションは、バケットとオブジェクトのバージョンを管理し、ファイルアップロードのためのバケット通知を設定し、認可されたユーザーのみがファイルにアクセスできるようにする必要があります。DevOpsエンジニアは、S3 APIを使用してこれらの機能を実装しなければなりません。",
        "Question": "DevOpsエンジニアは、S3バケットとその内容を効果的に管理するための要件を満たすために、次のどのアクションを取るべきですか？",
        "Options": {
            "1": "s3api put-bucket-aclコマンドを使用してバケットのアクセス制御リストを設定し、s3api head-objectコマンドを使用してオブジェクトの権限を確認します。",
            "2": "s3api rbコマンドを使用してバケットを削除し、s3api mvコマンドを使用してオブジェクトをバケット間で移動させて管理を改善します。",
            "3": "s3api put-bucket-versioningコマンドを使用してバケットでバージョニングを有効にし、s3api put-bucket-notification-configurationコマンドを使用してオブジェクトアップロードの通知を設定します。",
            "4": "s3api mbコマンドを使用してバケットを作成し、s3 syncコマンドを使用してバケット内のオブジェクトのアップロードとバージョニングを管理します。"
        },
        "Correct Answer": "s3api put-bucket-versioningコマンドを使用してバケットでバージョニングを有効にし、s3api put-bucket-notification-configurationコマンドを使用してオブジェクトアップロードの通知を設定します。",
        "Explanation": "put-bucket-versioningコマンドを使用してバケットでバージョニングを有効にすることで、変更を追跡し、オブジェクトの以前のバージョンを復元できます。put-bucket-notification-configurationを使用してバケット通知を設定することで、アプリケーションが新しいアップロードに適切に応答できるようになります。",
        "Other Options": [
            "mbコマンドを使用してバケットを作成し、syncコマンドでアップロードを管理することは、バージョニングと通知の要件に対処しておらず、このユースケースには重要です。",
            "put-bucket-aclでアクセス制御リストを設定することは権限にとって重要ですが、アプリケーションを効果的に管理するために必要なバージョニングと通知の主要な要件を満たしていません。",
            "rbコマンドでバケットを削除し、mvでオブジェクトを移動することは、アップロードを管理し、S3環境内でファイルのバージョンを維持するという目標に合致しないため、逆効果です。"
        ]
    },
    {
        "Question Number": "70",
        "Situation": "DevOpsエンジニアは、パフォーマンス監視とトラブルシューティングのためにAmazon S3に保存されたアプリケーションログを分析する必要があります。ログは大きく、エンジニアはそれらに対してSQLのようなクエリを効率的に実行したいと考えています。ソリューションはコストを最小限に抑え、複雑なETLプロセスを必要とせずにログから迅速な洞察を提供する必要があります。",
        "Question": "エンジニアがS3ログをSQLのようなクエリを使用して効率的に分析できるAWSサービスの組み合わせはどれですか？",
        "Options": {
            "1": "AWS Lambdaを利用してログデータをリアルタイムで処理し、結果をAmazon RDSに保存してSQLクエリを実行します。",
            "2": "AWS Glueを使用してログのデータカタログを作成し、Amazon Redshiftを実行してカタログ化されたデータに対してSQLクエリを実行します。",
            "3": "Amazon EMRを実装してログを処理し、Apache Hiveを使用してSQLクエリを実行し、結果を再びS3に保存します。",
            "4": "Amazon Athenaを設定してS3のログを直接クエリし、Amazon QuickSightを使用してクエリ結果の可視化を行います。"
        },
        "Correct Answer": "Amazon Athenaを設定してS3のログを直接クエリし、Amazon QuickSightを使用してクエリ結果の可視化を行います。",
        "Explanation": "Amazon Athenaを使用すると、標準SQLを使用してS3に保存されたデータを直接クエリでき、実行したクエリに対してのみ料金が発生するため、コスト効率が良いです。Amazon QuickSightとの統合により、データの効果的な可視化が可能になり、追加のインフラ管理のオーバーヘッドなしで迅速な洞察を提供します。",
        "Other Options": [
            "AWS GlueとAmazon Redshiftを使用すると、データカタログの作成と別のデータウェアハウスの維持に追加コストが発生し、S3ログを直接クエリするには効率が悪くなります。",
            "Amazon EMRを使用してログを処理するのは、このユースケースには必要以上に複雑でコストがかかります。特にAthenaはクラスター管理のオーバーヘッドなしでS3クエリを直接処理できます。",
            "AWS Lambdaを利用してリアルタイムでログを処理し、結果をAmazon RDSに保存するのは不必要な複雑さとコストを追加します。これは、単純なログ分析には必要ないLambda関数とRDSインスタンスの継続的な運用を必要とします。"
        ]
    },
    {
        "Question Number": "71",
        "Situation": "ある会社は、アプリケーションデータベースとしてAmazon DynamoDBを利用しています。アプリケーションは、パーティションキーとセカンダリアトリビュートの両方に基づいてデータを効率的にクエリする能力を必要としています。開発チームは、データストレージコストを抑えながら読み取りパフォーマンスを最適化するための適切なインデックスオプションを検討しています。",
        "Question": "開発チームがテーブル作成時にのみ作成できることを保証しながら、セカンダリアトリビュートに基づく効率的なクエリを可能にするために、どのインデックス戦略を実装すべきですか？",
        "Options": {
            "1": "セカンダリアトリビュートに基づく効率的なクエリを可能にするために、代替パーティションキーを持つグローバルセカンダリインデックスを実装します。",
            "2": "テーブルが確立された後に作成できるグローバルセカンダリインデックスを使用し、アプリケーションの進化に応じてインデックス戦略を変更できるようにします。",
            "3": "パーティションキーとセカンダリアトリビュートを新しいソートキーとして含むローカルセカンダリインデックスを作成し、テーブル作成時に効率的なクエリを保証します。",
            "4": "最終的に一貫性のある読み取りを可能にするローカルセカンダリインデックスを設定しますが、セカンダリアトリビュートに基づくクエリは許可されません。"
        },
        "Correct Answer": "パーティションキーとセカンダリアトリビュートを新しいソートキーとして含むローカルセカンダリインデックスを作成し、テーブル作成時に効率的なクエリを保証します。",
        "Explanation": "ローカルセカンダリインデックス（LSI）は、パーティションキーと異なるソートキーに基づいてインデックスを作成でき、セカンダリアトリビュートに対する効率的なクエリを可能にします。LSIはテーブル作成時に定義する必要があり、開発チームの要件に適合します。",
        "Other Options": [
            "グローバルセカンダリインデックス（GSI）はいつでも作成できますが、テーブル作成時に作成されるという要件を満たさないため、不適切な選択です。",
            "GSIはセカンダリアトリビュートに基づくクエリを許可しますが、テーブル作成時に作成されるという要件を満たさず、別々の読み取り/書き込みキャパシティユニットによるコスト増加を引き起こす可能性があります。",
            "ローカルセカンダリインデックスを設定することで効率的なクエリが可能ですが、セカンダリアトリビュートに基づくクエリを許可しないという記述は誤りです。LSIは確かにパーティションキーと代替ソートキーに基づくクエリを許可します。"
        ]
    },
    {
        "Question Number": "72",
        "Situation": "ある金融サービス会社は、異なる部門のために複数のAWSアカウントを管理しており、それぞれが独自のリソースとコンプライアンス要件を持っています。DevOpsチームは、すべてのアカウントでのコンプライアンスとセキュリティを確保しながら、インフラストラクチャの一貫した展開を可能にする構成管理ソリューションを実装したいと考えています。",
        "Question": "複数のAWSアカウントでインフラストラクチャをコードとして管理するために、コンプライアンス、セキュリティ、運用効率の最良のバランスを提供するアプローチはどれですか？",
        "Options": {
            "1": "AWS CodePipelineを手動承認付きで実装し、デプロイ後に各アカウントでコンプライアンスを確認するためにAWS Lambdaに依存します。",
            "2": "AWS Organizationsを活用し、各アカウントにAWS Configルールを設定してコンプライアンスを強制し、すべてのインフラストラクチャデプロイメントにAWS CloudFormationを使用します。",
            "3": "各アカウントに個別のCloudFormationスタックを作成し、インフラ変更の手動更新を行い、手動レビューを通じてコンプライアンスを確保します。",
            "4": "AWS CloudFormation StackSetsを利用して複数のアカウントにテンプレートを展開し、セキュリティコンプライアンスのためにサービスコントロールポリシー（SCP）を実装します。"
        },
        "Correct Answer": "AWS CloudFormation StackSetsを利用して複数のアカウントにテンプレートを展開し、セキュリティコンプライアンスのためにサービスコントロールポリシー（SCP）を実装します。",
        "Explanation": "AWS CloudFormation StackSetsを使用すると、複数のアカウントにわたるインフラストラクチャデプロイメントを集中管理でき、サービスコントロールポリシー（SCP）を通じてコンプライアンスを強制できます。このアプローチは、更新を効率化し、アカウント間の一貫性を確保し、セキュリティと運用効率を向上させます。",
        "Other Options": [
            "各アカウントに個別のCloudFormationスタックを作成すると、運用オーバーヘッドが増加し、一貫性のリスクが高まります。これは手動更新とレビューに大きく依存し、コンプライアンスのギャップを引き起こす可能性があります。",
            "AWS OrganizationsとAWS Configルールはコンプライアンスを強化しますが、AWS Configを通じてインフラを管理するだけではデプロイプロセスが複雑になり、StackSetsを使用するよりも効率が悪くなります。",
            "AWS CodePipelineを手動承認付きで実装すると、デプロイプロセスに不必要な遅延が生じ、デプロイ前に一貫したコンプライアンスチェックを提供しないため、非準拠のリソースがプロビジョニングされる可能性があります。"
        ]
    },
    {
        "Question Number": "73",
        "Situation": "ある企業が最近、アプリケーションインフラストラクチャをAWSに移行し、AWS OpsWorksを使用して構成管理を行っています。彼らは、Chefを利用して構成を管理し、デプロイプロセスを自動化しながら、アプリケーションが複数のEC2インスタンスに適切にデプロイされることを確実にしたいと考えています。DevOpsエンジニアは、すべてのリソースが効率的に管理され、アプリケーションが負荷に応じてスケールできることを確認する必要があります。",
        "Question": "DevOpsエンジニアは、アプリケーションの構成がすべてのコンピュートユニットに一貫して適用され、定義されたレシピに基づいて変更が動的に管理されることを確実にするために、主にどのAWS OpsWorksコンポーネントに焦点を当てるべきですか？",
        "Options": {
            "1": "OpsWorks Layerは、リソースのグループに関連する機能と特徴を整理します。",
            "2": "OpsWorks Applicationは、インスタンスにデプロイされるアプリケーションを指定します。",
            "3": "OpsWorks Agentは、インスタンスを構成するためにChefレシピを実行します。",
            "4": "OpsWorks Stackは、アプリケーションのリソースのコレクションを定義します。"
        },
        "Correct Answer": "OpsWorks Agentは、インスタンスを構成するためにChefレシピを実行します。",
        "Explanation": "OpsWorks Agentは、インスタンスがどのように構成されるべきかを定義するChefレシピを実行する責任があります。このコンポーネントは、すべてのインスタンスにわたって構成が一貫して適用されることを確保し、これは自動化とインフラストラクチャの望ましい状態を維持するために重要です。",
        "Other Options": [
            "OpsWorks Stackはリソースのコレクションを定義しますが、構成の実行を直接管理することはありません。",
            "OpsWorks Layerはリソースのグループに関連する機能を整理しますが、構成を実行することはありません。",
            "OpsWorks Applicationはデプロイされるアプリケーションを指定しますが、インスタンスの構成管理には責任を持ちません。"
        ]
    },
    {
        "Question Number": "74",
        "Situation": "あるグローバルなeコマース企業が、AWS CodePipelineとAWS CodeBuildを使用してウェブアプリケーションのCI/CDパイプラインを統合しました。DevOpsエンジニアは、プロダクションにデプロイする前にコード変更を検証するために、自動テストがパイプラインの一部であることを確実にする必要があります。チームは、単体テスト、統合テスト、パフォーマンステストを効果的に実装したいと考えています。",
        "Question": "DevOpsエンジニアは、テストが適切な順序で実行され、結果が明確に報告されることを保証しながら、自動テストをCI/CDパイプラインに統合するためにどのアプローチを取るべきですか？",
        "Options": {
            "1": "CodePipelineのデプロイメントフェーズ内でテストを組み込み、すべてのテストを同時に実行してコード変更に対する迅速なフィードバックを可能にします。",
            "2": "CodePipelineにテストフェーズを追加し、最初に単体テストを実行し、その後に統合テスト、最後にパフォーマンステストを実行し、各フェーズが成功する必要があることを保証します。",
            "3": "AWS Lambdaを利用してCodeBuildのビルドフェーズ中にテストを並行して実行し、異なるテストタイプの独立した実行を可能にします。",
            "4": "テスト用に別のCodePipelineを作成し、すべてのコード変更でトリガーされるようにし、メインのデプロイメントパイプラインの外で独立したテストを可能にします。"
        },
        "Correct Answer": "CodePipelineにテストフェーズを追加し、最初に単体テストを実行し、その後に統合テスト、最後にパフォーマンステストを実行し、各フェーズが成功する必要があることを保証します。",
        "Explanation": "このアプローチは、テストが論理的な順序で実行されることを保証し、問題の早期発見を可能にします。また、各ステージでの結果の明確な報告を提供し、プロダクションに到達する前にアプリケーションの全体的な品質を向上させます。",
        "Other Options": [
            "デプロイメントフェーズ中にすべてのテストを同時に実行すると、結果が不明瞭になる可能性があります。どのテストが失敗した場合、どのテストが失敗の原因であるかが不明確になり、トラブルシューティングが複雑になります。",
            "AWS Lambdaを使用してテストを並行して実行することは迅速な実行を提供するかもしれませんが、順次アプローチが提供する明確さと構造化された報告が欠ける可能性があります。さらに、Lambdaは特定の環境を必要とするテストタイプには適していない場合があります。",
            "テスト用に別のCodePipelineを作成すると、テストがデプロイメントプロセスから切り離される可能性がありますが、コード変更に対するフィードバックの遅延を引き起こす可能性があります。また、開発者が2つの別々のパイプラインを監視する必要があるため、複雑さが増します。"
        ]
    },
    {
        "Question Number": "75",
        "Situation": "DevOpsエンジニアは、AWS上の動的アプリケーション環境のためにインフラストラクチャをコードとして管理する（IaC）任務を担っています。チームは、コードを使用してインフラストラクチャを定義、プロビジョニング、管理できるソリューションを必要としており、構成変更が追跡され、バージョン管理されることを確実にする必要があります。",
        "Question": "DevOpsエンジニアは、インフラストラクチャをコードとして管理し、構成管理の要件を満たすためにどのソリューションを実装すべきですか？",
        "Options": {
            "1": "AWS Elastic Beanstalkをデプロイしてアプリケーション環境を管理します。Elastic Beanstalk CLIを使用してアプリケーションの構成を定義し、更新を管理します。",
            "2": "AWS OpsWorksを実装してChefを使用してアプリケーションスタックを管理します。Chefサーバーを使用して構成管理を行い、レシピのバージョン管理を維持します。",
            "3": "AWS CloudFormationを使用して、JSONまたはYAMLでインフラストラクチャをコードとして定義します。テンプレートをAWS CodeCommitのようなバージョン管理システムに保存して、変更を追跡し、コラボレーションを行います。",
            "4": "Amazon EC2 User Dataスクリプトを利用して、起動時にインスタンスを構成します。スクリプトをAWS S3に保持し、新しいインスタンスが作成されるたびに適用します。"
        },
        "Correct Answer": "AWS CloudFormationを使用して、JSONまたはYAMLでインフラストラクチャをコードとして定義します。テンプレートをAWS CodeCommitのようなバージョン管理システムに保存して、変更を追跡し、コラボレーションを行います。",
        "Explanation": "AWS CloudFormationは、インフラストラクチャをコードとして管理するための最適な選択です。JSONまたはYAMLを使用して宣言的にリソースを定義でき、バージョン管理システムとシームレスに統合されるため、変更を追跡しやすく、コラボレーションが容易です。",
        "Other Options": [
            "Amazon EC2 User Dataスクリプトは、起動時にインスタンスを構成する方法を提供しますが、完全なインフラストラクチャをコードとして管理するソリューションを提供しません。変更を効果的に追跡する能力が欠けており、CloudFormationと同じレベルのリソース管理やバージョン管理を提供しません。",
            "AWS OpsWorksは、Chefに依存する構成管理サービスであり、Chefに慣れていないチームには不必要な複雑さを加える可能性があります。レシピのバージョン管理を提供しますが、CloudFormationと比較してインフラストラクチャをコードとして定義および管理するための柔軟性はありません。",
            "AWS Elastic Beanstalkは、アプリケーションをデプロイおよび管理するために設計されており、インフラストラクチャをコードとして直接管理するためのものではありません。アプリケーションのデプロイを簡素化しますが、AWS CloudFormationが提供するようなインフラストラクチャ定義に対する制御のレベルは提供しません。"
        ]
    }
]