[
    {
        "Question Number": "1",
        "Situation": "한 회사가 AWS에서 실행되는 마이크로서비스 기반 애플리케이션을 개발하고 있습니다. 각 마이크로서비스는 느슨하게 결합되도록 설계되었으며 독립적으로 배포됩니다. 회사는 높은 가용성과 장애에 대한 복원력을 보장하는 것을 목표로 하고 있습니다. 현재 서비스는 동기식으로 통신하고 있으며, 이로 인해 지연 시간이 증가하고 사용자 경험이 저하되었습니다. DevOps 엔지니어는 애플리케이션의 복원력과 응답성을 개선하는 임무를 맡고 있습니다.",
        "Question": "복원력을 향상시키기 위해 DevOps 엔지니어가 구현해야 할 아키텍처 변경의 조합은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "모든 마이크로서비스를 단일 가용 영역에 배포하여 네트워크 지연 시간을 줄입니다.",
            "2": "Amazon SNS를 활용하여 마이크로서비스 간의 이벤트 기반 알림을 통해 응답성을 개선합니다.",
            "3": "Amazon SQS를 구현하여 마이크로서비스를 분리하고 비동기 통신을 가능하게 합니다.",
            "4": "모든 마이크로서비스에 대해 공유 데이터베이스를 구현하여 데이터 접근 및 관리를 단순화합니다.",
            "5": "Amazon API Gateway를 사용하여 모든 API 요청을 관리하고 속도 제한 기능을 제공합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon SQS를 구현하여 마이크로서비스를 분리하고 비동기 통신을 가능하게 합니다.",
            "Amazon SNS를 활용하여 마이크로서비스 간의 이벤트 기반 알림을 통해 응답성을 개선합니다."
        ],
        "Explanation": "Amazon SQS를 구현하면 마이크로서비스가 비동기적으로 통신할 수 있어 직접적인 의존성을 줄이고 복원력을 향상시킵니다. Amazon SNS를 활용하면 이벤트 기반 아키텍처를 통해 통신 모델이 향상되어 서비스가 동기 호출에 의존하지 않고 이벤트에 반응할 수 있게 되어 지연 시간이 감소하고 응답성이 증가합니다.",
        "Other Options": [
            "Amazon API Gateway를 사용하는 것은 API 관리를 위한 이점이 있지만 복원력을 본질적으로 개선하거나 서비스를 분리하지 않습니다. 주로 라우팅 및 보안에 중점을 둡니다.",
            "공유 데이터베이스는 마이크로서비스 간의 긴밀한 결합을 생성하여 느슨한 결합의 목적을 무너뜨리고 단일 실패 지점을 초래할 수 있어 복원력을 저해합니다.",
            "모든 마이크로서비스를 단일 가용 영역에 배포하면 영역 장애로 인한 다운타임 위험이 증가하여 높은 가용성을 달성하려는 목표에 반합니다."
        ]
    },
    {
        "Question Number": "2",
        "Situation": "대규모 조직이 여러 AWS 계정에서 IAM 권한을 관리하기 위한 새로운 정책을 구현하고 있습니다. 그들의 운영 복잡성으로 인해 개별 팀이 과도한 접근 권한을 부여하지 않고 자신의 권한을 관리할 수 있도록 해야 합니다. 그들은 이러한 정책을 시행하기 위해 IAM 권한 경계를 사용하기로 결정했습니다. 보안 팀은 권한 경계가 준수 요구 사항을 충족하도록 올바르게 설정되었는지 확인하고 싶어합니다.",
        "Question": "조직의 보안 정책 준수를 보장하면서 IAM 권한 관리를 위임하기 위해 권한 경계를 효과적으로 구현할 수 있는 접근 방식은 무엇입니까?",
        "Options": {
            "1": "IAM 역할에 대해 허용되는 최대 권한을 정의하는 권한 경계 정책을 생성합니다. 이 정책을 모든 계정 내 IAM 역할에 연결하여 지정된 권한을 초과할 수 없도록 합니다. 각 팀이 경계를 준수하면서 자신의 역할을 생성하고 관리할 수 있도록 필요한 권한을 제공합니다.",
            "2": "모든 계정에 대해 모든 AWS 서비스에 대한 전체 접근 권한을 부여하는 단일 IAM 정책을 생성합니다. 모든 팀이 경계 없이 IAM 역할과 정책을 관리할 수 있도록 하여 그들이 준수 요구 사항을 준수할 것이라고 믿습니다.",
            "3": "AWS Organizations에서 관리 계정을 설정하고 서비스 제어 정책(SCP)을 사용하여 모든 계정에서 권한을 시행합니다. 각 팀이 제한 없이 IAM 정책을 생성할 수 있도록 하여 SCP에만 의존합니다.",
            "4": "AWS CloudFormation StackSets를 활용하여 모든 계정에 공통 IAM 권한 경계 템플릿을 배포합니다. 각 팀의 IAM 역할이 이 템플릿을 사용하여 생성되도록 하여 정의된 권한 한계를 시행합니다."
        },
        "Correct Answer": "IAM 역할에 대해 허용되는 최대 권한을 정의하는 권한 경계 정책을 생성합니다. 이 정책을 모든 계정 내 IAM 역할에 연결하여 지정된 권한을 초과할 수 없도록 합니다. 각 팀이 경계를 준수하면서 자신의 역할을 생성하고 관리할 수 있도록 필요한 권한을 제공합니다.",
        "Explanation": "이 접근 방식은 권한 경계를 효과적으로 활용하여 각 팀의 역할 관리가 보안 팀이 설정한 한도 내에서 제한되도록 합니다. 이는 위임된 관리를 허용하면서 조직의 정책 준수를 시행합니다.",
        "Other Options": [
            "이 옵션은 서비스 제어 정책(SCP)에만 의존하며 권한 경계가 제공하는 필요한 세부 제어를 제공하지 않습니다. SCP는 접근을 제한할 수 있지만 개별 역할에 대해 어떤 권한이 가능한지를 정의하지 않습니다.",
            "이 옵션은 모든 팀에 과도한 권한을 부여하며 경계가 없으므로 상당한 보안 위험을 초래합니다. 강제된 제한 없이 팀이 준수하도록 의존하는 것은 건전한 보안 관행이 아닙니다.",
            "CloudFormation StackSets를 권한 경계에 사용하는 것은 올바른 방향으로 나아가는 단계이지만 권한 경계 개념을 직접 구현하지는 않습니다. IAM 역할에 대한 최대 권한을 정의하는 데 필요한 구체성이 부족합니다."
        ]
    },
    {
        "Question Number": "3",
        "Situation": "한 회사가 EC2 인스턴스의 성능을 모니터링하고 CPU 사용량에 따라 자동으로 확장할 수 있도록 하기를 원합니다. 평균 CPU 사용량이 지정된 임계값을 초과할 때 확장 작업을 트리거하기 위해 CloudWatch 경고를 설정해야 합니다. DevOps 엔지니어는 경고가 올바르게 구성되어 적절한 작업을 시작할 수 있도록 해야 합니다.",
        "Question": "다음 구성 중 CloudWatch 경고가 Auto Scaling 그룹의 CPU 사용량에 따라 확장 작업을 적절히 시작하도록 보장하는 구성은 무엇입니까?",
        "Options": {
            "1": "CPU 사용량 메트릭에 대해 여러 개의 CloudWatch 경고를 구성하여 각 경고가 확장 작업을 위해 서로 다른 SNS 주제로 알림을 보냅니다. 지역에 관계없이.",
            "2": "CPU 사용량을 모니터링하고 경고 상태가 OK로 변경될 때만 Auto Scaling 작업을 호출하는 단일 CloudWatch 경고를 생성합니다.",
            "3": "CPU 사용량을 추적하는 CloudWatch 경고를 설정하고 경고의 상태 변경을 사용하여 동일한 지역 내에서 Auto Scaling 그룹에 대한 필요한 확장 정책을 직접 실행합니다.",
            "4": "CPU 사용량에 대한 CloudWatch 경고를 생성하여 임계값이 초과될 때 팀에 알리기 위해 SNS 알림을 트리거하지만 확장 작업을 시작하지는 않습니다."
        },
        "Correct Answer": "CPU 사용량을 추적하는 CloudWatch 경고를 설정하고 경고의 상태 변경을 사용하여 동일한 지역 내에서 Auto Scaling 그룹에 대한 필요한 확장 정책을 직접 실행합니다.",
        "Explanation": "이 구성은 CloudWatch 경고가 경고의 상태 변경(예: OK에서 ALARM으로) 기반으로 확장 작업을 직접 호출할 수 있도록 하여 Auto Scaling 그룹을 효과적으로 관리하는 데 필수적입니다. 경고는 제어하려는 Auto Scaling 그룹과 동일한 지역에 있어야 합니다.",
        "Other Options": [
            "이 옵션은 알림만 보내고 어떤 확장 작업도 트리거하지 않으므로 필요한 기능에는 충분하지 않습니다.",
            "이 옵션은 경고의 목적을 올바르게 설명하지만 경고가 적절히 구성된 확장 정책을 통해 작업을 시작해야 한다는 점을 명시하지 않으므로 자동 확장을 위해 중요합니다.",
            "이 옵션은 여러 개의 경고와 SNS 주제를 구성하여 불필요한 복잡성을 생성하며, 이는 효율적이지 않습니다. 또한 SNS 알림만으로는 확장 작업을 트리거할 수 없으며, 확장 정책과 통합되어야 합니다."
        ]
    },
    {
        "Question Number": "4",
        "Situation": "소프트웨어 개발 팀이 AWS에서 CI/CD 파이프라인을 도입하여 애플리케이션 배포 프로세스를 간소화하고 있습니다. 그들은 코드 품질을 유지하고 보안 문제를 해결하며 애플리케이션 기능을 검증하기 위해 다양한 유형의 테스트가 파이프라인 내에 효과적으로 통합되도록 해야 합니다. 팀은 소프트웨어 개발 생명 주기(SDLC)를 자동화하기 위한 다양한 테스트 전략을 고려하고 있습니다.",
        "Question": "팀이 개발 프로세스 초기에 취약점을 식별하고 불안전한 코드 배포 가능성을 최소화하기 위해 우선적으로 고려해야 할 테스트 전략은 무엇입니까?",
        "Options": {
            "1": "CI/CD 파이프라인의 일환으로 보안 스캔을 수행하여 코드베이스의 취약점을 식별합니다.",
            "2": "사용자 인터페이스 테스트를 수행하여 애플리케이션이 디자인 및 사용성 요구 사항을 충족하는지 확인합니다.",
            "3": "통합 테스트를 사용하여 애플리케이션의 다양한 구성 요소가 예상대로 함께 작동하는지 검증합니다.",
            "4": "단위 테스트를 구현하여 개별 구성 요소의 기능적 정확성을 검증합니다."
        },
        "Correct Answer": "CI/CD 파이프라인의 일환으로 보안 스캔을 수행하여 코드베이스의 취약점을 식별합니다.",
        "Explanation": "CI/CD 파이프라인에서 보안 스캔을 수행하면 취약점을 조기에 발견할 수 있어 안전한 코드베이스를 유지하고 프로덕션 환경에서의 잠재적 악용을 방지하는 데 중요합니다.",
        "Other Options": [
            "단위 테스트를 구현하는 것은 주로 개별 구성 요소의 기능을 테스트하는 데 집중하지만 보안 취약점을 다루지 않으므로 불안전한 코드가 배포될 수 있습니다.",
            "통합 테스트를 사용하면 구성 요소가 잘 작동하는지 확인할 수 있지만 일반적으로 단위 테스트 후에 수행되며 개발 생명 주기 초기에 보안 문제를 구체적으로 다루지 않습니다.",
            "사용자 인터페이스 테스트를 수행하는 것은 사용성에 필수적이지만 기본 코드의 보안 취약점을 식별하지 않으므로 불안전한 배포를 방지하는 데 덜 중요합니다."
        ]
    },
    {
        "Question Number": "5",
        "Situation": "한 회사는 Amazon EC2 인스턴스의 집합에 의존하고 있으며, 이 인스턴스들은 준수 및 성능을 모니터링하고 관리해야 합니다. DevOps 팀은 모든 인스턴스가 최신 패치 및 구성으로 업데이트되도록 하는 임무를 맡고 있습니다. 그들은 인스턴스가 원하는 상태에서 벗어날 때 자동으로 준수 검사를 수행하고 수정할 수 있는 솔루션을 구현하고자 합니다.",
        "Question": "DevOps 팀이 EC2 인스턴스의 준수 및 패치 관리를 가장 효과적으로 수행하는 방법은 무엇입니까?",
        "Options": {
            "1": "EC2 인스턴스의 패치 준수 및 구성 드리프트 관리를 위해 서드파티 도구를 구현합니다. 정기적인 스캔을 예약하고 도구의 결과에 따라 패치를 적용합니다.",
            "2": "AWS Config를 활용하여 EC2 인스턴스의 구성을 모니터링하고 AWS Systems Manager Run Command를 사용하여 비준수가 감지될 때 수동으로 패치를 적용합니다. 정기적으로 구성을 검토하여 준수를 보장합니다.",
            "3": "AWS Systems Manager Patch Manager를 사용하여 EC2 인스턴스의 패치 프로세스를 자동화합니다. 필요한 패치 버전을 정의하는 패치 기준선을 만들고 패치 프로세스가 정기적으로 발생하도록 예약합니다. Systems Manager 준수 대시보드를 사용하여 준수를 모니터링합니다.",
            "4": "AWS Lambda 함수를 설정하여 EC2 인스턴스의 준수를 주기적으로 확인하고 필요에 따라 패치를 적용합니다. Amazon CloudWatch Events를 사용하여 일정에 따라 Lambda 함수를 트리거합니다."
        },
        "Correct Answer": "AWS Systems Manager Patch Manager를 사용하여 EC2 인스턴스의 패치 프로세스를 자동화합니다. 필요한 패치 버전을 정의하는 패치 기준선을 만들고 패치 프로세스가 정기적으로 발생하도록 예약합니다. Systems Manager 준수 대시보드를 사용하여 준수를 모니터링합니다.",
        "Explanation": "AWS Systems Manager Patch Manager를 사용하는 것은 EC2 인스턴스의 패치 관리를 자동화하기 위해 특별히 설계된 최상의 접근 방식입니다. 패치 기준선을 정의하고 정기적인 패치 일정을 설정하며 Systems Manager 대시보드를 통해 준수를 모니터링할 수 있어 인스턴스가 최소한의 수동 개입으로 안전하고 준수 상태를 유지할 수 있습니다.",
        "Other Options": [
            "준수 검사를 위한 Lambda 함수를 설정하는 것은 추가적인 복잡성을 도입하며, Systems Manager Patch Manager가 제공하는 강력한 패치 관리 기능을 제공하지 않을 수 있습니다. 또한 패치 적용을 위해 Lambda 함수에만 의존하면 일관되지 않은 결과를 초래할 수 있습니다.",
            "AWS Config를 사용하여 준수를 모니터링하는 것은 Run Command를 통해 패치를 적용하기 위한 수동 개입이 필요하며, 자동화된 패치 관리 솔루션만큼 효율적이지 않습니다. 이 접근 방식은 보다 반응적이며 인스턴스가 더 오랜 기간 동안 취약할 수 있습니다.",
            "서드파티 도구를 구현하면 추가 기능을 제공할 수 있지만 불필요한 복잡성과 잠재적인 비용을 추가합니다. AWS Systems Manager Patch Manager는 다른 AWS 서비스와 원활하게 통합되는 네이티브 솔루션으로, 사용 및 관리가 더 용이합니다."
        ]
    },
    {
        "Question Number": "6",
        "Situation": "한 금융 서비스 회사가 애플리케이션 인프라를 AWS로 이전하고 있으며, 배포 및 관리 프로세스를 간소화하기 위해 코드로서의 인프라(IaC) 원칙을 채택하고자 합니다. 이 회사는 애플리케이션의 다양한 구성 요소에서 작업하는 여러 팀이 있으며, 여러 환경에서 인프라 변경을 관리하기 위한 일관된 전략이 필요합니다. DevOps 엔지니어는 일관성을 보장하고 오류를 줄이며 인프라 업데이트를 쉽게 할 수 있는 솔루션을 구현하는 임무를 맡고 있습니다. 엔지니어는 AWS 서비스와 IaC 기술을 최적으로 활용하는 접근 방식을 선택해야 합니다.",
        "Question": "DevOps 엔지니어가 여러 환경에서 일관성을 보장하면서 인프라 관리를 자동화하기 위해 구현해야 할 접근 방식은 무엇입니까?",
        "Options": {
            "1": "인프라 프로비저닝을 위해 Terraform을 구현하고, Terraform 구성 파일이 저장된 S3에서 감지된 변경 사항에 따라 업데이트를 트리거하기 위해 AWS Lambda를 사용합니다.",
            "2": "AWS CDK를 활용하여 프로그래밍 언어로 코드로서의 인프라를 정의합니다. AWS CloudFormation StackSets를 사용하여 여러 계정 및 리전에서 인프라 변경을 배포합니다.",
            "3": "애플리케이션 배포 및 관리를 위해 AWS Elastic Beanstalk를 사용하고, AWS Systems Manager를 사용하여 구성 매개변수 및 환경 설정을 관리합니다.",
            "4": "AWS CloudFormation과 중첩 스택을 활용하여 공통 구성 요소를 관리합니다. AWS CodePipeline을 사용하여 배포를 조정하고 여러 환경에서 인프라 업데이트를 유지합니다."
        },
        "Correct Answer": "AWS CDK를 활용하여 프로그래밍 언어로 코드로서의 인프라를 정의합니다. AWS CloudFormation StackSets를 사용하여 여러 계정 및 리전에서 인프라 변경을 배포합니다.",
        "Explanation": "AWS CDK를 사용하면 개발자가 친숙한 프로그래밍 언어로 인프라를 정의할 수 있어 팀 간의 협업이 개선됩니다. CloudFormation StackSets와 결합하면 이 접근 방식은 여러 계정 및 리전에서 인프라 변경의 일관된 배포를 가능하게 하여 복잡한 환경을 관리하는 데 매우 효율적인 솔루션이 됩니다.",
        "Other Options": [
            "AWS CloudFormation과 중첩 스택을 사용하는 것은 인프라 관리를 위한 좋은 구조를 제공하지만, 일반 프로그래밍 언어로 코딩을 선호하는 팀에게는 AWS CDK가 제공하는 유연성과 사용 용이성이 부족합니다.",
            "Terraform은 IaC를 위한 유능한 도구이지만, S3에서 변경 사항을 모니터링하기 위해 AWS Lambda를 사용하는 것은 불필요한 복잡성을 추가하며 AWS 서비스와 AWS CDK 및 CloudFormation만큼 원활하게 통합되지 않을 수 있습니다.",
            "AWS Elastic Beanstalk는 주로 인프라 관리를 추상화하는 플랫폼 서비스(PaaS) 솔루션으로, 자동화된 관리의 목표인 코드로서의 인프라 원칙을 구현하는 것과 완전히 일치하지 않습니다."
        ]
    },
    {
        "Question Number": "7",
        "Situation": "개발 팀이 AWS에 호스팅된 애플리케이션을 위한 CI/CD 파이프라인을 구현하고 있습니다. 팀은 코드, Docker 이미지 및 빌드 아티팩트를 관리하기 위한 강력한 솔루션을 구축해야 하며, 여러 환경에서 버전 관리 및 접근성을 보장해야 합니다. 복잡성과 운영 오버헤드를 최소화하고자 합니다.",
        "Question": "다음 솔루션 중 팀의 CI/CD 파이프라인에서 코드, 이미지 및 아티팩트를 관리하는 요구 사항을 가장 잘 충족하며 운영 오버헤드가 가장 적은 것은 무엇입니까?",
        "Options": {
            "1": "AWS CodePipeline과 AWS Lambda를 활용하여 코드, 이미지 및 아티팩트를 관리합니다.",
            "2": "자체 호스팅된 Git 서버, 개인 Docker 레지스트리 및 온프레미스 아티팩트 리포지토리를 구현합니다.",
            "3": "소스 코드를 위해 AWS CodeCommit, Docker 이미지를 위해 Amazon ECR, 빌드 아티팩트를 위해 AWS CodeArtifact를 활용합니다.",
            "4": "소스 코드를 위해 GitHub, 이미지를 위해 Docker Hub, 빌드 아티팩트를 저장하기 위해 S3 버킷을 사용합니다."
        },
        "Correct Answer": "소스 코드를 위해 AWS CodeCommit, Docker 이미지를 위해 Amazon ECR, 빌드 아티팩트를 위해 AWS CodeArtifact를 활용합니다.",
        "Explanation": "이 옵션은 AWS 생태계 내에서 완전히 통합된 솔루션을 제공하여 코드, 이미지 및 아티팩트의 원활한 버전 관리, 저장 및 검색을 보장합니다. 이러한 작업에 최적화된 관리형 서비스를 활용하여 운영 오버헤드를 최소화합니다.",
        "Other Options": [
            "GitHub를 사용하는 것은 AWS 서비스와 통합할 때 외부 종속성과 관리 복잡성을 도입합니다. Docker Hub는 개인 레포지토리에 대해 추가 구성이 필요할 수 있어 오버헤드를 증가시킵니다.",
            "Git, Docker 및 아티팩트에 대한 자체 호스팅 솔루션을 구현하는 것은 지속적인 유지 관리, 업데이트 및 인프라 관리를 요구하며, 이는 관리형 서비스를 사용하는 것에 비해 운영 복잡성을 추가합니다.",
            "AWS CodePipeline은 주로 CI/CD 오케스트레이션 도구이지 리포지토리 솔루션이 아닙니다. 다른 서비스와 함께 사용할 수 있지만, 코드, 이미지 및 아티팩트를 직접 관리하지는 않습니다."
        ]
    },
    {
        "Question Number": "8",
        "Situation": "귀 조직은 보안 준수 및 서비스 중단과 관련된 여러 사건을 경험했습니다. 사건 대응 시간을 개선하고 규정 준수를 유지하기 위해 AWS 환경 전반에 걸쳐 이벤트를 더 잘 모니터링, 캡처 및 대응할 수 있는 솔루션을 구현해야 합니다.",
        "Question": "AWS 리소스 전반에 걸쳐 운영 이벤트를 중앙에서 관리하고 대응하는 데 도움이 되는 AWS 서비스는 무엇입니까?",
        "Options": {
            "1": "Amazon CloudWatch Events",
            "2": "Amazon EventBridge",
            "3": "AWS Health Dashboard",
            "4": "AWS CloudTrail"
        },
        "Correct Answer": "Amazon EventBridge",
        "Explanation": "Amazon EventBridge는 AWS 서비스, 통합된 SaaS 애플리케이션 및 자체 사용자 정의 애플리케이션에서 이벤트를 라우팅하여 이벤트 기반 애플리케이션을 구축할 수 있도록 합니다. 운영 이벤트를 효율적으로 관리하고 대응하는 데 도움이 되어 중앙 집중식 이벤트 관리 및 사건 대응을 위한 최선의 선택입니다.",
        "Other Options": [
            "AWS Health Dashboard는 AWS 서비스의 성능 및 가용성에 대한 정보를 제공하지만, 리소스 전반에 걸쳐 운영 이벤트를 관리하도록 설계되지 않았습니다.",
            "AWS CloudTrail은 AWS 계정 활동 및 API 사용을 기록하는 데 중점을 두고 있으며, 이는 준수에 중요하지만 운영 이벤트를 직접 관리하거나 대응하지는 않습니다.",
            "Amazon CloudWatch Events는 이벤트 기반 자동화를 위한 레거시 서비스이지만, EventBridge에 의해 대부분 대체되었으며, EventBridge는 더 많은 기능과 더 나은 통합 기능을 제공합니다."
        ]
    },
    {
        "Question Number": "9",
        "Situation": "데이터 엔지니어링 팀은 온프레미스 시스템에서 대규모 데이터 세트를 정기적으로 처리하고 이를 Amazon S3로 이동하여 추가 분석을 수행하는 임무를 맡고 있습니다. 그들은 데이터를 변환하고 Amazon Redshift에 로드하여 보고 목적으로 사용할 수 있도록 하면서 신뢰할 수 있고 확장 가능한 프로세스를 유지하고자 합니다. 이 작업을 위해 AWS Data Pipeline을 사용하는 것을 고려하고 있습니다.",
        "Question": "팀이 데이터 처리 워크플로를 최적화하기 위해 활용해야 할 기능 조합은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "ETL 활동을 실행하기 위해 Amazon EC2 인스턴스를 작업 실행기로 사용합니다.",
            "2": "파이프라인의 데이터 소스로 Amazon DynamoDB를 통합합니다.",
            "3": "파이프라인이 지정된 간격으로 실행되도록 일정을 정의합니다.",
            "4": "데이터를 처리해야 할 때마다 작업을 수동으로 트리거합니다.",
            "5": "성공적인 실행을 위한 전제 조건을 포함하는 파이프라인 정의를 설정합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "파이프라인이 지정된 간격으로 실행되도록 일정을 정의합니다.",
            "ETL 활동을 실행하기 위해 Amazon EC2 인스턴스를 작업 실행기로 사용합니다."
        ],
        "Explanation": "파이프라인의 실행 일정을 정의함으로써 팀은 데이터 처리 작업을 정기적으로 자동화하여 시기적절하고 일관된 워크플로를 보장할 수 있습니다. 또한, EC2 인스턴스를 작업 실행기로 활용하면 Amazon Redshift로 데이터를 이동하는 데 필요한 추출, 변환, 로드(ETL) 활동을 효율적으로 실행할 수 있습니다.",
        "Other Options": [
            "이 옵션은 일정을 정의하는 것이 자동화에 필수적이지만, 예약된 실행 없이 단순히 파이프라인 정의만 있는 것은 워크플로 최적화 요구 사항을 충족하지 않기 때문에 잘못되었습니다.",
            "이 옵션은 작업을 수동으로 트리거하는 것을 제안하므로 데이터 처리 워크플로의 자동화 및 신뢰성 목표에 반하기 때문에 잘못되었습니다.",
            "이 옵션은 DynamoDB 통합이 유용할 수 있지만, 이 특정 시나리오에서 데이터 처리 워크플로를 최적화하는 데 필요한 기능은 아니기 때문에 잘못되었습니다."
        ]
    },
    {
        "Question Number": "10",
        "Situation": "한 회사가 새로운 애플리케이션을 개발하고 있으며 소프트웨어 배포 프로세스를 간소화하기 위해 CI/CD 파이프라인을 구현했습니다. 파이프라인의 일환으로 배포 전에 품질과 신뢰성을 보장하기 위해 다양한 단계에서 여러 유형의 테스트가 활용되고 있습니다. DevOps 엔지니어는 속도와 효과성을 최적화하기 위해 파이프라인의 특정 지점에서 어떤 테스트를 실행해야 할지 결정해야 합니다.",
        "Question": "DevOps 엔지니어로서 CI/CD 파이프라인의 지정된 단계에서 어떤 유형의 테스트를 구현해야 합니까? (두 가지 선택)",
        "Options": {
            "1": "보안 테스트는 취약점이 도입되지 않도록 배포 후에만 실행해야 합니다.",
            "2": "단위 테스트는 초기 버그를 잡기 위해 모든 코드 커밋에서 실행해야 합니다.",
            "3": "부하 테스트는 스트레스 하에서 성능을 검증하기 위해 배포 후에 수행해야 합니다.",
            "4": "통합 테스트는 성공적인 단위 테스트 후에 실행되어 구성 요소가 함께 작동하는지 확인해야 합니다.",
            "5": "UI 테스트는 인터페이스가 예상대로 작동하는지 확인하기 위해 모든 커밋에서 수행해야 합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "단위 테스트는 초기 버그를 잡기 위해 모든 코드 커밋에서 실행해야 합니다.",
            "통합 테스트는 성공적인 단위 테스트 후에 실행되어 구성 요소가 함께 작동하는지 확인해야 합니다."
        ],
        "Explanation": "단위 테스트는 개발 프로세스 초기에 버그를 잡는 데 필수적이며, 통합 테스트는 초기 단위 테스트가 통과한 후 애플리케이션의 다양한 구성 요소가 원활하게 작동하는지 검증하는 데 중요합니다. 이 조합은 애플리케이션이 더 복잡한 테스트로 진행되기 전에 견고한 기반 위에 구축되도록 도와줍니다.",
        "Other Options": [
            "통합 테스트는 일반적으로 단위 테스트 후에 실행되며, 모든 커밋에서 실행하는 것은 비효율적입니다.",
            "부하 테스트는 애플리케이션이 스테이징 환경에 배포된 후에 수행하여 시스템이 높은 트래픽 하에서 어떻게 작동하는지 평가하는 것이 가장 좋습니다.",
            "UI 테스트는 자원이 많이 소모되며 일반적으로 전용 테스트 단계나 일정에 따라 덜 자주 실행됩니다.",
            "보안 테스트는 배포 후에만 수행하는 것이 아니라 개발 프로세스 전반에 걸쳐 통합되어야 하며, 이를 통해 취약점을 조기에 발견하고 모든 단계에서 보안을 유지해야 합니다."
        ]
    },
    {
        "Question Number": "11",
        "Situation": "DevOps 엔지니어가 다중 계정 AWS 조직을 관리하고 있으며, 개발자들이 조직 정책을 준수하면서 다양한 계정에서 역할을 맡을 수 있도록 하는 솔루션을 구현해야 합니다. 조직은 서비스 제어 정책(SCP)을 사용하여 계정 간의 작업에 대한 제한을 시행합니다. DevOps 엔지니어는 개발자들이 SCP를 위반하지 않고 다양한 계정에서 역할을 맡을 수 있도록 해야 합니다.",
        "Question": "SCP를 준수하면서 개발자들이 여러 계정에서 역할을 맡을 수 있도록 하는 최선의 접근 방식은 무엇입니까?",
        "Options": {
            "1": "조직 전체에 IAM Identity Center(구 AWS SSO)를 활성화하여 SCP 제한을 우회하면서 역할을 맡을 수 있도록 합니다.",
            "2": "AWS Organizations를 사용하여 특정 계정에 대한 역할 맡기를 허용하는 SCP를 생성하고 이러한 정책을 루트 또는 조직 단위에 연결합니다.",
            "3": "각 계정에 IAM 역할을 생성하고 개발자의 IAM 사용자가 SCP를 고려하지 않고 이러한 역할을 맡을 수 있도록 신뢰 관계를 설정합니다.",
            "4": "교차 계정 IAM 역할을 구현하고 AWS SSO를 사용하여 액세스를 관리하며, SCP가 필요한 작업을 허용하도록 설정되었는지 확인합니다."
        },
        "Correct Answer": "AWS Organizations를 사용하여 특정 계정에 대한 역할 맡기를 허용하는 SCP를 생성하고 이러한 정책을 루트 또는 조직 단위에 연결합니다.",
        "Explanation": "AWS Organizations를 사용하여 적절한 SCP를 생성하면 개발자들이 지정된 계정에서 역할을 맡을 수 있도록 하면서 조직 전반에 걸쳐 설정된 거버넌스 및 보안 정책을 준수할 수 있습니다. 이 접근 방식은 필요한 액세스를 허용하면서 SCP 준수를 유지하는 데 도움이 됩니다.",
        "Other Options": [
            "신뢰 관계 없이 IAM 역할을 생성하면 SCP에 의해 부과된 제한으로 인해 개발자가 해당 역할을 맡을 수 없는 상황이 발생할 수 있어 이 접근 방식은 비준수적입니다.",
            "교차 계정 IAM 역할과 AWS SSO를 구현하는 것은 SCP 준수를 보장하지 않으며, SCP가 여전히 개발자가 역할을 맡을 때 수행하려는 작업을 제한할 수 있습니다.",
            "IAM Identity Center(구 AWS SSO)를 활성화한다고 해서 SCP 제한을 우회하는 것은 아니며, 역할 맡기가 허용되도록 SCP를 올바르게 구성하는 것이 필수적입니다."
        ]
    },
    {
        "Question Number": "12",
        "Situation": "한 회사가 다양한 부서를 위해 여러 AWS 계정을 관리하고 있으며, DevOps 엔지니어는 사용자가 임시 자격 증명으로 역할을 맡을 수 있도록 하면서 교차 계정 액세스를 위한 안전한 방법을 구현해야 합니다. 이 솔루션은 민감한 작업에 대해 MFA를 지원해야 합니다. 엔지니어는 이 요구 사항을 충족하기 위해 다양한 AWS STS 작업을 고려하고 있습니다.",
        "Question": "이 요구 사항을 충족하기 위해 엔지니어가 사용해야 할 AWS STS 작업의 조합은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "get-session-token을 사용하여 MFA로 인증하는 사용자에게 임시 자격 증명을 제공합니다.",
            "2": "assume-role-with-web-identity를 사용하여 사용자가 Facebook이나 Google과 같은 웹 신원을 사용하여 AWS 리소스에 접근할 수 있도록 합니다.",
            "3": "assume-role-with-saml을 사용하여 사용자가 계정 간에 역할을 맡을 수 있도록 SAML 기반 인증을 활성화합니다.",
            "4": "assume-role을 사용하여 IAM 사용자가 다른 계정에서 역할을 맡고 임시 보안 자격 증명을 얻을 수 있도록 합니다.",
            "5": "get-session-token을 사용하여 MFA 없이 AWS 리소스에 접근할 수 있도록 사용자를 인증합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "assume-role을 사용하여 IAM 사용자가 다른 계정에서 역할을 맡고 임시 보안 자격 증명을 얻을 수 있도록 합니다.",
            "get-session-token을 사용하여 MFA로 인증하는 사용자에게 임시 자격 증명을 제공합니다."
        ],
        "Explanation": "assume-role을 사용하면 IAM 사용자가 다른 AWS 계정의 리소스에 임시로 접근할 수 있으며, 최소 권한 원칙을 유지합니다. get-session-token은 MFA로 인증하는 사용자에게 임시 자격 증명을 제공하는 데 사용되어 민감한 작업에 대한 추가 보안 계층을 추가합니다.",
        "Other Options": [
            "assume-role-with-saml은 SAML 기반 인증을 지원하므로, 표준 IAM 사용자 역할이 사용되는 경우 이 시나리오에 필요하지 않습니다.",
            "assume-role-with-web-identity는 웹 신원 제공자를 통해 인증하는 사용자에게 적합하며, IAM 사용자가 관련된 이 시나리오에는 적용되지 않습니다.",
            "MFA 없이 get-session-token을 사용하는 것은 잘못된 접근 방식입니다. 요구 사항은 민감한 작업에 대해 MFA가 시행되어야 한다고 명시하고 있으므로 이 옵션은 보안 요구 사항에 부합하지 않습니다."
        ]
    },
    {
        "Question Number": "13",
        "Situation": "사용자 인증을 다양한 신원 제공자를 통해 요구하는 모바일 애플리케이션을 개발하고 있습니다. 인증된 사용자와 인증되지 않은 사용자 모두에게 원활한 경험을 제공하면서 신원을 병합할 수 있는 능력을 유지하고자 합니다. 애플리케이션에 가장 적합한 흐름을 결정해야 합니다.",
        "Question": "Cognito에서 사용자 신원을 효과적으로 관리하기 위해 어떤 옵션 조합을 구현해야 합니까? (두 개 선택)",
        "Options": {
            "1": "인증된 사용자와 인증되지 않은 사용자 모두를 위한 간단한 Cognito 흐름을 구현하여 로그인 프로세스를 간소화합니다.",
            "2": "여러 신원을 단일 인증된 사용자로 병합하기 위해 Classic Cognito Authenticated 흐름을 적용합니다.",
            "3": "인증 중 신원 제공자와 지속적으로 통신하기 위해 Enhanced Cognito 흐름을 활용합니다.",
            "4": "인증 없이 게스트 사용자를 관리하기 위해 pre-Cognito auth 흐름을 채택합니다.",
            "5": "대규모 사용자 기반을 지원해야 할 때 Web Identity Provider를 사용합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "인증 중 신원 제공자와 지속적으로 통신하기 위해 Enhanced Cognito 흐름을 활용합니다.",
            "대규모 사용자 기반을 지원해야 할 때 Web Identity Provider를 사용합니다."
        ],
        "Explanation": "Enhanced Cognito 흐름은 신원 제공자와의 지속적인 통신이 유리한 상황을 위해 설계되어 실시간 업데이트와 더 나은 사용자 경험을 제공합니다. Web Identity Provider를 사용하는 것은 애플리케이션을 대규모 청중으로 확장할 때 매우 중요하며, 사용자가 다양한 신원 출처를 통해 효과적으로 인증할 수 있도록 합니다.",
        "Other Options": [
            "간단한 Cognito 흐름은 특히 확장이 우려되는 경우 여러 신원 출처를 효과적으로 관리하는 데 필요한 기능을 제공하지 않을 수 있습니다.",
            "Classic Cognito Authenticated 흐름은 실시간 상호작용과 관련하여 Enhanced 흐름만큼의 유연성을 제공하지 않으며 신원 병합 기능을 제한할 수 있습니다.",
            "pre-Cognito auth 흐름은 주로 게스트 사용자에게 적합하지만 인증된 사용자 관리나 신원 병합을 촉진하지 않습니다."
        ]
    },
    {
        "Question Number": "14",
        "Situation": "AWS 계정의 보안 및 규정 준수를 관리하는 책임이 있습니다. 조직은 감사 목적으로 리소스 전반에 걸쳐 이루어진 API 호출을 기록하고 모니터링해야 하는 엄격한 요구 사항이 있습니다. 모든 AWS API 호출이 안전하게 기록되고 저장되도록 하면서 분석을 위한 쉬운 접근을 제공해야 합니다. 또한 로그는 최소 1년 동안 보존되어야 합니다. 이 요구 사항을 달성하기 위한 가장 효과적인 방법은 무엇입니까?",
        "Question": "AWS 환경에서 API 호출의 포괄적인 로그를 보장하기 위해 어떤 방법을 구현해야 합니까?",
        "Options": {
            "1": "AWS Config를 활성화하여 리소스 변경 사항을 추적하고 구성 기록을 암호화된 S3 버킷에 저장하여 보존 정책을 준수합니다.",
            "2": "Amazon CloudWatch Logs를 활용하여 API 호출을 캡처하고 조직의 1년 로그 저장 요구 사항을 충족하는 보존 정책을 설정합니다.",
            "3": "AWS Lambda 함수를 구현하여 계정에서 이루어진 모든 API 호출을 기록하고 이러한 로그를 DynamoDB에 저장하여 쉽게 쿼리하고 보존합니다.",
            "4": "모든 관리 이벤트를 캡처하고 AWS Key Management Service (KMS)를 사용하여 로그 파일 암호화를 활성화하는 새로운 AWS CloudTrail 트레일을 생성합니다. 로그를 보존을 위한 수명 주기 정책이 있는 S3 버킷에 저장합니다."
        },
        "Correct Answer": "모든 관리 이벤트를 캡처하고 AWS Key Management Service (KMS)를 사용하여 로그 파일 암호화를 활성화하는 새로운 AWS CloudTrail 트레일을 생성합니다. 로그를 보존을 위한 수명 주기 정책이 있는 S3 버킷에 저장합니다.",
        "Explanation": "AWS CloudTrail을 사용하여 트레일을 생성하면 모든 API 호출이 기록되며, 관리 이벤트와 데이터 이벤트 모두 포함됩니다. KMS 암호화가 적용된 S3 버킷에 로그를 저장함으로써 보안 요구 사항을 충족합니다. 또한, 수명 주기 정책을 구성하여 필요한 기간 동안 로그 보존을 관리할 수 있어 감사 요구 사항을 효과적으로 해결합니다.",
        "Other Options": [
            "AWS Config는 귀중한 리소스 구성 기록을 제공하지만 모든 서비스에서 API 호출을 포괄적으로 기록하지 않습니다. 이는 규정 준수 및 변경 추적에 더 적합합니다.",
            "Amazon CloudWatch Logs는 AWS 서비스에 대한 모든 API 호출을 캡처하도록 설계되지 않았습니다. 이는 주로 애플리케이션 및 시스템 이벤트를 기록하는 데 사용되므로 철저한 API 호출 로그에는 불충분합니다.",
            "AWS Lambda 함수를 사용하여 API 호출을 기록하는 것은 비효율적이거나 효과적인 접근 방식이 아니며, 사용자 정의 구현이 필요하고 로그 누락이나 불완전한 데이터로 이어질 수 있습니다. CloudTrail은 이 목적을 위해 특별히 설계되었습니다."
        ]
    },
    {
        "Question Number": "15",
        "Situation": "개발 팀이 AWS Elastic Beanstalk에 웹 애플리케이션을 배포하고 있으며, 리소스 및 설정을 관리하기 위해 구성 파일을 사용하여 환경을 사용자 정의하고자 합니다. 배포 중 특정 명령이 리더 EC2 인스턴스에서만 실행되도록 해야 합니다.",
        "Question": ".ebextensions .config 파일에서 Elastic Beanstalk 환경의 리더 인스턴스에서만 명령이 실행되도록 보장하는 구성 설정은 무엇입니까?",
        "Options": {
            "1": "조건문 없이 명령 섹션에 명령을 직접 지정합니다.",
            "2": "리더 인스턴스에서 실행해야 하는 명령을 정의하기 위해 리소스 섹션을 활용합니다.",
            "3": ".config 파일의 container_commands 섹션 내에서 leader_only 옵션을 사용합니다.",
            "4": "리더 인스턴스를 나타내는 환경 변수를 추가하고 이를 container_commands에서 참조합니다."
        },
        "Correct Answer": "container_commands 섹션 내에서 leader_only 옵션을 사용합니다.",
        "Explanation": "leader_only 옵션은 .config 파일의 container_commands 섹션에서 사용되어 명령이 리더 인스턴스에서만 한 번 실행되도록 보장합니다. 이는 특정 명령이 모든 인스턴스에서 실행되지 않아야 하는 환경에서 중요합니다.",
        "Other Options": [
            "이 옵션은 명령이 리더 인스턴스에 제한되지 않도록 보장하지 않으며, 명령 섹션에 나열된 명령은 환경의 모든 인스턴스에서 실행됩니다.",
            "리소스 섹션은 AWS 리소스를 정의하는 데 사용되며 명령을 실행하지 않으므로 리더 인스턴스에서의 실행 제어와는 무관합니다.",
            "환경 변수는 인스턴스별 실행을 제어할 수 없으며, 구성 설정에 사용되며 이를 참조한다고 해서 리더 인스턴스에서 실행이 보장되지 않습니다."
        ]
    },
    {
        "Question Number": "16",
        "Situation": "한 회사가 Amazon ECS를 사용하여 AWS에 확장 가능한 마이크로서비스 기반 애플리케이션을 배포했습니다. 이 애플리케이션은 변동하는 작업 부하를 경험하고 있으며, 개발 팀은 수동 개입 없이 부하를 처리할 수 있도록 필요한 리소스가 자동으로 프로비저닝되도록 해야 합니다. 또한, 성능과 비용을 최적화하기 위해 애플리케이션을 모니터링하고 싶어합니다. DevOps 엔지니어로서, ECS 서비스에 대한 자동 확장 및 모니터링을 구현하기 위한 최선의 접근 방식을 결정해야 합니다.",
        "Question": "ECS 서비스에 대한 자동 확장 및 모니터링을 가능하게 하는 가장 효과적인 접근 방식은 무엇입니까?",
        "Options": {
            "1": "ECS 작업을 호스팅하기 위해 미리 정의된 인스턴스 유형을 가진 EC2 Auto Scaling 그룹을 구현하고, CloudWatch 메트릭을 기반으로 수동으로 확장할 수 있도록 합니다.",
            "2": "AWS Lambda 함수를 사용하여 애플리케이션 성능을 모니터링하고 미리 정해진 일정에 따라 ECS 작업 수를 수동으로 조정합니다.",
            "3": "CPU 및 메모리 사용량 메트릭을 기반으로 확장 정책을 트리거하는 CloudWatch 경고를 구성합니다. 리소스 가용성을 보장하기 위해 최소 및 최대 작업 수를 설정합니다.",
            "4": "ECS 성능 메트릭을 시각화하기 위해 CloudWatch 대시보드를 설정하지만, 필요에 따라 서비스를 수동으로 확장하거나 축소하는 데 의존합니다."
        },
        "Correct Answer": "CPU 및 메모리 사용량 메트릭을 기반으로 확장 정책을 트리거하는 CloudWatch 경고를 구성합니다. 리소스 가용성을 보장하기 위해 최소 및 최대 작업 수를 설정합니다.",
        "Explanation": "이 옵션은 실제 성능 메트릭을 기반으로 ECS 작업의 자동 확장을 위해 CloudWatch 경고를 효과적으로 활용하여 애플리케이션이 수동 개입 없이 변동하는 작업 부하를 효율적으로 처리할 수 있도록 합니다. 최소 및 최대 작업 수를 설정하면 항상 충분한 리소스가 제공되며 비용도 관리할 수 있습니다.",
        "Other Options": [
            "이 옵션은 모니터링 및 수동 조정을 위해 AWS Lambda 함수에 의존하며, 변동하는 작업 부하에 필요한 동적 확장 기능을 제공하지 않으며 리소스 요구에 대한 응답에 잠재적인 지연을 초래할 수 있습니다.",
            "EC2 Auto Scaling 그룹을 고려하지만, ECS 작업을 직접 관리하지 않습니다. 대신, EC2 인스턴스를 수동으로 조정하기보다는 메트릭에 반응하는 ECS 전용 자동 확장 메커니즘을 사용하는 것이 더 좋습니다.",
            "이 접근 방식은 자동 확장의 잠재력을 충분히 활용하지 않습니다. 수동 개입은 리소스 조정에 지연을 초래할 수 있으며, 이는 피크 부하 동안 애플리케이션 성능에 부정적인 영향을 미칠 수 있습니다."
        ]
    },
    {
        "Question Number": "17",
        "Situation": "하루 동안 변동하는 부하를 경험하는 애플리케이션을 관리하고 있습니다. 비용을 최소화하면서 최적의 성능을 보장하기 위해 AWS에서 Auto Scaling Group (ASG)을 구현했습니다. 스케일링 이벤트 동안 사용자 정의 작업을 수행하기 위해 라이프사이클 훅을 활용하고 인스턴스가 서비스에 들어가기 전에 올바르게 구성되도록 하고 싶습니다. 최근 스케일 아웃 이벤트에서 인스턴스가 트래픽을 제공하기 시작하기 전에 필요한 구성을 기다리지 않는 것을 발견했습니다.",
        "Question": "이 시나리오에서 Auto Scaling Lifecycle Hooks를 사용하는 주된 목적은 무엇입니까?",
        "Options": {
            "1": "Auto Scaling Group이 수요에 따라 올바른 인스턴스 유형을 선택할 수 있도록 합니다.",
            "2": "인스턴스가 종료되기 전에 사용자 정의 작업을 수행할 수 있도록 합니다.",
            "3": "부하가 특정 임계값 이하로 감소할 때 인스턴스를 자동으로 종료합니다.",
            "4": "인스턴스가 In Service 상태에 들어가기 전에 시작되고 구성되도록 보장합니다."
        },
        "Correct Answer": "인스턴스가 In Service 상태에 들어가기 전에 시작되고 구성되도록 보장합니다.",
        "Explanation": "라이프사이클 훅은 인스턴스가 In Service 상태로 전환되는 것을 일시 중지하도록 설계되어, 인스턴스가 완전히 작동하기 전에 소프트웨어 설치 또는 상태 점검과 같은 사용자 정의 작업을 수행할 수 있게 합니다.",
        "Other Options": [
            "이 옵션은 잘못된 것입니다. 라이프사이클 훅은 주로 인스턴스의 시작 또는 종료와 관련된 작업에 초점을 맞추며, 종료 작업만을 다루지 않습니다.",
            "이 옵션은 잘못된 것입니다. 구성 측면을 언급하지만, 라이프사이클 훅의 목적을 정확하게 반영하지 않으며, 추가 작업을 위한 상태 전환을 일시 중지하는 것입니다.",
            "이 옵션은 잘못된 것입니다. 라이프사이클 훅은 인스턴스를 자동으로 종료하지 않으며, 스케일링 이벤트 동안 인스턴스의 전환 상태만 관리합니다."
        ]
    },
    {
        "Question Number": "18",
        "Situation": "한 소프트웨어 회사가 AWS CodePipeline을 사용하여 애플리케이션의 새 버전을 배포했습니다. 이 과정에는 CodeBuild와 CodeDeploy를 포함한 여러 단계가 있습니다. 배포 후 사용자들이 애플리케이션에 문제가 있다고 보고했으며, DevOps 엔지니어는 신속하게 실패 원인을 파악해야 합니다. 엔지니어는 AWS CloudWatch 메트릭, 로그 및 AWS CodePipeline 실행 세부정보에 접근할 수 있습니다.",
        "Question": "DevOps 엔지니어가 실패한 배포를 분석하고 근본 원인을 파악하는 가장 효과적인 방법은 무엇입니까?",
        "Options": {
            "1": "배포 리소스와 관련된 오류 메시지에 대한 CloudFormation 스택 이벤트를 검사합니다.",
            "2": "CloudWatch 합성 모니터링 테스트를 실행하여 사용자들이 보고한 문제를 재현할 수 있는지 확인합니다.",
            "3": "애플리케이션의 상태 메트릭을 확인하여 실패가 리소스 사용과 관련이 있는지 확인합니다.",
            "4": "AWS CodePipeline 실행 기록을 검토하여 실패한 단계를 찾고 CodeBuild 및 CodeDeploy의 관련 로그를 검사합니다."
        },
        "Correct Answer": "AWS CodePipeline 실행 기록을 검토하여 실패한 단계를 찾고 CodeBuild 및 CodeDeploy의 관련 로그를 검사합니다.",
        "Explanation": "가장 효과적인 접근 방식은 AWS CodePipeline 실행 기록을 검토하는 것입니다. 이는 파이프라인의 각 단계를 포괄적으로 보여줍니다. 실패한 단계를 식별함으로써 엔지니어는 CodeBuild 및 CodeDeploy의 로그에 직접 접근할 수 있어 문제의 정확한 원인을 파악하는 데 도움이 됩니다.",
        "Other Options": [
            "CloudWatch 대시보드에서 상태 메트릭을 확인하는 것은 리소스 사용에 대한 통찰을 제공할 수 있지만, 배포 실패를 직접적으로 다루지 않으며 CodePipeline 단계와 관련된 문제를 강조하지 않을 수 있습니다.",
            "CloudFormation 스택 이벤트를 검사하는 것은 인프라 문제에 유용하지만, CodePipeline에서 관리하는 애플리케이션 배포 프로세스와 관련된 자세한 로그를 제공하지 않습니다.",
            "CloudWatch 합성 모니터링 테스트를 실행하는 것은 애플리케이션이 올바르게 작동하는지 확인하는 데 도움이 될 수 있지만, 배포 실패 또는 이를 초래한 단계에 대한 구체적인 정보를 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "19",
        "Situation": "개발 팀은 AWS CodePipeline을 사용하여 지속적인 통합 및 지속적인 배포(CI/CD) 프로세스를 자동화하고 있습니다. 그들은 애플리케이션의 품질을 보장하기 위해 중요한 일련의 단위 테스트를 보유하고 있습니다. 그러나 파이프라인 실행 중에 모든 테스트가 실행되지 않고 있어 프로덕션에서 잠재적인 문제가 발생할 수 있음을 발견했습니다. DevOps 엔지니어로서 모든 단위 테스트가 실행되고 코드 커버리지가 정확하게 보고되도록 하기 위해 어떤 조치를 취해야 합니까?",
        "Question": "CI/CD 파이프라인에서 모든 단위 테스트가 실행되고 코드 커버리지가 보고되도록 보장하는 가장 좋은 방법은 무엇입니까?",
        "Options": {
            "1": "CI/CD 파이프라인 외부에서 테스트를 수동으로 실행하고 커버리지를 추적하는 방법을 사용합니다.",
            "2": "빌드 사양을 수정하여 테스트 스위트와 커버리지 보고서를 트리거하는 명령을 포함합니다.",
            "3": "모든 테스트를 자동으로 실행하고 커버리지 보고서를 생성하는 테스트 프레임워크를 통합합니다.",
            "4": "단위 테스트를 실행하고 코드 커버리지를 보고하기 위해 별도의 파이프라인을 설정합니다."
        },
        "Correct Answer": "빌드 사양을 수정하여 테스트 스위트와 커버리지 보고서를 트리거하는 명령을 포함합니다.",
        "Explanation": "빌드 사양을 수정하여 테스트 스위트를 명시적으로 트리거하고 커버리지 보고서를 생성하는 명령을 포함하면 CI/CD 프로세스 중에 모든 단위 테스트가 실행되도록 보장할 수 있습니다. 이 접근 방식은 테스트를 자동화 파이프라인에 원활하게 통합하여 테스트가 생략될 위험을 제거합니다.",
        "Other Options": [
            "테스트 프레임워크를 통합하는 것은 유용하지만, 테스트가 실행되도록 빌드 프로세스를 명시적으로 수정하지 않으면 모든 테스트가 실행될 것이라는 보장이 없습니다.",
            "별도의 파이프라인을 설정하면 추가적인 복잡성이 발생할 수 있으며, 기존 CI/CD 파이프라인 내에서 통합 테스트의 필요성을 해결하지 않습니다.",
            "수동 접근 방식을 사용하는 것은 CI/CD의 자동화 원칙에 반하며, 이는 인적 오류를 줄이고 효율성을 향상시키는 것을 목표로 합니다."
        ]
    },
    {
        "Question Number": "20",
        "Situation": "조직은 다중 계정 AWS 아키텍처를 구현하고 있으며 안전한 크로스 계정 액세스를 위한 솔루션이 필요합니다. DevOps 엔지니어는 사용자가 다양한 AWS 계정에서 역할을 가정하여 업무를 수행할 수 있도록 하면서 기존의 신원 공급자를 활용하여 인증을 수행할 수 있도록 해야 합니다. 이 솔루션은 Multi-Factor Authentication (MFA)이 활성화된 사용자도 지원해야 합니다.",
        "Question": "DevOps 엔지니어가 이러한 요구 사항을 충족하기 위해 추천해야 할 접근 방식은 무엇입니까?",
        "Options": {
            "1": "웹 신원 공급자로 인증된 사용자에게 임시 자격 증명을 제공하기 위해 assume-role-with-web-identity 기능을 구현하여 다양한 계정의 AWS 리소스에 접근할 수 있도록 합니다.",
            "2": "AWS Management Console을 활용하여 추가 인증 없이 계정 간 역할 전환을 허용하는 IAM 정책을 사용하여 크로스 계정 액세스를 구성합니다.",
            "3": "AWS CLI를 사용하여 assume-role-with-saml을 호출하여 신원 공급자에서 온 사용자가 대상 계정에서 역할을 가정하여 크로스 계정 리소스에 접근할 수 있도록 합니다.",
            "4": "get-session-token API를 활용하여 MFA가 활성화된 사용자에게 임시 보안 자격 증명을 생성하여 여러 AWS 계정의 리소스에 접근할 수 있도록 합니다."
        },
        "Correct Answer": "AWS CLI를 사용하여 assume-role-with-saml을 호출하여 신원 공급자에서 온 사용자가 대상 계정에서 역할을 가정하여 크로스 계정 리소스에 접근할 수 있도록 합니다.",
        "Explanation": "assume-role-with-saml 기능은 연합 액세스를 위해 특별히 설계되어 SAML 신원 공급자에 의해 인증된 사용자가 다양한 AWS 계정에서 역할을 가정할 수 있도록 합니다. 이는 기존 인증 메커니즘을 활용하면서 안전한 크로스 계정 액세스를 보장합니다.",
        "Other Options": [
            "get-session-token API는 MFA가 활성화된 사용자에게 임시 보안 자격 증명을 얻기 위해 사용되지만, 크로스 계정 역할 가정을 직접적으로 촉진하지는 않습니다. 이는 기존 자격 증명의 보안을 강화하는 것과 관련이 있습니다.",
            "assume-role-with-web-identity 기능은 Google이나 Facebook과 같은 웹 신원 공급자를 통해 인증된 사용자에게 사용되며, 이는 크로스 계정 액세스를 위한 SAML 기반 인증의 필요성과 일치하지 않을 수 있습니다.",
            "AWS Management Console을 사용하여 역할 전환을 위한 IAM 정책을 구성하는 것은 MFA가 포함된 안전한 크로스 계정 액세스에 필수적인 임시 자격 증명을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "21",
        "Situation": "한 회사는 AWS 서비스를 사용하여 마이크로서비스 아키텍처를 위한 자동화된 CI/CD 파이프라인을 구현하고 있습니다. 그들은 AWS CodeArtifact를 사용하여 의존성과 아티팩트를 안전하게 관리하고 있습니다. 보안 팀은 CodeArtifact 리포지토리에서 민감한 아티팩트의 노출에 대해 우려를 제기했습니다. DevOps 엔지니어는 민감한 아티팩트에 대한 접근을 허가된 인원만 가능하도록 하면서 개발 팀이 필요한 빌드 아티팩트에 접근할 수 있도록 해야 합니다.",
        "Question": "DevOps 엔지니어가 AWS CodeArtifact에서 민감한 아티팩트에 대한 접근을 관리하기 위한 가장 좋은 접근 방식은 무엇입니까?",
        "Options": {
            "1": "모든 아티팩트에 대해 AWS CodeArtifact의 공개 리포지토리를 사용하여 조직 내 모든 사람이 접근할 수 있도록 합니다.",
            "2": "AWS CodeArtifact를 구성하여 민감한 아티팩트를 정의된 기간 후에 자동으로 만료시켜 모든 사용자가 접근할 수 없도록 합니다.",
            "3": "개발 팀과 관련된 특정 IAM 역할에 대해서만 민감한 아티팩트에 대한 접근을 허용하는 AWS IAM 정책을 구현하여 다른 모든 역할에 대한 접근을 거부합니다.",
            "4": "모든 개발자에게 모든 CodeArtifact 리포지토리에 대한 전체 접근을 부여하는 단일 IAM 역할을 생성합니다."
        },
        "Correct Answer": "개발 팀과 관련된 특정 IAM 역할에 대해서만 민감한 아티팩트에 대한 접근을 허용하는 AWS IAM 정책을 구현하여 다른 모든 역할에 대한 접근을 거부합니다.",
        "Explanation": "특정 IAM 정책을 구현하면 권한이 있는 역할만 민감한 아티팩트에 접근할 수 있도록 하여 보안을 유지하면서 개발 팀에 필요한 접근을 가능하게 합니다. 이 접근 방식은 보안과 접근성을 효과적으로 균형 있게 유지합니다.",
        "Other Options": [
            "공개 리포지토리를 사용하는 것은 민감한 아티팩트를 보호하는 목적에 반하며, 이는 누구에게나 무제한 접근을 허용하여 보안을 위협합니다.",
            "모든 개발자에게 제한 없이 단일 IAM 역할을 생성하는 것은 모든 아티팩트를 모든 사람에게 노출시켜 민감한 정보에 대한 무단 접근 위험을 증가시킵니다.",
            "아티팩트의 자동 만료를 구성하는 것은 즉각적인 접근 제어 문제를 해결하지 않으며, 필요한 아티팩트의 사용 불가로 인해 개발 프로세스에 중단을 초래할 수 있습니다."
        ]
    },
    {
        "Question Number": "22",
        "Situation": "한 회사가 AWS 서비스에 대한 연합 액세스를 요구하는 기업 애플리케이션을 위한 맞춤형 프록시를 구현하고 있습니다. 이 애플리케이션은 인증을 위해 LDAP를 사용하며, GetFederationToken API를 통해 AWS Security Token Service (STS)에서 임시 보안 자격 증명을 검색해야 합니다. 이 과정에는 디렉토리에서 프록시로 전송된 권한이 포함되며, 이후 GetFederationToken을 요청합니다. 또한, 조직은 액세스가 보안 정책, 특히 MFA 요구 사항을 준수하도록 해야 합니다.",
        "Question": "DevOps 엔지니어가 맞춤형 프록시를 통한 연합 액세스가 안전하도록 하면서 GetFederationToken API의 제한을 준수하기 위해 무엇을 해야 합니까?",
        "Options": {
            "1": "모든 연합 인증 요청을 처리하는 별도의 마이크로서비스를 개발하여, GetFederationToken 요청을 하기 전에 모든 사용자에게 MFA를 강제합니다.",
            "2": "GetFederationToken을 호출할 수 있는 전체 권한을 가진 IAM 사용자를 설정하여, 맞춤형 프록시에 필요한 것보다 더 넓은 액세스를 허용합니다.",
            "3": "모든 사용자가 GetFederationToken API에 접근하기 전에 MFA를 요구하도록 맞춤형 프록시를 구성하여 추가적인 보안 계층을 보장합니다.",
            "4": "MFA를 요구하지 않고 GetFederationToken을 호출할 수 있는 권한을 맞춤형 프록시에 부여하는 IAM 정책을 구현합니다. 이 API는 설계상 MFA를 지원하지 않기 때문입니다."
        },
        "Correct Answer": "MFA를 요구하지 않고 GetFederationToken을 호출할 수 있는 권한을 맞춤형 프록시에 부여하는 IAM 정책을 구현합니다. 이 API는 설계상 MFA를 지원하지 않기 때문입니다.",
        "Explanation": "GetFederationToken API는 MFA를 지원하지 않으므로, 맞춤형 프록시가 이 API에 접근할 수 있도록 MFA를 요구하지 않는 IAM 정책을 구현하는 것이 올바른 접근 방식입니다. 이는 애플리케이션이 AWS의 제한을 준수하면서 의도한 대로 기능할 수 있도록 보장합니다.",
        "Other Options": [
            "GetFederationToken API에 대한 액세스에 MFA를 요구하는 것은 불가능합니다. 이 API는 MFA를 지원하지 않기 때문에, 이 옵션은 불필요한 복잡성을 초래하고 사용자가 임시 자격 증명을 얻는 것을 방해합니다.",
            "GetFederationToken을 호출할 수 있는 전체 권한을 가진 IAM 사용자를 만드는 것은 모범 사례가 아닙니다. 이는 필요 이상으로 넓은 액세스를 부여하여 보안 취약점을 초래할 수 있으므로 피해야 합니다.",
            "MFA를 강제하는 연합 인증 요청을 처리하기 위해 별도의 마이크로서비스를 개발하는 것은 불필요합니다. GetFederationToken API 자체가 MFA를 지원하지 않기 때문에, 이는 아키텍처를 복잡하게 만들 뿐 해결책을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "23",
        "Situation": "한 회사가 EC2 인스턴스의 Auto Scaling 그룹에 웹 애플리케이션을 배포했습니다. 그들은 애플리케이션이 수동 개입 없이 가변 트래픽 부하를 처리할 수 있도록 보장하고 싶어합니다. 이를 달성하기 위해 DevOps 엔지니어는 CPU 사용량 메트릭에 따라 Auto Scaling 그룹의 EC2 인스턴스 수를 자동으로 조정하는 솔루션을 구현해야 합니다. 엔지니어는 또한 스케일링 작업이 발생할 때마다 알림을 받고 싶어합니다.",
        "Question": "CPU 사용량에 따라 Auto Scaling 그룹을 자동으로 스케일링하고 스케일링 작업에 대한 알림이 전송되도록 CloudWatch 경고 및 스케일링 정책을 설정하는 가장 효율적인 방법은 무엇입니까?",
        "Options": {
            "1": "CPU 사용률이 지정된 임계값을 초과할 때 트리거되는 CloudWatch 경고를 생성합니다. 이 경고를 스케일링 작업을 정의하는 Auto Scaling 정책과 연결하고, 경고가 SNS 알림을 전송하도록 구성합니다.",
            "2": "CPU 사용량 임계값에 대한 CloudWatch 경고를 생성하고 이러한 경고에 대해 SNS 알림을 구성합니다. AWS CLI 명령을 사용하여 이러한 경고에 따라 트리거되는 스케일링 정책을 정의합니다.",
            "3": "CPU 사용량을 모니터링하기 위해 CloudWatch 대시보드를 설정하고 대시보드 메트릭에 따라 Auto Scaling 그룹 크기를 수동으로 조정합니다. 인스턴스 변경에 대한 알림을 보내도록 CloudTrail을 구성합니다.",
            "4": "AWS Lambda를 사용하여 EC2 인스턴스 CPU 메트릭을 모니터링하고 스케일링 작업을 수동으로 호출합니다. Lambda 실행에 따라 스케일링 작업이 수행될 때 Amazon SNS를 사용하여 알립니다."
        },
        "Correct Answer": "CPU 사용률이 지정된 임계값을 초과할 때 트리거되는 CloudWatch 경고를 생성합니다. 이 경고를 스케일링 작업을 정의하는 Auto Scaling 정책과 연결하고, 경고가 SNS 알림을 전송하도록 구성합니다.",
        "Explanation": "올바른 답변은 CloudWatch 경고와 Auto Scaling 정책을 결합한 포괄적인 솔루션을 제공합니다. 이는 CPU 사용량에 따라 스케일링 작업이 자동화되도록 보장하며, 이해관계자에게 SNS를 통해 알림을 전송합니다. 이 접근 방식은 수동 개입을 최소화하고 요구 사항에 완벽하게 부합합니다.",
        "Other Options": [
            "이 옵션은 CloudWatch 대시보드와 수동 조정을 사용하는 것을 제안하는데, 이는 스케일링을 효과적으로 자동화하지 않으며 트래픽 부하를 관리하기 위해 인간의 개입에 의존합니다.",
            "AWS Lambda를 사용하여 모니터링하고 스케일링 작업을 호출하는 것은 불필요한 복잡성을 추가하고 응답 시간에 지연을 초래할 수 있어 CloudWatch 경고를 직접 사용하는 것보다 덜 효율적입니다.",
            "이 옵션은 CloudWatch 경고를 생성하는 것을 언급하지만, 스케일링 작업을 정의하는 Auto Scaling 정책과의 연관성에 대한 구체성이 부족합니다. 이는 스케일링 프로세스를 자동화하는 데 중요합니다."
        ]
    },
    {
        "Question Number": "24",
        "Situation": "한 조직이 사용자 인증 및 신원 관리를 요구하는 모바일 애플리케이션을 개발하고 있습니다. 그들은 인증된 사용자와 인증되지 않은 사용자가 애플리케이션의 특정 기능에 접근할 수 있도록 하는 솔루션을 구현하고 싶어합니다. 이 애플리케이션은 AWS Cognito를 사용하여 신원 관리를 수행하며, 인증되지 않은 사용자 흐름을 원활하게 처리하고 게스트 액세스를 위한 임시 AWS 자격 증명을 제공해야 합니다.",
        "Question": "DevOps 엔지니어로서, 인증되지 않은 사용자가 사전 인증 없이 애플리케이션에 접근할 수 있도록 AWS Cognito에서 다음 중 어떤 구성을 구현하시겠습니까?",
        "Options": {
            "1": "사용자 가입 및 로그인을 관리하기 위해 Cognito 사용자 풀을 사용하고, 인증되지 않은 사용자가 애플리케이션의 백엔드에 접근할 수 있도록 프록시 역할을 하는 API Gateway를 생성합니다. 이 접근 방식은 Cognito의 신원 기능을 우회합니다.",
            "2": "애플리케이션 내에서 인증되지 않은 사용자에게 임시 자격 증명을 생성하는 사용자 정의 인증 흐름을 구현합니다. 이러한 자격 증명을 데이터베이스에 저장하고 필요할 때 검색하여 Cognito 없이 사용자 신원을 관리합니다.",
            "3": "인증되지 않은 액세스를 위해 별도의 IAM 역할을 생성하고 해당 역할에 정책을 직접 할당하여 인증되지 않은 사용자가 Cognito를 거치지 않고 AWS 서비스와 상호작용할 수 있도록 합니다.",
            "4": "AWS Cognito에서 인증되지 않은 신원을 허용하는 Identity Pool을 구성합니다. 인증된 사용자와 인증되지 않은 사용자를 위한 두 개의 IAM 역할을 설정합니다. 이를 통해 게스트 사용자가 AWS 리소스에 안전하게 접근할 수 있도록 합니다."
        },
        "Correct Answer": "AWS Cognito에서 인증되지 않은 신원을 허용하는 Identity Pool을 구성합니다. 인증된 사용자와 인증되지 않은 사용자를 위한 두 개의 IAM 역할을 설정합니다. 이를 통해 게스트 사용자가 AWS 리소스에 안전하게 접근할 수 있도록 합니다.",
        "Explanation": "AWS Cognito에서 Identity Pool을 사용하는 것은 인증된 사용자와 인증되지 않은 사용자를 모두 관리하는 가장 효과적인 방법입니다. 인증되지 않은 신원을 허용하고 적절한 IAM 역할을 설정함으로써, 게스트 사용자에게 임시 AWS 자격 증명을 안전하게 제공하여 사전 인증 없이 특정 AWS 서비스에 접근할 수 있도록 합니다.",
        "Other Options": [
            "Cognito 사용자 풀과 API Gateway를 사용하는 것은 아키텍처를 불필요하게 복잡하게 만듭니다. 사용자 풀은 인증된 사용자를 관리하는 데 훌륭하지만, Identity Pool 없이 인증되지 않은 액세스를 직접 지원하지 않습니다.",
            "사용자 정의 인증 흐름을 구현하는 것은 보안 위험과 관리 오버헤드를 증가시킬 수 있습니다. 이 옵션은 AWS Cognito의 신원 관리 이점을 우회하며, 자격 증명을 생성하고 검증하는 과정을 복잡하게 만들 수 있습니다.",
            "인증되지 않은 액세스를 위한 별도의 IAM 역할을 생성하는 것은 간단해 보일 수 있지만, Cognito가 제공하는 신원 관리 기능을 우회합니다. 이 접근 방식은 정책 관리에 문제를 초래할 수 있으며, Identity Pool을 사용하는 것만큼의 통합 및 보안을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "25",
        "Situation": "귀하는 준수 및 보안이 중요한 조직의 AWS 계정을 관리하고 있습니다. 감사 추적 및 보안 분석을 용이하게 하기 위해 AWS 환경 내에서 이루어진 모든 API 호출을 캡처하는 솔루션을 구현해야 합니다. 또한 이 데이터가 안전하게 저장되고 언제든지 검토할 수 있도록 접근할 수 있도록 해야 합니다.",
        "Question": "준수 및 보안 분석을 위한 API 호출 로그를 캡처하고 저장하는 데 가장 좋은 결과를 얻기 위해 어떤 AWS 서비스를 활용해야 합니까?",
        "Options": {
            "1": "AWS CloudTrail을 사용하여 모든 API 호출을 기록하고, 안전한 저장을 위해 서버 측 암호화가 활성화된 S3 버킷에 로그를 전달합니다.",
            "2": "Amazon CloudWatch를 사용하여 애플리케이션 로그를 모니터링하고 특정 API 호출 메트릭에 대한 경고를 설정합니다.",
            "3": "AWS Config를 사용하여 리소스 변경 사항을 추적하고 변경 사항이 발생할 때 SNS 주제에 알림을 보냅니다.",
            "4": "AWS CloudFormation을 사용하여 리소스를 정의하고 관리하며, AWS Lambda를 사용하여 실시간으로 API 호출을 캡처하여 로그를 기록합니다."
        },
        "Correct Answer": "AWS CloudTrail을 사용하여 모든 API 호출을 기록하고, 안전한 저장을 위해 서버 측 암호화가 활성화된 S3 버킷에 로그를 전달합니다.",
        "Explanation": "AWS CloudTrail은 AWS 계정에서 이루어진 모든 API 호출을 기록하도록 특별히 설계되어 있으며, 준수 및 보안 감사에 필요한 세부 정보를 제공합니다. 로그를 S3에 전달하고 서버 측 암호화를 지원하여 민감한 정보가 안전하게 저장되도록 합니다.",
        "Other Options": [
            "AWS CloudFormation은 주로 리소스 관리에 사용되며 API 호출을 본질적으로 캡처하지 않습니다. AWS Lambda는 이벤트를 처리할 수 있지만 API 호출에 대한 로깅 솔루션으로 설계되지 않았습니다.",
            "Amazon CloudWatch는 애플리케이션 성능 모니터링 및 경고에 유용하지만 API 호출 로그를 직접 캡처하지 않으므로 포괄적인 감사 추적에 적합하지 않습니다.",
            "AWS Config는 API 호출보다는 AWS 리소스의 구성 변경 사항을 추적하도록 설계되었습니다. 변경 사항에 대한 알림을 보낼 수 있지만 API 활동의 전체 로그를 제공하지는 않습니다."
        ]
    },
    {
        "Question Number": "26",
        "Situation": "한 온라인 소매 회사는 성능과 가용성을 높이기 위해 여러 AWS 리전에서 운영되고 있습니다. 이 회사는 제품 이미지를 저장하기 위해 Amazon S3, 콘텐츠 배달을 위해 Amazon CloudFront, DNS 관리를 위해 Amazon Route 53을 조합하여 사용하고 있습니다. 운영 팀은 웹 애플리케이션이 다양한 지리적 위치에서 사용자에게 원활하게 서비스를 제공할 수 있도록 하면서 데이터 일관성을 유지하고 높은 트래픽 기간 동안 지연 시간을 줄이는 임무를 맡고 있습니다. 그들은 복원력과 효율성을 개선하기 위해 리전 간 솔루션을 구현하는 것을 고려하고 있습니다.",
        "Question": "운영 팀이 애플리케이션을 위한 매우 복원력 있고 효율적인 리전 간 솔루션을 달성하기 위해 어떤 접근 방식을 취해야 합니까?",
        "Options": {
            "1": "여러 리전에서 애플리케이션을 배포하고 AWS Lambda 함수를 구성하여 리전 간 데이터 동기화를 관리하며, Amazon CloudFront를 사용하여 정적 콘텐츠를 캐시하여 성능을 향상시킵니다.",
            "2": "Amazon Route 53을 지연 기반 라우팅 정책으로 구성하여 사용자 요청을 가장 가까운 AWS 리전으로 유도하고, Amazon S3에 대해 리전 간 복제를 활성화하여 모든 리전에서 제품 이미지를 사용할 수 있도록 합니다.",
            "3": "여러 리전에서 Amazon RDS 읽기 복제를 구현하여 데이터베이스 부하를 분산시키고, Amazon CloudFront를 사용하여 동적 콘텐츠를 전 세계적으로 캐시하여 사용자가 자주 요청하는 데이터에 빠르게 접근할 수 있도록 합니다.",
            "4": "리전 간 복제가 활성화된 다중 리전 Amazon S3 버킷을 설정하고, Amazon Route 53을 장애 조치 라우팅 정책으로 구성하여 장애 발생 시 트래픽을 백업 리전으로 리디렉션합니다."
        },
        "Correct Answer": "Amazon Route 53을 지연 기반 라우팅 정책으로 구성하여 사용자 요청을 가장 가까운 AWS 리전으로 유도하고, Amazon S3에 대해 리전 간 복제를 활성화하여 모든 리전에서 제품 이미지를 사용할 수 있도록 합니다.",
        "Explanation": "이 솔루션은 Amazon Route 53의 지연 기반 라우팅을 활용하여 사용자를 가장 가까운 리전으로 유도하여 응답 시간과 사용자 경험을 개선합니다. Amazon S3의 리전 간 복제는 모든 리전에서 제품 이미지를 사용할 수 있도록 하여 높은 트래픽 기간 동안 복원력과 가용성을 향상시킵니다.",
        "Other Options": [
            "이 옵션은 Amazon RDS 읽기 복제 및 CloudFront를 캐싱에 집중하지만, S3에 저장된 제품 이미지의 글로벌 가용성 필요성을 해결하지 않으므로 애플리케이션에 중요합니다.",
            "이 옵션은 장애 조치 메커니즘을 설정하지만, 사용자 경험과 성능을 최적화하기 위해 사용자를 가장 가까운 리전으로 유도하는 데 필수적인 지연 기반 라우팅을 활용하지 않습니다.",
            "여러 리전에서 애플리케이션을 배포하는 것은 유익하지만, 데이터 동기화를 위해 AWS Lambda에만 의존하는 것은 지연 시간과 복잡성을 초래할 수 있으며, 콘텐츠 캐싱 및 가용성을 직접적으로 해결하지 않습니다."
        ]
    },
    {
        "Question Number": "27",
        "Situation": "한 스타트업은 AWS Elastic Beanstalk를 활용하여 웹 애플리케이션을 신속하게 배포하고 관리하고 있습니다. 팀은 애플리케이션이 적절하게 구조화되어 있으며 사용자 수요가 증가함에 따라 확장할 수 있도록 해야 합니다. 또한 다운타임을 최소화하는 배포 전략을 구현하는 것을 고려하고 있습니다.",
        "Question": "DevOps 엔지니어가 애플리케이션 배포를 최적화하고 Elastic Beanstalk 내에서 적절한 환경 관리를 보장하기 위해 어떤 두 가지 조치를 취해야 합니까? (두 가지 선택)",
        "Options": {
            "1": "Docker를 사용하여 앱을 컨테이너에 패키징하여 지원되지 않는 플랫폼을 배포합니다.",
            "2": "효율적인 데이터 관리를 위해 Elastic Beanstalk 환경 내에 데이터베이스 인스턴스를 생성합니다.",
            "3": "모든 환경에 여러 애플리케이션 버전을 동시에 배포하여 쉽게 롤백할 수 있도록 합니다.",
            "4": "블루/그린 배포 전략을 구현하여 최소한의 다운타임으로 애플리케이션 버전 간에 원활하게 전환합니다.",
            "5": "사용자-facing 애플리케이션을 위한 별도의 웹 서버 환경과 백그라운드 처리 작업을 위한 작업자 환경을 활용합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "사용자-facing 애플리케이션을 위한 별도의 웹 서버 환경과 백그라운드 처리 작업을 위한 작업자 환경을 활용합니다.",
            "블루/그린 배포 전략을 구현하여 최소한의 다운타임으로 애플리케이션 버전 간에 원활하게 전환합니다."
        ],
        "Explanation": "별도의 웹 서버 및 작업자 환경을 활용함으로써 스타트업은 사용자 상호작용과 백그라운드 처리를 효과적으로 분리하여 더 나은 리소스 관리 및 확장을 가능하게 합니다. 블루/그린 배포 전략을 구현하면 팀이 업데이트 중에 다운타임을 최소화하고 환경 간에 트래픽을 전환할 수 있습니다.",
        "Other Options": [
            "모든 환경에 여러 애플리케이션 버전을 동시에 배포하는 것은 버전 관리를 복잡하게 하고 불일치를 초래할 수 있어 명확한 배포 전략의 목적을 무색하게 합니다.",
            "Elastic Beanstalk 환경 내에 데이터베이스 인스턴스를 생성하는 것은 권장되지 않으며, 이는 데이터베이스 생애 주기를 애플리케이션에 묶어 독립적으로 관리하고 확장하기 어렵게 만듭니다.",
            "지원되지 않는 플랫폼을 배포하기 위해 Docker를 사용하는 것은 유용한 기능이지만, 이 시나리오에서 효과적인 환경 관리 또는 확장 전략의 필요성을 직접적으로 해결하지는 않습니다."
        ]
    },
    {
        "Question Number": "28",
        "Situation": "한 회사가 AWS CloudFormation을 사용하여 여러 AWS 계정과 리전에서 인프라 배포를 자동화하고 있습니다. 그들은 데이터베이스 자격 증명 및 API 키와 같은 민감한 정보를 안전하게 관리할 필요가 있습니다. 또한, 이 회사는 StackSets를 구현하여 배포를 효율적으로 관리할 계획입니다. DevOps 팀은 CloudFormation 템플릿이 런타임에 비밀 및 매개변수 값을 동적으로 검색할 수 있도록 보장하면서 보안 및 관리에 대한 모범 사례를 준수해야 합니다.",
        "Question": "DevOps 팀은 StackSets를 사용하여 여러 계정과 리전에서 런타임 비밀을 안전하게 검색하고 배포를 관리하기 위해 CloudFormation 템플릿을 어떻게 구성해야 합니까?",
        "Options": {
            "1": "CloudFormation 템플릿에서 매개변수 검색을 위한 정적 참조와 함께 AWS Systems Manager Parameter Store를 구현합니다. 여러 계정에서 배포를 관리하기 위해 Trusted Access를 활성화하지 않고 StackSets를 사용합니다.",
            "2": "비밀 검색을 위해 CloudFormation 템플릿에서 동적 참조와 함께 AWS Secrets Manager를 활용합니다. 템플릿을 계정과 리전 전역에 배포하기 위해 StackSet을 생성하고, 관리용으로 Organizations와 함께 Trusted Access가 설정되어 있는지 확인합니다.",
            "3": "매개변수 검색을 위해 CloudFormation 템플릿에서 동적 참조와 함께 SSM Parameter Store를 사용합니다. Trusted Access를 활성화하지 않고 여러 계정과 리전에서 배포를 위해 StackSets를 구현합니다.",
            "4": "비밀 검색을 위해 CloudFormation 템플릿에서 하드코딩된 참조와 함께 AWS Secrets Manager를 활용합니다. Organizations를 사용하지 않고 기본 계정에만 배포하도록 StackSets를 구성합니다."
        },
        "Correct Answer": "비밀 검색을 위해 CloudFormation 템플릿에서 동적 참조와 함께 AWS Secrets Manager를 활용합니다. 템플릿을 계정과 리전 전역에 배포하기 위해 StackSet을 생성하고, 관리용으로 Organizations와 함께 Trusted Access가 설정되어 있는지 확인합니다.",
        "Explanation": "AWS Secrets Manager를 동적 참조와 함께 사용하면 CloudFormation 템플릿이 런타임에 민감한 정보를 안전하게 검색할 수 있습니다. 이 접근 방식은 비밀 관리에 대한 모범 사례를 준수합니다. Trusted Access가 설정된 StackSets를 구현하면 여러 계정과 리전에서 템플릿의 효율적인 관리 및 배포가 가능합니다.",
        "Other Options": [
            "동적 참조와 함께 SSM Parameter Store를 사용하는 것은 안전한 옵션이지만, Trusted Access를 활성화하지 않으면 여러 계정에서 StackSets의 관리 기능이 제한됩니다.",
            "AWS Secrets Manager에 대한 하드코딩된 참조는 민감한 정보를 노출시키고 보안 모범 사례에 반합니다. 또한, StackSets를 기본 계정에만 배포하면 배포의 확장성과 효율성이 제한됩니다.",
            "AWS Systems Manager Parameter Store의 정적 참조는 비밀의 동적 검색을 허용하지 않으므로 CloudFormation을 사용하여 안전한 배포를 하는 목적에 반합니다. Trusted Access를 활성화하지 않는 것도 효과적인 다중 계정 관리를 방해합니다."
        ]
    },
    {
        "Question Number": "29",
        "Situation": "한 전자상거래 회사가 AWS로 인프라를 마이그레이션하고 있으며, Infrastructure as Code (IaC)를 사용하여 리소스 프로비저닝을 자동화하는 것을 목표로 하고 있습니다. DevOps 팀은 애플리케이션에 필요한 클라우드 리소스를 정의하고 관리하기 위해 AWS CloudFormation을 선택했습니다. 그들은 여러 환경에서 재사용성을 촉진하기 위해 CloudFormation 템플릿을 모듈화하고 싶어합니다. 팀은 재사용 가능한 구성 요소를 만들고 스택 업데이트를 효과적으로 관리하기 위한 최선의 접근 방식을 고려하고 있습니다.",
        "Question": "DevOps 팀은 AWS CloudFormation에서 재사용 가능한 구성 요소를 만들기 위해 어떤 접근 방식을 취해야 하며, 스택 업데이트가 관리 가능하고 기존 환경을 방해하지 않도록 해야 합니까?",
        "Options": {
            "1": "각 환경에 대해 개별 CloudFormation 템플릿을 만들고 모든 템플릿에서 구성을 복제하여 수동으로 업데이트를 관리합니다.",
            "2": "AWS CloudFormation 중첩 스택을 사용하여 재사용 가능한 구성 요소를 생성하고, 서로 다른 환경이 공통 리소스를 위해 단일 부모 스택을 참조할 수 있도록 합니다.",
            "3": "AWS CloudFormation StackSets를 활용하여 여러 계정과 리전에서 동일한 스택을 배포하여 모든 환경이 동기화되도록 합니다.",
            "4": "AWS CDK를 사용하여 프로그래밍 방식으로 인프라를 정의하여 재사용 가능한 구성 요소의 필요성을 없애고 스택 관리를 단순화합니다."
        },
        "Correct Answer": "AWS CloudFormation 중첩 스택을 사용하여 재사용 가능한 구성 요소를 생성하고, 서로 다른 환경이 공통 리소스를 위해 단일 부모 스택을 참조할 수 있도록 합니다.",
        "Explanation": "AWS CloudFormation 중첩 스택을 사용하면 조직이 서로 다른 환경에서 공유할 수 있는 재사용 가능한 구성 요소를 정의할 수 있어 중복을 줄이고 업데이트 관리를 용이하게 합니다. 중첩 스택에 대한 변경 사항은 이를 참조하는 모든 부모 스택에 반영되어 효율적인 업데이트를 촉진합니다.",
        "Other Options": [
            "각 환경에 대해 개별 CloudFormation 템플릿을 만드는 것은 코드 중복을 초래하고 업데이트 관리를 번거롭게 하며, 변경 사항을 여러 템플릿에 복제해야 합니다.",
            "AWS CDK를 활용하는 것은 재사용 가능한 구성 요소의 필요성을 본질적으로 없애지 않으며, 대신 기존 CloudFormation 관행과 일치하지 않을 수 있는 인프라 정의의 다른 방식을 도입하여 스택 관리가 복잡해질 수 있습니다.",
            "AWS CloudFormation StackSets를 활용하는 것은 여러 계정과 리전에서 스택을 배포하는 데 유용하지만, 단일 환경 내에서 재사용 가능한 구성 요소를 생성할 필요를 구체적으로 해결하지는 않습니다."
        ]
    },
    {
        "Question Number": "30",
        "Situation": "한 회사가 CloudWatch를 사용하여 AWS 리소스를 모니터링하고 있습니다. 그들은 모든 메트릭이 기본 두 주 제한을 초과하여 보존되도록 하고 싶어하며, 더 나은 통찰력을 위해 Auto Scaling 그룹 간의 메트릭 집계에도 관심이 있습니다. DevOps 엔지니어는 이러한 요구 사항을 충족하는 솔루션을 설정하는 임무를 맡고 있습니다.",
        "Question": "CloudWatch 메트릭이 두 주 이상 보존되고 Auto Scaling 그룹 간에 집계될 수 있도록 보장하는 가장 효과적인 방법은 무엇입니까?",
        "Options": {
            "1": "CloudWatch 메트릭 스트림을 사용하여 메트릭을 Amazon Kinesis Data Firehose 배달 스트림으로 전송합니다. 스트림을 구성하여 메트릭을 S3 버킷으로 전달하여 장기 저장합니다.",
            "2": "모든 EC2 인스턴스에서 상세 모니터링을 활성화하고 CloudWatch를 구성하여 메트릭을 Amazon RDS 데이터베이스에 직접 게시하여 더 긴 보존 및 집계를 제공합니다.",
            "3": "CloudWatch 대시보드를 생성하고 CloudWatch Logs를 사용하여 메트릭 데이터를 매일 S3 버킷으로 내보냅니다. S3 버킷에 대한 수명 주기 정책을 구성하여 데이터를 장기 보존합니다.",
            "4": "각 Auto Scaling 그룹에 대한 CloudWatch 경고를 설정하여 Lambda 함수를 트리거하여 매시간 메트릭을 DynamoDB에 기록하여 메트릭이 장기적으로 액세스될 수 있도록 합니다."
        },
        "Correct Answer": "CloudWatch 메트릭 스트림을 사용하여 메트릭을 Amazon Kinesis Data Firehose 배달 스트림으로 전송합니다. 스트림을 구성하여 메트릭을 S3 버킷으로 전달하여 장기 저장합니다.",
        "Explanation": "CloudWatch 메트릭 스트림을 사용하면 메트릭 데이터를 Kinesis Data Firehose로 지속적으로 전달할 수 있으며, 이를 S3 버킷으로 전송하도록 구성할 수 있습니다. 이 방법은 두 주 제한을 초과하여 메트릭의 장기 저장을 위한 확장 가능한 솔루션을 제공하며, 여러 Auto Scaling 그룹의 메트릭 집계 및 분석도 가능하게 합니다.",
        "Other Options": [
            "CloudWatch 대시보드를 생성하고 메트릭을 S3로 내보내는 것은 두 주 이상 보존을 보장하지 않으며, 메트릭을 적극적으로 내보내고 관리해야 하므로 간과할 위험이 있습니다.",
            "EC2 인스턴스에서 상세 모니터링을 활성화하면 추가 메트릭을 제공하지만, 두 주 이상 장기 저장 문제나 Auto Scaling 그룹 간의 메트릭 집계 문제를 해결하지는 않습니다.",
            "CloudWatch 경고를 설정하여 Lambda 함수를 트리거하여 메트릭을 DynamoDB에 기록하는 것은 불필요한 복잡성을 추가하며, 메트릭을 S3로 직접 스트리밍하는 것만큼의 확장성과 효율성을 제공하지 않을 수 있습니다."
        ]
    },
    {
        "Question Number": "31",
        "Situation": "한 회사가 AWS에서 고가용성과 잠재적인 중단으로부터의 신속한 복구가 필요한 중요한 애플리케이션을 운영하고 있습니다. 이 애플리케이션은 Elastic Load Balancer 뒤에 여러 개의 Amazon EC2 인스턴스를 사용합니다. 애플리케이션이 계속 운영될 수 있도록 DevOps 엔지니어는 시스템 장애를 감지하고 대응하기 위한 강력한 모니터링 및 경고 메커니즘을 설정해야 합니다.",
        "Question": "인스턴스 장애로부터 자동 복구를 보장하면서 애플리케이션에 대해 가장 효과적인 모니터링 및 경고 메커니즘을 제공하는 솔루션은 무엇입니까?",
        "Options": {
            "1": "Amazon CloudWatch 대시보드를 설정하여 메트릭을 시각화하고 잠재적인 문제에 대해 인스턴스 상태를 정기적으로 수동으로 확인합니다.",
            "2": "AWS CloudTrail을 사용하여 API 호출을 모니터링하고 무단 접근 시도에 대한 경고를 구성하되, 인스턴스 장애에 대해서는 수동 복구에 의존합니다.",
            "3": "EC2 인스턴스의 상태를 확인하고 감지 시 불건전한 인스턴스를 자동으로 재시작하는 Lambda 함수를 구현합니다.",
            "4": "인스턴스 상태 확인을 위한 CloudWatch 경고를 생성하고 이를 Amazon SNS 주제를 트리거하도록 구성하여 DevOps 팀에 알림을 보냅니다."
        },
        "Correct Answer": "인스턴스 상태 확인을 위한 CloudWatch 경고를 생성하고 이를 Amazon SNS 주제를 트리거하도록 구성하여 DevOps 팀에 알림을 보냅니다.",
        "Explanation": "인스턴스 상태 확인을 위한 CloudWatch 경고를 생성하면 인스턴스 장애를 즉시 감지할 수 있으며, Amazon SNS 주제를 트리거하면 DevOps 팀이 신속하게 통보받아 빠른 대응과 고가용성을 유지할 수 있습니다.",
        "Other Options": [
            "AWS CloudTrail을 사용하여 API 호출을 모니터링하는 것은 EC2 인스턴스에 대한 실시간 상태 확인을 제공하지 않으며, 수동 복구에 의존하므로 고가용성 애플리케이션에 적합하지 않습니다.",
            "메트릭을 시각화하기 위해 CloudWatch 대시보드를 설정하는 것은 유용하지만, 자동 경고 및 복구 메커니즘이 없으면 중요한 인스턴스 장애에 대한 응답이 지연될 수 있습니다.",
            "상태 확인을 위한 Lambda 함수를 구현하는 것은 유익하지만, CloudWatch 경고가 제공할 수 있는 즉각적인 경고 기능을 제공하지 않을 수 있으며, 이는 신속한 사고 대응에 중요합니다."
        ]
    },
    {
        "Question Number": "32",
        "Situation": "소프트웨어 개발 회사가 지속적인 통합 전략을 채택하고 있습니다. 그들은 모든 풀 리퀘스트가 빌드를 트리거하고 자동화된 테스트를 실행하여 메인 브랜치에 병합하기 전에 코드 품질을 검증하도록 하고 싶어합니다. 그들은 버전 관리를 위해 AWS CodeCommit을 사용하고 빌드 및 테스트 실행을 위해 AWS CodeBuild를 사용하고 있습니다.",
        "Question": "DevOps 엔지니어로서 이 목표를 효율적으로 달성하기 위해 어떤 접근 방식을 추천해야 합니까?",
        "Options": {
            "1": "AWS CodePipeline을 활용하여 CodeCommit 리포지토리의 풀 리퀘스트에 의해 트리거되는 파이프라인을 정의합니다. 이 파이프라인에는 테스트를 실행하고 결과를 리포지토리에 보고하는 CodeBuild 작업이 포함되어야 합니다.",
            "2": "CodeCommit 리포지토리를 모니터링하는 Lambda 함수를 설정하고 각 요청에 대해 CodeBuild 프로젝트를 트리거합니다. Lambda 함수가 CloudWatch에 로그를 전송하도록 합니다.",
            "3": "CodeCommit에서 풀 리퀘스트가 생성될 때마다 자동으로 테스트를 실행하는 CodeBuild 프로젝트를 트리거하는 웹훅을 생성합니다. 테스트 결과에 따라 개발 팀에 알림을 보내도록 CodeBuild를 구성합니다.",
            "4": "CodeCommit과 GitHub 통합을 구현하여 GitHub에서 풀 리퀘스트가 생성될 때마다 CodeBuild 프로젝트를 트리거하고, CodeBuild가 결과를 S3 버킷에 게시하도록 구성합니다."
        },
        "Correct Answer": "AWS CodePipeline을 활용하여 CodeCommit 리포지토리의 풀 리퀘스트에 의해 트리거되는 파이프라인을 정의합니다. 이 파이프라인에는 테스트를 실행하고 결과를 리포지토리에 보고하는 CodeBuild 작업이 포함되어야 합니다.",
        "Explanation": "AWS CodePipeline을 사용하면 빌드 및 테스트 단계에 대한 명확한 가시성을 갖춘 구조화된 접근 방식을 통해 테스트 프로세스를 자동화할 수 있습니다. 이 통합은 모든 풀 리퀘스트가 병합 전에 파이프라인을 통해 검증되도록 하여 코드 품질 관리를 향상시킵니다.",
        "Other Options": [
            "CodeCommit에서 웹훅을 생성하는 것은 실행 가능한 접근 방식이지만, 롤백이나 다단계 테스트와 같은 파이프라인의 포괄적인 기능이 부족하여 강력한 CI/CD 프로세스에 필수적입니다.",
            "Lambda 함수를 사용하여 풀 리퀘스트를 모니터링하는 것은 간접적인 방법으로 불필요한 복잡성과 잠재적인 지연을 추가합니다. 이는 CodePipeline의 내장 기능을 활용하지 않으며 관리 오버헤드를 초래할 수 있습니다.",
            "GitHub와 통합하는 것은 CodeCommit을 사용하도록 설정되어 있으므로 적용할 수 없습니다. 이 옵션은 다른 소스 제어 시스템을 도입하므로 요구 사항을 충족하지 않습니다."
        ]
    },
    {
        "Question Number": "33",
        "Situation": "한 회사가 AWS에서 인프라를 확장하고 있으며, 모든 새로운 AWS 계정이 준수 및 보안 모범 사례를 위한 표준화된 구성을 따르도록 해야 합니다. 그들은 이러한 계정의 프로비저닝 및 구성을 자동화하기 위해 코드로서의 인프라(IaC) 도구를 사용하는 것을 고려하고 있습니다.",
        "Question": "회사가 새로운 AWS 계정의 구성을 표준화하고 프로비저닝을 자동화하기 위해 어떤 접근 방식을 취해야 합니까?",
        "Options": {
            "1": "AWS Config 규칙을 사용하여 생성된 후 기존 AWS 계정에 대한 준수 정책을 시행합니다.",
            "2": "AWS Management Console을 사용하여 각 새로운 AWS 계정을 수동으로 구성하여 표준 준수를 보장합니다.",
            "3": "AWS Service Catalog를 구현하여 미리 정의된 포트폴리오를 통해 리소스를 관리하고 프로비저닝합니다.",
            "4": "AWS CloudFormation StackSets를 활용하여 AWS Organizations의 여러 계정에 표준화된 템플릿을 배포합니다."
        },
        "Correct Answer": "AWS CloudFormation StackSets를 활용하여 AWS Organizations의 여러 계정에 표준화된 템플릿을 배포합니다.",
        "Explanation": "AWS CloudFormation StackSets를 사용하면 단일 작업으로 여러 계정 및 리전에서 스택을 생성, 업데이트 또는 삭제할 수 있습니다. 이는 모든 AWS 계정이 표준화된 구성으로 프로비저닝되도록 보장하는 프로세스를 크게 단순화하여 준수 및 자동화에 이상적인 선택입니다.",
        "Other Options": [
            "각 새로운 AWS 계정을 수동으로 구성하는 것은 비효율적이며 인적 오류의 위험을 증가시켜 불일치 및 준수 문제를 초래할 수 있습니다.",
            "AWS Config 규칙을 사용하는 것은 계정이 생성된 후에만 준수를 시행하므로, 새로운 계정에 필요한 프로비저닝 프로세스를 표준화하지 않습니다.",
            "AWS Service Catalog를 구현하는 것은 리소스를 관리하는 데 도움이 될 수 있지만, 계정의 프로비저닝을 직접 자동화하거나 여러 계정에 대한 구성 표준을 시행하지 않습니다."
        ]
    },
    {
        "Question Number": "34",
        "Situation": "DevOps 팀은 여러 AWS 계정에 배포된 다양한 애플리케이션의 규정 준수를 유지하는 책임이 있습니다. 그들은 AWS Systems Manager를 사용하여 규정 준수 기준을 시행하고 구성 변동을 관리합니다. 최근 그들은 의도한 상태와 실제 상태 간의 불일치를 발견했습니다. 팀은 규정 준수 검사가 효과적이며 자동으로 변동을 수정할 수 있도록 해야 합니다.",
        "Question": "팀이 소프트웨어 규정 준수를 보장하고 구성 변동을 효과적으로 관리하기 위해 사용할 수 있는 전략은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "정기적으로 구성을 적용하기 위해 Systems Manager State Manager를 예약합니다.",
            "2": "AWS CloudTrail을 사용하여 구성 변경 사항을 추적합니다.",
            "3": "AWS Config 규칙을 사용하여 구성 항목의 규정 준수를 모니터링합니다.",
            "4": "규정 준수 검사를 위한 수동 검토 프로세스를 구현합니다.",
            "5": "Systems Manager Inventory를 활용하여 메타데이터 및 규정 준수 데이터를 수집합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "AWS Config 규칙을 사용하여 구성 항목의 규정 준수를 모니터링합니다.",
            "정기적으로 구성을 적용하기 위해 Systems Manager State Manager를 예약합니다."
        ],
        "Explanation": "AWS Config 규칙을 사용하면 팀이 규정 준수 규칙을 정의하고 구성 변경 사항을 실시간으로 추적할 수 있어 리소스가 원하는 구성에 부합하도록 보장합니다. 정기적으로 Systems Manager State Manager를 예약하여 구성을 적용하면 의도한 상태에서의 변동을 자동으로 수정하여 효과적으로 규정 준수를 유지할 수 있습니다.",
        "Other Options": [
            "규정 준수 검사를 위한 수동 검토 프로세스를 구현하는 것은 비효율적이며 인적 오류에 취약하여 자동화 솔루션에 비해 규정 준수를 유지하는 데 덜 효과적입니다.",
            "AWS CloudTrail을 사용하여 구성 변경 사항을 추적하면 변경 사항에 대한 가시성을 제공하지만 규정 준수를 적극적으로 시행하거나 구성 변동을 관리하지는 않습니다.",
            "Systems Manager Inventory를 활용하여 메타데이터 및 규정 준수 데이터를 수집하는 것은 가시성에 유용하지만, 규정 준수 시행에 중요한 구성 적용이나 변동 관리를 직접 수행하지는 않습니다."
        ]
    },
    {
        "Question Number": "35",
        "Situation": "개발 팀은 아티팩트 관리를 위해 AWS 서비스를 활용하여 애플리케이션 배포 프로세스를 간소화하려고 합니다. 그들은 아티팩트가 안전하게 저장되고 적절하게 버전 관리되며 다양한 환경에서 쉽게 접근할 수 있도록 하기를 원합니다. 팀은 AWS CodeArtifact와 Amazon ECR을 사용하기로 결정했습니다. DevOps 엔지니어가 효율적인 아티팩트 관리를 달성하기 위해 구현해야 할 단계의 조합은 무엇입니까? (두 가지 선택)",
        "Question": "DevOps 엔지니어가 효율적인 아티팩트 관리를 달성하기 위해 구현해야 할 단계의 조합은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "Amazon ECR을 설정하여 Docker 이미지를 저장하고, 롤백을 쉽게 할 수 있도록 버전 관리 및 태깅을 활성화합니다.",
            "2": "AWS Lambda를 사용하여 특정 보존 정책에 따라 AWS CodeArtifact에서 오래된 아티팩트 버전을 자동으로 정리합니다.",
            "3": "빌드 아티팩트를 저장하기 위해 Amazon S3 버킷을 생성하고 보존 관리를 위한 수명 주기 정책을 설정합니다.",
            "4": "AWS CodePipeline을 AWS CodeArtifact 및 Amazon ECR과 통합하여 자동 배포를 수행합니다.",
            "5": "AWS CodeArtifact를 구성하여 애플리케이션에서 사용되는 모든 종속성과 라이브러리를 저장하고 관리합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "AWS CodeArtifact를 구성하여 애플리케이션에서 사용되는 모든 종속성과 라이브러리를 저장하고 관리합니다.",
            "Amazon ECR을 설정하여 Docker 이미지를 저장하고, 롤백을 쉽게 할 수 있도록 버전 관리 및 태깅을 활성화합니다."
        ],
        "Explanation": "AWS CodeArtifact를 구성함으로써 팀은 라이브러리와 종속성을 효율적으로 관리하고 버전 관리를 통해 배포 간 일관된 버전을 사용할 수 있도록 보장합니다. Amazon ECR을 설정하면 팀이 Docker 이미지를 저장하고 버전 관리 및 쉬운 롤백을 가능하게 하여 컨테이너화된 애플리케이션에 필수적입니다.",
        "Other Options": [
            "빌드 아티팩트를 저장하기 위해 Amazon S3 버킷을 생성하는 것은 유효한 단계이지만, AWS CodeArtifact만큼 효과적으로 버전 관리 및 종속성 관리를 다루지 않습니다.",
            "AWS CodePipeline을 AWS CodeArtifact 및 Amazon ECR과 통합하는 것은 자동화에 유익하지만, 질문의 초점인 아티팩트 관리 프로세스에 직접 기여하지는 않습니다.",
            "AWS CodeArtifact에서 오래된 버전을 정리하기 위해 AWS Lambda를 사용하는 것은 좋은 관행이지만, 아티팩트 저장 및 버전 관리의 초기 설정에 직접적으로 도움이 되지는 않습니다."
        ]
    },
    {
        "Question Number": "36",
        "Situation": "당신은 Amazon EC2 인스턴스와 Amazon ECS에서 호스팅되는 컨테이너화된 애플리케이션의 배포 수명 주기를 관리하는 책임이 있습니다. EC2 인스턴스와 컨테이너 이미지 모두에 대한 이미지 빌드 프로세스를 간소화하고 자동화하기 위해 수동 개입을 최소화하고 배포 간 일관성을 보장하는 솔루션을 구현하고자 합니다.",
        "Question": "EC2 인스턴스와 컨테이너 이미지 모두에 대한 이미지 빌드 프로세스를 효율적으로 자동화하기 위해 구현해야 할 솔루션은 무엇입니까?",
        "Options": {
            "1": "AWS CodePipeline과 EC2 Image Builder를 활용하여 AMI 생성을 자동화하고, 동일한 파이프라인의 일환으로 Amazon ECR에서 컨테이너 이미지 빌드를 트리거합니다.",
            "2": "AWS CloudFormation을 사용하여 인프라를 정의하고 AWS Management Console을 통해 EC2 인스턴스와 컨테이너 모두에 대한 이미지 빌드를 수동으로 트리거합니다.",
            "3": "S3 이벤트를 수신하여 소스 코드 변경 사항에 따라 EC2 Image Builder 및 ECR 이미지 빌드를 트리거하는 Lambda 함수를 구현합니다.",
            "4": "EC2 인스턴스에서 크론 작업을 설정하여 필요할 때마다 AMI를 수동으로 빌드하고 컨테이너 이미지를 Amazon ECR에 푸시하는 스크립트를 실행합니다."
        },
        "Correct Answer": "AWS CodePipeline과 EC2 Image Builder를 활용하여 AMI 생성을 자동화하고, 동일한 파이프라인의 일환으로 Amazon ECR에서 컨테이너 이미지 빌드를 트리거합니다.",
        "Explanation": "AWS CodePipeline과 EC2 Image Builder를 사용하면 EC2 인스턴스용 AMI와 ECS용 컨테이너 이미지를 빌드하는 프로세스를 간소화하는 완전 자동화되고 통합된 솔루션을 제공합니다. 이 접근 방식은 일관성을 보장하고 수동 노력을 줄이며 배포 수명 주기를 위한 명확하고 유지 관리 가능한 파이프라인을 제공합니다.",
        "Other Options": [
            "크론 작업을 설정하면 수동 오버헤드가 발생하며 확장 가능한 솔루션이 아닙니다. 또한 다른 AWS 서비스와의 통합이 부족하여 자동화에 덜 효율적입니다.",
            "인프라 정의를 위해 AWS CloudFormation을 사용하는 것은 유익하지만, 이미지 빌드를 수동으로 트리거하는 것은 자동화 목표에 반합니다. 이 방법은 지속적인 통합 및 배포를 위한 간소화된 프로세스를 제공하지 않습니다.",
            "S3 이벤트에 대한 Lambda 함수를 구현하는 것은 자동화된 것처럼 보일 수 있지만, 외부 트리거에 의존하며 EC2 이미지와 컨테이너 이미지를 효율적으로 관리하기 위한 통합된 파이프라인을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "37",
        "Situation": "DevOps 엔지니어는 AWS에 새로 배포된 웹 애플리케이션의 자동 확장 기능을 테스트하는 임무를 맡았습니다. 그들은 애플리케이션이 정의된 정책에 따라 확장되는지 확인하기 위해 트래픽을 시뮬레이션하고 성능을 모니터링해야 합니다. 엔지니어는 이 목적을 위해 Bees with Machine Guns 도구를 사용하기로 결정했습니다.",
        "Question": "DevOps 엔지니어가 Bees with Machine Guns를 사용하여 트래픽을 효과적으로 시뮬레이션하고 애플리케이션의 자동 확장을 테스트하기 위해 어떤 단계를 밟아야 합니까?",
        "Options": {
            "1": "'sudo apt-get install beeswithmachineguns'를 사용하여 Bees 도구를 설치하고, 환경을 설정하기 위해 CloudFormation 스택을 생성한 후, 'bees attack -n 1000 -c 250'을 실행하여 정적 IP에 대해 부하 테스트를 시작합니다.",
            "2": "'sudo pip install beeswithmachineguns paramiko'를 실행하여 필요한 패키지를 설치하고, .boto에서 액세스 키를 구성한 후, 'ssh-keygen'으로 SSH 키를 생성하고, 'bees up -s 10 -g bees -k bees'를 실행하여 부하 테스트를 위한 10개의 인스턴스를 생성합니다.",
            "3": "Docker를 통해 Bees with Machine Guns를 배포하고, 로드 밸런서를 구성한 후, 'bees attack -n 1000 -c 250 -u http://elbdns'를 실행하여 인스턴스 수를 고려하지 않고 트래픽을 시뮬레이션합니다.",
            "4": "'pip install beeswithmachineguns'를 사용하여 Bees with Machine Guns를 설치하고, 인바운드 트래픽을 허용하도록 보안 그룹을 구성한 후, 'bees attack'을 실행하여 인스턴스를 사전에 설정하지 않고 부하 테스트를 수행합니다."
        },
        "Correct Answer": "'sudo pip install beeswithmachineguns paramiko'를 실행하여 필요한 패키지를 설치하고, .boto에서 액세스 키를 구성한 후, 'ssh-keygen'으로 SSH 키를 생성하고, 'bees up -s 10 -g bees -k bees'를 실행하여 부하 테스트를 위한 10개의 인스턴스를 생성합니다.",
        "Explanation": "이 옵션은 패키지 설치, 액세스 키 구성, SSH 키 생성 및 부하 테스트에 필요한 인스턴스 시작을 포함하여 자동 확장을 테스트하기 위해 Bees with Machine Guns를 설정하는 데 필요한 전체 단계를 올바르게 설명합니다.",
        "Other Options": [
            "이 옵션은 Bees with Machine Guns를 'apt-get'을 사용하여 설치하라고 잘못 제안하며, 이 도구에 적합한 방법이 아닙니다. 또한 작업에 불필요한 CloudFormation 스택 생성을 언급합니다.",
            "이 옵션은 'bees up'을 사용한 필수 인스턴스 설정을 언급하지 않으며, 애플리케이션에 필요한 인스턴스를 먼저 시작하지 않고 부하 테스트를 실행할 수 있다고 잘못 가정합니다.",
            "이 옵션은 Docker를 통해 Bees with Machine Guns를 배포하는 것을 언급하지만, 자동 확장을 테스트하는 데 필수적이지 않습니다. 또한 부하를 효과적으로 시뮬레이션하기 위해 인스턴스를 생성하는 것을 간과합니다."
        ]
    },
    {
        "Question Number": "38",
        "Situation": "한 회사가 AWS Lambda와 Amazon API Gateway를 사용하여 서버리스 애플리케이션을 개발하고 있습니다. 이 애플리케이션은 다양한 트래픽 수준을 처리하도록 설계되었으며, 팀은 피크 사용 시간 동안 애플리케이션이 항상 사용 가능하고 응답성이 유지되도록 하기를 원합니다. 애플리케이션은 수동 개입 없이 수요 변화에 따라 자동으로 확장되어야 합니다.",
        "Question": "서버리스 애플리케이션을 구성하여 다양한 트래픽 부하에서 높은 가용성과 자동 확장을 달성하기 위한 최선의 접근 방식은 무엇입니까?",
        "Options": {
            "1": "Amazon API Gateway를 구성하여 AWS Lambda 함수를 호출하고, 요청 비율 및 동시성 설정에 따라 자동으로 확장되도록 합니다.",
            "2": "Amazon CloudFront를 콘텐츠 전송 네트워크(CDN)로 설정하여 API 응답을 캐시하고 백엔드 서비스의 부하를 줄입니다.",
            "3": "AWS Fargate를 구현하여 트래픽에 따라 용량을 자동으로 조정하는 관리형 환경에서 컨테이너화된 애플리케이션을 실행합니다.",
            "4": "Amazon EC2 인스턴스를 애플리케이션 로드 밸런서 뒤에 두어 들어오는 요청을 처리하고 CPU 사용량에 따라 확장합니다."
        },
        "Correct Answer": "Amazon API Gateway를 구성하여 AWS Lambda 함수를 호출하고, 요청 비율 및 동시성 설정에 따라 자동으로 확장되도록 합니다.",
        "Explanation": "Amazon API Gateway와 AWS Lambda를 사용하면 애플리케이션이 들어오는 요청 비율에 따라 자동으로 확장됩니다. Lambda 함수는 트래픽의 급증을 처리하고 수동 개입 없이 원활하게 확장되어 피크 시간 동안 높은 가용성과 응답성을 보장합니다.",
        "Other Options": [
            "Amazon EC2 인스턴스를 애플리케이션 로드 밸런서 뒤에 두는 것은 서버 인스턴스를 수동으로 관리해야 하며, 서버리스 솔루션만큼 자동 확장을 제공하지 않습니다.",
            "AWS Fargate는 컨테이너화된 애플리케이션에 대한 자동 확장을 제공하지만, Lambda의 서버리스 접근 방식에 비해 예측할 수 없는 API 요청을 처리하는 데 효율적이지 않습니다.",
            "Amazon CloudFront를 설정하는 것은 응답을 캐시하는 데 유용하지만, 다양한 트래픽 부하에 따라 백엔드 서비스의 확장 필요성을 직접적으로 해결하지 않습니다."
        ]
    },
    {
        "Question Number": "39",
        "Situation": "소프트웨어 개발 팀은 AWS CodeDeploy를 사용하여 마이크로서비스 아키텍처의 배포를 자동화하고 있습니다. 최근 배포가 간헐적으로 실패하기 시작했으며, 팀은 이러한 문제를 효율적으로 해결해야 합니다. DevOps 엔지니어는 이러한 실패의 근본 원인을 파악하고 다운타임을 최소화하는 솔루션을 구현할 책임이 있습니다.",
        "Question": "DevOps 엔지니어가 AWS CodeDeploy에서 배포 실패를 진단하고 해결하기 위한 최선의 접근 방식은 무엇입니까?",
        "Options": {
            "1": "배포 구성을 수정하여 블루/그린 배포 전략을 사용하고, 트래픽을 라우팅하기 전에 새 인스턴스의 상태를 모니터링합니다.",
            "2": "AWS CloudWatch에서 CodeDeploy 애플리케이션에 대한 상세 모니터링을 활성화하고 로그를 분석하여 배포 오류를 식별합니다.",
            "3": "AWS CloudTrail을 사용하여 배포 과정에서 CodeDeploy가 수행한 API 호출을 검토하고, 무단 변경 사항을 식별합니다.",
            "4": "CodeDeploy에서 배포 스크립트의 실행 시간을 늘리기 위해 배포 타임아웃 설정을 증가시킵니다."
        },
        "Correct Answer": "AWS CloudWatch에서 CodeDeploy 애플리케이션에 대한 상세 모니터링을 활성화하고 로그를 분석하여 배포 오류를 식별합니다.",
        "Explanation": "AWS CloudWatch에서 상세 모니터링을 활성화하면 DevOps 엔지니어가 배포 과정에 대한 통찰력을 얻고 배포 중 발생한 정확한 오류를 파악할 수 있는 로그에 접근할 수 있어, 문제 해결을 위한 가장 효과적인 접근 방식입니다.",
        "Other Options": [
            "블루/그린 배포 전략은 다운타임을 줄이고 가용성을 향상시킬 수 있지만, 기존 배포 실패를 효과적으로 해결할 필요성을 직접적으로 다루지 않습니다.",
            "AWS CloudTrail을 사용하여 API 호출을 검토하는 것은 보안 감사에 유용하지만, 배포 과정이나 배포 중 발생한 특정 오류에 대한 상세 정보를 제공하지 않습니다.",
            "배포 타임아웃 설정을 증가시키는 것은 문제를 일시적으로 숨길 수 있지만, 근본적인 배포 오류를 해결하지 않으며, 이는 향후 더 큰 문제를 초래할 수 있습니다."
        ]
    },
    {
        "Question Number": "40",
        "Situation": "개발 팀이 마이크로서비스 아키텍처에서 작업하고 있으며 CI/CD 파이프라인의 일환으로 컨테이너 이미지를 구축, 저장 및 관리할 수 있는 신뢰할 수 있는 방법이 필요합니다. 그들은 소스 코드에서 이미지를 자동으로 구축하고 배포를 위해 안전하게 저장하는 솔루션을 요구합니다. 팀은 수동 단계에 소요되는 시간을 최소화하여 워크플로우를 간소화하는 것을 목표로 하고 있습니다.",
        "Question": "다음 솔루션 중 팀의 자동화된 CI/CD 파이프라인에서 컨테이너 이미지를 관리하는 요구 사항을 가장 잘 충족하는 것은 무엇입니까?",
        "Options": {
            "1": "AWS Lambda를 사용하여 이미지를 구축하고 AWS CloudFormation에 저장합니다.",
            "2": "AWS CodeBuild를 사용하여 컨테이너 이미지를 생성하고 Amazon ECR에 저장합니다.",
            "3": "Jenkins 서버를 배포하여 이미지를 구축하고 자체 호스팅된 레지스트리에서 관리합니다.",
            "4": "Docker CLI를 사용하여 컨테이너 이미지를 수동으로 구축하고 Amazon S3에 푸시합니다."
        },
        "Correct Answer": "AWS CodeBuild를 사용하여 컨테이너 이미지를 생성하고 Amazon ECR에 저장합니다.",
        "Explanation": "AWS CodeBuild는 소스 코드를 컴파일하고 테스트를 실행하며 배포 준비가 된 소프트웨어 패키지를 생성하는 완전 관리형 빌드 서비스입니다. Amazon ECR과 원활하게 통합되어 팀이 안전하고 확장 가능한 환경에서 컨테이너 이미지를 자동으로 구축하고 저장할 수 있도록 합니다.",
        "Other Options": [
            "Docker CLI를 사용하여 컨테이너 이미지를 수동으로 구축하고 Amazon S3에 푸시하는 것은 CI/CD 파이프라인에서 아티팩트를 관리하는 최선의 방법이 아닙니다. 이 접근 방식은 수동 개입이 필요하여 팀의 수동 단계를 최소화하려는 목표와 모순됩니다.",
            "AWS Lambda를 사용하여 이미지를 구축하고 AWS CloudFormation에 저장하는 것은 불가능합니다. AWS Lambda는 컨테이너 이미지를 구축하도록 설계되지 않았습니다. CloudFormation은 코드로서의 인프라 서비스이며, 컨테이너 레지스트리 역할을 하지 않습니다.",
            "Jenkins 서버를 배포하면 이미지 구축을 용이하게 할 수 있지만, Jenkins 인프라 관리에 추가적인 오버헤드를 초래합니다. 이 접근 방식은 CI/CD 워크플로우를 위해 특별히 설계된 완전 관리형 서비스인 AWS CodeBuild를 사용하는 것보다 효율성이 떨어집니다."
        ]
    },
    {
        "Question Number": "41",
        "Situation": "AWS에 호스팅된 마이크로서비스 기반 애플리케이션을 위한 CI/CD 파이프라인을 구현하고 있습니다. 파이프라인에는 빌드, 테스트 및 배포와 같은 다양한 단계가 포함됩니다. 각 단계가 문제를 조기에 발견하고 코드 품질을 유지하기 위해 적절한 유형의 테스트를 포함하도록 하고 싶습니다. 사용 가능한 다양한 테스트 유형을 고려할 때, CI/CD 파이프라인 전반에 걸쳐 구현하기에 가장 효과적인 테스트 전략은 무엇입니까?",
        "Question": "최고의 코드 품질을 보장하기 위해 CI/CD 파이프라인의 다양한 단계에서 우선시해야 할 테스트 전략은 무엇입니까?",
        "Options": {
            "1": "성능 테스트는 빌드 단계에서 수행하여 애플리케이션이 부하 요구 사항을 충족하는지 확인하고, 테스트 단계에서 단위 테스트를 수행하며, 배포 단계에서 종단 간 테스트를 수행해야 합니다.",
            "2": "통합 테스트는 빌드 단계에서 수행하여 구성 요소가 함께 작동하는지 확인하고, 테스트 단계에서 단위 테스트를 수행하며, 배포 단계에서 보안 테스트를 수행해야 합니다.",
            "3": "종단 간 테스트는 빌드 단계에서 수행하여 애플리케이션 전체를 검증하고, 테스트 단계에서 단위 테스트를 수행하며, 배포 단계에서 성능 테스트를 수행해야 합니다.",
            "4": "단위 테스트는 빌드 단계에서 수행하여 문제를 조기에 발견하고, 테스트 단계에서 통합 테스트를 수행하며, 배포 단계에서 종단 간 테스트를 수행해야 합니다."
        },
        "Correct Answer": "단위 테스트는 빌드 단계에서 수행하여 문제를 조기에 발견하고, 테스트 단계에서 통합 테스트를 수행하며, 배포 단계에서 종단 간 테스트를 수행해야 합니다.",
        "Explanation": "이 전략은 단위 테스트가 코드의 정확성에 대한 즉각적인 피드백을 제공하고, 통합 테스트가 구성 요소 간의 상호 작용을 검증하며, 종단 간 테스트가 전체 애플리케이션이 의도한 대로 작동하는지 확인하기 때문에 효과적입니다. 이러한 계층적 접근 방식은 가능한 한 이른 단계에서 문제를 식별하고 해결하는 데 도움이 됩니다.",
        "Other Options": [
            "빌드 단계에서 종단 간 테스트를 실행하는 것은 비효율적입니다. 이 테스트는 더 많은 리소스를 소모하며, 코드가 더 안정적일 때 파이프라인의 후반부에서 수행해야 합니다.",
            "빌드 단계에서 통합 테스트를 수행하는 것은 문제를 조기에 식별할 수 없으며, 단위 테스트는 개별 구성 요소의 오류를 먼저 잡도록 설계되었기 때문입니다.",
            "빌드 단계에서 성능 테스트를 수행하는 것은 시기상조입니다. 성능은 단위 및 통합 테스트가 애플리케이션이 올바르게 작동함을 확인한 후에 평가해야 합니다."
        ]
    },
    {
        "Question Number": "42",
        "Situation": "DevOps 엔지니어가 전자상거래 애플리케이션에서 주문을 처리하기 위한 워크플로우를 설계하고 있습니다. 이 워크플로우는 입력 매개변수와 출력을 포함하여 각 실행의 세부 감사 추적을 유지해야 합니다. 엔지니어는 이 요구 사항을 효과적으로 구현하기 위해 다양한 AWS 서비스를 고려하고 있습니다.",
        "Question": "DevOps 엔지니어가 모든 실행의 감사 추적이 유지되도록 보장하기 위해 선택해야 할 AWS 서비스는 무엇입니까?",
        "Options": {
            "1": "AWS Step Functions를 사용하여 실행 세부 정보를 자동으로 기록하고 상태 전환을 추적합니다.",
            "2": "AWS CloudTrail을 사용하여 애플리케이션 내에서 이루어진 API 호출을 기록합니다.",
            "3": "Amazon S3를 사용하여 실행 로그를 저장하여 나중에 검토합니다.",
            "4": "Amazon CloudWatch를 사용하여 워크플로우 성능 모니터링을 위한 메트릭을 생성합니다."
        },
        "Correct Answer": "AWS Step Functions를 사용하여 실행 세부 정보를 자동으로 기록하고 상태 전환을 추적합니다.",
        "Explanation": "AWS Step Functions는 각 실행에 대한 내장 감사 추적을 제공하며, 워크플로우의 각 단계에서 입력 및 출력을 포함합니다. 이는 실행 세부 정보와 상태 전환의 상세 로그가 필요한 애플리케이션에 가장 적합한 선택입니다.",
        "Other Options": [
            "AWS CloudTrail은 API 호출을 기록하지만 워크플로우에 대한 상세 실행 로그를 제공하거나 상태 전환을 유지하지 않습니다.",
            "Amazon S3는 실행 로그를 저장할 수 있지만, 실행 상태를 본질적으로 추적하거나 워크플로우의 구조화된 감사 추적을 제공하지 않습니다.",
            "Amazon CloudWatch는 주로 모니터링 및 경고에 사용되며, 성능 메트릭을 추적할 수 있지만 워크플로우 실행의 상세 감사 추적을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "43",
        "Situation": "한 금융 서비스 회사가 대량의 사용자 데이터에 빠르게 접근할 수 있는 서버리스 애플리케이션을 구축하고 있습니다. 이 애플리케이션은 Amazon DynamoDB를 사용하여 사용자 프로필과 접근 로그를 저장합니다. DevOps 엔지니어는 최소한의 지연 시간과 비용을 보장하면서 데이터 검색 프로세스를 최적화해야 합니다. 엔지니어는 DynamoDB 작업의 제한 사항을 준수하면서 단일 요청으로 여러 사용자 프로필을 효율적으로 검색하기 위해 어떤 접근 방식을 취해야 할까요?",
        "Question": "DevOps 엔지니어는 요청 제한을 준수하면서 DynamoDB를 사용하여 여러 사용자 프로필을 효율적으로 어떻게 검색해야 합니까?",
        "Options": {
            "1": "BatchGetItem API를 사용하여 단일 요청으로 최대 100개의 사용자 프로필을 가져오고, 총 응답 크기가 16MB를 초과하지 않도록 합니다.",
            "2": "GetItem API를 사용하여 각 사용자 프로필을 개별적으로 검색하고 결과를 단일 응답으로 집계합니다.",
            "3": "Scan API를 사용하여 모든 사용자 프로필을 검색하고 데이터가 가져온 후 애플리케이션에서 결과를 필터링합니다.",
            "4": "특정 기준에 맞는 사용자 프로필을 찾기 위해 매번 전체 테이블을 스캔하는 Query 작업을 사용합니다."
        },
        "Correct Answer": "BatchGetItem API를 사용하여 단일 요청으로 최대 100개의 사용자 프로필을 가져오고, 총 응답 크기가 16MB를 초과하지 않도록 합니다.",
        "Explanation": "BatchGetItem API를 사용하면 엔지니어가 단일 요청으로 여러 항목(최대 100개)을 효율적으로 검색할 수 있어 성능과 비용을 최적화할 수 있습니다. 이 접근 방식은 DynamoDB의 제한 사항을 준수하며 설명된 사용 사례에 이상적입니다.",
        "Other Options": [
            "각 사용자 프로필에 대해 GetItem API를 개별적으로 사용하는 것은 여러 요청을 초래하여 지연 시간과 비용이 증가하므로 이 시나리오에 효율적이지 않습니다.",
            "전체 테이블을 쿼리하고 스캔하는 것은 비효율적이며 불필요한 데이터 처리로 인해 높은 지연 시간으로 이어질 수 있습니다, 특히 대량의 데이터 세트와 함께 사용할 경우 더욱 그렇습니다.",
            "Scan API를 사용하면 테이블의 모든 항목을 검색하게 되어 특정 프로필을 필터링하는 데 불필요하게 비용이 많이 들고 비효율적이며, 필터링된 결과를 추가로 처리해야 합니다."
        ]
    },
    {
        "Question Number": "44",
        "Situation": "한 금융 서비스 회사는 모든 AWS 리소스에 대해 엄격한 보안 감사 요구 사항을 준수해야 합니다. 이 회사는 사용자 활동, 구성 및 AWS 리소스에 대한 변경 사항을 추적해야 하며 성능에 미치는 영향을 최소화해야 합니다. DevOps 팀은 감사 로그를 효과적으로 수집하고 분석하는 솔루션을 구현하는 임무를 맡고 있습니다.",
        "Question": "운영 오버헤드를 최소화하면서 포괄적인 보안 감사를 제공하는 솔루션은 무엇입니까?",
        "Options": {
            "1": "모든 리전에서 AWS CloudTrail을 활성화하고, 데이터 이벤트를 기록하도록 구성하며, S3 버킷에 로그를 저장하고 AWS Lambda를 사용하여 주기적으로 로그를 분석합니다.",
            "2": "AWS CloudTrail을 활성화하고 관리 이벤트만 기록하도록 구성하며, 로그 데이터를 시각화하기 위해 Amazon QuickSight 대시보드를 설정합니다.",
            "3": "AWS Config 규칙을 설정하여 리소스 구성을 모니터링하고, 관리 이벤트에 대해 AWS CloudTrail을 활성화하며, 특정 로그 패턴에 대한 경고를 트리거하기 위해 Amazon CloudWatch를 사용합니다.",
            "4": "AWS CloudTrail을 활용하여 API 호출을 캡처하고 Amazon EventBridge와 통합하여 이벤트를 중앙 집중식 로깅 솔루션으로 라우팅하며 분석을 위한 사용자 지정 필터를 설정합니다."
        },
        "Correct Answer": "AWS CloudTrail을 활용하여 API 호출을 캡처하고 Amazon EventBridge와 통합하여 이벤트를 중앙 집중식 로깅 솔루션으로 라우팅하며 분석을 위한 사용자 지정 필터를 설정합니다.",
        "Explanation": "이 옵션은 AWS 서비스에 대한 모든 API 호출을 캡처하고 이를 분석을 위해 다양한 목적지로 쉽게 라우팅할 수 있어 사용자 활동 및 준수에 대한 포괄적인 뷰를 제공하며, 상당한 운영 오버헤드 없이 가능합니다.",
        "Other Options": [
            "이 옵션은 추가 처리 및 Lambda를 통한 주기적인 분석이 필요하여 운영 오버헤드를 도입하고 사용자 활동에 대한 실시간 통찰력을 제공하지 않을 수 있습니다.",
            "이 설정은 구성을 모니터링하고 리소스 상태를 확인하는 데 도움이 되지만, 보안 감사에 중요한 API 수준의 활동을 포괄적으로 캡처하지 않습니다.",
            "관리 이벤트만 기록하는 것은 감사의 깊이를 제한하며, QuickSight를 사용한 시각화는 원시 로그에 대한 통찰력을 제공하지 않으므로 준수 목적에 덜 효과적입니다."
        ]
    },
    {
        "Question Number": "45",
        "Situation": "DevOps 엔지니어가 인스턴스 시작 및 종료 프로세스 중에 사용자 정의 작업이 필요한 웹 애플리케이션을 위한 Auto Scaling 그룹(ASG)을 구성하고 있습니다. 엔지니어는 이러한 작업을 허용하기 위해 라이프사이클 훅을 구현하고자 합니다.",
        "Question": "라이프사이클 훅이 올바르게 작동하도록 보장하기 위한 주요 구성 요소는 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "Auto Scaling 그룹에서 종료 보호를 활성화합니다.",
            "2": "라이프사이클 훅의 기본 타임아웃을 30분으로 설정합니다.",
            "3": "준비가 되면 AWS CLI 명령을 사용하여 라이프사이클 작업을 완료합니다.",
            "4": "과도한 인스턴스 시작을 방지하기 위해 쿨다운 기간을 지정합니다.",
            "5": "라이프사이클 프로세스 중에 메시지를 수신하기 위해 알림 대상을 구성합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "준비가 되면 AWS CLI 명령을 사용하여 라이프사이클 작업을 완료합니다.",
            "라이프사이클 프로세스 중에 메시지를 수신하기 위해 알림 대상을 구성합니다."
        ],
        "Explanation": "라이프사이클 훅이 올바르게 작동하도록 보장하기 위해서는 사용자 정의 작업이 완료되면 AWS CLI 명령을 사용하여 라이프사이클 작업을 완료하는 것이 필수적입니다. 또한 알림 대상을 구성하면 Auto Scaling 그룹이 라이프사이클 상태 변경에 대한 메시지를 전송할 수 있어 이러한 이벤트에 따라 적절한 작업을 수행할 수 있습니다.",
        "Other Options": [
            "라이프사이클 훅의 기본 타임아웃을 30분으로 설정하는 것만으로는 충분하지 않습니다. 타임아웃은 사용자 정의할 수 있지만, 라이프사이클 작업을 완료하지 않으면 ASG는 기본 타임아웃 후에 진행됩니다.",
            "Auto Scaling 그룹에서 종료 보호를 활성화하면 인스턴스가 수동으로 종료되는 것을 방지하지만, 라이프사이클 훅 기능이나 스케일링 이벤트 중 수행되는 사용자 정의 작업에는 영향을 미치지 않습니다.",
            "쿨다운 기간을 지정하면 인스턴스 시작 및 종료 속도를 관리하는 데 도움이 되지만, 라이프사이클 훅의 작동이나 수행되는 사용자 정의 작업과는 직접적인 관련이 없습니다."
        ]
    },
    {
        "Question Number": "46",
        "Situation": "AWS CodeBuild 프로젝트를 설정하여 애플리케이션의 빌드 프로세스를 자동화하고 있습니다. 빌드 아티팩트는 안전하게 저장되어야 하며, 빌드에는 VPC 내의 리소스에 대한 접근이 필요합니다. 또한, 출력 아티팩트가 AWS KMS를 사용하여 암호화되도록 해야 합니다.",
        "Question": "이 요구 사항을 충족하기 위해 어떤 구성을 구현해야 합니까?",
        "Options": {
            "1": "VPC 접근 없이 공용 서브넷에서 실행되도록 CodeBuild 프로젝트를 구성합니다. 특정 IAM 권한이 필요하지 않은 기본 KMS 키를 사용하여 아티팩트를 암호화합니다.",
            "2": "AWS 리소스에 접근할 수 있는 권한을 가진 CodeBuild용 IAM 역할을 생성하고 이를 CodeBuild 프로젝트에 연결합니다. CodeBuild 프로젝트 설정에서 VPC 접근을 활성화하고 아티팩트 암호화를 위한 KMS 키를 지정합니다.",
            "3": "특정 S3 버킷에만 접근할 수 있는 제한된 권한을 가진 서비스 역할로 CodeBuild 프로젝트를 배포합니다. VPC 접근을 비활성화하고 아티팩트 암호화를 위해 사용자 지정 KMS 키를 사용합니다.",
            "4": "IAM 역할이 연결되지 않은 VPC에서 CodeBuild 프로젝트를 실행하도록 설정하여 CodeBuild가 제한 없이 모든 리소스에 접근할 수 있도록 합니다. 기본 KMS 키를 사용하여 아티팩트 암호화를 활성화합니다."
        },
        "Correct Answer": "AWS 리소스에 접근할 수 있는 권한을 가진 CodeBuild용 IAM 역할을 생성하고 이를 CodeBuild 프로젝트에 연결합니다. CodeBuild 프로젝트 설정에서 VPC 접근을 활성화하고 아티팩트 암호화를 위한 KMS 키를 지정합니다.",
        "Explanation": "이 옵션은 모든 요구 사항을 올바르게 충족합니다. AWS 리소스에 접근할 수 있는 IAM 역할을 제공하고, VPC 내의 리소스와 상호작용할 수 있도록 VPC 접근을 활성화하며, 빌드 출력 아티팩트를 암호화하기 위한 KMS 키를 지정하여 보안 및 규정 준수를 보장합니다.",
        "Other Options": [
            "이 옵션은 CodeBuild를 VPC 접근 없이 공용 서브넷에서 실행하는 것이 VPC 내의 리소스에 접근하는 요구 사항을 충족하지 않으며, 기본 KMS 키를 사용하는 것이 필요한 보안 수준을 제공하지 않을 수 있기 때문에 잘못되었습니다.",
            "이 옵션은 CodeBuild가 리소스에 안전하게 접근하기 위해 연결된 IAM 역할이 필요하기 때문에 잘못되었습니다. IAM 역할 없이 실행하면 무단 접근이 발생할 수 있으며 적절한 권한 관리를 허용하지 않습니다. 또한, 기본 KMS 키로 아티팩트 암호화를 활성화하는 것은 사용자 지정 보안 요구 사항을 충족하지 않습니다.",
            "이 옵션은 서비스 역할의 권한을 제한하므로 CodeBuild가 필요한 AWS 리소스에 접근하지 못할 수 있습니다. 또한, VPC 접근을 비활성화하는 것은 VPC 내의 리소스에 접근해야 하는 요구 사항과 모순됩니다."
        ]
    },
    {
        "Question Number": "47",
        "Situation": "한 의료 회사가 민감한 환자 데이터를 처리하는 여러 웹 애플리케이션을 Amazon EC2 인스턴스에 배포했습니다. 산업 규정을 준수하기 위해 회사는 강력한 네트워크 보안 조치를 구현해야 합니다. 그들은 특히 일반적인 웹 공격으로부터 애플리케이션을 보호하는 것과 EC2 인스턴스 간의 내부 트래픽이 안전하도록 하는 것에 대해 우려하고 있습니다. DevOps 팀은 이러한 보안 목표를 달성하기 위해 다양한 AWS 서비스를 평가하고 있습니다.",
        "Question": "이 애플리케이션에 대해 가장 효과적인 네트워크 보안을 제공하는 AWS 서비스의 조합은 무엇입니까?",
        "Options": {
            "1": "AWS Shield를 설정하여 DDoS 보호를 제공하고, VPC 서브넷으로의 트래픽을 제어하기 위해 네트워크 ACL을 구성합니다.",
            "2": "AWS Network Firewall을 구현하여 VPC의 경계에서 트래픽을 모니터링하고 제어하며, AWS WAF를 사용하여 SQL 인젝션 공격으로부터 보호합니다.",
            "3": "AWS WAF를 구성하여 웹 애플리케이션을 일반적인 공격으로부터 보호하고, 보안 그룹을 사용하여 EC2 인스턴스 간의 인바운드 및 아웃바운드 트래픽을 제어합니다.",
            "4": "향상된 DDoS 보호를 위해 AWS Shield Advanced를 배포하고, EC2 인스턴스 간의 트래픽을 모니터링하기 위해 VPC Flow Logs를 활성화합니다."
        },
        "Correct Answer": "AWS Network Firewall을 구현하여 VPC의 경계에서 트래픽을 모니터링하고 제어하며, AWS WAF를 사용하여 SQL 인젝션 공격으로부터 보호합니다.",
        "Explanation": "이 옵션은 네트워크 수준에서 트래픽을 제어하고 모니터링하는 AWS Network Firewall의 기능과 SQL 인젝션과 같은 애플리케이션 계층 위협으로부터 보호하는 AWS WAF의 기능을 효과적으로 결합합니다. 이 두 가지는 네트워크 및 애플리케이션 계층 모두에 대한 포괄적인 보안 접근 방식을 제공합니다.",
        "Other Options": [
            "AWS WAF와 보안 그룹을 사용하는 것은 좋은 접근 방식이지만, AWS Network Firewall만큼 경계에서의 트래픽 모니터링 및 제어 수준을 제공하지 않으므로 이 시나리오에서는 덜 효과적입니다.",
            "AWS Shield는 DDoS 보호를 제공하지만, 네트워크 ACL은 서브넷 수준에서만 트래픽을 필터링하며 AWS Network Firewall의 고급 기능이 부족하여 이 접근 방식의 전반적인 효과를 감소시킵니다.",
            "AWS Shield Advanced는 향상된 DDoS 보호를 제공하지만, 애플리케이션 계층 공격을 직접적으로 다루지 않으며, VPC Flow Logs는 주로 모니터링 용도로 사용되므로 능동적인 트래픽 제어 또는 위협 예방에는 적합하지 않습니다."
        ]
    },
    {
        "Question Number": "48",
        "Situation": "DevOps 엔지니어가 AWS에 호스팅된 마이크로서비스 기반 애플리케이션에 대한 지속적 통합 및 지속적 배포(CI/CD) 파이프라인을 구현하는 임무를 맡았습니다. 이 애플리케이션은 프로덕션에 배포하기 전에 성능을 벤치마킹하기 위해 부하 및 스트레스 테스트를 실행해야 합니다. 엔지니어는 테스트 프로세스가 자동화되고 다양한 부하를 처리할 수 있도록 확장 가능해야 합니다.",
        "Question": "CI/CD 파이프라인에서 애플리케이션의 부하 및 스트레스 테스트를 자동화하는 데 가장 효과적인 솔루션은 무엇입니까?",
        "Options": {
            "1": "부하 테스트 도구가 설치된 EC2 인스턴스를 설정하고, 배포 전에 필요에 따라 수동으로 테스트를 트리거합니다.",
            "2": "AWS Lambda 함수를 구현하여 서드파티 도구를 사용해 부하 테스트를 트리거하고, 결과를 분석하기 위해 Amazon DynamoDB에 저장합니다.",
            "3": "AWS Fargate를 활용하여 컨테이너화된 부하 테스트 도구를 실행하고, 동시 사용자 수에 따라 서비스를 확장하여 실제 트래픽을 시뮬레이션합니다.",
            "4": "AWS CodeBuild를 사용하여 Apache JMeter로 부하 테스트를 실행하고, 테스트 중 성능 메트릭을 모니터링하기 위해 Amazon CloudWatch 알람을 구성합니다."
        },
        "Correct Answer": "AWS Fargate를 활용하여 컨테이너화된 부하 테스트 도구를 실행하고, 동시 사용자 수에 따라 서비스를 확장하여 실제 트래픽을 시뮬레이션합니다.",
        "Explanation": "AWS Fargate를 사용하면 엔지니어가 서버를 관리하지 않고도 컨테이너화된 애플리케이션을 실행할 수 있습니다. 이는 테스트 요구 사항에 따라 부하 테스트 도구를 동적으로 확장할 수 있는 기능을 제공하여 실제 트래픽을 효과적으로 시뮬레이션하는 데 필수적입니다. 이 솔루션은 CI/CD 파이프라인에 쉽게 통합되어 자동화를 지원합니다.",
        "Other Options": [
            "AWS CodeBuild를 사용하여 부하 테스트를 실행하는 것은 실행 가능한 옵션이지만, Fargate만큼의 확장성과 실시간 부하 시뮬레이션 수준을 제공하지 않으므로 대규모 테스트에는 덜 효과적입니다.",
            "부하 테스트를 위해 AWS Lambda를 구현하면 실행 시간 제약과 동시 요청 관리로 인해 제한이 발생할 수 있습니다. 또한, 서드파티 도구를 사용하는 것은 테스트 설정 및 통합을 복잡하게 만들 수 있습니다.",
            "부하 테스트를 위해 EC2 인스턴스를 설정하는 것은 수동 접근 방식으로, Fargate와 같은 AWS 서비스가 제공하는 자동화 및 확장성의 이점을 활용하지 않으므로 CI/CD 파이프라인에 덜 적합합니다."
        ]
    },
    {
        "Question Number": "49",
        "Situation": "온라인 미디어 스트리밍 서비스가 예상치 못한 장애 발생 시 다운타임과 데이터 손실을 최소화하기 위해 재해 복구 전략을 강화할 계획입니다. 이 서비스는 복구 시간 목표(RTO)를 4시간으로, 복구 지점 목표(RPO)를 30분으로 정의했습니다. DevOps 팀은 이러한 목표를 충족하면서 비용 효율성을 보장하는 솔루션을 구현해야 합니다.",
        "Question": "다음 중 RTO 및 RPO 요구 사항을 충족하면서 비용 효율성을 고려한 최상의 재해 복구 전략은 무엇입니까?",
        "Options": {
            "1": "Amazon S3를 데이터 저장소로 활용하고 라이프사이클 정책을 설정하여 데이터를 다른 지역으로 복제하여 RTO 및 RPO를 요구 사항 내에서 제공합니다.",
            "2": "데이터베이스에 대해 동기식 복제를 사용하는 다중 AZ 배포를 구성하여 장애 발생 시 빠른 복구와 최소한의 데이터 손실을 보장합니다.",
            "3": "AWS Backup을 사용하여 데이터베이스의 시간별 스냅샷을 생성하고 RTO 내에서 시작할 수 있는 다른 지역에 대기 인스턴스를 설정합니다.",
            "4": "여러 지역에 걸쳐 활성-활성 구성을 구현하여 실시간 데이터 복제를 보장하여 거의 제로에 가까운 RTO 및 RPO를 달성합니다."
        },
        "Correct Answer": "AWS Backup을 사용하여 데이터베이스의 시간별 스냅샷을 생성하고 RTO 내에서 시작할 수 있는 다른 지역에 대기 인스턴스를 설정합니다.",
        "Explanation": "이 옵션은 신뢰할 수 있는 백업 전략을 제공하여 정의된 RTO 및 RPO와 잘 일치합니다. 시간별 스냅샷은 데이터 손실이 30분 RPO를 초과하지 않도록 보장하며, 대기 인스턴스는 4시간 RTO를 충족하기 위해 신속하게 시작될 수 있어 비용 효율적이고 규정 준수 솔루션이 됩니다.",
        "Other Options": [
            "활성-활성 구성은 우수한 가용성과 빠른 복구를 제공하지만 일반적으로 비용이 많이 들고 스트리밍 서비스의 예산 제약을 초과할 수 있어 덜 적합합니다.",
            "Amazon S3를 데이터 복제를 위한 라이프사이클 정책과 함께 사용하는 것은 비용 절감에 유리하지만, S3에서 대기 인스턴스를 시작하는 데 시간이 더 걸릴 수 있어 4시간의 엄격한 RTO를 충족하지 못할 수 있습니다.",
            "다중 AZ 배포는 높은 가용성과 낮은 복구 시간을 제공하지만, 마지막 동기화 이전에 장애가 발생할 경우 데이터 손실이 발생할 수 있는 동기식 복제에 의존하므로 RPO 요구 사항을 충족하지 못할 수 있습니다."
        ]
    },
    {
        "Question Number": "50",
        "Situation": "한 회사가 Amazon Elastic Kubernetes Service (EKS)에서 마이크로서비스 애플리케이션을 배포하고 있으며, 애플리케이션이 장애에 대해 높은 가용성과 복원력을 유지하도록 보장하고자 합니다. 회사는 수동 개입 없이 불건전한 포드를 자동으로 교체할 수 있는 솔루션이 필요합니다.",
        "Question": "DevOps 엔지니어가 애플리케이션의 복원력을 보장하고 불건전한 포드가 자동으로 교체되도록 하기 위해 어떤 접근 방식을 취해야 합니까?",
        "Options": {
            "1": "지정된 복제 수를 가진 Kubernetes 배포를 구현하여 Kubernetes가 기존 포드가 실패할 때 자동으로 새로운 포드를 생성할 수 있도록 합니다.",
            "2": "일정에 따라 포드를 생성하고 성공적으로 완료된 후 종료되는 Kubernetes 작업을 설정합니다.",
            "3": "리소스 메트릭에 따라 포드 스케일링을 관리하고 원하는 복제 수를 유지하도록 Horizontal Pod Autoscaler를 구성합니다.",
            "4": "Kubernetes StatefulSet을 사용하여 포드를 관리하고 각 포드에 대한 지속적인 저장소와 고유한 네트워크 식별자를 허용합니다."
        },
        "Correct Answer": "지정된 복제 수를 가진 Kubernetes 배포를 구현하여 Kubernetes가 기존 포드가 실패할 때 자동으로 새로운 포드를 생성할 수 있도록 합니다.",
        "Explanation": "Kubernetes 배포를 사용하면 애플리케이션의 원하는 상태가 유지됩니다. 포드가 불건전해지거나 실패할 경우 Kubernetes는 지정된 복제 수를 충족하기 위해 자동으로 교체하여 애플리케이션의 높은 가용성과 복원력을 보장합니다.",
        "Other Options": [
            "Horizontal Pod Autoscaler를 구성하는 것은 부하에 따라 포드를 스케일링하는 데 유용하지만 불건전한 포드를 교체하는 직접적인 처리는 하지 않습니다.",
            "Kubernetes 작업을 설정하는 것은 배치 처리에 적합하지만 배포가 제공하는 지속적인 유지 관리 및 자동 포드 교체를 제공하지 않습니다.",
            "Kubernetes StatefulSet을 사용하는 것은 안정적인 네트워크 식별자와 지속적인 저장소가 필요한 애플리케이션에 적합하지만, 불건전한 포드를 자동으로 교체하는 관리 기능은 배포와 같이 내재되어 있지 않습니다."
        ]
    },
    {
        "Question Number": "51",
        "Situation": "DevOps 엔지니어가 AWS CodeDeploy를 사용하여 애플리케이션 배포를 자동화하는 임무를 맡고 있습니다. 애플리케이션은 여러 환경에 배포되며, 다운타임과 위험을 최소화하는 방식으로 배포를 보장해야 합니다. 엔지니어는 AWS CodeDeploy에서 사용할 수 있는 다양한 배포 전략을 고려하고 있습니다.",
        "Question": "DevOps 엔지니어가 다운타임을 최소화하고 필요할 경우 신속한 롤백이 가능하도록 애플리케이션을 배포하기 위해 어떤 배포 전략을 선택해야 합니까?",
        "Options": {
            "1": "Canary 배포 전략을 구현하여 새로운 버전으로의 트래픽의 소규모 비율을 점진적으로 전환하고 문제를 모니터링합니다.",
            "2": "In-Place 배포 전략을 사용하여 기존 인스턴스를 직접 업데이트하고 리소스 사용을 줄입니다.",
            "3": "Blue/Green 배포 전략을 사용하여 새로운 버전을 기존 버전과 함께 배포하고 새로운 버전이 안정성이 확인되면 트래픽을 전환합니다.",
            "4": "Rolling 배포 전략을 사용하여 인스턴스를 배치로 업데이트하여 일부 인스턴스는 이전 버전을 실행하고 다른 인스턴스는 새로운 버전을 실행하도록 합니다."
        },
        "Correct Answer": "Blue/Green 배포 전략을 사용하여 새로운 버전을 기존 버전과 함께 배포하고 새로운 버전이 안정성이 확인되면 트래픽을 전환합니다.",
        "Explanation": "Blue/Green 배포 전략은 새로운 버전을 기존 버전과 함께 배포하고 테스트할 수 있도록 하여 다운타임을 최소화하는 데 최적입니다. 새로운 버전이 안정성이 확인되면 트래픽을 전환하여 문제가 발생할 경우 신속하게 이전 버전으로 롤백할 수 있도록 보장합니다.",
        "Other Options": [
            "In-Place 배포 전략은 기존 인스턴스를 직접 업데이트하므로 배포 실패 시 다운타임이 발생할 수 있으며 신속한 롤백을 허용하지 않습니다.",
            "Rolling 배포 전략은 인스턴스를 배치로 업데이트하므로 업데이트 과정에서 일부 다운타임이나 성능 저하가 발생할 수 있어 제로 다운타임이 중요한 시나리오에는 덜 이상적입니다.",
            "Canary 배포 전략은 새로운 버전으로의 트래픽의 소규모 비율을 전환하는 것을 포함하여 테스트에 효과적일 수 있지만 점진적인 트래픽 전환에 의존하므로 최소한의 다운타임을 보장하지 않으며 일부 사용자는 여전히 이전 버전을 사용할 수 있습니다."
        ]
    },
    {
        "Question Number": "52",
        "Situation": "개발 팀이 Docker 컨테이너를 사용하여 마이크로서비스 기반 애플리케이션을 만들고 있습니다. 각 서비스가 격리되어 독립적으로 배포될 수 있으며 수요에 따라 쉽게 확장될 수 있도록 해야 합니다. 팀은 또한 Docker 이미지를 빌드하고 배포하는 프로세스를 간소화하고자 합니다.",
        "Question": "DevOps 엔지니어가 마이크로서비스 애플리케이션의 효율적인 컨테이너 관리 및 배포를 달성하기 위해 어떤 접근 방식을 추천해야 합니까?",
        "Options": {
            "1": "Docker Swarm을 활용하여 컨테이너 배포를 조정하고 자동으로 확장 및 로드 밸런싱을 관리합니다.",
            "2": "Docker Compose를 사용하여 다중 컨테이너 Docker 애플리케이션을 정의하고 실행하여 서비스 관리를 용이하게 합니다.",
            "3": "Docker Registry를 활용하여 모든 이미지를 저장하고 각 호스트에 컨테이너를 수동으로 배포하여 일관성을 보장합니다.",
            "4": "Kubernetes를 구현하여 마이크로서비스 아키텍처의 컨테이너 조정, 확장 및 자가 복구를 관리합니다."
        },
        "Correct Answer": "Kubernetes를 구현하여 마이크로서비스 아키텍처의 컨테이너 조정, 확장 및 자가 복구를 관리합니다.",
        "Explanation": "Kubernetes는 컨테이너화된 애플리케이션의 배포, 확장 및 관리를 자동화하는 강력한 컨테이너 조정 플랫폼입니다. 자가 복구, 로드 밸런싱, 자동 롤아웃 및 롤백과 같은 기능을 제공하여 마이크로서비스 아키텍처를 효과적으로 관리하는 데 가장 적합한 선택입니다.",
        "Other Options": [
            "Docker Compose는 로컬 개발 및 다중 컨테이너 애플리케이션 정의에 적합하지만, 프로덕션 환경에 필요한 고급 조정 기능이 부족합니다.",
            "Docker Swarm은 기본적인 조정 기능을 제공하지만 Kubernetes만큼 기능이 풍부하거나 널리 채택되지 않아 복잡한 마이크로서비스 아키텍처에 대한 효과가 제한됩니다.",
            "Docker Registry를 사용하여 수동 배포를 수행하는 것은 조정 기능을 제공하지 않으며, 이는 마이크로서비스 환경에서 확장 및 업데이트 관리를 위해 필수적입니다."
        ]
    },
    {
        "Question Number": "53",
        "Situation": "한 회사가 AWS에서 Amazon ECS를 사용하여 마이크로서비스를 호스팅하고 있으며, 트래픽 관리를 위해 Application Load Balancers (ALBs)를 사용하고 있습니다. 그들은 서비스가 지속적으로 사용 가능하고 비정상 인스턴스를 자동으로 감지할 수 있도록 해야 합니다. 팀은 ALBs에 대한 헬스 체크를 설정하여 서비스의 상태를 효과적으로 모니터링할 계획입니다. 요구 사항은 요청이 건강한 인스턴스에만 전달되어야 하며, 팀은 배포 중 다운타임을 최소화하고 효율적인 헬스 체크를 구성하고자 합니다.",
        "Question": "DevOps 엔지니어가 회사의 요구 사항을 충족하기 위해 ALBs에 대한 헬스 체크를 구성하기 위해 어떤 접근 방식을 취해야 합니까?",
        "Options": {
            "1": "ALB의 기본 헬스 체크 설정을 사용하여 대상 인스턴스에 대한 TCP 연결을 확인하고 연결이 성공하는 한 인스턴스가 건강하다고 가정합니다.",
            "2": "애플리케이션이 완전히 초기화되었을 때만 200 OK 응답을 반환하는 경로로 헬스 체크를 설정하고, 3개의 연속 성공적인 체크에 대한 건강 기준을 구성합니다.",
            "3": "데이터베이스 쿼리를 트리거하는 경로를 사용하여 헬스 체크를 구현하고, 데이터베이스에 접근할 수 있는 경우 200 OK 응답을 반환하며, 비정상 기준을 2개의 실패한 체크로 설정합니다.",
            "4": "애플리케이션 응답과 데이터베이스 연결을 모두 확인하는 경로로 ALB에서 헬스 체크를 구성하고, 건강 기준을 5개의 성공적인 체크로 설정합니다."
        },
        "Correct Answer": "애플리케이션 응답과 데이터베이스 연결을 모두 확인하는 경로로 ALB에서 헬스 체크를 구성하고, 건강 기준을 5개의 성공적인 체크로 설정합니다.",
        "Explanation": "이 옵션은 헬스 체크가 포괄적이며 애플리케이션의 가용성뿐만 아니라 데이터베이스에 연결할 수 있는 능력을 검증합니다. 5개의 성공적인 체크에 대한 건강 기준을 설정하면 인스턴스를 건강하다고 표시하기 전에 추가적인 보증을 추가하여 배포 중에 매우 중요합니다.",
        "Other Options": [
            "이 옵션은 200 OK 응답만 확인하는 단일 경로에 의존하는 것이 애플리케이션의 전반적인 건강 상태를 충분히 나타내지 못할 수 있기 때문에 잘못되었습니다. 특히 데이터베이스나 서비스와 같은 다른 종속성이 확인되지 않는 경우 더욱 그렇습니다.",
            "이 옵션은 기본 TCP 헬스 체크를 사용하면 실제 애플리케이션 상태를 평가하지 않기 때문에 잘못되었습니다. 이로 인해 비정상 인스턴스가 건강하다고 표시되어 잠재적인 다운타임이나 성능 저하가 발생할 수 있습니다.",
            "이 옵션은 데이터베이스 쿼리만 트리거하는 헬스 체크에 의존하면 인스턴스가 데이터베이스 가용성에 따라 건강하다고 표시될 수 있으며, 애플리케이션의 반응성이나 기능을 검증하지 않기 때문에 잘못되었습니다."
        ]
    },
    {
        "Question Number": "54",
        "Situation": "한 회사가 AWS에서 마이크로서비스 아키텍처로 전환하고 있으며, 애플리케이션이 AWS 리소스에 대해 안전하고 통제된 접근을 보장해야 합니다. 보안 팀은 인간 사용자와 애플리케이션 구성 요소 모두에 대해 IAM 엔터티를 적절히 사용하는 것의 중요성을 강조했습니다. 그들은 보안 정책을 준수하면서 특정 서비스에 대한 제한된 접근을 부여하는 방법을 설정하고자 합니다.",
        "Question": "마이크로서비스 아키텍처에서 개발자와 애플리케이션 구성 요소 모두에 대해 안전하고 최소한의 접근을 제공하기 위해 어떤 IAM 전략이 가장 적합합니까?",
        "Options": {
            "1": "IAM 역할 없이 애플리케이션 구성 요소에 직접 접근을 부여하기 위해 리소스 기반 정책을 사용합니다.",
            "2": "모든 접근 관리를 위해 IAM 정책을 AWS 계정 루트 사용자에게 직접 할당합니다.",
            "3": "개발자를 위한 IAM 사용자를 생성하고 세분화된 권한을 가진 그룹에 할당합니다.",
            "4": "애플리케이션 구성 요소에 IAM 역할을 활용하고 개발자를 위한 신원 공급자를 사용하여 접근을 관리합니다."
        },
        "Correct Answer": "애플리케이션 구성 요소에 IAM 역할을 활용하고 개발자를 위한 신원 공급자를 사용하여 접근을 관리합니다.",
        "Explanation": "애플리케이션 구성 요소에 IAM 역할을 활용하면 서비스가 필요에 따라 특정 권한을 가진 역할을 맡을 수 있어 최소 권한 원칙을 유지합니다. 개발자에게 신원 공급자를 사용하는 것은 수많은 IAM 사용자를 생성하지 않고도 안전한 인증 및 접근 관리를 가능하게 합니다.",
        "Other Options": [
            "IAM 사용자를 생성하고 그룹에 할당하는 것은 유효한 접근 방식이지만 관리 오버헤드가 발생할 수 있으며 애플리케이션에 대한 역할 기반 접근의 이점을 활용하지 못할 수 있습니다.",
            "리소스 기반 정책은 접근 제어를 제공할 수 있지만 IAM 역할 없이 애플리케이션 구성 요소에만 의존하는 것은 보안을 저해할 수 있으며 모범 사례를 촉진하지 않습니다.",
            "AWS 계정 루트 사용자에게 정책을 할당하는 것은 전체 계정을 잠재적인 취약성에 노출시키는 상당한 보안 위험을 초래하므로 매우 권장되지 않습니다."
        ]
    },
    {
        "Question Number": "55",
        "Situation": "한 회사가 Amazon ECS와 Application Load Balancer를 사용하여 AWS에 마이크로서비스 아키텍처를 배포했습니다. 그들은 CPU 및 메모리 사용량과 같은 메트릭을 기반으로 서비스에 대한 자동 스케일링을 구성했습니다. 최근, 그들은 서비스가 피크 부하 동안 성능 문제를 겪고 있어 지연 시간이 증가하고 사용자 불만이 발생하는 것을 관찰했습니다. DevOps 엔지니어는 성능 저하 없이 증가된 트래픽을 처리할 수 있도록 서비스를 스케일링하기 위해 구현해야 할 가장 효과적인 메트릭을 결정해야 합니다.",
        "Question": "DevOps 엔지니어가 높은 트래픽 기간 동안 ECS 서비스를 스케일링하여 복원력을 향상시키기 위해 우선적으로 고려해야 할 메트릭은 무엇입니까?",
        "Options": {
            "1": "서비스에서 처리된 요청의 평균 지연 시간, 이는 사용자 경험의 직접적인 지표이기 때문입니다.",
            "2": "Application Load Balancer에 대한 활성 연결의 총 수, 이는 서비스에 도달하는 즉각적인 트래픽을 반영합니다.",
            "3": "개별 ECS 작업의 메모리 사용량, 이는 부하 하에서 애플리케이션의 상태를 나타낼 수 있습니다.",
            "4": "서비스 인스턴스 전반의 평균 CPU 사용량, 이는 스케일링 작업이 작업 부하 요구에 기반하도록 보장합니다."
        },
        "Correct Answer": "서비스 인스턴스 전반의 평균 CPU 사용량, 이는 스케일링 작업이 작업 부하 요구에 기반하도록 보장합니다.",
        "Explanation": "서비스 인스턴스 전반의 평균 CPU 사용량은 ECS 서비스의 처리 용량과 직접적으로 연관된 중요한 메트릭입니다. CPU 사용량을 모니터링함으로써 시스템은 사용량이 정의된 임계값을 초과할 때 자동으로 확장(인스턴스 추가)할 수 있어, 높은 수요 동안 성능을 유지할 수 있습니다.",
        "Other Options": [
            "Application Load Balancer에 대한 활성 연결의 총 수는 전체 트래픽을 나타내지만, 서비스 인스턴스가 과부하 상태인지에 대한 통찰력을 제공하지 않으며, 근본적인 성능 문제를 해결하지 않는 스케일링 작업으로 이어질 수 있습니다.",
            "개별 ECS 작업의 메모리 사용량은 중요하지만, 스케일링 결정에 있어 CPU 사용량에 비해 종종 2차적인 문제입니다. 높은 메모리 사용량이 항상 추가 인스턴스의 필요성과 연관되지 않으며, 특히 CPU 리소스가 여전히 사용 가능한 경우에는 더욱 그렇습니다.",
            "서비스에서 처리된 요청의 평균 지연 시간은 성능 모니터링에 좋은 메트릭이지만, 반응적이지 능동적이지 않습니다. 지연 시간을 기반으로 스케일링하면 사용자 경험에 영향을 미치기 전에 근본적인 용량 문제를 해결하는 데 지연이 발생할 수 있습니다."
        ]
    },
    {
        "Question Number": "56",
        "Situation": "한 회사가 Amazon S3에 저장된 중요한 데이터에 대한 교차 리전 백업 및 복구 전략을 구현하려고 합니다. 그들은 데이터가 다른 리전으로 백업되어 리전 전체의 중단에 대한 복원력을 제공하기를 원합니다. 솔루션은 비용 효율적이고 구현이 쉬우며, 실패 시 자동 백업 및 빠른 복구 옵션을 제공해야 합니다.",
        "Question": "DevOps 엔지니어로서 회사의 교차 리전 백업 및 복구 요구 사항을 충족하기 위해 어떤 솔루션을 구현해야 합니까?",
        "Options": {
            "1": "S3 버킷에 대한 교차 리전 복제를 구성하여 다른 리전으로 백업합니다. 객체 변경 사항을 추적하기 위해 소스 버킷에서 버전 관리를 활성화합니다. AWS Backup을 사용하여 버전 관리된 객체를 대상 리전으로 자동 백업합니다.",
            "2": "AWS Backup을 사용하여 S3 버킷 데이터를 다른 리전으로 백업합니다. 백업 계획을 구성하여 백업 빈도 및 보존 기간을 정의합니다. 비즈니스 요구 사항에 따라 복구 지점 목표(RPO)가 충족되도록 합니다.",
            "3": "AWS CLI를 사용하여 매일 S3 버킷 데이터를 다른 리전으로 수동으로 복사합니다. 작업이 성공적으로 완료되면 알림을 받기 위해 CloudWatch 경고를 생성하지만 자동 백업은 구현하지 않습니다.",
            "4": "예약된 AWS Lambda 함수를 설정하여 S3 버킷의 객체를 다른 리전의 다른 S3 버킷으로 복사합니다. 보안을 강화하고 데이터 복원력을 보장하기 위해 복사된 객체를 다른 계정에 저장합니다."
        },
        "Correct Answer": "S3 버킷에 대한 교차 리전 복제를 구성하여 다른 리전으로 백업합니다. 객체 변경 사항을 추적하기 위해 소스 버킷에서 버전 관리를 활성화합니다. AWS Backup을 사용하여 버전 관리된 객체를 대상 리전으로 자동 백업합니다.",
        "Explanation": "S3에 대한 교차 리전 복제는 데이터를 다른 리전으로 자동으로 효율적으로 복제하는 방법을 제공하여 높은 가용성과 중단에 대한 복원력을 보장합니다. 버전 관리를 활성화하면 회사가 객체 변경 사항을 추적할 수 있으며, AWS Backup을 사용하면 백업 프로세스가 자동화되어 수동 개입 없이 정기적으로 데이터가 백업됩니다.",
        "Other Options": [
            "예약된 AWS Lambda 함수를 설정하여 객체를 복사하는 것은 효율성이 떨어지고 잠재적인 실패 지점을 도입합니다. 지속적인 유지 관리 및 모니터링이 필요하며, 교차 리전 복제와 같은 내장된 버전 관리 또는 자동 백업 기능을 제공하지 않습니다.",
            "S3 데이터에 대해 AWS Backup을 사용하는 것은 직접적인 옵션이 아니며, 현재 AWS Backup은 S3 버킷을 직접 지원하지 않습니다. 이는 EC2, EBS, RDS 및 기타 AWS 리소스에 더 적합하여 이 시나리오에 적합하지 않습니다.",
            "S3 버킷 데이터를 수동으로 복사하는 것은 확장 가능한 솔루션이 아니며 인적 오류의 위험을 증가시킵니다. 이는 자동화나 강력한 재해 복구 전략에 필요한 효율적인 복구 옵션을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "57",
        "Situation": "개발 팀이 AWS CodeBuild를 사용하여 마이크로서비스 아키텍처의 빌드 프로세스를 자동화하고 있습니다. 각 마이크로서비스는 서로 다른 프로그래밍 언어로 개발되며 특정 빌드 도구와 종속성이 필요합니다. 팀은 빌드 환경이 일관되도록 하고 AWS Lambda에 배포하기 위해 빌드 아티팩트가 신뢰성 있게 생성되도록 해야 합니다. 이 시나리오에 대해 CodeBuild를 구성하는 가장 효과적인 방법은 무엇입니까?",
        "Question": "여러 마이크로서비스에 대해 일관되고 신뢰할 수 있는 아티팩트 생성을 보장하기 위해 팀이 AWS CodeBuild에서 구현해야 할 구성은 무엇입니까?",
        "Options": {
            "1": "각 마이크로서비스에 맞춘 Docker 이미지를 활용하는 CodeBuild 프로젝트를 설정하여 모든 서비스의 빌드 환경이 Lambda의 런타임 환경과 일치하도록 합니다.",
            "2": "각 마이크로서비스에 대해 별도의 빌드 프로젝트를 생성하고 각 프로젝트 내에서 종속성을 개별적으로 관리합니다.",
            "3": "모든 마이크로서비스에 대해 프로그래밍 언어를 동적으로 감지하고 빌드 시간에 필요한 종속성을 설치하는 단일 빌드 사양 파일을 사용하는 단일 빌드 프로젝트를 사용합니다.",
            "4": "여러 CodeBuild 프로젝트를 조정하기 위해 AWS CodePipeline을 구현하여 각 프로젝트가 서로 다른 마이크로서비스 및 그 종속성의 빌드 프로세스를 처리하도록 구성합니다."
        },
        "Correct Answer": "각 마이크로서비스에 맞춘 Docker 이미지를 활용하는 CodeBuild 프로젝트를 설정하여 모든 서비스의 빌드 환경이 Lambda의 런타임 환경과 일치하도록 합니다.",
        "Explanation": "각 마이크로서비스에 맞춘 Docker 이미지를 사용하는 것은 AWS Lambda의 런타임 환경을 반영하는 일관된 빌드 환경을 제공하여 생성된 아티팩트가 배포에 호환되고 신뢰할 수 있도록 보장합니다.",
        "Other Options": [
            "각 마이크로서비스에 대해 별도의 빌드 프로젝트를 생성하면 관리 오버헤드가 증가하고 빌드 프로세스가 복잡해져 생성된 아티팩트의 일관성이 떨어질 수 있습니다.",
            "동적 빌드 사양을 가진 단일 빌드 프로젝트를 사용하는 것은 복잡성을 초래하고 서로 다른 프로그래밍 언어 간의 다양한 종속성으로 인해 빌드 프로세스 중 실패를 초래할 수 있습니다.",
            "AWS CodePipeline은 조정에 유용하지만, 각 마이크로서비스에 대한 빌드 환경 일관성을 직접적으로 해결하지 않으며, 이는 신뢰할 수 있는 아티팩트 생성을 위해 중요합니다."
        ]
    },
    {
        "Question Number": "58",
        "Situation": "한 회사가 애플리케이션을 AWS로 마이그레이션하고 있으며, 생산 및 아카이브 작업 부하에 대한 성능 요구 사항을 충족하기 위해 적절한 Amazon EBS 볼륨 유형을 선택해야 합니다. 이 애플리케이션은 상당한 읽기 및 쓰기 작업을 포함한 다양한 작업 부하를 처리할 것으로 예상됩니다.",
        "Question": "DevOps 엔지니어가 생산 작업 부하의 성능을 최적화하기 위해 선택해야 할 EBS 볼륨 유형은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "접근 빈도가 낮은 아카이브 작업 부하를 위한 자기 HDD 볼륨.",
            "2": "무거운 부하에서 예측 가능한 성능을 위한 Provisioned IOPS SSD (io1).",
            "3": "기본 IOPS를 갖춘 버스트 성능을 위한 General Purpose SSD (gp2).",
            "4": "드물게 접근하는 경우와 비용 효율성을 위한 Cold HDD (sc1) 볼륨.",
            "5": "일관된 높은 IOPS 성능을 위한 Provisioned IOPS SSD (io2)."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "일관된 높은 IOPS 성능을 위한 Provisioned IOPS SSD (io2).",
            "기본 IOPS를 갖춘 버스트 성능을 위한 General Purpose SSD (gp2)."
        ],
        "Explanation": "Provisioned IOPS SSD (io2)는 지속적인 IOPS가 필요한 고성능 애플리케이션을 위해 설계되었으며, General Purpose SSD (gp2)는 변동하는 I/O 패턴을 가진 작업 부하에 대해 가격과 성능의 좋은 균형을 제공합니다. 두 가지 모두 생산 작업 부하에 적합합니다.",
        "Other Options": [
            "자기 HDD 볼륨은 높은 대기 시간과 낮은 성능 특성으로 인해 생산 작업 부하에 적합하지 않으며, 아카이브 용도로만 이상적입니다.",
            "Provisioned IOPS SSD (io1)는 io2에 비해 구식이며 동일한 수준의 성능과 비용 효율성을 제공하지 않으므로 새로운 구현에 덜 바람직합니다.",
            "Cold HDD (sc1) 볼륨은 드물게 접근하는 경우를 위해 특별히 설계되었으며, 생산 작업 부하의 성능 요구 사항을 충족하지 못합니다."
        ]
    },
    {
        "Question Number": "59",
        "Situation": "한 금융 서비스 회사가 AWS에서 Amazon RDS 인스턴스에 의존하는 중요한 애플리케이션을 운영하고 있습니다. 최근 RDS 인스턴스의 실패로 인해 심각한 중단이 발생하여 애플리케이션이 다운되었습니다. DevOps 엔지니어는 단일 실패 지점을 제거하고 데이터베이스 계층의 고가용성을 보장하기 위해 아키텍처를 재설계하는 임무를 맡았습니다.",
        "Question": "Amazon RDS 데이터베이스 계층이 복원력이 있고 단일 실패 지점을 피하도록 보장하기 위한 최선의 전략은 무엇입니까?",
        "Options": {
            "1": "Amazon RDS 인스턴스를 단일 가용 영역에 배포하고 AWS Lambda 함수를 사용하여 수동 장애 조치 프로세스를 생성하여 필요할 때 데이터베이스를 새 인스턴스로 신속하게 전환할 수 있도록 합니다.",
            "2": "Amazon RDS Multi-AZ 배포를 구현하여 기본 인스턴스에 장애가 발생할 경우 자동으로 대기 인스턴스로 장애 조치합니다. 읽기 중심 작업 부하를 위해 읽기 복제본을 구성하여 수평 확장을 허용합니다.",
            "3": "다양한 지역에 여러 Amazon RDS 인스턴스를 설정하고 AWS Global Database를 사용하여 지역 간 복제 및 장애 조치 기능을 제공하여 지역 중단에 대한 복원력을 보장합니다.",
            "4": "단일 인스턴스를 사용하는 Amazon RDS를 사용하되, 장애 발생 시 데이터베이스를 복원하기 위한 자동 백업 전략을 설정합니다. 이를 통해 최소한의 다운타임과 데이터 손실을 보장할 수 있습니다."
        },
        "Correct Answer": "Amazon RDS Multi-AZ 배포를 구현하여 기본 인스턴스에 장애가 발생할 경우 자동으로 대기 인스턴스로 장애 조치합니다. 읽기 중심 작업 부하를 위해 읽기 복제본을 구성하여 수평 확장을 허용합니다.",
        "Explanation": "Amazon RDS Multi-AZ 배포를 구현하면 기본 인스턴스에 장애가 발생할 경우 대기 인스턴스로 자동으로 장애 조치되므로 단일 실패 지점을 제거합니다. 또한 읽기 복제본을 구성하면 가용성을 저하시키지 않으면서 읽기 중심 작업 부하의 성능을 향상시킵니다.",
        "Other Options": [
            "자동 백업 전략을 사용하는 단일 인스턴스는 단일 실패 지점을 제거하지 않으며, 인스턴스가 실패하면 백업이 복원될 때까지 여전히 다운타임이 발생합니다.",
            "수동 장애 조치 프로세스와 함께 단일 가용 영역에 RDS 인스턴스를 배포하면 장애 발생 시 다운타임의 위험이 증가하며, 개입이 필요하고 자동이 아닙니다.",
            "다양한 지역에 여러 RDS 인스턴스를 설정하면 복잡성과 잠재적인 지연 문제가 발생할 수 있으며, 지역 복원력을 제공하지만 대부분의 애플리케이션에는 필요하지 않을 수 있으며 단일 지역 내 즉각적인 고가용성 요구를 해결하지 않습니다."
        ]
    },
    {
        "Question Number": "60",
        "Situation": "한 금융 서비스 회사는 AWS 리소스에서 생성된 모든 로그와 메트릭이 저장 중 및 전송 중 모두 암호화되도록 해야 합니다. DevOps 팀은 규정 준수 요구 사항을 충족하기 위해 다양한 암호화 옵션을 고려하고 있습니다. 그들은 특히 권한이 있는 직원이 쉽게 접근할 수 있도록 하면서 AWS 서비스를 사용하여 암호화 키를 효과적으로 관리하는 데 집중하고 있습니다.",
        "Question": "로그와 메트릭을 저장 중 및 전송 중 모두 암호화하면서 운영 오버헤드를 가장 적게 제공하는 옵션은 무엇입니까?",
        "Options": {
            "1": "Amazon CloudWatch Logs를 사용하여 AWS 리소스에서 로그를 수집하고 AWS KMS를 사용하여 저장 중 암호화를 활성화합니다. 모든 로그 스트림이 전송 중 데이터 암호화를 위해 TLS를 사용하도록 구성되어 있는지 확인합니다.",
            "2": "AWS Key Management Service (AWS KMS)를 활용하여 Amazon S3에 저장된 로그를 암호화하기 위한 고객 관리 키를 생성합니다. AWS KMS (SSE-KMS)를 사용하여 서버 측 암호화를 활성화하고, 로그가 S3에 기록되기 전에 암호화하는 데 키를 사용하도록 로깅 서비스를 구성합니다.",
            "3": "모든 로그와 메트릭을 AWS 서비스로 전송하기 전에 클라이언트 측 암호화를 구현합니다. 암호화 키를 애플리케이션 코드 내에 안전하게 저장하여 로그가 AWS로 전송되기 전에 암호화되도록 합니다.",
            "4": "AWS CloudTrail을 구성하여 API 호출을 기록하고 AWS KMS의 고객 관리 키를 사용하여 암호화를 활성화합니다. AWS 서비스 간의 모든 트래픽이 HTTPS를 사용하여 암호화되도록 하여 전송 중 로그 데이터를 보호합니다."
        },
        "Correct Answer": "Amazon CloudWatch Logs를 사용하여 AWS 리소스에서 로그를 수집하고 AWS KMS를 사용하여 저장 중 암호화를 활성화합니다. 모든 로그 스트림이 전송 중 데이터 암호화를 위해 TLS를 사용하도록 구성되어 있는지 확인합니다.",
        "Explanation": "이 옵션은 Amazon CloudWatch Logs를 활용하여 자동으로 AWS KMS와 통합되어 저장 중 암호화를 지원하고 전송 중 TLS 암호화를 지원합니다. 이는 운영 오버헤드를 최소화하면서 보안 요구 사항을 준수하는 관리 솔루션을 제공합니다.",
        "Other Options": [
            "AWS KMS를 사용하여 S3에서 로그를 암호화하는 것은 저장 중 강력한 암호화를 제공하지만, CloudWatch Logs와 TLS를 사용하는 것만큼 전송 중 암호화를 효과적으로 처리하지 않습니다.",
            "클라이언트 측 암호화는 애플리케이션에 복잡성을 추가하고 암호화 키의 신중한 관리를 요구하므로 운영 오버헤드와 키 관리 오류의 가능성을 증가시킵니다.",
            "AWS CloudTrail은 KMS 암호화로 API 호출을 기록하지만, CloudWatch Logs만큼 모든 유형의 로그와 메트릭을 포괄적으로 다루지 않으므로 전체 로그 및 메트릭 암호화에 덜 효과적입니다."
        ]
    },
    {
        "Question Number": "61",
        "Situation": "한 회사가 AWS에 배포된 마이크로서비스 아키텍처를 모니터링하기 위해 Amazon CloudWatch를 사용하고 있습니다. 개발 팀은 CloudWatch 메트릭과 로그를 활용하여 성능 문제를 해결하고 리소스 사용을 최적화합니다. 그러나 다양한 서비스 간의 요청 추적 및 개별 구성 요소의 성능 분석에 어려움을 겪고 있습니다. DevOps 엔지니어로서 마이크로서비스의 가시성을 개선하기 위해 무엇을 할 수 있을까요?",
        "Question": "마이크로서비스에 대한 상세한 추적 및 성능 메트릭을 제공하기 위해 어떤 AWS 서비스를 활성화해야 합니까?",
        "Options": {
            "1": "Amazon X-Ray를 사용하여 요청을 추적하고 서비스 성능을 분석합니다.",
            "2": "CloudWatch Logs를 구성하여 상세한 애플리케이션 로그를 캡처합니다.",
            "3": "AWS CloudTrail을 활성화하여 계정의 API 호출을 모니터링합니다.",
            "4": "AWS Config를 설정하여 리소스의 구성 변경을 추적합니다."
        },
        "Correct Answer": "Amazon X-Ray를 사용하여 요청을 추적하고 서비스 성능을 분석합니다.",
        "Explanation": "Amazon X-Ray는 애플리케이션에 대한 추적 기능과 성능 통찰력을 제공하도록 특별히 설계되어 있어 요청이 마이크로서비스를 통해 어떻게 이동하는지 이해하고 병목 현상이나 오류를 식별하는 데 용이합니다.",
        "Other Options": [
            "AWS CloudTrail은 API 호출을 기록하는 데 중점을 두며 애플리케이션 요청이나 성능 메트릭에 대한 추적 기능을 제공하지 않습니다.",
            "CloudWatch Logs는 애플리케이션 로그를 캡처하지만 마이크로서비스 아키텍처에서 개별 서비스의 성능을 분석하는 데 필요한 추적 기능을 제공하지 않습니다.",
            "AWS Config는 주로 AWS 리소스의 구성 변경을 모니터링하는 데 사용되며 애플리케이션 성능이나 요청 추적에 대한 통찰력을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "62",
        "Situation": "한 회사가 중요한 애플리케이션을 실행하는 여러 EC2 인스턴스를 운영하고 있습니다. 이들은 최소한의 다운타임으로 이러한 인스턴스의 백업을 정기적으로 생성하는 전략을 구현하고자 합니다. DevOps 엔지니어는 애플리케이션에 중단을 초래하지 않고 EBS 볼륨의 백업과 인스턴스에서 AMI를 생성할 수 있는 프로세스를 만들어야 합니다. 이를 달성하기 위해 엔지니어는 어떤 AWS 서비스 또는 서비스 조합을 사용해야 합니까?",
        "Question": "최소한의 다운타임으로 실행 중인 EC2 인스턴스에서 EBS 볼륨과 AMI의 백업을 생성하는 가장 효율적인 방법은 무엇입니까?",
        "Options": {
            "1": "EC2 인스턴스를 중지하고 create-image 명령을 사용하여 AMI를 생성한 후 인스턴스를 다시 시작합니다.",
            "2": "create-snapshot 명령을 사용하여 EBS 볼륨의 스냅샷을 찍고, 그런 다음 create-image 명령을 사용하여 인스턴스에서 AMI를 생성합니다.",
            "3": "데이터가 저장되도록 인스턴스를 종료한 후 저장된 구성을 사용하여 새 인스턴스를 생성합니다.",
            "4": "describe-instances 명령을 사용하여 실행 중인 인스턴스를 나열한 후 자동화 없이 수동으로 백업을 생성합니다."
        },
        "Correct Answer": "create-snapshot 명령을 사용하여 EBS 볼륨의 스냅샷을 찍고, 그런 다음 create-image 명령을 사용하여 인스턴스에서 AMI를 생성합니다.",
        "Explanation": "create-snapshot 명령을 사용하면 인스턴스가 여전히 실행 중일 때 EBS 볼륨을 백업할 수 있어 최소한의 다운타임을 보장합니다. 이후 중지된 인스턴스에서 create-image 명령을 사용하면 다른 인스턴스의 실행 상태에 영향을 주지 않고 AMI를 생성할 수 있습니다.",
        "Other Options": [
            "인스턴스를 중지하면 다운타임이 발생하고 애플리케이션 가용성이 중단되므로 최소한의 다운타임을 보장하는 목표와는 반대입니다.",
            "수동으로 백업을 생성하면 자동화가 부족하여 인적 오류가 발생할 수 있으며 정기적인 백업에 대한 확장 가능한 솔루션이 아닙니다.",
            "인스턴스를 종료하면 적절한 AMI나 스냅샷이 사전에 생성되지 않는 한 데이터 손실이 발생하며 백업 생성 요구 사항과 일치하지 않습니다."
        ]
    },
    {
        "Question Number": "63",
        "Situation": "Amazon Elastic Kubernetes Service(Amazon EKS)에 배포된 마이크로서비스 애플리케이션을 관리하고 있으며, 다운타임을 최소화하고 서비스의 새로운 버전을 사용자에게 가능한 한 빨리 제공하는 배포 전략을 구현해야 합니다. 이 애플리케이션은 중요하며, 다운타임이 발생하면 상당한 수익 손실로 이어질 수 있습니다.",
        "Question": "이러한 요구 사항을 효과적으로 충족하기 위해 어떤 배포 전략을 선택해야 합니까?",
        "Options": {
            "1": "EKS 클러스터에서 카나리 배포 전략을 사용하여 새로운 버전을 점진적으로 배포하고 성능을 모니터링합니다.",
            "2": "Amazon EKS에서 마이크로서비스에 대한 블루/그린 배포 전략을 구현하여 버전 간의 빠른 전환을 허용합니다.",
            "3": "EKS에서 재생성 배포 전략을 구현하여 새로운 버전이 시작되기 전에 이전 버전이 완전히 종료되도록 합니다.",
            "4": "Amazon EKS 배포에서 롤링 업데이트 전략을 구성하여 서비스의 점진적인 업데이트를 수행합니다."
        },
        "Correct Answer": "Amazon EKS에서 마이크로서비스에 대한 블루/그린 배포 전략을 구현하여 버전 간의 빠른 전환을 허용합니다.",
        "Explanation": "블루/그린 배포 전략을 사용하면 두 개의 환경(블루와 그린)을 유지할 수 있습니다. 블루 환경이 트래픽을 처리하는 동안 그린 환경에 애플리케이션의 새로운 버전을 배포할 수 있습니다. 새로운 버전이 검증되면 최소한의 다운타임으로 트래픽을 그린 환경으로 전환할 수 있으며 필요 시 쉽게 롤백할 수 있습니다.",
        "Other Options": [
            "카나리 배포 전략을 사용하는 것은 새로운 버전을 점진적으로 도입하므로 이 경우 최적이 아니며, 이는 중요한 애플리케이션의 다운타임 최소화 요구 사항을 충족하지 못할 수 있습니다.",
            "롤링 업데이트 전략은 인스턴스를 하나씩 업데이트하므로 업데이트 중 서비스의 일시적인 가용성 저하를 초래할 수 있어 높은 가용성이 요구되는 애플리케이션에는 적합하지 않습니다.",
            "재생성 배포 전략을 구현하면 이전 버전이 완전히 종료된 후 새로운 버전이 시작되므로 다운타임이 발생하게 되어 중요한 애플리케이션에는 허용되지 않습니다."
        ]
    },
    {
        "Question Number": "64",
        "Situation": "한 회사가 AWS에서 여러 마이크로서비스를 운영하고 있으며, 오류율의 비정상적인 급증에 대한 알림을 설정하면서 특정 애플리케이션 성능 메트릭을 모니터링해야 합니다. DevOps 엔지니어는 사용자 정의 메트릭 생성 및 알림을 허용하는 솔루션을 구현하는 임무를 맡고 있습니다.",
        "Question": "어떤 구성 단계가 요구 사항을 효과적으로 충족할까요? (두 가지 선택)",
        "Options": {
            "1": "오류율이 미리 정의된 임계값을 초과할 때 트리거되는 사용자 정의 메트릭에 대한 CloudWatch 경고를 설정합니다.",
            "2": "경고를 설정하지 않고 모든 메트릭을 시각화하기 위해 CloudWatch 대시보드를 생성합니다.",
            "3": "SNS 주제를 구성하고 계정의 모든 CloudWatch 경고에 대한 알림을 보내도록 설정합니다.",
            "4": "특정 오류 패턴을 모니터링하고 경고를 트리거하기 위해 CloudWatch Logs 메트릭 필터를 구현합니다.",
            "5": "각 마이크로서비스에 대한 CloudWatch 사용자 정의 메트릭을 생성하여 주요 성능 지표를 캡처합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "각 마이크로서비스에 대한 CloudWatch 사용자 정의 메트릭을 생성하여 주요 성능 지표를 캡처합니다.",
            "특정 오류 패턴을 모니터링하고 경고를 트리거하기 위해 CloudWatch Logs 메트릭 필터를 구현합니다."
        ],
        "Explanation": "사용자 정의 메트릭을 생성하면 회사가 각 마이크로서비스와 관련된 특정 성능 지표를 추적할 수 있으며, 메트릭 필터는 특정 오류 패턴을 모니터링하고 이러한 패턴에 따라 경고를 트리거할 수 있게 합니다. 이 조합은 애플리케이션의 요구에 맞춘 포괄적인 모니터링 솔루션을 제공합니다.",
        "Other Options": [
            "모든 사용자 정의 메트릭에 대한 CloudWatch 경고를 설정하는 것은 특정 임계값 및 조건을 정의하지 않으면 충분하지 않을 수 있으며, 이는 불필요한 알림으로 이어질 수 있습니다.",
            "계정의 모든 CloudWatch 경고에 대한 알림을 보내도록 SNS 주제를 구성하는 것은 지나치게 광범위하며, 관련 없는 알림이 전송되어 팀이 압도당할 수 있습니다.",
            "메트릭을 시각화하기 위해 CloudWatch 대시보드를 생성하는 것은 오류율에 기반한 알림 요구 사항을 해결하지 않으므로 지정된 요구에 대해 효과적이지 않습니다."
        ]
    },
    {
        "Question Number": "65",
        "Situation": "한 전자상거래 플랫폼이 AWS 서비스를 활용하여 웹 애플리케이션과 백엔드 프로세스를 관리하고 있습니다. 이 플랫폼은 Amazon EC2, AWS Lambda 및 Amazon API Gateway를 포함한 다양한 서비스에서 상당한 양의 로그 데이터를 생성합니다. 운영 팀은 모니터링, 분석 및 알림 목적으로 이 로그 데이터를 실시간으로 처리해야 합니다. 그들은 수동 개입을 최소화하면서 적시 로그 처리 및 저장을 보장하는 솔루션을 구현하고자 합니다.",
        "Question": "어떤 솔루션이 최소한의 관리 오버헤드로 CloudWatch Logs의 로그 데이터를 처리하는 자동화된 접근 방식을 제공합니까?",
        "Options": {
            "1": "CloudWatch Logs를 사용하여 로그 처리를 위한 EC2 인스턴스를 프로비저닝하고 결과를 관계형 데이터베이스에 저장하는 CloudFormation 스택을 트리거합니다.",
            "2": "CloudWatch Logs 구독 필터를 설정하여 로그 데이터를 Amazon Kinesis Data Stream으로 스트리밍합니다. Lambda 함수를 사용하여 데이터를 처리하고 Amazon OpenSearch Service로 전달합니다.",
            "3": "CloudWatch Logs Insights를 활성화하여 CloudWatch에서 직접 로그를 쿼리합니다. 로그 데이터를 요약하고 매일 이메일로 전송하는 보고서를 예약합니다.",
            "4": "AWS Step Function을 트리거하여 로그 처리를 조정하고 결과를 S3 버킷에 저장하는 CloudWatch Logs 구독 필터를 생성합니다."
        },
        "Correct Answer": "CloudWatch Logs 구독 필터를 설정하여 로그 데이터를 Amazon Kinesis Data Stream으로 스트리밍합니다. Lambda 함수를 사용하여 데이터를 처리하고 Amazon OpenSearch Service로 전달합니다.",
        "Explanation": "이 옵션은 최소한의 오버헤드로 로그 데이터를 실시간으로 처리할 수 있게 합니다. 구독 필터를 사용하여 로그를 Kinesis로 스트리밍함으로써, 이 솔루션은 높은 데이터 볼륨을 효율적으로 처리할 수 있습니다. Lambda 함수는 로그를 처리하고 Amazon OpenSearch Service로 전송하여 전체 파이프라인을 자동화합니다.",
        "Other Options": [
            "이 옵션은 예약된 쿼리와 수동 보고서에 의존하므로 실시간 로그 처리를 제공하지 않으며, 문제를 식별하는 데 지연이 발생할 수 있습니다.",
            "이 옵션은 CloudWatch Logs 구독 필터를 사용하지만 AWS Step Functions의 사용은 간단한 로그 처리를 위한 불필요한 복잡성을 도입하여 효율성을 떨어뜨립니다.",
            "이 옵션은 EC2 인스턴스를 프로비저닝하고 관리해야 하므로 운영 오버헤드가 증가하며 로그 데이터 처리를 위해 서버리스 구성 요소를 활용하지 않습니다."
        ]
    },
    {
        "Question Number": "66",
        "Situation": "한 회사가 AWS에 호스팅된 웹 애플리케이션을 위한 강력한 배포 전략을 구현하고자 합니다. 그들은 배포 프로세스가 다운타임을 최소화하고 실패 시 빠른 롤백 메커니즘을 제공하도록 보장하고자 합니다. 운영 팀은 AWS 서비스를 사용하여 기존 CI/CD 파이프라인과 통합할 수 있는 다양한 배포 전략을 고려하고 있습니다.",
        "Question": "다음 중 어떤 배포 전략이 다운타임을 최소화하고 빠른 롤백 메커니즘을 제공하는 회사의 요구 사항을 가장 잘 충족합니까?",
        "Options": {
            "1": "AWS Elastic Beanstalk를 사용하여 롤링 배포 전략을 적용하여 배포 프로세스 중 일부 인스턴스가 이전 버전을 실행하는 동안 인스턴스를 점진적으로 업데이트합니다.",
            "2": "AWS CodeDeploy에서 불변 배포 전략을 구성하여 애플리케이션의 새 버전을 위한 새로운 인스턴스를 생성하고 배포가 완료되면 이전 인스턴스를 종료합니다.",
            "3": "AWS Lambda 함수를 사용하여 카나리 배포를 설정하여 새로운 버전으로의 트래픽의 작은 하위 집합을 유도하고 성능을 관찰한 후 모든 사용자에게 배포합니다.",
            "4": "AWS CodeDeploy를 사용하여 블루/그린 배포 전략을 구현하여 애플리케이션의 새 버전을 별도의 환경에 배포하고 검증 후 트래픽을 전환합니다."
        },
        "Correct Answer": "AWS CodeDeploy를 사용하여 블루/그린 배포 전략을 구현하여 애플리케이션의 새 버전을 별도의 환경에 배포하고 검증 후 트래픽을 전환합니다.",
        "Explanation": "블루/그린 배포 전략은 애플리케이션의 이전 버전과 새 버전 간의 원활한 전환을 가능하게 하여 다운타임을 최소화합니다. 또한 새로운 배포에서 문제가 발생할 경우 트래픽을 쉽게 이전 버전으로 다시 전환할 수 있는 빠른 롤백 옵션을 제공합니다.",
        "Other Options": [
            "롤링 배포 전략은 인스턴스가 점진적으로 업데이트되므로 다운타임을 완전히 제거하지 않습니다. 이는 일시적인 불일치를 초래할 수 있으며 블루/그린 배포만큼 빠른 롤백 옵션을 제공하지 않습니다.",
            "카나리 배포는 새로운 기능을 테스트하는 데 유용하지만 주요 릴리스 동안 모든 사용자에 대한 다운타임을 효과적으로 최소화하지 못할 수 있습니다. 문제가 발견되면 트래픽을 다시 전환해야 하므로 롤백 프로세스가 복잡해질 수 있습니다.",
            "불변 배포 전략은 깨끗한 배포를 보장하는 데 효과적이지만, 더 많은 자원을 소모할 수 있으며 블루/그린 전략만큼 빠른 롤백 기능을 제공하지 않을 수 있습니다."
        ]
    },
    {
        "Question Number": "67",
        "Situation": "대기업이 AWS Control Tower를 도입하여 안전하고 규정을 준수하는 다중 계정 환경을 구축했습니다. 그들은 모든 계정에서 일관된 거버넌스와 보안을 보장하면서 계정 프로비저닝을 간소화하고자 합니다. 조직은 또한 모든 계정에서 규정 준수 및 보안 발견 사항을 지속적으로 모니터링해야 합니다. 그들은 규정 준수 상태 및 보안 경고에 대한 개요를 제공하는 솔루션을 구현하고자 합니다.",
        "Question": "다음 솔루션 중에서 기업이 모든 계정에서 중앙 집중식 거버넌스 및 보안 준수 모니터링을 효율적으로 달성하기 위해 구현해야 할 것은 무엇입니까?",
        "Options": {
            "1": "AWS Organizations를 활용하여 계정을 관리하고, 모든 계정에 AWS Config를 배포하여 규정 준수를 추적하며, 일관된 거버넌스를 위해 AWS Control Tower를 설정합니다.",
            "2": "AWS Config를 사용하여 리소스 규정 준수를 위한 규칙을 만들고, AWS Security Hub를 설정하여 보안 발견 사항을 집계하며, Amazon GuardDuty와 통합하여 계정 간 위협 탐지를 수행합니다.",
            "3": "AWS Service Catalog를 구현하여 규정 준수 리소스의 포트폴리오를 만들고, 거버넌스를 위한 서비스 제어 정책(SCPs)을 시행하며, Amazon Detective를 사용하여 보안 사건을 분석합니다.",
            "4": "AWS Config 규칙을 구성하여 리소스 규정 준수를 모니터링하고, AWS Systems Manager를 활용하여 계정 간 자동화를 수행하며, Amazon CloudWatch를 설정하여 운영 모니터링을 합니다."
        },
        "Correct Answer": "AWS Config를 사용하여 리소스 규정 준수를 위한 규칙을 만들고, AWS Security Hub를 설정하여 보안 발견 사항을 집계하며, Amazon GuardDuty와 통합하여 계정 간 위협 탐지를 수행합니다.",
        "Explanation": "이 옵션은 AWS Config를 활용한 규정 준수 규칙, AWS Security Hub를 통한 중앙 집중식 보안 발견 사항, Amazon GuardDuty를 통한 위협 탐지를 통해 거버넌스 및 보안에 대한 포괄적인 접근 방식을 제공합니다. 이 설정은 보안 경고의 지속적인 모니터링 및 집계를 가능하게 하여 기업이 모든 계정에서 효과적으로 규정 준수를 유지하도록 합니다.",
        "Other Options": [
            "이 옵션은 리소스 프로비저닝 및 사건 분석에 중점을 두지만, 모든 계정에서 지속적인 규정 준수 모니터링을 위한 포괄적인 솔루션을 제공하지 않습니다. AWS Service Catalog와 Amazon Detective는 유용하지만, 거버넌스 및 보안 모니터링의 전체 범위를 다루지 않습니다.",
            "이 옵션은 계정 관리 및 규정 준수 추적을 강조하지만, 보안 경고 및 발견 사항 집계에 대한 집중적인 접근 방식이 부족합니다. AWS Control Tower는 유용하지만, 완전한 보안 태세를 위해 AWS Security Hub와 같은 추가 도구가 필요합니다.",
            "이 옵션은 리소스 규정 준수 및 운영 모니터링을 강조하지만, 보안 발견 사항에 대한 중앙 집중식 뷰를 제공하지 않으며 위협 탐지 서비스의 통합도 없습니다. AWS Systems Manager와 Amazon CloudWatch는 운영에 도움을 줄 수 있지만, 규정 준수 모니터링을 총체적으로 다루지 않습니다."
        ]
    },
    {
        "Question Number": "68",
        "Situation": "금융 서비스 회사가 사용자 트래픽의 급증을 경험하고 있으며, 이로 인해 AWS에 호스팅된 웹 애플리케이션의 성능이 저하되고 있습니다. 이 애플리케이션은 Amazon ECS에 배포된 마이크로서비스 아키텍처로 구축되었습니다. DevOps 팀은 사용자 수요에 따라 애플리케이션을 자동으로 확장하면서 비용을 최적화할 수 있는 솔루션을 구현하는 임무를 맡고 있습니다.",
        "Question": "다음 솔루션 중에서 회사가 변동하는 사용자 트래픽에 효율적으로 애플리케이션을 확장할 수 있도록 하는 가장 좋은 방법은 무엇입니까?",
        "Options": {
            "1": "Amazon CloudFront를 활용하여 정적 콘텐츠를 캐시하고 애플리케이션 계층에서 트래픽을 오프로드하여 성능을 개선합니다.",
            "2": "피크 트래픽 동안 ECS 작업 인스턴스의 수를 수동으로 증가시키고, 이후 트래픽 패턴에 따라 감소시킵니다.",
            "3": "CPU 사용률 및 요청 수를 기반으로 하는 목표 추적 정책으로 ECS 서비스에 대해 AWS Auto Scaling을 구현합니다.",
            "4": "ECS 서비스 앞에 로드 밸런서를 배포하여 사용자 트래픽을 애플리케이션 인스턴스에 고르게 분산시킵니다."
        },
        "Correct Answer": "CPU 사용률 및 요청 수를 기반으로 하는 목표 추적 정책으로 ECS 서비스에 대해 AWS Auto Scaling을 구현합니다.",
        "Explanation": "ECS 서비스에 대해 AWS Auto Scaling을 목표 추적 정책과 함께 구현하면 애플리케이션이 CPU 사용률 및 요청 수와 같은 실시간 메트릭을 기반으로 실행 중인 작업 수를 자동으로 조정할 수 있습니다. 이는 사용자 트래픽 변동을 처리하는 데 있어 최적의 리소스 사용과 비용 효율성을 보장합니다.",
        "Other Options": [
            "ECS 작업 인스턴스를 수동으로 증가 및 감소시키는 것은 비효율적이며, 인간의 개입이 필요하고 확장 지연을 초래할 수 있어 갑작스러운 트래픽 급증 시 성능 문제를 초래할 수 있습니다.",
            "Amazon CloudFront를 사용하는 것은 정적 콘텐츠의 성능을 크게 개선할 수 있지만, 백엔드 서비스의 동적 확장을 다루지 않으며 피크 트래픽 동안 성능 저하를 완화하지 못할 수 있습니다.",
            "로드 밸런서를 배포하는 것은 트래픽 분산을 위한 좋은 방법이지만, 수요에 따라 ECS 작업 수를 자동으로 확장하지 않으므로 변동하는 사용자 트래픽을 효과적으로 처리하는 데 필수적입니다."
        ]
    },
    {
        "Question Number": "69",
        "Situation": "회사가 운영을 확장하고 있으며 AWS 리소스에 대한 사용자 액세스를 효율적으로 관리해야 합니다. 조직에는 다양한 AWS 서비스에 대해 서로 다른 수준의 액세스가 필요한 여러 팀이 있습니다. 보안 및 규정 준수를 보장하기 위해 DevOps 엔지니어는 조직이 성장함에 따라 확장할 수 있는 신원 및 액세스 관리 솔루션을 구현하는 임무를 맡고 있습니다.",
        "Question": "이 요구 사항을 충족하기 위해 어떤 조합의 조치를 구현해야 합니까? (두 가지 선택)",
        "Options": {
            "1": "AWS CloudTrail을 활성화하여 모든 IAM 활동을 감사 목적으로 기록하고 조직 정책에 대한 준수를 보장합니다.",
            "2": "실시간 사용자 활동에 따라 IAM 정책을 자동으로 조정하는 AWS Lambda 함수를 배포합니다.",
            "3": "AWS Organizations를 활용하여 각 팀에 대해 별도의 계정을 만들고, 서비스 제어 정책(SCPs)을 구현하여 액세스를 제한합니다.",
            "4": "AWS Single Sign-On (SSO)을 구현하여 AWS 서비스 전반에 걸쳐 사용자 인증 및 권한 부여를 중앙 집중화합니다.",
            "5": "각 팀에 맞춤화된 권한 정책을 가진 IAM 역할을 생성하고, 이를 사용자에게 직무 기능에 따라 할당합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "각 팀에 맞춤화된 권한 정책을 가진 IAM 역할을 생성하고, 이를 사용자에게 직무 기능에 따라 할당합니다.",
            "AWS Single Sign-On (SSO)을 구현하여 AWS 서비스 전반에 걸쳐 사용자 인증 및 권한 부여를 중앙 집중화합니다."
        ],
        "Explanation": "특정 권한 정책을 가진 IAM 역할을 생성하면 사용자가 직무 기능에 따라 AWS 리소스에 필요한 액세스를 보장받을 수 있어 최소 권한 원칙을 촉진합니다. AWS Single Sign-On (SSO)을 구현하면 사용자 신원 관리가 중앙 집중화되고 여러 AWS 계정 및 서비스에 걸쳐 액세스 관리 프로세스가 간소화되어 보안 및 규정 준수가 향상됩니다.",
        "Other Options": [
            "AWS Organizations를 활용하여 각 팀에 대해 별도의 계정을 만드는 것은 복잡성과 관리 오버헤드를 증가시킬 수 있으며, 모든 팀이 공유 리소스에 대한 액세스가 필요한 경우 더욱 그렇습니다. IAM 역할 및 정책을 통해 액세스를 관리하는 것이 더 효율적입니다.",
            "AWS CloudTrail을 활성화하는 것은 IAM 활동을 감사하는 데 중요하지만, AWS 리소스에 대한 사용자 액세스 관리에 직접적으로 대응하지 않습니다. 이는 모니터링 도구로 작용할 뿐입니다.",
            "사용자 활동에 따라 IAM 정책을 조정하는 AWS Lambda 함수를 배포하는 것은 권한 관리의 모범 사례가 아닙니다. IAM 정책은 직무 역할에 따라 미리 정의되어야 하며, 동적으로 권한을 조정하는 것은 보안 위험을 초래할 수 있습니다."
        ]
    },
    {
        "Question Number": "70",
        "Situation": "한 스타트업이 AWS CloudFormation을 사용하여 인프라를 코드로 관리하고 있습니다. 이들은 인프라가 쉽게 업데이트되고 다양한 스택 간에 구성 요소를 재사용할 수 있도록 정의되기를 원합니다. 팀은 초기 배포뿐만 아니라 향후 수정에도 사용할 수 있는 템플릿을 생성해야 하며, 중복을 피해야 합니다. 팀은 CloudFormation 템플릿에서 모듈성과 유지 관리성을 위한 모범 사례를 고려하고 있습니다.",
        "Question": "팀이 CloudFormation 템플릿에서 재사용 가능한 구성 요소를 효과적으로 정의하기 위해 어떤 접근 방식을 취해야 합니까?",
        "Options": {
            "1": "CloudFormation 매크로를 사용하여 템플릿을 동적으로 변환하여 리소스 정의의 유연성을 높입니다.",
            "2": "모든 리소스를 단일 CloudFormation 템플릿에 정의하여 관리를 단순화하고 크로스 스택 참조를 피합니다.",
            "3": "각 구성 요소에 대해 별도의 CloudFormation 스택을 생성하고 중첩 스택을 사용하여 종속성을 관리합니다.",
            "4": "AWS SAM을 사용하여 서버리스 구성 요소를 정의합니다. 이는 모듈성과 재사용성을 위한 내장 지원을 제공합니다."
        },
        "Correct Answer": "각 구성 요소에 대해 별도의 CloudFormation 스택을 생성하고 중첩 스택을 사용하여 종속성을 관리합니다.",
        "Explanation": "각 구성 요소에 대해 별도의 CloudFormation 스택을 생성하면 더 나은 모듈성과 재사용성을 제공합니다. 중첩 스택을 사용함으로써 팀은 종속성을 효과적으로 관리하고 명확한 관심사 분리를 유지할 수 있어 인프라의 유지 관리성과 확장성을 향상시킵니다.",
        "Other Options": [
            "모든 리소스를 단일 CloudFormation 템플릿에 정의하면 복잡성과 업데이트 관리의 어려움이 발생할 수 있습니다. 하나의 리소스에 대한 변경이 전체 스택을 다시 배포해야 할 수도 있습니다.",
            "AWS SAM을 사용하는 것은 서버리스 애플리케이션에 유익하지만 모든 인프라 구성 요소를 포함하지 않을 수 있습니다. 이는 Lambda 함수 및 관련 리소스에 더 적합하며 인프라 관리에 대한 포괄적인 접근 방식이 아닙니다.",
            "CloudFormation 매크로는 유연성을 제공할 수 있지만 템플릿에 복잡성을 추가하고 원래 정의를 모호하게 만들어 인프라를 코드로 관리하고 유지하는 데 어려움을 줄 수 있습니다."
        ]
    },
    {
        "Question Number": "71",
        "Situation": "한 회사가 AWS Systems Manager를 구현하여 온프레미스 서버와 가상 머신(VM)을 관리하고 있습니다. DevOps 엔지니어는 이러한 리소스를 Systems Manager 콘솔을 통해 모니터링하고 관리할 수 있도록 해야 합니다. 엔지니어는 이러한 리소스에 대한 관리형 인스턴스 활성화를 생성하는 과정에 있습니다. 활성화를 완료한 후, 엔지니어는 서버와 VM의 SSM 에이전트가 Systems Manager 서비스에 안전하게 연결될 수 있도록 해야 합니다.",
        "Question": "DevOps 엔지니어가 관리형 인스턴스 활성화를 생성한 후 SSM 에이전트가 Systems Manager 서비스에 연결될 수 있도록 하려면 무엇을 해야 합니까?",
        "Options": {
            "1": "각 관리형 인스턴스에 사용자 지정 스크립트를 배포하여 AWS Secrets Manager에서 활성화 코드와 ID를 검색하여 Systems Manager에 등록합니다.",
            "2": "각 관리형 인스턴스에서 AWS CLI를 수동으로 구성하여 활성화 세부 정보를 사용하여 Systems Manager 서비스에 연결합니다.",
            "3": "각 관리형 인스턴스에 대한 공용 인터넷 액세스를 활성화하여 활성화 코드 없이 Systems Manager 서비스에 연결할 수 있도록 합니다.",
            "4": "활성화 코드와 활성화 ID를 사용하여 각 관리형 인스턴스에 SSM 에이전트를 설치하고 활성화 과정에서 인스턴스 한계를 지정합니다."
        },
        "Correct Answer": "활성화 코드와 활성화 ID를 사용하여 각 관리형 인스턴스에 SSM 에이전트를 설치하고 활성화 과정에서 인스턴스 한계를 지정합니다.",
        "Explanation": "활성화 코드와 활성화 ID는 관리형 인스턴스에 SSM 에이전트를 설치하는 데 필요합니다. 이는 활성화 과정의 일환으로 관리형 인스턴스에서 Systems Manager에 대한 안전한 액세스를 제공합니다.",
        "Other Options": [
            "AWS CLI 구성은 SSM 에이전트가 Systems Manager에 연결하는 데 필요하지 않습니다. 활성화 코드와 ID가 관리형 인스턴스의 안전한 등록을 처리합니다.",
            "Secrets Manager에서 활성화 코드와 ID를 검색하는 것은 관리형 인스턴스를 Systems Manager에 등록하는 표준 방법이 아닙니다. 활성화 세부 정보를 사용하여 SSM 에이전트를 직접 설치하는 것이 올바른 접근 방식입니다.",
            "공용 인터넷 액세스를 활성화하는 것은 관리형 인스턴스를 Systems Manager에 연결하는 안전한 방법도 아니며 권장되는 방법도 아닙니다. 활성화 코드와 ID가 안전한 대안을 제공합니다."
        ]
    },
    {
        "Question Number": "72",
        "Situation": "한 회사가 Elastic Beanstalk를 사용하여 Docker 컨테이너 배포를 용이하게 하며 애플리케이션을 AWS로 마이그레이션하고 있습니다. DevOps 팀은 Dockerfile과 필요한 Elastic Beanstalk 구성을 포함하여 이 환경에서 애플리케이션이 적절하게 구성되도록 해야 합니다.",
        "Question": "AWS Elastic Beanstalk에서 Docker 컨테이너를 배포하기 위한 가장 적절한 구성은 무엇입니까?",
        "Options": {
            "1": "애플리케이션 종속성을 지정하지 않는 Elastic Beanstalk에서 생성된 기본 Dockerfile을 사용합니다. 환경 변수를 정의하기 위해 간단한 .ebextensions 구성을 만들고 Dockerrun.aws.json 파일의 필요성을 생략합니다.",
            "2": "기본 이미지와 애플리케이션 종속성을 지정하는 Dockerfile을 생성합니다. Dockerrun.aws.json 파일이 개인 레지스트리에 저장된 Docker 이미지로 가리키도록 하고, 인증을 위해 S3 버킷에 .dockercfg 파일을 포함합니다.",
            "3": "공용 레지스트리에서 미리 빌드된 Docker 이미지를 활용하고 Elastic Beanstalk가 Dockerfile 없이 이 이미지를 직접 사용하도록 구성합니다.",
            "4": "모든 애플리케이션 로직과 종속성을 포함하는 Dockerfile을 구현하되, Elastic Beanstalk가 Docker 이미지 구성을 자동으로 감지하므로 Dockerrun.aws.json 파일은 생성하지 않습니다."
        },
        "Correct Answer": "기본 이미지와 애플리케이션 종속성을 지정하는 Dockerfile을 생성합니다. Dockerrun.aws.json 파일이 개인 레지스트리에 저장된 Docker 이미지로 가리키도록 하고, 인증을 위해 S3 버킷에 .dockercfg 파일을 포함합니다.",
        "Explanation": "올바른 옵션은 Elastic Beanstalk에서 Docker 컨테이너를 배포하기 위한 완전하고 안전한 설정을 제공합니다. 여기에는 이미지를 빌드하기 위한 Dockerfile, 배포 매개변수를 정의하기 위한 Dockerrun.aws.json 파일, 개인 Docker 레지스트리와 인증하기 위한 .dockercfg 파일이 포함됩니다.",
        "Other Options": [
            "이 옵션은 Dockerfile에서 애플리케이션 종속성을 지정하지 않으면 런타임 문제를 초래할 수 있으므로 잘못된 것입니다. 또한 Dockerrun.aws.json 파일은 Elastic Beanstalk가 애플리케이션을 배포하는 방법을 정의하는 데 필수적입니다.",
            "이 옵션은 Elastic Beanstalk가 Dockerrun.aws.json 파일 없이 작동할 수 있다고 잘못 가정하므로 잘못된 것입니다. Elastic Beanstalk는 Docker 구성을 감지할 수 있지만 이 파일을 제공하면 배포 및 관리 기능이 향상됩니다.",
            "이 옵션은 Dockerrun.aws.json 파일을 제외하면 Docker 컨테이너가 배포되고 관리되는 방식을 구성하는 능력이 제한되므로 잘못된 것입니다. 이는 Elastic Beanstalk에서 애플리케이션을 성공적으로 배포하는 데 중요합니다."
        ]
    },
    {
        "Question Number": "73",
        "Situation": "한 금융 서비스 회사가 애플리케이션 관리를 위해 다양한 지역에 여러 개의 AWS 계정을 사용하고 있습니다. 보안 팀은 모든 계정이 조직의 보안 정책을 준수하고 보안 통제가 일관되게 적용되도록 하기를 원합니다. 팀은 이러한 계정 전반에 걸쳐 보안 준수를 강제하기 위해 자동화 솔루션을 사용하는 것을 고려하고 있습니다.",
        "Question": "보안 팀이 여러 AWS 계정과 지역에 걸쳐 보안 통제를 자동화하는 가장 효과적인 방법은 무엇입니까?",
        "Options": {
            "1": "각 계정에 Amazon GuardDuty를 배포하고 중앙 계정에서 결과를 집계하여 수동 검토를 수행합니다.",
            "2": "AWS Systems Manager를 설정하여 모든 계정에서 일정에 따라 보안 통제를 시행하는 스크립트를 실행합니다.",
            "3": "AWS Organizations를 사용하여 비준수 리소스에 대한 접근을 제한하는 서비스 제어 정책을 생성합니다.",
            "4": "AWS Control Tower를 구현하여 가드레일을 설정하고 계정 간의 준수를 관리합니다."
        },
        "Correct Answer": "AWS Control Tower를 구현하여 가드레일을 설정하고 계정 간의 준수를 관리합니다.",
        "Explanation": "AWS Control Tower는 여러 AWS 계정을 관리하기 위한 포괄적인 솔루션을 제공하며, 계정과 지역 전반에 걸쳐 보안 정책과 준수를 시행하기 위한 내장된 가드레일을 제공합니다. 이는 보안 통제를 일관되게 적용하기 위한 가장 효과적이고 자동화된 접근 방식입니다.",
        "Other Options": [
            "AWS Organizations와 서비스 제어 정책은 작업을 제한할 수 있지만, 준수를 시행하거나 계정 간에 보안 통제를 자동으로 적용하지는 않습니다.",
            "Amazon GuardDuty를 배포하고 결과를 집계하는 것은 준수 문제를 해결하기 위해 수동 개입이 필요하므로 보안 통제의 시행에서 자동화가 부족합니다.",
            "AWS Systems Manager를 사용하여 스크립트를 실행하면 통제를 시행할 수 있지만, 여러 계정과 지역에 걸쳐 준수를 관리하는 데 있어 AWS Control Tower만큼 효과적인 통합 접근 방식을 제공하지 않을 수 있습니다."
        ]
    },
    {
        "Question Number": "74",
        "Situation": "한 회사가 컨테이너화된 애플리케이션을 AWS로 마이그레이션하고 Amazon Elastic Container Registry (ECR)를 사용하여 컨테이너 이미지를 관리할 계획입니다. 보안 팀은 AWS Key Management Service (KMS)를 사용하여 ECR 리포지토리에 대한 암호화를 구현했습니다. 조직의 AWS Organization 내 모든 계정이 암호화된 리포지토리에 접근할 수 있도록 하려면 KMS 키 정책을 올바르게 구성해야 합니다.",
        "Question": "KMS 키로 Amazon ECR 리포지토리를 암호화할 때, 조직 내 모든 계정에 접근을 허용하기 위해 KMS 키 정책에 포함해야 할 가장 중요한 조건은 무엇입니까?",
        "Options": {
            "1": "KMS 키 정책을 설정하여 모든 AWS 계정에서 제한 없이 접근할 수 있도록 합니다.",
            "2": "KMS 키 접근을 위한 조건으로 사용자가 IAM 역할을 사용하여 인증하도록 요구합니다.",
            "3": "KMS 키 정책에 조직 ID를 기반으로 접근을 허용하는 조건을 포함합니다.",
            "4": "계정의 루트 사용자만 ECR을 위한 KMS 키에 접근할 수 있도록 지정합니다."
        },
        "Correct Answer": "KMS 키 정책에 조직 ID를 기반으로 접근을 허용하는 조건을 포함합니다.",
        "Explanation": "조직 내 모든 계정이 KMS로 암호화된 ECR 리포지토리에 접근할 수 있도록 하려면 KMS 키 정책에 조직 ID를 기반으로 한 조건이 포함되어야 합니다. 이는 조직 내 계정 간의 보안을 유지하면서 통제된 접근을 가능하게 합니다.",
        "Other Options": [
            "모든 AWS 계정에서 제한 없이 접근을 허용하는 것은 KMS 키를 조직 내 계정뿐만 아니라 모든 AWS 계정에 노출시켜 상당한 보안 위험을 초래합니다.",
            "사용자가 IAM 역할을 사용하여 인증하도록 요구하는 것은 KMS 키에 대한 조직 전체의 접근 필요성을 해결하지 않으며, 이는 여러 계정에 걸쳐 ECR 리포지토스에 대한 접근을 관리하는 데 중요합니다.",
            "오직 루트 사용자만 KMS 키에 접근할 수 있도록 지정하는 것은 접근을 심각하게 제한하며, 조직 내 여러 계정에 접근을 허용하는 주된 목적을 무산시킵니다."
        ]
    },
    {
        "Question Number": "75",
        "Situation": "소프트웨어 개발 팀이 AWS에 호스팅된 웹 애플리케이션의 배포를 자동화하기 위해 CI/CD 파이프라인을 사용하고 있습니다. 이 파이프라인에는 코드 커밋, 빌드, 테스트 및 배포 단계가 포함되어 있습니다. 최근 팀은 배포 전략을 롤링 업데이트에서 블루-그린 배포 모델로 전환하여 릴리스 중 다운타임을 최소화하기로 결정했습니다. 팀은 이 전환이 효과적으로 구현되기를 원합니다.",
        "Question": "팀이 CI/CD 파이프라인에서 블루-그린 배포 모델을 구현하기 위해 어떤 조치를 취해야 합니까?",
        "Options": {
            "1": "파이프라인을 수정하여 새 버전을 기존 환경에 직접 배포하고 테스트 중에 실패가 발생하면 롤백합니다.",
            "2": "현재 배포를 위한 환경과 새 버전을 위한 두 개의 별도 환경을 생성하고 AWS Elastic Load Balancing을 사용하여 트래픽을 전환합니다.",
            "3": "현재 버전을 유지하면서 새로운 버전으로 트래픽을 점진적으로 전환하기 위해 카나리 배포 전략을 구현합니다.",
            "4": "AWS CodeDeploy를 사용하여 배포 프로세스를 자동으로 관리하고 새 버전으로 트래픽을 전환하기 전에 상태 검사를 수행합니다."
        },
        "Correct Answer": "현재 배포를 위한 환경과 새 버전을 위한 두 개의 별도 환경을 생성하고 AWS Elastic Load Balancing을 사용하여 트래픽을 전환합니다.",
        "Explanation": "블루-그린 배포 모델에서는 두 개의 별도 환경을 유지합니다: 하나는 활성(블루)이고 다른 하나는 대기(그린)입니다. 새 버전이 그린 환경에서 준비되면 AWS Elastic Load Balancing을 사용하여 블루에서 그린으로 트래픽을 전환하여 다운타임을 최소화하고 필요 시 쉽게 롤백할 수 있습니다.",
        "Other Options": [
            "이 옵션은 기존 환경에 직접 배포하는 것을 설명하고 있으며, 이는 블루-그린 배포 전략을 따르지 않으며 릴리스 중 다운타임이나 문제를 초래할 수 있습니다.",
            "AWS CodeDeploy는 배포 및 상태 검사를 용이하게 할 수 있지만, 본질적으로 블루-그린 아키텍처를 생성하지는 않습니다. 이 옵션은 블루-그린 배포의 핵심 원칙인 두 개의 별도 환경의 필요성을 언급하지 않습니다.",
            "이 옵션은 카나리 배포 전략을 설명하고 있으며, 이는 전체 롤아웃 전에 소규모 사용자 집단에 변경 사항을 배포하는 것입니다. 이는 두 개의 완전한 환경을 유지해야 하는 블루-그린 접근 방식과 다릅니다."
        ]
    }
]