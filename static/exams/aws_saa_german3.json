[
    {
        "Question Number": "1",
        "Situation": "Ein E-Commerce-Unternehmen verzeichnet saisonale Spitzen im Website-Verkehr während der Feiertagsverkäufe. Um eine hohe Verfügbarkeit sicherzustellen und den eingehenden Verkehr effizient zu verteilen, möchte das Unternehmen eine Lastenausgleichslösung implementieren, die Anfragen basierend auf dem Inhalt der Anfragen weiterleiten kann.",
        "Question": "Welche AWS-Lastenausgleichslösung sollte der Lösungsarchitekt empfehlen?",
        "Options": {
            "1": "Classic Load Balancer, konfiguriert mit Round-Robin-Routing",
            "2": "Network Load Balancer mit statischen IP-Adressen",
            "3": "Application Load Balancer mit pfadbasierten Routing-Regeln",
            "4": "AWS Global Accelerator mit DNS-basiertem Routing"
        },
        "Correct Answer": "Application Load Balancer mit pfadbasierten Routing-Regeln",
        "Explanation": "Der Application Load Balancer (ALB) ist dafür ausgelegt, HTTP- und HTTPS-Verkehr zu verarbeiten und kann Anfragen basierend auf dem Inhalt der Anfragen weiterleiten, wie z.B. URL-Pfade oder Host-Header. Dies macht ihn ideal für ein E-Commerce-Unternehmen, das den Verkehr während saisonaler Spitzen effizient verteilen und Anfragen basierend auf dem Inhalt an verschiedene Dienste weiterleiten muss. Das pfadbasiertes Routing ermöglicht es dem ALB, den Verkehr an spezifische Backend-Dienste basierend auf dem URL-Pfad zu leiten, was besonders nützlich für eine Anwendung mit mehreren Diensten oder Mikrodiensten ist.",
        "Other Options": [
            "Der Classic Load Balancer ist eine veraltete Option, die kein inhaltsbasiertes Routing unterstützt. Er verwendet hauptsächlich Round-Robin- oder Sticky-Session-Routing, was weniger flexibel für Anwendungen ist, die Routing basierend auf dem Anfrageinhalt erfordern.",
            "Der Network Load Balancer ist für die Verarbeitung von TCP-Verkehr optimiert und kann Millionen von Anfragen pro Sekunde verarbeiten, während er ultra-niedrige Latenzen aufrechterhält. Allerdings unterstützt er kein inhaltsbasiertes Routing, was in diesem Szenario erforderlich ist.",
            "AWS Global Accelerator ist dafür ausgelegt, die Verfügbarkeit und Leistung von Anwendungen mit globalen Nutzern zu verbessern, indem der Verkehr zu optimalen Endpunkten basierend auf Gesundheit, Geografie und Routing-Richtlinien geleitet wird. Allerdings bietet er keine inhaltsbasierten Routing-Funktionen, was ihn für das spezifische Bedürfnis, Anfragen basierend auf ihrem Inhalt weiterzuleiten, ungeeignet macht."
        ]
    },
    {
        "Question Number": "2",
        "Situation": "Ein Unternehmen möchte seine Daten auf Amazon EBS-Volumes, die an EC2-Instanzen angeschlossen sind, sichern und sicherstellen, dass die Daten im Ruhezustand verschlüsselt bleiben. Sie planen auch, Snapshots dieser Volumes für Backup-Zwecke zu erstellen.",
        "Question": "Welche der folgenden Aussagen beschreibt korrekt, wie die EBS-Verschlüsselung für diesen Anwendungsfall funktioniert? (Wählen Sie zwei aus.)",
        "Options": {
            "1": "EBS-Volumes können nur verschlüsselt werden, wenn sie an dedizierte Instanzen angeschlossen sind, und die Verschlüsselung muss manuell auf jeden erstellten Snapshot angewendet werden.",
            "2": "Jedes EBS-Volume verwendet einen einzigartigen Data Encryption Key (DEK), der von AWS KMS generiert wird, und alle Snapshots sowie zukünftige Volumes, die aus diesen Snapshots erstellt werden, verwenden denselben DEK.",
            "3": "Die EBS-Verschlüsselung beruht ausschließlich auf der Instanzebene und erfordert keine KMS-Integration, wodurch die Verschlüsselung für das Volume transparent ist.",
            "4": "Aktivieren Sie die Verschlüsselung standardmäßig für alle EBS-Volumes mit AWS KMS-verwalteten Schlüsseln, um sicherzustellen, dass alle vorhandenen und neuen Snapshots automatisch verschlüsselt werden.",
            "5": "Die EBS-Verschlüsselung verschlüsselt nur Snapshots, nicht die aktiven Volumendaten, die im Ruhezustand auf EC2-Instanzen gespeichert sind."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Jedes EBS-Volume verwendet einen einzigartigen Data Encryption Key (DEK), der von AWS KMS generiert wird, und alle Snapshots sowie zukünftige Volumes, die aus diesen Snapshots erstellt werden, verwenden denselben DEK.",
            "Aktivieren Sie die Verschlüsselung standardmäßig für alle EBS-Volumes mit AWS KMS-verwalteten Schlüsseln, um sicherzustellen, dass alle vorhandenen und neuen Snapshots automatisch verschlüsselt werden."
        ],
        "Explanation": "Jedes EBS-Volume verwendet einen einzigartigen Data Encryption Key (DEK), der von AWS KMS generiert wird. Dieser DEK wird verwendet, um das Volume zu verschlüsseln, und alle Snapshots, die vom Volume erstellt werden, sowie alle zukünftigen Volumes, die aus diesen Snapshots erstellt werden, verwenden ebenfalls denselben DEK. Dies stellt sicher, dass die Daten im Ruhezustand verschlüsselt bleiben. Darüber hinaus ermöglicht AWS, die Verschlüsselung standardmäßig für alle EBS-Volumes mit AWS KMS-verwalteten Schlüsseln zu aktivieren. Dies stellt sicher, dass alle vorhandenen und neuen Snapshots automatisch verschlüsselt werden, was eine zusätzliche Sicherheitsebene bietet.",
        "Other Options": [
            "EBS-Volumes können nur verschlüsselt werden, wenn sie an dedizierte Instanzen angeschlossen sind, und die Verschlüsselung muss manuell auf jeden erstellten Snapshot angewendet werden. Dies ist falsch, da die EBS-Verschlüsselung nicht auf dedizierte Instanzen beschränkt ist und Snapshots, die von verschlüsselten Volumes erstellt werden, automatisch verschlüsselt sind.",
            "Die EBS-Verschlüsselung beruht ausschließlich auf der Instanzebene und erfordert keine KMS-Integration, wodurch die Verschlüsselung für das Volume transparent ist. Dies ist falsch, da die EBS-Verschlüsselung eine Integration mit AWS KMS zur Generierung und Verwaltung der Verschlüsselungsschlüssel erfordert.",
            "Die EBS-Verschlüsselung verschlüsselt nur Snapshots, nicht die aktiven Volumendaten, die im Ruhezustand auf EC2-Instanzen gespeichert sind. Dies ist falsch, da die EBS-Verschlüsselung sowohl die aktiven Volumendaten als auch die Snapshots verschlüsselt."
        ]
    },
    {
        "Question Number": "3",
        "Situation": "Ein globales Gaming-Unternehmen startet ein neues Online-Multiplayer-Spiel, das Spieler aus der ganzen Welt anzieht. Das Unternehmen möchte minimale Latenz und ein nahtloses Spielerlebnis für alle Spieler gewährleisten, unabhängig von ihrem geografischen Standort. Darüber hinaus möchten sie ihre Spielserver vor DDoS-Angriffen schützen.",
        "Question": "Welche AWS-Dienste sollte der Lösungsarchitekt empfehlen, um die Inhaltsbereitstellung zu optimieren und die Sicherheit am Edge zu verbessern? (Wählen Sie zwei aus.)",
        "Options": {
            "1": "Amazon CloudFront mit AWS Shield Advanced",
            "2": "AWS Global Accelerator mit Amazon Route 53",
            "3": "AWS Direct Connect mit AWS WAF",
            "4": "Amazon ElastiCache mit AWS Firewall Manager",
            "5": "AWS Global Accelerator mit AWS Shield Advanced"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon CloudFront mit AWS Shield Advanced",
            "AWS Global Accelerator mit AWS Shield Advanced"
        ],
        "Explanation": "Amazon CloudFront mit AWS Shield Advanced und AWS Global Accelerator mit AWS Shield Advanced sind die richtigen Antworten. Amazon CloudFront ist ein Content Delivery Network (CDN), das Daten, Videos, Anwendungen und APIs global mit niedriger Latenz und hohen Übertragungsgeschwindigkeiten an Kunden liefert. AWS Shield Advanced bietet kosteneffektiven DDoS-Schutz für Ressourcen, die auf AWS ausgeführt werden, was für das Gaming-Unternehmen entscheidend ist, um ihre Server vor DDoS-Angriffen zu schützen. AWS Global Accelerator ist ein Netzwerkdienst, der den Verkehr der Nutzer durch die globale Netzwerk-Infrastruktur von Amazon Web Services leitet und die Internetnutzungsleistung um bis zu 60 % verbessert. In Kombination mit AWS Shield Advanced verbessert es nicht nur die Leistung, sondern bietet auch DDoS-Schutz.",
        "Other Options": [
            "AWS Global Accelerator mit Amazon Route 53 ist keine vollständige Lösung. Während AWS Global Accelerator die Verfügbarkeit und Leistung der Anwendungen verbessert, ist Amazon Route 53 ein skalierbarer Domain Name System (DNS)-Webdienst, bietet jedoch keinen DDoS-Schutz.",
            "AWS Direct Connect mit AWS WAF ist nicht die beste Lösung. AWS Direct Connect ist eine Cloud-Service-Lösung, die es einfach macht, eine dedizierte Netzwerkverbindung von Ihren Räumlichkeiten zu AWS herzustellen, und AWS WAF ist eine Webanwendungsfirewall, die hilft, Ihre Webanwendungen vor gängigen Web-Exploits zu schützen, aber keiner dieser Dienste optimiert die Inhaltsbereitstellung oder bietet DDoS-Schutz am Edge.",
            "Amazon ElastiCache mit AWS Firewall Manager ist nicht die richtige Lösung. Amazon ElastiCache ist ein Webdienst, der es einfach macht, einen In-Memory-Cache in der Cloud bereitzustellen, zu betreiben und zu skalieren, und AWS Firewall Manager ist ein Sicherheitsmanagementdienst, der es Ihnen ermöglicht, Firewall-Regeln zentral zu konfigurieren und zu verwalten. Allerdings optimiert keiner dieser Dienste die Inhaltsbereitstellung oder bietet DDoS-Schutz am Edge."
        ]
    },
    {
        "Question Number": "4",
        "Situation": "Ein Einzelhandelsunternehmen möchte ein Überwachungssystem implementieren, bei dem spezifische Aktionen automatisch ausgelöst werden, wenn bestimmte Ereignisse in ihrer AWS-Umgebung auftreten. Zum Beispiel, wenn eine EC2-Instanz ihren Status von \"gestoppt\" auf \"laufend\" ändert, sollte eine Lambda-Funktion ausgelöst werden, um diese Aktivität zu protokollieren. Sie möchten auch regelmäßige Aufgaben planen, wie z.B. nächtliche Backups, mit demselben Dienst.",
        "Question": "Welche AWS-Dienstkonfiguration würde diese Anforderungen am besten erfüllen?",
        "Options": {
            "1": "Amazon CloudWatch Logs mit geplanten Abfragen",
            "2": "AWS Lambda mit periodischen Aufruf-Einstellungen",
            "3": "Amazon EventBridge mit Ereignismusterregeln und Zeitplanregeln",
            "4": "AWS Step Functions mit Wiederholungsmustern"
        },
        "Correct Answer": "Amazon EventBridge mit Ereignismusterregeln und Zeitplanregeln",
        "Explanation": "Amazon EventBridge ist dafür ausgelegt, ereignisgesteuerte Architekturen zu erleichtern und kann auf Statusänderungen in AWS-Ressourcen, wie z.B. EC2-Instanzen, reagieren. Es ermöglicht Ihnen, Ereignismuster zu erstellen, die Aktionen auslösen (wie das Auslösen einer Lambda-Funktion), wenn bestimmte Ereignisse auftreten, wie z.B. eine Statusänderung einer EC2-Instanz. Darüber hinaus unterstützt EventBridge geplante Ereignisse, sodass Sie regelmäßige Aufgaben wie nächtliche Backups einrichten können. Dies macht es zur besten Lösung für die im Szenario beschriebenen Anforderungen.",
        "Other Options": [
            "Amazon CloudWatch Logs mit geplanten Abfragen wird hauptsächlich für das Protokollieren und Abfragen von Protokolldaten verwendet. Während es bei der Überwachung von Protokollen helfen kann, bietet es nicht von sich aus die Möglichkeit, Aktionen basierend auf Ereignissen auszulösen oder Aufgaben direkt zu planen.",
            "AWS Lambda mit periodischen Aufruf-Einstellungen kann Funktionen nach einem Zeitplan ausführen, aber es behandelt nicht nativ ereignisgesteuerte Auslöser basierend auf Statusänderungen von Ressourcen. Es würde zusätzliche Konfiguration erfordern, um Statusänderungen von EC2 zu überwachen.",
            "AWS Step Functions ist ein Dienst zur Orchestrierung komplexer Workflows und zur Verwaltung von Zuständen über mehrere Dienste hinweg. Während es Wiederholungen handhaben und Workflows verwalten kann, ist es nicht speziell für ereignisgesteuerte Auslöser oder die direkte Planung von Aufgaben konzipiert, was es weniger geeignet für die angegebenen Anforderungen macht."
        ]
    },
    {
        "Question Number": "5",
        "Situation": "Eine Webanwendung muss schwankende Verkehrsbelastungen bewältigen, und das Unternehmen möchte eine Lastenausgleichsstrategie verwenden, die die Kosten minimiert und gleichzeitig den Verkehr effizient über Instanzen verteilt. Sie möchten auch die Kosten optimieren, indem sie Layer 7 (Anwendungsschicht) Lastenausgleich verwenden.",
        "Question": "Welche Lastenausgleichsoption wäre für diese Anforderung am kosteneffektivsten?",
        "Options": {
            "1": "Verwenden Sie einen Classic Load Balancer mit manueller Skalierung",
            "2": "Setzen Sie einen Application Load Balancer (ALB) mit aktivierter automatischer Skalierung ein",
            "3": "Verwenden Sie einen Network Load Balancer (NLB), um HTTP/HTTPS-Verkehr zu verarbeiten",
            "4": "Setzen Sie individuelle Lastenausgleicher für jede Availability Zone ein"
        },
        "Correct Answer": "Setzen Sie einen Application Load Balancer (ALB) mit aktivierter automatischer Skalierung ein",
        "Explanation": "Ein Application Load Balancer (ALB) ist speziell dafür konzipiert, HTTP- und HTTPS-Verkehr auf Layer 7 zu verarbeiten, was fortgeschrittenes Routing und Verkehrsmanagement basierend auf dem Inhalt der Anfragen ermöglicht. Durch die Aktivierung der automatischen Skalierung kann die Anwendung die Anzahl der Instanzen basierend auf der aktuellen Verkehrsbelastung automatisch anpassen, was eine effiziente Ressourcennutzung und Kostenwirksamkeit sicherstellt. Diese Kombination ermöglicht es dem Unternehmen, den Verkehr effizient zu verteilen und gleichzeitig die Kosten im Zusammenhang mit einer Überprovisionierung von Ressourcen zu minimieren.",
        "Other Options": [
            "Die Verwendung eines Classic Load Balancer mit manueller Skalierung ist nicht kosteneffektiv, da sie manuelles Eingreifen erfordert, um die Anzahl der Instanzen basierend auf der Verkehrsbelastung anzupassen, was zu einer Unter- oder Überauslastung von Ressourcen führen kann, was die Kosten erhöht.",
            "Die Verwendung eines Network Load Balancer (NLB) ist nicht geeignet für HTTP/HTTPS-Verkehr, da er auf Layer 4 arbeitet und nicht die fortgeschrittenen Routingfähigkeiten bietet, die ein ALB bietet. Darüber hinaus sind NLBs typischerweise teurer und optimieren die Kosten nicht so effektiv für Webanwendungen.",
            "Das Einsetzen individueller Lastenausgleicher für jede Availability Zone ist ineffizient und kostspielig. Dieser Ansatz würde die Wartung mehrerer Lastenausgleicher erfordern, was zu erhöhtem Betriebsaufwand und Kosten führen würde, anstatt einen einzigen ALB zu nutzen, der den Verkehr effizient über mehrere Zonen verwalten kann."
        ]
    },
    {
        "Question Number": "6",
        "Situation": "Ein Marketing-Analyseunternehmen möchte sein großangelegtes Data Warehouse zu AWS migrieren. Die Daten sind für komplexe analytische Abfragen strukturiert und nicht für transaktionale Workloads, und das Unternehmen benötigt eine Lösung, die sich leicht in seine bestehenden SQL-basierten BI-Tools integrieren lässt. Darüber hinaus möchte das Unternehmen historische Daten, die in Amazon S3 gespeichert sind, direkt abfragen, ohne sie in das Data Warehouse zu laden.",
        "Question": "Welche Kombination aus AWS-Dienst und -Funktion sollte der Lösungsarchitekt empfehlen?",
        "Options": {
            "1": "Amazon Redshift mit Redshift Spectrum",
            "2": "Amazon RDS mit Read Replicas",
            "3": "Amazon DynamoDB mit Global Tables",
            "4": "Amazon S3 mit Athena für Ad-hoc-Abfragen"
        },
        "Correct Answer": "Amazon Redshift mit Redshift Spectrum",
        "Explanation": "Amazon Redshift ist ein vollständig verwalteter Data Warehouse-Dienst, der für komplexe analytische Abfragen konzipiert ist, was ihn für die Bedürfnisse des Marketing-Analyseunternehmens geeignet macht. Redshift Spectrum ermöglicht es Benutzern, Abfragen gegen Daten zu führen, die in Amazon S3 gespeichert sind, ohne sie in Redshift laden zu müssen, was ideal für die Abfrage historischer Daten ist. Diese Kombination ermöglicht eine nahtlose Integration mit bestehenden SQL-basierten BI-Tools, da Redshift Standard-SQL für Abfragen verwendet.",
        "Other Options": [
            "Amazon RDS mit Read Replicas ist hauptsächlich für transaktionale Workloads und relationale Datenbankverwaltung konzipiert, was nicht mit dem Bedarf des Unternehmens an komplexen analytischen Abfragen und der direkten Abfrage historischer Daten in S3 übereinstimmt.",
            "Amazon DynamoDB mit Global Tables ist ein NoSQL-Datenbankdienst, der für hochvolumige transaktionale Workloads optimiert ist, nicht für komplexe analytische Abfragen. Es unterstützt SQL-basierte BI-Tools nicht so effektiv wie Redshift.",
            "Amazon S3 mit Athena für Ad-hoc-Abfragen ist eine praktikable Option, um Daten direkt in S3 abzufragen, bietet jedoch möglicherweise nicht das gleiche Leistungsniveau und die gleiche Optimierung für komplexe analytische Abfragen wie Amazon Redshift mit Redshift Spectrum."
        ]
    },
    {
        "Question Number": "7",
        "Situation": "Ein Biotechnologieunternehmen führt großangelegte Genomsequenzierungsanalysen durch, die intermittierend erhebliche Rechenressourcen erfordern. Das Unternehmen möchte die Kosten optimieren, indem sichergestellt wird, dass die Rechenressourcen nur bei Bedarf genutzt werden und automatisch basierend auf den Anforderungen der Workloads skalieren können.",
        "Question": "Welchen AWS-Compute-Dienst sollte der Lösungsarchitekt für dieses Szenario empfehlen?",
        "Options": {
            "1": "Amazon EC2 Auto Scaling",
            "2": "AWS Lambda",
            "3": "AWS Batch",
            "4": "Amazon ECS auf EC2"
        },
        "Correct Answer": "AWS Batch",
        "Explanation": "AWS Batch ist speziell für die effiziente Ausführung von Batch-Computing-Workloads in beliebiger Größenordnung konzipiert. Es provisioniert automatisch die optimale Menge und Art von Rechenressourcen (z. B. CPU- oder speicheroptimierte Instanzen) basierend auf dem Volumen und den spezifischen Ressourcenanforderungen der eingereichten Batch-Jobs. Dies macht es ideal für die Bedürfnisse des Biotechnologieunternehmens, da es großangelegte Genomsequenzierungsanalysen durchführen kann, die intermittierend erhebliche Rechenressourcen erfordern, und die Kosten optimiert, indem es Ressourcen nur bei Bedarf nutzt und automatisch basierend auf den Anforderungen der Workloads skaliert.",
        "Other Options": [
            "Amazon EC2 Auto Scaling ist nützlich für die Verwaltung von EC2-Instanzen und deren Skalierung basierend auf der Nachfrage, ist jedoch nicht speziell für Batch-Verarbeitungs-Workloads ausgelegt. Es erfordert mehr manuelle Einrichtung und Verwaltung im Vergleich zu AWS Batch, das für Batch-Jobs konzipiert ist.",
            "AWS Lambda ist ein serverloser Compute-Dienst, der Code als Reaktion auf Ereignisse ausführt und automatisch die erforderlichen Rechenressourcen verwaltet. Es ist jedoch nicht für langlaufende Batch-Jobs wie Genomsequenzierungsanalysen geeignet, da es eine maximale Ausführungszeit von 15 Minuten pro Aufruf hat.",
            "Amazon ECS auf EC2 ist ein Container-Orchestrierungsdienst, der es Ihnen ermöglicht, Docker-Container auszuführen und zu verwalten. Während es basierend auf der Nachfrage skalieren kann, erfordert es mehr Verwaltung und ist nicht speziell für Batch-Verarbeitungs-Workloads wie AWS Batch optimiert, was es weniger geeignet für die intermittierenden Rechenressourcenbedürfnisse des Unternehmens macht."
        ]
    },
    {
        "Question Number": "8",
        "Situation": "Eine Online-Bildungsplattform hat während der Hauptverkehrszeiten einen hohen Lesezugriff auf Kursinhalte. Um die Antwortzeiten zu verbessern und die Datenbanklast zu reduzieren, möchte das Unternehmen eine Caching-Schicht implementieren.",
        "Question": "Welche Caching-Lösung sollte der Lösungsarchitekt empfehlen, um die beste Leistungsverbesserung zu erzielen?",
        "Options": {
            "1": "Implementieren Sie Amazon S3 mit Transfer Acceleration für schnellere Inhaltsbereitstellung.",
            "2": "Setzen Sie Amazon ElastiCache mit Redis ein, um häufig aufgerufene Kursinhalte zu cachen.",
            "3": "Verwenden Sie Amazon CloudFront, um Datenbankabfragen an Edge-Standorten zu cachen.",
            "4": "Richten Sie einen In-Memory-Cache auf jedem Anwendungsserver ein, um Kursinhalte zu speichern."
        },
        "Correct Answer": "Setzen Sie Amazon ElastiCache mit Redis ein, um häufig aufgerufene Kursinhalte zu cachen.",
        "Explanation": "Amazon ElastiCache mit Redis ist ein In-Memory-Datenspeicher, der einen schnellen Zugriff auf häufig abgerufene Daten bietet. Durch das Caching von Kursinhalten im Speicher werden die Antwortzeiten für Leseanfragen erheblich reduziert und die Last auf der Datenbank während der Hauptverkehrszeiten verringert. Redis ist besonders gut geeignet für Szenarien, in denen geringe Latenz und hohe Durchsatzraten erforderlich sind, was es zu einer idealen Wahl zur Verbesserung der Leistung auf einer Online-Bildungsplattform macht.",
        "Other Options": [
            "Die Implementierung von Amazon S3 mit Transfer Acceleration konzentriert sich hauptsächlich auf die Verbesserung der Geschwindigkeit von Datei-Uploads und -Downloads, nicht auf das Caching dynamischer Inhalte oder Datenbankabfragen. Während es die Inhaltsbereitstellung für statische Assets verbessern kann, adressiert es nicht effektiv den Bedarf an Caching häufig aufgerufener Kursinhalte.",
            "Die Verwendung von Amazon CloudFront zum Cachen von Datenbankabfragen an Edge-Standorten ist kein typischer Anwendungsfall für CloudFront, das für das Caching statischer und dynamischer Webinhalte konzipiert ist, nicht für Datenbankabfragen. Während es die Inhaltsbereitstellung für statische Assets verbessern kann, bietet es nicht das gleiche Leistungsniveau für häufig aufgerufene dynamische Inhalte wie ein In-Memory-Cache wie Redis.",
            "Das Einrichten eines In-Memory-Caches auf jedem Anwendungsserver kann zu Inkonsistenzen und erhöhter Komplexität bei der Verwaltung der Cache-Synchronisierung über mehrere Server hinweg führen. Dieser Ansatz skaliert möglicherweise auch nicht gut, wenn die Anzahl der Anwendungsserver zunimmt, was ihn im Vergleich zu einer zentralisierten Caching-Lösung wie Amazon ElastiCache weniger effizient macht."
        ]
    },
    {
        "Question Number": "9",
        "Situation": "Ein Unternehmen entwickelt eine Anwendung, die mehrere Schritte umfasst, einschließlich des Aufrufs von Lambda-Funktionen, des Wartens auf einen bestimmten Zeitraum und des Übergangs von Daten zwischen verschiedenen Aufgaben. Sie möchten sicherstellen, dass die Aufgaben in der richtigen Reihenfolge ausgeführt werden und skalierbar, zuverlässig und verwaltbar sind. Das Unternehmen zieht verschiedene AWS-Dienste in Betracht, um den Workflow dieser Aufgaben zu orchestrieren.",
        "Question": "Welchen AWS-Dienst sollte das Unternehmen für diesen Zweck verwenden?",
        "Options": {
            "1": "Verwenden Sie AWS Step Functions, um eine Zustandsmaschine zu definieren und auszuführen, die den Fluss der Aufgaben und deren Übergänge verwaltet.",
            "2": "Verwenden Sie AWS Lambda, um Aufgaben zu orchestrieren, indem Sie andere Lambda-Funktionen in der Reihenfolge aufrufen und Daten über Umgebungsvariablen übergeben.",
            "3": "Verwenden Sie Amazon SQS, um die Aufgaben zu warten und sie sequenziell mit EC2-Instanzen zu verarbeiten.",
            "4": "Verwenden Sie Amazon EC2 Auto Scaling, um die Aufgabenausführung zu verwalten und automatisch basierend auf der Anzahl der abzuschließenden Aufgaben zu skalieren."
        },
        "Correct Answer": "Verwenden Sie AWS Step Functions, um eine Zustandsmaschine zu definieren und auszuführen, die den Fluss der Aufgaben und deren Übergänge verwaltet.",
        "Explanation": "AWS Step Functions ist speziell für die Orchestrierung komplexer Workflows konzipiert, die mehrere Schritte umfassen, einschließlich des Aufrufs von AWS Lambda-Funktionen, des Wartens auf bestimmte Zeiträume und des Übergangs von Daten zwischen Aufgaben. Es ermöglicht Ihnen, eine Zustandsmaschine zu definieren, die die Reihenfolge der Aufgaben und deren Übergänge klar umreißt, um sicherzustellen, dass sie in der richtigen Reihenfolge ausgeführt werden. Step Functions bieten auch integrierte Fehlerbehandlung, Wiederholungen und die Möglichkeit, den Zustand zu verwalten, was es zu einer zuverlässigen und verwaltbaren Lösung für die Orchestrierung von Workflows macht.",
        "Other Options": [
            "Die Verwendung von AWS Lambda zur Orchestrierung von Aufgaben durch sequenzielles Aufrufen anderer Lambda-Funktionen ist nicht ideal, da Lambda hauptsächlich für die Ausführung einzelner Funktionen und nicht für die Verwaltung komplexer Workflows konzipiert ist. Während Sie Funktionen in der Reihenfolge aufrufen können, fehlen die integrierten Zustandsverwaltungs- und Fehlerbehandlungsfunktionen, die Step Functions bieten.",
            "Die Verwendung von Amazon SQS, um die Aufgaben zu warten und sie sequenziell mit EC2-Instanzen zu verarbeiten, ist nicht die beste Wahl zur Orchestrierung von Workflows. SQS ist ein Messaging-Dienst, der helfen kann, Komponenten zu entkoppeln, jedoch nicht von sich aus die Ausführungsreihenfolge oder den Zustand der Aufgaben verwaltet, was für das beschriebene Szenario entscheidend ist.",
            "Die Verwendung von Amazon EC2 Auto Scaling zur Verwaltung der Aufgabenausführung und zur automatischen Skalierung basierend auf der Anzahl der abzuschließenden Aufgaben ist nicht geeignet zur Orchestrierung von Workflows. EC2 Auto Scaling konzentriert sich auf die Skalierung von EC2-Instanzen basierend auf der Nachfrage, bietet jedoch keine Workflow-Orchestrierungsfunktionen, die für die Verwaltung der Reihenfolge und Abhängigkeiten von Aufgaben unerlässlich sind."
        ]
    },
    {
        "Question Number": "10",
        "Situation": "Ein Unternehmen möchte sicherstellen, dass seine AWS-Umgebung dem Prinzip der minimalen Berechtigung folgt, um Sicherheitsrisiken zu minimieren. Das Unternehmen hat mehrere Anwendungen, die auf AWS ausgeführt werden, und jede benötigt spezifische Berechtigungen, um auf bestimmte Ressourcen zuzugreifen.",
        "Question": "Was ist der effektivSTE Ansatz zur Umsetzung dieser Sicherheitsbestimmung?",
        "Options": {
            "1": "Weisen Sie jeder Anwendung die AdministratorAccess-Richtlinie zu, um sicherzustellen, dass sie vollständige Berechtigungen für alle Ressourcen hat.",
            "2": "Erstellen Sie benutzerdefinierte IAM-Richtlinien, die nur die Berechtigungen gewähren, die jede Anwendung benötigt, und fügen Sie sie den jeweiligen IAM-Rollen für die Anwendungen hinzu.",
            "3": "Verwenden Sie das Root-Benutzerkonto für alle Anwendungen und verfolgen Sie manuell die Berechtigungen für jede Anwendung.",
            "4": "Gewähren Sie allen IAM-Benutzern im Konto vollständige Berechtigungen und verlassen Sie sich auf die internen Kontrollen der Anwendung, um den Zugriff einzuschränken."
        },
        "Correct Answer": "Erstellen Sie benutzerdefinierte IAM-Richtlinien, die nur die Berechtigungen gewähren, die jede Anwendung benötigt, und fügen Sie sie den jeweiligen IAM-Rollen für die Anwendungen hinzu.",
        "Explanation": "Das Erstellen benutzerdefinierter IAM-Richtlinien, die nur die Berechtigungen gewähren, die jede Anwendung benötigt, ist der effektivste Weg, um das Prinzip der minimalen Berechtigung umzusetzen. Dieser Ansatz stellt sicher, dass jede Anwendung nur auf die Ressourcen zugreifen kann, die für ihren Betrieb erforderlich sind, wodurch das Risiko unbefugten Zugriffs oder versehentlicher Änderungen an anderen Ressourcen verringert wird. Durch das Anhängen dieser Richtlinien an spezifische IAM-Rollen kann das Unternehmen Berechtigungen zentral verwalten und bei Bedarf anpassen, ohne andere Anwendungen zu beeinträchtigen.",
        "Other Options": [
            "Das Zuweisen der AdministratorAccess-Richtlinie an jede Anwendung ist keine sichere Praxis, da es vollständige Berechtigungen für alle Ressourcen gewährt, was dem Prinzip der minimalen Berechtigung widerspricht und die Sicherheitsrisiken erheblich erhöht.",
            "Die Verwendung des Root-Benutzerkontos für alle Anwendungen wird dringend abgeraten, da das Root-Konto uneingeschränkten Zugriff auf alle AWS-Ressourcen hat. Diese Praxis stellt ein erhebliches Sicherheitsrisiko dar, da jede Kompromittierung des Root-Kontos die vollständige Kontrolle über die AWS-Umgebung zur Folge hätte.",
            "Das Gewähren aller IAM-Benutzer im Konto vollständiger Berechtigungen und das Verlassen auf die internen Kontrollen der Anwendung ist kein sicherer Ansatz. Es setzt die AWS-Umgebung potenziellen Missbrauchs aus, da jeder IAM-Benutzer auf jede Ressource ohne Einschränkungen zugreifen könnte, was das Prinzip der minimalen Berechtigung untergräbt."
        ]
    },
    {
        "Question Number": "11",
        "Situation": "Eine Online-Bildungsplattform benötigt eine Datenbanklösung, die sich automatisch basierend auf der Nachfrage skalieren kann. Ihr Traffic variiert stark, mit Spitzen zu bestimmten Tageszeiten. Sie wünschen sich eine kosteneffektive Lösung, die die Kapazität automatisch anpasst, ohne manuelles Eingreifen.",
        "Question": "Welche Datenbank-Kapazitätsplanungsstrategie würde diese Anforderungen am besten erfüllen?",
        "Options": {
            "1": "Bereitgestellte Kapazität mit manueller Skalierung während der Spitzenzeiten",
            "2": "Reservierte Instanzen mit einer 3-jährigen Verpflichtung",
            "3": "On-Demand-Kapazität mit aktivierter automatischer Skalierung",
            "4": "Verwendung von Lese-Replikaten zur Bewältigung von Hochlastzeiten"
        },
        "Correct Answer": "On-Demand-Kapazität mit aktivierter automatischer Skalierung",
        "Explanation": "On-Demand-Kapazität mit aktivierter automatischer Skalierung ist die beste Lösung für die Online-Bildungsplattform, da sie es der Datenbank ermöglicht, ihre Kapazität automatisch basierend auf der Echtzeitnachfrage anzupassen, ohne dass manuelles Eingreifen erforderlich ist. Dies ist besonders wichtig, um variable Traffic-Muster zu bewältigen, da es sicherstellt, dass die Plattform Spitzenlasten effizient verwalten kann und gleichzeitig kosteneffektiv in Zeiten mit geringem Traffic bleibt. Die Funktion zur automatischen Skalierung weist Ressourcen nach Bedarf dynamisch zu, was perfekt mit der Anforderung übereinstimmt, eine Lösung zu haben, die sich an schwankende Traffic-Niveaus anpassen kann.",
        "Other Options": [
            "Bereitgestellte Kapazität mit manueller Skalierung während der Spitzenzeiten erfordert manuelles Eingreifen zur Anpassung der Kapazität, was nicht den Anforderungen an eine automatische Skalierung basierend auf der Nachfrage entspricht. Dies könnte zu Leistungsproblemen während unerwarteter Traffic-Spitzen führen, wenn die Skalierung nicht rechtzeitig erfolgt.",
            "Reservierte Instanzen mit einer 3-jährigen Verpflichtung binden die Plattform an eine feste Kapazität und Kosten, was in einer Situation mit stark variierendem Traffic nicht ideal ist. Diese Strategie bietet nicht die Flexibilität, die erforderlich ist, um sich automatisch an die Nachfrage anzupassen, was möglicherweise zu Überprovisionierung und unnötigen Kosten während Zeiten mit geringem Traffic führt.",
            "Die Verwendung von Lese-Replikaten zur Bewältigung von Hochlastzeiten kann helfen, Leseanfragen zu verteilen, adressiert jedoch nicht die gesamte Kapazitätsplanung für die Datenbank. Diese Strategie könnte unzureichend sein, wenn die primäre Datenbank selbst nicht in der Lage ist, die erhöhten Schreiboperationen oder die Gesamtlast zu bewältigen, und sie erfordert auch manuelle Konfiguration und Verwaltung."
        ]
    },
    {
        "Question Number": "12",
        "Situation": "Ein Unternehmen migriert seine lokale Oracle-Datenbank zu AWS. Sie möchten die Änderungen an der Anwendung minimieren, während sie zu einem verwalteten Datenbankdienst wechseln.",
        "Question": "Welchen AWS-Datenbankdienst sollte der Lösungsarchitekt für diese heterogene Migration empfehlen?",
        "Options": {
            "1": "Amazon Aurora mit PostgreSQL-Kompatibilität",
            "2": "Amazon RDS für Oracle",
            "3": "Amazon DynamoDB",
            "4": "Amazon Redshift"
        },
        "Correct Answer": "Amazon RDS für Oracle",
        "Explanation": "Amazon RDS für Oracle ist die beste Wahl für die Migration einer lokalen Oracle-Datenbank zu AWS, während die Änderungen an der Anwendung minimiert werden. RDS für Oracle bietet einen verwalteten Datenbankdienst, der Oracle-Datenbankfunktionen unterstützt und einen reibungslosen Übergang ermöglicht, ohne dass signifikante Änderungen am Anwendungscode oder an den Datenbankabfragen erforderlich sind. Dieser Dienst übernimmt auch routinemäßige Datenbankaufgaben wie Backups, Patching und Skalierung, was helfen kann, den operativen Aufwand zu reduzieren.",
        "Other Options": [
            "Amazon Aurora mit PostgreSQL-Kompatibilität ist ein relationaler Datenbankdienst, der Kompatibilität mit PostgreSQL bietet. Es würde jedoch Änderungen an der Anwendung erfordern, um sich an den PostgreSQL-Dialekt und die Funktionen anzupassen, was es weniger geeignet für eine nahtlose Migration von Oracle macht.",
            "Amazon DynamoDB ist ein NoSQL-Datenbankdienst, der für hohe Leistung und Skalierbarkeit ausgelegt ist. Die Migration von einer Oracle-relationalen Datenbank zu einer NoSQL-Datenbank würde erhebliche Änderungen an der Anwendungsarchitektur und dem Datenmodell erfordern, was dem Ziel widerspricht, Änderungen während der Migration zu minimieren.",
            "Amazon Redshift ist ein Data-Warehousing-Dienst, der für Analysen und Berichterstattung optimiert ist. Er ist nicht für transaktionale Workloads wie die typischerweise von einer Oracle-Datenbank verarbeiteten ausgelegt. Die Migration zu Redshift würde ein komplettes Redesign der Anwendung und der Datenzugriffsmuster erfordern, was es zu einer ungeeigneten Wahl für dieses Szenario macht."
        ]
    },
    {
        "Question Number": "13",
        "Situation": "Ein Unternehmen behebt Leistungsprobleme in seiner auf Microservices basierenden Anwendung, die auf AWS bereitgestellt ist. Sie möchten tiefgehende Einblicke in die Architektur ihrer Anwendung gewinnen, um Engpässe zu identifizieren und die Reaktionszeiten zu verbessern.",
        "Question": "Welchen AWS-Dienst sollte das Unternehmen verwenden, um Anfragen durch seine Microservices zu verfolgen und zu analysieren und detaillierte Einblicke in die Anwendungsleistung zu erhalten?",
        "Options": {
            "1": "Verwenden Sie AWS X-Ray, um den Fluss von Anfragen durch die Anwendung zu verfolgen und zu analysieren, und Einblicke in Latenzen und Engpässe in Echtzeit zu erhalten.",
            "2": "Verwenden Sie Amazon CloudWatch Logs, um Anwendungsprotokolle zu überwachen und zu speichern, aber analysieren Sie die Leistungsdaten manuell mit EC2-Instanzen.",
            "3": "Verwenden Sie AWS CloudTrail, um API-Anfragen zu verfolgen, aber konfigurieren Sie zusätzliche benutzerdefinierte Protokollierung für spezifische Leistungsanalysen.",
            "4": "Verwenden Sie Amazon RDS Performance Insights, um die Datenbankleistung zu analysieren und langsame Abfragen in der Anwendung zu identifizieren."
        },
        "Correct Answer": "Verwenden Sie AWS X-Ray, um den Fluss von Anfragen durch die Anwendung zu verfolgen und zu analysieren, und Einblicke in Latenzen und Engpässe in Echtzeit zu erhalten.",
        "Explanation": "AWS X-Ray ist speziell für die Verfolgung von Anfragen in Microservices-Architekturen konzipiert. Es bietet detaillierte Einblicke in die Leistung von Anwendungen, indem es Entwicklern ermöglicht, den Fluss von Anfragen durch verschiedene Dienste zu visualisieren, Latenzen zu identifizieren und Engpässe zu lokalisieren. Diese tiefgehende Sichtbarkeit ist entscheidend für die Fehlersuche bei Leistungsproblemen und die Optimierung der Reaktionszeiten in einer Microservices-Umgebung.",
        "Other Options": [
            "Amazon CloudWatch Logs ist nützlich zur Überwachung und Speicherung von Protokollen, bietet jedoch nicht dasselbe Maß an Verfolgung und Analyse für Anfrageflüsse wie AWS X-Ray. Die manuelle Analyse mit EC2-Instanzen wäre zeitaufwendig und weniger effektiv zur Identifizierung von Leistungsengpässen.",
            "AWS CloudTrail konzentriert sich hauptsächlich auf die Verfolgung von API-Anfragen und Änderungen an AWS-Ressourcen, nicht auf die Analyse der Anwendungsleistung. Während es einige Einblicke in die API-Nutzung bieten kann, bietet es nicht die detaillierte Anfrageverfolgung, die erforderlich ist, um Leistungsprobleme in Microservices zu identifizieren.",
            "Amazon RDS Performance Insights ist auf die Analyse der Datenbankleistung und die Identifizierung langsamer Abfragen zugeschnitten, bietet jedoch keine Einblicke in die gesamte Anwendungsleistung oder den Fluss von Anfragen durch Microservices. Es ist auf die Analyse auf Datenbankebene beschränkt und adressiert nicht die breitere Anwendungsarchitektur."
        ]
    },
    {
        "Question Number": "14",
        "Situation": "Ein Unternehmen entwickelt eine ereignisgesteuerte Anwendung, bei der verschiedene Komponenten auf Echtzeitereignisse reagieren müssen, wie z.B. Kundenbestellungen und Bestandsaktualisierungen. Das System muss sicherstellen, dass die Komponenten lose gekoppelt sind, um Skalierbarkeit und Zuverlässigkeit zu verbessern. Das Unternehmen möchte auch die Fähigkeit haben, Ereignisse asynchron zu verarbeiten, sodass jeder Dienst sie unabhängig verarbeiten kann.",
        "Question": "Welchen AWS-Dienst sollte das Unternehmen verwenden, um ein Publish/Subscribe-Nachrichtenmuster zu implementieren? (Wählen Sie zwei.)",
        "Options": {
            "1": "Verwenden Sie Amazon SNS (Simple Notification Service), um Ereignisse zu veröffentlichen, und abonnieren Sie verschiedene Anwendungsbestandteile (wie AWS Lambda-Funktionen) zu den SNS-Themen zur Verarbeitung.",
            "2": "Verwenden Sie Amazon SQS (Simple Queue Service) für direkte Nachrichtenwarteschlangen zwischen Komponenten, ohne ein Publish/Subscribe-Modell zu implementieren.",
            "3": "Verwenden Sie AWS Direct Connect, um eine private Verbindung zwischen Komponenten herzustellen und die Ereignisse direkt über die dedizierte Netzwerkverbindung zu veröffentlichen.",
            "4": "Verwenden Sie Amazon EventBridge, um Ereignisbussen zu erstellen und Regeln zu definieren, um Ereignisse an mehrere Ziele weiterzuleiten, wodurch ein Publish/Subscribe-Muster ermöglicht wird.",
            "5": "Verwenden Sie Amazon S3, um Ereignisse zu speichern, und lassen Sie die Komponenten den S3-Bucket abfragen, um neue Ereignisse zu verarbeiten."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Verwenden Sie Amazon SNS (Simple Notification Service), um Ereignisse zu veröffentlichen, und abonnieren Sie verschiedene Anwendungsbestandteile (wie AWS Lambda-Funktionen) zu den SNS-Themen zur Verarbeitung.",
            "Verwenden Sie Amazon EventBridge, um Ereignisbussen zu erstellen und Regeln zu definieren, um Ereignisse an mehrere Ziele weiterzuleiten, wodurch ein Publish/Subscribe-Muster ermöglicht wird."
        ],
        "Explanation": "Amazon SNS (Simple Notification Service) ist ein Webdienst, der die Lieferung oder das Senden von Nachrichten an abonnierte Endpunkte oder Clients koordiniert und verwaltet. Er ist darauf ausgelegt, das Publish/Subscribe-Nachrichtenmuster zu unterstützen, was genau das ist, was das Unternehmen benötigt. AWS Lambda-Funktionen können zu SNS-Themen abonniert werden und die Ereignisse asynchron verarbeiten. Amazon EventBridge ist ein serverloser Ereignisbusdienst, der es einfach macht, Anwendungen miteinander zu verbinden, indem Daten aus Ihren eigenen Anwendungen, integrierten Software-as-a-Service (SaaS)-Anwendungen und AWS-Diensten verwendet werden. Er ermöglicht es Ihnen, ein Pub/Sub-Nachrichtenparadigma zu erstellen, mit Ereignisbussen und Regeln, um Ereignisse an mehrere Ziele weiterzuleiten.",
        "Other Options": [
            "Amazon SQS (Simple Queue Service) ist ein vollständig verwalteter Nachrichtenwarteschdienst, der es Ihnen ermöglicht, Microservices, verteilte Systeme und serverlose Anwendungen zu entkoppeln und zu skalieren. Es unterstützt jedoch nicht von sich aus ein Publish/Subscribe-Modell, was eine Anforderung im gegebenen Szenario ist.",
            "AWS Direct Connect ist eine Cloud-Service-Lösung, die es einfach macht, eine dedizierte Netzwerkverbindung von Ihren Räumlichkeiten zu AWS herzustellen. Es unterstützt kein Publish/Subscribe-Nachrichtenmuster und bietet nicht von sich aus eine asynchrone Ereignisverarbeitung.",
            "Amazon S3 (Simple Storage Service) ist ein Objektspeicherdienst, der branchenführende Skalierbarkeit, Datenverfügbarkeit, Sicherheit und Leistung bietet. Er ist jedoch nicht für Echtzeitereignisgesteuerte Anwendungen oder zur Implementierung eines Publish/Subscribe-Nachrichtenmusters konzipiert. Die Verwendung von S3 würde erfordern, dass Komponenten kontinuierlich nach neuen Ereignissen abfragen, was ineffizient und nicht in Echtzeit ist."
        ]
    },
    {
        "Question Number": "15",
        "Situation": "Ein Unternehmen verwendet Amazon Elastic Container Service (ECS), um eine auf Microservices basierende Anwendung in einer Produktionsumgebung bereitzustellen. Die Anwendung verarbeitet sensible Kundendaten, und das Unternehmen möchte sicherstellen, dass die Sicherheit auf allen Ebenen der Anwendung ordnungsgemäß implementiert ist.",
        "Question": "Welche der folgenden Praktiken sollten implementiert werden, um die ECS-Container zu sichern und sicherzustellen, dass die Daten geschützt sind?",
        "Options": {
            "1": "Verwenden Sie Amazon ECS mit AWS Fargate für serverlose Containerverwaltung und stellen Sie sicher, dass alle sensiblen Daten in Amazon S3 mit aktivierter Verschlüsselung gespeichert werden.",
            "2": "Verwenden Sie IAM-Rollen für ECS-Aufgaben, um die minimal erforderlichen Berechtigungen für den Zugriff auf AWS-Ressourcen zuzuweisen, und konfigurieren Sie die Sicherheitsgruppen für Containerinstanzen, um den eingehenden Verkehr einzuschränken.",
            "3": "Verlassen Sie sich ausschließlich auf die Verschlüsselung auf Aufgabenebene von Amazon ECS, um sensible Daten im Ruhezustand zu schützen, da dies eine End-to-End-Verschlüsselung für die gesamte Anwendung bietet.",
            "4": "Aktivieren Sie öffentliche IP-Adressen für ECS-Instanzen, um den Zugriff auf Container aus dem Internet sicherzustellen, und konfigurieren Sie Sicherheitsgruppen für flexiblen Datenverkehr."
        },
        "Correct Answer": "Verwenden Sie IAM-Rollen für ECS-Aufgaben, um die minimal erforderlichen Berechtigungen für den Zugriff auf AWS-Ressourcen zuzuweisen, und konfigurieren Sie die Sicherheitsgruppen für Containerinstanzen, um den eingehenden Verkehr einzuschränken.",
        "Explanation": "Die Verwendung von IAM-Rollen für ECS-Aufgaben ermöglicht es Ihnen, die minimal erforderlichen Berechtigungen zuzuweisen, die notwendig sind, damit die Container auf AWS-Ressourcen zugreifen können, was ein grundlegendes Sicherheitsprinzip ist. Dies minimiert das Risiko eines unbefugten Zugriffs auf sensible Daten. Darüber hinaus hilft die Konfiguration von Sicherheitsgruppen für Containerinstanzen, den eingehenden und ausgehenden Verkehr zu steuern, sodass nur vertrauenswürdige Quellen mit den Containern kommunizieren können, was die Sicherheit weiter erhöht.",
        "Other Options": [
            "Die Verwendung von Amazon ECS mit AWS Fargate für serverlose Containerverwaltung und die Speicherung sensibler Daten in Amazon S3 mit aktivierter Verschlüsselung ist eine gute Praxis, adressiert jedoch nicht die Notwendigkeit für angemessene Zugriffskontrollen und Netzwerksicherheit für die ECS-Container selbst. Während Verschlüsselung wichtig ist, sollte sie Teil einer umfassenderen Sicherheitsstrategie sein, die IAM-Rollen und Sicherheitsgruppen umfasst.",
            "Sich ausschließlich auf die Verschlüsselung auf Aufgabenebene von Amazon ECS zu verlassen, ist nicht ausreichend, um sensible Daten im Ruhezustand zu schützen. Während die Verschlüsselung auf Aufgabenebene helfen kann, bietet sie keine umfassende Sicherheit für die gesamte Anwendung und adressiert nicht andere kritische Aspekte wie Zugriffskontrolle und Netzwerksicherheit.",
            "Das Aktivieren öffentlicher IP-Adressen für ECS-Instanzen stellt ein erhebliches Sicherheitsrisiko dar, da die Container dem Internet ausgesetzt werden. Dies kann zu unbefugtem Zugriff und Angriffen führen. Stattdessen empfehlen die besten Sicherheitspraktiken, den Zugriff über Sicherheitsgruppen einzuschränken und wo möglich private IPs zu verwenden."
        ]
    },
    {
        "Question Number": "16",
        "Situation": "Eine Finanzhandelsplattform verarbeitet Tausende von Transaktionen pro Sekunde und benötigt einen hoch skalierbaren Warteschdienst, um ein umfangreiches Volumen an Nachrichten mit nahezu unbegrenztem Durchsatz zu bewältigen. Das Handelssystem erfordert keine Nachrichtenreihenfolge und kann gelegentliche doppelte Nachrichten tolerieren, solange garantiert wird, dass jede Nachricht mindestens einmal verarbeitet wird.",
        "Question": "Welche Amazon SQS-Konfiguration würde diese Anforderungen am besten erfüllen?",
        "Options": {
            "1": "Konfigurieren Sie eine Amazon SQS FIFO-Warteschlange, um eine genau einmalige Verarbeitung und die Beibehaltung der Nachrichtenreihenfolge zu gewährleisten.",
            "2": "Verwenden Sie eine Amazon SQS Standard-Warteschlange mit mindestens einmaliger Zustellung, die hohen Durchsatz und gelegentliche Duplikate zulässt.",
            "3": "Richten Sie ein Amazon SNS-Thema mit FIFO-Nachrichtenlieferung ein, um hohen Durchsatz und geringe Latenz zu gewährleisten.",
            "4": "Setzen Sie Amazon Kinesis Data Streams ein, um eine geordnete Nachrichtenverarbeitung und mindestens einmalige Zustellung für die Echtzeit-Transaktionsverarbeitung bereitzustellen."
        },
        "Correct Answer": "Verwenden Sie eine Amazon SQS Standard-Warteschlange mit mindestens einmaliger Zustellung, die hohen Durchsatz und gelegentliche Duplikate zulässt.",
        "Explanation": "Eine Amazon SQS Standard-Warteschlange ist für hohen Durchsatz ausgelegt und kann ein umfangreiches Volumen an Nachrichten mit nahezu unbegrenzter Skalierbarkeit bewältigen. Sie bietet eine mindestens einmalige Zustellung, was bedeutet, dass Nachrichten möglicherweise mehr als einmal zugestellt werden, aber garantiert, dass jede Nachricht mindestens einmal verarbeitet wird. Dies passt perfekt zu den Anforderungen des Handelssystems, das keine Nachrichtenreihenfolge benötigt und gelegentliche Duplikate tolerieren kann.",
        "Other Options": [
            "Die Konfiguration einer Amazon SQS FIFO-Warteschlange wäre nicht geeignet, da FIFO-Warteschlangen für Szenarien konzipiert sind, in denen die Nachrichtenreihenfolge entscheidend ist, und sie eine genau einmalige Verarbeitung garantieren. Dies geht mit einem geringeren Durchsatz im Vergleich zu Standard-Warteschlangen einher, was für eine Handelsplattform mit hohem Volumen nicht ideal ist.",
            "Die Einrichtung eines Amazon SNS-Themas mit FIFO-Nachrichtenlieferung ist nicht angemessen, da SNS hauptsächlich für Pub/Sub-Nachrichten verwendet wird und nicht für das Warten von Nachrichten in der gleichen Weise wie SQS konzipiert ist. Darüber hinaus sind FIFO-Themen im Vergleich zu Standard-Warteschlangen auch in ihrem Durchsatz begrenzt.",
            "Der Einsatz von Amazon Kinesis Data Streams würde eine geordnete Nachrichtenverarbeitung und mindestens einmalige Zustellung bieten, ist jedoch komplexer und wird typischerweise für Echtzeitanalysen verwendet, anstatt einfache Wartungsbedürfnisse zu erfüllen. Die Anforderungen des Handelssystems erfordern nicht die zusätzliche Komplexität von Kinesis, wenn eine Standard-Warteschlange ausreicht."
        ]
    },
    {
        "Question Number": "17",
        "Situation": "Eine Organisation verwendet Amazon S3 zur Speicherung vertraulicher Daten und benötigt eine serverseitige Verschlüsselungsmethode, die es dem AWS Key Management Service (KMS) ermöglicht, die Schlüssel zu verwalten. Darüber hinaus wünschen sie sich Funktionen wie Schlüsselrotationskontrolle und Rollentrennung.",
        "Question": "Welche S3-Verschlüsselungsoption erfüllt diese Anforderungen am besten?",
        "Options": {
            "1": "Client-Seitige Verschlüsselung",
            "2": "Server-Seitige Verschlüsselung mit S3-Verwalteten Schlüsseln (SSE-S3)",
            "3": "Server-Seitige Verschlüsselung mit vom Kunden bereitgestellten Schlüsseln (SSE-C)",
            "4": "Server-Seitige Verschlüsselung mit AWS KMS-Verwalteten Schlüsseln (SSE-KMS)"
        },
        "Correct Answer": "Server-Seitige Verschlüsselung mit AWS KMS-Verwalteten Schlüsseln (SSE-KMS)",
        "Explanation": "SSE-KMS ist die beste Option für dieses Szenario, da es dem AWS Key Management Service (KMS) ermöglicht, die Verschlüsselungsschlüssel zu verwalten. Diese Methode bietet verbesserte Sicherheitsfunktionen wie Schlüsselrotationskontrolle, die es der Organisation ermöglicht, Schlüssel automatisch nach einem Zeitplan zu rotieren, und Rollentrennung, die sicherstellt, dass verschiedenen Rollen Berechtigungen für die Nutzung und Verwaltung von Schlüsseln zugewiesen werden können. Dies passt perfekt zu den Anforderungen der Organisation, vertrauliche Daten sicher zu verwalten.",
        "Other Options": [
            "Client-Seitige Verschlüsselung erfordert, dass der Client die Verschlüsselungsschlüssel verwaltet, was AWS KMS für das Schlüsselmanagement nicht nutzt und die Funktionen der Schlüsselrotation und Rollentrennung, die die Organisation benötigt, nicht bietet.",
            "Server-Seitige Verschlüsselung mit S3-Verwalteten Schlüsseln (SSE-S3) verwendet Amazon S3 zur Verwaltung der Verschlüsselungsschlüssel, bietet jedoch nicht dasselbe Maß an Kontrolle über das Schlüsselmanagement, wie es SSE-KMS bietet, wie z.B. Schlüsselrotation und Rollentrennung.",
            "Server-Seitige Verschlüsselung mit vom Kunden bereitgestellten Schlüsseln (SSE-C) ermöglicht es Kunden, ihre eigenen Verschlüsselungsschlüssel zu verwalten, was bedeutet, dass die Organisation das Schlüsselmanagement und die Rotation selbst übernehmen müsste, wiederum ohne AWS KMS zu nutzen und ohne die gewünschten Funktionen."
        ]
    },
    {
        "Question Number": "18",
        "Situation": "Ein Startup entwickelt ein mobiles Backend, das die Verarbeitung von Benutzer-Uploads, Bildtransformationen und die Speicherung der Ergebnisse erfordert. Das Team möchte den operativen Aufwand minimieren und sicherstellen, dass das Backend nahtlos mit der Benutzeranforderung skalieren kann.",
        "Question": "Welchen serverlosen AWS-Dienst sollte der Lösungsarchitekt verwenden, um die Bildverarbeitungsaufgaben zu übernehmen? (Wählen Sie zwei.)",
        "Options": {
            "1": "AWS Fargate",
            "2": "Amazon EC2",
            "3": "AWS Lambda",
            "4": "Amazon ECS",
            "5": "Amazon S3-Ereignisbenachrichtigungen"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "AWS Lambda",
            "Amazon S3-Ereignisbenachrichtigungen"
        ],
        "Explanation": "AWS Lambda ist ein serverloser Compute-Dienst, der es Ihnen ermöglicht, Ihren Code auszuführen, ohne Server bereitzustellen oder zu verwalten. Es skaliert Ihre Anwendung automatisch mit hoher Verfügbarkeit, und Sie zahlen nur für die Compute-Zeit, die Sie verbrauchen. Dies macht es zur perfekten Wahl für die Verarbeitung von Bildverarbeitungsaufgaben auf skalierbare und kosteneffektive Weise. Amazon S3-Ereignisbenachrichtigungen können in Verbindung mit AWS Lambda verwendet werden, um die Bildverarbeitungsaufgaben auszulösen, wann immer ein neues Bild in einen S3-Bucket hochgeladen wird. Dies ermöglicht es dem System, sofort auf Benutzer-Uploads zu reagieren und den operativen Aufwand weiter zu reduzieren.",
        "Other Options": [
            "AWS Fargate ist eine serverlose Compute-Engine für Container. Obwohl es verwendet werden kann, um Bildverarbeitungsaufgaben auszuführen, ist es für diesen speziellen Anwendungsfall nicht so einfach oder kosteneffektiv wie AWS Lambda. Es bietet auch nicht die sofortige Reaktion auf Benutzer-Uploads, die mit S3-Ereignisbenachrichtigungen erreicht werden kann.",
            "Amazon EC2 ist ein Webdienst, der anpassbare Compute-Kapazitäten in der Cloud bereitstellt. Es ist nicht serverlos, was bedeutet, dass manuelle Skalierung und Serververwaltung erforderlich sind, was dem Wunsch des Teams widerspricht, den operativen Aufwand zu minimieren.",
            "Amazon ECS (Elastic Container Service) ist ein hoch skalierbarer, leistungsstarker Container-Orchestrierungsdienst. Obwohl es für Bildverarbeitungsaufgaben verwendet werden könnte, ist es nicht serverlos und erfordert mehr operativen Aufwand als AWS Lambda. Es bietet auch nicht die sofortige Reaktion auf Benutzer-Uploads, die mit S3-Ereignisbenachrichtigungen erreicht werden kann."
        ]
    },
    {
        "Question Number": "19",
        "Situation": "Ein Unternehmen richtet den Zugriffskontrolle für seine AWS-Umgebung ein und möchte sicherstellen, dass jedes Teammitglied das angemessene Maß an Zugriff auf AWS-Dienste hat. Das Unternehmen hat mehrere Abteilungen, wie Entwicklung, Finanzen und Personalwesen, die jeweils unterschiedliche Berechtigungsstufen benötigen.",
        "Question": "Welche IAM-Struktur wäre der effektivste und verwaltbarste Weg, um Berechtigungen an Benutzer in diesen Abteilungen zuzuweisen?",
        "Options": {
            "1": "Erstellen Sie individuelle IAM-Benutzer für jedes Teammitglied und fügen Sie jeder Benutzerin direkt Richtlinien hinzu.",
            "2": "Erstellen Sie IAM-Gruppen für jede Abteilung, weisen Sie Benutzer der entsprechenden Gruppe zu und fügen Sie jeder Gruppe abteilungsspezifische Richtlinien hinzu.",
            "3": "Verwenden Sie eine einzelne IAM-Rolle mit vollständigen Berechtigungen und lassen Sie alle Benutzer diese Rolle nach Bedarf übernehmen.",
            "4": "Erstellen Sie separate AWS-Konten für jede Abteilung und verwalten Sie den Zugriff auf Kontoebene."
        },
        "Correct Answer": "Erstellen Sie IAM-Gruppen für jede Abteilung, weisen Sie Benutzer der entsprechenden Gruppe zu und fügen Sie jeder Gruppe abteilungsspezifische Richtlinien hinzu.",
        "Explanation": "Die Erstellung von IAM-Gruppen für jede Abteilung ist der effektivste und verwaltbarste Weg, um Berechtigungen zuzuweisen, da sie eine zentrale Verwaltung der Berechtigungen ermöglicht. Durch das Hinzufügen von Richtlinien zu Gruppen anstelle von einzelnen Benutzern kann das Unternehmen den Zugriff einfach verwalten, wenn Teammitglieder der Organisation beitreten oder sie verlassen oder die Rollen wechseln. Dieser Ansatz reduziert den administrativen Aufwand für die Verwaltung von Berechtigungen und stellt sicher, dass alle Benutzer in einer Abteilung konsistente Zugriffsrechte haben, die mit ihren Aufgaben übereinstimmen.",
        "Other Options": [
            "Die Erstellung individueller IAM-Benutzer für jedes Teammitglied und das direkte Hinzufügen von Richtlinien zu jedem Benutzer kann zu einer komplexen und unübersichtlichen Situation führen, wenn die Anzahl der Benutzer wächst. Es wird schwierig, konsistente Berechtigungen über Benutzer hinweg aufrechtzuerhalten, und Änderungen an den Zugriffsrechten müssten individuell für jeden Benutzer vorgenommen werden.",
            "Die Verwendung einer einzigen IAM-Rolle mit vollständigen Berechtigungen für alle Benutzer ist keine sichere Praxis. Sie verstößt gegen das Prinzip der minimalen Berechtigung, da sie allen Benutzern Zugriff auf alle Ressourcen gewährt, was das Risiko von versehentlichen oder böswilligen Aktionen erhöht, die die AWS-Umgebung gefährden könnten.",
            "Die Erstellung separater AWS-Konten für jede Abteilung kompliziert die Verwaltung und kann zu höheren Kosten und administrativem Aufwand führen. Es erschwert auch das Teilen von Ressourcen zwischen Abteilungen und erfordert komplexere Abrechnungs- und Zugriffsmanagementstrategien."
        ]
    },
    {
        "Question Number": "20",
        "Situation": "Ein Unternehmen verwendet eine Auto Scaling-Gruppe (ASG), um EC2-Instanzen basierend auf schwankender Nachfrage zu verwalten. Sie möchten die Instanzkapazität automatisch anpassen, um eine aggregierte CPU-Auslastung von 40 % aufrechtzuerhalten.",
        "Question": "Welche Art von Skalierungsrichtlinie sollten sie implementieren und warum?",
        "Options": {
            "1": "Manuelle Skalierung, da sie eine direkte Kontrolle über die gewünschte Kapazität basierend auf der Echtzeitüberwachung ermöglicht.",
            "2": "Geplante Skalierung, die die Kapazität zu bestimmten Zeiten entsprechend vorhergesagten Nachfragemustern anpasst.",
            "3": "Dynamische Skalierung mit Zielverfolgung, da sie die Kapazität automatisch anpasst, um das angegebene CPU-Ziel aufrechtzuerhalten.",
            "4": "Einfache Skalierung, die eine Erhöhung oder Verringerung der Kapazität basierend auf einzelnen CPU-Schwellenbedingungen ermöglicht."
        },
        "Correct Answer": "Dynamische Skalierung mit Zielverfolgung",
        "Explanation": "Dynamische Skalierung mit Zielverfolgung ist die am besten geeignete Option für dieses Szenario, da sie automatisch die Anzahl der EC2-Instanzen in der Auto Scaling-Gruppe anpasst, um ein festgelegtes Ziel für die CPU-Auslastung aufrechtzuerhalten – in diesem Fall 40 %. Diese Art von Skalierungsrichtlinie überwacht kontinuierlich die CPU-Auslastung und nimmt bei Bedarf Anpassungen vor, sodass die Anwendung auf schwankende Nachfrage reagieren kann, ohne dass manuelles Eingreifen erforderlich ist.",
        "Other Options": [
            "Manuelle Skalierung erfordert menschliches Eingreifen, um die gewünschte Kapazität anzupassen, was nicht effizient ist, um ein bestimmtes CPU-Auslastungsziel aufrechtzuerhalten, insbesondere in einer dynamischen Umgebung.",
            "Geplante Skalierung ist nützlich für vorhersehbare Arbeitslasten, bei denen die Nachfrage zu bestimmten Zeiten vorhergesagt werden kann, reagiert jedoch nicht auf Echtzeitänderungen der CPU-Auslastung, was sie weniger effektiv macht, um ein Zielauslastungsniveau aufrechtzuerhalten.",
            "Einfache Skalierung reagiert auf spezifische Schwellenwerte, bietet jedoch nicht die kontinuierliche Anpassung, die erforderlich ist, um ein durchschnittliches CPU-Auslastungsziel wie 40 % aufrechtzuerhalten. Es kann zu Überprovisionierung oder Unterprovisionierung führen, wenn die Nachfrage häufig schwankt."
        ]
    },
    {
        "Question Number": "21",
        "Situation": "Ein Unternehmen möchte seinen Amazon S3-Bucket sichern und den Zugriff nur über seine CloudFront-Distribution einschränken. Sie entscheiden sich, eine Origin Access Identity (OAI) zu verwenden, um dies zu erreichen.",
        "Question": "Was ist die Hauptfunktion von OAI in dieser Konfiguration?",
        "Options": {
            "1": "OAI fungiert als Benutzer, der zu IAM-Richtlinien hinzugefügt werden kann, um den Zugriff auf S3-Buckets einzuschränken.",
            "2": "OAI wird zu einer Identität, die mit CloudFront verbunden ist, und ermöglicht nur Anfragen von CloudFront, auf den S3-Bucket zuzugreifen, wobei der gesamte direkte Zugriff standardmäßig blockiert ist.",
            "3": "OAI ermöglicht den direkten Zugriff auf den S3-Bucket von jedem Standort aus und umgeht die CloudFront-Einschränkungen.",
            "4": "OAI wird verwendet, um öffentlichen Zugriff auf den S3-Bucket über einen benutzerdefinierten Header bereitzustellen."
        },
        "Correct Answer": "OAI wird zu einer Identität, die mit CloudFront verbunden ist, und ermöglicht nur Anfragen von CloudFront, auf den S3-Bucket zuzugreifen, wobei der gesamte direkte Zugriff standardmäßig blockiert ist.",
        "Explanation": "Die Origin Access Identity (OAI) ist eine spezielle CloudFront-Funktion, die es Ihnen ermöglicht, den Zugriff auf Ihren Amazon S3-Bucket so einzuschränken, dass nur CloudFront darauf zugreifen kann. Durch die Zuordnung einer OAI zu Ihrer CloudFront-Distribution stellen Sie sicher, dass Anfragen an den S3-Bucket nur von CloudFront kommen können, wodurch der gesamte direkte Zugriff auf den S3-Bucket aus dem Internet effektiv blockiert wird. Dies erhöht die Sicherheit, indem unbefugter Zugriff auf den S3-Inhalt verhindert wird, während Benutzer weiterhin über CloudFront darauf zugreifen können.",
        "Other Options": [
            "OAI fungiert nicht als Benutzer, der zu IAM-Richtlinien hinzugefügt werden kann. Stattdessen ist es eine CloudFront-Funktion, die eine Möglichkeit bietet, den Zugriff auf S3-Buckets speziell für CloudFront einzuschränken.",
            "Diese Option ist tatsächlich die richtige Antwort, da sie die Funktion von OAI in diesem Kontext genau beschreibt.",
            "OAI ermöglicht keinen direkten Zugriff auf den S3-Bucket von jedem Standort aus. Tatsächlich tut es das Gegenteil, indem es sicherstellt, dass nur CloudFront auf den S3-Bucket zugreifen kann und alle anderen direkten Zugriffe blockiert."
        ]
    },
    {
        "Question Number": "22",
        "Situation": "Ein Technologieunternehmen hostet eine kritische Anwendung auf Amazon EC2-Instanzen. Um die Sicherheit zu erhöhen, müssen sie den Zugriff auf die Instanzen kontrollieren und den Datenschutz auf mehreren Ebenen, einschließlich Netzwerk- und Anwendungsschichten, sicherstellen. Sie sind auch besorgt über unbefugten Zugriff und möchten daher sichere Zugriffspolitiken durchsetzen und potenzielle Bedrohungen überwachen.",
        "Question": "Welche der folgenden Best Practices sollten sie implementieren, um die Sicherheit ihrer EC2-Umgebung zu gewährleisten? (Wählen Sie zwei aus.)",
        "Options": {
            "1": "Sicherheitsgruppen an die EC2-Instanzen anhängen, um den eingehenden und ausgehenden Datenverkehr einzuschränken, IAM-Rollen zur Verwaltung von Berechtigungen verwenden und CloudTrail-Protokollierung aktivieren, um Zugriff und Aktivitäten zu überwachen.",
            "2": "Alle EC2-Instanzen in einem öffentlichen Subnetz mit uneingeschränktem Zugriff bereitstellen, um die Fernverwaltung und den Zugriff für Benutzer zu erleichtern.",
            "3": "AWS Shield auf den EC2-Instanzen aktivieren, um alle Sicherheitsanforderungen zu erfüllen und unbefugten Zugriff zu verhindern, indem der gesamte eingehende Datenverkehr blockiert wird.",
            "4": "EC2-Schlüsselpaare verwenden, um den Zugriff für alle Benutzer zu verwalten, und Schlüssel direkt auf den Instanzen speichern, um schnelle Anmeldungen zu erleichtern.",
            "5": "Netzwerk-ACLs zusätzlich zu Sicherheitsgruppen für eine mehrschichtige Netzwerksicherheit implementieren und Amazon GuardDuty zur Bedrohungserkennung aktivieren."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Sicherheitsgruppen an die EC2-Instanzen anhängen, um den eingehenden und ausgehenden Datenverkehr einzuschränken, IAM-Rollen zur Verwaltung von Berechtigungen verwenden und CloudTrail-Protokollierung aktivieren, um Zugriff und Aktivitäten zu überwachen.",
            "Netzwerk-ACLs zusätzlich zu Sicherheitsgruppen für eine mehrschichtige Netzwerksicherheit implementieren und Amazon GuardDuty zur Bedrohungserkennung aktivieren."
        ],
        "Explanation": "Sicherheitsgruppen fungieren als virtuelle Firewall für EC2-Instanzen, um den eingehenden und ausgehenden Datenverkehr zu kontrollieren. IAM-Rollen bieten sicheren, kontrollierten Zugriff auf AWS-Dienste und -Ressourcen. Die CloudTrail-Protokollierung hilft bei der Überwachung und Protokollierung von Kontoaktivitäten im Zusammenhang mit Aktionen in der AWS-Infrastruktur. Netzwerk-ACLs bieten eine zusätzliche Sicherheitsebene, die es Ihnen ermöglicht, den Datenverkehr in und aus einem oder mehreren Subnetzen zu steuern. Amazon GuardDuty ist ein Bedrohungserkennungsdienst, der kontinuierlich nach bösartigem oder unbefugtem Verhalten überwacht.",
        "Other Options": [
            "Die Bereitstellung aller EC2-Instanzen in einem öffentlichen Subnetz mit uneingeschränktem Zugriff ist keine Best Practice für die Sicherheit. Sie setzt die Instanzen potenziellen Bedrohungen aus dem Internet aus und bietet keine Kontrolle darüber, wer auf die Instanzen zugreifen kann.",
            "Während AWS Shield DDoS-Schutz bietet, erfüllt es nicht alle Sicherheitsanforderungen für EC2-Instanzen. Es blockiert nicht den gesamten eingehenden Datenverkehr, was unerwünscht ist, da es den legitimen Zugriff auf die Instanzen verhindern würde.",
            "Die Verwendung von EC2-Schlüsselpaaren zur Verwaltung des Zugriffs ist eine gute Praxis, aber das Speichern von Schlüsseln direkt auf den Instanzen ist es nicht. Wenn eine Instanz kompromittiert wird, könnten die Schlüssel zugänglich sein, was zu weiterem unbefugtem Zugriff führen könnte."
        ]
    },
    {
        "Question Number": "23",
        "Situation": "Eine globale Nachrichtenorganisation muss ihre Content-Delivery-Anwendung in mehreren geografischen Regionen bereitstellen, um die Latenz zu reduzieren und die Benutzererfahrung für Zuschauer weltweit zu verbessern. Die Anwendung erfordert die Synchronisierung von Inhaltsaktualisierungen in Echtzeit über alle Regionen.",
        "Question": "Welchen AWS-Dienst sollte der Lösungsarchitekt empfehlen, um diese Anforderungen an verteiltes Rechnen zu erfüllen?",
        "Options": {
            "1": "Amazon CloudFront",
            "2": "AWS Global Accelerator",
            "3": "Amazon Route 53",
            "4": "Amazon ElastiCache"
        },
        "Correct Answer": "Amazon CloudFront",
        "Explanation": "Amazon CloudFront ist ein Content-Delivery-Netzwerk (CDN), das Inhalte an Edge-Standorten auf der ganzen Welt zwischenspeichert, was dazu beiträgt, die Latenz für Benutzer zu reduzieren, die auf die Anwendung aus verschiedenen geografischen Regionen zugreifen. Es unterstützt auch Echtzeit-Inhaltsaktualisierungen, die eine Synchronisierung über alle Regionen ermöglichen, was es ideal für eine globale Nachrichtenorganisation macht, die zeitnahe Updates an ihre Zuschauer liefern muss.",
        "Other Options": [
            "AWS Global Accelerator verbessert die Verfügbarkeit und Leistung von Anwendungen, indem es den Datenverkehr zu optimalen Endpunkten leitet, bietet jedoch keine Content-Delivery- oder Caching-Funktionen wie CloudFront.",
            "Amazon Route 53 ist ein skalierbarer Domain Name System (DNS)-Webdienst, der die Domainregistrierung und -weiterleitung bereitstellt, jedoch keine Content-Delivery oder Synchronisierung von Inhaltsaktualisierungen behandelt.",
            "Amazon ElastiCache ist ein Dienst, der In-Memory-Caching zur Verbesserung der Anwendungsleistung bereitstellt, jedoch nicht für die Content-Delivery über geografische Regionen ausgelegt ist und keine Echtzeitsynchronisierung von Inhaltsaktualisierungen unterstützt."
        ]
    },
    {
        "Question Number": "24",
        "Situation": "Ein internationales Finanzunternehmen muss eine hohe Verfügbarkeit für seine Kernanwendung sicherstellen, die auch während regionaler Ausfälle betriebsbereit bleiben muss. Sie möchten eine Failover-Strategie implementieren, die die Ausfallzeiten minimiert und den Datenverkehr automatisch an eine Standby-Umgebung in einer anderen Region umleitet, falls die primäre Region ausfällt.",
        "Question": "Welche AWS-Failover-Strategie wäre unter Berücksichtigung ihrer Anforderungen am besten geeignet und warum?",
        "Options": {
            "1": "Pilot Light, da es eine minimale Version der Anwendung in einer anderen Region aufrechterhält, die ein schnelles Hochfahren während Failover-Ereignissen ermöglicht.",
            "2": "Warm Standby, da es eine verkleinerte Version der Anwendung in einer anderen Region ausführt, die ein schnelleres Failover mit minimaler Einrichtungszeit ermöglicht.",
            "3": "Active-Active Failover, bei dem beide Regionen die volle Anwendungslast ausführen, was eine sofortige Umleitung des Datenverkehrs zur sekundären Region im Falle eines Ausfalls ermöglicht.",
            "4": "Backup and Restore, da es das Wiederherstellen von Backups aus einer anderen Region umfasst und eine kostengünstige Lösung für nicht kritische Anwendungen bietet."
        },
        "Correct Answer": "Active-Active Failover, bei dem beide Regionen die volle Anwendungslast ausführen, was eine sofortige Umleitung des Datenverkehrs zur sekundären Region im Falle eines Ausfalls ermöglicht.",
        "Explanation": "Die Active-Active Failover-Strategie ist für das internationale Finanzunternehmen am besten geeignet, da sie es beiden Regionen ermöglicht, die volle Anwendungslast gleichzeitig auszuführen. Das bedeutet, dass, wenn eine Region einen Ausfall erleidet, der Datenverkehr sofort zur anderen Region umgeleitet werden kann, ohne dass Ausfallzeiten entstehen. Dieser Ansatz gewährleistet eine hohe Verfügbarkeit und erfüllt die Anforderungen des Unternehmens an minimale Ausfallzeiten während regionaler Ausfälle, was ihn zur effektivsten Lösung für ihre Kernanwendung macht.",
        "Other Options": [
            "Pilot Light ist nicht geeignet, da es nur eine minimale Version der Anwendung in einer anderen Region aufrechterhält, die während eines Failover-Ereignisses Zeit benötigt, um hochgefahren zu werden, was zu potenziellen Ausfallzeiten führen kann.",
            "Warm Standby, obwohl besser als Pilot Light, führt immer noch eine verkleinerte Version der Anwendung aus. Obwohl es ein schnelleres Failover als Pilot Light ermöglicht, bietet es möglicherweise nicht die sofortige Umleitung des Datenverkehrs, die für eine hohe Verfügbarkeit erforderlich ist, da es einige Einrichtungszeit benötigt, um auf volle Kapazität hochzufahren.",
            "Backup and Restore ist in diesem Szenario nicht geeignet, da es das Wiederherstellen von Backups umfasst, was erhebliche Zeit in Anspruch nehmen kann und nicht für hohe Verfügbarkeit ausgelegt ist. Diese Strategie eignet sich besser für nicht kritische Anwendungen, bei denen Ausfallzeiten toleriert werden können."
        ]
    },
    {
        "Question Number": "25",
        "Situation": "Ein Unternehmen speichert sensible Kundendaten in einer Amazon RDS MySQL-Datenbank. Um den Sicherheits- und regulatorischen Anforderungen gerecht zu werden, müssen sie sicherstellen, dass die Daten im Ruhezustand verschlüsselt sind, mit strenger Kontrolle darüber, wer auf die Verschlüsselungsschlüssel zugreifen kann. Darüber hinaus müssen sie sicherstellen, dass auch Backups und Snapshots der Datenbank verschlüsselt sind.",
        "Question": "Welche Lösung würde diese Anforderungen am besten erfüllen? (Wählen Sie zwei aus.)",
        "Options": {
            "1": "Aktivieren Sie die RDS-Verschlüsselung im Ruhezustand mit dem AWS Key Management Service (KMS) und einem vom Kunden verwalteten CMK, um sicherzustellen, dass nur bestimmte IAM-Rollen Berechtigungen zum Zugriff auf den Schlüssel haben.",
            "2": "Verwenden Sie die integrierte MySQL-Verschlüsselungsfunktion, um Daten im Ruhezustand zu verschlüsseln, und konfigurieren Sie RDS, um die Verschlüsselung bei automatisierten Backups und Snapshots zu aktivieren.",
            "3": "Aktivieren Sie die Transparent Data Encryption (TDE) in MySQL und verwalten Sie die Verschlüsselungsschlüssel mit AWS CloudHSM, um sicherzustellen, dass die Verschlüsselungsschlüssel nicht von AWS zugänglich sind.",
            "4": "Speichern Sie Daten im Klartext in der RDS-Datenbank, aktivieren Sie jedoch SSL/TLS für den sicheren Zugriff und verlassen Sie sich auf die Netzwerksicherheit, um Daten im Ruhezustand zu schützen.",
            "5": "Konfigurieren Sie RDS, um die Verschlüsselung im Transit mit SSL/TLS zu verwenden, und verschlüsseln Sie Backups manuell, bevor Sie sie in Amazon S3 speichern."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Aktivieren Sie die RDS-Verschlüsselung im Ruhezustand mit dem AWS Key Management Service (KMS) und einem vom Kunden verwalteten CMK, um sicherzustellen, dass nur bestimmte IAM-Rollen Berechtigungen zum Zugriff auf den Schlüssel haben.",
            "Aktivieren Sie die Transparent Data Encryption (TDE) in MySQL und verwalten Sie die Verschlüsselungsschlüssel mit AWS CloudHSM, um sicherzustellen, dass die Verschlüsselungsschlüssel nicht von AWS zugänglich sind."
        ],
        "Explanation": "Der AWS Key Management Service (KMS) ermöglicht die Verschlüsselung im Ruhezustand und gibt dem Kunden die Kontrolle darüber, wer auf die Verschlüsselungsschlüssel zugreifen kann, indem Berechtigungen bestimmten IAM-Rollen zugewiesen werden. Dies erfüllt die Anforderung einer strengen Kontrolle über den Zugriff auf die Verschlüsselungsschlüssel. Option 3 ist korrekt, da die Transparent Data Encryption (TDE) in MySQL die Verschlüsselung im Ruhezustand bereitstellt und AWS CloudHSM die Verwaltung der Verschlüsselungsschlüssel in einer Weise ermöglicht, dass sie nicht von AWS zugänglich sind, was die Anforderung einer strengen Kontrolle über den Zugriff auf die Verschlüsselungsschlüssel erfüllt.",
        "Other Options": [
            "Obwohl die integrierte Verschlüsselungsfunktion von MySQL Daten im Ruhezustand verschlüsseln kann, bietet sie nicht das Maß an Kontrolle über den Zugriff auf die Verschlüsselungsschlüssel, das in diesem Szenario erforderlich ist.",
            "Das Speichern von Daten im Klartext in der RDS-Datenbank bietet keine Verschlüsselung im Ruhezustand, was eine Anforderung in diesem Szenario ist. Während SSL/TLS sicheren Zugriff bietet, schützt es nicht die Daten im Ruhezustand.",
            "Obwohl es die Verschlüsselung im Transit mit SSL/TLS bietet und die manuelle Verschlüsselung von Backups ermöglicht, bietet es keine Verschlüsselung im Ruhezustand für die Daten in der RDS-Datenbank, was eine Anforderung in diesem Szenario ist."
        ]
    },
    {
        "Question Number": "26",
        "Situation": "Eine Regierungsbehörde muss sensible Daten aus mehreren Niederlassungen in einen Amazon S3-Datenlake aufnehmen. Die Datenaufnahmepunkte müssen gesichert werden, um unbefugten Zugriff zu verhindern und die Datenintegrität während des Transfers zu gewährleisten.",
        "Question": "Welche Lösung sollte der Lösungsarchitekt implementieren, um den Zugriff auf die Datenaufnahmepunkte zu sichern?",
        "Options": {
            "1": "Verwenden Sie Amazon S3 vorab signierte URLs für jede Niederlassung, um Daten direkt in S3 hochzuladen.",
            "2": "Richten Sie eine VPN-Verbindung zwischen jeder Niederlassung und dem AWS VPC ein und beschränken Sie den S3-Zugriff auf die VPC-Endpunkte.",
            "3": "Implementieren Sie IAM-Benutzer mit S3-Zugriffsschlüsseln für jede Niederlassung.",
            "4": "Aktivieren Sie den öffentlichen Zugriff auf den S3-Bucket und verwenden Sie die Verschlüsselung auf Objektebene."
        },
        "Correct Answer": "Richten Sie eine VPN-Verbindung zwischen jeder Niederlassung und dem AWS VPC ein und beschränken Sie den S3-Zugriff auf die VPC-Endpunkte.",
        "Explanation": "Die Einrichtung einer VPN-Verbindung zwischen jeder Niederlassung und dem AWS VPC stellt sicher, dass alle Datenübertragungen über einen sicheren, verschlüsselten Kanal erfolgen. Dies schützt sensible Daten vor unbefugtem Zugriff während der Übertragung. Durch die Beschränkung des S3-Zugriffs auf VPC-Endpunkte erhöhen Sie die Sicherheit weiter, indem Sie sicherstellen, dass nur Datenverkehr, der aus dem VPC stammt, auf den S3-Bucket zugreifen kann, wodurch er effektiv vom öffentlichen Internet isoliert wird und das Risiko einer Exposition gegenüber potenziellen Bedrohungen verringert wird.",
        "Other Options": [
            "Die Verwendung von Amazon S3 vorab signierten URLs ermöglicht temporären Zugriff zum Hochladen von Daten direkt in S3, bietet jedoch keinen sicheren Kanal für die Datenübertragung. Wenn die vorab signierte URL abgefangen wird, könnten unbefugte Benutzer Zugriff auf den S3-Bucket erhalten, was die Datensicherheit gefährdet.",
            "Die Implementierung von IAM-Benutzern mit S3-Zugriffsschlüsseln für jede Niederlassung kann Zugriffskontrolle bieten, sichert jedoch nicht die Datenübertragung selbst. Wenn die Zugriffsschlüssel kompromittiert werden, könnten unbefugte Benutzer auf den S3-Bucket zugreifen. Darüber hinaus verschlüsselt diese Methode die Daten während der Übertragung nicht, wodurch sie anfällig für Abfangen bleibt.",
            "Der öffentliche Zugriff auf den S3-Bucket und die Verwendung der Verschlüsselung auf Objektebene sind äußerst unsicher. Öffentlicher Zugriff bedeutet, dass jeder im Internet potenziell auf die Daten zugreifen kann, was dem Erfordernis widerspricht, unbefugten Zugriff zu verhindern. Die Verschlüsselung auf Objektebene schützt die Daten im Ruhezustand, sichert jedoch nicht die Daten während der Übertragung, wodurch sie anfällig für Abfangen bleibt."
        ]
    },
    {
        "Question Number": "27",
        "Situation": "Ein Medienstreaming-Unternehmen möchte die Leistung seiner Anwendung verbessern, die Video-Inhalte weltweit an Benutzer liefert. Das Unternehmen muss die Latenz minimieren und die Last auf den Backend-Servern reduzieren.",
        "Question": "Welche Caching-Strategie sollte das Unternehmen verwenden, um eine schnelle Inhaltslieferung sicherzustellen und eine hohe Verfügbarkeit aufrechtzuerhalten?",
        "Options": {
            "1": "Verwenden Sie Amazon CloudFront als Content Delivery Network (CDN), um Video-Inhalte an Edge-Standorten zwischenzuspeichern, und speichern Sie häufig abgerufene Inhalte in Amazon S3 für die langfristige Speicherung.",
            "2": "Verwenden Sie Amazon ElastiCache, um Datenbankabfragen zwischenzuspeichern und Video-Inhalte in Amazon DynamoDB zu speichern, um schnelle Zugriffszeiten für Benutzer sicherzustellen.",
            "3": "Verwenden Sie Amazon EC2-Instanzen mit einem Lastenausgleich, um Video-Inhalte zwischenzuspeichern, und speichern Sie Inhalte in einem traditionellen Dateisystem für eine einfache Abrufbarkeit.",
            "4": "Verwenden Sie Amazon RDS mit Lese-Replikaten, um Daten zwischenzuspeichern und die Video-Lieferung zu optimieren, und speichern Sie Medieninhalte in Amazon EFS für den gemeinsamen Zugriff."
        },
        "Correct Answer": "Verwenden Sie Amazon CloudFront als Content Delivery Network (CDN), um Video-Inhalte an Edge-Standorten zwischenzuspeichern, und speichern Sie häufig abgerufene Inhalte in Amazon S3 für die langfristige Speicherung.",
        "Explanation": "Die Verwendung von Amazon CloudFront als CDN ermöglicht es dem Medienstreaming-Unternehmen, Video-Inhalte an Edge-Standorten weltweit zwischenzuspeichern. Dies reduziert die Latenz für Benutzer erheblich, indem Inhalte von einem näheren Standort geliefert werden, anstatt von einem zentralen Server. Darüber hinaus bietet die Speicherung häufig abgerufener Inhalte in Amazon S3 eine skalierbare und langlebige Speicherlösung, die sicherstellt, dass die Inhalte jederzeit abrufbar sind. Diese Kombination optimiert die Leistung und gewährleistet eine hohe Verfügbarkeit, was sie zur besten Wahl für eine schnelle Inhaltslieferung macht.",
        "Other Options": [
            "Die Verwendung von Amazon ElastiCache, um Datenbankabfragen zwischenzuspeichern und Video-Inhalte in Amazon DynamoDB zu speichern, ist nicht ideal für die Lieferung von Video-Inhalten. ElastiCache wird hauptsächlich zum Caching von In-Memory-Daten verwendet, um Datenbankabfragen zu beschleunigen, während DynamoDB eine NoSQL-Datenbank ist, die möglicherweise nicht für die effiziente Bereitstellung großer Videodateien optimiert ist.",
            "Die Verwendung von Amazon EC2-Instanzen mit einem Lastenausgleich zum Cachen von Video-Inhalten und die Speicherung von Inhalten in einem traditionellen Dateisystem ist keine effiziente Strategie. Dieser Ansatz würde mehr Management- und Skalierungsaufwand erfordern, und traditionelle Dateisysteme bieten möglicherweise nicht die gleichen Leistungsgewinne wie ein CDN für die globale Inhaltslieferung.",
            "Die Verwendung von Amazon RDS mit Lese-Replikaten zum Cachen von Daten und zur Optimierung der Video-Lieferung ist für Video-Inhalte nicht geeignet. RDS ist für relationale Datenbanken konzipiert und nicht für die Bereitstellung großer Mediendateien optimiert. Darüber hinaus ist Amazon EFS ein Dateispeicherdienst, der möglicherweise nicht die gleichen Leistungsgewinne wie ein CDN für das Streaming von Videos bietet."
        ]
    },
    {
        "Question Number": "28",
        "Situation": "Ein Unternehmen betreibt eine Anwendung auf Amazon EC2-Instanzen, die auf Daten zugreifen müssen, die in einem Amazon S3-Bucket gespeichert sind. Um die Verwaltung langfristiger Anmeldeinformationen zu vermeiden, möchte das Unternehmen den Instanzen sicher die erforderlichen Berechtigungen bereitstellen.",
        "Question": "Welche Konfiguration würde diese Anforderungen am besten erfüllen?",
        "Options": {
            "1": "Fügen Sie jeder EC2-Instanz eine IAM-Rolle mit den erforderlichen Berechtigungen zum Zugriff auf den S3-Bucket hinzu. Die Rolle stellt temporäre Anmeldeinformationen bereit, die automatisch rotiert werden.",
            "2": "Generieren Sie manuell einen IAM-Zugriffsschlüssel und einen geheimen Zugriffsschlüssel mit S3-Berechtigungen und speichern Sie diese auf jeder EC2-Instanz zur Verwendung durch die Anwendung.",
            "3": "Erstellen Sie einen IAM-Benutzer mit S3-Zugriffsberechtigungen, konfigurieren Sie die Anmeldeinformationen des Benutzers auf jeder EC2-Instanz und richten Sie einen geplanten Job ein, um die Anmeldeinformationen manuell zu rotieren.",
            "4": "Verwenden Sie AWS Secrets Manager, um S3-Zugriffsanmeldeinformationen zu speichern und diese im Anwendungscode, der auf den EC2-Instanzen ausgeführt wird, abzurufen."
        },
        "Correct Answer": "Fügen Sie jeder EC2-Instanz eine IAM-Rolle mit den erforderlichen Berechtigungen zum Zugriff auf den S3-Bucket hinzu. Die Rolle stellt temporäre Anmeldeinformationen bereit, die automatisch rotiert werden.",
        "Explanation": "Das Hinzufügen einer IAM-Rolle zu einer EC2-Instanz ist die beste Praxis, um Berechtigungen für den Zugriff auf AWS-Ressourcen wie S3 bereitzustellen. Diese Methode ermöglicht es der Instanz, die Rolle zu übernehmen und temporäre Sicherheitsanmeldeinformationen zu erhalten, die automatisch von AWS rotiert werden. Dies beseitigt die Notwendigkeit für langfristige Anmeldeinformationen, erhöht die Sicherheit und vereinfacht das Management, da die Anmeldeinformationen von AWS verwaltet werden und nicht manuell gespeichert oder rotiert werden müssen.",
        "Other Options": [
            "Das manuelle Generieren eines IAM-Zugriffsschlüssels und eines geheimen Zugriffsschlüssels und das Speichern dieser auf jeder EC2-Instanz ist nicht sicher. Wenn diese Anmeldeinformationen kompromittiert werden, können sie unbegrenzt verwendet werden, bis sie manuell widerrufen werden. Darüber hinaus kann die Verwaltung und Rotation dieser Anmeldeinformationen mühsam und fehleranfällig sein.",
            "Das Erstellen eines IAM-Benutzers mit S3-Zugriffsberechtigungen und das Konfigurieren der Anmeldeinformationen des Benutzers auf jeder EC2-Instanz ist ebenfalls unsicher. Ähnlich wie bei der vorherigen Option erfordert dieser Ansatz die manuelle Verwaltung langfristiger Anmeldeinformationen, was zu Sicherheitsanfälligkeiten führen kann, wenn die Anmeldeinformationen geleakt oder nicht ordnungsgemäß rotiert werden.",
            "Die Verwendung von AWS Secrets Manager zur Speicherung von S3-Zugriffsanmeldeinformationen und deren Abruf im Anwendungscode ist ein besserer Ansatz als das direkte Speichern von Anmeldeinformationen auf der Instanz. Es erfordert jedoch immer noch die Verwaltung von Anmeldeinformationen, was unnötig ist, wenn IAM-Rollen automatisch temporäre Anmeldeinformationen bereitstellen können. Dies fügt Komplexität hinzu, ohne signifikante Vorteile in diesem Szenario."
        ]
    },
    {
        "Question Number": "29",
        "Situation": "Eine Finanzinstitution, SecureBank, hat strenge Compliance-Anforderungen für Datenverschlüsselung und Schlüsselmanagement. Um die regulatorischen Standards zu erfüllen, muss SecureBank ein Hardware-Sicherheitsmodul (HSM) verwenden, das den FIPS 140-2 Level 3 für die Schlüsselverwaltung und -speicherung entspricht. Sie ziehen AWS CloudHSM und AWS Key Management Service (KMS) in Betracht, um diese Anforderungen zu erfüllen. SecureBank möchte die volle Kontrolle über den Schlüsselmanagementprozess und die Möglichkeit, sich in branchenübliche APIs für benutzerdefinierte Verschlüsselungs-Workflows zu integrieren. Sie möchten auch die Unterschiede in der Kundenkontrolle, den Compliance-Niveaus und der Integration mit AWS-Diensten zwischen AWS CloudHSM und AWS KMS verstehen.",
        "Question": "Welche der folgenden Optionen erklärt am besten die primären Unterschiede zwischen AWS CloudHSM und AWS Key Management Service (KMS) hinsichtlich der Kundenkontrolle und der Compliance-Niveaus, insbesondere im Umgang mit strengen Sicherheitsstandards wie FIPS 140-2 Level 3?",
        "Options": {
            "1": "AWS CloudHSM und AWS KMS bieten beide FIPS 140-2 Level 3 Compliance; jedoch ist nur AWS CloudHSM ein vollständig verwalteter, Multi-Tenant-Service, der es Kunden ermöglicht, ihre Verschlüsselungsschlüssel in einer gemeinsamen Umgebung zu verwalten.",
            "2": "AWS CloudHSM ist ein Single-Tenant-Hardware-Sicherheitsmodul (HSM), das von AWS bereitgestellt, aber vollständig vom Kunden verwaltet wird und FIPS 140-2 Level 3 Compliance bietet. Im Gegensatz dazu bietet AWS KMS in der Regel Level 2 Compliance und bietet eine tiefere Integration mit AWS-Diensten, jedoch mit weniger Kontrolle für den Kunden über das Schlüsselmanagement.",
            "3": "AWS CloudHSM ist so konzipiert, dass es sich nahtlos in AWS-Dienste wie S3 Server-Side Encryption integriert und eine nahtlose Verschlüsselungsverwaltung bietet. AWS KMS hingegen ist besser für compliance-gesteuerte Umgebungen geeignet, die ein kundenkontrolliertes HSM benötigen.",
            "4": "Im Gegensatz zu AWS CloudHSM ermöglicht AWS KMS den Kunden die Verwendung von branchenüblichen APIs, einschließlich PKCS#11 und CNG-Bibliotheken, zur Integration in andere Verschlüsselungs-Workflows, was es geeigneter für benutzerdefinierte kryptografische Implementierungen macht."
        },
        "Correct Answer": "AWS CloudHSM ist ein Single-Tenant-Hardware-Sicherheitsmodul (HSM), das von AWS bereitgestellt, aber vollständig vom Kunden verwaltet wird und FIPS 140-2 Level 3 Compliance bietet. Im Gegensatz dazu bietet AWS KMS in der Regel Level 2 Compliance und bietet eine tiefere Integration mit AWS-Diensten, jedoch mit weniger Kontrolle für den Kunden über das Schlüsselmanagement.",
        "Explanation": "AWS CloudHSM bietet den Kunden die volle Kontrolle über ihre Verschlüsselungsschlüssel und ist so konzipiert, dass es strengen Compliance-Anforderungen, einschließlich FIPS 140-2 Level 3, entspricht. Es handelt sich um eine Single-Tenant-Lösung, was bedeutet, dass die Hardware einem einzelnen Kunden gewidmet ist, was die Sicherheit und Kontrolle erhöht. Auf der anderen Seite ist AWS Key Management Service (KMS) ein Multi-Tenant-Service, der das Schlüsselmanagement vereinfacht und sich nahtlos in andere AWS-Dienste integriert, jedoch nicht das gleiche Maß an Kontrolle über das Schlüsselmanagement wie CloudHSM bietet. KMS erfüllt in der Regel die FIPS 140-2 Level 2 Compliance, was möglicherweise nicht den strengsten regulatorischen Anforderungen entspricht, mit denen SecureBank konfrontiert ist.",
        "Other Options": [
            "Option 1 gibt fälschlicherweise an, dass sowohl AWS CloudHSM als auch AWS KMS FIPS 140-2 Level 3 Compliance bieten. Während CloudHSM diesen Standard erfüllt, erfüllt KMS typischerweise die Level 2 Compliance, was eine kritische Unterscheidung für die Bedürfnisse von SecureBank ist.",
            "Option 3 stellt die Fähigkeiten von AWS CloudHSM und AWS KMS falsch dar. CloudHSM ist nicht primär für die Integration mit AWS-Diensten wie S3 konzipiert; vielmehr konzentriert es sich darauf, eine sichere Umgebung für das Schlüsselmanagement bereitzustellen. KMS ist in der Tat stärker in AWS-Dienste integriert, bietet jedoch nicht das gleiche Maß an Kontrolle wie CloudHSM.",
            "Option 4 behauptet fälschlicherweise, dass AWS KMS die Verwendung von branchenüblichen APIs wie PKCS#11 und CNG-Bibliotheken für benutzerdefinierte kryptografische Implementierungen ermöglicht. In Wirklichkeit unterstützt AWS CloudHSM diese APIs und bietet die Flexibilität, die für benutzerdefinierte Verschlüsselungs-Workflows erforderlich ist, während KMS nicht das gleiche Maß an Kontrolle oder API-Unterstützung bietet."
        ]
    },
    {
        "Question Number": "30",
        "Situation": "Eine mobile App erlebt große Nutzungsspitzen während wichtiger Ereignisse, was erfordert, dass die Anwendung schnell skalieren kann. Die App muss diese Spitzen effizient bewältigen und gleichzeitig die Kosten im Griff behalten.",
        "Question": "Welche Skalierungsstrategien würden diese Bedürfnisse am besten erfüllen? (Wählen Sie zwei aus.)",
        "Options": {
            "1": "Vertikale Skalierung durch Upgrade auf größere Instanztypen während hoher Verkehrslast",
            "2": "Horizontale Skalierung mit einer Auto Scaling-Gruppe und dynamischen Skalierungsrichtlinien",
            "3": "Geplante Skalierung, um Ressourcen während der Ereigniszeiten hinzuzufügen",
            "4": "Manuelle Skalierung durch Hinzufügen von Instanzen basierend auf der prognostizierten Nachfrage",
            "5": "Implementierung von prädiktiver Skalierung mit Amazon CloudWatch, um Verkehrsspitzen vorherzusehen und die Kapazität proaktiv anzupassen"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Horizontale Skalierung mit einer Auto Scaling-Gruppe und dynamischen Skalierungsrichtlinien",
            "Implementierung von prädiktiver Skalierung mit Amazon CloudWatch, um Verkehrsspitzen vorherzusehen und die Kapazität proaktiv anzupassen"
        ],
        "Explanation": "Die horizontale Skalierung mit einer Auto Scaling-Gruppe und dynamischen Skalierungsrichtlinien ist eine korrekte Antwort, da sie es der Anwendung ermöglicht, mehr Instanzen hinzuzufügen, wenn die Nachfrage steigt, und sie zu entfernen, wenn die Nachfrage sinkt, was ideal ist, um große Nutzungsspitzen zu bewältigen. Die Implementierung von prädiktiver Skalierung mit Amazon CloudWatch ist ebenfalls korrekt, da sie maschinelles Lernen verwendet, um zukünftige Nachfrage vorherzusagen und die Kapazität proaktiv anzupassen, was helfen kann, Verkehrsspitzen effizient zu bewältigen und die Kosten im Griff zu behalten.",
        "Other Options": [
            "Die vertikale Skalierung durch Upgrade auf größere Instanztypen während hoher Verkehrslast ist keine ideale Lösung, da sie die Kapazität einer einzelnen Instanz erhöht, was kostspielig sein kann und möglicherweise nicht die Flexibilität bietet, die erforderlich ist, um große Nutzungsspitzen zu bewältigen.",
            "Die geplante Skalierung, um Ressourcen während der Ereigniszeiten hinzuzufügen, kann ineffizient sein, da sie eine präzise Vorhersage erfordert, wann die Spitzen auftreten werden, was nicht immer möglich ist.",
            "Die manuelle Skalierung durch Hinzufügen von Instanzen basierend auf der prognostizierten Nachfrage ist nicht die beste Strategie, da sie manuelles Eingreifen erfordert und möglicherweise nicht schnell genug auf plötzliche Nachfrageanstiege reagieren kann."
        ]
    },
    {
        "Question Number": "31",
        "Situation": "Ein Unternehmen, XYZ Corp, verwaltet sensible Informationen wie Datenbankanmeldeinformationen, API-Schlüssel und andere Geheimnisse, die für verschiedene Microservices in ihrer Anwendung erforderlich sind. Sie möchten diese Geheimnisse sicher speichern und sicherstellen, dass jede Anwendung nur bei Bedarf darauf zugreifen kann. Darüber hinaus möchte XYZ Corp, dass die Geheimnisse automatisch rotiert werden, ohne dass manuelle Updates an den Anwendungen oder Ausfallzeiten für Konfigurationsänderungen erforderlich sind. Das Sicherheitsteam hat sich für AWS Secrets Manager entschieden, um diese Geheimnisse zu verwalten und zu rotieren. Sie möchten auch sicherstellen, dass die Geheimnisse im Ruhezustand verschlüsselt sind und nur für autorisierte Dienste und Anwendungen zugänglich sind.",
        "Question": "Welche der folgenden Schritte beschreibt korrekt, wie AWS Secrets Manager die Geheimnisabfrage und -rotation für den sicheren Zugriff durch Anwendungen behandelt?",
        "Options": {
            "1": "Secrets Manager ruft Geheimnisse von AWS Key Management Service (KMS) ab und aktualisiert sie regelmäßig direkt in der Anwendung, um die Synchronisation aufrechtzuerhalten.",
            "2": "Die Anwendung ruft Geheimnisse von Secrets Manager über ein SDK ab, und Secrets Manager nutzt AWS Lambda für die automatische Rotation der Geheimnisse, wobei die Geheimnisse im Ruhezustand mit KMS verschlüsselt sind.",
            "3": "Secrets Manager bietet automatische Rotation, indem alle Geheimnisse innerhalb von IAM-Rollen gespeichert werden, die regelmäßig über AWS Identity and Access Management (IAM)-Richtlinien rotiert werden.",
            "4": "AWS Secrets Manager ruft Anmeldeinformationen direkt von IAM für die Autorisierung ab, und Geheimnisse werden automatisch rotiert, ohne dass Lambda-Funktionen erforderlich sind."
        },
        "Correct Answer": "Die Anwendung ruft Geheimnisse von Secrets Manager über ein SDK ab, und Secrets Manager nutzt AWS Lambda für die automatische Rotation der Geheimnisse, wobei die Geheimnisse im Ruhezustand mit KMS verschlüsselt sind.",
        "Explanation": "AWS Secrets Manager ermöglicht es Anwendungen, Geheimnisse sicher über AWS SDKs abzurufen. Wenn eine Anwendung ein Geheimnis benötigt, ruft sie die Secrets Manager API auf, die das Geheimnis aus einem sicheren Speicher abruft. Secrets Manager unterstützt auch die automatische Rotation von Geheimnissen, die mit AWS Lambda-Funktionen implementiert werden kann. Das bedeutet, dass die Geheimnisse ohne manuelles Eingreifen aktualisiert werden können und die Anwendungen ohne Ausfallzeiten weiter funktionieren können. Darüber hinaus sind die Geheimnisse im Ruhezustand mit AWS Key Management Service (KMS) verschlüsselt, was sicherstellt, dass sensible Informationen geschützt sind.",
        "Other Options": [
            "AWS Secrets Manager ruft Geheimnisse nicht direkt von KMS ab. Stattdessen verwaltet es die Geheimnisse selbst und verwendet KMS zur Verschlüsselung im Ruhezustand. Geheimnisse werden nicht regelmäßig direkt in der Anwendung aktualisiert; stattdessen rufen Anwendungen die neueste Version des Geheimnisses bei Bedarf ab.",
            "AWS Secrets Manager speichert Geheimnisse nicht innerhalb von IAM-Rollen. IAM wird zur Verwaltung von Berechtigungen und Zugriffskontrolle verwendet, aber Secrets Manager verwaltet die Geheimnisse selbst und verwendet Lambda für die Rotation, nicht IAM-Richtlinien.",
            "AWS Secrets Manager ruft Anmeldeinformationen nicht direkt von IAM ab. Stattdessen verwaltet es Geheimnisse unabhängig und verwendet Lambda-Funktionen für die automatische Rotation. IAM wird für Autorisierung und Zugriffskontrolle verwendet, aber es behandelt nicht die Geheimnisabfrage."
        ]
    },
    {
        "Question Number": "32",
        "Situation": "Ein Unternehmen verwaltet seine Verschlüsselungsschlüssel mit AWS Key Management Service (AWS KMS) und möchte den Zugriff auf diese Schlüssel basierend auf Benutzerrollen steuern.",
        "Question": "Welche Methode sollte das Unternehmen verwenden, um Zugriffsberechtigungen für KMS-Schlüssel zu definieren?",
        "Options": {
            "1": "Berechtigungen direkt an IAM-Benutzer zuweisen",
            "2": "Ressourcenbasierte Richtlinien für die KMS-Schlüssel verwenden",
            "3": "MFA Delete für die KMS-Schlüssel aktivieren",
            "4": "Zugriffskontrolllisten (ACLs) für die KMS-Schlüssel konfigurieren"
        },
        "Correct Answer": "Ressourcenbasierte Richtlinien für die KMS-Schlüssel verwenden",
        "Explanation": "AWS Key Management Service (KMS) ermöglicht es Ihnen, Zugriffsberechtigungen für KMS-Schlüssel mithilfe von ressourcenbasierten Richtlinien zu definieren. Diese Richtlinien sind direkt an die KMS-Schlüssel angehängt und geben an, welche IAM-Benutzer, Rollen oder Dienste bestimmte Aktionen auf den Schlüsseln ausführen können. Diese Methode bietet eine feingranulare Kontrolle über den Zugriff und ist der empfohlene Ansatz zur Verwaltung von Berechtigungen für KMS-Schlüssel, da sie es Ihnen ermöglicht, Berechtigungen auf der Ressourcenebene und nicht auf der Benutzerebene zu definieren.",
        "Other Options": [
            "Berechtigungen direkt an IAM-Benutzer zuzuweisen, ist nicht die beste Praxis zur Verwaltung des Zugriffs auf KMS-Schlüssel, da es nicht die erforderliche Granularität bietet und zu Verwaltungskomplexität führen kann. Ressourcenbasierte Richtlinien sind für die Schlüsselverwaltung bevorzugt.",
            "MFA Delete ist eine Funktion, die hauptsächlich mit Amazon S3 verbunden ist und nicht auf KMS-Schlüssel zutrifft. Während MFA (Multi-Faktor-Authentifizierung) die Sicherheit erhöhen kann, steuert es nicht direkt die Zugriffsberechtigungen für KMS-Schlüssel.",
            "Das Konfigurieren von Zugriffskontrolllisten (ACLs) ist für KMS-Schlüssel nicht anwendbar. KMS verwendet IAM-Richtlinien und ressourcenbasierte Richtlinien für die Zugriffskontrolle, während ACLs typischerweise in anderen AWS-Diensten wie S3 verwendet werden."
        ]
    },
    {
        "Question Number": "33",
        "Situation": "Ein Unternehmen muss nutzergenerierte Inhalte, einschließlich Bilder, Videos und Dokumente, speichern, mit der Fähigkeit, den Speicherplatz einfach zu skalieren und schnellen Zugriff zu bieten. Das Unternehmen sucht nach einer Lösung, die große Mengen unstrukturierter Daten verarbeiten und hohe Verfügbarkeit unterstützen kann. Sie möchten auch sicherstellen, dass die Speicherlösung kosteneffektiv ist und von mehreren Diensten leicht zugänglich ist.",
        "Question": "Welchen AWS-Speichertyp sollte das Unternehmen verwenden, um diese Daten zu speichern, und welche Eigenschaften hat er?",
        "Options": {
            "1": "Verwenden Sie Amazon S3 (Objektspeicher) zum Speichern von Dateien, da es hochgradig skalierbar und für unstrukturierte Daten geeignet ist, mit einfachem Zugriff über HTTP/HTTPS.",
            "2": "Verwenden Sie Amazon EBS (Blockspeicher), um große Videodateien zu speichern, da es einen latenzarmen Zugriff auf die Daten und eine hohe Durchsatzrate für leistungsintensive Anwendungen bietet.",
            "3": "Verwenden Sie Amazon EFS (Dateispeicher) zum Speichern von nutzergenerierten Inhalten, da es den gemeinsamen Dateizugriff über mehrere EC2-Instanzen mit skalierbarem Speicherplatz bietet.",
            "4": "Verwenden Sie Amazon RDS (relationaler Datenbankdienst), um nutzergenerierte Inhalte aufgrund seiner starken Konsistenz und seines strukturierten Datenmodells zu speichern."
        },
        "Correct Answer": "Verwenden Sie Amazon S3 (Objektspeicher) zum Speichern von Dateien, da es hochgradig skalierbar und für unstrukturierte Daten geeignet ist, mit einfachem Zugriff über HTTP/HTTPS.",
        "Explanation": "Amazon S3 (Simple Storage Service) ist dafür ausgelegt, beliebige Datenmengen von überall im Web zu speichern und abzurufen. Es handelt sich um einen Objektspeicherdienst, der hochgradig skalierbar ist und sich ideal für nutzergenerierte Inhalte wie Bilder, Videos und Dokumente eignet. S3 unterstützt unstrukturierte Daten und bietet hohe Verfügbarkeit, was einen einfachen Zugriff über HTTP/HTTPS ermöglicht. Darüber hinaus ist es kosteneffektiv, da Benutzer nur für den Speicher bezahlen, den sie nutzen, und es gut mit verschiedenen AWS-Diensten integriert ist, was es für mehrere Anwendungen zugänglich macht.",
        "Other Options": [
            "Die Verwendung von Amazon EBS (Elastic Block Store) ist in diesem Szenario nicht ideal für die Speicherung großer Videodateien, da EBS Blockspeicher ist, der hauptsächlich für Daten verwendet wird, die einen latenzarmen Zugriff und eine hohe Durchsatzrate erfordern, typischerweise für Anwendungen, die auf EC2-Instanzen ausgeführt werden. Es ist nicht für die Speicherung unstrukturierter Daten im großen Maßstab ausgelegt und eignet sich besser für Datenbanken oder Anwendungen, die schnellen Zugriff auf Datenblöcke benötigen.",
            "Die Verwendung von Amazon EFS (Elastic File System) könnte den gemeinsamen Dateizugriff über mehrere EC2-Instanzen ermöglichen, ist jedoch besser für Szenarien geeignet, in denen Dateispeicher benötigt wird, als für Objektspeicher. EFS ist auch im Allgemeinen teurer als S3 für große Mengen unstrukturierter Daten und bietet nicht das gleiche Maß an Skalierbarkeit und Kosteneffektivität wie S3 für die Speicherung großer Mengen nutzergenerierter Inhalte.",
            "Die Verwendung von Amazon RDS (Relational Database Service) ist ungeeignet für die Speicherung nutzergenerierter Inhalte, da RDS für strukturierte Daten und relationale Datenbanken konzipiert ist. Es ist nicht für unstrukturierte Daten wie Bilder und Videos optimiert, und die Verwendung zu solchen Zwecken wäre weder kosteneffektiv noch effizient, da sie komplexe Datenbankschemata und -verwaltung erfordern würde."
        ]
    },
    {
        "Question Number": "34",
        "Situation": "Eine Organisation hat ihren lokalen Identitätsanbieter mit AWS föderiert, um Benutzern zu ermöglichen, Rollen mithilfe von SAML zu übernehmen. Die Organisation möchte die Multi-Faktor-Authentifizierung (MFA) für alle föderierten Benutzer, die auf die AWS Management Console zugreifen, durchsetzen.",
        "Question": "Was ist der beste Ansatz, um MFA in diesem Szenario durchzusetzen? (Wählen Sie zwei.)",
        "Options": {
            "1": "MFA-Einstellungen in den AWS IAM-Rollen, die für den föderierten Zugriff verwendet werden, konfigurieren",
            "2": "MFA über den lokalen Identitätsanbieter der Organisation verlangen",
            "3": "MFA auf der Ebene des AWS-Root-Kontos aktivieren",
            "4": "Ein Amazon Cognito-Benutzerpool mit MFA-Anforderungen einrichten",
            "5": "AWS IAM-Richtlinien verwenden, um MFA-Authentifizierung für die Rollenübernahme zu verlangen"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "MFA über den lokalen Identitätsanbieter der Organisation verlangen",
            "AWS IAM-Richtlinien verwenden, um MFA-Authentifizierung für die Rollenübernahme zu verlangen"
        ],
        "Explanation": "In diesem Szenario ist der beste Ansatz zur Durchsetzung von MFA für alle föderierten Benutzer, die auf die AWS Management Console zugreifen, MFA über den lokalen Identitätsanbieter der Organisation zu verlangen und AWS IAM-Richtlinien zu verwenden, um MFA-Authentifizierung für die Rollenübernahme zu verlangen. Der lokale Identitätsanbieter ist für die anfängliche Benutzerauthentifizierung, einschließlich MFA, verantwortlich. Nachdem der Benutzer authentifiziert wurde, generiert der Identitätsanbieter eine SAML-Assertion, die verwendet wird, um temporäre Sicherheitsanmeldeinformationen anzufordern und eine IAM-Rolle zu übernehmen. AWS IAM-Richtlinien können verwendet werden, um MFA zum Zeitpunkt der Rollenübernahme durchzusetzen, sodass sich der Benutzer mit MFA authentifizieren muss, bevor er die Rolle übernehmen kann.",
        "Other Options": [
            "Das Konfigurieren von MFA-Einstellungen in den AWS IAM-Rollen, die für den föderierten Zugriff verwendet werden, ist nicht möglich, da die Durchsetzung von MFA keine Einstellung ist, die direkt in IAM-Rollen konfiguriert werden kann.",
            "Die Aktivierung von MFA auf der Ebene des AWS-Root-Kontos würde MFA für föderierte Benutzer nicht durchsetzen. MFA auf der Ebene des Root-Kontos gilt nur für den Root-Benutzer des Kontos, nicht für IAM-Benutzer oder föderierte Benutzer.",
            "Das Einrichten eines Amazon Cognito-Benutzerpools mit MFA-Anforderungen würde MFA für föderierte Benutzer, die auf die AWS Management Console zugreifen, nicht durchsetzen. Amazon Cognito wird verwendet, um die Benutzerauthentifizierung in mobilen und Webanwendungen zu erstellen, zu sichern und zu skalieren, nicht um MFA für föderierte Benutzer, die auf die AWS Management Console zugreifen, durchzusetzen."
        ]
    },
    {
        "Question Number": "35",
        "Situation": "Eine Anwendung zur Verarbeitung von Echtzeit-Aktienhandelsdaten erfordert eine hohe CPU-Leistung, benötigt jedoch nicht viel Speicher. Das Unternehmen möchte die Kosten optimieren, indem es den am besten geeigneten Instanztyp auswählt.",
        "Question": "Welche Instanzfamilie würde diese Leistungs- und Kostenanforderungen am besten erfüllen?",
        "Options": {
            "1": "Speicheroptimiert",
            "2": "Rechenoptimiert",
            "3": "Speicheroptimiert",
            "4": "Beschleunigtes Rechnen"
        },
        "Correct Answer": "Rechenoptimiert",
        "Explanation": "Die Instanzfamilie Rechenoptimiert ist speziell für Anwendungen konzipiert, die eine hohe CPU-Leistung erfordern. Da die betreffende Anwendung Echtzeit-Aktienhandelsdaten verarbeitet, profitiert sie von der erhöhten Verarbeitungsleistung, die diese Instanzen bieten. Darüber hinaus sind rechenoptimierte Instanzen im Allgemeinen kosteneffektiver für CPU-intensive Arbeitslasten im Vergleich zu anderen Instanztypen, die möglicherweise mehr Speicher oder Speicherfähigkeiten bieten, als benötigt werden.",
        "Other Options": [
            "Speicheroptimierte Instanzen sind für Anwendungen konzipiert, die eine hohe Speicherleistung erfordern. Da die Anwendung nicht viel Speicher benötigt, wäre diese Option nicht geeignet und würde wahrscheinlich unnötige Kosten verursachen.",
            "Speicheroptimierte Instanzen sind auf Arbeitslasten zugeschnitten, die einen hohen Speicher-Durchsatz und IOPS erfordern. Da die Anwendung keine signifikanten Speicheranforderungen hat, wäre dieser Instanztyp nicht geeignet und würde die Kosten nicht optimieren.",
            "Instanzen für beschleunigtes Rechnen sind für Arbeitslasten konzipiert, die von Hardwarebeschleunigern wie GPUs profitieren. Diese Instanzen werden typischerweise für maschinelles Lernen, Grafik-Rendering oder andere spezialisierte Aufgaben verwendet. Da die Anwendung sich auf die CPU-Leistung konzentriert und keine Beschleunigung erfordert, würde diese Option die Anforderungen nicht effektiv erfüllen."
        ]
    },
    {
        "Question Number": "36",
        "Situation": "Eine E-Commerce-Plattform hat hohen Leseverkehr für Produktkataloge, was die Leistung der primären Datenbank beeinträchtigt. Das Unternehmen möchte Leseoperationen auslagern, um die Skalierbarkeit zu verbessern, ohne die Datenkonsistenz zu gefährden.",
        "Question": "Welche Strategie sollte der Lösungsarchitekt implementieren, um dies zu erreichen?",
        "Options": {
            "1": "Aktivieren Sie die Multi-AZ-Bereitstellung für die Amazon RDS-Instanz, um den Leseverkehr zu verteilen.",
            "2": "Erstellen Sie Amazon RDS-Lese-Replikate und konfigurieren Sie die Anwendung so, dass Leseabfragen an die Replikate geleitet werden.",
            "3": "Verwenden Sie Amazon DynamoDB mit Global Tables, um die Leseskalierbarkeit zu bewältigen.",
            "4": "Implementieren Sie ein Master-Slave-Replikationssetup mit Amazon EC2-Instanzen und MySQL."
        },
        "Correct Answer": "Erstellen Sie Amazon RDS-Lese-Replikate und konfigurieren Sie die Anwendung so, dass Leseabfragen an die Replikate geleitet werden.",
        "Explanation": "Die Erstellung von Amazon RDS-Lese-Replikaten ermöglicht es der E-Commerce-Plattform, den Leseverkehr von der primären Datenbank auszulagern. Lese-Replikate sind speziell dafür ausgelegt, Leseoperationen zu verarbeiten, was hilft, die Skalierbarkeit und Leistung zu verbessern, ohne die Datenkonsistenz zu gefährden. Die Replikate replizieren Daten asynchron von der primären Datenbank, sodass Leseabfragen an diese Replikate geleitet werden können, wodurch die Last auf der primären Instanz verringert und die Gesamtanwendungsleistung verbessert wird.",
        "Other Options": [
            "Die Aktivierung der Multi-AZ-Bereitstellung für die Amazon RDS-Instanz konzentriert sich hauptsächlich auf hohe Verfügbarkeit und Failover-Funktionen und nicht auf die Skalierung von Leseoperationen. Obwohl sie Redundanz bietet, hilft sie nicht effektiv bei der Verteilung des Leseverkehrs.",
            "Die Verwendung von Amazon DynamoDB mit Global Tables ist eine andere Datenbanklösung, die möglicherweise nicht geeignet ist, wenn die bestehende Architektur auf Amazon RDS basiert. Darüber hinaus kann sie Komplexität bei der Migration von Daten und der Sicherstellung der Kompatibilität mit der aktuellen Anwendung einführen.",
            "Die Implementierung eines Master-Slave-Replikationssetups mit Amazon EC2-Instanzen und MySQL erfordert mehr Verwaltungsaufwand und nutzt nicht die integrierten Funktionen von Amazon RDS. Dieser Ansatz kann auch Konsistenzprobleme einführen und ist weniger effizient im Vergleich zur Verwendung von RDS-Lese-Replikaten."
        ]
    },
    {
        "Question Number": "37",
        "Situation": "Ein Marketingteam muss Clickstream-Daten analysieren, die in Amazon S3 gespeichert sind, um Einblicke in das Benutzerverhalten zu gewinnen und das Engagement auf der Website zu verbessern. Sie möchten SQL-Abfragen direkt auf diesen Daten ausführen, ohne ein vollständiges Data Warehouse einzurichten oder Server zu verwalten. Darüber hinaus wünschen sie sich eine Lösung, die es ihnen ermöglicht, nur für die Daten zu zahlen, die sie tatsächlich abfragen, um Kosten zu sparen und die Infrastruktur minimal und serverlos zu halten.",
        "Question": "Welcher AWS-Dienst würde am besten ihren Bedürfnissen entsprechen?",
        "Options": {
            "1": "Amazon Redshift",
            "2": "Amazon EMR",
            "3": "Amazon RDS",
            "4": "Amazon Athena"
        },
        "Correct Answer": "Amazon Athena",
        "Explanation": "Amazon Athena ist ein serverloser interaktiver Abfragedienst, der es Benutzern ermöglicht, Daten direkt in Amazon S3 mit standardisiertem SQL zu analysieren. Er ist für Ad-hoc-Abfragen konzipiert und erfordert keine Infrastrukturverwaltung, was ihn ideal für die Bedürfnisse des Marketingteams macht. Mit Athena zahlen die Benutzer nur für die Abfragen, die sie ausführen, was mit ihrem Ziel der Kosteneinsparungen bei minimaler Infrastruktur übereinstimmt.",
        "Other Options": [
            "Amazon Redshift ist ein vollständig verwalteter Data-Warehouse-Dienst, der die Einrichtung eines Clusters und die Verwaltung von Ressourcen erfordert. Er ist nicht serverlos und würde höhere Kosten und Komplexität für das Marketingteam mit sich bringen, das nach einer einfacheren Lösung sucht.",
            "Amazon EMR (Elastic MapReduce) ist eine Cloud-Plattform für Big Data, die die Verarbeitung großer Datenmengen mit Frameworks wie Apache Hadoop und Apache Spark ermöglicht. Es erfordert jedoch mehr Verwaltung und Einrichtung im Vergleich zu einer serverlosen Lösung wie Athena, was es weniger geeignet für die Bedürfnisse des Teams macht.",
            "Amazon RDS (Relational Database Service) ist ein verwalteter relationaler Datenbankdienst, der die Bereitstellung und Verwaltung von Datenbankinstanzen erfordert. Er ist nicht dafür ausgelegt, Daten direkt aus S3 abzufragen, und würde mehr Aufwand erfordern, als das Marketingteam wünscht."
        ]
    },
    {
        "Question Number": "38",
        "Situation": "Ein Videoproduktionsunternehmen speichert Tausende von Videodateien, die nach der ursprünglichen Produktion selten aufgerufen werden. Sie möchten eine kosteneffektive Speicherlösung, die es ihnen ermöglicht, diese Dateien zu archivieren, sie aber bei Bedarf innerhalb weniger Minuten wieder abzurufen.",
        "Question": "Welcher AWS-Speicherdienst würde am besten diese Anforderungen erfüllen?",
        "Options": {
            "1": "Amazon EFS",
            "2": "Amazon S3 Glacier Instant Retrieval",
            "3": "Amazon FSx for Windows File Server",
            "4": "Amazon EBS Provisioned IOPS"
        },
        "Correct Answer": "Amazon S3 Glacier Instant Retrieval",
        "Explanation": "Amazon S3 Glacier Instant Retrieval ist speziell für die langfristige Datenarchivierung konzipiert und ermöglicht eine schnelle Datenwiederherstellung, typischerweise innerhalb von Millisekunden. Dieser Dienst ist ideal für das Videoproduktionsunternehmen, da er ihnen ermöglicht, große Mengen seltener Videodateien kosteneffektiv zu speichern und dennoch die Möglichkeit bietet, diese Dateien bei Bedarf innerhalb weniger Minuten abzurufen. Die Funktion 'Instant Retrieval' stellt sicher, dass die Wiederherstellungszeit mit der Anforderung des Unternehmens nach schnellem Zugriff auf archivierte Dateien übereinstimmt.",
        "Other Options": [
            "Amazon EFS (Elastic File System) ist für den Latenzarmen Zugriff auf gemeinsamen Dateispeicher konzipiert und ist nicht kosteneffektiv für die langfristige Archivierung seltener Daten. Es eignet sich besser für Anwendungen, die häufigen Zugriff auf Daten erfordern.",
            "Amazon FSx for Windows File Server bietet vollständig verwaltete Windows-Dateisysteme, ist jedoch ebenfalls nicht für die langfristige Archivierung optimiert. Es ist besser geeignet für Anwendungen, die gemeinsamen Dateispeicher mit Windows-Kompatibilität und latenzarmen Zugriff erfordern.",
            "Amazon EBS (Elastic Block Store) Provisioned IOPS ist für leistungsstarken Blockspeicher für EC2-Instanzen konzipiert. Es ist nicht geeignet für die Archivierung großer Mengen seltener Daten, da es teurer ist und für Workloads gedacht ist, die konsistente und latenzarme Leistung erfordern."
        ]
    },
    {
        "Question Number": "39",
        "Situation": "Eine Organisation verwendet eine Auto Scaling Group (ASG), um ihre Flotte von EC2-Instanzen zu verwalten und auf unterschiedliche Nachfrageschwankungen zu reagieren. Ihr Ziel ist es, die Anzahl der Instanzen automatisch anzupassen, um einen durchschnittlichen CPU-Auslastungswert von 40 % aufrechtzuerhalten.",
        "Question": "Welche Art von Skalierungsrichtlinie sollte die Organisation implementieren, um dieses Ziel effektiv zu erreichen, und warum?",
        "Options": {
            "1": "Manuelle Skalierung: Bietet direkte Kontrolle über die gewünschte Kapazität basierend auf Echtzeitüberwachung.",
            "2": "Geplante Skalierung: Passt die Kapazität zu festgelegten Zeiten an, die mit prognostizierten Nachfragetrends übereinstimmen.",
            "3": "Dynamische Skalierung mit Zielverfolgung: Passt die Kapazität automatisch an, um das festgelegte Ziel der CPU-Auslastung aufrechtzuerhalten.",
            "4": "Einfache Skalierung: Erhöht oder verringert die Kapazität basierend auf einzelnen CPU-Schwellenwertauslösern."
        },
        "Correct Answer": "Dynamische Skalierung mit Zielverfolgung",
        "Explanation": "Dynamische Skalierung mit Zielverfolgung ist die effektivste Skalierungsrichtlinie für das Ziel der Organisation, einen durchschnittlichen CPU-Auslastungswert von 40 % aufrechtzuerhalten. Diese Richtlinie passt automatisch die Anzahl der EC2-Instanzen in der Auto Scaling Group basierend auf Echtzeitmetriken an, wobei speziell das festgelegte Niveau der CPU-Auslastung angestrebt wird. Durch die kontinuierliche Überwachung der CPU-Auslastung und die erforderlichen Anpassungen kann die Organisation sicherstellen, dass sie ihre Leistungsziele ohne manuelle Eingriffe erreicht, wodurch die Ressourcennutzung und die Kosten optimiert werden.",
        "Other Options": [
            "Manuelle Skalierung erfordert direkte menschliche Intervention, um die gewünschte Kapazität anzupassen, was nicht effizient ist, um auf unterschiedliche Nachfrageschwankungen zu reagieren. Dieser Ansatz bietet nicht die Automatisierung, die erforderlich ist, um ein bestimmtes Ziel der CPU-Auslastung effektiv aufrechtzuerhalten.",
            "Geplante Skalierung passt die Kapazität zu festgelegten Zeiten an, die möglicherweise nicht mit den tatsächlichen Nachfrageschwankungen übereinstimmen. Diese Methode ist weniger reaktionsschnell auf Echtzeitänderungen in der Arbeitslast und kann zu Über- oder Unterprovisionierung von Ressourcen führen.",
            "Einfache Skalierung erhöht oder verringert die Kapazität basierend auf einzelnen CPU-Schwellenwertauslösern, was zu schnellen Skalierungsaktionen führen kann, die die CPU-Auslastung möglicherweise nicht auf dem gewünschten Durchschnitt von 40 % stabilisieren. Diese Methode fehlt die kontinuierliche Anpassungsfunktion der Zielverfolgung, was sie weniger geeignet macht, um ein bestimmtes Auslastungsniveau aufrechtzuerhalten."
        ]
    },
    {
        "Question Number": "40",
        "Situation": "Ein Unternehmen implementiert eine hochverfügbare Datenbank auf AWS mit Amazon RDS und möchte sicherstellen, dass bei einem Ausfall automatisch auf eine Standby-Instanz umgeschaltet wird. Sie müssen auch einen Teil des Leseverkehrs auslagern und die Leseleistung verbessern.",
        "Question": "Welche Amazon RDS-Konfiguration sollten sie wählen und welche Vorteile bietet sie? (Wählen Sie zwei.)",
        "Options": {
            "1": "Verwenden Sie die Amazon RDS Multi-AZ-Instanzarchitektur für die synchrone Replikation zu einer Standby-Instanz, die automatisches Failover in derselben Region bietet, wobei Backups von der Standby-Instanz zur Leistungsverbesserung erstellt werden.",
            "2": "Konfigurieren Sie die Amazon RDS Multi-AZ-Clusterarchitektur mit einer Schreibinstanz und zwei Leseinstanzen in verschiedenen Verfügbarkeitszonen, um den Leseverkehr auszulagern und schnellere Failover-Zeiten mit transaktionsprotokollbasierter Replikation zu ermöglichen.",
            "3": "Richten Sie Amazon RDS in einer einzelnen Verfügbarkeitszone mit häufigen Snapshots zu S3 für Backups ein, um die Datensicherheit zu gewährleisten, jedoch kein automatisches Failover zu bieten.",
            "4": "Setzen Sie Amazon RDS mit regionaler Replikation ein, um das Failover in eine andere AWS-Region zu ermöglichen, wodurch das Risiko regionaler Ausfälle verringert wird, jedoch keine synchrone Replikation unterstützt wird.",
            "5": "Implementieren Sie Amazon RDS-Lese-Replikate in derselben Region, um den Leseverkehr zu verteilen und die Leseleistung zu verbessern, während eine Multi-AZ-Konfiguration für automatisches Failover beibehalten wird."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Verwenden Sie die Amazon RDS Multi-AZ-Instanzarchitektur für die synchrone Replikation zu einer Standby-Instanz, die automatisches Failover in derselben Region bietet, wobei Backups von der Standby-Instanz zur Leistungsverbesserung erstellt werden.",
            "Implementieren Sie Amazon RDS-Lese-Replikate in derselben Region, um den Leseverkehr zu verteilen und die Leseleistung zu verbessern, während eine Multi-AZ-Konfiguration für automatisches Failover beibehalten wird."
        ],
        "Explanation": "Die erste richtige Antwort ist korrekt, weil Amazon RDS Multi-AZ-Bereitstellungen hohe Verfügbarkeit und Failover-Unterstützung für DB-Instanzen bieten. Sie arbeiten, indem sie die Daten automatisch an eine Standby-Instanz in einer anderen Verfügbarkeitszone (AZ) replizieren. Im Falle eines Ausfalls führt Amazon RDS ein automatisches Failover zur Standby-Instanz durch, sodass Sie die Datenbankoperationen sofort nach Abschluss des Failovers wieder aufnehmen können. Die zweite richtige Antwort ist korrekt, weil Amazon RDS-Lese-Replikate die Leistung und Haltbarkeit für Datenbankinstanzen (DB) verbessern. Diese Funktion erleichtert es, über die Kapazitätsgrenzen einer einzelnen DB-Instanz für leseintensive Datenbank-Workloads elastisch hinaus zu skalieren.",
        "Other Options": [
            "Die Option 'Konfigurieren Sie die Amazon RDS Multi-AZ-Clusterarchitektur mit einer Schreibinstanz und zwei Leseinstanzen in verschiedenen Verfügbarkeitszonen, um den Leseverkehr auszulagern und schnellere Failover-Zeiten mit transaktionsprotokollbasierter Replikation zu ermöglichen.' ist falsch, weil Amazon RDS keine Konfiguration mit einer Schreibinstanz und zwei Leseinstanzen in einer Multi-AZ-Bereitstellung unterstützt.",
            "Die Option 'Richten Sie Amazon RDS in einer einzelnen Verfügbarkeitszone mit häufigen Snapshots zu S3 für Backups ein, um die Datensicherheit zu gewährleisten, jedoch kein automatisches Failover zu bieten.' ist falsch, weil dieses Setup kein automatisches Failover bietet, was eine Anforderung in der Frage ist.",
            "Die Option 'Setzen Sie Amazon RDS mit regionaler Replikation ein, um das Failover in eine andere AWS-Region zu ermöglichen, wodurch das Risiko regionaler Ausfälle verringert wird, jedoch keine synchrone Replikation unterstützt wird.' ist falsch, weil die regionale Replikation keine synchrone Replikation unterstützt, die für automatisches Failover erforderlich ist."
        ]
    },
    {
        "Question Number": "41",
        "Situation": "Eine Anwendung, die auf Amazon EC2-Instanzen in einem öffentlichen Subnetz läuft, muss sicher mit einer Amazon RDS-Datenbank kommunizieren, die in einem privaten Subnetz gehostet wird.",
        "Question": "Wie sollte die Anwendung konfiguriert werden, um sicheren Zugriff auf die Datenbank zu ermöglichen?",
        "Options": {
            "1": "Fügen Sie eine eingehende Regel zur RDS-Sicherheitsgruppe hinzu, um allen Datenverkehr aus dem Internet zuzulassen",
            "2": "Verwenden Sie ein NAT-Gateway, um den Datenverkehr vom öffentlichen Subnetz zum privaten Subnetz zu leiten",
            "3": "Erstellen Sie eine VPC-Peering-Verbindung zwischen dem öffentlichen und dem privaten Subnetz",
            "4": "Konfigurieren Sie die EC2-Instanzen so, dass sie die private IP-Adresse der Datenbank verwenden und den Zugriff über die RDS-Sicherheitsgruppe zulassen"
        },
        "Correct Answer": "Konfigurieren Sie die EC2-Instanzen so, dass sie die private IP-Adresse der Datenbank verwenden und den Zugriff über die RDS-Sicherheitsgruppe zulassen",
        "Explanation": "Um den sicheren Zugriff von den EC2-Instanzen im öffentlichen Subnetz auf die RDS-Datenbank im privaten Subnetz zu ermöglichen, sollten die EC2-Instanzen die private IP-Adresse der Datenbank verwenden. Dies stellt sicher, dass der Datenverkehr nicht über das öffentliche Internet geleitet wird, was die Sicherheit aufrechterhält. Darüber hinaus muss die RDS-Sicherheitsgruppe so konfiguriert werden, dass sie eingehenden Datenverkehr von der Sicherheitsgruppe der EC2-Instanzen zulässt, um sicherzustellen, dass nur autorisierter Datenverkehr erlaubt ist.",
        "Other Options": [
            "Das Hinzufügen einer eingehenden Regel zur RDS-Sicherheitsgruppe, um allen Datenverkehr aus dem Internet zuzulassen, ist unsicher und nicht empfehlenswert. Dies würde die RDS-Datenbank potenziellen Angriffen aus dem Internet aussetzen und ihre Sicherheit gefährden.",
            "Die Verwendung eines NAT-Gateways zur Weiterleitung des Datenverkehrs vom öffentlichen Subnetz zum privaten Subnetz ist in diesem Szenario nicht erforderlich. NAT-Gateways werden typischerweise verwendet, um Instanzen in einem privaten Subnetz den Zugriff auf das Internet zu ermöglichen, nicht für die Kommunikation zwischen öffentlichen und privaten Subnetzen innerhalb derselben VPC.",
            "Die Erstellung einer VPC-Peering-Verbindung zwischen dem öffentlichen und dem privaten Subnetz ist nicht notwendig, da beide Subnetze bereits Teil derselben VPC sind. VPC-Peering wird verwendet, um verschiedene VPCs zu verbinden, nicht Subnetze innerhalb derselben VPC."
        ]
    },
    {
        "Question Number": "42",
        "Situation": "Ein Biotechnologieunternehmen implementiert eine leistungsstarke Anwendung, die eine Container-Orchestrierung über mehrere Verfügbarkeitszonen für Resilienz und Skalierbarkeit erfordert. Sie bevorzugen eine verwaltete Lösung, die mit AWS-Diensten wie IAM für Sicherheit und EBS für Speicher integriert ist. Die Plattform sollte außerdem Open Source und cloudunabhängig sein, um Flexibilität für zukünftige Bereitstellungen außerhalb von AWS zu bieten.",
        "Question": "Welche AWS-Dienstkonfiguration würde diese Anforderungen am besten erfüllen?",
        "Options": {
            "1": "Amazon ECS mit Fargate und EBS-Integration",
            "2": "Amazon EKS mit verwalteten Knoten-Gruppen und Multi-AZ-Kontrollebene",
            "3": "Amazon EC2-Instanzen mit Docker und Cross-AZ-Replikation",
            "4": "AWS Batch mit Cross-Region-Replikation"
        },
        "Correct Answer": "Amazon EKS mit verwalteten Knoten-Gruppen und Multi-AZ-Kontrollebene",
        "Explanation": "Amazon EKS (Elastic Kubernetes Service) ist ein verwalteter Kubernetes-Dienst, der eine Container-Orchestrierung über mehrere Verfügbarkeitszonen bietet und so Resilienz und Skalierbarkeit gewährleistet. Es integriert sich nahtlos mit AWS-Diensten wie IAM für Sicherheit und EBS für Speicher. EKS ist auch Open Source und cloudunabhängig, was Flexibilität für zukünftige Bereitstellungen außerhalb von AWS ermöglicht. Die verwalteten Knoten-Gruppen vereinfachen die Verwaltung der zugrunde liegenden EC2-Instanzen, und die Multi-AZ-Kontrollebene verbessert die Verfügbarkeit und Fehlertoleranz.",
        "Other Options": [
            "Amazon ECS mit Fargate und EBS-Integration ist eine praktikable Option für die Container-Orchestrierung, jedoch nicht so cloudunabhängig wie EKS. ECS ist enger mit AWS-Diensten integriert und bietet nicht das gleiche Maß an Flexibilität für zukünftige Bereitstellungen außerhalb von AWS.",
            "Amazon EC2-Instanzen mit Docker und Cross-AZ-Replikation erfordern im Vergleich zu einem verwalteten Dienst wie EKS mehr manuelle Verwaltung und Einrichtung. Während es die gewünschten Ergebnisse erzielen kann, bietet es nicht das gleiche Maß an Integration mit AWS-Diensten oder die Benutzerfreundlichkeit, die mit einer verwalteten Lösung einhergeht.",
            "AWS Batch mit Cross-Region-Replikation ist für die Batch-Verarbeitung konzipiert und nicht für kontinuierliche Hochleistungsanwendungen. Es bietet nicht die erforderlichen Container-Orchestrierungsfähigkeiten für das beschriebene Szenario und ist nicht geeignet für Anwendungen, die Echtzeit-Skalierung und Resilienz erfordern."
        ]
    },
    {
        "Question Number": "43",
        "Situation": "Ein Finanzdienstleistungsunternehmen benötigt eine sichere, latenzarme Verbindung zwischen seinem lokalen Rechenzentrum und AWS, um die Verarbeitung von Echtzeitdaten und Handelsoperationen zu unterstützen. Um die Netzwerk kosten zu senken und gleichzeitig die Zuverlässigkeit zu gewährleisten, sucht das Unternehmen nach einer privaten, konsistenten Verbindung für kritische Datenübertragungen, die das öffentliche Internet umgeht und damit verbundene Sicherheits- und Leistungsrisiken vermeidet.",
        "Question": "Welche Netzwerkverbindungsoption würde diese Bedürfnisse am besten erfüllen?",
        "Options": {
            "1": "Einrichten eines AWS Site-to-Site VPN, das eine verschlüsselte Datenübertragung über das öffentliche Internet für eine kostengünstige Lösung ermöglicht",
            "2": "Einrichten von AWS Direct Connect für eine dedizierte, private Netzwerkverbindung, die sichere und konsistente Bandbreite bietet",
            "3": "Verwendung einer regulären Internetverbindung mit AWS Shield zum Schutz vor DDoS-Angriffen und zur Gewährleistung der Sicherheit",
            "4": "Konfigurieren von VPC Peering, um eine direkte Verbindung zwischen dem lokalen Rechenzentrum und AWS herzustellen und sichere Konnektivität bereitzustellen"
        },
        "Correct Answer": "Einrichten von AWS Direct Connect für eine dedizierte, private Netzwerkverbindung, die sichere und konsistente Bandbreite bietet",
        "Explanation": "AWS Direct Connect ist speziell dafür konzipiert, eine dedizierte, private Verbindung zwischen einem lokalen Rechenzentrum und AWS bereitzustellen. Diese Option umgeht das öffentliche Internet und gewährleistet eine niedrigere Latenz, höhere Zuverlässigkeit und verbesserte Sicherheit für kritische Datenübertragungen. Es ist ideal für die Verarbeitung von Echtzeitdaten und Handelsoperationen, da es konsistente Bandbreite und reduzierte Netzwerk kosten im Vergleich zu herkömmlichen Internetverbindungen bietet.",
        "Other Options": [
            "Das Einrichten eines AWS Site-to-Site VPN ermöglicht eine verschlüsselte Datenübertragung über das öffentliche Internet, was nicht den Anforderungen an eine private Verbindung entspricht. Obwohl es eine kostengünstige Lösung ist, führt es zu Latenz und potenziellen Sicherheitsrisiken, die mit dem öffentlichen Internetverkehr verbunden sind.",
            "Die Verwendung einer regulären Internetverbindung mit AWS Shield bietet Schutz vor DDoS-Angriffen, bietet jedoch nicht die dedizierte, private Verbindung, die das Unternehmen benötigt. Diese Option verlässt sich weiterhin auf das öffentliche Internet, was zu Leistungsproblemen und Sicherheitsanfälligkeiten führen kann.",
            "Die Konfiguration von VPC Peering erstellt eine direkte Verbindung zwischen zwei VPCs, stellt jedoch keine Verbindung zwischen einem lokalen Rechenzentrum und AWS her. Es ist nicht für die Bedürfnisse des Unternehmens geeignet, da es nicht die erforderliche dedizierte, private Netzwerkverbindung für sichere und konsistente Datenübertragungen bietet."
        ]
    },
    {
        "Question Number": "44",
        "Situation": "Ein Unternehmen entwirft eine global resiliente Anwendung, die hohe Verfügbarkeit und niedrige Latenz für Benutzer in mehreren geografischen Regionen erfordert. Sie möchten auch sicherstellen, dass Ausfälle in einer Region oder Verfügbarkeitszone (AZ) die Verfügbarkeit der Anwendung an anderen Orten nicht beeinträchtigen.",
        "Question": "Welcher AWS-Dienst oder welches Feature unterstützt diese Bedürfnisse am besten, indem es die globale Infrastruktur von AWS nutzt?",
        "Options": {
            "1": "Verwenden Sie Amazon Route 53 mit latenzbasiertem Routing, um Benutzer zur nächstgelegenen AWS-Region zu leiten, was die niedrige Latenz verbessert und regionale Fehlertoleranz ermöglicht.",
            "2": "Bereitstellung der Anwendung in einer einzigen Verfügbarkeitszone innerhalb einer AWS-Region, Verwendung von Snapshots zur Datensicherung für Resilienz.",
            "3": "Verwenden Sie Amazon S3 mit Cross-Region-Replikation, um Daten über mehrere Verfügbarkeitszonen innerhalb einer einzigen Region zu spiegeln.",
            "4": "Globale Bereitstellung mit Amazon CloudFront-Edge-Standorten, um einen schnellen Zugriff mit niedriger Latenz zu gewährleisten, ohne vollständige Fehlertoleranz auf regionaler oder AZ-Ebene."
        },
        "Correct Answer": "Verwenden Sie Amazon Route 53 mit latenzbasiertem Routing, um Benutzer zur nächstgelegenen AWS-Region zu leiten, was die niedrige Latenz verbessert und regionale Fehlertoleranz ermöglicht.",
        "Explanation": "Amazon Route 53 ist ein hochverfügbarer und skalierbarer Domain Name System (DNS)-Webdienst, der latenzbasiertes Routing bietet. Diese Funktion ermöglicht es der Anwendung, Benutzer zur nächstgelegenen AWS-Region zu leiten, was die Latenz minimiert und die Leistung verbessert. Darüber hinaus stellt das Routing des Datenverkehrs zu verschiedenen Regionen sicher, dass Benutzer, wenn eine Region ausfällt, weiterhin auf die Anwendung aus einer anderen Region zugreifen können, wodurch regionale Fehlertoleranz und hohe Verfügbarkeit über geografische Standorte hinweg gewährleistet werden.",
        "Other Options": [
            "Die Bereitstellung der Anwendung in einer einzigen Verfügbarkeitszone innerhalb einer AWS-Region bietet nicht die notwendige Resilienz oder hohe Verfügbarkeit. Wenn diese AZ ausfällt, wäre die Anwendung vollständig nicht verfügbar, was den Anforderungen an die Fehlertoleranz widerspricht.",
            "Die Verwendung von Amazon S3 mit Cross-Region-Replikation adressiert nur die Datensicherheit und -verfügbarkeit, gewährleistet jedoch nicht die niedrige Latenz für Benutzer oder bietet eine anwendungsbezogene Fehlertoleranz. Es konzentriert sich hauptsächlich auf die Datenspeicherung und nicht auf die Anwendungsleistung über Regionen hinweg.",
            "Die globale Bereitstellung mit Amazon CloudFront-Edge-Standorten kann die Latenz bei der Inhaltsbereitstellung verbessern, bietet jedoch keine vollständige Fehlertoleranz auf regionaler oder AZ-Ebene. Wenn der Ursprungsserver in einer bestimmten Region ausfällt, können Benutzer dennoch Ausfallzeiten erleben, was nicht den Anforderungen an hohe Verfügbarkeit entspricht."
        ]
    },
    {
        "Question Number": "45",
        "Situation": "Ein Medienunternehmen muss Inhalte schnell an ein globales Publikum liefern, um die Latenz zu reduzieren und die Benutzererfahrung zu verbessern. Sie möchten auch Inhalte näher an den Benutzern zwischenspeichern, um die Last auf ihren Ursprungsservern zu verringern.",
        "Question": "Welcher AWS-Dienst würde diese Anforderungen am besten erfüllen und welchen Vorteil bietet er?",
        "Options": {
            "1": "Amazon CloudFront",
            "2": "Amazon S3",
            "3": "AWS Direct Connect",
            "4": "Amazon API Gateway"
        },
        "Correct Answer": "Amazon CloudFront",
        "Explanation": "Amazon CloudFront ist ein Content Delivery Network (CDN)-Dienst, der Inhalte an Edge-Standorten auf der ganzen Welt zwischenspeichert. Dies ermöglicht eine reduzierte Latenz und schnellere Bereitstellung von Inhalten an Benutzer, da die Inhalte von einem näheren Standort bereitgestellt werden. Durch das Zwischenspeichern von Inhalten näher an den Benutzern verringert CloudFront auch die Last auf den Ursprungsservern, was die Gesamtleistung und Benutzererfahrung verbessert. Dies macht es zur besten Wahl für das Medienunternehmen, das Inhalte schnell und effizient an ein globales Publikum liefern möchte.",
        "Other Options": [
            "Amazon S3 ist ein skalierbarer Speicher Dienst, der es ermöglicht, beliebige Datenmengen zu speichern und abzurufen. Während es zur Speicherung von Inhalten verwendet werden kann, bietet es nicht die Zwischenspeicher- und globalen Verteilungsfunktionen, die für die Reduzierung der Latenz und die Verbesserung der Benutzererfahrung in diesem Szenario entscheidend sind.",
            "AWS Direct Connect ist ein Dienst, der eine dedizierte Netzwerkverbindung von Ihren Räumlichkeiten zu AWS bereitstellt. Es wird hauptsächlich verwendet, um eine private Verbindung zu AWS-Diensten herzustellen, was die Bandbreite verbessern und die Latenz für Datenübertragungen verringern kann, jedoch nicht den Bedarf an Inhaltsbereitstellung und Zwischenspeicherung für ein globales Publikum adressiert.",
            "Amazon API Gateway ist ein Dienst zur Erstellung, Veröffentlichung und Verwaltung von APIs. Während es beim Aufbau serverloser Anwendungen und der Verwaltung von API-Aufrufen helfen kann, bietet es nicht die Inhaltsbereitstellungs- und Zwischenspeicherfähigkeiten, die erforderlich sind, um Medieninhalte schnell an ein globales Publikum zu liefern."
        ]
    },
    {
        "Question Number": "46",
        "Situation": "Ein Gesundheitsdienstleister speichert Patientendaten auf AWS und muss die Datenschutz- und Privatsphäre-Vorschriften einhalten, die strenge Zugriffskontrollen und das Management des Datenlebenszyklus erfordern. Der Anbieter muss sicherstellen, dass der Datenzugriff auf autorisierte Benutzer beschränkt ist, die Daten verschlüsselt sind und alte Daten gemäß den Richtlinien archiviert oder gelöscht werden.",
        "Question": "Welche Maßnahmen sollte der Gesundheitsdienstleister ergreifen, um Richtlinien für sicheren Datenzugriff, Lebenszyklusmanagement und Schutz umzusetzen?",
        "Options": {
            "1": "Verwenden Sie IAM-Richtlinien, um den Zugriff auf Daten zu steuern, implementieren Sie S3-Lebenszyklusrichtlinien, um das Altern von Daten zu verwalten, und konfigurieren Sie die Verschlüsselung über AWS KMS.",
            "2": "Speichern Sie alle Daten in Amazon Glacier, um sicherzustellen, dass sie archiviert werden, und löschen Sie Daten nach fünf Jahren automatisch.",
            "3": "Aktivieren Sie das AWS CloudTrail-Logging, um alle Daten automatisch zu archivieren und das Management des Datenlebenszyklus ohne zusätzliche Richtlinien sicherzustellen.",
            "4": "Verwenden Sie AWS Shield für das Lebenszyklusmanagement und zur Kontrolle des Zugriffs auf sensible Daten in Übereinstimmung mit den Vorschriften."
        },
        "Correct Answer": "Verwenden Sie IAM-Richtlinien, um den Zugriff auf Daten zu steuern, implementieren Sie S3-Lebenszyklusrichtlinien, um das Altern von Daten zu verwalten, und konfigurieren Sie die Verschlüsselung über AWS KMS.",
        "Explanation": "Diese Option ist korrekt, da sie umfassend die Bedürfnisse des Gesundheitsdienstleisters nach sicherem Datenzugriff, Lebenszyklusmanagement und Datenschutz anspricht. IAM (Identity and Access Management)-Richtlinien ermöglichen es dem Anbieter, festzulegen, wer auf bestimmte Daten zugreifen kann, und stellen sicher, dass nur autorisierte Benutzer Zugriff haben. S3-Lebenszyklusrichtlinien ermöglichen es dem Anbieter, den Übergang von Daten zu verschiedenen Speicherklassen zu automatisieren oder sie nach einem bestimmten Zeitraum zu löschen, wodurch das Altern von Daten effektiv verwaltet wird. Darüber hinaus gewährleistet die Verwendung von AWS KMS (Key Management Service) zur Verschlüsselung, dass die Daten sowohl im Ruhezustand als auch während der Übertragung geschützt sind und die Datenschutzvorschriften eingehalten werden.",
        "Other Options": [
            "Diese Option ist falsch, da das Speichern von Daten in Amazon Glacier zwar eine gute Möglichkeit ist, Daten zu archivieren, jedoch keine umfassende Lösung für Zugriffskontrolle oder Verschlüsselung bietet. Sie adressiert auch nicht die Notwendigkeit, den Datenzugriff oder Lebenszyklusrichtlinien über einfaches Archivieren und Löschen nach fünf Jahren hinaus zu verwalten.",
            "Diese Option ist falsch, da die Aktivierung des AWS CloudTrail-Loggings hauptsächlich für die Prüfung und Überwachung von API-Aufrufen gedacht ist und nicht direkt das Management des Datenlebenszyklus oder der Zugriffskontrolle verwaltet. CloudTrail archiviert keine Daten automatisch und erzwingt keine Lebenszyklusmanagementrichtlinien; es erfordert zusätzliche Konfigurationen, um diese Ziele zu erreichen.",
            "Diese Option ist falsch, da AWS Shield ein Dienst ist, der Anwendungen vor DDoS-Angriffen schützt und keine Funktionen für das Lebenszyklusmanagement oder die Zugriffskontrolle bietet. Sie adressiert nicht die spezifischen Bedürfnisse des Datenschutzes und der Compliance-Vorschriften, die im Szenario skizziert sind."
        ]
    },
    {
        "Question Number": "47",
        "Situation": "Ein E-Commerce-Unternehmen überarbeitet sein Bestellsystem, um Zuverlässigkeit und Skalierbarkeit zu verbessern. Das System muss ein hohes Bestellvolumen bewältigen und sicherstellen, dass jede Bestellung genau einmal verarbeitet wird, selbst im Falle von Komponentenfehlern.",
        "Question": "Welchen AWS-Dienst sollte der Lösungsarchitekt implementieren, um die Bestellung von den Verarbeitungs-Komponenten effektiv zu entkoppeln?",
        "Options": {
            "1": "Amazon SNS (Simple Notification Service)",
            "2": "Amazon SQS (Simple Queue Service)",
            "3": "AWS Step Functions",
            "4": "Amazon MQ"
        },
        "Correct Answer": "Amazon SQS (Simple Queue Service)",
        "Explanation": "Amazon SQS ist ein vollständig verwalteter Nachrichtenwarteschlangen-Dienst, der die Entkopplung von Microservices, verteilten Systemen und serverlosen Anwendungen ermöglicht. Er erlaubt es der Bestellkomponente, Nachrichten an eine Warteschlange zu senden, die dann unabhängig von der Verarbeitungs-Komponente verarbeitet werden kann. Dies stellt sicher, dass jede Bestellung genau einmal verarbeitet wird, selbst im Falle von Komponentenfehlern, da SQS eine mindestens-einmal-Zustellung bietet und für eine genau-einmal-Verarbeitung mit den Funktionen zur Duplikatsvermeidung konfiguriert werden kann. Darüber hinaus kann SQS ein hohes Nachrichtenvolumen verarbeiten, was es für die Skalierbarkeitsanforderungen des E-Commerce-Systems geeignet macht.",
        "Other Options": [
            "Amazon SNS (Simple Notification Service) wird hauptsächlich für Pub/Sub-Nachrichten verwendet und ist nicht dafür ausgelegt, die Bestellung von der Verarbeitung so zu entkoppeln, dass eine genau-einmal-Verarbeitung gewährleistet ist. SNS eignet sich besser für die Übertragung von Nachrichten an mehrere Abonnenten als für das Warten von Nachrichten zur Verarbeitung.",
            "AWS Step Functions ist ein serverloser Orchestrierungsdienst, der es ermöglicht, mehrere AWS-Dienste in serverlosen Workflows zu koordinieren. Während er komplexe Workflows verwalten kann, ist er nicht speziell für die Entkopplung von Komponenten wie SQS konzipiert. Er eignet sich besser für die Orchestrierung von Aufgaben als für die Handhabung von Nachrichtenwarteschlangen.",
            "Amazon MQ ist ein verwalteter Nachrichtenbroker-Dienst, der verschiedene Messaging-Protokolle unterstützt. Während er zur Entkopplung von Komponenten verwendet werden kann, ist er komplexer einzurichten und zu verwalten als SQS. Darüber hinaus bietet er möglicherweise nicht das gleiche Maß an Skalierbarkeit und Zuverlässigkeit für die Verarbeitung von Bestellungen mit hohem Volumen wie SQS."
        ]
    },
    {
        "Question Number": "48",
        "Situation": "Ein Medienunternehmen nutzt Amazon RDS für mehrere Anwendungen in verschiedenen Abteilungen. Sie möchten die Datenbankkosten jeder Abteilung verfolgen und zuordnen, um die Ausgaben zu verstehen und die Nutzung zu optimieren.",
        "Question": "Welche AWS-Kostenmanagementfunktion würde ihnen am besten helfen, dies zu erreichen? (Wählen Sie zwei aus.)",
        "Options": {
            "1": "Aktivieren Sie die Abrechnung über mehrere Konten in den Abteilungen",
            "2": "Wenden Sie Kostenverteilungstags auf jede RDS-Datenbankinstanz nach Abteilung an",
            "3": "Richten Sie separate AWS Budgets für jede Abteilung ein",
            "4": "Verwenden Sie die AWS Free Tier für alle Abteilungsdatenbanken",
            "5": "Implementieren Sie AWS Cost Categories, um Kosten basierend auf abteilungsspezifischen Kriterien zu gruppieren"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Wenden Sie Kostenverteilungstags auf jede RDS-Datenbankinstanz nach Abteilung an",
            "Implementieren Sie AWS Cost Categories, um Kosten basierend auf abteilungsspezifischen Kriterien zu gruppieren"
        ],
        "Explanation": "Das Anwenden von Kostenverteilungstags auf jede RDS-Datenbankinstanz nach Abteilung ermöglicht es dem Unternehmen, die Kosten jeder Abteilung zu verfolgen und zuzuordnen. Diese Tags können verwendet werden, um Kosten in detaillierten Abrechnungsberichten zu kategorisieren. AWS Cost Categories können verwendet werden, um Kosten basierend auf abteilungsspezifischen Kriterien zu gruppieren. Dies ermöglicht es dem Unternehmen, anzupassen, wie sie Kosten anzeigen und verwalten, und kann ihnen helfen, die Kosten zu verstehen, die mit der Nutzung von AWS-Ressourcen jeder Abteilung verbunden sind.",
        "Other Options": [
            "Die Aktivierung der Abrechnung über mehrere Konten in den Abteilungen ist nicht die beste Lösung, da dies erfordern würde, dass jede Abteilung ihr eigenes AWS-Konto hat, was möglicherweise nicht praktikabel oder effizient ist. Diese Option hilft auch nicht direkt, die Kosten jeder Abteilung zu verfolgen und zuzuordnen.",
            "Das Einrichten separater AWS Budgets für jede Abteilung könnte helfen, die Kosten zu verwalten, aber es hilft nicht direkt, die Kosten jeder Abteilung zu verfolgen und zuzuordnen. Es geht mehr darum, Ausgabenlimits festzulegen und zu verwalten, als Kosten zu verfolgen und zuzuordnen.",
            "Die Verwendung der AWS Free Tier für alle Abteilungsdatenbanken ist keine praktikable Lösung, da die Free Tier Nutzungslimits hat und ein Medienunternehmen mit mehreren Anwendungen in verschiedenen Abteilungen wahrscheinlich diese Limits überschreiten wird. Darüber hinaus hilft diese Option nicht bei der Verfolgung und Zuordnung von Kosten."
        ]
    },
    {
        "Question Number": "49",
        "Situation": "Eine Organisation muss einem Drittanbieter vorübergehenden Zugriff auf bestimmte Ressourcen innerhalb ihres AWS-Kontos gewähren. Der Zugriff des Anbieters sollte auf eine bestimmte Dauer beschränkt sein, und die Organisation möchte sicherstellen, dass der Anbieter sich nicht direkt als IAM-Benutzer anmelden kann.",
        "Question": "Welche Ansätze sollte die Organisation wählen, um dem Anbieter sicheren, vorübergehenden Zugriff zu gewähren? (Wählen Sie zwei aus.)",
        "Options": {
            "1": "Erstellen Sie einen IAM-Benutzer für den Anbieter mit den erforderlichen Berechtigungen und löschen Sie das Benutzerkonto, sobald der Zugriff nicht mehr benötigt wird.",
            "2": "Richten Sie eine IAM-Gruppe mit den erforderlichen Berechtigungen ein, fügen Sie den Anbieter zur Gruppe hinzu und entfernen Sie ihn, sobald der Zugriff nicht mehr erforderlich ist.",
            "3": "Verwenden Sie IAM-Rollen und den Secure Token Service (STS), um dem Anbieter vorübergehenden Zugriff durch Rollenübernahme zu gewähren.",
            "4": "Fügen Sie der Root-Konto-Richtlinie vorübergehend eine Berechtigung hinzu, um dem Anbieter Zugriff zu gewähren, und entfernen Sie sie nach der erforderlichen Dauer.",
            "5": "Verwenden Sie AWS IAM Identity Center (AWS Single Sign-On), um dem Anbieter eine vorübergehende Zugriffsrolle zuzuweisen."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Verwenden Sie IAM-Rollen und den Secure Token Service (STS), um dem Anbieter vorübergehenden Zugriff durch Rollenübernahme zu gewähren.",
            "Verwenden Sie AWS IAM Identity Center (AWS Single Sign-On), um dem Anbieter eine vorübergehende Zugriffsrolle zuzuweisen."
        ],
        "Explanation": "IAM-Rollen und der Secure Token Service (STS) sind dafür ausgelegt, vorübergehenden Zugriff auf AWS-Ressourcen zu gewähren. Durch die Rollenübernahme kann dem Anbieter die erforderliche Berechtigung gewährt werden, ohne einen dauerhaften IAM-Benutzer erstellen zu müssen. Die Berechtigungen können einfach durch Entfernen der Rolle widerrufen werden. AWS IAM Identity Center (AWS Single Sign-On) ermöglicht ebenfalls die Zuweisung von vorübergehendem Zugriff, der widerrufen werden kann, sobald der Zugriff des Anbieters nicht mehr benötigt wird. Beide Methoden stellen sicher, dass der Anbieter sich nicht direkt als IAM-Benutzer anmelden kann, was den Anforderungen der Organisation entspricht.",
        "Other Options": [
            "Einen IAM-Benutzer für den Anbieter zu erstellen und ihn zu löschen, sobald der Zugriff nicht mehr benötigt wird, ist kein empfohlener Ansatz, da dies die Erstellung und Verwaltung permanenter IAM-Benutzer beinhaltet, was ein Sicherheitsrisiko darstellen kann. Darüber hinaus verhindert dies nicht, dass der Anbieter sich direkt als IAM-Benutzer anmeldet.",
            "Das Einrichten einer IAM-Gruppe und das Hinzufügen des Anbieters zur Gruppe ist ebenfalls kein empfohlener Ansatz. Während es ermöglicht, Berechtigungen auf Gruppenebene zu verwalten, beinhaltet es dennoch die Erstellung eines permanenten IAM-Benutzers für den Anbieter, was in diesem Szenario nicht gewünscht ist.",
            "Das Anhängen einer Richtlinie an das Root-Konto, um dem Anbieter vorübergehend Zugriff zu gewähren, ist keine gute Praxis. Das Root-Konto hat vollen Zugriff auf alle Ressourcen im AWS-Konto, und es wird nicht empfohlen, es für alltägliche Interaktionen oder zur Gewährung vorübergehenden Zugriffs an Dritte zu verwenden."
        ]
    },
    {
        "Question Number": "50",
        "Situation": "Ein Medienproduktionsunternehmen muss 20 PB archiviertes hochauflösendes Videomaterial von seinem lokalen Speicher zu AWS für die langfristige Speicherung und gelegentliche Verarbeitung migrieren. Die Daten befinden sich an mehreren Standorten, und das Unternehmen bevorzugt eine Lösung, die sowohl kosteneffektiv ist als auch während des Übertragungsprozesses einige Datenverarbeitungsfähigkeiten bietet.",
        "Question": "Welche AWS-Datenmigrationslösung würde am besten zu den Bedürfnissen des Unternehmens passen?",
        "Options": {
            "1": "AWS Snowball mit 80 TB Geräten",
            "2": "AWS Snowball Edge mit speicheroptimierten Geräten",
            "3": "AWS Snowmobile",
            "4": "AWS Direct Connect mit einer dedizierten Verbindung"
        },
        "Correct Answer": "AWS Snowball Edge mit speicheroptimierten Geräten",
        "Explanation": "AWS Snowball Edge mit speicheroptimierten Geräten ist die beste Lösung für die Bedürfnisse des Unternehmens, da es den Transfer großer Datenmengen (bis zu 100 TB pro Gerät) ermöglicht und gleichzeitig Verarbeitungsfähigkeiten vor Ort bietet. Das bedeutet, dass das Unternehmen während des Transfers einige Datenverarbeitungen durchführen kann, was angesichts ihres Bedarfs an gelegentlicher Verarbeitung des archivierten Materials unerlässlich ist. Darüber hinaus sind Snowball Edge-Geräte für Edge-Computing konzipiert, was sie geeignet macht, Daten effizient über mehrere Standorte hinweg zu handhaben.",
        "Other Options": [
            "AWS Snowball mit 80 TB Geräten ist nicht die beste Option, da es große Datenübertragungen bewältigen kann, jedoch nicht das gleiche Maß an Verarbeitungsfähigkeiten bietet wie Snowball Edge-Geräte. Das Unternehmen benötigt speziell einige Verarbeitungsfähigkeiten während des Transfers, die Snowball nicht bietet.",
            "AWS Snowmobile ist eine praktikable Option für extrem große Datenmigrationen (bis zu 100 PB), eignet sich jedoch besser für Szenarien, in denen die Daten an einem einzigen Standort liegen und einen großangelegten physischen Transfer erfordern. Da die Daten über mehrere Standorte verteilt sind und das Unternehmen eine flexiblere Lösung bevorzugt, ist Snowmobile nicht die beste Wahl.",
            "AWS Direct Connect bietet eine dedizierte Netzwerkverbindung zu AWS, die den Datentransfer erleichtern kann, jedoch nicht von Natur aus ein Mittel bietet, um große Datenmengen effizient zu migrieren oder Verarbeitungsfähigkeiten während des Transfers anzubieten. Diese Option wäre wahrscheinlich kostspieliger und weniger effektiv für die spezifischen Bedürfnisse des Unternehmens im Vergleich zur Verwendung von Snowball Edge."
        ]
    },
    {
        "Question Number": "51",
        "Situation": "Ein Unternehmen konfiguriert die Netzwerksicherheit für seine AWS-Umgebung und möchte das Verhalten von zustandsbehafteten und zustandslosen Firewalls verstehen. Das Sicherheitsteam muss es den Clients ermöglichen, HTTPS-Verbindungen zum Webserver des Unternehmens herzustellen und sicherstellen, dass die Antworten korrekt zurückgegeben werden.",
        "Question": "Wie sollte das Unternehmen die Sicherheitsregeln konfigurieren, um diese Verbindung zu ermöglichen und den Unterschied zwischen zustandsbehaftetem und zustandslosem Filtern zu verstehen?",
        "Options": {
            "1": "Verwenden Sie eine zustandsbehaftete Firewall, die automatisch eingehende Antworten auf eine ausgehende Anfrage zulässt, und konfigurieren Sie nur eine ausgehende Regel für HTTPS (Port 443) vom Client zum Server.",
            "2": "Verwenden Sie eine zustandslose Firewall und konfigurieren Sie sowohl ausgehende als auch eingehende Regeln auf Port 443, um HTTPS-Verkehr vom Client zum Server und die Antwort vom Server zum Client zuzulassen.",
            "3": "Verwenden Sie eine zustandsbehaftete Firewall und konfigurieren Sie sowohl ausgehende als auch eingehende Regeln auf Port 443, da zustandsbehaftete Firewalls nicht automatisch Verbindungszustände verfolgen.",
            "4": "Verwenden Sie eine zustandslose Firewall und konfigurieren Sie nur eine eingehende Regel auf Port 443, da die ausgehende Antwort automatisch zugelassen wird."
        },
        "Correct Answer": "Verwenden Sie eine zustandsbehaftete Firewall, die automatisch eingehende Antworten auf eine ausgehende Anfrage zulässt, und konfigurieren Sie nur eine ausgehende Regel für HTTPS (Port 443) vom Client zum Server.",
        "Explanation": "Eine zustandsbehaftete Firewall verfolgt den Zustand aktiver Verbindungen und erlaubt automatisch den Rückverkehr für etablierte Verbindungen. In diesem Szenario wird die zustandsbehaftete Firewall die eingehende Antwort vom Server zurück zum Client zulassen, ohne dass eine separate eingehende Regel erforderlich ist, wenn ein Client eine HTTPS-Verbindung zum Webserver initiiert. Daher ist nur eine ausgehende Regel für den HTTPS-Verkehr vom Client zum Server erforderlich, da die zustandsbehaftete Firewall den entsprechenden eingehenden Verkehr automatisch verarbeitet.",
        "Other Options": [
            "Die Verwendung einer zustandslosen Firewall erfordert explizite Regeln für sowohl eingehenden als auch ausgehenden Verkehr. Daher würde die Konfiguration nur einer ausgehenden Regel für HTTPS nicht zulassen, dass die Antwort des Servers den Client erreicht, da die zustandslose Firewall die Verbindungszustände nicht verfolgt und die eingehende Antwort blockieren würde.",
            "Diese Option gibt fälschlicherweise an, dass zustandsbehaftete Firewalls Verbindungszustände nicht automatisch verfolgen. Tatsächlich verfolgen zustandsbehaftete Firewalls Verbindungszustände, weshalb nur eine ausgehende Regel für die ursprüngliche Anfrage erforderlich ist, um die eingehende Antwort automatisch zuzulassen.",
            "Diese Option ist falsch, da eine zustandslose Firewall ausgehende Antworten nicht automatisch zulässt. Sie erfordert explizite Regeln für beide Richtungen. Die Konfiguration nur einer eingehenden Regel würde nicht zulassen, dass die Antwort des Servers den Client erreicht, da die ausgehende Anfrage keine entsprechende Regel hätte, um den Rückverkehr zuzulassen."
        ]
    },
    {
        "Question Number": "52",
        "Situation": "Ein Einzelhandelsunternehmen möchte Echtzeit-Clickstream-Daten von seiner stark frequentierten E-Commerce-Website sammeln, um das Nutzerverhalten zu analysieren und das Kundenengagement zu verbessern. Die Daten müssen in Echtzeit transformiert werden, einschließlich Datenbereinigung und -tagging, bevor sie an Amazon Redshift für Analysen und Amazon S3 für die langfristige Archivierung geliefert werden. Das Unternehmen sucht nach einer verwalteten, skalierbaren Lösung, die einen kontinuierlichen Datenfluss mit minimalem Betriebsaufwand und Echtzeit-Transformationsfähigkeiten bewältigen kann.",
        "Question": "Welche AWS-Dienstkonfiguration würde diese Anforderungen am besten erfüllen?",
        "Options": {
            "1": "Verwenden Sie Amazon Kinesis Data Streams in Verbindung mit AWS Lambda, um Daten in Echtzeit zu transformieren und dann an Amazon S3 zur Speicherung zu liefern.",
            "2": "Implementieren Sie Amazon Kinesis Data Firehose mit einer AWS Lambda-Funktion für die Echtzeit-Transformation und konfigurieren Sie es so, dass die transformierten Daten sowohl an Amazon Redshift als auch an Amazon S3 geliefert werden.",
            "3": "Verwenden Sie Amazon S3 als Hauptdatenspeicher und verarbeiten Sie Datenumwandlungen im Batch mit AWS Glue, bevor Sie sie in Amazon Redshift laden.",
            "4": "Richten Sie Amazon Managed Streaming für Apache Kafka ein, um die Streaming-Datenaufnahme zu verwalten, wobei AWS Lambda die Transformation durchführt und die Daten dann an Redshift liefert."
        },
        "Correct Answer": "Implementieren Sie Amazon Kinesis Data Firehose mit einer AWS Lambda-Funktion für die Echtzeit-Transformation und konfigurieren Sie es so, dass die transformierten Daten sowohl an Amazon Redshift als auch an Amazon S3 geliefert werden.",
        "Explanation": "Amazon Kinesis Data Firehose ist speziell für die Echtzeit-Datenaufnahme und -transformation konzipiert. Es ermöglicht eine nahtlose Integration mit AWS Lambda, das zur Durchführung der erforderlichen Datenbereinigung und -tagging in Echtzeit verwendet werden kann. Diese Konfiguration ermöglicht es dem Einzelhandelsunternehmen, Clickstream-Daten effizient in Echtzeit zu sammeln und zu verarbeiten und die transformierten Daten sowohl an Amazon Redshift für Analysen als auch an Amazon S3 für die langfristige Speicherung zu liefern. Diese Lösung ist verwaltet und skalierbar, minimiert den Betriebsaufwand und erfüllt die Anforderung an einen kontinuierlichen Datenfluss.",
        "Other Options": [
            "Die Verwendung von Amazon Kinesis Data Streams mit AWS Lambda ist eine praktikable Option für die Echtzeit-Datenverarbeitung; jedoch sind zusätzliche Schritte erforderlich, um die Datenlieferung sowohl an Amazon Redshift als auch an Amazon S3 zu verwalten, was es weniger unkompliziert macht als die Verwendung von Kinesis Data Firehose, die dies direkt handhaben kann.",
            "Die Verwendung von Amazon S3 als Hauptdatenspeicher und die Batch-Verarbeitung von Datenumwandlungen mit AWS Glue erfüllt nicht die Anforderung an die Echtzeit-Datenumwandlung, da sie auf Batch-Verarbeitung angewiesen ist, die Latenz einführt und nicht für kontinuierlichen Datenfluss geeignet ist.",
            "Die Einrichtung von Amazon Managed Streaming für Apache Kafka kann die Streaming-Datenaufnahme effektiv verwalten, fügt jedoch im Vergleich zu Kinesis Data Firehose Komplexität in Bezug auf Verwaltung und Betriebsaufwand hinzu. Darüber hinaus wären mehr Konfigurationen erforderlich, um es mit AWS Lambda für Transformationen zu integrieren und Daten an Redshift zu liefern."
        ]
    },
    {
        "Question Number": "53",
        "Situation": "Eine Finanzinstitution betreibt geschäftskritische Anwendungen, die stabile, hochbandbreitige und latenzarme Verbindungen zwischen ihren lokalen Rechenzentren und AWS erfordern, um die Echtzeit-Datenverarbeitung und Handelsaktivitäten zu unterstützen. Sie möchten sicherstellen, dass alle Datenübertragungen über eine sichere, private Verbindung erfolgen, die das öffentliche Internet umgeht, um potenzielle Sicherheitsrisiken und Leistungsvariabilität zu vermeiden.",
        "Question": "Welche Option würde am besten ihren Anforderungen entsprechen?",
        "Options": {
            "1": "Verwendung einer Hochgeschwindigkeits-Leitung von einem Telekommunikationsanbieter direkt zu AWS.",
            "2": "Einrichtung eines AWS Site-to-Site VPN über das öffentliche Internet.",
            "3": "Bereitstellung von AWS Direct Connect für eine private, dedizierte Netzwerkverbindung.",
            "4": "Einrichtung eines verschlüsselten Dateiübertragungsprotokolls (FTP) für periodische Datensynchronisationen."
        },
        "Correct Answer": "Bereitstellung von AWS Direct Connect für eine private, dedizierte Netzwerkverbindung.",
        "Explanation": "AWS Direct Connect bietet eine dedizierte, private Verbindung zwischen den lokalen Rechenzentren und AWS. Diese Option erfüllt die Anforderungen der Finanzinstitution an stabile, hochbandbreitige und latenzarme Verbindungen, die für geschäftskritische Anwendungen wie die Echtzeit-Datenverarbeitung und den Handel unerlässlich sind. Direct Connect umgeht das öffentliche Internet, was Sicherheitsrisiken und Leistungsvariabilität erheblich reduziert und es zur besten Wahl für sichere und zuverlässige Datenübertragungen macht.",
        "Other Options": [
            "Die Verwendung einer Hochgeschwindigkeits-Leitung von einem Telekommunikationsanbieter direkt zu AWS kann eine hohe Bandbreite bieten, garantiert jedoch nicht dasselbe Maß an Integration und Zuverlässigkeit wie AWS Direct Connect. Darüber hinaus kann es höhere Kosten und Komplexität bei der Einrichtung und Verwaltung mit sich bringen.",
            "Die Einrichtung eines AWS Site-to-Site VPN über das öffentliche Internet bietet Verschlüsselung und Sicherheit, erfüllt jedoch nicht die Anforderungen an niedrige Latenz und hohe Bandbreite, die für Echtzeitanwendungen erforderlich sind. VPNs können auch von Leistungsvariabilität betroffen sein, da sie auf das öffentliche Internet angewiesen sind.",
            "Die Einrichtung eines verschlüsselten Dateiübertragungsprotokolls (FTP) für periodische Datensynchronisationen erfüllt nicht die Anforderungen an die Echtzeit-Datenverarbeitung und Handelsaktivitäten. Diese Methode eignet sich besser für die Batch-Verarbeitung als für kontinuierliche, latenzarme Datenübertragungen, die für die Abläufe der Institution entscheidend sind."
        ]
    },
    {
        "Question Number": "54",
        "Situation": "Ein Unternehmen hat zwei AWS-Konten: ein Entwicklungs- und ein Produktionskonto. Entwickler im Entwicklungsaccount benötigen vorübergehenden Zugriff auf bestimmte Ressourcen im Produktionskonto zu Testzwecken. Das Unternehmen möchte das Prinzip der minimalen Berechtigung durchsetzen und sicherstellen, dass Entwickler nur für eine begrenzte Zeit auf die erforderlichen Ressourcen zugreifen können.",
        "Question": "Welchen Ansatz sollte das Unternehmen verwenden, um dieses Erfordernis zu erfüllen?",
        "Options": {
            "1": "Erstellen Sie IAM-Benutzer im Produktionskonto und fügen Sie Richtlinien hinzu, die den Zugriff auf die erforderlichen Ressourcen gewähren.",
            "2": "Verwenden Sie den AWS Security Token Service (STS), um temporäre Sicherheitsanmeldeinformationen zu erstellen, die es Entwicklern ermöglichen, eine Rolle im Produktionskonto mit Berechtigungen für den Zugriff auf die erforderlichen Ressourcen zu übernehmen.",
            "3": "Richten Sie den Zugriff über Konten hinweg ein, indem Sie eine IAM-Gruppe im Entwicklungsaccount erstellen und eine Richtlinie anhängen, die den Zugriff auf Ressourcen im Produktionskonto gewährt.",
            "4": "Verwenden Sie AWS Organizations, um Berechtigungen automatisch vom Entwicklungsaccount auf das Produktionskonto für alle Entwickler zu replizieren."
        },
        "Correct Answer": "Verwenden Sie den AWS Security Token Service (STS), um temporäre Sicherheitsanmeldeinformationen zu erstellen, die es Entwicklern ermöglichen, eine Rolle im Produktionskonto mit Berechtigungen für den Zugriff auf die erforderlichen Ressourcen zu übernehmen.",
        "Explanation": "Die Verwendung des AWS Security Token Service (STS) zur Erstellung temporärer Sicherheitsanmeldeinformationen ist der beste Ansatz für dieses Szenario, da es Entwicklern ermöglicht, eine Rolle im Produktionskonto mit spezifischen Berechtigungen zu übernehmen. Diese Methode entspricht dem Prinzip der minimalen Berechtigung, indem sie den Zugriff nur auf die erforderlichen Ressourcen für eine begrenzte Zeit gewährt. Die von STS bereitgestellten temporären Anmeldeinformationen laufen nach einer bestimmten Dauer ab, wodurch sichergestellt wird, dass der Zugriff nicht dauerhaft ist und das Risiko eines unbefugten Zugriffs auf Produktionsressourcen verringert wird.",
        "Other Options": [
            "Das Erstellen von IAM-Benutzern im Produktionskonto und das Anhängen von Richtlinien, die den Zugriff auf die erforderlichen Ressourcen gewähren, ist nicht ideal, da es die Erstellung permanenter Benutzerkonten erfordern würde, was dem Prinzip der minimalen Berechtigung widerspricht und keinen temporären Zugriff bietet.",
            "Das Einrichten des Zugriffs über Konten hinweg, indem eine IAM-Gruppe im Entwicklungsaccount erstellt und eine Richtlinie angehängt wird, die den Zugriff auf Ressourcen im Produktionskonto gewährt, ist falsch, da IAM-Gruppen keine Berechtigungen über Konten hinweg direkt unterstützen. Stattdessen sollten Rollen für den Zugriff über Konten hinweg verwendet werden.",
            "Die Verwendung von AWS Organizations, um Berechtigungen automatisch vom Entwicklungsaccount auf das Produktionskonto für alle Entwickler zu replizieren, ist nicht geeignet, da sie breiteren Zugriff gewähren würde, als notwendig, und damit das Prinzip der minimalen Berechtigung verletzt. Dieser Ansatz erlaubt keine feingranulare Kontrolle, die für den temporären Zugriff erforderlich ist."
        ]
    },
    {
        "Question Number": "55",
        "Situation": "Ein Unternehmen möchte eine skalierbare Anwendungsarchitektur entwerfen, die hohe Volumina an asynchronen Aufgaben bewältigen kann und erfordert, dass Komponenten ohne direkte Abhängigkeiten voneinander kommunizieren.",
        "Question": "Welcher AWS-Dienst wäre am besten geeignet, um eine lose gekoppelte, ereignisgesteuerte Architektur zu implementieren, und warum?",
        "Options": {
            "1": "Amazon SQS",
            "2": "Amazon RDS",
            "3": "Amazon DynamoDB",
            "4": "AWS Lambda"
        },
        "Correct Answer": "Amazon SQS",
        "Explanation": "Amazon SQS (Simple Queue Service) ist speziell für die Entkopplung von Komponenten einer verteilten Anwendung konzipiert. Es ermöglicht die asynchrone Kommunikation zwischen verschiedenen Teilen einer Anwendung durch die Verwendung von Nachrichtenwarteschlangen. Das bedeutet, dass Komponenten Nachrichten an die Warteschlange senden können, ohne die anderen Komponenten zu kennen, die diese Nachrichten verarbeiten werden, wodurch eine lose gekoppelte Architektur ermöglicht wird. SQS kann hohe Volumina an Nachrichten verarbeiten, was es für Anwendungen geeignet macht, die Skalierbarkeit und Zuverlässigkeit bei der Verarbeitung asynchroner Aufgaben erfordern.",
        "Other Options": [
            "Amazon RDS (Relational Database Service) ist ein verwalteter relationaler Datenbankdienst, der hauptsächlich zum Speichern strukturierter Daten verwendet wird. Er bietet nicht die ereignisgesteuerte Architektur oder die Entkopplung von Komponenten, die SQS bietet, da er direkte Verbindungen zwischen der Anwendung und der Datenbank erfordert.",
            "Amazon DynamoDB ist ein NoSQL-Datenbankdienst, der schnelle und vorhersehbare Leistung mit nahtloser Skalierbarkeit bietet. Während es hohe Volumina an Daten verarbeiten kann, ist es nicht speziell für die Verwaltung asynchroner Aufgaben oder für die Entkopplung von Komponenten in einer ereignisgesteuerten Architektur wie SQS konzipiert.",
            "AWS Lambda ist ein serverloser Compute-Dienst, der Code als Reaktion auf Ereignisse ausführt. Während es Teil einer ereignisgesteuerten Architektur sein kann, dient es nicht selbst als Messaging-Dienst. Es wird oft in Verbindung mit SQS oder anderen Diensten verwendet, um Nachrichten zu verarbeiten, bietet jedoch nicht den Warteschlangenmechanismus, der eine lose Kopplung zwischen Komponenten ermöglicht."
        ]
    },
    {
        "Question Number": "56",
        "Situation": "Ein Solutions Architect muss sicherstellen, dass nur bestimmte IAM-Rollen innerhalb des AWS-Kontos des Unternehmens auf spezifische sensible Daten zugreifen können, die in Amazon S3 gespeichert sind. Das Unternehmen folgt einem strengen Prinzip des minimalen Zugriffs.",
        "Question": "Welche Methode ist am BESTEN geeignet, um diese Anforderung durchzusetzen?",
        "Options": {
            "1": "Verwenden Sie S3-Bucket-Richtlinien, die den Zugriff nur für bestimmte IAM-Rollen gewähren",
            "2": "Aktivieren Sie MFA Delete für den S3-Bucket",
            "3": "Konfigurieren Sie einen Amazon CloudWatch-Alarm für unbefugte Zugriffsversuche",
            "4": "Aktivieren Sie S3 Transfer Acceleration"
        },
        "Correct Answer": "Verwenden Sie S3-Bucket-Richtlinien, die den Zugriff nur für bestimmte IAM-Rollen gewähren",
        "Explanation": "Die Verwendung von S3-Bucket-Richtlinien, um den Zugriff nur für bestimmte IAM-Rollen zu gewähren, ist die am besten geeignete Methode, um die Anforderung zur Einschränkung des Zugriffs auf sensible Daten durchzusetzen. Bucket-Richtlinien ermöglichen eine feingranulare Kontrolle darüber, wer auf die in dem S3-Bucket gespeicherten Daten zugreifen kann, was mit dem Prinzip des minimalen Zugriffs übereinstimmt. Durch die Angabe, welche IAM-Rollen auf den Bucket zugreifen können, kann der Solutions Architect sicherstellen, dass nur autorisierte Rollen die erforderlichen Berechtigungen zum Zugriff auf sensible Daten haben, wodurch die Sicherheit erhöht wird.",
        "Other Options": [
            "Die Aktivierung von MFA Delete für den S3-Bucket ist eine Sicherheitsfunktion, die das versehentliche Löschen von Objekten im Bucket verhindert und eine Multi-Faktor-Authentifizierung für Löschvorgänge erfordert. Obwohl es eine zusätzliche Sicherheitsebene bietet, kontrolliert es nicht den Zugriff auf die Daten selbst, was es weniger relevant für die Anforderung macht, den Zugriff basierend auf IAM-Rollen einzuschränken.",
            "Die Konfiguration eines Amazon CloudWatch-Alarms für unbefugte Zugriffsversuche kann helfen, verdächtige Aktivitäten zu überwachen und zu melden, verhindert jedoch keinen Zugriff. Dieser Ansatz konzentriert sich eher auf die Erkennung als auf die Durchsetzung der Zugriffskontrolle, was in diesem Szenario die Hauptsorge ist.",
            "Die Aktivierung von S3 Transfer Acceleration verbessert die Geschwindigkeit des Datentransfers zu und von S3, hat jedoch nichts mit der Zugriffskontrolle zu tun. Diese Option adressiert nicht die Anforderung, den Zugriff auf sensible Daten basierend auf IAM-Rollen einzuschränken."
        ]
    },
    {
        "Question Number": "57",
        "Situation": "Ein Online-Nachrichtenportal erhält täglich Millionen von Benutzerinteraktionen, einschließlich Klicks, Ansichten und Shares. Diese Interaktionen müssen in Echtzeit für Analysen und personalisierte Inhaltsbereitstellung erfasst werden. Das Unternehmen erwartet, dass das Volumen der Interaktionen im nächsten Jahr schnell wachsen wird.",
        "Question": "Welches Datenaufnahme-Muster sollte der Solutions Architect entwerfen, um dieses Szenario effektiv zu bewältigen?",
        "Options": {
            "1": "Batch-Aufnahme mit täglichen Datenübertragungen",
            "2": "Echtzeit-Streaming-Aufnahme",
            "3": "Manuelle Daten-Uploads über die AWS Management Console",
            "4": "Geplante Aufnahme mit AWS Data Pipeline"
        },
        "Correct Answer": "Echtzeit-Streaming-Aufnahme",
        "Explanation": "Die Echtzeit-Streaming-Aufnahme ist das am besten geeignete Muster für dieses Szenario, da das Online-Nachrichtenportal eine sofortige Verarbeitung von Benutzerinteraktionen wie Klicks, Ansichten und Shares erfordert. Angesichts des erwarteten schnellen Wachstums des Interaktionsvolumens ermöglicht ein Echtzeitzugang einen kontinuierlichen Datenfluss und sofortige Analysen, die eine personalisierte Inhaltsbereitstellung und zeitnahe Einblicke ermöglichen. Diese Methode stellt sicher, dass Daten verarbeitet werden, sobald sie ankommen, was entscheidend ist, um ein ansprechendes Benutzererlebnis aufrechtzuerhalten und sich in Echtzeit an das Benutzerverhalten anzupassen.",
        "Other Options": [
            "Batch-Aufnahme mit täglichen Datenübertragungen ist für dieses Szenario nicht geeignet, da sie das Sammeln von Daten über einen Zeitraum und die Verarbeitung auf einmal umfasst. Dies würde zu Verzögerungen bei Analysen und Inhaltsbereitstellung führen, was für eine Plattform, die auf Echtzeit-Benutzerinteraktionen angewiesen ist, nicht geeignet ist.",
            "Manuelle Daten-Uploads über die AWS Management Console sind unpraktisch für die Verarbeitung von Millionen täglicher Interaktionen. Diese Methode ist arbeitsintensiv und skaliert nicht gut, was sie für eine Umgebung mit hohem Volumen, in der Automatisierung und Geschwindigkeit entscheidend sind, ungeeignet macht.",
            "Geplante Aufnahme mit AWS Data Pipeline kann ein gewisses Maß an Automatisierung bieten, funktioniert jedoch weiterhin nach einem vordefinierten Zeitplan und nicht in Echtzeit. Dies würde den Anforderungen des Nachrichtenportals an eine sofortige Datenverarbeitung nicht gerecht werden und könnte zu veralteten Analysen und Inhaltsbereitstellungen führen."
        ]
    },
    {
        "Question Number": "58",
        "Situation": "Ein Startup baut eine Echtzeitanalyseplattform auf AWS. Die Plattform muss Daten von Tausenden von IoT-Geräten erfassen, die Daten in Echtzeit verarbeiten und die verarbeiteten Daten für weitere Analysen speichern. Die Lösung muss hochgradig skalierbar sein und den Betriebsaufwand minimieren.",
        "Question": "Welche Kombination von AWS-Diensten sollte der Solutions Architect verwenden, um diese Plattform zu erstellen? (Wählen Sie ZWEI.)",
        "Options": {
            "1": "AWS Lambda",
            "2": "Amazon Kinesis Data Streams",
            "3": "Amazon RDS für MySQL",
            "4": "Amazon S3",
            "5": "Amazon QuickSight"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "AWS Lambda",
            "Amazon Kinesis Data Streams"
        ],
        "Explanation": "AWS Lambda ist ein serverloser Compute-Service, der es Ihnen ermöglicht, Ihren Code auszuführen, ohne Server bereitzustellen oder zu verwalten. Er kann verwendet werden, um die Daten in Echtzeit zu verarbeiten, was eine Anforderung in dem gegebenen Szenario ist. Amazon Kinesis Data Streams ist ein skalierbarer und langlebiger Echtzeit-Datenstreaming-Service, der kontinuierlich Gigabytes von Daten pro Sekunde aus Hunderttausenden von Quellen wie Website-Klickströmen, Datenbankereignisströmen, Finanztransaktionen, sozialen Medien, IT-Protokollen und Standortverfolgungsereignissen erfassen kann. Dies macht ihn zu einer geeigneten Wahl für die Echtzeiterfassung von Daten von Tausenden von IoT-Geräten.",
        "Other Options": [
            "Amazon RDS für MySQL ist ein relationaler Datenbankdienst. Während er zur Speicherung von Daten verwendet werden kann, ist er nicht für die Echtzeiterfassung und -verarbeitung von Daten ausgelegt, was eine Anforderung in dem gegebenen Szenario ist.",
            "Amazon S3 ist ein Speicherdienst. Während er zur Speicherung verarbeiteter Daten verwendet werden kann, unterstützt er keine Echtzeiterfassung und -verarbeitung von Daten.",
            "Amazon QuickSight ist ein Business-Analytics-Service. Während er zur Analyse von Daten verwendet werden kann, unterstützt er keine Echtzeiterfassung, -verarbeitung und -speicherung von Daten, die Anforderungen in dem gegebenen Szenario sind."
        ]
    },
    {
        "Question Number": "59",
        "Situation": "Ein Unternehmen verwendet Amazon EC2-Instanzen, um eine Legacy-Anwendung zu hosten. Die Anwendung benötigt Zugriff auf Dateien, die auf einem Netzwerkdateisystem gespeichert sind, und muss mehrere gleichzeitige Verbindungen mit niedriger Latenz unterstützen. Das Unternehmen benötigt eine verwaltete Lösung, die skalierbaren Speicher mit hoher Verfügbarkeit bietet.",
        "Question": "Welchen AWS-Dienst sollte der Solutions Architect empfehlen?",
        "Options": {
            "1": "Amazon S3",
            "2": "Amazon EFS (Elastic File System)",
            "3": "Amazon FSx für Windows File Server",
            "4": "Amazon EBS (Elastic Block Store)"
        },
        "Correct Answer": "Amazon EFS (Elastic File System)",
        "Explanation": "Amazon EFS (Elastic File System) ist ein vollständig verwalteter, skalierbarer und elastischer Dateispeicherdienst, der für die Verwendung mit Amazon EC2-Instanzen konzipiert ist. Er unterstützt mehrere gleichzeitige Verbindungen und bietet einen latenzarmen Zugriff auf Dateien, was ihn ideal für Anwendungen macht, die einen gemeinsamen Zugriff auf ein Dateisystem erfordern. EFS skaliert automatisch, wenn Dateien hinzugefügt oder entfernt werden, und gewährleistet hohe Verfügbarkeit und Haltbarkeit, was perfekt mit den Anforderungen der beschriebenen Legacy-Anwendung übereinstimmt.",
        "Other Options": [
            "Amazon S3 ist ein Objektspeicherdienst, der nicht für Anwendungen geeignet ist, die eine Dateisystemschnittstelle und einen latenzarmen Zugriff erfordern. Er ist für die Speicherung und den Abruf großer Mengen unstrukturierter Daten konzipiert, unterstützt jedoch nicht die Dateisystemsemantik, die für den gleichzeitigen Zugriff durch mehrere Instanzen erforderlich ist.",
            "Amazon FSx für Windows File Server bietet ein vollständig verwaltetes Windows-Dateisystem, das das SMB-Protokoll unterstützt und für Windows-basierte Anwendungen geeignet ist. Obwohl es hohe Verfügbarkeit und Skalierbarkeit bietet, ist es speziell auf Windows-Umgebungen zugeschnitten und möglicherweise nicht erforderlich, wenn die Legacy-Anwendung keine Windows-spezifischen Funktionen benötigt.",
            "Amazon EBS (Elastic Block Store) bietet Blockspeicher für EC2-Instanzen und ist für Einzelfallnutzungen geeignet. Es unterstützt keine mehreren gleichzeitigen Verbindungen von verschiedenen Instanzen, was eine Anforderung für die Legacy-Anwendung ist. EBS ist auch kein verwaltetes Dateisystem, da es eine manuelle Verwaltung von Volumes erfordert."
        ]
    },
    {
        "Question Number": "60",
        "Situation": "Ein Analyseunternehmen hat mehrere Amazon EC2-Instanzen innerhalb eines privaten Subnetzes, die Internetzugang für Software-Updates und externe Datensynchronisation benötigen. Um die Netzwerk Kosten niedrig zu halten, ziehen sie Optionen zur Einrichtung von Network Address Translation (NAT) in Betracht, um den ausgehenden Internetzugang für diese Instanzen zu ermöglichen. Das Unternehmen möchte einen kosteneffektiven Ansatz zur Bereitstellung der Internetverbindung, ohne übermäßige Infrastruktur bereitzustellen.",
        "Question": "Welcher Ansatz wäre der kosteneffektivste?",
        "Options": {
            "1": "Bereitstellung eines NAT-Gateways in jeder Availability Zone, um Redundanz zu gewährleisten und den Datenverkehr über mehrere Zonen zu verteilen",
            "2": "Verwendung einer einzelnen NAT-Instanz zur Handhabung des Datenverkehrs für alle EC2-Instanzen innerhalb des privaten Subnetzes, um die Infrastrukturkosten zu minimieren",
            "3": "Bereitstellung separater NAT-Gateways für jedes VPC, damit jedes virtuelle Netzwerk seine eigenen Internetzugangsbedürfnisse unabhängig verwalten kann",
            "4": "Verwendung von NAT-Gateways mit Elastic IPs in mehreren Regionen, um Internetzugang bereitzustellen und hohe Verfügbarkeit zu gewährleisten"
        },
        "Correct Answer": "Verwendung einer einzelnen NAT-Instanz zur Handhabung des Datenverkehrs für alle EC2-Instanzen innerhalb des privaten Subnetzes, um die Infrastrukturkosten zu minimieren",
        "Explanation": "Die Verwendung einer einzelnen NAT-Instanz ist die kosteneffektivste Lösung, um mehreren EC2-Instanzen in einem privaten Subnetz Internetzugang zu gewähren. NAT-Instanzen sind in der Regel günstiger als NAT-Gateways, und eine einzelne Instanz kann den ausgehenden Datenverkehr für alle Instanzen im Subnetz handhaben. Dieser Ansatz minimiert die Infrastrukturkosten und ermöglicht dennoch die notwendige Internetverbindung für Software-Updates und Datensynchronisation.",
        "Other Options": [
            "Die Bereitstellung eines NAT-Gateways in jeder Availability Zone würde Redundanz und Lastverteilung bieten, aber die Kosten erheblich erhöhen, da NAT-Gateways teurer sind als NAT-Instanzen. Diese Option ist für die Bedürfnisse des Unternehmens nicht kosteneffektiv.",
            "Die Bereitstellung separater NAT-Gateways für jedes VPC würde ebenfalls zu höheren Kosten führen, da jedes Gateway Gebühren verursacht. Dieser Ansatz ist unnötig, wenn das Ziel darin besteht, die Infrastrukturkosten zu minimieren und dennoch Internetzugang bereitzustellen.",
            "Die Verwendung von NAT-Gateways mit Elastic IPs in mehreren Regionen würde hohe Verfügbarkeit gewährleisten, wäre jedoch sehr kostspielig. NAT-Gateways werden pro Stunde und pro GB verarbeiteten Daten berechnet, was diese Option für eine kostensensible Anforderung unpraktisch macht."
        ]
    },
    {
        "Question Number": "61",
        "Situation": "Ein Unternehmen verwendet mehrere AWS-Konten, um verschiedene Umgebungen zu verwalten, wie z. B. Entwicklung, Test und Produktion. Das Sicherheitsteam möchte konsistente Sicherheitsrichtlinien für alle Konten durchsetzen und gleichzeitig eine zentrale Verwaltung und Überwachung ermöglichen.",
        "Question": "Welchen AWS-Dienst sollte das Unternehmen nutzen, um eine sichere Multi-Account-Umgebung einzurichten, und welches Feature kann helfen, spezifische Sicherheitskontrollen für jedes Konto durchzusetzen?",
        "Options": {
            "1": "Verwenden Sie AWS Identity and Access Management (IAM) mit Berechtigungsgrenzen für jedes Konto.",
            "2": "Verwenden Sie AWS Control Tower mit Service Control Policies (SCPs), um Sicherheitsrichtlinien über die Konten hinweg zu verwalten.",
            "3": "Implementieren Sie AWS Shield, um Sicherheitsregeln über die verschiedenen Konten hinweg durchzusetzen.",
            "4": "Verwenden Sie Amazon GuardDuty, um Sicherheitsrichtlinien über die Konten hinweg zu verwalten."
        },
        "Correct Answer": "Verwenden Sie AWS Control Tower mit Service Control Policies (SCPs), um Sicherheitsrichtlinien über die Konten hinweg zu verwalten.",
        "Explanation": "AWS Control Tower ist speziell dafür konzipiert, Organisationen dabei zu helfen, eine sichere Multi-Account-AWS-Umgebung einzurichten und zu verwalten. Es bietet eine zentrale Möglichkeit, Konten zu verwalten und Richtlinien über diese durchzusetzen. Service Control Policies (SCPs) sind ein Feature von AWS Organizations, das es Ihnen ermöglicht, Berechtigungsgrenzen für Ihre Konten zu definieren und sicherzustellen, dass spezifische Sicherheitskontrollen konsistent über alle Konten hinweg durchgesetzt werden. Dies macht es zur besten Wahl für die Anforderungen des Unternehmens, konsistente Sicherheitsrichtlinien durchzusetzen und gleichzeitig eine zentrale Verwaltung und Überwachung zu ermöglichen.",
        "Other Options": [
            "AWS Identity and Access Management (IAM) mit Berechtigungsgrenzen ist nützlich für die Verwaltung von Berechtigungen innerhalb eines einzelnen Kontos, bietet jedoch keine zentrale Möglichkeit, Richtlinien über mehrere Konten hinweg durchzusetzen. Daher ist es nicht geeignet für die Multi-Account-Umgebung des Unternehmens.",
            "AWS Shield ist ein verwalteter DDoS-Schutzdienst, der hilft, Anwendungen vor DDoS-Angriffen zu schützen. Während es die Sicherheit erhöht, bietet es keinen Mechanismus zur Durchsetzung von Sicherheitsrichtlinien über mehrere Konten hinweg, was es für die Bedürfnisse des Unternehmens irrelevant macht.",
            "Amazon GuardDuty ist ein Bedrohungserkennungsdienst, der kontinuierlich nach bösartiger Aktivität und unbefugtem Verhalten überwacht. Während es Sicherheitsinformationen bereitstellt, setzt es keine Sicherheitsrichtlinien über Konten hinweg durch, was eine wichtige Anforderung für das Unternehmen ist."
        ]
    },
    {
        "Question Number": "62",
        "Situation": "Ein Unternehmen entwirft ein hochverfügbares und fehlertolerantes System, das mit Verkehrsspitzen und potenziellen Komponentenfehlern umgehen muss, während es einen konsistenten Service aufrechterhält. Das System wird Microservices verwenden und muss Resilienz und Skalierbarkeit sicherstellen.",
        "Question": "Welches verteilte Entwurfsmuster sollte das Unternehmen verwenden, um dies zu erreichen?",
        "Options": {
            "1": "Verwenden Sie das Circuit Breaker-Muster, um sicherzustellen, dass Dienstfehler erkannt und proaktiv verwaltet werden, damit das System die Leistung während teilweiser Fehler aufrechterhalten kann.",
            "2": "Verwenden Sie das monolithische Muster, um die Komplexität zu reduzieren und sicherzustellen, dass alle Komponenten eng integriert sind und voneinander abhängen.",
            "3": "Verwenden Sie das Retry-Muster, um fehlgeschlagene Operationen kontinuierlich zu wiederholen, selbst wenn das System hohen Verkehr oder Komponentenfehler erfährt.",
            "4": "Verwenden Sie das zustandsbehaftete Muster, um sicherzustellen, dass Dienste Sitzungsdaten über Anfragen hinweg beibehalten, damit sie mit Verkehrsspitzen umgehen können."
        },
        "Correct Answer": "Verwenden Sie das Circuit Breaker-Muster, um sicherzustellen, dass Dienstfehler erkannt und proaktiv verwaltet werden, damit das System die Leistung während teilweiser Fehler aufrechterhalten kann.",
        "Explanation": "Das Circuit Breaker-Muster ist darauf ausgelegt, Fehler zu erkennen und zu verhindern, dass das System Anfragen an einen Dienst sendet, der wahrscheinlich ausfällt. Dies ist besonders nützlich in einer Microservices-Architektur, in der die Dienste voneinander abhängig sind. Durch die Implementierung eines Circuit Breakers kann das System schnell ausfallen und den Verkehr umleiten oder Fallback-Optionen bereitstellen, wodurch die Gesamtleistung und Verfügbarkeit des Systems während teilweiser Fehler aufrechterhalten wird. Dieses Muster verbessert die Resilienz, indem es dem System ermöglicht, sich elegant von Fehlern zu erholen und Verkehrsspitzen effektiv zu verwalten.",
        "Other Options": [
            "Das monolithische Muster ist nicht geeignet für ein hochverfügbares und fehlertolerantes System, das Microservices verwendet. Monolithische Architekturen koppeln alle Komponenten eng, was es schwierig macht, einzelne Dienste unabhängig zu skalieren und zu verwalten, was den Zielen von Resilienz und Skalierbarkeit widerspricht.",
            "Das Retry-Muster kann in bestimmten Szenarien nützlich sein, kann jedoch Probleme während hohem Verkehr oder Komponentenfehlern verschärfen. Kontinuierliches Wiederholen fehlgeschlagener Operationen ohne Strategie kann zu einer erhöhten Belastung des Systems und potenziellen kaskadierenden Fehlern führen, was nicht ideal ist, um einen konsistenten Service während Fehlern aufrechtzuerhalten.",
            "Das zustandsbehaftete Muster kann die Skalierbarkeit und Resilienz in einer Microservices-Architektur komplizieren. Das Beibehalten von Sitzungsdaten über Anfragen hinweg kann zu Herausforderungen bei der Lastverteilung und dem Management von Fehlern führen, da zustandsbehaftete Dienste möglicherweise nicht einfach skalieren oder sich von Fehlern erholen können, ohne Sitzungsinformationen zu verlieren."
        ]
    },
    {
        "Question Number": "63",
        "Situation": "Ein Unternehmen verwendet Amazon Kinesis, um Echtzeit-Streaming-Daten zu verarbeiten. Sie möchten sicherstellen, dass nur autorisierte Benutzer auf die Datenströme zugreifen können und dass die Daten sowohl während der Übertragung als auch im Ruhezustand verschlüsselt sind.",
        "Question": "Welche der folgenden Maßnahmen sollte das Unternehmen ergreifen, um ihre Kinesis-Datenströme zu sichern?",
        "Options": {
            "1": "Aktivieren Sie die serverseitige Verschlüsselung (SSE) mit dem AWS Key Management Service (KMS), um Daten im Ruhezustand zu verschlüsseln, und verwenden Sie IAM-Richtlinien, um den Zugriff auf die Streams zu steuern.",
            "2": "Konfigurieren Sie Kinesis Data Streams so, dass nur im Ruhezustand Verschlüsselung verwendet wird, aktivieren Sie jedoch keine Verschlüsselung während der Übertragung, da dies für interne AWS-Kommunikationen nicht erforderlich ist.",
            "3": "Aktivieren Sie VPC-Peering zwischen Kinesis und anderen AWS-Diensten, um sicherzustellen, dass die Daten über private Netzwerkverbindungen übertragen werden, um die Sicherheit zu erhöhen.",
            "4": "Erlauben Sie offenen Zugriff auf Kinesis-Streams ohne Verschlüsselung, um sicherzustellen, dass die Daten schnell von verschiedenen Anwendungen abgerufen werden können, und verwenden Sie CloudTrail, um Zugriffsprotokolle zu überwachen."
        },
        "Correct Answer": "Aktivieren Sie die serverseitige Verschlüsselung (SSE) mit dem AWS Key Management Service (KMS), um Daten im Ruhezustand zu verschlüsseln, und verwenden Sie IAM-Richtlinien, um den Zugriff auf die Streams zu steuern.",
        "Explanation": "Die Aktivierung der serverseitigen Verschlüsselung (SSE) mit dem AWS Key Management Service (KMS) stellt sicher, dass die in Kinesis Data Streams gespeicherten Daten im Ruhezustand verschlüsselt sind, was eine Sicherheitsebene gegen unbefugten Zugriff bietet. Darüber hinaus ermöglicht die Verwendung von IAM-Richtlinien dem Unternehmen, festzulegen, wer auf die Streams zugreifen kann und welche Aktionen sie durchführen können, wodurch sichergestellt wird, dass nur autorisierte Benutzer Zugriff auf sensible Daten haben. Diese Kombination aus Verschlüsselung und Zugriffskontrolle ist entscheidend für die Sicherung von Daten in einer Cloud-Umgebung.",
        "Other Options": [
            "Die Konfiguration von Kinesis Data Streams zur Verwendung von Verschlüsselung nur im Ruhezustand, jedoch ohne Aktivierung der Verschlüsselung während der Übertragung, ist unzureichend, da Daten während der Übertragung abgefangen werden können. Die Verschlüsselung während der Übertragung ist entscheidend, um Daten zu schützen, während sie über das Netzwerk reisen, insbesondere im Kontext von Echtzeit-Streaming.",
            "Die Aktivierung von VPC-Peering kann die Sicherheit erhöhen, indem private Kommunikation zwischen AWS-Diensten ermöglicht wird, adressiert jedoch nicht die Notwendigkeit der Verschlüsselung im Ruhezustand oder während der Übertragung. Ohne Verschlüsselung könnten Daten weiterhin unbefugtem Zugriff ausgesetzt sein, was diese Option unvollständig macht, um Kinesis-Datenströme zu sichern.",
            "Das Erlauben von offenem Zugriff auf Kinesis-Streams ohne Verschlüsselung stellt ein erhebliches Sicherheitsrisiko dar, da es sensible Daten jedem aussetzt, der auf die Streams zugreifen kann. Die Überwachung von Zugriffsprotokollen mit CloudTrail verhindert keinen unbefugten Zugriff; sie bietet nur nachträglich Sichtbarkeit. Dieser Ansatz widerspricht den besten Praktiken für Datensicherheit."
        ]
    },
    {
        "Question Number": "64",
        "Situation": "Stellen Sie sich vor, Sie starten eine globale Website für das Streaming von hochwertigen Medieninhalten. Sie müssen sicherstellen, dass Ihre Benutzer minimale Latenz und reibungsloses Abspielen erleben, unabhängig von ihrem geografischen Standort. Um dies zu erreichen, entscheiden Sie sich, Amazon CloudFront für die Inhaltsbereitstellung zu verwenden.",
        "Question": "Welches Element von CloudFront ist dafür verantwortlich, Inhalte näher bei den Benutzern zwischenzuspeichern, um schnelleren Zugriff zu ermöglichen, und wie trägt es zur Reduzierung der Latenz bei?",
        "Options": {
            "1": "Distribution, da sie die Hauptkonfiguration bereitstellt und das Cache-Verhalten definiert.",
            "2": "Edge Location, da sie zwischengespeicherte Inhalte näher bei den Benutzern speichert, was zu schnelleren Zugriffszeiten für häufig angeforderte Daten führt.",
            "3": "Regional Edge Cache, das als größere Version von Edge Locations fungiert, um mehr Daten für verbesserte Cache-Effizienz zu halten.",
            "4": "Origin, da sie den ursprünglichen Inhalt enthält, der von CloudFront auf Anfrage des Benutzers abgerufen wird."
        },
        "Correct Answer": "Edge Location, da sie zwischengespeicherte Inhalte näher bei den Benutzern speichert, was zu schnelleren Zugriffszeiten für häufig angeforderte Daten führt.",
        "Explanation": "Edge Locations sind das zentrale Element von Amazon CloudFront, das Inhalte an verschiedenen geografischen Standorten auf der ganzen Welt zwischenspeichert. Durch das Speichern von Kopien von Inhalten näher bei den Benutzern reduziert Edge Locations erheblich die Distanz, die Daten zurücklegen müssen, was die Latenz minimiert und die Geschwindigkeit der Inhaltsbereitstellung verbessert. Dies ist besonders wichtig für das Streaming von hochwertigen Medien, da Benutzer schnellen Zugriff auf Inhalte ohne Pufferung erwarten.",
        "Other Options": [
            "Distribution ist eine Konfiguration, die definiert, wie CloudFront Inhalte bereitstellt, einschließlich Einstellungen für das Cache-Verhalten, aber sie speichert nicht direkt Inhalte im Cache. Es geht mehr um die gesamte Einrichtung als um das physische Caching von Inhalten.",
            "Regional Edge Cache fungiert als Zwischenstation zwischen dem Ursprung und den Edge Locations und hält größere Datenmengen, um die Cache-Effizienz zu verbessern. Es ist jedoch nicht das primäre Element, das für das Caching von Inhalten am nächsten bei den Benutzern verantwortlich ist; diese Rolle wird speziell von Edge Locations erfüllt.",
            "Origin bezieht sich auf die ursprüngliche Quelle des Inhalts, wie einen S3-Bucket oder einen Webserver. Während es wichtig ist, um Inhalte abzurufen, wenn sie nicht im Cache verfügbar sind, trägt es nicht zur Reduzierung der Latenz bei, da es typischerweise weiter entfernt von den Endbenutzern liegt als Edge Locations."
        ]
    },
    {
        "Question Number": "65",
        "Situation": "Sie entwerfen ein Jobverarbeitungssystem, bei dem Nachrichten in einer bestimmten Reihenfolge verarbeitet werden müssen und keine Duplikate erlaubt sind. Sie möchten jedoch dieses Bedürfnis nach Reihenfolge mit hoher Skalierbarkeit in Einklang bringen, da das Volumen der Nachrichten stark variieren kann.",
        "Question": "Welchen Typ von Amazon SQS-Warteschlange sollten Sie wählen, um diese Anforderungen zu erfüllen, und warum?",
        "Options": {
            "1": "Standard-Warteschlange, da sie unbegrenzten Durchsatz ermöglicht und für hohe Skalierbarkeit ohne strenge Reihenfolge optimiert ist.",
            "2": "FIFO-Warteschlange, da sie genau einmalige Verarbeitung bietet und die strikte Reihenfolge der Nachrichten beibehält, was für Ihre Anforderungen entscheidend ist.",
            "3": "Standard-Warteschlange, da sie eine mindestens einmalige Zustellung bietet, was sie geeignet macht, um variable Nachrichtenvolumina zu verarbeiten.",
            "4": "FIFO-Warteschlange, da sie keine Grenzen für TPS auferlegt und für eine bestmögliche Reihenfolge optimiert ist, was sie ideal für Anwendungen mit hohem Volumen macht."
        },
        "Correct Answer": "FIFO-Warteschlange, da sie genau einmalige Verarbeitung bietet und die strikte Reihenfolge der Nachrichten beibehält, was für Ihre Anforderungen entscheidend ist.",
        "Explanation": "Eine FIFO (First-In-First-Out) Warteschlange in Amazon SQS ist speziell dafür konzipiert, sicherzustellen, dass Nachrichten in der genauen Reihenfolge verarbeitet werden, in der sie gesendet werden, und dass jede Nachricht genau einmal verarbeitet wird. Dies ist entscheidend für Szenarien, in denen die Reihenfolge der Nachrichtenverarbeitung kritisch ist und Duplikate vermieden werden müssen. Angesichts der Anforderungen, eine strikte Reihenfolge aufrechtzuerhalten und Duplikate zu verhindern, ist eine FIFO-Warteschlange die am besten geeignete Wahl.",
        "Other Options": [
            "Standard-Warteschlange, da sie unbegrenzten Durchsatz ermöglicht und für hohe Skalierbarkeit ohne strenge Reihenfolge optimiert ist. Diese Option erfüllt jedoch nicht die Anforderung an eine strikte Reihenfolge und könnte zu Nachrichten-Duplikationen führen.",
            "FIFO-Warteschlange, da sie genau einmalige Verarbeitung bietet und die strikte Reihenfolge der Nachrichten beibehält, was für Ihre Anforderungen entscheidend ist. Diese Option ist tatsächlich korrekt, wird jedoch in der Frage wiederholt, was irreführend ist.",
            "Standard-Warteschlange, da sie eine mindestens einmalige Zustellung bietet, was sie geeignet macht, um variable Nachrichtenvolumina zu verarbeiten. Während diese Option hohe Skalierbarkeit ermöglicht, garantiert sie nicht die Reihenfolge der Nachrichten und kann zu Duplikaten führen, was nicht den Anforderungen entspricht."
        ]
    }
]