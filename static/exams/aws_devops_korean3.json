[
    {
        "Question Number": "1",
        "Situation": "귀 조직은 개발, 테스트, 프로덕션 등 다양한 환경을 위한 여러 AWS 계정에 걸쳐 CI/CD 파이프라인을 구현하고 있습니다. 코드 변경 사항이 최소한의 수동 개입과 최대한의 보안을 유지하면서 모든 계정에 자동으로 빌드, 테스트 및 배포되도록 하려 합니다. 다음 중 어떤 배포 패턴을 사용해야 합니까?",
        "Question": "다중 계정 AWS 환경에서 SDLC를 자동화하는 데 가장 적합한 배포 패턴은 무엇입니까?",
        "Options": {
            "1": "하나의 계정에 공유 리포지토리를 사용하여 AWS CodePipeline을 설정하고 다른 계정에 수동으로 아티팩트를 배포합니다.",
            "2": "각 계정에 별도의 CI/CD 파이프라인을 생성하여 중앙 조정 없이 독립적으로 배포를 트리거합니다.",
            "3": "프로덕션 계정에 단일 CI/CD 파이프라인을 구현하여 모든 하위 환경에 직접 배포합니다.",
            "4": "관리 계정에 중앙 집중식 CI/CD 파이프라인을 설정하고 배포를 위해 교차 계정 역할을 사용합니다."
        },
        "Correct Answer": "관리 계정에 중앙 집중식 CI/CD 파이프라인을 설정하고 배포를 위해 교차 계정 역할을 사용합니다.",
        "Explanation": "관리 계정에 중앙 집중식 CI/CD 파이프라인을 설정하면 여러 계정에 걸쳐 배포의 거버넌스 및 관리를 간소화할 수 있습니다. 교차 계정 역할을 사용하면 다른 계정에서 리소스를 배포하기 위한 안전하고 권한이 부여된 접근을 보장하므로 보안 및 규정 준수를 유지하는 데 중요합니다.",
        "Other Options": [
            "각 계정에 별도의 CI/CD 파이프라인을 생성하면 배포 관행이 일관되지 않게 되고 관리 오버헤드가 증가하여 배포 프로세스를 제어하기 어려워집니다.",
            "하나의 계정에 공유 리포지토리를 사용하여 AWS CodePipeline을 설정하고 다른 계정에 수동으로 아티팩트를 배포하면 오류와 불일치로 이어질 수 있는 수동 단계가 추가되어 자동화의 이점을 무효화합니다.",
            "프로덕션 계정에 단일 CI/CD 파이프라인을 구현하여 하위 환경에 직접 배포하면 보안과 안정성이 저하될 수 있으며, 프로덕션의 변경 사항이 다른 환경에 의도치 않게 영향을 미칠 수 있습니다."
        ]
    },
    {
        "Question Number": "2",
        "Situation": "한 회사가 사용자 트래픽에 따라 동적으로 확장되는 새로운 웹 애플리케이션을 배포하고 있습니다. 애플리케이션은 Amazon EC2 인스턴스에서 호스팅되며, 회사는 높은 가용성과 비용 효율성을 보장하고자 합니다. 그들은 인스턴스를 효과적으로 관리하기 위해 특정 확장 정책을 가진 Auto Scaling 그룹(ASG)을 사용할 계획입니다.",
        "Question": "회사가 ASG가 AWS의 시작 구성 및 Auto Scaling 그룹에 대한 제한을 준수하면서 올바르게 확장되도록 보장하기 위해 어떤 구성을 구현해야 합니까?",
        "Options": {
            "1": "ASG를 최소 크기 2, 원하는 크기 4, 최대 크기 6으로 구성합니다. 인스턴스 매개변수를 정의하기 위해 시작 템플릿을 사용합니다. 매주 월요일부터 금요일까지 오전 9시에 용량을 늘리기 위한 예약 확장 정책을 구현합니다.",
            "2": "최소 크기 0, 원하는 크기 2, 최대 크기 4인 ASG를 생성합니다. 더 나은 비용 관리를 위해 다양한 인스턴스 유형을 포함하는 시작 구성을 활용합니다. 애플리케이션 부하 메트릭을 기반으로 하는 동적 확장 정책을 설정합니다.",
            "3": "최소 크기 1, 원하는 크기 5, 최대 크기 10인 ASG를 설정합니다. 이전 AMI와 더 작은 인스턴스 유형을 포함하는 시작 구성을 사용합니다. 네트워크 트래픽이 20% 이하로 떨어질 때 축소되는 확장 정책을 생성합니다.",
            "4": "ASG의 최소 크기를 1, 원하는 크기를 3, 최대 크기를 5로 설정합니다. 최신 AMI와 인스턴스 유형을 사용하는 시작 구성을 사용합니다. CPU 사용량 메트릭이 70%를 초과할 때 확장 작업을 트리거하는 확장 정책을 생성합니다."
        },
        "Correct Answer": "ASG의 최소 크기를 1, 원하는 크기를 3, 최대 크기를 5로 설정합니다. 최신 AMI와 인스턴스 유형을 사용하는 시작 구성을 사용합니다. CPU 사용량 메트릭이 70%를 초과할 때 확장 작업을 트리거하는 확장 정책을 생성합니다.",
        "Explanation": "이 옵션은 ASG가 트래픽을 처리할 수 있는 충분한 인스턴스를 보유하도록 하면서 CPU 사용량에 따라 확장 작업을 위한 버퍼를 제공합니다. 이 구성은 동적 확장을 위한 AWS 모범 사례를 준수하며 최신 리소스를 활용합니다.",
        "Other Options": [
            "이 옵션은 ASG의 최소 크기를 너무 높게 설정하여 트래픽이 낮을 때 불필요한 비용이 발생할 수 있습니다. 최소 크기 2는 사용량이 낮은 기간 동안 0으로 축소할 수 있는 애플리케이션에는 적합하지 않습니다.",
            "이 옵션은 구식 AMI와 더 작은 인스턴스 유형을 포함하고 있어 애플리케이션에 필요한 성능을 제공하지 못할 수 있습니다. 또한 CPU 사용량을 고려하지 않고 네트워크 트래픽에 따라 확장하는 것은 피크 부하 동안 리소스를 효과적으로 관리하지 못할 수 있습니다.",
            "이 옵션은 최소 크기를 0으로 설정하여 갑작스러운 수요가 발생할 경우 확장 지연을 초래할 수 있습니다. 동적 확장 정책은 유용하지만 높은 가용성을 위해 최소 크기를 1로 시작하는 것이 권장됩니다."
        ]
    },
    {
        "Question Number": "3",
        "Situation": "한 회사가 AWS에서 실행되는 웹 서비스에 의해 생성된 애플리케이션 로그를 모니터링하기 위해 Amazon CloudWatch를 사용하고 있습니다. DevOps 팀은 애플리케이션의 오류를 나타내는 특정 로그 이벤트에서 CloudWatch 메트릭을 생성하는 임무를 맡았습니다. 그들은 중요한 오류 이벤트가 효과적으로 모니터링되고 발생 시 알람이 트리거되도록 해야 합니다. 팀은 로그 이벤트에 'ERROR'라는 키워드가 포함되어 있음을 확인했습니다.",
        "Question": "DevOps 엔지니어가 로그에서 'ERROR' 키워드의 발생을 추적하는 CloudWatch 메트릭을 생성하기 위해 무엇을 해야 합니까?",
        "Options": {
            "1": "모든 로그 이벤트를 캡처하는 CloudWatch 메트릭 필터를 설정한 다음 CloudWatch 대시보드에서 'ERROR'를 수동으로 검색합니다.",
            "2": "‘ERROR’를 인식하는 패턴으로 CloudWatch 메트릭 필터를 생성하고 팀에 알리기 위해 CloudWatch 알람과 연결합니다.",
            "3": "‘ERROR’를 포함하는 로그 이벤트를 전달하기 위해 Amazon SNS 주제를 구성하고 SNS 알림에서 수동으로 CloudWatch 메트릭을 생성합니다.",
            "4": "로그를 처리하고 'ERROR' 단어의 각 발생에 대해 사용자 정의 CloudWatch 메트릭을 게시하는 Lambda 함수를 구현합니다."
        },
        "Correct Answer": "‘ERROR’를 인식하는 패턴으로 CloudWatch 메트릭 필터를 생성하고 팀에 알리기 위해 CloudWatch 알람과 연결합니다.",
        "Explanation": "특정 패턴으로 CloudWatch 메트릭 필터를 생성하면 'ERROR' 키워드가 포함된 로그 이벤트를 자동으로 추적할 수 있습니다. 이 접근 방식은 실시간 모니터링을 가능하게 하고 메트릭을 기반으로 알람을 설정할 수 있어 사전 사고 관리에 필수적입니다.",
        "Other Options": [
            "모든 로그 이벤트를 캡처하는 메트릭 필터를 설정하는 것은 'ERROR' 발생을 효율적으로 추적할 수 있는 특정 메커니즘을 제공하지 않으며, 오류를 식별하기 위해 수동 개입이 필요하므로 자동 모니터링의 목적을 무효화합니다.",
            "Lambda 함수를 구현하면 프로세스에 불필요한 복잡성과 지연이 추가됩니다. 오류를 추적할 수 있지만 CloudWatch 메트릭 필터가 쉽게 사용 가능한 상황에서 로그 이벤트에서 직접 메트릭을 생성하는 가장 효율적인 방법은 아닙니다.",
            "로그 이벤트에 대한 SNS 주제를 구성하면 추가 설정 및 유지 관리가 필요합니다. 이 접근 방식은 로그에서 직접 메트릭을 생성하지 않으며 알림 및 모니터링에 지연을 초래할 수 있습니다."
        ]
    },
    {
        "Question Number": "4",
        "Situation": "한 회사가 여러 AWS 계정을 관리하기 위해 AWS Organizations를 구현했습니다. 이들은 서비스 제어 정책(Service Control Policies, SCPs)을 사용하여 회원 계정에서 사용할 수 있는 서비스를 제한함으로써 거버넌스를 강화하고자 합니다. 회사는 이러한 정책이 회원 계정 내의 모든 사용자, 특히 루트 사용자에게 효과적으로 적용되도록 해야 합니다.",
        "Question": "서비스 제어 정책(SCPs)에 대한 두 가지 진술 중 어떤 것이 사실입니까? (두 가지 선택)",
        "Options": {
            "1": "SCPs는 회원 계정에서 특정 서비스에 대한 접근을 제한할 수 있습니다.",
            "2": "SCPs는 회원 계정에 대해 모든 AWS 서비스를 활성화하는 데 사용할 수 있습니다.",
            "3": "SCPs는 조직의 관리 계정에는 적용되지 않습니다.",
            "4": "SCPs는 회원 계정 내의 모든 사용자에게 적용되며, 루트 사용자도 포함됩니다.",
            "5": "SCPs는 회원 계정 내의 서비스 연결 역할에 영향을 미칩니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "SCPs는 회원 계정 내의 모든 사용자에게 적용되며, 루트 사용자도 포함됩니다.",
            "SCPs는 조직의 관리 계정에는 적용되지 않습니다."
        ],
        "Explanation": "서비스 제어 정책(SCPs)은 조직 내 모든 계정에 대해 최대 사용 가능한 권한을 정의하는 데 사용될 수 있습니다. 이들은 회원 계정 내의 모든 사용자에게 적용되며, 루트 사용자도 포함되지만 서비스 연결 역할에는 영향을 미치지 않습니다. 또한, SCPs는 관리 계정 자체에는 적용되지 않으므로 관리 계정은 조직 전반에 걸쳐 정책을 관리할 수 있는 능력을 유지합니다.",
        "Other Options": [
            "SCPs는 회원 계정 내의 서비스 연결 역할에 영향을 미칩니다. 이는 SCPs가 조직 내에서 정의된 SCPs와 독립적으로 운영되는 서비스 연결 역할에 영향을 미치지 않기 때문에 잘못된 것입니다.",
            "SCPs는 회원 계정에 대해 모든 AWS 서비스를 활성화하는 데 사용할 수 있습니다. 이는 SCPs가 모든 서비스를 활성화하는 것이 아니라 권한을 제한하도록 설계되었기 때문에 잘못된 것입니다.",
            "SCPs는 회원 계정에서 특정 서비스에 대한 접근을 제한할 수 있습니다. 이 진술은 사실처럼 보이지만, SCPs가 권한을 제한할 뿐 서비스를 제공하지 않는다는 완전한 맥락을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "5",
        "Situation": "한 금융 서비스 회사는 Amazon S3 버킷에 저장된 개인 식별 정보(PII) 및 결제 세부정보와 같은 민감한 데이터의 보호에 대해 우려하고 있습니다. 이들은 규제 기준을 준수하기 위해 AWS 환경 전반에서 민감한 데이터를 자동으로 발견해야 합니다. DevOps 엔지니어는 수동 감독 및 운영 오버헤드를 최소화하면서 이를 대규모로 달성하기 위한 솔루션을 구현하는 임무를 맡고 있습니다.",
        "Question": "DevOps 엔지니어가 민감한 데이터의 대규모 발견을 자동화하기 위해 구현해야 할 옵션 조합은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "AWS Config 규칙을 설정하여 S3 버킷 정책을 모니터링하고 민감한 데이터를 노출할 수 있는 변경 사항에 대해 경고합니다.",
            "2": "Amazon Macie를 구성하여 Amazon S3 버킷에 저장된 민감한 데이터를 정기적으로 자동으로 분류하고 발견합니다.",
            "3": "Amazon Macie를 AWS Lambda와 함께 사용하여 S3 버킷에서 민감한 데이터가 감지될 때 경고를 트리거합니다.",
            "4": "AWS Security Hub를 배포하여 다양한 AWS 서비스에서 민감한 데이터에 대한 결과를 집계하고 규정 준수에 대한 포괄적인 뷰를 제공합니다.",
            "5": "AWS Glue Data Catalog를 구현하여 S3 및 RDS를 포함한 여러 데이터 저장소에서 민감한 데이터를 조직하고 발견합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon Macie를 구성하여 Amazon S3 버킷에 저장된 민감한 데이터를 정기적으로 자동으로 분류하고 발견합니다.",
            "Amazon Macie를 AWS Lambda와 함께 사용하여 S3 버킷에서 민감한 데이터가 감지될 때 경고를 트리거합니다."
        ],
        "Explanation": "Amazon Macie는 AWS에서 민감한 데이터의 발견 및 분류를 자동화하도록 특별히 설계되었습니다. Macie를 정기적으로 실행하도록 구성함으로써 회사는 지속적인 규정 준수 모니터링을 보장할 수 있습니다. 또한, Macie와 AWS Lambda를 통합하면 팀이 발견된 내용을 기반으로 자동 응답 또는 경고를 설정할 수 있어 데이터 보호 전략을 강화할 수 있습니다.",
        "Other Options": [
            "AWS Config 규칙을 설정하는 것은 구성 준수를 모니터링하는 데 유용하지만 민감한 데이터를 직접 발견하거나 분류하지는 않습니다. 이는 변경 사항 및 준수를 추적하는 데 더 중점을 둡니다.",
            "AWS Glue Data Catalog는 주로 메타데이터 저장소로 데이터를 조직하고 발견하는 데 도움이 되지만, Macie와 같은 민감한 데이터에 대한 분류 및 모니터링 기능을 본질적으로 제공하지 않습니다.",
            "AWS Security Hub는 다양한 AWS 보안 서비스의 결과를 집계하지만, 민감한 데이터의 발견을 자동화하지는 않습니다. 이는 데이터 분류보다는 보안 태세 관리에 더 중점을 둡니다."
        ]
    },
    {
        "Question Number": "6",
        "Situation": "한 회사가 AWS에 호스팅된 애플리케이션에서 간헐적인 성능 문제를 겪고 있습니다. 이 애플리케이션은 Amazon EC2 인스턴스와 Amazon RDS를 데이터베이스로 사용합니다. 운영 팀은 EC2 인스턴스의 높은 CPU 사용량과 RDS의 느린 쿼리 성능에 대한 경고를 받습니다. 애플리케이션 성능을 최적화하기 위해 팀은 이러한 이벤트에 따라 자동으로 구성 변경을 구현해야 합니다.",
        "Question": "EC2 및 RDS의 성능 경고에 따라 자동으로 구성 변경을 구현하기 위한 가장 효과적인 솔루션은 무엇입니까?",
        "Options": {
            "1": "Amazon RDS Performance Insights를 설정하여 느린 쿼리를 모니터링합니다. 성능 기준이 초과될 때 데이터베이스 구성을 최적화하는 AWS Lambda 함수를 생성합니다.",
            "2": "EC2 CPU 사용량 및 RDS 성능 메트릭에 대한 Amazon CloudWatch 경고를 생성합니다. AWS Step Functions를 사용하여 경고 상태에 따라 EC2 인스턴스 유형 및 RDS 매개변수를 조정하는 Lambda 함수를 호출하는 워크플로를 조정합니다.",
            "3": "EC2 인스턴스의 CPU 사용량에 대한 Amazon CloudWatch 경고를 구성합니다. 경고가 발생할 때 인스턴스 유형을 더 큰 크기로 수정하는 AWS Lambda 함수를 생성합니다.",
            "4": "AWS Systems Manager를 활용하여 EC2 및 RDS에 대한 CloudWatch 경고에 따라 자동화된 작업을 실행합니다. 성능 문제가 감지될 때 EC2 인스턴스를 확장하고 RDS 구성을 수정하는 실행 문서를 설정합니다."
        },
        "Correct Answer": "EC2 CPU 사용량 및 RDS 성능 메트릭에 대한 Amazon CloudWatch 경고를 생성합니다. AWS Step Functions를 사용하여 경고 상태에 따라 EC2 인스턴스 유형 및 RDS 매개변수를 조정하는 Lambda 함수를 호출하는 워크플로를 조정합니다.",
        "Explanation": "이 접근 방식은 CloudWatch 경고를 사용하여 성능 메트릭을 모니터링하고 Step Functions를 사용하여 응답 조정을 관리하여 감지된 성능 문제에 따라 EC2 및 RDS 구성에 대한 조정을 자동화합니다.",
        "Other Options": [
            "이 옵션은 EC2 인스턴스 크기 변경만 다루고 있으며 RDS 성능 문제를 고려하지 않거나 두 서비스에 대한 조정된 응답을 제공하지 않습니다.",
            "RDS Performance Insights는 모니터링에 유용하지만 이 옵션은 EC2 인스턴스 확장 또는 두 서비스 전반에 걸친 성능 최적화에 대한 포괄적인 접근 방식을 제공하지 않습니다.",
            "AWS Systems Manager는 작업을 자동화할 수 있지만 이 옵션은 여러 경고 및 작업을 효율적으로 처리하는 데 필요한 Step Functions의 조정 기능이 부족합니다."
        ]
    },
    {
        "Question Number": "7",
        "Situation": "한 회사가 여러 AWS 계정을 관리하고 있으며, Amazon VPC 서브넷 및 Amazon RDS 데이터베이스와 같은 특정 리소스를 이러한 계정 간에 공유하고자 합니다. 리소스는 현재 그들의 계정 중 하나에 위치하고 있으며, AWS Resource Access Manager (RAM)를 사용하여 이 공유를 용이하게 하려고 합니다. DevOps 엔지니어로서, 공유할 리소스를 포함하는 동일한 계정 내에서 리소스 공유를 생성해야 합니다.",
        "Question": "지정된 리소스에 대해 AWS RAM을 사용하여 동일한 AWS 계정 내에서 리소스 공유를 생성하는 올바른 접근 방식은 무엇입니까?",
        "Options": {
            "1": "AWS RAM 콘솔로 이동하여 새 리소스 공유를 생성하고, 공유할 리소스를 선택한 다음, 접근할 수 있는 계정을 지정합니다. 공유가 활성화되어 있는지 확인합니다.",
            "2": "AWS CloudFormation을 사용하여 RAM을 사용한 리소스 공유를 정의하는 스택을 생성하고, 템플릿에 포함된 리소스와 계정을 지정합니다.",
            "3": "AWS CLI를 사용하여 리소스 ARN 및 계정 ID를 지정하여 리소스 공유를 생성합니다. 공유 리소스에 대한 적절한 권한을 포함해야 합니다.",
            "4": "AWS Management Console에 접근하여 리소스의 설정으로 이동하고, VPC 또는 RDS 인스턴스의 리소스 정책을 수정하여 각 계정에 대한 접근을 수동으로 부여합니다."
        },
        "Correct Answer": "AWS RAM 콘솔로 이동하여 새 리소스 공유를 생성하고, 공유할 리소스를 선택한 다음, 접근할 수 있는 계정을 지정합니다. 공유가 활성화되어 있는지 확인합니다.",
        "Explanation": "AWS RAM을 사용하여 리소스 공유를 생성하는 올바른 접근 방식은 AWS RAM 콘솔에 접근하는 것입니다. 여기에서 새 리소스 공유를 쉽게 생성하고, 공유할 특정 리소스를 선택하며, 접근할 계정을 지정할 수 있습니다. 공유를 활성화하는 것도 공유 프로세스를 가능하게 하는 데 필수적입니다.",
        "Other Options": [
            "AWS CLI를 사용하여 리소스 공유를 생성하는 것은 가능하지만, 더 복잡한 명령 구문이 필요하며 콘솔 내에서 공유를 생성하는 가장 간단한 방법은 아닙니다.",
            "VPC 또는 RDS 인스턴스의 리소스 정책을 수동으로 수정하는 것은 AWS RAM을 활용하지 않으며, 다중 계정 설정에서 리소스를 공유하는 효과적인 방법이 아닙니다.",
            "AWS CloudFormation을 사용하여 리소스 공유를 생성하는 것은 불필요합니다. AWS RAM은 콘솔을 통해 직접 관리할 수 있으므로 이 옵션은 작업에 비해 더 복잡합니다."
        ]
    },
    {
        "Question Number": "8",
        "Situation": "한 금융 서비스 회사가 민감한 고객 데이터를 처리할 새로운 웹 애플리케이션을 AWS에 배포하고 있습니다. 이들은 여러 가용 영역 및 리전에서 애플리케이션을 분산시켜 높은 가용성과 내결함성을 보장하고자 합니다. DevOps 팀은 잠재적인 중단에 대비하여 다운타임을 최소화하고 회복력을 극대화하는 솔루션을 구현하는 임무를 맡고 있습니다.",
        "Question": "다음 구성 중 여러 가용 영역 및 리전에서 애플리케이션의 높은 가용성을 보장하면서 다운타임을 최소화하는 목표를 가장 잘 달성할 수 있는 것은 무엇입니까?",
        "Options": {
            "1": "Amazon ECS를 활용하여 애플리케이션을 다중 리전 설정에서 실행하고, 각 리전에서 로드 밸런서를 배치합니다. Route 53을 지연 기반 라우팅으로 구성하여 트래픽을 가장 가까운 리전으로 유도하여 높은 가용성과 빠른 장애 조치를 보장합니다.",
            "2": "AWS Lambda를 사용하여 애플리케이션을 구축하고 여러 리전에 배포합니다. Amazon API Gateway를 활용하여 들어오는 요청을 처리하고 적절한 Lambda 함수로 라우팅하여 지리적 중복성을 보장합니다.",
            "3": "AWS Global Accelerator를 사용하여 단일 가용 영역에 애플리케이션을 설정하여 다양한 위치의 사용자에게 성능과 가용성을 향상시키고, 해당 영역에 단일 데이터베이스 인스턴스를 사용합니다.",
            "4": "단일 리전 내 여러 가용 영역에 EC2 인스턴스에서 애플리케이션을 배포합니다. 애플리케이션 로드 밸런서를 사용하여 인스턴스 간에 트래픽을 분산합니다. Auto Scaling을 구현하여 인스턴스의 상태와 용량을 관리합니다."
        },
        "Correct Answer": "Amazon ECS를 활용하여 애플리케이션을 다중 리전 설정에서 실행하고, 각 리전에서 로드 밸런서를 배치합니다. Route 53을 지연 기반 라우팅으로 구성하여 트래픽을 가장 가까운 리전으로 유도하여 높은 가용성과 빠른 장애 조치를 보장합니다.",
        "Explanation": "Amazon ECS를 사용하여 다중 리전 설정에서 애플리케이션을 배포하면 한 리전에서의 실패를 처리할 수 있는 강력한 아키텍처를 제공합니다. 이는 트래픽을 자동으로 다른 리전으로 리디렉션하여 다운타임을 최소화하고 애플리케이션이 중단 중에도 가용성을 유지하도록 합니다.",
        "Other Options": [
            "단일 리전 내 여러 가용 영역에 EC2 인스턴스에서 애플리케이션을 배포하는 것은 가용성을 향상시키지만 지리적 중복성을 제공하지 않습니다. 전체 리전이 다운되면 애플리케이션은 사용할 수 없습니다.",
            "여러 리전에서 AWS Lambda를 사용하는 것은 어느 정도의 중복성을 제공할 수 있지만, 상태 저장 애플리케이션이나 지속적인 연결이 필요한 애플리케이션에는 효과적이지 않으며, 이는 더 높은 지연 시간과 지역 배포 관리의 복잡성을 초래할 수 있습니다.",
            "AWS Global Accelerator를 사용하여 단일 가용 영역에 애플리케이션을 설정하는 것은 높은 가용성을 보장하지 않습니다. 애플리케이션이 여전히 해당 단일 가용 영역에 의존하기 때문입니다. 만약 그것이 실패하면, 글로벌 가속기가 있음에도 불구하고 애플리케이션은 다운됩니다."
        ]
    },
    {
        "Question Number": "9",
        "Situation": "현재 중첩 스택 중 하나의 실패로 인해 UPDATE_ROLLBACK_FAILED 상태에 있는 AWS CloudFormation 스택을 관리하고 있습니다. 기존 리소스를 잃지 않고 이 문제를 해결해야 합니다. 또한, AWS Lambda로 지원되는 사용자 지정 리소스가 있으며, 스택에는 작업을 위한 특정 권한이 필요합니다.",
        "Question": "사용자 지정 리소스가 올바르게 작동하도록 하면서 CloudFormation 스택의 UPDATE_ROLLBACK_FAILED 상태를 처리하는 가장 좋은 접근 방식은 무엇입니까?",
        "Options": {
            "1": "실패한 리소스의 오류를 수동으로 해결한 다음, CloudFormation 콘솔을 사용하여 롤백 프로세스를 계속 진행합니다.",
            "2": "전체 스택을 삭제하고 처음부터 다시 생성하여 롤백 문제를 피합니다.",
            "3": "CloudFormation 스택에 서비스 역할을 설정하여 필요한 권한을 제공하고, 실패한 리소스를 해결하지 않고 업데이트를 재시도합니다.",
            "4": "롤백 중에 실패한 리소스를 건너뛰고 나머지 스택에 대해 롤백을 계속 진행합니다."
        },
        "Correct Answer": "실패한 리소스의 오류를 수동으로 해결한 다음, CloudFormation 콘솔을 사용하여 롤백 프로세스를 계속 진행합니다.",
        "Explanation": "UPDATE_ROLLBACK_FAILED 상태를 효과적으로 처리하기 위해서는 실패를 초래한 리소스의 오류를 수동으로 해결한 다음, CloudFormation 콘솔이나 CLI를 사용하여 롤백 프로세스를 계속 진행해야 합니다. 이는 기존 리소스를 잃지 않고 스택을 안정적인 상태로 되돌릴 수 있도록 합니다.",
        "Other Options": [
            "롤백 중에 실패한 리소스를 건너뛰는 것은 근본적인 문제를 해결하지 않으며, 스택의 추가적인 불일치를 초래할 수 있습니다.",
            "실패한 리소스를 해결하지 않고 서비스 역할을 설정하는 것은 다른 작업이 성공할 수 있게 할 수 있지만, 현재 스택의 상태를 해결하지 못하고 나중에 더 복잡한 문제를 초래할 수 있습니다.",
            "전체 스택을 삭제하는 것은 자원과 현재 사용 중인 구성의 손실을 초래할 수 있는 극단적인 조치로, 더 나은 옵션이 있을 때는 권장되지 않습니다."
        ]
    },
    {
        "Question Number": "10",
        "Situation": "한 금융 서비스 회사가 Amazon EC2 Auto Scaling을 사용하여 애플리케이션의 확장성을 관리하고 있습니다. 이들은 애플리케이션의 수요에 따라 적절한 수의 인스턴스가 실행되고 있는지 확인하고자 합니다. 회사는 또한 Amazon CloudWatch를 사용하여 애플리케이션의 성능 지표를 모니터링하고 있습니다. 이들은 부하 변동에 대응하면서 비용을 최소화하는 효율적인 확장 정책을 설정하고자 합니다.",
        "Question": "회사가 Auto Scaling 솔루션을 최적화하기 위해 어떤 구성 단계를 밟아야 합니까? (두 가지 선택)",
        "Options": {
            "1": "과거 활용 지표를 기반으로 예측 확장을 활성화합니다.",
            "2": "비용 효율적이지 않은 인스턴스 유형을 사용하도록 Auto Scaling을 구성합니다.",
            "3": "CPU 활용도를 모니터링하고 확장 작업을 트리거하기 위해 CloudWatch 경고를 생성합니다.",
            "4": "알려진 사용 패턴에 따라 예약된 확장 작업을 구현합니다.",
            "5": "더 빠른 확장을 허용하기 위해 쿨다운 기간을 최소로 설정합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "CPU 활용도를 모니터링하고 확장 작업을 트리거하기 위해 CloudWatch 경고를 생성합니다.",
            "알려진 사용 패턴에 따라 예약된 확장 작업을 구현합니다."
        ],
        "Explanation": "CPU 활용도를 모니터링하기 위해 CloudWatch 경고를 생성하면 Auto Scaling 그룹이 부하 변화에 신속하게 반응할 수 있습니다. 예약된 확장 작업을 구현하면 예측 가능한 사용 패턴을 활용하여 필요할 때 자원이 확보되도록 하면서 비용을 효과적으로 관리할 수 있습니다.",
        "Other Options": [
            "쿨다운 기간을 최소로 설정하면 빠른 확장 작업이 발생하여 불안정성을 초래하거나 여러 확장 이벤트가 빠르게 발생함에 따라 불필요한 비용이 발생할 수 있습니다.",
            "비용 효율적이지 않은 인스턴스 유형을 사용하도록 Auto Scaling을 구성하면 추가 이점을 제공하지 않으면서 운영 비용이 증가하게 되어 최적화 목표에 반합니다.",
            "과거 활용 지표를 기반으로 예측 확장을 활성화하는 것은 시간이 지남에 따라 패턴이 변경될 경우 모든 워크로드의 요구에 항상 적합하지 않을 수 있어, 특정 경고 및 예약 작업을 설정하는 것보다 신뢰성이 떨어질 수 있습니다."
        ]
    },
    {
        "Question Number": "11",
        "Situation": "한 금융 서비스 회사가 AWS CloudFormation을 사용하여 클라우드 리소스를 관리하는 코드형 인프라(IaC) 접근 방식을 사용하고 있습니다. 이들은 배포 전에 CloudFormation 템플릿에 대한 변경 사항을 추적하고 승인할 수 있는 변경 관리 프로세스를 구현할 수 있는 솔루션이 필요합니다. 회사는 모든 변경 사항이 아키텍처 팀에 의해 검토되고 승인되도록 하고자 합니다.",
        "Question": "이 시나리오에서 CloudFormation 템플릿에 대한 변경 관리를 가장 잘 촉진할 수 있는 접근 방식은 무엇입니까?",
        "Options": {
            "1": "AWS Config 규칙을 활성화하여 CloudFormation 스택의 변경 사항을 모니터링하고 모든 업데이트에 대해 아키텍처 팀에 알립니다.",
            "2": "AWS CloudFormation StackSets를 사용하여 여러 계정 및 리전에서 변경 사항을 관리하되 승인 없이 진행합니다.",
            "3": "CloudFormation 스택에 대한 업데이트를 배포하기 전에 수동 승인 단계를 포함한 AWS CodePipeline을 구현합니다.",
            "4": "CloudFormation 템플릿을 위한 Git 리포지토리를 생성하고 검토 및 승인 프로세스를 위해 풀 요청을 활용합니다."
        },
        "Correct Answer": "CloudFormation 스택에 대한 업데이트를 배포하기 전에 수동 승인 단계를 포함한 AWS CodePipeline을 구현합니다.",
        "Explanation": "AWS CodePipeline을 사용하면 구조화된 배포 프로세스와 통합된 수동 승인 단계를 통해 CloudFormation 템플릿에 대한 모든 변경 사항이 적용되기 전에 아키텍처 팀에 의해 검토되고 승인되도록 보장합니다. 이는 변경 관리의 모범 사례와 일치합니다.",
        "Other Options": [
            "AWS CloudFormation StackSets를 사용하는 것은 여러 계정 및 리전에서 스택을 관리하는 데 더 적합하며, 변경 사항에 대한 검토 및 승인 프로세스를 본질적으로 제공하지 않으므로 설명된 시나리오에 적합하지 않습니다.",
            "Git 리포지토리를 생성하고 풀 요청을 활용하는 것은 버전 관리 및 협업을 위한 좋은 관행이지만, CloudFormation 스택의 배포 프로세스와 직접 통합되지 않아 배포에 지연과 추가 수동 단계를 초래할 수 있습니다.",
            "AWS Config 규칙을 활성화하면 변경 사항을 모니터링하는 데 도움이 되지만, 승인 워크플로우를 포함한 능동적인 변경 관리 프로세스를 제공하지 않으므로 배포 전 승인의 요구 사항을 충족하지 못합니다."
        ]
    },
    {
        "Question Number": "12",
        "Situation": "소프트웨어 개발 팀이 AWS CodePipeline을 사용하여 Amazon ECS에 배포된 애플리케이션의 CI/CD 프로세스를 관리하고 있습니다. 이들은 AWS CodeDeploy를 통합하여 배포를 보다 효율적으로 처리하고자 합니다. 팀은 다양한 배포 단계에서 Lambda 함수를 호출하기 위해 후크를 사용할 계획입니다. 또한 파이프라인 실행 중에 AWS Service Catalog에 새로운 제품 버전을 검증하고 푸시하는 프로세스를 포함하고자 합니다. 팀은 CodeDeploy가 CloudFormation 스택을 직접 배포할 수 없으며, AWS Service Catalog 배포 작업이 CodeDeploy에서 지원되지 않는다는 것을 알고 있습니다.",
        "Question": "팀이 CodePipeline 실행 중에 AWS Service Catalog에서 제품 버전을 검증하고 업데이트하는 솔루션을 구현하기 위해 무엇을 해야 합니까?",
        "Options": {
            "1": "AWS CloudFormation을 구성하여 CodePipeline 실행 중에 AWS Service Catalog에 대한 업데이트를 자동화합니다.",
            "2": "AWS Service Catalog API를 호출하고 제품 버전을 관리하기 위해 Lambda 함수를 CodePipeline 작업으로 추가합니다.",
            "3": "제품 버전 관리를 위해 AWS Service Catalog API를 호출하는 CodeDeploy 배포 후크를 사용합니다.",
            "4": "AWS Service Catalog에 푸시하기 전에 제품 버전을 검증하기 위해 파이프라인에 수동 승인 단계를 생성합니다."
        },
        "Correct Answer": "AWS Service Catalog API를 호출하고 제품 버전을 관리하기 위해 Lambda 함수를 CodePipeline 작업으로 추가합니다.",
        "Explanation": "CodePipeline의 작업으로 Lambda 함수를 추가하면 팀이 AWS Service Catalog API를 호출하여 CI/CD 워크플로의 일환으로 제품의 새로운 버전을 효과적으로 검증하고 푸시할 수 있습니다.",
        "Other Options": [
            "CodeDeploy 배포 후크를 사용하는 것은 여기서 적용되지 않으며, CodeDeploy는 AWS Service Catalog 배포 작업을 지원하지 않으므로 이 요구 사항에 적합하지 않습니다.",
            "이 작업을 위해 AWS CloudFormation을 구성하는 것은 불가능합니다. CodeDeploy가 CloudFormation 스택을 배포할 수 없기 때문에 이 옵션은 유효하지 않습니다.",
            "수동 승인 단계를 생성하는 것은 제품 버전을 검증하고 푸시하는 프로세스를 자동화하지 않으므로 팀의 배포 파이프라인 간소화 목표에 반합니다."
        ]
    },
    {
        "Question Number": "13",
        "Situation": "조직이 AWS CloudFormation을 사용하여 인프라를 코드로 관리하고 있습니다. 팀은 코드 중복 없이 다양한 환경에 쉽게 맞춤화할 수 있는 재사용 가능한 템플릿을 만들고자 합니다. 또한 특정 리소스가 특정 조건에서만 생성되도록 보장해야 하며, 서로 다른 스택 간에 출력을 공유해야 합니다.",
        "Question": "팀이 재사용성, 조건부 리소스 생성 및 스택 간 출력 공유 목표를 달성하는 데 가장 잘 도움이 되는 AWS CloudFormation 기능의 조합은 무엇입니까?",
        "Options": {
            "1": "내장 함수를 사용하여 스택 간 리소스를 직접 참조하고, 단순성을 위해 모든 값을 하드코딩하며, 복잡성을 최소화하기 위해 매개변수 사용을 피합니다.",
            "2": "중첩 스택을 활용하여 공통 리소스를 캡슐화하고, 가상 매개변수를 사용하여 계정 ID와 같은 값을 동적으로 검색하며, 부모 및 자식 스택 간에 리소스를 공유하기 위해 출력을 정의합니다.",
            "3": "매개변수를 사용하여 다양한 환경에 맞게 템플릿을 사용자 정의하고, 스택 간에 중요한 리소스 정보를 공유하기 위해 출력을 정의하며, 입력 값에 따라 리소스 생성을 제어하기 위해 조건을 활용합니다.",
            "4": "각 환경에 대해 별도의 CloudFormation 템플릿을 만들고, 템플릿에 값을 하드코딩하며, 조건 없이 리소스에 대한 정적 값을 정의하기 위해 매핑을 사용합니다."
        },
        "Correct Answer": "매개변수를 사용하여 다양한 환경에 맞게 템플릿을 사용자 정의하고, 스택 간에 중요한 리소스 정보를 공유하기 위해 출력을 정의하며, 입력 값에 따라 리소스 생성을 제어하기 위해 조건을 활용합니다.",
        "Explanation": "이 옵션은 사용자 정의를 위한 매개변수 사용, 스택 간 정보 공유를 위한 출력, 리소스 생성을 관리하기 위한 조건을 효과적으로 결합하여 CloudFormation 템플릿의 재사용성과 모듈성 요구 사항에 완벽하게 부합합니다.",
        "Other Options": [
            "이 옵션은 각 환경에 대해 별도의 템플릿을 만드는 것을 제안하는데, 이는 재사용성 목표에 모순됩니다. 값을 하드코딩하면 유연성이 제한되고 유지 관리가 더 어려워지며, 매핑은 필요한 동적 사용자 지정을 제공하지 않습니다.",
            "중첩 스택을 활용하는 것은 재사용성을 촉진할 수 있지만, 이 옵션은 템플릿을 사용자 정의하고 특정 기준에 따라 리소스 생성을 제어하는 데 필수적인 매개변수와 조건의 필요성을 간과합니다.",
            "이 옵션은 매개변수를 피하고 값을 하드코딩하라고 잘못 제안하는데, 이는 CloudFormation 템플릿의 유연성과 유지 관리성을 크게 감소시킵니다. 또한, 내장 함수는 스택 간 리소스를 공유할 때 출력의 필요성을 대체할 수 없습니다."
        ]
    },
    {
        "Question Number": "14",
        "Situation": "소프트웨어 회사가 컨테이너화를 사용하여 레거시 애플리케이션을 AWS로 마이그레이션하고 있습니다. 이 애플리케이션은 높은 가용성과 복원력을 갖춘 방식으로 배포해야 하는 여러 마이크로서비스로 구성되어 있습니다. 회사는 오케스트레이션을 위해 Amazon ECS를 활용하고 서비스가 자동으로 장애에서 복구될 수 있도록 하기를 원합니다. DevOps 엔지니어로서 이러한 요구 사항을 충족하는 솔루션을 설계해야 합니다.",
        "Question": "Amazon ECS에 배포된 컨테이너화된 마이크로서비스가 복원력이 있고 장애에서 자동으로 복구될 수 있도록 보장하기 위해 어떤 접근 방식을 취해야 합니까?",
        "Options": {
            "1": "Amazon EKS를 사용하여 자가 치유 기능이 활성화된 마이크로서비스를 배포합니다. Kubernetes Horizontal Pod Autoscaler를 구성하여 CPU 사용량 메트릭에 따라 포드 수를 관리합니다.",
            "2": "각 서비스 앞에 애플리케이션 로드 밸런서를 두고 Amazon ECS에 마이크로서비스를 배포합니다. 헬스 체크를 구성하여 트래픽을 건강한 작업으로만 유도하고 각 서비스의 원하는 수를 최대 예상 부하로 설정합니다.",
            "3": "EC2 시작 유형으로 Amazon ECS에 마이크로서비스를 배포합니다. Auto Scaling 그룹을 사용하여 인스턴스를 관리하고 서비스가 서로를 찾을 수 있도록 서비스 검색 메커니즘이 포함된 작업 정의를 구성합니다.",
            "4": "Fargate 시작 유형으로 Amazon ECS에서 마이크로서비스를 실행합니다. 배포 중 다운타임이 발생하지 않도록 최소 건강 비율을 100으로, 최대 비율을 200으로 설정합니다."
        },
        "Correct Answer": "각 서비스 앞에 애플리케이션 로드 밸런서를 두고 Amazon ECS에 마이크로서비스를 배포합니다. 헬스 체크를 구성하여 트래픽을 건강한 작업으로만 유도하고 각 서비스의 원하는 수를 최대 예상 부하로 설정합니다.",
        "Explanation": "Amazon ECS에 애플리케이션 로드 밸런서를 사용하여 마이크로서비스를 배포하면 트래픽 관리를 개선하고 건강한 작업만 트래픽을 수신하도록 보장합니다. 헬스 체크는 불건전한 작업을 자동으로 교체하는 데 도움이 되어 복원력을 제공합니다. 원하는 수를 최대 예상 부하로 설정하면 트래픽 급증을 처리할 수 있는 충분한 용량을 보장합니다.",
        "Other Options": [
            "Fargate에서 최소 건강 비율을 100으로 설정하면 배포 중에 작업을 중단할 수 없으므로 리소스 고갈 및 업데이트 배포 실패로 이어질 수 있습니다.",
            "EC2 시작 유형과 Auto Scaling 그룹을 사용하는 것은 유효한 접근 방식이지만 관리 오버헤드가 더 많이 필요합니다. 작업 정의를 적절히 구성해야 하며, 서비스 검색 메커니즘은 복원력을 크게 개선하지 않고 복잡성을 추가할 수 있습니다.",
            "Amazon EKS를 사용하는 것은 자가 치유 기능을 제공하지만 이 시나리오에는 불필요한 복잡성을 초래할 수 있습니다. 애플리케이션 로드 밸런서가 있는 ECS는 복원력 및 자동 복구 요구 사항을 충족하는 보다 간단한 솔루션입니다."
        ]
    },
    {
        "Question Number": "15",
        "Situation": "DevOps 엔지니어가 AWS에서 마이크로서비스 아키텍처의 배포 자동화를 설정하는 임무를 맡았습니다. 회사는 AWS CodeDeploy를 사용하여 애플리케이션의 배포를 관리하고 있습니다. 엔지니어는 여러 EC2 인스턴스에서 원활한 애플리케이션 업데이트를 촉진하기 위해 배포 에이전트가 올바르게 구성되도록 해야 합니다.",
        "Question": "AWS CodeDeploy의 배포 에이전트를 구성하기 위해 엔지니어가 취해야 할 조치의 조합은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "CodeDeploy 에이전트 설치 스크립트를 포함하는 CloudFormation 템플릿을 생성하고 이를 모든 관련 EC2 인스턴스에 배포합니다.",
            "2": "각 EC2 인스턴스에서 서비스로 실행되도록 CodeDeploy 에이전트를 구성하여 인스턴스 시작 시 자동으로 시작되도록 합니다.",
            "3": "배포 그룹의 일부가 될 모든 EC2 인스턴스에 최신 버전의 CodeDeploy 에이전트를 설치합니다.",
            "4": "모든 배포 후 각 EC2 인스턴스에서 CodeDeploy 에이전트를 수동으로 업데이트하여 호환성을 보장합니다.",
            "5": "AWS Systems Manager를 사용하여 배포 그룹의 모든 EC2 인스턴스에서 CodeDeploy 에이전트의 설치 및 구성을 자동화합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "배포 그룹의 일부가 될 모든 EC2 인스턴스에 최신 버전의 CodeDeploy 에이전트를 설치합니다.",
            "AWS Systems Manager를 사용하여 배포 그룹의 모든 EC2 인스턴스에서 CodeDeploy 에이전트의 설치 및 구성을 자동화합니다."
        ],
        "Explanation": "모든 EC2 인스턴스에 CodeDeploy 에이전트를 설치하면 각 인스턴스가 배포를 수신하고 실행할 수 있게 됩니다. AWS Systems Manager를 사용하여 이 프로세스를 자동화하면 효율성이 향상되고 특히 대규모 환경에서 인적 오류의 가능성이 줄어듭니다.",
        "Other Options": [
            "CloudFormation 템플릿을 만드는 것은 좋은 관행이지만 에이전트를 수동으로 설치하는 경우에는 필요하지 않습니다. 또한, 모든 인스턴스에 최신 버전의 에이전트가 설치되도록 보장하지 않습니다.",
            "CodeDeploy 에이전트를 서비스로 실행하도록 구성하는 것은 중요하지만, 초기 단계에서 모든 인스턴스에 에이전트가 올바르게 설치되어야 한다는 필요성을 해결하지 않습니다.",
            "CodeDeploy 에이전트를 수동으로 업데이트하는 것은 확장 가능한 솔루션이 아니며, 많은 EC2 인스턴스가 있는 환경에서는 운영 오버헤드를 증가시킵니다."
        ]
    },
    {
        "Question Number": "16",
        "Situation": "회사가 중요한 EC2 인스턴스에 대한 백업 전략을 구현하고 있습니다. 그들은 백업을 쉽게 식별할 수 있도록 태그를 지정하고 이러한 스냅샷의 보존을 효율적으로 관리하는 신뢰할 수 있는 스냅샷 시스템을 만들고자 합니다. DevOps 엔지니어는 스냅샷이 정기적으로 생성되고 만료된 스냅샷이 데이터 손실 없이 자동으로 정리되도록 해야 합니다. 다음 솔루션 중 이 요구 사항을 가장 효과적으로 달성할 수 있는 방법은 무엇입니까?",
        "Question": "DevOps 엔지니어가 EC2 인스턴스에 대한 효율적인 스냅샷 관리 및 데이터 복구를 보장하기 위해 어떤 접근 방식을 사용해야 합니까?",
        "Options": {
            "1": "AWS Backup을 활용하여 EC2 인스턴스의 시간별, 일별 및 주별 스냅샷을 예약하는 백업 계획을 생성합니다. 백업 태그를 활용하여 이러한 백업의 보존을 관리하고 만료된 스냅샷의 자동 삭제를 보장합니다.",
            "2": "EC2 인스턴스에서 cron 작업을 생성하여 AWS CLI를 사용해 다른 인스턴스의 스냅샷을 주기적으로 생성하고 관련 메타데이터로 이러한 스냅샷에 수동으로 태그를 지정합니다. 오래된 스냅샷을 삭제하는 별도의 스크립트를 구현합니다.",
            "3": "정기적으로 트리거되는 Lambda 함수를 구현하여 EC2 인스턴스의 스냅샷을 생성하고 'retain until' 및 'instanceId'와 같은 사용자 정의 메타데이터로 태그를 지정합니다. 만료 태그에 따라 스냅샷을 정리하는 데 동일한 함수를 사용합니다.",
            "4": "스냅샷 정책이 내장된 EC2 인스턴스를 프로비저닝하는 CloudFormation 템플릿을 설정합니다. 이러한 정책을 구성하여 스냅샷에 자동으로 태그를 지정하고 정의된 보존 전략에 따라 수명 주기를 관리합니다."
        },
        "Correct Answer": "정기적으로 트리거되는 Lambda 함수를 구현하여 EC2 인스턴스의 스냅샷을 생성하고 'retain until' 및 'instanceId'와 같은 사용자 정의 메타데이터로 태그를 지정합니다. 만료 태그에 따라 스냅샷을 정리하는 데 동일한 함수를 사용합니다.",
        "Explanation": "Lambda 함수를 사용하면 스냅샷 생성 및 정리를 자동화하고 서버리스 솔루션을 제공합니다. 태그 지정의 유연성을 허용하며, 수동 개입 없이 필요한 만큼만 스냅샷이 유지되도록 보장합니다.",
        "Other Options": [
            "스냅샷 정책을 위한 CloudFormation 템플릿 설정은 복잡할 수 있으며 Lambda 함수만큼의 자동화 및 유연성을 제공하지 않을 수 있습니다. 또한 더 많은 관리 오버헤드가 필요합니다.",
            "AWS Backup은 백업 관리에 대한 강력한 솔루션을 제공하지만, 더 간단한 Lambda 솔루션이 요구 사항을 충족할 수 있는 경우 불필요한 추가 비용과 복잡성을 초래할 수 있습니다.",
            "EC2 인스턴스에서 cron 작업을 사용하는 것은 스냅샷 관리가 해당 인스턴스의 가동 시간에 연결되므로 신뢰성 문제를 초래할 수 있습니다. 이 접근 방식은 서버리스 솔루션에 비해 더 수동적이고 비효율적입니다."
        ]
    },
    {
        "Question Number": "17",
        "Situation": "회사가 데이터베이스 워크로드를 AWS로 마이그레이션하고 있으며 MySQL 호환 애플리케이션에 Amazon Aurora를 사용하는 것을 고려하고 있습니다. DevOps 엔지니어는 성능을 최적화하면서 데이터 내구성, 가용성 및 보안을 보장해야 합니다.",
        "Question": "이 요구 사항을 가장 잘 지원하는 Amazon Aurora의 두 가지 기능은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "사용자 주도 스냅샷이 S3에 저장되며 몇 초 내에 복원할 수 있습니다.",
            "2": "비용 절감을 위해 단일 가용 영역에 하나의 백업 복사본만 유지됩니다.",
            "3": "데이터 저장소는 결함 허용 및 자가 치유 기능을 갖추고 있어 데이터 손실을 투명하게 처리합니다.",
            "4": "데이터베이스 성능에 영향을 주지 않는 자동, 지속적, 증분 백업.",
            "5": "최소한의 다운타임으로 최대 15개의 복제본 중 하나로 자동 장애 조치."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "최소한의 다운타임으로 최대 15개의 복제본 중 하나로 자동 장애 조치.",
            "데이터베이스 성능에 영향을 주지 않는 자동, 지속적, 증분 백업."
        ],
        "Explanation": "Amazon Aurora는 복제본으로의 자동 장애 조치를 제공하여 중단 시 높은 가용성과 최소한의 다운타임을 보장합니다. 또한 자동, 지속적, 증분 백업은 데이터가 데이터베이스 성능에 영향을 주지 않고 일관되게 백업되도록 보장하여 운영 효율성을 유지하는 데 중요합니다.",
        "Other Options": [
            "이 옵션은 잘못된 것입니다. Aurora는 단일 영역에 하나만 유지하는 것이 아니라 여러 가용 영역에 여러 백업 복사본을 유지합니다. 이는 내구성과 가용성을 향상시킵니다.",
            "이 옵션은 스냅샷 기능을 설명하지만 Aurora가 제공하는 자동화된 백업의 특성을 강조하지 않기 때문에 잘못된 것입니다. 이는 운영 연속성에 중요한 요소입니다.",
            "이 옵션은 오해의 소지가 있습니다. Aurora는 자가 치유 기능을 제공하지만, 데이터 가용성과 성능을 보장하는 데 가장 중요한 것은 자동 장애 조치와 지속적인 백업의 조합입니다."
        ]
    },
    {
        "Question Number": "18",
        "Situation": "회사가 Amazon EC2 인스턴스에서 Application Load Balancer (ALB) 뒤에 고트래픽 웹 애플리케이션을 운영하고 있습니다. DevOps 팀은 애플리케이션의 성능을 모니터링하고 실시간으로 잠재적인 문제를 식별해야 합니다. 그들은 특히 애플리케이션 오류 및 전체 시스템 건강과 관련된 메트릭을 추적하여 발생할 수 있는 문제에 신속하게 대응할 수 있도록 하기를 원합니다.",
        "Question": "DevOps 팀이 ALB에 대한 애플리케이션 오류 및 시스템 건강을 효과적으로 추적하기 위해 모니터링해야 할 CloudWatch 메트릭은 무엇입니까?",
        "Options": {
            "1": "CPUUtilization",
            "2": "ApproximateNumberOfMessagesDelayed",
            "3": "NetworkIn",
            "4": "HTTPCode_ELB_5XX_Count"
        },
        "Correct Answer": "HTTPCode_ELB_5XX_Count",
        "Explanation": "HTTPCode_ELB_5XX_Count는 Application Load Balancer에서 반환된 5xx 서버 오류의 수를 추적하기 위해 특별히 설계된 CloudWatch 메트릭입니다. 이 메트릭을 모니터링하면 팀이 서버 오류를 유발할 수 있는 애플리케이션 문제를 식별할 수 있어, 근본적인 문제를 신속하게 해결할 수 있습니다.",
        "Other Options": [
            "CPUUtilization은 EC2 인스턴스에서 사용된 CPU 용량의 비율을 측정하지만 ALB와 관련된 애플리케이션 오류나 건강을 직접적으로 나타내지 않습니다.",
            "ApproximateNumberOfMessagesDelayed는 Amazon SQS와 함께 사용되는 메트릭으로 ALB의 애플리케이션 성능이나 오류 모니터링과 관련이 없습니다.",
            "NetworkIn은 EC2 인스턴스로 들어오는 네트워크 트래픽의 양을 추적하며, 이는 부하를 이해하는 데 유용하지만 애플리케이션 오류나 전체 건강에 대한 통찰력을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "19",
        "Situation": "한 금융 서비스 회사가 AWS에 여러 애플리케이션을 배포했습니다. 컴플라이언스 및 보안 모범 사례를 보장하기 위해, 회사는 비준수 리소스를 자동으로 수정하기 위해 AWS Config 규칙을 구성하고자 합니다. DevOps 팀은 이러한 비준수 리소스를 식별할 뿐만 아니라 수동 개입 없이 이를 준수 상태로 되돌리기 위한 수정 조치를 취하는 솔루션을 구현해야 합니다.",
        "Question": "다음 구성 중 AWS Config에서 비준수 리소스에 대한 가장 효과적인 자동 수정 기능을 제공하는 것은 무엇입니까?",
        "Options": {
            "1": "비준수가 감지되면 새로운 리소스를 배포하기 위해 AWS CloudFormation StackSets를 사용하는 AWS Config 규칙을 구성하여 모든 리소스가 재프로비저닝되도록 합니다.",
            "2": "비준수 리소스가 감지되면 Amazon SNS를 통해 DevOps 팀에 알림을 보내도록 AWS Config 규칙을 설정하여 문제를 수동으로 수정할 수 있도록 합니다.",
            "3": "AWS Systems Manager Automation 문서에 정의된 수정 작업을 가진 AWS Config 규칙을 생성하여 비준수 리소스를 자동으로 수정합니다.",
            "4": "비준수 리소스를 Amazon S3 버킷에 기록하기 위해 AWS Lambda 함수를 트리거하는 AWS Config 규칙을 구현하여 나중에 분석 및 수동 수정을 위해 기록합니다."
        },
        "Correct Answer": "AWS Systems Manager Automation 문서에 정의된 수정 작업을 가진 AWS Config 규칙을 생성하여 비준수 리소스를 자동으로 수정합니다.",
        "Explanation": "AWS Systems Manager Automation 문서에 정의된 수정 작업을 가진 AWS Config 규칙을 생성하면 비준수를 즉시 자동으로 수정할 수 있어 리소스가 수동 개입 없이 지속적으로 준수 상태를 유지할 수 있습니다.",
        "Other Options": [
            "AWS Config 규칙을 설정하여 DevOps 팀에 Amazon SNS를 통해 알림을 보내는 것은 자동 수정을 제공하지 않으며, 수동 개입이 필요하므로 자동화의 목적을 무색하게 합니다.",
            "AWS Lambda 함수를 트리거하여 비준수 리소스를 Amazon S3 버킷에 기록하는 AWS Config 규칙을 구현하는 것은 문제를 나중에 분석하기 위해 기록할 뿐, 수정 조치를 취하지 않습니다.",
            "AWS CloudFormation StackSets를 사용하여 리소스를 재프로비저닝하도록 AWS Config 규칙을 구성하는 것은 수정에 대한 실행 가능한 솔루션이 아니며, 리소스 다운타임을 초래할 수 있고 기존 리소스의 비준수를 직접 해결하지 않습니다."
        ]
    },
    {
        "Question Number": "20",
        "Situation": "한 회사가 AWS에 마이크로서비스 아키텍처를 배포하고 Amazon CloudWatch를 모니터링에 사용하고 있습니다. DevOps 엔지니어는 마이크로서비스에서 생성된 로그 데이터를 분석하여 성능 병목 현상과 오류 비율을 식별해야 합니다. 엔지니어는 특히 CloudWatch Logs Insights를 사용하여 특정 기준에 따라 로그를 신속하게 필터링할 수 있는 쿼리를 실행하는 데 관심이 있습니다.",
        "Question": "DevOps 엔지니어가 'service-logs' 로그 그룹에서 'timeout'이라는 단어가 포함된 모든 오류 메시지를 찾기 위해 사용해야 하는 CloudWatch Logs Insights 쿼리는 무엇입니까?",
        "Options": {
            "1": "fields @timestamp, @message | filter @logStream = 'service-logs' and @message like 'timeout' | sort @timestamp desc | limit 20",
            "2": "fields @timestamp, @message | filter @logGroup = 'service-logs' and @message like 'timeout' | sort @timestamp desc | limit 20",
            "3": "fields @timestamp, @message | filter @logStream like 'service-logs' and @message = 'timeout' | sort @timestamp desc | limit 20",
            "4": "fields @timestamp, @message | filter @logGroup = 'service-logs' and @message = 'timeout' | sort @timestamp asc | limit 20"
        },
        "Correct Answer": "fields @timestamp, @message | filter @logGroup = 'service-logs' and @message like 'timeout' | sort @timestamp desc | limit 20",
        "Explanation": "올바른 쿼리는 로그 그룹 'service-logs'를 기준으로 로그를 필터링하고 'timeout'이라는 단어가 포함된 메시지를 식별하는 데 적절한 구문을 사용합니다. 또한 결과를 타임스탬프 기준으로 내림차순 정렬하여 최근 오류를 분석하는 데 적합합니다.",
        "Other Options": [
            "이 옵션은 @logStream 대신 @logGroup을 잘못 사용하여 지정된 로그 그룹에서 결과를 얻지 못합니다. 또한 메시지를 필터링하기 위해 '=' 대신 'like'라는 잘못된 연산자를 사용합니다.",
            "이 옵션은 '=' 대신 'like'를 잘못 사용하여 'timeout'이라는 단어가 포함된 메시지를 찾지 못하게 되며, 정확한 일치를 찾으려 합니다.",
            "이 옵션은 @logStream에 'like'를 잘못 사용하여 유효하지 않으며 로그를 반환하지 않습니다. 또한 'timeout'에 대해 부분 일치가 아닌 정확한 일치를 사용합니다."
        ]
    },
    {
        "Question Number": "21",
        "Situation": "한 금융 서비스 회사가 인프라를 AWS로 이전하고 있으며, 리소스를 효율적으로 관리하고 프로비저닝하기 위해 코드로서의 인프라(IaC)를 구현하고자 합니다. 팀은 전체 인프라의 배포를 반복 가능하고 버전 관리된 방식으로 자동화할 수 있도록 다양한 도구를 평가하고 있습니다. 그들은 AWS 서비스와 잘 통합되고 모듈 구성 지원이 가능한 도구에 특히 관심이 있습니다.",
        "Question": "다음 도구 중 AWS에서 코드로서의 인프라에 대한 회사의 요구를 가장 잘 지원하는 것은 무엇입니까?",
        "Options": {
            "1": "Terraform은 IaC에 대한 플랫폼 독립적인 접근 방식을 제공하며 팀이 HCL 언어를 사용하여 AWS 리소스를 관리할 수 있도록 하지만 AWS 서비스와의 통합이 원활하지 않습니다.",
            "2": "AWS OpsWorks는 Chef 또는 Puppet을 사용한 구성 관리를 제공하지만 AWS 리소스를 직접 정의하기 위한 강력한 IaC 솔루션을 제공하지 않습니다.",
            "3": "AWS CloudFormation은 팀이 JSON 또는 YAML 템플릿을 사용하여 인프라를 코드로 정의할 수 있도록 하여 버전 관리 및 손쉬운 복제를 가능하게 합니다.",
            "4": "AWS CDK는 개발자가 친숙한 프로그래밍 언어를 사용하여 클라우드 인프라를 정의할 수 있게 하여 더 높은 수준의 추상화를 제공하지만 학습 곡선이 더 가파를 수 있습니다."
        },
        "Correct Answer": "AWS CloudFormation은 팀이 JSON 또는 YAML 템플릿을 사용하여 인프라를 코드로 정의할 수 있도록 하여 버전 관리 및 손쉬운 복제를 가능하게 합니다.",
        "Explanation": "AWS CloudFormation은 AWS 리소스를 코드로 관리하기 위해 특별히 설계되었습니다. 팀이 선언적 템플릿을 사용하여 AWS 리소스를 생성, 업데이트 및 관리할 수 있도록 하여 인프라가 버전 관리되고 쉽게 복제될 수 있도록 합니다. 이는 회사의 신뢰할 수 있는 IaC 솔루션 요구와 완벽하게 일치합니다.",
        "Other Options": [
            "Terraform은 플랫폼 독립적인 강력한 IaC 솔루션을 제공하지만 AWS CloudFormation과 비교할 때 AWS 서비스와의 통합이 원활하지 않습니다.",
            "AWS OpsWorks는 애플리케이션 구성 관리에 더 중점을 두고 있으며 CloudFormation이나 Terraform과 같은 수준의 인프라 프로비저닝 기능을 제공하지 않아 회사의 요구에 덜 적합합니다.",
            "AWS CDK는 프로그래밍 언어를 사용하여 인프라를 정의할 수 있게 하여 개발자에게 유익할 수 있지만 팀의 목표에 불필요한 복잡성과 학습 곡선을 도입할 수 있습니다."
        ]
    },
    {
        "Question Number": "22",
        "Situation": "한 금융 서비스 회사가 AWS Elastic Beanstalk를 사용하여 웹 애플리케이션을 배포하고 있습니다. 그들은 애플리케이션의 새 버전을 출시할 준비를 하고 있으며, 배포 중 다운타임과 위험을 최소화하고자 합니다. DevOps 팀은 원활한 전환을 보장하기 위해 다양한 배포 전략을 고려하고 있습니다. 그들은 문제가 발생할 경우 신속하게 롤백할 수 있는 능력을 보장하면서 새로운 버전으로 트래픽을 점진적으로 전환하고자 합니다.",
        "Question": "롤백이 필요할 경우 현재 버전을 유지하면서 새 버전을 배포할 수 있는 AWS Elastic Beanstalk에서 가장 적합한 배포 전략은 무엇입니까?",
        "Options": {
            "1": "새 버전을 배포하기 위해 그린/블루 배포 전략을 사용하여 새 버전을 위한 병렬 환경을 만들고 철저한 테스트 후에만 트래픽을 전환합니다.",
            "2": "추가 배치와 함께 롤링 업데이트를 사용하여 환경의 인스턴스를 점진적으로 교체하여 성능을 모니터링할 수 있는 원활한 전환을 허용합니다.",
            "3": "불변 배포 전략을 구현하여 새 인스턴스를 별도의 환경에서 시작한 후 안정성이 확인되면 CNAME을 교환하여 트래픽을 새 환경으로 전환합니다.",
            "4": "트래픽 분할 방법을 사용하여 사용자 요청의 일부를 새 버전으로 보내고 대다수는 이전 버전을 계속 사용하여 실시간 성능 평가를 가능하게 합니다."
        },
        "Correct Answer": "불변 배포 전략을 구현하여 새 인스턴스를 별도의 환경에서 시작한 후 안정성이 확인되면 CNAME을 교환하여 트래픽을 새 환경으로 전환합니다.",
        "Explanation": "불변 배포 전략은 새 인스턴스가 새로운 환경에서 생성되도록 하여 기존 애플리케이션에 영향을 미칠 위험을 최소화합니다. 새 버전이 안정성이 확인되면 CNAME을 교환하여 다운타임 없이 신속하고 원활한 전환을 가능하게 하며, 필요 시 쉽게 롤백할 수 있습니다.",
        "Other Options": [
            "추가 배치와 함께 롤링 업데이트를 사용하는 것은 인스턴스가 점진적으로 교체되므로 위험을 초래할 수 있으며, 문제가 발생할 경우 롤백 과정이 더 복잡하고 시간이 소요될 수 있습니다.",
            "그린/블루 전략을 사용하여 새 버전을 배포하는 것도 좋은 옵션이지만, 전환이 확인될 때까지 두 개의 별도 환경을 동시에 유지해야 하므로 자원이 더 많이 소모됩니다.",
            "트래픽 분할은 새 버전에 점진적으로 노출될 수 있도록 하지만, 불변 배포만큼의 격리를 제공하지 않으므로 심각한 문제가 발생할 경우 롤백이 더 어려워집니다."
        ]
    },
    {
        "Question Number": "23",
        "Situation": "한 회사가 Amazon SQS를 사용하여 마이크로서비스 간의 메시지 큐잉을 관리하고 있습니다. 그들은 메시지 가시성을 수정하고, 큐 속성을 설정하며, 효율적인 메시지 검색을 보장하는 등 여러 요구 사항이 있습니다. DevOps 엔지니어는 이러한 요구 사항을 충족하면서 비용 효율성과 성능을 보장하기 위해 SQS 구성을 최적화하는 임무를 맡았습니다.",
        "Question": "DevOps 엔지니어가 제공된 요구 사항에 따라 메시지 처리 및 가시성을 최적화하기 위해 어떤 SQS 작업 조합을 사용해야 합니까?",
        "Options": {
            "1": "메시지 가시성 타임아웃을 12시간으로 변경하고, 수신 메시지 대기 시간을 20초로 설정하며, 처리 후 즉시 메시지를 삭제합니다.",
            "2": "긴 폴링을 위한 큐 속성을 설정하고, 메시지 가시성 타임아웃을 최대 12시간으로 변경하며, 소비 후 메시지가 삭제되도록 합니다.",
            "3": "짧은 폴링을 활성화하기 위해 큐 속성을 설정하고, 메시지 가시성 타임아웃을 1시간으로 변경하며, 비제로 지연으로 메시지를 전송합니다.",
            "4": "특정 IAM 역할이 메시지를 보낼 수 있도록 add-permission 작업을 사용하고, 긴 폴링을 위한 큐 속성을 구성하며, 지연 매개변수를 0으로 설정하여 메시지를 전송합니다."
        },
        "Correct Answer": "긴 폴링을 위한 큐 속성을 설정하고, 메시지 가시성 타임아웃을 최대 12시간으로 변경하며, 소비 후 메시지가 삭제되도록 합니다.",
        "Explanation": "이 옵션은 SQS에 대한 모범 사례와 올바르게 일치하며, 긴 폴링을 활용하여 CPU 사용량을 줄이고, 연장된 메시지 가시성 타임아웃을 허용하며, 처리 후 메시지가 즉시 삭제되도록 하여 성능과 비용을 모두 최적화합니다.",
        "Other Options": [
            "이 옵션은 처리 후 메시지를 즉시 삭제하라고 잘못 제안하고 있으며, 이는 올바르게 처리되지 않을 경우 메시지 손실로 이어질 수 있습니다. 또한 긴 폴링 구성 없이 12시간으로 가시성 타임아웃을 설정하는 것은 자원 사용을 효과적으로 최적화하지 못할 수 있습니다.",
            "이 옵션은 권한 및 지연 설정에 초점을 맞추고 있지만, 효율적인 SQS 메시지 처리를 위해 중요한 가시성 타임아웃 및 메시지 삭제 프로세스를 적절히 다루지 않습니다.",
            "이 옵션은 짧은 폴링을 활성화하라고 제안하는데, 이는 비용 증가 및 비효율적인 메시지 검색으로 이어질 수 있어 최적이 아닙니다. 가시성 타임아웃도 1시간으로 설정되어 있어 최대 요구 사항을 충족하지 않습니다."
        ]
    },
    {
        "Question Number": "24",
        "Situation": "한 회사가 보안 모범 사례 준수를 보장하기 위해 AWS 환경을 검토하고 있습니다. 그들은 노출된 AWS 액세스 키, S3 버킷의 공개 액세스, 불안전한 웹 트래픽 등 클라우드 보안 위협과 관련된 잠재적 취약점을 발견했습니다. DevOps 팀은 이러한 위협을 식별하고 수정하여 전반적인 보안 태세를 강화하는 임무를 맡았습니다.",
        "Question": "DevOps 팀이 AWS 환경에서 가장 중요한 클라우드 보안 위협을 해결하기 위해 우선적으로 수행해야 할 작업은 무엇입니까?",
        "Options": {
            "1": "모든 애플리케이션에 대해 AWS Identity and Access Management (IAM) 역할을 구현하고 코드에서 AWS 액세스 키 사용을 피합니다.",
            "2": "모든 S3 버킷이 비공개이고 공개 액세스를 허용하지 않도록 AWS Config 규칙을 구성합니다.",
            "3": "S3 버킷 버전 관리 및 로깅을 활성화하여 버킷에 저장된 민감한 데이터에 대한 액세스를 모니터링합니다.",
            "4": "AWS Shield를 사용하여 DDoS 공격으로부터 보호하고 모든 웹 트래픽이 CloudFront를 통해 라우팅되도록 합니다."
        },
        "Correct Answer": "모든 애플리케이션에 대해 AWS Identity and Access Management (IAM) 역할을 구현하고 코드에서 AWS 액세스 키 사용을 피합니다.",
        "Explanation": "노출된 AWS 액세스 키는 무단 액세스 및 잠재적인 데이터 유출로 이어질 수 있는 중요한 보안 위험입니다. IAM 역할을 구현함으로써 애플리케이션은 코드에 민감한 액세스 키를 포함하지 않고도 필요한 AWS 리소스에 안전하게 접근할 수 있어 노출 위험을 줄일 수 있습니다.",
        "Other Options": [
            "S3 버킷 버전 관리 및 로깅을 활성화하는 것은 모니터링을 위한 좋은 관행이지만, 노출된 액세스 키로 인한 즉각적인 위험을 직접적으로 해결하지는 않습니다. 이는 AWS 환경에서 무단 작업으로 이어질 수 있습니다.",
            "DDoS 공격으로부터 보호하기 위해 AWS Shield를 사용하는 것은 유익하지만, 불안전한 액세스 키나 공개 S3 버킷 액세스와 관련된 위험을 완화하지 않으며, 이는 보안 준수에 더 시급한 문제입니다.",
            "S3 버킷이 비공개인지 확인하기 위해 AWS Config 규칙을 구성하는 것은 중요하지만, 노출된 AWS 액세스 키를 먼저 해결하는 것이 더 직접적인 위험 완화가 되며, 액세스 키는 S3 액세스를 넘어 더 넓은 보안 취약점으로 이어질 수 있습니다."
        ]
    },
    {
        "Question Number": "25",
        "Situation": "DevOps 팀은 Linux 및 Windows 인스턴스를 포함하여 여러 지역에 걸쳐 대규모 EC2 인스턴스 풀을 관리하는 책임이 있습니다. 그들은 SSH 액세스나 배스천 호스트에 의존하지 않고 패치 자동화 및 일반 유지 관리 작업을 효율적으로 수행할 수 있는 솔루션을 구현하고자 합니다.",
        "Question": "이 요구 사항을 충족하기 위해 팀이 활용해야 할 AWS Systems Manager 기능의 조합은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "SSM Automation을 활용하여 인스턴스 재시작 및 패치와 같은 일상적인 작업을 위한 워크플로를 생성합니다.",
            "2": "리소스 그룹을 활용하여 태그를 기반으로 인스턴스를 정리하여 관리 용이성을 높입니다.",
            "3": "SSM Run Command를 사용하여 EC2 인스턴스에서 패치 및 유지 관리 작업을 위한 스크립트를 실행합니다.",
            "4": "SSM Session Manager를 구현하여 SSH 없이 대화형 셸 세션을 설정합니다.",
            "5": "필요할 때 EC2 인스턴스에서 수동 업데이트를 트리거하는 Lambda 함수를 생성합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "SSM Run Command를 사용하여 EC2 인스턴스에서 패치 및 유지 관리 작업을 위한 스크립트를 실행합니다.",
            "SSM Automation을 활용하여 인스턴스 재시작 및 패치와 같은 일상적인 작업을 위한 워크플로를 생성합니다."
        ],
        "Explanation": "SSM Run Command는 EC2 인스턴스에서 스크립트를 실행할 수 있게 해주어 패치 및 유지 관리 작업에 이상적입니다. SSM Automation은 이러한 작업을 위한 워크플로를 생성할 수 있는 방법을 제공하여 팀이 수동 개입 없이 작업을 자동화할 수 있게 합니다.",
        "Other Options": [
            "리소스 그룹을 활용하면 인스턴스를 정리하는 데 도움이 될 수 있지만, 패치 또는 유지 관리 작업을 직접 자동화하지는 않습니다.",
            "SSM Session Manager는 대화형 셸 세션을 허용하지만, 패치 또는 유지 관리 작업을 직접 자동화하지는 않습니다.",
            "수동 업데이트를 위한 Lambda 함수를 생성하는 것은 자동화 및 원격 관리를 위해 특별히 설계된 SSM 기능을 사용하는 것만큼 효율적이지 않습니다."
        ]
    },
    {
        "Question Number": "26",
        "Situation": "DevOps 팀은 AWS OpsWorks에 배포된 여러 애플리케이션을 관리하고 있습니다. 그들은 높은 가용성을 보장하기 위해 인스턴스에 대한 자동 복구를 구성했습니다. 그러나 특정 조건에서 자동으로 복구되지 않는 일부 인스턴스에 문제가 발생하고 있습니다. 그들은 자동 복구 설정이 효과적인지 확인하고 그 한계를 이해하고자 합니다.",
        "Question": "AWS OpsWorks의 자동 복구 기능에 관한 다음 진술 중 어떤 것이 TRUE입니까?",
        "Options": {
            "1": "OpsWorks는 자동 복구 과정에서 필요할 경우 인스턴스의 운영 체제를 자동으로 업그레이드합니다.",
            "2": "OpsWorks는 심각한 손상이나 시작 실패 오류가 있는 인스턴스를 수동 개입 없이 복구할 수 있습니다.",
            "3": "OpsWorks의 자동 복구 과정은 주로 피크 부하 동안 성능을 향상시키기 위해 설계되었습니다.",
            "4": "OpsWorks가 5분 이상 통신을 잃으면 인스턴스가 비정상으로 표시되어 자동 복구 과정이 시작됩니다."
        },
        "Correct Answer": "OpsWorks가 5분 이상 통신을 잃으면 인스턴스가 비정상으로 표시되어 자동 복구 과정이 시작됩니다.",
        "Explanation": "OpsWorks가 인스턴스와 5분 이상 통신을 잃으면 해당 인스턴스를 비정상으로 표시하고 자동 복구 과정을 시작하여 애플리케이션이 계속 사용 가능하도록 합니다.",
        "Other Options": [
            "이 진술은 잘못된 것입니다. OpsWorks는 자동 복구 과정에서 인스턴스의 운영 체제를 자동으로 업그레이드하지 않습니다. OS 업그레이드에는 수동 개입이 필요합니다.",
            "이 진술은 잘못된 것입니다. OpsWorks는 심각한 손상이나 시작 실패 오류가 있는 인스턴스를 수동 개입 없이 복구할 수 없습니다. 이러한 문제는 다른 문제 해결 접근 방식이 필요합니다.",
            "이 진술은 잘못된 것입니다. 자동 복구 과정은 성능을 향상시키기 위해 설계된 것이 아니라 비정상 인스턴스에서 복구하기 위한 실패 응답 메커니즘입니다."
        ]
    },
    {
        "Question Number": "27",
        "Situation": "소프트웨어 개발 팀은 AWS에 배포될 새로운 애플리케이션을 작업하고 있습니다. 그들은 빌드, 테스트 및 배포 프로세스를 자동화하기 위해 CI/CD 파이프라인을 구현하고 있습니다. 팀은 빌드 프로세스 중 생성된 모든 아티팩트가 안전하게 저장되고 전체 수명 주기 동안 관리될 수 있도록 해야 합니다. 목표는 내부 정책을 준수하면서 효율성과 비용을 최적화하는 것입니다. 그들은 이러한 아티팩트를 관리하기 위해 다양한 AWS 서비스를 고려하고 있습니다.",
        "Question": "DevOps 엔지니어가 준수 및 비용 최적화를 보장하면서 아티팩트 수명 주기를 효과적으로 관리하기 위해 추천해야 할 전략은 무엇입니까?",
        "Options": {
            "1": "AWS CodeCommit을 활용하여 모든 빌드 아티팩트를 저장하고 내부 정책 준수를 보장하기 위해 저장 시 암호화를 활성화합니다.",
            "2": "AWS Systems Manager Parameter Store를 활용하여 빌드 아티팩트를 저장하고 매개변수 버전 관리를 통해 시간 경과에 따른 변경 사항을 추적합니다.",
            "3": "버전 관리가 활성화된 Amazon S3를 사용하여 빌드 아티팩트를 저장하고 수명 주기 정책을 구현하여 오래된 아티팩트를 S3 Glacier로 전환하여 비용을 절감합니다.",
            "4": "Docker 이미지를 저장하기 위해 AWS Elastic Container Registry (ECR)를 구현하고 배포 전에 취약점을 식별하기 위해 이미지 스캔을 구성합니다."
        },
        "Correct Answer": "버전 관리가 활성화된 Amazon S3를 사용하여 빌드 아티팩트를 저장하고 수명 주기 정책을 구현하여 오래된 아티팩트를 S3 Glacier로 전환하여 비용을 절감합니다.",
        "Explanation": "버전 관리가 활성화된 Amazon S3를 사용하면 빌드 아티팩트를 안전하게 저장할 수 있으며, 수명 주기 정책은 오래된 아티팩트를 S3 Glacier로 전환하여 비용을 절감하면서 준수성과 접근성을 유지하는 데 도움이 됩니다.",
        "Other Options": [
            "AWS CodeCommit은 주로 소스 코드 버전 관리를 위해 설계되었으며 아티팩트 저장을 위한 것이 아닙니다. 암호화를 제공할 수 있지만 빌드 아티팩트의 수명 주기를 관리하는 데 최적화되어 있지 않습니다.",
            "AWS Elastic Container Registry (ECR)는 Docker 이미지를 관리하는 데 적합하지만 비컨테이너화된 애플리케이션이나 다른 유형의 빌드 아티팩트에 대한 아티팩트 수명 주기 관리를 다루지 않습니다.",
            "AWS Systems Manager Parameter Store는 구성 데이터 및 비밀을 저장하기 위한 것이며 빌드 아티팩트를 위한 것이 아닙니다. 대용량 이진 파일의 수명 주기를 관리하기 위해 설계되지 않았습니다."
        ]
    },
    {
        "Question Number": "28",
        "Situation": "한 회사가 Amazon API Gateway를 통해 API의 새로운 버전을 배포했습니다. 새로운 버전에는 아직 테스트 중인 기능이 포함되어 있습니다. 원활한 전환을 보장하고 위험을 최소화하기 위해 회사는 카나리 릴리스 전략을 채택했습니다. DevOps 엔지니어의 목표는 API 캐싱을 구성하여 성능을 개선하면서 변경 사항이 카나리 릴리스에만 표시되도록 하는 것입니다.",
        "Question": "DevOps 엔지니어가 API 캐싱 및 카나리 릴리스를 설정하기 위해 어떤 단계 조합을 취해야 합니까? (두 가지 선택)",
        "Options": {
            "1": "카나리 단계에서 캐시 적중 비율을 모니터링하기 위해 CloudWatch 경고를 생성하고 그에 따라 캐싱 전략을 조정합니다.",
            "2": "API Gateway에서 카나리 단계와 프로덕션 단계 간의 트래픽 분배를 제어하기 위해 단계 변수를 설정합니다.",
            "3": "API Gateway 설정에서 카나리 단계에 대해 캐싱을 활성화하고 캐시 용량을 128MB로 설정합니다.",
            "4": "트래픽을 분리하기 위해 다른 기본 경로를 가진 카나리 릴리스를 위한 사용자 지정 도메인 이름을 구현합니다.",
            "5": "API Gateway에서 캐싱을 활성화하기 위해 메서드 요청을 구성하고 캐시 키 매개변수를 지정합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "API Gateway 설정에서 카나리 단계에 대해 캐싱을 활성화하고 캐시 용량을 128MB로 설정합니다.",
            "API Gateway에서 캐싱을 활성화하기 위해 메서드 요청을 구성하고 캐시 키 매개변수를 지정합니다."
        ],
        "Explanation": "카나리 단계에서 캐싱을 활성화하면 백엔드 서비스에 대한 호출 수를 줄여 API의 응답성을 직접 개선합니다. 또한, 캐싱을 활성화하고 캐시 키 매개변수를 지정하는 메서드 요청을 구성하면 API에 대한 요청에 최적화된 캐싱 메커니즘이 보장되며, 이는 카나리 릴리스 전략에 필수적입니다.",
        "Other Options": [
            "카나리 릴리스를 위한 사용자 지정 도메인 이름을 구현하는 것은 캐싱이나 응답성을 본질적으로 향상시키지 않으며, 주로 트래픽을 분리하는 역할을 하여 캐싱 계층의 성능에 영향을 미치지 않습니다.",
            "트래픽 분배를 제어하기 위해 단계 변수를 설정하는 것은 카나리 릴리스에 중요하지만, 이는 API 캐싱과는 직접적인 관련이 없는 별개의 문제입니다.",
            "캐시 적중 비율을 모니터링하기 위해 CloudWatch 경고를 생성하는 것은 캐싱 전략 조정에 도움이 될 수 있지만, 즉각적인 성능 향상을 위해 필요한 캐싱 메커니즘을 설정하지는 않습니다."
        ]
    },
    {
        "Question Number": "29",
        "Situation": "한 회사가 AWS CloudFormation을 사용하여 리소스를 프로비저닝하는 인프라를 관리하고 있습니다. 그들은 여러 EC2 인스턴스, RDS 데이터베이스 및 S3 버킷이 포함된 복잡한 스택을 가지고 있습니다. 그러나 인스턴스가 종종 필요한 종속성 없이 시작되어 애플리케이션 배포에 지연과 실패를 초래하는 것을 발견했습니다. 그들은 EC2 인스턴스가 생성될 때 필요한 패키지가 설치되고 서비스가 실행된 후에 CloudFormation에 신호를 보내도록 하기를 원합니다.",
        "Question": "회사가 모든 인스턴스가 올바르게 구성되고 CloudFormation이 각 인스턴스의 상태를 알 수 있도록 하기 위해 어떤 AWS CloudFormation 기능 조합을 사용해야 합니까?",
        "Options": {
            "1": "AWS Lambda를 사용하여 EC2 인스턴스에서 초기화 스크립트를 실행하고 cfn-signal을 사용하여 초기화 완료를 CloudFormation에 알립니다. cfn-hup을 통합하여 인스턴스에 대한 업데이트를 동적으로 적용합니다.",
            "2": "EC2 사용자 데이터 스크립트를 구현하여 인스턴스 시작 중 패키지 설치 및 서비스 시작을 처리합니다. cfn-signal을 사용하여 CloudFormation에 인스턴스 상태를 알리고 cfn-hup을 사용하여 추가 업데이트를 처리합니다.",
            "3": "cfn-init을 사용하여 EC2 인스턴스에서 패키지를 설치하고 서비스를 시작합니다. cfn-signal을 사용하여 프로세스의 성공 또는 실패를 나타내고 WaitCondition을 활용하여 CloudFormation이 신호를 기다리도록 합니다.",
            "4": "모든 필요한 종속성이 포함된 사용자 지정 AMI를 생성하고 CloudFormation을 사용하여 배포합니다. 배포가 완료되면 cfn-signal을 사용하여 CloudFormation에 알리고 cfn-hup을 사용하여 업데이트를 확인합니다."
        },
        "Correct Answer": "cfn-init을 사용하여 EC2 인스턴스에서 패키지를 설치하고 서비스를 시작합니다. cfn-signal을 사용하여 프로세스의 성공 또는 실패를 나타내고 WaitCondition을 활용하여 CloudFormation이 신호를 기다리도록 합니다.",
        "Explanation": "CloudFormation에서 인스턴스 초기화를 관리하는 가장 효과적인 방법은 cfn-init을 사용하는 것입니다. 이는 리소스 프로비저닝 프로세스의 일환으로 패키지를 설치하고 서비스를 시작할 수 있게 해줍니다. cfn-signal과 결합하면 CloudFormation이 이러한 작업의 성공 또는 실패를 인식할 수 있어 스택의 무결성과 준비 상태를 유지할 수 있습니다.",
        "Other Options": [
            "초기화에 AWS Lambda를 사용하는 것은 이상적이지 않으며, cfn-init은 CloudFormation 내에서 이 목적을 위해 특별히 설계되었고 cfn-signal을 통한 통합 신호를 제공합니다. 이 접근 방식은 또 다른 서비스를 도입하여 스택을 복잡하게 만들 수 있습니다.",
            "사용자 지정 AMI를 생성하는 것은 효과적일 수 있지만, 동적 업데이트의 유연성이나 프로비저닝 중 인스턴스 상태를 신호하는 기능을 제공하지 않습니다. cfn-hup에만 의존하는 것은 초기 구성 요구 사항을 해결하지 않습니다.",
            "사용자 데이터 스크립트를 사용하는 것은 패키지를 설치할 수 있지만, CloudFormation의 신호 메커니즘과 원활하게 통합되지 않습니다. cfn-signal을 사용할 수 있지만, cfn-init이 제공하는 구조화된 접근 방식과 버전 관리를 결여하고 있습니다."
        ]
    },
    {
        "Question Number": "30",
        "Situation": "한 회사가 지속적인 통합 및 배포가 필요한 마이크로서비스 기반 애플리케이션을 개발하고 있습니다. 개발 팀은 테스트를 실행하고 아티팩트를 생성하며 AWS 서비스와 원활하게 통합할 수 있는 빌드 도구가 필요합니다. 그들은 이를 위해 AWS CodeBuild를 사용하는 것을 고려하고 있습니다. 팀은 빌드 환경이 수동 개입 없이 최신 종속성과 구성을 자동으로 사용하도록 설정되기를 원합니다.",
        "Question": "개발 팀이 AWS CodeBuild가 최신 종속성을 자동으로 사용하여 아티팩트를 생성하도록 올바르게 구성되도록 보장하기 위한 최선의 접근 방식은 무엇입니까?",
        "Options": {
            "1": "모든 커밋 시 CodeBuild를 트리거하고 아티팩트 생성 전에 수동 승인 단계를 포함하는 CodePipeline을 생성합니다.",
            "2": "AWS Systems Manager Parameter Store를 사용하여 종속성 버전을 관리하고 이를 buildspec.yml 파일에서 참조합니다.",
            "3": "최신 종속성 버전으로 CodeBuild 프로젝트의 buildspec.yml 파일을 업데이트하는 예약된 AWS Lambda 함수를 구현합니다.",
            "4": "buildspec.yml 파일을 사용하여 빌드 명령을 정의하고 종속성 버전을 위한 환경 변수를 설정합니다."
        },
        "Correct Answer": "AWS Systems Manager Parameter Store를 사용하여 종속성 버전을 관리하고 이를 buildspec.yml 파일에서 참조합니다.",
        "Explanation": "AWS Systems Manager Parameter Store를 사용하면 팀이 종속성 버전을 중앙에서 관리하고 업데이트할 수 있습니다. buildspec.yml에서의 이 참조는 수동 업데이트 없이 항상 최신 버전이 사용되도록 보장합니다.",
        "Other Options": [
            "buildspec.yml 파일을 사용하여 빌드 명령을 정의하는 것은 필수적이지만, 종속성 버전을 위한 환경 변수를 설정하는 것은 최신 버전으로 자동 업데이트되도록 보장하지 않습니다.",
            "수동 승인 단계를 포함한 CodePipeline을 생성하는 것은 지연을 초래하고 종속성 업데이트 프로세스를 자동화하지 않으며, 이는 주요 요구 사항입니다.",
            "예약된 AWS Lambda 함수를 구현하는 것은 업데이트를 자동화할 수 있지만, 불필요한 복잡성을 추가하고 buildspec.yml 파일을 업데이트하기 위한 추가 유지 관리가 필요합니다."
        ]
    },
    {
        "Question Number": "31",
        "Situation": "DevOps 엔지니어는 조직 내 여러 AWS 계정을 관리하는 책임이 있습니다. 엔지니어는 일관된 보안 및 규정 준수 제어를 통해 자동화된 계정 프로비저닝을 가능하게 하는 솔루션을 구현해야 합니다. 이 솔루션은 또한 모든 계정에 대한 중앙 집중식 관리 및 가시성을 제공하여 회사 정책 준수를 보장해야 합니다. 조직은 운영 효율성을 달성하기 위해 수동 프로세스를 최소화하는 것을 목표로 합니다.",
        "Question": "규정 준수 및 중앙 집중식 관리를 보장하면서 자동화된 계정 프로비저닝을 달성하는 가장 효율적인 방법은 무엇입니까?",
        "Options": {
            "1": "AWS Systems Manager를 설정하여 계정 생성 프로세스를 자동화하고, AWS Service Catalog를 사용하여 각 계정의 규정 준수 및 리소스를 관리합니다.",
            "2": "AWS Control Tower를 구현하여 안전한 다중 계정 AWS 환경을 만듭니다. 사전 구성된 가드레일을 활용하여 규정 준수를 시행하고 계정 프로비저닝을 자동화합니다.",
            "3": "AWS CloudFormation StackSets를 활용하여 수동으로 계정을 생성한 후 여러 계정에 걸쳐 구성을 배포하여 리소스 프로비저닝의 일관성을 보장합니다.",
            "4": "AWS Organizations를 사용하여 수동으로 계정을 생성한 다음, 각 계정에서 AWS Config 규칙을 구성하여 보안 및 운영 기준에 대한 규정 준수를 유지합니다."
        },
        "Correct Answer": "AWS Control Tower를 구현하여 안전한 다중 계정 AWS 환경을 만듭니다. 사전 구성된 가드레일을 활용하여 규정 준수를 시행하고 계정 프로비저닝을 자동화합니다.",
        "Explanation": "AWS Control Tower는 안전한 다중 계정 AWS 환경을 설정하고 관리하는 간소화된 접근 방식을 제공합니다. 조직 정책에 대한 규정 준수를 보장하는 청사진과 가드레일을 사용하여 계정 프로비저닝 프로세스를 자동화하여 수동 노력을 크게 줄입니다.",
        "Other Options": [
            "AWS Organizations를 사용하여 수동으로 계정을 생성하는 것은 비효율적이며, 각 계정에 대해 상당한 수동 노력이 필요합니다. 이후 각 계정에서 AWS Config 규칙을 구성하는 것은 프로비저닝을 위한 자동화된 솔루션을 제공하지 않습니다.",
            "AWS CloudFormation StackSets를 활용하는 것은 수동 계정 생성이 필요하며, 프로세스를 자동화하지 않으므로 운영 효율성 및 중앙 집중식 관리 요구 사항에 모순됩니다.",
            "AWS Systems Manager를 설정하여 계정 생성을 자동화하는 것은 AWS Control Tower만큼 효과적으로 규정 준수 및 중앙 집중식 관리를 보장하지 않습니다. AWS Control Tower는 다중 계정 거버넌스를 위해 특별히 설계되었습니다."
        ]
    },
    {
        "Question Number": "32",
        "Situation": "한 회사가 AWS에서 마이크로서비스 아키텍처를 배포하고 있으며, 애플리케이션의 효과적인 모니터링 및 로깅을 보장하여 문제를 신속하게 감지하고 규정 준수를 유지해야 합니다.",
        "Question": "회사가 애플리케이션을 효과적으로 모니터링하고 기록하는 데 도움이 되는 옵션의 조합은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "Amazon CloudWatch Alarms를 설정하여 비정상적인 성능 지표에 대해 팀에 알립니다.",
            "2": "Amazon CloudWatch Logs를 구현하여 여러 마이크로서비스의 로그 데이터를 중앙 집중화합니다.",
            "3": "AWS X-Ray를 배포하여 성능 분석을 위해 마이크로서비스 간의 요청을 추적합니다.",
            "4": "Amazon S3 버전 관리를 활성화하여 애플리케이션 로그의 변경 사항을 추적합니다.",
            "5": "AWS Lambda를 사용하여 실시간으로 로그를 처리하고 특정 이벤트에 따라 경고를 보냅니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon CloudWatch Logs를 구현하여 여러 마이크로서비스의 로그 데이터를 중앙 집중화합니다.",
            "Amazon CloudWatch Alarms를 설정하여 비정상적인 성능 지표에 대해 팀에 알립니다."
        ],
        "Explanation": "Amazon CloudWatch Logs를 구현하면 회사는 모든 마이크로서비스의 로그를 중앙 집중화하고 관리할 수 있어 문제를 분석하고 해결하기가 더 쉬워집니다. Amazon CloudWatch Alarms를 설정하면 성능 지표를 모니터링하고 팀에 이상 징후를 경고하여 잠재적인 문제에 신속하게 대응할 수 있습니다.",
        "Other Options": [
            "AWS Lambda를 로그 처리에 사용하는 것은 초기 로그 수집에 최적이 아니며, 중앙 로그 관리보다는 이벤트 기반 처리에 더 적합합니다.",
            "Amazon S3 버전 관리는 파일의 다양한 버전을 유지하는 데 유용하지만, 애플리케이션에 대한 실시간 모니터링이나 로깅 기능을 제공하지 않습니다.",
            "AWS X-Ray는 요청 추적에 유용하지만, 로그 데이터를 중앙 집중화하거나 메트릭을 효과적으로 모니터링하는 주된 목적을 수행하지 않습니다."
        ]
    },
    {
        "Question Number": "33",
        "Situation": "AWS Organizations 아래에서 여러 AWS 계정을 관리하고 있으며, 한 조직에서 다른 조직으로 멤버 계정을 전송해야 합니다. 서비스 중단을 피하기 위해 프로세스가 올바르게 실행되도록 하려 합니다.",
        "Question": "AWS 계정을 조직 A에서 조직 B로 성공적으로 이동하기 위해 어떤 단계를 수행해야 합니까?",
        "Options": {
            "1": "조직 B로 이동하기 전에 멤버 계정의 모든 IAM 역할을 조직 A의 관리 계정으로 전송합니다.",
            "2": "멤버 계정을 조직 A에서 제거하고, 조직 B에서 초대를 보내고, 멤버 계정에서 초대를 수락합니다.",
            "3": "조직 B로 이동하기 전에 멤버 계정의 리소스를 삭제한 후, 조직 B에서 초대를 보냅니다.",
            "4": "멤버 계정의 모든 서비스를 비활성화한 다음, 조직 B에서 초대를 보내지 않고 조직 A에서 제거합니다."
        },
        "Correct Answer": "멤버 계정을 조직 A에서 제거하고, 조직 B에서 초대를 보내고, 멤버 계정에서 초대를 수락합니다.",
        "Explanation": "조직 간에 AWS 계정을 성공적으로 이동하려면 먼저 현재 조직에서 계정을 제거한 다음, 새 조직에서 초대를 보내야 하며, 멤버 계정이 이를 수락해야 전송이 완료됩니다.",
        "Other Options": [
            "계정을 이동하기 전에 리소스를 삭제하는 것은 불필요하며 데이터 손실로 이어질 수 있습니다. 올바른 프로세스는 계정을 제거하고 리소스를 삭제할 필요 없이 초대를 보내는 것입니다.",
            "서비스를 비활성화하는 것은 조직 간에 계정을 이동하는 데 필요하지 않습니다. 올바른 절차는 계정을 제거하고 초대를 관리하는 데 중점을 둡니다.",
            "IAM 역할을 전송하는 것은 조직 간에 계정을 이동하는 과정의 일부가 아닙니다. 초대 프로세스와 이를 수락하는 데 중점을 두어야 합니다."
        ]
    },
    {
        "Question Number": "34",
        "Situation": "귀하는 조직을 위해 여러 AWS 계정을 관리하고 있으며, 이 중 일부 계정을 새로 생성된 AWS Organization으로 마이그레이션할 계획입니다. 모든 계정이 Reserved Instances (RIs) 및 Savings Plans 할인 혜택을 누리면서 할인 공유에 대한 통제를 유지해야 합니다.",
        "Question": "AWS Organization으로 계정을 마이그레이션할 때, 다음 중 Reserved Instances (RIs) 및 Savings Plans 할인 공유 관리를 정확하게 반영하는 진술은 무엇입니까?",
        "Options": {
            "1": "OrganizationAccountAccessRole은 마이그레이션된 각 계정에 대해 수동으로 생성해야 하며, 관리 계정은 Organization 수준에서 할인 공유를 제어할 수 있습니다.",
            "2": "관리 계정은 개별 계정에 대해 Reserved Instances 할인을 비활성화할 수 있지만 전체 Organization에 대해서는 비활성화할 수 없습니다.",
            "3": "Savings Plans 할인은 관리 계정에서 별도의 구성 없이 모든 계정에 자동으로 공유됩니다.",
            "4": "모든 계정은 자동으로 Reserved Instances 할인을 받지만, 관리 계정은 할인 공유 설정을 제어할 수 없습니다."
        },
        "Correct Answer": "OrganizationAccountAccessRole은 마이그레이션된 각 계정에 대해 수동으로 생성해야 하며, 관리 계정은 Organization 수준에서 할인 공유를 제어할 수 있습니다.",
        "Explanation": "AWS Organization으로 계정을 마이그레이션하려면 OrganizationAccountAccessRole을 수동으로 생성해야 합니다. 또한, 관리 계정은 Organization 전반에 걸쳐 Reserved Instances 및 Savings Plans 할인 공유를 제어할 수 있는 권한이 있어 모든 계정이 이러한 할인 혜택을 누릴 수 있도록 합니다.",
        "Other Options": [
            "이 옵션은 관리 계정이 전체 Organization에 대해 Reserved Instances 할인을 비활성화할 수 있으므로 잘못된 것입니다.",
            "이 진술은 관리 계정이 할인 공유 설정을 제어할 수 있으므로 잘못되었습니다.",
            "이 옵션은 Savings Plans 할인이 적용될 수 있지만 공유를 위한 구성이 필요하므로 잘못된 것입니다; 자동으로 공유되지 않습니다."
        ]
    },
    {
        "Question Number": "35",
        "Situation": "DevOps 팀이 다계층 웹 애플리케이션을 프로비저닝하기 위한 AWS CloudFormation 템플릿을 설계하고 있습니다. 그들은 템플릿이 배포 환경 및 지역에 따라 특정 값을 검색할 수 있을 만큼 유연해야 하며, 매개변수 입력에 따라 조건부로 리소스를 생성하고자 합니다.",
        "Question": "DevOps 팀이 CloudFormation 템플릿에서 사용해야 할 내장 함수는 무엇입니까? (두 개 선택)",
        "Options": {
            "1": "Fn::GetAZs",
            "2": "Fn::Select",
            "3": "Fn::If",
            "4": "Fn::Base64",
            "5": "Fn::Join"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Fn::GetAZs",
            "Fn::If"
        ],
        "Explanation": "Fn::GetAZs는 스택이 배포되는 지역의 가용 영역을 동적으로 검색하는 데 사용될 수 있어 다양한 환경에 적응할 수 있습니다. Fn::If는 입력 매개변수에 따라 조건부로 리소스를 생성할 수 있게 하여 리소스 프로비저닝의 유연성을 제공합니다.",
        "Other Options": [
            "Fn::Join은 문자열을 연결하는 데 사용되지만 배포 컨텍스트에 특정한 값의 조건부 논리나 동적 검색을 제공하지 않습니다.",
            "Fn::Base64는 주로 사용자 데이터를 인코딩하는 데 사용되며, 환경에 따라 리소스를 조건부로 생성하거나 값을 검색하는 목적에는 적합하지 않습니다.",
            "Fn::Select는 목록에서 값을 선택하는 데 유용하지만 가용 영역의 동적 검색이나 조건부 리소스 생성 요구 사항을 충족하지 않습니다."
        ]
    },
    {
        "Question Number": "36",
        "Situation": "한 조직이 AWS CodePipeline을 사용하여 배포 프로세스를 자동화하고 있습니다. 그들은 실패를 우아하게 처리하고 이전 작업의 결과에 따라 후속 파이프라인을 트리거할 수 있는 요구 사항이 있습니다. 그러나 조건부 작업 및 파이프라인의 직접 호출에 제한이 있습니다.",
        "Question": "조직이 CodePipeline에서 실패를 관리하고 필요 시 다른 파이프라인을 트리거하기 위해 어떤 접근 방식을 취해야 합니까?",
        "Options": {
            "1": "AWS EventBridge에 의해 파이프라인 실패 시 트리거되는 Lambda 함수를 구현합니다. 이 함수는 실패 유형을 확인하고 필요에 따라 다른 CodePipeline을 호출할 수 있습니다.",
            "2": "AWS Step Functions를 활용하여 CodePipeline 워크플로를 조정하고, 작업 성공 또는 실패에 따라 조건부 분기를 허용합니다.",
            "3": "CloudWatch Events를 구성하여 CodePipeline 상태를 모니터링하고, 실패를 처리하고 다른 파이프라인을 시작할 수 있는 Lambda 함수를 호출합니다.",
            "4": "CodePipeline 내에서 특정 작업의 실패 시 다른 CodePipeline을 직접 호출하는 사용자 정의 작업을 생성합니다."
        },
        "Correct Answer": "AWS EventBridge에 의해 파이프라인 실패 시 트리거되는 Lambda 함수를 구현합니다. 이 함수는 실패 유형을 확인하고 필요에 따라 다른 CodePipeline을 호출할 수 있습니다.",
        "Explanation": "AWS EventBridge를 사용하여 파이프라인 실패를 캡처하면 조직이 Lambda 함수에서 사용자 정의 논리를 구현하여 실패의 맥락에 따라 다른 파이프라인을 조건부로 호출할 수 있습니다. 이 방법은 CodePipeline 자체가 조건부 작업을 지원하지 않기 때문에 실패를 처리하는 데 필요한 유연성을 제공합니다.",
        "Other Options": [
            "AWS Step Functions는 CodePipeline 워크플로를 직접 조정하여 실패 조건을 처리할 수 없으며, CodePipeline은 조건부 작업에 대한 기본 지원이 없습니다. 또한 다른 파이프라인을 직접 호출하지 않습니다.",
            "CodePipeline 내에서 사용자 정의 작업을 생성하는 것은 CodePipeline이 다른 CodePipeline을 직접 호출할 수 없기 때문에 효과적이지 않습니다.",
            "CloudWatch Events만으로는 파이프라인 작업에 따라 조건부 논리를 관리할 수 있는 기능을 제공하지 않습니다. 실패에 적절히 대응하기 위해서는 EventBridge와 함께 Lambda 함수가 필요합니다."
        ]
    },
    {
        "Question Number": "37",
        "Situation": "DevOps 엔지니어가 상호 의존적인 리소스를 포함하는 여러 AWS CloudFormation 스택을 관리하고 있습니다. 리소스가 오류 없이 올바르게 프로비저닝되도록 특정 순서로 스택을 생성해야 합니다. 엔지니어는 CloudFormation 서비스가 리소스 간의 의존성을 이해하도록 하면서 스택 생성 관리를 간소화해야 합니다.",
        "Question": "엔지니어가 리소스 의존성과 스택 생성을 효과적으로 관리하기 위해 어떤 접근 방식을 취해야 합니까?",
        "Options": {
            "1": "각 스택을 순차적으로 수동으로 생성하여 CloudFormation을 사용하지 않고 리소스가 단계별로 프로비저닝되도록 하여 자동화된 의존성 해결을 피합니다.",
            "2": "CloudFormation StackSets를 사용하여 여러 계정 및 리전 간의 의존성을 관리하고, StackSet 기능을 활용하여 리소스 생성 및 순서를 자동으로 처리합니다.",
            "3": "AWS SDK를 사용하여 각 리소스를 올바른 순서로 생성하도록 트리거하는 Lambda 함수를 설정하여 CloudFormation 의존성 관리 시스템을 우회하여 더 많은 제어를 확보합니다.",
            "4": "CloudFormation 템플릿에서 DependsOn 속성을 활용하여 리소스 생성 순서를 지정하고, 종속 리소스가 모든 전제 조건이 완전히 프로비저닝된 후에만 생성되도록 합니다."
        },
        "Correct Answer": "CloudFormation 템플릿에서 DependsOn 속성을 활용하여 리소스 생성 순서를 지정하고, 종속 리소스가 모든 전제 조건이 완전히 프로비저닝된 후에만 생성되도록 합니다.",
        "Explanation": "DependsOn 속성을 사용하면 엔지니어가 단일 CloudFormation 스택 내에서 리소스의 생성 순서를 명시적으로 정의할 수 있어 프로비저닝 과정에서 모든 의존성이 존중되도록 보장합니다. 이 방법은 CloudFormation의 내장된 의존성 관리 기능을 효과적으로 활용합니다.",
        "Other Options": [
            "스택을 순차적으로 수동으로 생성하는 것은 비효율적이며 인적 오류가 발생하기 쉽습니다. 이는 리소스 관리 및 의존성 해결을 자동화하도록 설계된 CloudFormation의 목적을 무색하게 합니다.",
            "리소스 생성을 관리하기 위해 Lambda 함수를 사용하는 것은 제어를 제공하지만 복잡성을 도입하고 CloudFormation의 내장된 의존성 처리의 이점을 제거하여 리소스 관리에 문제를 일으킬 수 있습니다.",
            "CloudFormation StackSets를 사용하는 것은 여러 계정 및 리전에서 스택을 관리하는 데 더 적합하지만 단일 스택의 리소스 생성 내에서 의존성을 관리하는 특정 요구를 해결하지는 않습니다."
        ]
    },
    {
        "Question Number": "38",
        "Situation": "조직은 Amazon RDS 데이터베이스에 중요한 사용자 데이터를 저장하는 상태 저장 애플리케이션에 의존하고 있습니다. 가용성과 복원력을 향상시키기 위해 조직은 복제 및 장애 조치 방법을 포함하는 재해 복구 전략을 구현해야 합니다. 애플리케이션은 장애 발생 시 최소한의 다운타임과 데이터 손실을 요구합니다.",
        "Question": "DevOps 엔지니어가 재해 발생 시 애플리케이션이 최소한의 데이터 손실로 신속하게 복구할 수 있도록 보장하기 위해 어떤 솔루션을 구현해야 합니까?",
        "Options": {
            "1": "Amazon RDS Multi-AZ 배포를 활성화하여 데이터를 다른 가용 영역의 대기 인스턴스에 동기적으로 복제합니다. 기본 인스턴스 장애 발생 시 대기 인스턴스로 자동 장애 조치를 구성합니다.",
            "2": "다른 리전에서 Amazon RDS 읽기 복제본을 설정하여 교차 리전 복제를 수행합니다. 기본 인스턴스 장애 발생 시 고가용성을 보장하기 위해 읽기 복제본을 사용합니다.",
            "3": "AWS Lambda를 사용하여 주기적으로 기본 RDS 인스턴스에서 다른 리전의 보조 RDS 인스턴스로 데이터를 복사하는 사용자 정의 솔루션을 구현합니다. 필요할 때 이 인스턴스를 장애 조치에 사용합니다.",
            "4": "Amazon RDS 데이터베이스의 백업을 매시간 생성하고 Amazon S3에 저장합니다. 장애 발생 시 최신 백업에서 데이터베이스를 복원하여 다운타임을 최소화합니다."
        },
        "Correct Answer": "Amazon RDS Multi-AZ 배포를 활성화하여 데이터를 다른 가용 영역의 대기 인스턴스에 동기적으로 복제합니다. 기본 인스턴스 장애 발생 시 대기 인스턴스로 자동 장애 조치를 구성합니다.",
        "Explanation": "Amazon RDS Multi-AZ 배포를 활성화하면 자동 장애 조치 기능과 대기 인스턴스에 대한 동기 데이터 복제를 제공합니다. 이는 재해 발생 시 최소한의 다운타임과 데이터 손실을 보장하여 높은 가용성과 복원력이 필요한 상태 저장 애플리케이션에 가장 적합한 옵션입니다.",
        "Other Options": [
            "다른 리전에서 읽기 복제본을 설정하는 것은 주로 읽기 확장을 위한 것이며 Multi-AZ 배포와 같은 수준의 가용성과 자동 장애 조치를 제공하지 않습니다. 또한 읽기 작업에 대한 추가 지연을 초래합니다.",
            "매시간 백업을 생성하고 Amazon S3에 저장하는 것은 재해 복구 시 더 큰 다운타임을 초래할 수 있으며, 데이터베이스는 최신 백업에서 복원해야 하므로 마지막 백업 이후의 데이터 손실이 발생할 수 있습니다.",
            "AWS Lambda를 사용하여 주기적으로 데이터를 복사하는 사용자 정의 솔루션은 복잡성을 도입하고 데이터 복제에 지연을 초래할 수 있습니다. 또한 다운타임과 데이터 손실을 최소화하는 데 중요한 동기 복제나 자동 장애 조치를 보장하지 않습니다."
        ]
    },
    {
        "Question Number": "39",
        "Situation": "사용자는 신원 관리 및 역할 수임을 위해 사용자 정의 프록시를 사용하는 AWS 환경을 관리하고 있습니다. 기업 사용자는 Fed Proxy 도메인을 통해 인증하며, 이는 그룹 검색을 위해 LDAP와 상호 작용한 후 AWS STS에서 역할 정보를 요청합니다. 사용자가 역할을 선택하면 Fed Proxy는 STS:AssumeRole을 호출하여 콘솔 액세스를 얻습니다.",
        "Question": "사용자가 사용자 정의 프록시를 통해 AWS Management Console에 액세스할 수 있도록 보장하는 데 있어 두 가지 중요한 단계는 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "Fed Proxy는 사용자 인증 후 STS에 역할 목록 요청을 보냅니다.",
            "2": "Fed Proxy는 콘솔에 액세스하는 각 기업 사용자에 대해 새로운 IAM 사용자를 생성합니다.",
            "3": "Fed Proxy는 사용자를 인증하고 LDAP 디렉토리에서 그룹을 검색합니다.",
            "4": "Fed Proxy는 사용자가 적절한 역할을 선택한 후 STS:AssumeRole을 보냅니다.",
            "5": "STP는 콘솔 세션 동안 각 사용자의 활동에 대한 자세한 로그를 반환합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Fed Proxy는 사용자를 인증하고 LDAP 디렉토리에서 그룹을 검색합니다.",
            "Fed Proxy는 사용자가 적절한 역할을 선택한 후 STS:AssumeRole을 보냅니다."
        ],
        "Explanation": "Fed Proxy를 통한 사용자 인증과 LDAP에서 그룹 검색은 사용자 신원을 검증하고 적절한 역할 액세스를 보장하는 데 필수적입니다. 또한 STS:AssumeRole을 보내는 것은 사용자가 선택한 역할에 따라 AWS 리소스에 대한 콘솔 액세스를 얻는 데 중요합니다.",
        "Other Options": [
            "이 옵션은 각 기업 사용자에 대해 새로운 IAM 사용자를 생성하는 것이 프록시를 통한 액세스를 관리하는 실용적이거나 효율적인 방법이 아니기 때문에 잘못된 것입니다. 대신 역할 수임이 사용됩니다.",
            "이 옵션은 STP가 사용자 활동에 대한 자세한 로그를 반환하는 것이 콘솔 액세스를 얻는 과정의 핵심 기능이 아니며, 감사 및 준수와 더 관련이 있기 때문에 잘못된 것입니다.",
            "이 옵션은 역할 요청이 사용자 인증 후에 이루어져야 하며 중요하지만 인증 및 역할 수임 단계만큼 중요하지 않기 때문에 잘못된 것입니다."
        ]
    },
    {
        "Question Number": "40",
        "Situation": "한 금융 서비스 회사가 AWS 리소스와 애플리케이션을 모니터링하기 위해 Amazon CloudWatch를 사용하고 있습니다. 이들은 CloudWatch 로그를 S3 버킷으로 내보내 장기 저장 및 분석을 원합니다. 또한, 회사는 Kinesis Data Firehose를 사용하여 CloudWatch 메트릭을 데이터 레이크로 스트리밍하는 솔루션을 설정하고자 합니다. DevOps 팀은 이러한 구성이 올바르게 구현되도록 하는 임무를 맡고 있습니다.",
        "Question": "로그 내보내기 및 메트릭 스트리밍 요구 사항을 충족하기 위해 DevOps 팀이 구현해야 할 구성은 무엇입니까?",
        "Options": {
            "1": "로그 그룹과 동일한 리전에 S3 버킷을 생성합니다. CloudWatch Logs를 구성하여 이 버킷으로 로그를 내보냅니다. S3에 쓰기 권한이 있는 IAM 역할로 Kinesis Data Firehose 배달 스트림을 설정합니다.",
            "2": "로그 그룹과 다른 리전에 S3 버킷을 생성합니다. 로그를 복사하기 위해 S3 크로스 리전 복제를 활성화합니다. CloudWatch를 구성하여 Kinesis Data Firehose 배달 스트림으로 메트릭을 스트리밍합니다.",
            "3": "로그 그룹과 동일한 리전에 S3 버킷을 생성합니다. S3 크로스 리전 복사를 사용하여 로그를 다른 리전으로 복사합니다. CloudWatch를 신뢰하는 IAM 역할로 Kinesis Data Firehose 배달 스트림을 설정합니다.",
            "4": "로그 그룹과 동일한 리전에 S3 버킷을 생성합니다. CloudWatch Logs를 구성하여 이 버킷으로 직접 로그를 내보냅니다. CloudWatch를 신뢰하는 역할을 사용하여 Kinesis Data Firehose로 메트릭을 스트리밍합니다."
        },
        "Correct Answer": "로그 그룹과 동일한 리전에 S3 버킷을 생성합니다. CloudWatch Logs를 구성하여 이 버킷으로 직접 로그를 내보냅니다. CloudWatch를 신뢰하는 역할을 사용하여 Kinesis Data Firehose로 메트릭을 스트리밍합니다.",
        "Explanation": "올바른 구성은 S3 버킷이 CloudWatch 로그 그룹과 동일한 리전에 생성되도록 보장하며, 이는 로그 내보내기의 요구 사항입니다. 또한, 적절한 IAM 역할을 가진 Kinesis Data Firehose 배달 스트림을 사용하면 메트릭을 문제없이 스트리밍할 수 있습니다.",
        "Other Options": [
            "이 옵션은 S3 버킷을 다른 리전에 생성하고 크로스 리전 복제에 의존하는 잘못된 제안을 하고 있으며, 이는 로그 내보내기에 불필요하고 설정을 복잡하게 만들 수 있습니다.",
            "이 옵션은 로그에 대해 크로스 리전 복제를 사용하는 것을 제안하고 있어 잘못된 것이며, 버킷이 로그 그룹과 동일한 리전에 있을 수 있을 때는 필요하지 않습니다. 또한 Kinesis Data Firehose에 대한 신뢰 관계를 잘못 생략하고 있습니다.",
            "이 옵션은 로그에 대해 크로스 리전 복제를 사용하는 것을 잘못 강조하고 있으며, S3 버킷이 동일한 리전에 있을 경우 필요하지 않습니다. 또한 메트릭 스트리밍을 위해 CloudWatch를 신뢰하는 IAM 역할의 요구 사항을 명시하지 않고 있습니다."
        ]
    },
    {
        "Question Number": "41",
        "Situation": "한 소매 회사가 Amazon Elastic Container Service (Amazon ECS)를 활용하여 컨테이너화된 애플리케이션 배포를 관리하고 있습니다. 개발 팀은 다운타임을 최소화하고 배포 실패 시 빠른 롤백을 가능하게 하는 배포 전략을 찾고 있습니다. 현재의 배포 방법은 업데이트 중 서비스 중단을 초래하고 있습니다. DevOps 엔지니어는 팀의 요구 사항을 가장 잘 충족하는 배포 방법을 추천해야 합니다.",
        "Question": "ECS 애플리케이션의 최소 다운타임을 보장하고 빠른 롤백을 용이하게 하기 위해 DevOps 엔지니어가 추천해야 할 배포 전략은 무엇입니까?",
        "Options": {
            "1": "트래픽을 새로운 버전으로 점진적으로 전환하는 카나리 배포 전략을 구현합니다.",
            "2": "애플리케이션 인스턴스를 점진적으로 업데이트하는 롤링 배포 전략을 선택합니다.",
            "3": "현재 버전과 함께 새로운 버전을 실행하는 섀도우 배포 전략을 선택하여 사용자에게 영향을 미치지 않도록 합니다.",
            "4": "두 개의 별도 환경 간에 트래픽을 전환하는 블루/그린 배포 전략을 사용합니다."
        },
        "Correct Answer": "두 개의 별도 환경 간에 트래픽을 전환하는 블루/그린 배포 전략을 사용합니다.",
        "Explanation": "블루/그린 배포 전략은 두 개의 별도 환경(블루와 그린)을 유지할 수 있게 해줍니다. 새로운 버전을 그린 환경에 배포하는 동안 블루 환경은 여전히 트래픽을 처리합니다. 새로운 버전이 검증되면 트래픽을 그린 환경으로 전환할 수 있어 최소한의 다운타임을 보장합니다. 문제가 발생할 경우 쉽게 블루 환경으로 되돌릴 수 있어 빠른 롤백이 가능합니다.",
        "Other Options": [
            "카나리 배포 전략은 새로운 버전을 소규모 사용자 집단에 점진적으로 도입하여 전체 롤아웃 전에 위험을 줄이는 데 도움이 되지만, 블루/그린 배포만큼 다운타임을 효과적으로 최소화하지는 못할 수 있습니다.",
            "롤링 배포 전략은 인스턴스를 점진적으로 업데이트하여 업데이트 과정 중 문제가 발생할 경우 일시적인 서비스 중단을 초래할 수 있어 제로 다운타임 요구 사항에 덜 적합합니다.",
            "섀도우 배포 전략은 새로운 버전을 현재 버전과 함께 실행하지만 사용자 트래픽을 처리하지 않으므로 즉각적인 롤백이나 라이브 업데이트 중 다운타임 최소화에 적합하지 않습니다."
        ]
    },
    {
        "Question Number": "42",
        "Situation": "한 조직이 최근 AWS Control Tower를 구현하여 Account Factory를 사용하여 여러 AWS 계정을 관리하고 있습니다. 그들은 모든 계정이 조직의 정책을 준수하도록 하고, 정책 위반이 신속하게 감지되고 수정되도록 하기를 원합니다. DevOps 팀은 이러한 목표를 달성하는 데 도움이 되는 가드레일을 설정하는 임무를 맡고 있습니다.",
        "Question": "AWS Control Tower에서 정책 위반을 감지하고 수정하기 위한 가드레일을 구현하는 데 가장 좋은 방법론은 무엇입니까?",
        "Options": {
            "1": "AWS Config 규칙을 활용하여 계정 리소스를 지속적으로 모니터링하고 비준수 문제를 식별합니다.",
            "2": "리소스 프로비저닝 중 준수를 강제하기 위해 CloudFormation 훅을 사용하는 능동적인 모니터링 시스템을 설정합니다.",
            "3": "AWS 서비스 제어 정책(SCP)을 활용하여 비준수 작업을 차단하는 예방적 가드레일을 시행합니다.",
            "4": "CloudFormation 템플릿을 사용하여 리소스를 배포하면서 정책 위반을 자동으로 수정하는 GitOps 접근 방식을 구현합니다."
        },
        "Correct Answer": "AWS Config 규칙을 활용하여 계정 리소스를 지속적으로 모니터링하고 비준수 문제를 식별합니다.",
        "Explanation": "AWS Config는 AWS 리소스의 구성을 지속적으로 모니터링하고 평가하는 방법을 제공합니다. AWS Config 규칙을 사용하여 정책 위반을 감지하고 수정 조치를 취할 수 있어 AWS Control Tower에서 효과적인 탐지 가드레일 메커니즘이 됩니다.",
        "Other Options": [
            "AWS 서비스 제어 정책(SCP)은 비준수 작업을 방지할 수 있지만, 기존 위반을 감지하는 메커니즘을 제공하지 않으므로 설명된 시나리오에 덜 적합합니다.",
            "GitOps 접근 방식은 배포를 간소화할 수 있지만, 정책 위반 감지나 기존 문제에 대한 수정 전략을 본질적으로 다루지 않습니다.",
            "CloudFormation 훅은 리소스 프로비저닝 중 사용자 정의에 사용할 수 있지만, 정책 위반을 감지하고 수정하는 데 필요한 지속적인 모니터링 기능을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "43",
        "Situation": "한 회사가 AWS에 애플리케이션을 배포하여 방대한 로그 데이터를 생성하고 있습니다. 애플리케이션 성능을 효과적으로 모니터링하고 문제를 해결하기 위해 DevOps 엔지니어는 CloudWatch Logs를 사용하여 로깅 솔루션을 설정하는 임무를 맡았습니다. 요구 사항에 따르면 엔지니어는 특정 로그 이벤트를 모니터링을 위한 CloudWatch 메트릭으로 변환하는 메트릭 필터를 생성하고 로그 데이터가 특정 기간 동안 유지되도록 해야 합니다.",
        "Question": "다음 구성 중 DevOps 엔지니어가 로그 데이터에 대한 메트릭 필터를 성공적으로 생성하고 로그 그룹에 적절한 보존 설정을 할 수 있도록 하는 것은 무엇입니까?",
        "Options": {
            "1": "CloudWatch Logs에서 로그 그룹을 생성하고, 관련 로그 데이터를 추출하기 위한 필터 패턴으로 메트릭 필터를 정의하며, 로그 그룹 보존 정책을 30일로 설정합니다. 메트릭 필터가 모든 수신 로그 이벤트에 적용되도록 합니다.",
            "2": "CloudWatch Logs에서 로그 그룹을 생성하고, 데이터 포인트를 추출하기 위한 메트릭 필터를 구성하며, 보존을 7일로 설정합니다. 구성 후, 기존 로그 데이터에 적용되도록 로그 필터를 설정합니다.",
            "3": "CloudWatch Logs에서 로그 그룹을 설정하고, 메트릭을 추출하기 위한 특정 패턴으로 메트릭 필터를 생성하며, 로그를 90일 동안 유지하도록 보존 설정을 구성합니다. 메트릭 필터는 수신 로그에만 적용됩니다.",
            "4": "CloudWatch Logs에서 로그 이벤트와 일치하는 필터 패턴으로 메트릭 필터를 생성하고, 메트릭 이름과 네임스페이스를 정의하며, 보존을 1년으로 설정합니다. 이는 기존 로그 데이터가 메트릭 계산에 포함되도록 보장합니다."
        },
        "Correct Answer": "CloudWatch Logs에서 로그 그룹을 생성하고, 관련 로그 데이터를 추출하기 위한 필터 패턴으로 메트릭 필터를 정의하며, 로그 그룹 보존 정책을 30일로 설정합니다. 메트릭 필터가 모든 수신 로그 이벤트에 적용되도록 합니다.",
        "Explanation": "로그 그룹을 생성하고 필터 패턴으로 메트릭 필터를 정의하면 관련 로그 데이터를 CloudWatch 메트릭으로 추출할 수 있습니다. 보존 정책을 30일로 설정하면 데이터 보존 요구 사항을 충족하며, 수신 로그에 메트릭 필터를 적용하면 지속적인 모니터링이 보장됩니다.",
        "Other Options": [
            "이 옵션은 메트릭 필터가 기존 로그 데이터에 적용될 수 있다고 잘못 명시하고 있으며, 메트릭 필터는 생성 이후에 생성된 로그에서만 작동합니다.",
            "이 옵션은 메트릭 필터를 생성하고 보존 정책을 설정하는 데 있어 올바르지만, 필터가 모든 수신 로그 이벤트에 적용된다고 명시하지 않아 지속적인 모니터링에 필요합니다.",
            "이 옵션은 기존 로그 데이터가 메트릭 계산에 포함될 수 있다고 잘못 암시하고 있으며, 이는 메트릭 필터가 생성 이후의 새로운 로그 이벤트에서만 작동하기 때문에 CloudWatch Logs에서 지원되지 않습니다."
        ]
    },
    {
        "Question Number": "44",
        "Situation": "한 회사가 상당한 계산 능력, 높은 처리량 및 최소 지연 시간이 필요한 고성능 컴퓨팅 애플리케이션을 실행하기 위해 다양한 Amazon EC2 인스턴스 패밀리를 평가하고 있습니다. 이 애플리케이션은 집약적인 그래픽 처리를 위해 GPU의 가용성도 필요합니다. DevOps 엔지니어로서 이러한 요구 사항을 충족하기 위해 가장 적합한 EC2 인스턴스 패밀리와 세대를 추천해야 합니다.",
        "Question": "다음 중 고성능 컴퓨팅 애플리케이션의 요구 사항을 가장 잘 충족하는 EC2 인스턴스 패밀리와 세대는 무엇입니까?",
        "Options": {
            "1": "인스턴스 스토어 볼륨 지원이 있는 두 번째 세대 R5 인스턴스",
            "2": "기본 성능 기능이 있는 첫 번째 세대 T3 인스턴스",
            "3": "향상된 네트워킹 기능이 있는 네 번째 세대 G4ad 인스턴스",
            "4": "전용 EBS 최적화가 있는 세 번째 세대 C5 인스턴스"
        },
        "Correct Answer": "향상된 네트워킹 기능이 있는 네 번째 세대 G4ad 인스턴스",
        "Explanation": "G4ad 인스턴스는 그래픽 및 계산 작업을 위한 GPU 지원을 제공하여 고성능 컴퓨팅 애플리케이션에 이상적입니다. 또한 향상된 네트워킹 기능을 갖추고 있어 높은 처리량과 낮은 지연 시간을 보장하며, 애플리케이션의 요구 사항에 완벽하게 부합합니다.",
        "Other Options": [
            "C5 인스턴스는 컴퓨팅 작업에 최적화되어 있지만 애플리케이션의 그래픽 처리 요구에 필수적인 GPU 기능이 부족합니다.",
            "R5 인스턴스는 메모리 집약적인 애플리케이션을 위해 설계되었으며, 고성능 컴퓨팅 작업에 필요한 GPU 지원을 제공하지 않습니다.",
            "T3 인스턴스는 일반 용도로 적합하고 버스트 가능한 작업에 적합하지만, 집약적인 계산 작업에 필요한 성능 기능을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "45",
        "Situation": "귀하는 AWS에서 민감한 고객 데이터를 처리하는 애플리케이션의 보안 및 규정 준수를 책임지고 있습니다. 애플리케이션은 모든 데이터가 저장 및 전송 중에 암호화되도록 해야 합니다. 또한 암호화 키에 대한 액세스를 제어하면서 규제 기준을 준수하기 위한 강력한 키 관리 전략을 수립해야 합니다.",
        "Question": "이 시나리오에서 데이터 암호화 및 키 관리 요구 사항을 가장 잘 충족하는 접근 방식은 무엇입니까?",
        "Options": {
            "1": "민감한 데이터에 대해 암호화 없이 EC2 인스턴스 스토리지를 사용하고, 전송 중 데이터에 대해 네트워크 보안 조치를 의존합니다.",
            "2": "AWS Secrets Manager를 사용하여 암호화 키를 저장하고, IAM 정책을 통해 해당 키에 대한 액세스를 보호합니다.",
            "3": "타사 라이브러리를 사용하여 클라이언트 측 암호화를 구현하고, 애플리케이션 내에 암호화 키를 일반 텍스트로 저장합니다.",
            "4": "AWS Key Management Service (KMS)를 사용하여 암호화 키를 관리하고, S3를 사용하여 서버 측 암호화로 데이터를 암호화합니다."
        },
        "Correct Answer": "AWS Key Management Service (KMS)를 사용하여 암호화 키를 관리하고, S3를 사용하여 서버 측 암호화로 데이터를 암호화합니다.",
        "Explanation": "AWS Key Management Service (KMS)를 사용하면 암호화 키를 중앙에서 안전하게 관리할 수 있습니다. S3의 서버 측 암호화는 저장 중인 데이터가 자동으로 암호화되도록 하여 규정 준수 및 보안 요구 사항을 효과적으로 충족합니다.",
        "Other Options": [
            "타사 라이브러리를 사용하여 클라이언트 측 암호화를 구현하는 것은 AWS 서비스와 잘 통합되지 않을 수 있으며, 암호화 키를 일반 텍스트로 저장하는 것은 보안을 저해하는 위험이 있습니다.",
            "AWS Secrets Manager를 암호화 키에 사용하는 것은 이 시나리오에 가장 적합하지 않으며, 주로 비밀 관리를 위해 설계되었고, KMS와 같은 수준의 키 관리 기능을 제공하지 않을 수 있습니다.",
            "암호화 없이 EC2 인스턴스 스토리지를 사용하는 것은 민감한 데이터에 대해 매우 안전하지 않으며, 전송 중 데이터에 대해 네트워크 보안에만 의존하는 것은 요구 사항을 완전히 충족하지 않습니다."
        ]
    },
    {
        "Question Number": "46",
        "Situation": "한 회사가 Amazon ECS를 사용하여 AWS에서 마이크로서비스 아키텍처를 배포하였으며, 모니터링 및 로깅을 위해 Amazon CloudWatch에 의존하고 있습니다. 보안 팀은 현재 로그 수집을 위해 구성된 IAM 역할 및 권한에 대해 우려를 제기했습니다. 그들은 오직 권한이 부여된 서비스만이 CloudWatch에 로그를 기록할 수 있도록 하고, 민감한 로그 데이터가 무단 접근으로부터 보호되도록 해야 합니다. 귀하는 이러한 요구 사항을 충족하는 안전하고 효율적인 로깅 솔루션을 구현하는 임무를 맡았습니다.",
        "Question": "다음 구성 중 AWS에서 안전한 로그 수집을 보장하면서 민감한 로그 데이터에 대한 접근을 제한하는 데 가장 적합한 것은 무엇입니까?",
        "Options": {
            "1": "기존 IAM 역할을 수정하여 CloudWatch Logs에 대한 더 넓은 권한을 포함시켜 모든 서비스가 제한 없이 CloudWatch에 로그를 기록할 수 있도록 합니다.",
            "2": "각 ECS 작업에 CloudWatch 에이전트를 설정하고, CloudWatch Logs에 대한 전체 접근 권한이 있는 일반 IAM 역할을 할당합니다.",
            "3": "ECS 작업에 대해서만 CloudWatch Logs에 기록할 수 있는 권한을 가진 전용 IAM 역할을 생성하고, 민감한 데이터를 보호하기 위해 CloudWatch Logs에 대한 암호화를 활성화합니다.",
            "4": "AWS Lambda를 사용하여 로그를 처리하고, 모든 ECS 작업에서 CloudWatch Logs에 기록할 수 있는 권한을 가진 IAM 역할을 할당합니다."
        },
        "Correct Answer": "ECS 작업에 대해서만 CloudWatch Logs에 기록할 수 있는 권한을 가진 전용 IAM 역할을 생성하고, 민감한 데이터를 보호하기 위해 CloudWatch Logs에 대한 암호화를 활성화합니다.",
        "Explanation": "ECS 작업에 대한 특정 권한을 가진 전용 IAM 역할을 생성하면 오직 권한이 부여된 서비스만이 CloudWatch에 로그를 기록할 수 있습니다. CloudWatch Logs에 대한 암호화를 활성화하면 민감한 로그 데이터에 대한 추가적인 보안 계층이 추가되어 이 구성이 최선의 선택이 됩니다.",
        "Other Options": [
            "기존 IAM 역할을 수정하여 더 넓은 권한을 포함시키는 것은 로그 데이터에 대한 무단 접근 위험을 증가시켜 최소 권한 원칙을 위반합니다.",
            "각 ECS 작업에 CloudWatch 에이전트를 설정하고 전체 접근 권한이 있는 일반 IAM 역할을 할당하는 것은 로그를 불필요한 위험에 노출시키며 보안 모범 사례를 준수하지 않습니다.",
            "AWS Lambda를 사용하여 로그를 처리하고 모든 ECS 작업에서 CloudWatch Logs에 기록할 수 있는 권한을 가진 IAM 역할을 할당하는 것은 로그 데이터에 대한 광범위한 접근을 허용하여 복잡성과 잠재적인 보안 문제를 초래합니다."
        ]
    },
    {
        "Question Number": "47",
        "Situation": "한 회사가 AWS에 호스팅된 웹 애플리케이션에서 성능 문제를 겪고 있습니다. 이 애플리케이션은 EC2 인스턴스를 사용하여 자동으로 확장되도록 설계되었습니다. 트래픽이 급증하는 동안 사용자들은 느린 응답 시간을 경험하고 일부 요청이 실패합니다. DevOps 엔지니어는 높은 가용성과 성능을 보장하기 위해 확장 문제를 식별하고 수정해야 합니다.",
        "Question": "엔지니어가 확장 문제를 효과적으로 해결하기 위해 어떤 조치를 취해야 합니까? (두 가지 선택)",
        "Options": {
            "1": "각 요청의 처리 시간을 줄이기 위해 애플리케이션 코드를 최적화합니다.",
            "2": "Amazon Elastic Load Balancing을 구성하여 트래픽을 건강한 인스턴스로 자동으로 라우팅합니다.",
            "3": "AWS Global Accelerator를 활성화하여 여러 지역에 트래픽을 분산시킵니다.",
            "4": "Auto Scaling 그룹을 조정하여 더 낮은 CPU 임계값에서 더 많은 인스턴스를 추가합니다.",
            "5": "Amazon CloudWatch 경고를 구현하여 CPU 및 메모리 사용량을 모니터링합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon CloudWatch 경고를 구현하여 CPU 및 메모리 사용량을 모니터링합니다.",
            "Auto Scaling 그룹을 조정하여 더 낮은 CPU 임계값에서 더 많은 인스턴스를 추가합니다."
        ],
        "Explanation": "Amazon CloudWatch 경고를 구현함으로써 엔지니어는 EC2 인스턴스의 성능 지표를 사전에 모니터링할 수 있어, 성능 저하가 심각해지기 전에 적시에 개입할 수 있습니다. Auto Scaling 그룹을 조정하여 더 낮은 CPU 임계값에서 더 많은 인스턴스를 추가하면 애플리케이션이 피크 부하 동안 신속하게 확장되어 응답 시간을 개선하고 요청 실패를 줄일 수 있습니다.",
        "Other Options": [
            "AWS Global Accelerator를 활성화하는 것은 단일 지역 내의 확장 문제와 직접적인 관련이 없습니다. 주로 글로벌 사용자에게 성능과 가용성을 개선하지만 Auto Scaling 그룹 내의 확장 문제를 해결하지는 않습니다.",
            "애플리케이션 코드를 최적화하는 것은 항상 유익하지만, 피크 트래픽 동안 충분하지 않은 EC2 인스턴스로 인한 즉각적인 확장 문제를 해결하지는 않습니다. 부하를 처리하기 위해 확장 작업이 우선시되어야 합니다.",
            "Amazon Elastic Load Balancing을 구성하는 것은 트래픽 분산에 중요하지만, 성능 문제가 발생할 때 인스턴스 수를 확장하는 문제를 직접적으로 해결하지는 않습니다. 이는 확장을 보완하지만 대체하지는 않습니다."
        ]
    },
    {
        "Question Number": "48",
        "Situation": "한 회사가 AWS Control Tower를 사용하여 계정 관리를 간소화하고 거버넌스를 개선하기 위해 다중 계정 전략을 구현하고자 합니다. 그들은 Account Factory를 활용하여 자동화된 계정 프로비저닝을 보장하고, 회사 정책을 준수하며 각 계정에 대한 사용자 정의 구성을 가능하게 하기를 원합니다. DevOps 엔지니어는 설정이 효율적이며 여러 계정에 걸쳐 확장에 대한 모범 사례와 일치하는지 확인해야 합니다.",
        "Question": "DevOps 엔지니어가 AWS Control Tower 및 Account Factory를 사용하여 맞춤형 계정 프로비저닝 프로세스를 구현하기 위해 가장 효과적인 접근 방식은 무엇입니까?",
        "Options": {
            "1": "Account Factory Customization을 구현하여 사용자 정의 청사진을 사용하여 계정 프로비저닝을 조정하고, 각 계정이 특정 요구 사항을 충족하면서 AWS Control Tower의 모범 사례를 준수하도록 합니다.",
            "2": "AWS Service Catalog를 활용하여 Account Factory를 우회하여 계정 프로비저닝을 위한 제품을 생성합니다. 이는 계정 구성 및 거버넌스의 일관성을 저해할 수 있습니다.",
            "3": "Account Factory를 활용하여 새로운 계정을 프로비저닝하고 각 계정에 대해 표준 청사진을 적용하여 AWS Organizations 서비스에서 설정한 조직 정책을 준수합니다.",
            "4": "Account Factory 외부에서 계정을 프로비저닝하는 사용자 정의 CloudFormation 템플릿을 생성하여 완전한 유연성을 제공하지만 거버넌스 기능을 줄입니다."
        },
        "Correct Answer": "Account Factory Customization을 구현하여 사용자 정의 청사진을 사용하여 계정 프로비저닝을 조정하고, 각 계정이 특정 요구 사항을 충족하면서 AWS Control Tower의 모범 사례를 준수하도록 합니다.",
        "Explanation": "사용자 정의 청사진을 사용한 Account Factory Customization을 구현하면 DevOps 엔지니어는 특정 조직의 요구 사항을 충족하도록 계정 프로비저닝 프로세스를 효과적으로 조정할 수 있으며, 여전히 AWS Control Tower가 제공하는 거버넌스 및 준수를 준수할 수 있습니다. 이 접근 방식은 사용자 정의와 모범 사례 준수 간의 균형을 보장합니다.",
        "Other Options": [
            "표준 청사진을 사용하여 Account Factory를 활용하는 것은 특정 조직 요구 사항에 필요한 사용자 정의 수준을 제공하지 않아 프로비저닝 프로세스의 효과를 제한합니다.",
            "Account Factory 외부에서 사용자 정의 CloudFormation 템플릿을 생성하는 것은 AWS Control Tower를 사용할 때의 거버넌스 및 준수 이점을 손상시켜 계정 관리의 일관성을 저해할 수 있습니다.",
            "계정 프로비저닝을 위해 AWS Service Catalog를 사용하여 Account Factory를 우회하면 표준화 및 감독 부족으로 이어져 AWS Control Tower가 제공하는 중앙 집중식 관리 전략의 이점을 약화시킬 수 있습니다."
        ]
    },
    {
        "Question Number": "49",
        "Situation": "당신은 AWS에서 마이크로서비스 아키텍처를 관리하고 있으며, 자주 구성 변경과 애플리케이션 설정 배포가 필요합니다. 팀은 코드와 별도로 애플리케이션 구성을 관리할 수 있는 솔루션이 필요하며, 이러한 구성을 애플리케이션을 재배포하지 않고도 업데이트할 수 있어야 합니다. 또한, 변경 사항을 추적하고 필요 시 구성을 롤백할 수 있는 능력을 유지하고자 합니다.",
        "Question": "이 시나리오에서 동적 애플리케이션 구성을 관리하는 데 가장 적합한 서비스는 무엇입니까?",
        "Options": {
            "1": "AWS OpsWorks",
            "2": "AWS Systems Manager",
            "3": "AWS AppConfig",
            "4": "AWS Config"
        },
        "Correct Answer": "AWS AppConfig",
        "Explanation": "AWS AppConfig는 코드와 별도로 애플리케이션 구성을 관리하도록 특별히 설계되었습니다. 구성에 대한 동적 업데이트, 변경 사항 추적 및 이전 구성으로의 롤백을 허용하여 마이크로서비스 아키텍처에 이상적입니다.",
        "Other Options": [
            "AWS Systems Manager는 구성 관리 기능을 제공하지만, 동적 애플리케이션 구성보다는 AWS 리소스의 상태 관리에 더 중점을 둡니다.",
            "AWS OpsWorks는 Chef 또는 Puppet을 사용하여 애플리케이션 배포 및 관리를 중심으로 하는 구성 관리 서비스이지만, AWS AppConfig만큼 효과적으로 동적 애플리케이션 구성 관리를 제공하지 않습니다.",
            "AWS Config는 주로 리소스 구성 추적 및 준수 감사에 사용되며, 동적 애플리케이션 구성 관리를 위한 것이 아니므로 이 사용 사례에 적합하지 않습니다."
        ]
    },
    {
        "Question Number": "50",
        "Situation": "한 회사가 피크 시간 동안 AWS Lambda 함수에 대한 트래픽이 증가하고 있습니다. 그들은 AWS Application Auto Scaling을 사용하여 더 많은 부하에서 Lambda 함수의 성능을 향상시키고자 합니다. 또한, Lambda 함수가 처리 완료 후에도 계속 실행되어야 하는 외부 확장이 동일한 실행 환경 내에서 독립적으로 실행되고 있습니다.",
        "Question": "DevOps 엔지니어는 Lambda 함수의 성능을 개선하면서 외부 확장이 지속적으로 작동할 수 있도록 하기 위해 어떤 접근 방식을 취해야 합니까?",
        "Options": {
            "1": "AWS Application Auto Scaling을 구현하여 Lambda 함수의 동시성 한도를 증가시키고 외부 확장이 공유 액세스를 위해 별도의 Lambda 레이어에서 작동하도록 구성합니다.",
            "2": "AWS Application Auto Scaling을 설정하여 Lambda 함수의 프로비저닝된 동시성을 조정하고 외부 확장을 Lambda 함수와 통신하는 별도의 AWS Fargate 작업으로 배포합니다.",
            "3": "AWS Application Auto Scaling을 활용하여 Lambda 함수에 대해 예약된 동시성을 활성화하고 외부 확장이 Amazon ECS에서 관리되는 별도의 컨테이너화된 서비스에서 독립적으로 실행되도록 합니다.",
            "4": "AWS Application Auto Scaling을 구성하여 Lambda 함수의 동시성 한도의 스케일링을 관리하면서 외부 확장이 Lambda 배포 패키지 내에 포함되도록 합니다."
        },
        "Correct Answer": "AWS Application Auto Scaling을 활용하여 Lambda 함수에 대해 예약된 동시성을 활성화하고 외부 확장이 Amazon ECS에서 관리되는 별도의 컨테이너화된 서비스에서 독립적으로 실행되도록 합니다.",
        "Explanation": "AWS Application Auto Scaling을 활용하여 예약된 동시성을 활성화하면 Lambda 함수가 증가하는 부하를 효과적으로 처리할 수 있으며, 외부 확장을 Amazon ECS와 같은 별도의 컨테이너화된 서비스에서 관리함으로써 독립적으로 실행되고 계속 처리할 수 있도록 보장합니다.",
        "Other Options": [
            "AWS Application Auto Scaling을 구현하여 Lambda 함수의 동시성 한도를 증가시키고 외부 확장을 Lambda 레이어 내에서 구성하는 것은 함수 호출 완료 후 확장이 독립적으로 실행될 수 없게 합니다.",
            "AWS Application Auto Scaling을 구성하여 Lambda 함수의 동시성 스케일링을 관리하면서 확장을 배포 패키지 내에 포함하는 것은 확장이 독립적으로 작동할 수 있는 능력을 제한하고 별도의 리소스 관리의 이점을 활용하지 못합니다.",
            "프로비저닝된 동시성을 위해 AWS Application Auto Scaling을 설정하는 것은 성능을 개선하지만, 외부 확장을 Fargate 작업으로 배포하는 것은 ECS 내에서 별도의 서비스로 효과적으로 관리할 수 있을 때 불필요하게 아키텍처를 복잡하게 만듭니다."
        ]
    },
    {
        "Question Number": "51",
        "Situation": "한 회사는 부서별로 여러 AWS 계정을 보유하고 있으며, AWS CloudFormation StackSets를 사용하여 이러한 계정과 리전 전반에 걸쳐 인프라를 코드로 관리하고 있습니다. DevOps 엔지니어는 CloudFormation 템플릿에 대한 변경 사항이 최소한의 수동 개입으로 모든 계정과 리전에서 일관되게 신뢰성 있게 전파될 수 있도록 해야 합니다.",
        "Question": "이 요구 사항을 어떻게 구현해야 합니까? (두 가지 선택)",
        "Options": {
            "1": "AWS Organizations를 사용하여 CloudFormation StackSets에 대한 변경을 특정 계정으로 제한하는 서비스 제어 정책을 생성하여 권한이 있는 계정만 변경할 수 있도록 합니다.",
            "2": "CloudFormation 템플릿의 변경 사항에 따라 트리거되는 AWS Lambda 함수를 설정하고 모든 대상 계정과 리전에서 StackSet을 자동으로 업데이트합니다.",
            "3": "교차 계정 액세스를 위한 필수 IAM 역할과 권한으로 CloudFormation StackSet을 생성합니다. StackSet을 사용하여 모든 대상 계정과 리전으로 변경 사항을 배포합니다.",
            "4": "CloudFormation Guard를 활용하여 배포 전에 템플릿을 검증하여 모든 계정에서 회사 정책 및 표준 준수를 보장합니다.",
            "5": "AWS Management Console을 사용하여 각 계정과 리전에 CloudFormation 템플릿을 수동으로 배포하여 모든 변경 사항이 올바르게 적용되도록 합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "교차 계정 액세스를 위한 필수 IAM 역할과 권한으로 CloudFormation StackSet을 생성합니다. StackSet을 사용하여 모든 대상 계정과 리전으로 변경 사항을 배포합니다.",
            "CloudFormation 템플릿의 변경 사항에 따라 트리거되는 AWS Lambda 함수를 설정하고 모든 대상 계정과 리전에서 StackSet을 자동으로 업데이트합니다."
        ],
        "Explanation": "CloudFormation StackSets를 사용하면 여러 계정과 리전에서 CloudFormation 템플릿을 일관되게 배포할 수 있습니다. 올바른 옵션은 StackSets의 기능을 활용하여 변경 사항을 포괄적으로 전파하고 Lambda를 통해 프로세스를 자동화하여 최소한의 수동 개입을 보장합니다.",
        "Other Options": [
            "검증을 위한 CloudFormation Guard 사용은 좋은 관행이지만, 계정과 리전 간의 변경 사항 전파 요구 사항을 직접적으로 해결하지는 않습니다. 이는 배포보다는 준수 검토에 더 중점을 둡니다.",
            "각 계정과 리전에 템플릿을 수동으로 배포하는 것은 비효율적이며 오류가 발생하기 쉬우며, 상당한 수동 노력이 필요하고 StackSets의 자동화 기능을 활용하지 못합니다.",
            "AWS Organizations를 통한 서비스 제어 정책 구현은 거버넌스에 도움이 되지만, CloudFormation 변경 사항을 계정과 리전 간에 전파하는 데 도움이 되지 않으며, 이는 여기서의 주요 요구 사항입니다."
        ]
    },
    {
        "Question Number": "52",
        "Situation": "소프트웨어 개발 팀이 AWS CodeBuild를 활용하여 CodeCommit에 저장된 애플리케이션의 빌드 프로세스를 자동화하고 있습니다. 그들은 최신 빌드 상태를 반영하고 공개 URL을 통해 접근할 수 있는 빌드 배지를 포함하고 싶어합니다. 또한, 그들은 풀 리퀘스트(PR)에 대한 빌드를 트리거하고 빌드 결과에 따라 PR을 업데이트할 수 있는 기능이 필요합니다. DevOps 엔지니어는 이러한 요구 사항이 효율적으로 충족되도록 해야 합니다.",
        "Question": "DevOps 엔지니어는 AWS 서비스를 사용하여 빌드 배지를 구현하고 PR 빌드 프로세스를 자동화하기 위해 어떻게 해야 합니까?",
        "Options": {
            "1": "각 브랜치에 대해 CodeBuild에서 빌드 배지를 활성화하되, PR 빌드 및 그 결과를 처리하기 위해 수동 프로세스에 의존합니다.",
            "2": "AWS Lambda를 활용하여 각 커밋에 대해 수동으로 빌드 배지를 생성하고 CloudWatch Events를 사용하여 PR에 대한 빌드를 트리거하되 PR 상태는 업데이트하지 않습니다.",
            "3": "빌드 상태를 표시하기 위해 독립형 웹 애플리케이션을 만들고 CodePipeline을 사용하여 PR 빌드를 관리하되 PR의 자동 업데이트는 없습니다.",
            "4": "CodeBuild 프로젝트를 구성하여 빌드 배지를 생성하고 EventBridge를 사용하여 새로운 PR에 대한 빌드를 트리거하며 빌드 상태로 PR을 업데이트합니다."
        },
        "Correct Answer": "CodeBuild 프로젝트를 구성하여 빌드 배지를 생성하고 EventBridge를 사용하여 새로운 PR에 대한 빌드를 트리거하며 빌드 상태로 PR을 업데이트합니다.",
        "Explanation": "이 옵션은 AWS 서비스를 효과적으로 활용하여 요구 사항을 직접적으로 해결합니다. CodeBuild를 구성하여 빌드 배지를 생성하고 EventBridge를 사용하여 빌드 트리거 및 PR 업데이트를 자동화함으로써 효율적이고 간소화된 워크플로우를 보장합니다.",
        "Other Options": [
            "이 옵션은 빌드 배지를 생성하기 위한 수동 접근 방식을 제안하며, 이는 비효율적이고 자동화의 목표에 반합니다. 또한 빌드 후 PR 상태 업데이트를 포함하지 않습니다.",
            "이 옵션은 빌드 배지를 활성화하지만 PR 빌드를 처리하기 위해 수동 프로세스에 의존하며, 이는 자동화 및 PR 상태의 동적 업데이트 요구 사항을 충족하지 않습니다.",
            "이 옵션은 상태를 표시하기 위해 별도의 애플리케이션을 구축할 것을 제안하며, 이는 불필요한 복잡성을 추가하고 AWS 서비스의 내장 기능을 활용하여 빌드 프로세스 및 PR 업데이트를 자동화하지 않습니다."
        ]
    },
    {
        "Question Number": "53",
        "Situation": "한 의료 기관이 애플리케이션을 AWS로 마이그레이션하고 있으며, 민감한 환자 데이터에 대한 접근이 효과적으로 제어되도록 해야 합니다. 그들은 사용자 역할 및 사용자와 데이터의 특정 속성을 기반으로 접근을 허용하는 보안 모델을 구현하고 싶어합니다. 이 기관은 AWS IAM을 사용하여 신원 관리를 하고 있으며, 준수 기준을 충족하고 무단 접근의 위험을 최소화하는 솔루션을 채택해야 합니다. DevOps 엔지니어는 이 접근 제어 메커니즘을 구현하는 임무를 맡고 있습니다.",
        "Question": "어떤 솔루션이 조직의 AWS 리소스에 대한 역할 기반 및 속성 기반 접근 제어 패턴을 가장 잘 구현합니까?",
        "Options": {
            "1": "각 사용자 그룹에 대해 IAM 역할을 정의하고 AWS Organizations를 구현하여 조직 단위에 따라 리소스 접근을 제한하는 계정 수준 정책을 관리합니다.",
            "2": "특정 권한을 가진 IAM 역할을 생성하고 부서 및 보안 승인과 같은 사용자 속성을 기반으로 접근을 제한하는 리소스 기반 정책을 적용합니다.",
            "3": "AWS SSO를 사용하여 사용자 그룹을 생성하고 역할에 따라 권한을 부여하며, AWS Resource Access Manager를 활용하여 계정 간 리소스를 공유합니다.",
            "4": "AWS IAM을 구현하여 사용자 역할과 속성을 모두 활용하여 민감한 리소스에 대한 접근 제한을 시행하는 세분화된 접근 제어 정책을 사용합니다."
        },
        "Correct Answer": "AWS IAM을 구현하여 사용자 역할과 속성을 모두 활용하여 민감한 리소스에 대한 접근 제한을 시행하는 세분화된 접근 제어 정책을 사용합니다.",
        "Explanation": "이 옵션은 사용자 속성과 역할에 따라 조건을 지정할 수 있는 세분화된 접근 제어 정책을 생성할 수 있는 AWS IAM의 기능을 활용하여 포괄적인 접근 방식을 허용합니다. 이는 의료 분야의 준수 요구 사항에 적합한 강력한 보안 모델을 보장합니다.",
        "Other Options": [
            "이 옵션은 리소스 기반 정책에 초점을 맞추지만, 조직의 요구 사항에 중요한 속성 기반 접근 제어를 시행하기 위해 AWS IAM의 기능을 완전히 활용하지 않습니다.",
            "이 옵션은 계정 수준에서 권한을 효과적으로 관리하지만, 사용자 속성을 기반으로 특정 리소스에 대한 세분화된 접근 제어의 필요성을 해결하지 않습니다.",
            "이 옵션은 속성 기반 접근 제어를 통합하지 않으며, AWS SSO는 주로 그룹 기반 권한을 처리하므로 사용자 속성을 기반으로 접근을 제어하는 데 필요한 세분화가 부족합니다."
        ]
    },
    {
        "Question Number": "54",
        "Situation": "클라우드 솔루션 아키텍트가 대규모 애플리케이션을 위한 AWS CloudFormation 스택을 관리하는 임무를 맡고 있습니다. 아키텍트는 스택 수정 중에 특정 중요한 리소스가 우발적인 업데이트로부터 보호되도록 해야 합니다. 아키텍트는 더 나은 조직을 위해 중첩 스택 사용을 고려하고 있지만, 모범 사례를 준수하고자 합니다.",
        "Question": "아키텍트는 리소스 보호를 시행하고 중첩 스택을 효과적으로 관리하기 위해 어떤 접근 방식을 취해야 합니까?",
        "Options": {
            "1": "비판적이지 않은 리소스에 대해서만 업데이트를 명시적으로 허용하는 스택 정책을 정의합니다. 중첩 스택을 업데이트하기 전에 루트 스택이 업데이트되도록 합니다.",
            "2": "모든 리소스에 대한 업데이트를 기본적으로 거부하고 특정 리소스에 대한 업데이트를 허용하는 스택 정책을 생성합니다. 항상 루트 스택을 업데이트하기 전에 중첩 스택을 업데이트합니다.",
            "3": "특정 중요한 리소스를 제외한 모든 리소스에 대한 업데이트를 허용하는 스택 정책을 구현합니다. 모든 중첩 스택이 수정된 후에만 부모 스택을 업데이트합니다.",
            "4": "지정된 중요한 리소스에 대해서만 업데이트를 허용하는 스택 정책을 설정합니다. 중첩 스택보다 먼저 루트 스택의 업데이트가 수행되도록 합니다."
        },
        "Correct Answer": "비판적이지 않은 리소스에 대해서만 업데이트를 명시적으로 허용하는 스택 정책을 정의합니다. 중첩 스택을 업데이트하기 전에 루트 스택이 업데이트되도록 합니다.",
        "Explanation": "비판적이지 않은 리소스에 대해서만 업데이트를 명시적으로 허용하는 스택 정책을 정의함으로써 아키텍트는 업데이트 중에 중요한 리소스가 보호되도록 합니다. 또한, 루트 스택을 먼저 업데이트하는 것은 중첩 스택에 대한 모범 사례와 일치합니다.",
        "Other Options": [
            "이 옵션은 모든 리소스에 대한 업데이트를 거부하는 스택 정책을 생성하는 것이 너무 제한적이며, 비판적이지 않은 리소스에 대한 필요한 업데이트를 방해할 수 있기 때문에 잘못된 것입니다.",
            "이 옵션은 비판적이지 않은 리소스에 대한 업데이트를 허용하는 스택 정책을 구현하지만, 충분한 보호를 제공하지 않으며 우발적인 변경으로 이어질 수 있기 때문에 잘못된 것입니다.",
            "이 옵션은 중첩 스택을 루트 스택보다 먼저 업데이트하라고 제안하고 있어, 이는 모범 사례가 아니며 의존성 문제를 초래할 수 있기 때문에 잘못된 것입니다."
        ]
    },
    {
        "Question Number": "55",
        "Situation": "귀사는 기존의 기업 자격 증명을 사용하여 직원들이 AWS 리소스에 접근할 수 있도록 기업 아이덴티티 연합 솔루션을 구현하고 있습니다. 귀사는 SAML 기반의 아이덴티티 제공자(IdP)를 사용하며, 이 솔루션이 보안 및 접근 관리에 대한 모범 사례를 준수하도록 하고자 합니다.",
        "Question": "다음 구성 중 임시 AWS 자격 증명의 사용을 최적화하면서 관리 오버헤드를 최소화하고 보안을 유지하는 데 가장 적합한 것은 무엇입니까?",
        "Options": {
            "1": "단기 세션에 대해 STS:AssumeRole을 사용하고 장기 접근에 대해 GetFederationToken을 사용합니다.",
            "2": "모든 사용자에게 GetFederationToken을 발급하는 맞춤형 연합 프록시를 구현합니다.",
            "3": "임시 접근을 위해 SAML 주장을 IAM 역할에 직접 매핑하도록 구성합니다.",
            "4": "AWS Directory Service를 SAML과 함께 사용하고 역할 가정만 구성합니다."
        },
        "Correct Answer": "임시 접근을 위해 SAML 주장을 IAM 역할에 직접 매핑하도록 구성합니다.",
        "Explanation": "SAML 주장을 IAM 역할에 직접 매핑하도록 구성하면 기존의 기업 자격 증명을 활용하면서 AWS 리소스에 대한 원활한 임시 접근이 가능합니다. 이 방법은 사용자가 필요한 권한만 가지도록 보장하여 보안 모범 사례를 지원하고, 별도의 토큰 생성을 없애어 접근 관리의 간소화를 이룹니다.",
        "Other Options": [
            "AWS Directory Service를 SAML과 함께 사용하고 역할 가정만 구성하는 것은 단기 자격 증명의 이점을 충분히 활용하지 못하며, 역할을 별도로 관리하는 데 있어 관리 오버헤드가 증가할 수 있습니다.",
            "모든 사용자에게 GetFederationToken을 발급하는 맞춤형 연합 프록시를 구현하는 것은 아키텍처를 복잡하게 만들고 관리 노력을 증가시킬 수 있으며, 이는 토큰 수명 및 권한에 대한 추가 관리가 필요할 수 있습니다.",
            "단기 세션에 대해 STS:AssumeRole을 사용하고 장기 접근에 대해 GetFederationToken을 사용하는 것은 두 가지 다른 접근 방법을 관리하는 데 불필요한 복잡성을 초래하여 혼란과 관리 오버헤드를 증가시킬 수 있습니다."
        ]
    },
    {
        "Question Number": "56",
        "Situation": "한 금융 서비스 회사가 AWS로 거래 데이터베이스를 마이그레이션하고 있습니다. 그들은 빠르고 신뢰할 수 있으며 비용 효율적인 데이터베이스 솔루션이 필요하며, 높은 가용성과 내결함성을 보장해야 합니다. 회사는 데이터가 증가함에 따라 자동 백업, 시점 복구 및 원활한 확장을 허용하는 솔루션을 구현해야 합니다. 보안 또한 주요 관심사이며, 데이터베이스는 전송 중 및 저장 중 암호화를 지원해야 합니다. 이러한 요구 사항을 고려하여 회사는 Amazon Aurora를 데이터베이스 솔루션으로 고려하고 있습니다.",
        "Question": "DevOps 엔지니어로서 Amazon Aurora를 사용하기 위한 회사의 요구 사항을 가장 잘 충족하는 구성은 무엇입니까?",
        "Options": {
            "1": "접근을 단순화하기 위해 VPC 외부에 Amazon Aurora MySQL 호환 에디션 데이터베이스 인스턴스를 생성합니다. 자동 백업 및 시점 복구를 비활성화하고, 암호화 메커니즘을 구현하지 않습니다.",
            "2": "백업 및 복구 옵션이 없는 VPC 내에 Amazon Aurora PostgreSQL 호환 에디션 데이터베이스를 설정합니다. 데이터베이스가 암호화되지 않도록 하고 SSL을 사용하지 않도록 합니다. 애플리케이션은 안전한 내부 네트워크에서 실행됩니다.",
            "3": "자동 백업이 활성화된 VPC 내에 Amazon Aurora MySQL 호환 에디션 데이터베이스를 배포합니다. 전송 중 안전한 데이터를 위해 SSL을 구성하고, KMS를 사용하여 저장 중 암호화를 활성화합니다. Aurora 복제를 사용하여 성능에 영향을 주지 않고 읽기 트래픽을 처리합니다.",
            "4": "Multi-AZ 배포가 있는 Amazon Aurora MySQL 호환 에디션 데이터베이스를 사용하되, 백업 또는 복구 옵션을 구성하지 않습니다. 더 쉬운 접근을 위해 데이터베이스 인스턴스를 공용 서브넷에 유지합니다."
        },
        "Correct Answer": "자동 백업이 활성화된 VPC 내에 Amazon Aurora MySQL 호환 에디션 데이터베이스를 배포합니다. 전송 중 안전한 데이터를 위해 SSL을 구성하고, KMS를 사용하여 저장 중 암호화를 활성화합니다. Aurora 복제를 사용하여 성능에 영향을 주지 않고 읽기 트래픽을 처리합니다.",
        "Explanation": "이 옵션은 Amazon Aurora 데이터베이스가 VPC 내에 안전하게 배포되도록 보장하며, 자동 백업 및 시점 복구를 가능하게 합니다. 또한 SSL을 활용하여 안전한 데이터 전송을 보장하고, KMS를 통해 저장 중 암호화를 지원하여 신뢰성, 보안 및 성능에 대한 모든 요구 사항을 충족합니다.",
        "Other Options": [
            "이 옵션은 PostgreSQL 호환 에디션을 사용하고 있으며, 필수적인 백업 및 복구 기능이 부족하여 거래 데이터베이스에 필수적인 요소입니다.",
            "이 옵션은 데이터베이스를 VPC 외부에 배포하도록 지정하고 있어 보안 모범 사례를 준수하지 않습니다. 또한 자동 백업 및 암호화를 비활성화하여 데이터 손실 및 보안에 대한 중대한 위험을 초래합니다.",
            "이 옵션은 데이터베이스 인스턴스를 공용 서브넷에 유지하여 잠재적인 보안 위협에 노출되게 합니다. 또한 거래 데이터베이스에 대해 백업 및 복구 옵션을 비활성화하는 것은 바람직하지 않습니다."
        ]
    },
    {
        "Question Number": "57",
        "Situation": "한 금융 서비스 회사가 온라인 뱅킹 플랫폼의 트래픽 패턴이 변동하고 있습니다. 플랫폼은 피크 사용 시간 동안 높은 가용성과 성능을 유지해야 하며, 저 트래픽 기간 동안 비용을 최소화해야 합니다. 회사는 수신 요청을 처리하기 위해 Application Load Balancer(ALB) 뒤에 Amazon EC2 인스턴스를 사용하고 있습니다. DevOps 엔지니어는 실시간 트래픽 변화에 효과적으로 대응하는 자동 확장 솔루션을 구현하는 임무를 맡았습니다.",
        "Question": "엔지니어가 탄력적인 아키텍처를 달성하기 위해 구현해야 할 자동 확장 및 로드 밸런싱 전략은 무엇입니까?",
        "Options": {
            "1": "Auto Scaling 그룹의 크기를 고정하고 Network Load Balancer(NLB)를 사용하여 트래픽을 처리하며, 어떤 확장 작업도 수행하지 않아 인스턴스가 항상 사용 가능하도록 합니다.",
            "2": "CloudWatch 메트릭(예: CPU 사용률 및 요청 수)을 기반으로 동적 확장 정책을 사용하도록 Auto Scaling 그룹을 구성하고, ALB와 통합하여 인스턴스 간에 트래픽을 고르게 분배합니다.",
            "3": "업무 시간 동안 EC2 인스턴스 수를 늘리고 비업무 시간 동안 줄이기 위해 예약된 확장 작업을 활용하며, ALB를 통해 트래픽을 분배합니다.",
            "4": "자동 확장이 없는 단일 EC2 인스턴스를 구현하고 ALB를 사용하여 모든 트래픽을 라우팅하여 항상 하나의 인스턴스가 요청을 처리할 수 있도록 합니다."
        },
        "Correct Answer": "CloudWatch 메트릭(예: CPU 사용률 및 요청 수)을 기반으로 동적 확장 정책을 사용하도록 Auto Scaling 그룹을 구성하고, ALB와 통합하여 인스턴스 간에 트래픽을 고르게 분배합니다.",
        "Explanation": "이 옵션은 실시간 트래픽 패턴에 맞춰 조정되는 동적 확장 접근 방식을 제공하며, CloudWatch 메트릭을 활용하여 EC2 인스턴스를 추가하거나 제거할 시점을 결정하여 높은 가용성과 효율적인 자원 사용을 보장합니다.",
        "Other Options": [
            "이 옵션은 트래픽 패턴에 따라 어떤 확장도 허용하지 않으므로 자원의 과소 또는 과다 제공으로 이어져 성능 저하 또는 불필요한 비용이 발생할 수 있습니다.",
            "예약된 확장은 예측 가능한 트래픽 패턴에 효과적일 수 있지만, 실시간 트래픽 변화에 대응하지 못해 예상치 못한 피크 시간 동안 성능 문제를 초래할 수 있습니다.",
            "자동 확장이 없는 단일 인스턴스에 의존하는 것은 단일 실패 지점을 생성합니다. 해당 인스턴스가 다운되면 플랫폼이 사용할 수 없게 되어 높은 가용성이 손상됩니다."
        ]
    },
    {
        "Question Number": "58",
        "Situation": "서버리스 애플리케이션이 AWS Lambda 함수를 사용하여 Amazon Kinesis 스트림에서 들어오는 이벤트를 처리합니다. 애플리케이션은 트래픽 증가로 인해 Lambda 함수 호출이 급증합니다.",
        "Question": "기본 AWS Lambda 서비스 한도를 준수하면서 애플리케이션이 증가된 부하를 처리할 수 있도록 하려면 무엇을 해야 합니까?",
        "Options": {
            "1": "AWS Step Functions를 활성화하여 Lambda 함수를 조정하고 더 많은 동시 실행을 허용합니다.",
            "2": "Lambda 함수 내에서 동시 실행 수를 관리하기 위한 스로틀링 메커니즘을 구현합니다.",
            "3": "해당 지역에서 AWS Lambda에 허용되는 최대 동시 실행 수에 대한 서비스 할당량 증가를 요청합니다.",
            "4": "더 나은 동시성 처리를 위해 AWS Lambda 대신 Amazon ECS를 사용하도록 애플리케이션을 재설계합니다."
        },
        "Correct Answer": "해당 지역에서 AWS Lambda에 허용되는 최대 동시 실행 수에 대한 서비스 할당량 증가를 요청합니다.",
        "Explanation": "AWS Lambda의 기본 동시 실행 한도는 지역당 1000입니다. 증가된 부하를 효과적으로 처리하기 위해 이 한도를 높이기 위한 서비스 할당량 증가 요청을 할 수 있으며, 이를 통해 스로틀링 없이 더 많은 동시 실행이 가능합니다.",
        "Other Options": [
            "스로틀링 메커니즘을 구현하면 부하 관리에 도움이 될 수 있지만, 실제 동시 실행 한도를 증가시키지 않으며 이벤트 처리 지연을 초래할 수 있습니다.",
            "Amazon ECS를 사용하도록 애플리케이션을 재설계하면 더 나은 동시성 처리를 제공할 수 있지만, 서버리스 모델에서 벗어나고 할당량 증가로 충분할 때 불필요한 복잡성을 추가합니다.",
            "AWS Step Functions를 활성화하면 Lambda 함수를 조정하는 데 도움이 되지만, 동시 실행 한도를 직접 증가시키지 않으며 이벤트 처리에 추가 지연을 초래할 수 있습니다."
        ]
    },
    {
        "Question Number": "59",
        "Situation": "금융 서비스 회사가 여러 가용 영역(AZ)에서 높은 가용성과 낮은 지연 시간을 요구하는 웹 애플리케이션을 AWS 클라우드에 배포하고 있습니다. DevOps 팀은 피크 시간 동안 다운타임을 최소화하고 사용자 경험을 개선하기 위해 지역 간 트래픽이 효율적으로 분산되도록 애플리케이션을 구성해야 합니다.",
        "Question": "DevOps 팀이 교차 AZ 서비스에 대한 로드 밸런싱을 가장 효과적으로 구성하려면 무엇을 해야 합니까?",
        "Options": {
            "1": "각 AZ에 애플리케이션 로드 밸런서(ALB)를 배포하고 웹 애플리케이션의 EC2 인스턴스를 해당 ALB에 등록하여 교차 존 로드 밸런싱을 활성화합니다.",
            "2": "AWS Global Accelerator와 함께 네트워크 로드 밸런서(NLB)를 사용하여 여러 지역에 트래픽을 분산시키고 높은 가용성과 복원력을 제공합니다.",
            "3": "Amazon Route 53 가중 라우팅 정책을 구성하여 여러 AZ에 트래픽을 분산시키고, Auto Scaling Group을 사용하여 인스턴스 상태 및 스케일링을 관리합니다.",
            "4": "Amazon CloudFront 배포를 구현하여 콘텐츠를 캐시하고 사용자 요청을 가장 가까운 지역으로 라우팅하며, 동적 콘텐츠를 위해 애플리케이션 로드 밸런서와 통합합니다."
        },
        "Correct Answer": "각 AZ에 애플리케이션 로드 밸런서(ALB)를 배포하고 웹 애플리케이션의 EC2 인스턴스를 해당 ALB에 등록하여 교차 존 로드 밸런싱을 활성화합니다.",
        "Explanation": "각 가용 영역에 애플리케이션 로드 밸런서를 배포하고 EC2 인스턴스를 등록함으로써 DevOps 팀은 여러 AZ의 다양한 인스턴스에 들어오는 애플리케이션 트래픽을 분산시켜 트래픽 급증 시 더 높은 가용성과 내결함성을 보장할 수 있습니다.",
        "Other Options": [
            "AWS Global Accelerator와 함께 네트워크 로드 밸런서를 사용하는 것은 TCP/UDP 트래픽에 더 적합하여 AZ 간 애플리케이션 수준 로드 밸런싱이 필요한 웹 애플리케이션에는 최적이 아닙니다.",
            "Amazon CloudFront 배포를 구현하면 주로 콘텐츠 전송 및 캐싱에 초점을 맞추며, 여러 AZ에서 실시간 처리가 필요한 동적 웹 애플리케이션 요청에 대한 트래픽을 효과적으로 분산시키지 못할 수 있습니다.",
            "Amazon Route 53 가중 라우팅 정책을 구성하는 것은 주로 DNS 수준의 트래픽 관리에 해당하며, 웹 애플리케이션에 대한 애플리케이션 로드 밸런서가 제공하는 능동적인 상태 검사 및 지능형 트래픽 분산 기능을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "60",
        "Situation": "금융 서비스 회사가 높은 가용성과 낮은 지연 시간을 요구하는 새로운 애플리케이션을 배포하고 있습니다. 이 애플리케이션은 여러 AWS 지역에 호스팅되어 복원력을 보장하고 잠재적인 장애로부터 빠른 복구를 지원합니다. 회사는 현재 Amazon EC2 인스턴스와 Amazon RDS를 데이터베이스 요구에 사용하고 있습니다. 그들은 자동 장애 조치 및 사용자 다운타임 최소화를 허용하는 전략을 구현하고자 합니다.",
        "Question": "다음 구성 중 지역 장애 발생 시 애플리케이션의 가용성을 극대화하고 다운타임을 최소화하는 구성은 무엇입니까?",
        "Options": {
            "1": "단일 지역의 애플리케이션 앞에 Amazon CloudFront 배포를 설정하여 콘텐츠를 캐시합니다. Route 53을 사용하여 정적 콘텐츠를 위한 S3 버킷으로 트래픽을 유도하고, 데이터베이스를 위해 단일 Multi-AZ 배포로 Amazon RDS를 구현합니다.",
            "2": "세 개의 AWS 지역에 애플리케이션을 배포하고, Amazon Route 53의 장애 조치 라우팅 정책을 사용하여 기본 지역이 사용할 수 없을 때 대기 지역으로 트래픽을 리디렉션합니다. 데이터베이스를 위해 Amazon RDS의 교차 지역 복제를 활용합니다.",
            "3": "두 개의 AWS 지역에 애플리케이션을 배포하고 AWS Global Accelerator를 사용하여 트래픽을 라우팅합니다. Route 53을 지연 기반 라우팅으로 구성하여 사용자 요청을 가장 가까운 지역으로 유도하고, 데이터베이스를 위해 Amazon RDS의 교차 지역 읽기 복제를 사용합니다.",
            "4": "단일 지역에 Amazon Elastic Load Balancer를 구현하여 여러 EC2 인스턴스에 트래픽을 분산시키고, 해당 지역 내에서 데이터베이스 가용성을 보장하기 위해 Amazon RDS를 Multi-AZ 배포로 구성합니다."
        },
        "Correct Answer": "세 개의 AWS 지역에 애플리케이션을 배포하고, Amazon Route 53의 장애 조치 라우팅 정책을 사용하여 기본 지역이 사용할 수 없을 때 대기 지역으로 트래픽을 리디렉션합니다. 데이터베이스를 위해 Amazon RDS의 교차 지역 복제를 활용합니다.",
        "Explanation": "세 개의 AWS 지역에 애플리케이션을 배포하고 Route 53 장애 조치 라우팅을 사용하며 Amazon RDS의 교차 지역 복제를 활용하면 한 지역이 실패할 경우 트래픽이 대기 지역으로 원활하게 리디렉션되어 다운타임을 최소화하고 애플리케이션의 높은 가용성을 유지할 수 있습니다.",
        "Other Options": [
            "두 개의 AWS 지역에 애플리케이션을 배포하고 AWS Global Accelerator 및 지연 기반 라우팅을 사용하는 것은 유익하지만, 장애 조치 라우팅으로 세 개의 지역에 배포하는 것만큼의 중복성과 장애 조치 기능을 제공하지 않습니다.",
            "CloudFront 배포를 설정하고 S3 버킷으로 트래픽을 유도하면 애플리케이션의 가용성이 하나의 지역으로 제한되며, 자동 장애 조치나 지역 장애에 대한 복원력을 제공하지 않습니다.",
            "단일 지역에서 Elastic Load Balancer와 Multi-AZ RDS 배포를 사용하는 것은 해당 지역 내에서 가용성을 제공하지만, 지역 장애에 대한 보호를 제공하지 않으며 이는 높은 가용성에 필수적입니다."
        ]
    },
    {
        "Question Number": "61",
        "Situation": "한 금융 서비스 회사가 가용성과 복원력을 향상시키기 위해 애플리케이션을 AWS로 마이그레이션하고 있습니다. 이들은 중단 사태 발생 시 자동으로 장애 조치를 처리할 수 있는 솔루션이 필요하며, 최소한의 다운타임을 보장해야 합니다. 회사는 높은 가용성을 달성하기 위해 여러 AWS 리전에서 애플리케이션을 실행할 것으로 예상하고 있습니다. 이들은 데이터베이스 복제 및 장애 조치에 대한 다양한 전략을 고려하고 있습니다. 이러한 요구 사항을 충족하기 위해 어떤 전략을 구현해야 할까요?",
        "Question": "다음 중 다중 리전 장애 조치 및 최소한의 다운타임을 제공하는 가장 복원력 있는 데이터베이스 전략은 무엇입니까?",
        "Options": {
            "1": "한 리전에서 Amazon RDS의 다중 AZ 배포를 생성하고 다른 리전에서 수동 백업을 사용합니다.",
            "2": "Amazon Aurora를 구현하고 교차 리전 복제를 설정하여 자동 장애 조치를 설정합니다.",
            "3": "한 리전에서 단일 Amazon RDS 인스턴스를 배포하고 다른 리전에서 읽기 복제본을 설정합니다.",
            "4": "Amazon DynamoDB의 글로벌 테이블을 사용하여 여러 리전에서 자동 복제를 보장합니다."
        },
        "Correct Answer": "Amazon Aurora를 구현하고 교차 리전 복제를 설정하여 자동 장애 조치를 설정합니다.",
        "Explanation": "Amazon Aurora의 교차 리전 복제는 자동 장애 조치를 가능하게 하며, 여러 리전에서 높은 가용성을 제공하여 복원력 및 최소한의 다운타임 요구 사항을 효과적으로 충족합니다.",
        "Other Options": [
            "단일 Amazon RDS 인스턴스를 읽기 복제본과 함께 배포하는 것은 자동 장애 조치를 제공하지 않으며 수동 개입에 의존하므로 최소한의 다운타임 요구 사항과 모순됩니다.",
            "Amazon DynamoDB의 글로벌 테이블은 자동 복제를 제공하지만, 복잡한 트랜잭션이나 관계형 기능이 필요한 모든 데이터베이스 작업에 적합하지 않을 수 있습니다.",
            "한 리전에서 Amazon RDS의 다중 AZ 배포를 생성하는 것은 해당 리전 내의 중단에 대해서만 보호하며, 다른 리전으로의 장애 조치 기능을 제공하지 않으므로 다중 리전 요구 사항을 충족하지 못합니다."
        ]
    },
    {
        "Question Number": "62",
        "Situation": "한 조직이 AWS 환경 내에서 발생하는 API 호출 및 이벤트를 기록하기 위해 AWS CloudTrail을 구현했습니다. 이들은 이러한 로그를 기반으로 의심스러운 활동을 자동으로 감지하고, 그러한 활동이 감지될 때 보안 팀에 알리기를 원합니다. DevOps 엔지니어는 이 요구 사항을 충족하기 위한 효과적인 솔루션을 구축해야 합니다.",
        "Question": "AWS CloudTrail 로그를 기반으로 의심스러운 활동을 적시에 감지하고 알리기 위해 엔지니어가 취해야 할 접근 방식은 무엇입니까?",
        "Options": {
            "1": "정기적으로 CloudTrail 로그에서 이상을 확인하고 발견된 경우 보안 팀에 경고를 보내는 예약된 AWS Lambda 함수를 생성합니다.",
            "2": "Amazon GuardDuty를 활성화하여 CloudTrail 로그에서 잠재적인 위협을 분석하고 감지된 문제에 대해 보안 팀에 알립니다.",
            "3": "Amazon CloudWatch Logs 구독 필터를 설정하여 CloudTrail 로그에서 특정 패턴을 찾고, 보안 팀에 알림을 보내는 AWS Lambda 함수를 트리거합니다.",
            "4": "AWS Config 규칙을 사용하여 CloudTrail 로그의 변경 사항을 모니터링하고 비준수 변경 사항이 감지되면 경고를 보냅니다."
        },
        "Correct Answer": "Amazon CloudWatch Logs 구독 필터를 설정하여 CloudTrail 로그에서 특정 패턴을 찾고, 보안 팀에 알림을 보내는 AWS Lambda 함수를 트리거합니다.",
        "Explanation": "CloudWatch Logs 구독 필터를 사용하면 특정 API 호출 패턴을 실시간으로 감지할 수 있어 자동화된 Lambda 함수를 통해 즉각적인 조치를 취할 수 있습니다. 이 접근 방식은 의심스러운 활동에 대해 보안 팀에 적시적이고 직접적인 알림을 제공합니다.",
        "Other Options": [
            "예약된 Lambda 함수를 생성하는 것은 구독 필터를 사용하는 것만큼 적시적이지 않으며, 지정된 간격으로만 로그를 확인하므로 사건에 대한 대응이 지연될 수 있습니다.",
            "AWS Config 규칙은 주로 준수 모니터링에 사용되며 CloudTrail 로그에서 API 호출 이상을 실시간으로 감지하는 기능을 제공하지 않습니다.",
            "GuardDuty는 위협 감지에 효과적이지만, CloudTrail 로그에만 집중하지 않으며 사용자 정의 이벤트 알림에서 동일한 즉각성을 제공하지 않을 수 있는 추가 서비스입니다."
        ]
    },
    {
        "Question Number": "63",
        "Situation": "DevOps 팀은 문제를 신속하게 식별하고 대응하기 위해 애플리케이션 로그를 실시간으로 모니터링할 책임이 있습니다. 이들은 다양한 소스에서 로그를 수집하고 처리하여 경고 및 분석을 위해 사용할 수 있는 솔루션을 구현해야 합니다. 팀은 이를 달성하기 위해 AWS 서비스를 활용하기로 결정했습니다.",
        "Question": "실시간 로그 수집을 위한 가장 효율적이고 확장 가능한 솔루션을 제공하는 아키텍처는 무엇입니까?",
        "Options": {
            "1": "Amazon CloudWatch Logs를 설정하여 소스에서 직접 로그를 수집합니다. CloudWatch 로그 그룹을 생성하고 경고를 위해 로그를 Amazon SNS 주제로 전송하는 구독 필터를 구성합니다.",
            "2": "로그 파일을 파일 시스템에서 읽고 Amazon S3에 업로드하는 사용자 정의 로그 전송기를 실행하는 Amazon EC2 인스턴스를 배포합니다. Amazon Athena를 사용하여 S3에 저장된 로그를 쿼리합니다.",
            "3": "애플리케이션 인스턴스에서 로그 파일을 직접 업로드하여 Amazon S3를 사용하여 로그를 수집합니다. S3 이벤트에 의해 트리거되는 AWS Lambda 함수를 사용하여 로그를 처리하고 Amazon DynamoDB에 저장합니다.",
            "4": "Amazon Kinesis Data Streams를 사용하여 여러 소스에서 실시간으로 로그를 수집합니다. AWS Lambda를 구성하여 로그를 처리하고 Amazon S3에 저장하며 Amazon Elasticsearch Service로 검색 및 분석을 위해 전송합니다."
        },
        "Correct Answer": "Amazon Kinesis Data Streams를 사용하여 여러 소스에서 실시간으로 로그를 수집합니다. AWS Lambda를 구성하여 로그를 처리하고 Amazon S3에 저장하며 Amazon Elasticsearch Service로 검색 및 분석을 위해 전송합니다.",
        "Explanation": "Amazon Kinesis Data Streams를 사용하면 다양한 소스에서 고처리량의 실시간 로그 수집을 처리하는 강력한 방법을 제공합니다. 로그 볼륨이 증가함에 따라 확장 가능하며, AWS Lambda와 원활하게 통합되어 Amazon S3 및 Amazon Elasticsearch Service를 통해 경고 및 분석을 위한 즉각적인 접근을 가능하게 합니다.",
        "Other Options": [
            "이 옵션은 CloudWatch Logs의 실시간 처리 기능에 의해 제한되며, 여러 소스에서 로그를 효과적으로 수집하거나 처리할 수 있는 유연성이 부족합니다.",
            "이 접근 방식은 S3에 파일을 업로드하는 데 의존하므로 지연이 발생하며 진정한 실시간이 아닙니다. 또한 DynamoDB는 로그 데이터에 비해 로그 저장 및 쿼리에 적합하지 않습니다.",
            "EC2 인스턴스를 사용하여 로그를 전송하는 것은 추가 관리 오버헤드와 잠재적인 병목 현상을 초래하며, 특히 확장 시 Kinesis가 제공하는 실시간 수집 기능이 부족합니다."
        ]
    },
    {
        "Question Number": "64",
        "Situation": "한 회사가 AWS SAM을 사용하여 서버리스 애플리케이션을 개발하고 있으며, 배포 파이프라인이 효율적이고 애플리케이션의 인프라에 대한 변경 사항을 배포할 때 오류 가능성을 줄이도록 보장하고자 합니다. 현재 팀은 SAM CLI 명령을 사용하여 애플리케이션을 수동으로 배포하고 있으며, 이로 인해 환경 간 불일치가 발생하고 릴리스 주기가 지연되고 있습니다.",
        "Question": "다음 전략 중 여러 환경에서 일관성을 보장하면서 서버리스 애플리케이션의 배포를 자동화하는 데 가장 효과적인 방법은 무엇입니까?",
        "Options": {
            "1": "SAM CLI 명령을 자동화하는 셸 스크립트를 작성하고 AWS Lambda를 사용하여 매일 실행되도록 예약하여 애플리케이션을 패키징하고 배포합니다.",
            "2": "AWS CloudFormation StackSets를 설정하여 AWS SAM을 활용하여 여러 계정 및 리전으로 서버리스 애플리케이션을 배포합니다.",
            "3": "AWS CodeBuild를 활용하여 각 배포를 위한 빌드 프로젝트에서 SAM CLI 명령을 수동으로 실행하여 SAM 애플리케이션이 배포 전에 올바르게 패키징되도록 합니다.",
            "4": "AWS CodePipeline을 사용하여 CI/CD 파이프라인을 생성하고 AWS SAM 애플리케이션을 패키징하는 빌드 단계를 포함하여 AWS CloudFormation을 사용하여 배포합니다."
        },
        "Correct Answer": "AWS CodePipeline을 사용하여 CI/CD 파이프라인을 생성하고 AWS SAM 애플리케이션을 패키징하는 빌드 단계를 포함하여 AWS CloudFormation을 사용하여 배포합니다.",
        "Explanation": "AWS CodePipeline을 사용하여 CI/CD 파이프라인을 생성하면 일관되고 자동화된 배포 프로세스를 통해 인적 오류 가능성을 줄이고 모든 변경 사항이 통제된 방식으로 배포되도록 보장합니다. 이 접근 방식은 AWS SAM 및 CloudFormation과 잘 통합되어 인프라를 코드로 효과적으로 관리할 수 있습니다.",
        "Other Options": [
            "AWS CodeBuild를 사용하여 SAM CLI 명령을 수동으로 실행하는 것은 수동 프로세스 때문에 오류의 위험을 초래하며, 간소화되거나 자동화된 배포 파이프라인을 제공하지 않습니다.",
            "AWS CloudFormation StackSets는 주로 여러 계정 및 리전에서 리소스를 배포하는 데 사용되지만, 단일 애플리케이션 배포에는 필요하지 않을 수 있어 이 시나리오에 덜 적합합니다.",
            "SAM CLI 명령을 자동화하는 셸 스크립트를 작성하는 것은 관리하기 어려울 수 있으며, 버전 관리 및 롤백 기능과 같은 CI/CD 파이프라인의 강력한 기능이 부족하여 최적의 솔루션이 아닙니다."
        ]
    },
    {
        "Question Number": "65",
        "Situation": "한 금융 서비스 회사가 지속적인 통합 및 지속적인 배포(CI/CD)가 필요한 마이크로서비스 기반 애플리케이션을 개발하고 있습니다. 이 애플리케이션은 여러 서비스로 구성되어 있으며, 컨테이너화되어 저장소에 보관됩니다. 회사는 각 서비스가 적절하게 버전 관리되고 아티팩트가 배포를 위해 쉽게 접근 가능하도록 보장하고자 합니다. DevOps 엔지니어는 이러한 리소스를 효율적으로 관리할 수 있는 코드, 이미지 및 아티팩트 저장소를 설정하는 임무를 맡고 있습니다.",
        "Question": "엔지니어가 코드, 이미지 및 아티팩트의 저장 및 버전 관리를 가장 효과적으로 자동화하기 위해 구현해야 할 솔루션은 무엇입니까?",
        "Options": {
            "1": "소스 코드를 위해 AWS CodeCommit을 사용하고, Docker 이미지를 위해 Amazon ECR을 사용하며, 소프트웨어 아티팩트를 관리하기 위해 AWS CodeArtifact를 사용합니다.",
            "2": "소스 코드를 위해 GitHub을 사용하고, Docker 이미지를 위해 AWS S3를 사용하며, 소프트웨어 아티팩트를 관리하기 위해 AWS CodePipeline을 사용합니다.",
            "3": "소스 코드를 위해 AWS CodeCommit을 사용하고, Docker 이미지를 위해 Amazon ECR을 사용하며, 소프트웨어 아티팩트를 관리하기 위해 AWS S3를 사용합니다.",
            "4": "소스 코드를 위해 AWS CodeCommit을 사용하고, Docker 이미지를 위해 AWS S3를 사용하며, 소프트웨어 아티팩트를 관리하기 위해 AWS CodeDeploy를 사용합니다."
        },
        "Correct Answer": "소스 코드를 위해 AWS CodeCommit을 사용하고, Docker 이미지를 위해 Amazon ECR을 사용하며, 소프트웨어 아티팩트를 관리하기 위해 AWS CodeArtifact를 사용합니다.",
        "Explanation": "이 솔루션은 코드, 이미지 및 아티팩트를 처리하도록 특별히 설계된 AWS 서비스를 효과적으로 활용합니다. AWS CodeCommit은 안전하고 확장 가능한 소스 제어 서비스를 제공하며, Amazon ECR은 Docker 이미지를 쉽게 저장하고 검색할 수 있는 완전 관리형 Docker 컨테이너 레지스트리입니다. AWS CodeArtifact는 여러 패키지 형식을 지원하는 완전 관리형 아티팩트 저장소 서비스로, 소프트웨어 아티팩트를 관리하는 데 이상적입니다.",
        "Other Options": [
            "소스 코드를 위해 GitHub을 사용하는 것은 외부 종속성을 도입하며, CodeCommit에 비해 다른 AWS 서비스와 원활하게 통합되지 않을 수 있습니다. 또한, Docker 이미지를 위해 AWS S3를 사용하는 것은 ECR이 그 목적을 위해 특별히 설계되었기 때문에 최적이 아닙니다.",
            "AWS S3는 Docker 이미지를 저장하는 데 적합하지 않으며, Amazon ECR이 제공하는 버전 관리 및 수명 주기 정책과 같은 기능이 부족합니다. CodeDeploy는 주로 배포를 위한 것이지 아티팩트 관리를 위한 것이 아니므로 이 옵션은 덜 효과적입니다.",
            "소프트웨어 아티팩트를 관리하기 위해 S3를 사용하는 것은 AWS CodeArtifact가 제공하는 버전 관리 및 종속성 관리에 필요한 기능을 제공하지 않으므로 아티팩트 관리의 비효율성을 초래할 수 있습니다."
        ]
    },
    {
        "Question Number": "66",
        "Situation": "한 회사가 애플리케이션을 AWS로 마이그레이션하고 있으며, 신뢰성과 확장성을 개선하기 위한 배포 전략을 평가하고 있습니다. DevOps 팀은 애플리케이션 무결성을 유지하면서 개발 및 운영 프로세스를 간소화하기 위해 가변 및 불변 배포 패턴을 고려하고 있습니다.",
        "Question": "SDLC 자동화의 맥락에서 가변 배포 패턴과 불변 배포 패턴의 차이를 가장 잘 설명하는 진술은 무엇입니까?",
        "Options": {
            "1": "가변 배포 패턴은 마이크로서비스 아키텍처에 선호되며, 불변 배포 패턴은 모놀리식 애플리케이션에 가장 적합합니다.",
            "2": "불변 배포 패턴은 기존 인스턴스를 업데이트할 수 있는 반면, 가변 배포 패턴은 모든 배포에 대해 새로운 인스턴스를 생성합니다.",
            "3": "가변 배포 패턴과 불변 배포 패턴 모두 각 배포 프로세스에 대해 수동 개입이 필요합니다.",
            "4": "가변 배포 패턴은 기존 인스턴스를 업데이트할 수 있는 반면, 불변 배포 패턴은 모든 배포에 대해 새로운 인스턴스를 생성합니다."
        },
        "Correct Answer": "가변 배포 패턴은 기존 인스턴스를 업데이트할 수 있는 반면, 불변 배포 패턴은 모든 배포에 대해 새로운 인스턴스를 생성합니다.",
        "Explanation": "가변 배포 패턴은 기존 인스턴스에 직접 변경을 적용할 수 있게 하여 시간이 지남에 따라 불일치를 초래할 수 있습니다. 반면, 불변 배포 패턴은 각 배포가 새로운 인스턴스를 생성하도록 보장하여 오류의 위험을 줄이고 명확한 버전 기록을 제공합니다.",
        "Other Options": [
            "이 진술은 가변 및 불변 배포 패턴의 정의를 반대로 설명하고 있기 때문에 잘못되었습니다. 가변 배포는 기존 인스턴스를 수정하는 반면, 불변 배포는 각 업데이트에 대해 완전히 새로운 인스턴스를 생성합니다.",
            "이 진술은 배포 패턴을 잘못 설명하고 있습니다. 가변 배포 패턴은 마이크로서비스 아키텍처를 선호하지 않으며, 다양한 아키텍처에서 사용할 수 있지만 불변 패턴이 완화할 수 있는 위험을 초래할 수 있습니다.",
            "이 진술은 가변 및 불변 배포 패턴 모두 상당한 정도로 자동화될 수 있어 현대 CI/CD 파이프라인에서 수동 개입의 필요성을 줄일 수 있다는 점에서 잘못되었습니다."
        ]
    },
    {
        "Question Number": "67",
        "Situation": "조직이 온프레미스 서버와 AWS EC2 인스턴스로 구성된 하이브리드 클라우드 환경을 관리하고 있습니다. 조직은 모든 EC2 인스턴스가 인스턴스 프로파일 역할을 할당할 필요 없이 AWS Systems Manager에 관리 인스턴스로 자동 등록되도록 해야 합니다. 또한 모든 관리 인스턴스에서 일관된 구성을 유지하고자 합니다. AWS Systems Manager의 기본 호스트 구성(Default Host Configuration)을 사용하여 이를 달성하는 가장 좋은 방법은 무엇입니까?",
        "Question": "DevOps 엔지니어가 EC2 인스턴스를 Systems Manager에 자동 등록하기 위해 기본 호스트 구성을 활성화하기 위해 어떤 조치를 취해야 합니까?",
        "Options": {
            "1": "원하는 AWS 리전에서 DHMC를 활성화하고 모든 EC2 인스턴스에서 IMDSv2가 활성화되어 있는지 확인합니다.",
            "2": "SSM을 위한 EC2 인스턴스 프로파일 역할을 설정하고 각 인스턴스가 SSM 에이전트를 자동으로 업데이트하도록 구성합니다.",
            "3": "온프레미스 서버에 대한 하이브리드 활성화를 배포하고 모든 인스턴스에 대해 활성화 코드와 ID를 사용하여 SSM 에이전트를 구성합니다.",
            "4": "각 EC2 인스턴스에 SSM 에이전트를 수동으로 설치한 다음 IAM 역할을 사용하여 Systems Manager에 등록합니다."
        },
        "Correct Answer": "원하는 AWS 리전에서 DHMC를 활성화하고 모든 EC2 인스턴스에서 IMDSv2가 활성화되어 있는지 확인합니다.",
        "Explanation": "원하는 AWS 리전에서 기본 호스트 구성(DHMC)을 활성화하면 EC2 인스턴스가 특정 인스턴스 프로파일 역할을 요구하지 않고도 Systems Manager에 자동 등록될 수 있으며, IMDSv2를 사용하여 보안을 강화할 수 있습니다. 이는 Systems Manager에서 EC2 인스턴스를 관리하는 가장 효율적인 방법입니다.",
        "Other Options": [
            "이 옵션은 SSM 에이전트를 수동으로 설치하고 IAM 역할을 사용하는 것이 DHMC를 활용하지 않기 때문에 잘못된 것입니다. DHMC는 추가 구성 없이 등록 프로세스를 자동화하도록 설계되었습니다.",
            "이 옵션은 EC2 인스턴스에 대해 하이브리드 활성화를 배포하는 것이 불필요하기 때문에 잘못된 것입니다. EC2 인스턴스는 DHMC를 통해 자동으로 등록될 수 있습니다. 하이브리드 활성화는 온프레미스 서버에 더 관련이 있습니다.",
            "이 옵션은 DHMC를 사용할 때 EC2 인스턴스 프로파일 역할을 설정할 필요가 없기 때문에 잘못된 것입니다. DHMC는 자동 등록을 위한 인스턴스 프로파일 역할의 요구 사항을 제거합니다."
        ]
    },
    {
        "Question Number": "68",
        "Situation": "금융 기관의 보안 팀은 IAM 사용자 로그인 이벤트를 기록하는 AWS CloudTrail 로그의 무결성을 보장하는 임무를 맡고 있습니다. 그들은 us-east-1 리전에서 CloudTrail을 활성화했으며, 로그 파일이 전달 후 변조되지 않았는지 확인하고자 합니다. 보안 태세를 강화하기 위해 이 로그 파일의 무결성에 대한 보장을 제공하는 AWS 기능을 활용해야 합니다.",
        "Question": "보안 팀이 CloudTrail 로그 파일의 무결성을 검증하기 위해 어떤 방법을 사용해야 합니까?",
        "Options": {
            "1": "AWS Lambda 함수를 사용하여 주기적으로 CloudTrail 로그의 타임스탬프를 현재 시간과 비교하여 변경되지 않았는지 확인합니다.",
            "2": "CloudTrail 로그 파일 무결성 검증을 구현하여 SHA-256 해싱 및 RSA 디지털 서명을 사용하여 로그 파일이 전달 후 수정되지 않았음을 확인합니다.",
            "3": "CloudTrail 로그가 저장된 버킷에서 Amazon S3 버전 관리를 활성화하여 변경 사항이 감지되면 이전 버전의 로그를 복원할 수 있도록 합니다.",
            "4": "AWS Config 규칙을 구성하여 CloudTrail 로그 파일의 변경 사항을 모니터링하고 수정 사항이 감지되면 팀에 알립니다."
        },
        "Correct Answer": "CloudTrail 로그 파일 무결성 검증을 구현하여 SHA-256 해싱 및 RSA 디지털 서명을 사용하여 로그 파일이 전달 후 수정되지 않았음을 확인합니다.",
        "Explanation": "CloudTrail 로그 파일 무결성 검증은 로그 파일이 전달 후 변조되지 않았는지 확인하는 방법을 제공합니다. 이 기능은 해싱을 위해 SHA-256을 사용하고 서명을 위해 RSA를 사용하여 로그 파일의 진위성과 무결성을 보장합니다.",
        "Other Options": [
            "AWS Config 규칙은 리소스의 변경 사항을 모니터링할 수 있지만, 전달 후 CloudTrail 로그의 무결성을 직접 검증하지 않기 때문에 이 옵션은 특정 사용 사례에 덜 적합합니다.",
            "AWS Lambda 함수를 사용하여 타임스탬프를 확인하는 것은 로그 파일의 무결성을 검증하는 강력한 솔루션을 제공하지 않으며, 로그가 변경되었는지 여부를 확인하지 않고 단지 최근임을 확인할 뿐입니다.",
            "Amazon S3 버전 관리를 활성화하면 팀이 이전 버전의 로그를 복원할 수 있지만, 로그의 무결성을 검증하는 방법을 본질적으로 제공하지 않으며, 이는 규정 준수 및 보안에 필수적입니다."
        ]
    },
    {
        "Question Number": "69",
        "Situation": "한 회사가 사용자 업로드 파일을 Amazon S3에 저장하는 서버리스 애플리케이션을 개발하고 있습니다. 이 애플리케이션은 버킷 및 객체 버전을 관리하고, 파일 업로드에 대한 버킷 알림을 설정하며, 권한이 있는 사용자만 파일에 접근할 수 있도록 해야 합니다. DevOps 엔지니어는 S3 API를 사용하여 이러한 기능을 구현해야 합니다.",
        "Question": "DevOps 엔지니어가 S3 버킷 및 그 내용을 효과적으로 관리하기 위해 어떤 조치를 취해야 합니까?",
        "Options": {
            "1": "s3api put-bucket-acl 명령을 사용하여 버킷의 접근 제어 목록을 설정하고, s3api head-object 명령을 사용하여 객체 권한을 확인합니다.",
            "2": "s3api rb 명령을 사용하여 버킷을 삭제하고, s3api mv 명령을 사용하여 객체를 버킷 간에 이동하여 더 나은 관리를 합니다.",
            "3": "s3api put-bucket-versioning 명령을 사용하여 버킷에서 버전 관리를 활성화하고, s3api put-bucket-notification-configuration 명령을 사용하여 객체 업로드에 대한 알림을 설정합니다.",
            "4": "s3api mb 명령을 사용하여 버킷을 생성하고, s3 sync 명령을 사용하여 버킷 내에서 객체 업로드 및 버전 관리를 수행합니다."
        },
        "Correct Answer": "s3api put-bucket-versioning 명령을 사용하여 버킷에서 버전 관리를 활성화하고, s3api put-bucket-notification-configuration 명령을 사용하여 객체 업로드에 대한 알림을 설정합니다.",
        "Explanation": "put-bucket-versioning 명령을 사용하여 버킷에서 버전 관리를 활성화하면 변경 사항을 추적하고 객체의 이전 버전을 복구할 수 있습니다. put-bucket-notification-configuration을 사용하여 버킷 알림을 설정하면 애플리케이션이 새로운 업로드에 적절히 반응할 수 있습니다.",
        "Other Options": [
            "mb 명령을 사용하여 버킷을 생성하고 sync 명령으로 업로드를 관리하는 것은 버전 관리 및 알림 요구 사항을 해결하지 않으며, 이는 이 사용 사례에 매우 중요합니다.",
            "put-bucket-acl로 접근 제어 목록을 설정하는 것은 권한에 중요하지만, 애플리케이션을 효과적으로 관리하기 위한 버전 관리 및 알림의 주요 요구 사항을 충족하지 않습니다.",
            "rb 명령으로 버킷을 삭제하고 mv로 객체를 이동하는 것은 업로드 관리 및 S3 환경 내에서 파일 버전을 유지하는 목표와 일치하지 않기 때문에 비생산적입니다."
        ]
    },
    {
        "Question Number": "70",
        "Situation": "DevOps 엔지니어가 성능 모니터링 및 문제 해결을 위해 Amazon S3에 저장된 애플리케이션 로그를 분석해야 합니다. 로그가 크고, 엔지니어는 효율적으로 SQL 유사 쿼리를 실행하고자 합니다. 솔루션은 비용을 최소화하고 복잡한 ETL 프로세스 없이 로그에서 빠른 통찰을 제공해야 합니다.",
        "Question": "어떤 AWS 서비스 조합이 엔지니어가 S3 로그를 SQL 유사 쿼리를 사용하여 효율적으로 분석할 수 있도록 하면서 상당한 비용을 발생시키지 않게 할까요?",
        "Options": {
            "1": "AWS Lambda를 활용하여 로그 데이터를 실시간으로 처리하고, SQL 쿼리를 위해 Amazon RDS에 결과를 저장합니다.",
            "2": "AWS Glue를 사용하여 로그에 대한 데이터 카탈로그를 생성하고, Amazon Redshift를 실행하여 카탈로그된 데이터에 대해 SQL 쿼리를 수행합니다.",
            "3": "Amazon EMR을 구현하여 로그를 처리하고 Apache Hive를 사용하여 SQL 쿼리를 실행하며, 결과를 다시 S3에 저장합니다.",
            "4": "Amazon Athena를 설정하여 S3의 로그를 직접 쿼리하고, Amazon QuickSight를 사용하여 쿼리 결과를 시각화합니다."
        },
        "Correct Answer": "Amazon Athena를 설정하여 S3의 로그를 직접 쿼리하고, Amazon QuickSight를 사용하여 쿼리 결과를 시각화합니다.",
        "Explanation": "Amazon Athena를 사용하면 S3에 저장된 데이터를 표준 SQL로 직접 쿼리할 수 있으며, 실행한 쿼리에 대해서만 비용을 지불하므로 비용 효율적입니다. Amazon QuickSight와 통합하면 데이터를 효과적으로 시각화하여 추가 인프라를 관리하는 오버헤드 없이 빠른 통찰을 제공합니다.",
        "Other Options": [
            "AWS Glue와 Amazon Redshift를 사용하는 것은 데이터 카탈로깅 및 별도의 데이터 웨어하우스 유지 관리에 추가 비용이 발생하므로 S3 로그를 직접 쿼리하는 데 비효율적입니다.",
            "로그 처리를 위해 Amazon EMR을 구현하는 것은 이 사용 사례에 비해 더 복잡하고 비용이 많이 들며, Athena가 S3 쿼리를 직접 처리할 수 있으므로 클러스터 관리의 오버헤드가 필요하지 않습니다.",
            "AWS Lambda를 사용하여 로그를 실시간으로 처리하고 결과를 Amazon RDS에 저장하는 것은 불필요한 복잡성과 비용을 추가하며, 이는 간단한 로그 분석에 필요하지 않은 Lambda 함수와 RDS 인스턴스의 지속적인 운영을 요구합니다."
        ]
    },
    {
        "Question Number": "71",
        "Situation": "한 회사가 애플리케이션 데이터베이스로 Amazon DynamoDB를 사용하고 있습니다. 애플리케이션은 파티션 키와 보조 속성을 기반으로 데이터를 검색할 수 있는 효율적인 쿼리 기능이 필요합니다. 개발 팀은 읽기 성능을 최적화하면서 데이터 저장 비용을 관리할 수 있는 적절한 인덱싱 옵션을 탐색하고 있습니다.",
        "Question": "개발 팀이 테이블 생성 시에만 생성할 수 있도록 하면서 보조 속성을 기반으로 효율적인 쿼리를 허용하기 위해 어떤 인덱싱 전략을 구현해야 할까요?",
        "Options": {
            "1": "보조 속성에 대한 효율적인 쿼리를 허용하기 위해 대체 파티션 키를 가진 글로벌 보조 인덱스를 구현합니다.",
            "2": "테이블이 설정된 후에 생성할 수 있는 글로벌 보조 인덱스를 사용하여 애플리케이션이 발전함에 따라 인덱싱 전략을 수정할 수 있습니다.",
            "3": "파티션 키와 보조 속성을 새로운 정렬 키로 포함하는 로컬 보조 인덱스를 생성하여 테이블 생성 시 효율적인 쿼리를 보장합니다.",
            "4": "최종적으로 일관된 읽기를 허용하지만 보조 속성을 기반으로 쿼리를 허용하지 않는 로컬 보조 인덱스를 설정합니다."
        },
        "Correct Answer": "파티션 키와 보조 속성을 새로운 정렬 키로 포함하는 로컬 보조 인덱스를 생성하여 테이블 생성 시 효율적인 쿼리를 보장합니다.",
        "Explanation": "로컬 보조 인덱스(LSI)는 파티션 키와 다른 정렬 키를 기반으로 인덱스를 생성할 수 있어 보조 속성에 대한 효율적인 쿼리를 가능하게 합니다. LSI는 테이블 생성 시 정의되어야 하므로 개발 팀의 요구 사항에 적합합니다.",
        "Other Options": [
            "글로벌 보조 인덱스(GSI)는 언제든지 생성할 수 있지만 테이블 생성 시에 생성되어야 한다는 요구 사항을 충족하지 않으므로 부적절한 선택입니다.",
            "GSI는 보조 속성에 대한 쿼리를 허용하지만 테이블 생성 시에 생성되어야 한다는 요구 사항을 충족하지 않으며, 별도의 읽기/쓰기 용량 단위로 인해 비용이 증가할 수 있습니다.",
            "로컬 보조 인덱스를 설정하면 효율적인 쿼리가 가능하지만, 보조 속성을 기반으로 쿼리를 허용하지 않는다고 잘못 언급하고 있어 이는 사실이 아닙니다. LSI는 실제로 파티션 키와 대체 정렬 키를 기반으로 쿼리를 허용합니다."
        ]
    },
    {
        "Question Number": "72",
        "Situation": "한 금융 서비스 회사가 각기 다른 부서에 대해 여러 AWS 계정을 관리하고 있으며, 각 계정마다 고유한 리소스 및 규정 준수 요구 사항이 있습니다. DevOps 팀은 모든 계정에서 일관된 인프라 배포를 허용하면서 규정 준수 및 보안을 보장하는 구성 관리 솔루션을 구현하고자 합니다.",
        "Question": "여러 AWS 계정에서 코드로서의 인프라 관리를 위해 규정 준수, 보안 및 운영 효율성 간의 최상의 균형을 제공하는 접근 방식은 무엇인가요?",
        "Options": {
            "1": "AWS CodePipeline을 구현하고 배포에 대한 수동 승인을 통해 각 계정에서 배포 후 규정 준수를 확인하기 위해 AWS Lambda에 의존합니다.",
            "2": "각 계정에 AWS Config 규칙을 사용하여 규정 준수를 시행하고, 모든 인프라 배포에 AWS CloudFormation을 활용합니다.",
            "3": "각 계정에 개별 CloudFormation 스택을 생성하고 인프라 변경에 대한 수동 업데이트를 통해 규정 준수를 보장합니다.",
            "4": "AWS CloudFormation StackSets를 활용하여 여러 계정에 템플릿을 배포하고, 보안 규정을 위한 서비스 제어 정책(SCP)을 구현합니다."
        },
        "Correct Answer": "AWS CloudFormation StackSets를 활용하여 여러 계정에 템플릿을 배포하고, 보안 규정을 위한 서비스 제어 정책(SCP)을 구현합니다.",
        "Explanation": "AWS CloudFormation StackSets를 사용하면 여러 계정에서 인프라 배포를 중앙 집중식으로 관리하면서 서비스 제어 정책(SCP)을 통해 규정 준수를 시행할 수 있습니다. 이 접근 방식은 업데이트를 간소화하고 계정 간 일관성을 보장하여 보안과 운영 효율성을 모두 향상시킵니다.",
        "Other Options": [
            "각 계정에 개별 CloudFormation 스택을 생성하면 운영 오버헤드와 불일치의 위험이 증가하며, 이는 수동 업데이트와 검토에 크게 의존하므로 규정 준수의 격차를 초래할 수 있습니다.",
            "AWS Organizations와 AWS Config 규칙이 규정 준수를 강화하지만, 인프라를 오직 AWS Config를 통해 관리하는 것은 배포 프로세스를 복잡하게 만들어 StackSets를 사용하는 것보다 덜 효율적입니다.",
            "AWS CodePipeline을 수동 승인으로 구현하면 배포 프로세스에 불필요한 지연이 발생하고, 배포 전에 일관된 규정 준수 검사를 제공하지 않으므로 비규정 준수 리소스가 프로비저닝될 수 있습니다."
        ]
    },
    {
        "Question Number": "73",
        "Situation": "한 회사가 최근에 애플리케이션 인프라를 AWS로 마이그레이션하고 AWS OpsWorks를 구성 관리에 사용하고 있습니다. 그들은 Chef를 사용하여 구성 관리를 하고 배포 프로세스를 자동화하면서 애플리케이션이 여러 EC2 인스턴스에 올바르게 배포되도록 보장하고자 합니다. DevOps 엔지니어는 모든 리소스가 효율적으로 관리되고 애플리케이션이 부하에 따라 확장될 수 있도록 해야 합니다.",
        "Question": "DevOps 엔지니어가 애플리케이션 구성이 모든 컴퓨트 유닛에 일관되게 적용되고 정의된 레시피에 따라 변경 사항이 동적으로 관리되도록 보장하기 위해 주로 집중해야 할 AWS OpsWorks 구성 요소는 무엇입니까?",
        "Options": {
            "1": "OpsWorks Layer, 관련 기능과 특성을 리소스 그룹에 조직합니다.",
            "2": "OpsWorks Application, 인스턴스에 배포할 애플리케이션을 지정합니다.",
            "3": "OpsWorks Agent, 인스턴스를 구성하기 위해 Chef 레시피를 실행합니다.",
            "4": "OpsWorks Stack, 애플리케이션을 위한 리소스 모음을 정의합니다."
        },
        "Correct Answer": "OpsWorks Agent, 인스턴스를 구성하기 위해 Chef 레시피를 실행합니다.",
        "Explanation": "OpsWorks Agent는 인스턴스가 어떻게 구성되어야 하는지를 정의하는 Chef 레시피를 실행하는 역할을 합니다. 이 구성 요소는 모든 인스턴스에 걸쳐 구성이 일관되게 적용되도록 보장하며, 이는 자동화 및 인프라의 원하는 상태를 유지하는 데 중요합니다.",
        "Other Options": [
            "OpsWorks Stack은 리소스 모음을 정의하지만 구성을 직접 실행하지는 않습니다.",
            "OpsWorks Layer는 리소스 그룹에 대한 관련 기능을 조직하지만 구성을 직접 실행하지는 않습니다.",
            "OpsWorks Application은 배포할 애플리케이션을 지정하지만 인스턴스의 구성 관리를 책임지지 않습니다."
        ]
    },
    {
        "Question Number": "74",
        "Situation": "글로벌 전자상거래 회사가 AWS CodePipeline과 AWS CodeBuild를 사용하여 웹 애플리케이션에 CI/CD 파이프라인을 통합했습니다. DevOps 엔지니어는 프로덕션에 배포하기 전에 코드 변경 사항을 검증하기 위해 자동화된 테스트가 파이프라인의 일부가 되도록 해야 합니다. 팀은 단위 테스트, 통합 테스트 및 성능 테스트를 효과적으로 구현하고자 합니다.",
        "Question": "DevOps 엔지니어가 테스트가 적절한 순서로 실행되고 결과가 명확하게 보고되도록 CI/CD 파이프라인에 자동화된 테스트를 통합하기 위해 어떤 접근 방식을 취해야 합니까?",
        "Options": {
            "1": "CodePipeline의 배포 단계 내에서 테스트를 통합하여 모든 테스트를 동시에 실행하여 코드 변경 사항에 대한 피드백을 빠르게 받을 수 있도록 합니다.",
            "2": "CodePipeline에 테스트 단계를 추가하여 단위 테스트를 먼저 실행하고, 그 다음 통합 테스트, 마지막으로 성능 테스트를 실행하여 각 단계가 성공해야 다음 단계로 이동할 수 있도록 합니다.",
            "3": "AWS Lambda를 사용하여 CodeBuild의 빌드 단계에서 테스트를 병렬로 실행하여 서로 다른 테스트 유형을 독립적으로 실행할 수 있도록 합니다.",
            "4": "테스트를 위한 별도의 CodePipeline을 생성하여 모든 코드 변경 시 트리거되도록 하여 주요 배포 파이프라인 외부에서 독립적으로 테스트할 수 있도록 합니다."
        },
        "Correct Answer": "CodePipeline에 테스트 단계를 추가하여 단위 테스트를 먼저 실행하고, 그 다음 통합 테스트, 마지막으로 성능 테스트를 실행하여 각 단계가 성공해야 다음 단계로 이동할 수 있도록 합니다.",
        "Explanation": "이 접근 방식은 테스트가 논리적인 순서로 실행되도록 하여 문제를 조기에 발견할 수 있게 합니다. 또한 각 단계에서 결과를 명확하게 보고하여 프로덕션에 도달하기 전에 애플리케이션의 전반적인 품질을 향상시킵니다.",
        "Other Options": [
            "배포 단계에서 모든 테스트를 동시에 실행하면 결과가 불명확해질 수 있습니다. 어떤 테스트가 실패하면 어떤 테스트가 실패를 초래했는지 명확하지 않아 문제 해결이 복잡해질 수 있습니다.",
            "AWS Lambda를 사용하여 테스트를 병렬로 실행하면 빠른 실행이 가능할 수 있지만, 순차적 접근 방식이 제공하는 명확성과 구조화된 보고가 부족할 수 있습니다. 또한 Lambda는 특정 환경이 필요한 테스트 유형에는 적합하지 않을 수 있습니다.",
            "테스트를 위한 별도의 CodePipeline을 생성하면 테스트가 배포 프로세스와 분리될 수 있지만, 코드 변경에 대한 피드백 지연을 초래할 수 있습니다. 또한 개발자가 두 개의 별도 파이프라인을 모니터링해야 하므로 복잡성이 증가합니다."
        ]
    },
    {
        "Question Number": "75",
        "Situation": "DevOps 엔지니어가 AWS에서 동적 애플리케이션 환경을 위한 인프라를 코드로 관리(IaC)하는 업무를 맡고 있습니다. 팀은 코드를 사용하여 인프라를 정의, 프로비저닝 및 관리할 수 있는 솔루션이 필요하며, 구성 변경 사항을 추적하고 버전 관리할 수 있어야 합니다.",
        "Question": "DevOps 엔지니어가 인프라를 코드로 관리하고 구성 관리를 위한 요구 사항을 충족하기 위해 어떤 솔루션을 구현해야 합니까?",
        "Options": {
            "1": "AWS Elastic Beanstalk를 배포하여 애플리케이션 환경을 관리합니다. Elastic Beanstalk CLI를 사용하여 애플리케이션 구성을 정의하고 업데이트를 관리합니다.",
            "2": "AWS OpsWorks를 구현하여 Chef를 사용하여 애플리케이션 스택을 관리합니다. Chef 서버를 사용하여 구성 관리를 처리하고 레시피에 대한 버전 관리를 유지합니다.",
            "3": "AWS CloudFormation을 사용하여 JSON 또는 YAML로 인프라를 코드로 정의합니다. 변경 사항 추적 및 협업을 위해 AWS CodeCommit과 같은 버전 관리 시스템에 템플릿을 저장합니다.",
            "4": "Amazon EC2 사용자 데이터 스크립트를 사용하여 인스턴스를 시작할 때 구성합니다. 스크립트를 AWS S3에 유지하고 새 인스턴스가 생성될 때마다 적용합니다."
        },
        "Correct Answer": "AWS CloudFormation을 사용하여 JSON 또는 YAML로 인프라를 코드로 정의합니다. 변경 사항 추적 및 협업을 위해 AWS CodeCommit과 같은 버전 관리 시스템에 템플릿을 저장합니다.",
        "Explanation": "AWS CloudFormation은 인프라를 코드로 관리하는 데 가장 적합합니다. JSON 또는 YAML을 사용하여 선언적으로 리소스를 정의할 수 있으며, 버전 관리 시스템과 원활하게 통합되어 변경 사항을 쉽게 추적하고 협업할 수 있습니다.",
        "Other Options": [
            "Amazon EC2 사용자 데이터 스크립트는 시작 시 인스턴스를 구성하는 방법을 제공하지만 완전한 인프라를 코드로 관리하는 솔루션을 제공하지 않습니다. 변경 사항을 효과적으로 추적할 수 없으며 CloudFormation과 같은 수준의 리소스 관리 및 버전 관리를 제공하지 않습니다.",
            "AWS OpsWorks는 Chef에 의존하는 구성 관리 서비스로, Chef에 익숙하지 않은 팀에게는 불필요한 복잡성을 추가할 수 있습니다. 레시피에 대한 버전 관리를 제공하지만 CloudFormation에 비해 인프라를 코드로 정의하고 관리하는 데는 덜 유연합니다.",
            "AWS Elastic Beanstalk는 애플리케이션을 배포하고 관리하기 위해 설계되었으며, 인프라를 코드로 직접 관리하는 것은 아닙니다. 애플리케이션 배포를 단순화하지만 AWS CloudFormation이 제공하는 인프라 정의에 대한 제어 수준은 제공하지 않습니다."
        ]
    }
]