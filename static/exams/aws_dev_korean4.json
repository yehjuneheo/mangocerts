[
    {
        "Question Number": "1",
        "Situation": "개발자가 Amazon SNS를 사용하여 여러 구독자에게 메시지를 배포하는 알림 시스템을 설계하고 있습니다. 메시지 흐름을 최적화하고 각 구독자가 관련 메시지만 수신하도록 보장하기 위해 개발자는 구독 필터 정책을 구현하기로 결정했습니다.",
        "Question": "메시지 속성을 기반으로 최적화된 메시지 전달을 달성하기 위해 개발자가 SNS 주제에 적용해야 할 구성은 무엇입니까?",
        "Options": {
            "1": "각 구독에 대한 필터 정책을 생성하여 메시지 속성을 기반으로 해당 구독자에게 전달되어야 할 메시지를 지정합니다.",
            "2": "필터 없이 단일 구독을 사용하고 각 구독자 애플리케이션 내에서 메시지 필터링을 처리합니다.",
            "3": "다양한 메시지 유형에 대해 여러 SNS 주제를 구현하고 사용자를 적절한 주제에 구독시킵니다.",
            "4": "모든 구독자에게 안전한 전달을 보장하기 위해 SNS 주제에서 메시지 암호화를 활성화합니다."
        },
        "Correct Answer": "각 구독에 대한 필터 정책을 생성하여 메시지 속성을 기반으로 해당 구독자에게 전달되어야 할 메시지를 지정합니다.",
        "Explanation": "각 구독에 대한 필터 정책을 생성하면 개발자가 속성을 기반으로 각 구독자에게 전달되는 메시지를 결정하는 특정 기준을 정의할 수 있습니다. 이를 통해 구독자는 자신과 관련된 메시지만 수신하게 되어 메시지 흐름을 효과적으로 최적화할 수 있습니다.",
        "Other Options": [
            "필터 없이 단일 구독을 사용하면 모든 구독자가 모든 메시지를 수신하게 되어 관련성과 관계없이 메시지 전달이 최적화되지 않습니다.",
            "다양한 메시지 유형에 대해 여러 SNS 주제를 구현하면 복잡성이 증가하고 관리가 어려워질 수 있으며, 필터 정책은 단일 주제 내에서 더 세분화된 제어를 가능하게 합니다.",
            "메시지 암호화를 활성화하면 보안이 강화되지만 구독자 관련성을 기반으로 최적화된 메시지 전달의 필요성을 해결하지 않으며, 이는 개발자의 주요 목표입니다."
        ]
    },
    {
        "Question Number": "2",
        "Situation": "한 회사가 Elastic Beanstalk를 사용하여 애플리케이션의 새 버전을 배포할 준비를 하고 있습니다. 높은 서비스 기준을 유지하기 위해 배포 과정에서 발생할 수 있는 다운타임을 최소화하고자 합니다. 애플리케이션이 항상 사용자에게 완전히 가용한 상태를 유지하는 것이 중요하며, 이는 배포 중 추가 비용이 발생하더라도 마찬가지입니다.",
        "Question": "새 애플리케이션 버전의 배포 중 전체 가용성을 유지하고 다운타임을 줄이려는 회사의 요구 사항을 고려할 때, 이 목표를 효과적으로 달성하기 위해 어떤 Elastic Beanstalk 배포 정책을 선택해야 합니까?",
        "Options": {
            "1": "한 번에 모두",
            "2": "롤링",
            "3": "추가 배치와 함께 롤링",
            "4": "불변"
        },
        "Correct Answer": "불변",
        "Explanation": "Elastic Beanstalk의 불변 배포 정책은 새 애플리케이션 버전으로 새로운 인스턴스 집합을 생성하면서 이전 버전을 계속 실행합니다. 이 접근 방식은 새 인스턴스가 배포되고 테스트되는 동안 다운타임이 발생하지 않도록 보장합니다. 이는 배포 과정에서 전체 가용성을 유지해야 하는 회사의 요구 사항에 이상적입니다.",
        "Other Options": [
            "한 번에 모두 배포 정책은 모든 인스턴스를 동시에 업데이트하므로 배포 중 문제가 발생할 경우 다운타임이 발생할 수 있습니다. 이는 다운타임을 최소화하고 가용성을 유지하려는 회사의 목표와 일치하지 않습니다.",
            "롤링 배포 정책은 한 번에 몇 개의 인스턴스를 업데이트하므로 전체 다운타임의 위험을 줄이지만 업데이트 과정에서 문제가 발생할 경우 일시적인 비가용 상태가 발생할 수 있습니다. 이 옵션은 회사의 지속적인 가용성 요구를 완전히 충족하지 않습니다.",
            "추가 배치와 함께 롤링 정책은 인스턴스를 배치로 업데이트하며 배포 중 일부 추가 용량을 추가합니다. 이는 일정 수준의 가용성을 제공하지만, 전체 과정 동안 애플리케이션이 완전히 가용한 상태를 유지한다는 보장을 제공하지 않으며, 이는 회사가 요구하는 사항입니다."
        ]
    },
    {
        "Question Number": "3",
        "Situation": "솔루션 아키텍트가 애플리케이션 로그를 면밀히 분석하여 성능 병목 현상과 시스템 효율성에 영향을 미칠 수 있는 오류를 식별하고 있습니다. 방대한 로그 데이터에서 통찰력을 발견하기 위해 아키텍트는 고급 검색 기능을 지원하고 로그 항목에 대한 심층 분석을 가능하게 하는 전문 쿼리 언어를 활용하고자 합니다.",
        "Question": "이 분석을 효과적으로 수행하고 조사 과정이 철저하고 효율적이도록 하기 위해 아키텍트가 사용해야 할 전문 로그 쿼리 언어는 무엇입니까?",
        "Options": {
            "1": "SQL",
            "2": "JSONPath",
            "3": "Amazon CloudWatch Logs Insights Query Language",
            "4": "GraphQL"
        },
        "Correct Answer": "Amazon CloudWatch Logs Insights Query Language",
        "Explanation": "Amazon CloudWatch Logs Insights Query Language는 로그 데이터를 유연하고 효율적으로 쿼리하고 분석하기 위해 특별히 설계되었습니다. 이 전문 언어는 로그 항목을 검색, 필터링 및 집계하기 위한 고급 기능을 제공하여 솔루션 아키텍트가 애플리케이션 로그 내에서 성능 병목 현상과 오류를 식별하는 데 필요한 이상적인 선택입니다.",
        "Other Options": [
            "SQL은 관계형 데이터베이스를 관리하고 쿼리하는 데 강력한 언어이지만 로그 분석에 맞춰져 있지 않으며 효과적인 로그 검색 및 집계를 위한 특정 기능이 부족합니다.",
            "JSONPath는 주로 JSON 문서에서 데이터를 쿼리하고 추출하는 데 사용되지만, 포괄적인 로그 검사를 위한 고급 분석 기능을 제공하지 않습니다.",
            "GraphQL은 클라이언트가 특정 데이터를 요청할 수 있도록 하는 API용 쿼리 언어입니다. 강력하지만 로그 분석을 위해 설계되지 않았으며 애플리케이션 로그를 효과적으로 분석하는 데 필요한 목표 기능을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "4",
        "Situation": "개발자가 AWS 클라우드 환경에서 여러 EC2 인스턴스를 설정해야 하는 프로젝트를 진행하고 있습니다. 이러한 인스턴스가 필요한 소프트웨어 패키지와 특정 파일로 올바르게 구성되도록 하기 위해, 개발자는 AWS CloudFormation을 사용하여 이 프로세스를 자동화하는 것을 목표로 하고 있습니다. 인스턴스 시작 시 패키지 설치와 파일 생성을 효율적으로 처리할 수 있는 적절한 헬퍼 스크립트를 선택하는 것이 개발자에게 필수적입니다.",
        "Question": "이 시나리오에서 개발자가 AWS CloudFormation을 사용하여 EC2 인스턴스를 시작할 때 패키지를 효과적으로 설치하고 파일을 생성하기 위해 어떤 특정 헬퍼 스크립트를 사용해야 합니까?",
        "Options": {
            "1": "cfn-signal",
            "2": "cfn-init",
            "3": "cfn-hup",
            "4": "cfn-get-metadata"
        },
        "Correct Answer": "cfn-init",
        "Explanation": "정답은 cfn-init입니다. 이 헬퍼 스크립트는 EC2 인스턴스 초기화 중에 실행되도록 설계되어 있으며, CloudFormation 템플릿의 메타데이터에 지정된 대로 패키지 설치와 파일 생성을 관리합니다. 인스턴스가 시작된 직후 원하는 구성에 따라 설정되도록 보장합니다.",
        "Other Options": [
            "cfn-signal은 리소스 생성 상태를 CloudFormation에 신호를 보내는 데 사용되지만, 패키지 설치나 파일 생성을 처리하지 않습니다.",
            "cfn-hup은 CloudFormation 스택의 변경 사항에 응답하는 데 사용되지만, 초기 패키지 설치 및 파일 생성을 위한 것이 아닙니다.",
            "cfn-get-metadata는 CloudFormation 스택에서 메타데이터를 검색하는 헬퍼 스크립트이지만, EC2 인스턴스에서 패키지를 설치하거나 파일을 생성하지 않습니다."
        ]
    },
    {
        "Question Number": "5",
        "Situation": "개발자가 AWS Lambda와 API Gateway를 활용하여 서버리스 애플리케이션을 만들었습니다. 이 애플리케이션은 HTTP 요청을 처리하기 위한 강력하고 확장 가능한 솔루션을 제공합니다. 개발자가 이 애플리케이션을 프로덕션 환경으로 confidently 이동하기 전에, 개발 환경에서 철저한 테스트를 수행하는 것이 중요합니다. 이 테스트 단계에는 모든 기능이 예상대로 작동하는지 확인하기 위해 사용자 상호작용을 모방하는 모의 API 엔드포인트를 평가하는 것이 포함됩니다. 개발자의 주요 목표는 배포된 Lambda 함수가 API Gateway 통합에 의해 올바르게 트리거되는지 확인하는 것입니다. 이는 애플리케이션의 성능과 신뢰성에 필수적입니다.",
        "Question": "개발자가 배포된 Lambda 함수에 대한 통합 테스트를 효과적으로 수행하여 API Gateway가 의도한 대로 함수를 성공적으로 트리거하도록 하려면 어떤 방법을 사용해야 합니까?",
        "Options": {
            "1": "AWS X-Ray를 사용하여 Lambda와 API Gateway 간의 상호작용을 추적하여 성능 및 오류를 분석합니다.",
            "2": "AWS CloudWatch Logs를 사용하여 Lambda 함수의 로그 출력을 확인하고 API Gateway 통합이 작동하는지 확인합니다.",
            "3": "모의 API Gateway 단계를 만들고 AWS SAM을 사용하여 모의 페이로드로 Lambda 함수를 로컬에서 테스트합니다.",
            "4": "AWS API Gateway 단계를 사용하여 테스트 환경을 구성하고 Lambda 함수의 테스트 버전을 배포합니다."
        },
        "Correct Answer": "AWS API Gateway 단계를 사용하여 테스트 환경을 구성하고 Lambda 함수의 테스트 버전을 배포합니다.",
        "Explanation": "AWS API Gateway 단계를 사용하여 테스트 환경을 구성하면 개발자가 테스트 목적으로 Lambda 함수의 별도 버전을 배포할 수 있습니다. 이 설정은 개발자가 API Gateway가 Lambda 함수를 올바르게 트리거하는지 확인하고 전체 통합이 예상대로 작동하는지 검증할 수 있는 현실적인 테스트 시나리오를 제공합니다. 이는 프로덕션 버전에 영향을 주지 않고 제어된 환경에서 배포된 애플리케이션의 엔드 투 엔드 테스트를 가능하게 합니다.",
        "Other Options": [
            "AWS X-Ray를 사용하는 것은 성능 문제를 추적하고 분석하는 데 유용하지만, API Gateway에 의해 트리거된 함수의 직접적인 통합 테스트를 촉진하지는 않습니다. 이는 모니터링에 더 중점을 두고 있습니다.",
            "AWS CloudWatch Logs는 로그 출력을 검토하고 실행 후 문제를 진단하는 데 유용하지만, API Gateway와 Lambda 함수 간의 통합을 실시간으로 적극적으로 테스트할 수 있는 수단을 제공하지 않습니다.",
            "모의 API Gateway 단계를 만들고 AWS SAM을 사용하여 로컬에서 테스트하는 것은 로컬 개발에 유효한 접근 방식이지만, API Gateway와 함께 Lambda 함수의 실제 배포를 테스트하지 않으므로 통합 테스트에 필수적입니다."
        ]
    },
    {
        "Question Number": "6",
        "Situation": "Amazon S3 정적 웹사이트에서 이미지와 비디오를 호스팅하는 회사는 콘텐츠에 대한 접근이 안전하고 통제되도록 보장할 방법을 찾고 있습니다. 그들은 특정 사용자가 콘텐츠를 임시로 볼 수 있도록 하면서도 무단 접근을 방지하고자 합니다. 이를 달성하기 위해, 회사는 사용자가 정의된 시간 내에만 파일에 접근할 수 있도록 보안적이고 시간 제한이 있는 접근 권한을 부여하는 다양한 방법을 탐색하고 있습니다.",
        "Question": "회사가 공유 콘텐츠에 대한 보안과 제한된 가용성을 보장하면서 이러한 접근 제어 요구 사항을 효과적으로 충족하기 위해 어떤 솔루션을 구현해야 합니까?",
        "Options": {
            "1": "공용 URL을 사용하여 제한된 시간 동안 콘텐츠를 공유합니다.",
            "2": "AWS SDK API를 사용하여 생성된 시간 제한이 있는 권한을 가진 사전 서명된 URL을 사용합니다.",
            "3": "특정 IP 주소에 대한 접근을 제한하기 위해 S3 버킷 정책을 사용합니다.",
            "4": "AWS CloudFront를 활성화하고 캐시 제어를 위한 만료 시간을 설정합니다."
        },
        "Correct Answer": "AWS SDK API를 사용하여 생성된 시간 제한이 있는 권한을 가진 사전 서명된 URL을 사용합니다.",
        "Explanation": "사전 서명된 URL을 사용하면 회사가 특정 사용자에게 S3 콘텐츠에 대한 접근을 안전하게 공유할 수 있습니다. 이 방법은 시간 제한이 있는 권한을 부여하여 사용자가 URL 생성 시 설정된 만료 시간까지만 콘텐츠에 접근할 수 있도록 보장합니다. 사전 서명된 URL은 콘텐츠를 공개적으로 노출하지 않고 접근을 제어하는 안전한 방법으로, 회사의 요구에 이상적입니다.",
        "Other Options": [
            "공용 URL을 사용하여 콘텐츠를 공유하면 링크가 있는 누구나 접근할 수 있게 되어, 무단 접근을 방지하려는 회사의 요구를 충족하지 못합니다.",
            "특정 IP 주소에 대한 접근을 제한하기 위해 S3 버킷 정책을 사용하는 것은 접근을 제한할 수 있지만, 시간 제한이 있는 솔루션을 제공하지 않습니다. 사용자는 지정된 IP 범위 내에 있는 한 접근 권한을 유지하게 되며, 이는 회사의 임시 접근 필요를 충족하지 못합니다.",
            "AWS CloudFront를 활성화하고 캐시 제어를 위한 만료 시간을 설정하는 것은 콘텐츠 전송 및 캐싱에 도움이 될 수 있지만, 특정 사용자 접근 제어의 필요를 해결하지는 않습니다. 사용자는 다른 보안 조치와 결합되지 않는 한 의도된 시간 프레임을 넘어 캐시된 콘텐츠에 여전히 접근할 수 있습니다."
        ]
    },
    {
        "Question Number": "7",
        "Situation": "한 회사가 Amazon API Gateway로 API를 마이그레이션하고 있으며, 각기 다른 배포 단계를 설정해야 합니다. 개발, 스테이징 및 프로덕션 단계마다 관리 및 접근을 용이하게 하기 위해 각기 다른 커스텀 도메인을 설정해야 합니다.",
        "Question": "회사가 각 단계에 대해 커스텀 도메인을 지원하기 위해 API Gateway에서 어떤 구성을 구현해야 합니까?",
        "Options": {
            "1": "각 개별 단계에 대해 별도의 API Gateway API를 생성하고, 각 API에 대해 서로 다른 커스텀 도메인을 할당하여 관리를 개선합니다.",
            "2": "API Gateway 단계를 효과적으로 사용하고, 각 고유 단계를 서로 다른 커스텀 도메인 이름과 연결하여 정확한 라우팅을 위해 기본 경로 매핑을 활용합니다.",
            "3": "여러 도메인을 사용할 필요 없이 단일 커스텀 도메인 내에서 경로 기반 라우팅을 구현하여 다양한 단계를 구분합니다.",
            "4": "각 배포 단계에 대해 서브도메인을 활용하고 DNS 레코드를 적절히 구성하되, API Gateway 내의 설정은 수정하지 않습니다."
        },
        "Correct Answer": "API Gateway 단계를 효과적으로 사용하고, 각 고유 단계를 서로 다른 커스텀 도메인 이름과 연결하여 정확한 라우팅을 위해 기본 경로 매핑을 활용합니다.",
        "Explanation": "올바른 접근 방식은 API Gateway 단계를 사용하고 기본 경로 매핑을 통해 각 단계를 고유한 커스텀 도메인과 연결하는 것입니다. 이 방법은 다양한 배포 단계를 명확하게 조직하고 관리할 수 있게 하며, API Gateway 기능의 유연성을 활용할 수 있습니다.",
        "Other Options": [
            "각 단계에 대해 별도의 API Gateway API를 생성하는 것은 관리 복잡성을 증가시키고 노력의 중복을 초래할 수 있어 비효율적인 접근 방식입니다.",
            "단일 커스텀 도메인 내에서 경로 기반 라우팅을 사용하는 것은 유효한 옵션이지만, 각 단계에 대한 커스텀 도메인이 제공하는 명확한 구분과 분리를 제공하지 않습니다.",
            "서브도메인을 사용하고 DNS 레코드를 구성하는 것은 실행 가능한 방법이지만, API Gateway 외부에서 추가 관리가 필요하며 여러 단계를 처리할 때 혼란을 초래할 수 있습니다."
        ]
    },
    {
        "Question Number": "8",
        "Situation": "한 회사가 AWS Lambda 함수의 여러 버전을 관리하여 배포 파이프라인의 다양한 단계(예: 개발, 테스트, 프로덕션)를 지원하고 있습니다. 그들은 새로운 버전이 배포될 때마다 클라이언트 구성을 변경하지 않고 특정 버전으로 트래픽을 라우팅하고자 합니다.",
        "Question": "회사가 배포 단계에 따라 트래픽 라우팅을 달성하기 위해 어떤 Lambda 기능을 사용해야 합니까?",
        "Options": {
            "1": "Lambda Layers",
            "2": "Lambda Aliases",
            "3": "Lambda Snapshots",
            "4": "Lambda Provisioned Concurrency"
        },
        "Correct Answer": "Lambda Aliases",
        "Explanation": "Lambda Aliases는 특정 버전의 Lambda 함수에 대한 포인터를 생성할 수 있게 해줍니다. 이를 통해 함수의 다양한 버전으로 트래픽을 관리하고 라우팅하는 것이 쉬워지며, 개발, 테스트 및 프로덕션과 같은 배포 단계에 이상적입니다. 별칭을 사용함으로써 회사는 클라이언트 구성을 변경하지 않고도 별칭을 업데이트하여 새로운 버전을 가리킬 수 있습니다.",
        "Other Options": [
            "Lambda Layers는 여러 함수 간에 공통 코드와 종속성을 관리하는 데 사용되지만, 서로 다른 버전 간의 트래픽 라우팅을 촉진하지는 않습니다.",
            "Lambda Snapshots는 AWS Lambda에서 인식되는 기능이 아니므로 버전 간의 관리나 트래픽 라우팅에 사용할 수 없습니다.",
            "Lambda Provisioned Concurrency는 함수가 미리 설정된 수의 인스턴스를 준비하여 성능을 개선하는 기능이지만, 버전 라우팅을 처리하지는 않습니다."
        ]
    },
    {
        "Question Number": "9",
        "Situation": "한 회사가 AWS Lambda 함수의 여러 반복을 적극적으로 관리하여 배포 파이프라인의 다양한 단계인 개발, 테스트 및 프로덕션 환경을 수용하고 있습니다. 그들은 새로운 버전이 배포될 때마다 클라이언트 구성을 변경하지 않고 특정 버전으로 트래픽을 라우팅할 수 있는 솔루션을 찾고 있습니다. 이는 배포 프로세스를 크게 향상시키고 다양한 단계 간의 전환 중 발생할 수 있는 잠재적인 오류를 줄이는 데 도움이 될 것입니다.",
        "Question": "회사가 배포 파이프라인의 다양한 단계에 따라 함수의 적절한 버전으로 트래픽을 효과적으로 관리하고 라우팅하기 위해 AWS Lambda의 어떤 특정 기능을 활용해야 합니까?",
        "Options": {
            "1": "Lambda Layers, 여러 Lambda 함수 간에 공유 코드와 라이브러리를 관리할 수 있지만, 트래픽 관리에는 직접적으로 도움이 되지 않습니다.",
            "2": "Lambda Aliases, 특정 버전의 Lambda 함수에 대한 포인터를 생성할 수 있는 기능으로, 클라이언트 구성을 수정하지 않고도 트래픽 라우팅을 쉽게 관리할 수 있습니다.",
            "3": "Lambda Snapshots, AWS Lambda의 기능이 아니므로 트래픽 라우팅이나 버전 관리에 적용되지 않습니다.",
            "4": "Lambda Provisioned Concurrency, 함수가 즉시 응답할 수 있도록 준비되도록 보장하는 기능이지만, 트래픽 라우팅 기능은 제공하지 않습니다."
        },
        "Correct Answer": "Lambda Aliases, 특정 버전의 Lambda 함수에 대한 포인터를 생성할 수 있는 기능으로, 클라이언트 구성을 수정하지 않고도 트래픽 라우팅을 쉽게 관리할 수 있습니다.",
        "Explanation": "Lambda Aliases는 Lambda 함수의 다양한 버전을 관리하는 데 특별히 설계되었습니다. 특정 버전을 가리키는 별칭을 생성함으로써, 회사는 각 배포 단계에 적합한 버전으로 트래픽 라우팅을 쉽게 제어할 수 있으며, 업데이트 중 클라이언트 구성이 변경되지 않도록 보장할 수 있습니다.",
        "Other Options": [
            "Lambda Layers는 함수 간에 코드와 라이브러리를 공유하는 데 중점을 두며, 함수 버전 기반의 트래픽 라우팅 메커니즘을 제공하지 않습니다.",
            "Lambda Snapshots는 AWS Lambda의 기능으로 존재하지 않으므로, 함수 버전 관리나 트래픽 라우팅과 관련이 없습니다.",
            "Lambda Provisioned Concurrency는 함수 시작 시간을 개선하기 위해 설계되었지만, 서로 다른 함수 버전 간의 트래픽을 관리하거나 라우팅하는 기능은 없습니다."
        ]
    },
    {
        "Question Number": "10",
        "Situation": "한 회사가 AWS Lambda와 Amazon SQS를 활용하여 서버리스 애플리케이션을 성공적으로 개발했습니다. 이 혁신적인 애플리케이션은 SQS 큐에서 메시지를 효율적으로 처리하고 해당 메시지의 내용에 따라 여러 Lambda 함수를 트리거하도록 설계되었습니다. 그러나 회사는 동시성 문제와 관련된 잠재적인 위험을 확인했습니다. 그들은 여러 Lambda 함수가 우연히 동일한 메시지를 동시에 처리할 수 있어 애플리케이션의 일관성이 떨어지고 데이터가 손상될 수 있다는 점을 걱정하고 있습니다. 이 위험을 완화하기 위해 회사는 각 메시지가 중복 없이 올바르게 처리되도록 보장하는 옵션을 탐색하고 있습니다.",
        "Question": "회사가 동시성 문제를 효과적으로 처리하고 각 메시지가 Lambda에 의해 한 번만 처리되도록 보장하여 데이터 무결성과 일관성을 유지하기 위해 어떤 전략을 구현할 수 있습니까?",
        "Options": {
            "1": "'최소 한 번' 배달 모델을 사용하여 각 메시지가 처리되도록 하되, 실패 시 재시도를 허용합니다.",
            "2": "SQS에 대해 데드레터 큐(DLQ)를 설정하여 실패한 메시지를 포착하고 일정 기간 후에 재처리합니다.",
            "3": "SQS에서 이벤트를 처리하기 위해 Lambda의 내장 중복 제거 기능을 사용하여 중복 메시지가 처리되지 않도록 합니다.",
            "4": "SQS 큐에 대해 FIFO 옵션을 사용하여 각 메시지가 전송된 순서대로 한 번만 처리되도록 보장합니다."
        },
        "Correct Answer": "SQS 큐에 대해 FIFO 옵션을 사용하여 각 메시지가 전송된 순서대로 한 번만 처리되도록 보장합니다.",
        "Explanation": "SQS 큐에 대한 FIFO(선입선출) 옵션은 각 메시지가 정확히 한 번 처리되고 전송된 순서대로 처리되도록 설계되었습니다. 이는 여러 Lambda 함수가 동시에 동일한 메시지를 처리하는 것을 방지하여 동시성 문제의 위험을 크게 줄이고 데이터 무결성과 일관성을 유지합니다.",
        "Other Options": [
            "'최소 한 번' 배달 모델을 사용하는 것은 중복 처리를 방지하지 않으며, 메시지가 최소 한 번 배달되도록 보장할 뿐, 동일한 메시지가 여러 번 처리될 수 있습니다.",
            "데드레터 큐(DLQ)를 설정하는 것은 처리에 실패한 메시지를 처리하는 데 유용하지만, 본질적으로 동시성 문제를 해결하거나 여러 프로세스가 동시에 동일한 메시지를 처리하는 것을 방지하지는 않습니다.",
            "Lambda의 내장 중복 제거 기능은 이를 지원하는 이벤트 소스에 주로 적용되며, 도움이 될 수 있지만 추가 구성 없이 SQS의 맥락에서 메시지가 정확히 한 번 처리된다는 것을 보장하지는 않습니다."
        ]
    },
    {
        "Question Number": "11",
        "Situation": "한 개발자가 AWS SAM(서버리스 애플리케이션 모델)을 사용하여 서버리스 애플리케이션을 배포하고 있습니다. 이 애플리케이션은 다양한 작업을 처리하는 여러 AWS Lambda 함수, 요청을 관리하는 Amazon API Gateway API, 애플리케이션 데이터를 저장하는 여러 Amazon DynamoDB 테이블로 구성되어 있습니다. 애플리케이션의 인프라가 신뢰할 수 있고 유지 관리 가능하도록 하기 위해 개발자는 이러한 인프라 변경 사항의 버전 관리를 가능하게 하고 배포 중 문제가 발생할 경우 변경 사항을 롤백할 수 있는 전략을 구현하고자 합니다.",
        "Question": "개발자가 애플리케이션의 인프라를 효과적으로 관리하면서 모든 변경 사항이 추적되고 필요 시 되돌릴 수 있도록 하기 위해 어떤 모범 사례를 채택해야 합니까?",
        "Options": {
            "1": "각 리소스에 대해 별도의 AWS CloudFormation 템플릿을 사용합니다.",
            "2": "AWS Management Console을 사용하여 리소스를 수동으로 업데이트합니다.",
            "3": "모든 인프라를 단일 SAM 템플릿 내에서 코드로 정의하고 Git과 같은 버전 관리 시스템을 사용합니다.",
            "4": "개별 AWS CLI 명령 및 스크립트를 사용하여 리소스를 배포합니다."
        },
        "Correct Answer": "모든 인프라를 단일 SAM 템플릿 내에서 코드로 정의하고 Git과 같은 버전 관리 시스템을 사용합니다.",
        "Explanation": "모든 인프라를 단일 SAM 템플릿 내에서 코드로 정의하면 애플리케이션 리소스의 조직 및 관리가 더 용이해집니다. Git과 같은 버전 관리 시스템을 사용함으로써 개발자는 변경 사항을 추적하고 팀원과 협업하며 필요 시 이전 버전으로 쉽게 롤백할 수 있어 보다 효율적이고 신뢰할 수 있는 개발 프로세스를 촉진합니다.",
        "Other Options": [
            "각 리소스에 대해 별도의 AWS CloudFormation 템플릿을 사용하는 것은 복잡성을 초래하고 리소스 간의 종속성 관리가 어려워져 변경 사항을 통합된 단위로 추적하기 어렵게 만듭니다.",
            "AWS Management Console을 통해 리소스를 수동으로 업데이트하는 것은 인적 오류가 발생하기 쉽고 버전 관리가 부족하며, 서로 다른 환경에서 인프라를 복제하거나 이전 상태로 되돌리기 어렵습니다.",
            "개별 AWS CLI 명령 및 스크립트를 사용하여 리소스를 배포하는 것은 번거롭고 오류가 발생하기 쉬우며, 변경 사항 추적이나 애플리케이션 전반의 종속성 관리를 위한 명확한 구조를 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "12",
        "Situation": "한 개발자가 AWS X-Ray를 사용하여 애플리케이션 활동을 추적하고 있으며 각 추적과 함께 추가 데이터를 기록해야 합니다. 그들은 일부 데이터가 필터 표현식을 사용하여 검색 가능해야 하며, 다른 데이터는 정보 제공 목적으로만 사용되며 인덱싱할 필요가 없습니다.",
        "Question": "개발자가 이러한 요구 사항을 효과적으로 충족하기 위해 어떤 AWS X-Ray 기능을 사용해야 합니까?",
        "Options": {
            "1": "검색 가능한 데이터에는 주석을 사용하고 인덱싱할 필요가 없는 정보에는 메타데이터를 사용합니다.",
            "2": "검색 가능성이 있는 데이터에는 메타데이터를 사용하고 정보 제공 목적으로만 사용되는 데이터에는 주석을 사용합니다.",
            "3": "검색이 필요한 데이터에는 세그먼트를 사용하고 인덱싱이 필요 없는 정보에는 하위 세그먼트를 사용합니다.",
            "4": "순수 정보 데이터에는 필터 표현식을 구현하고 검색 가능해야 하는 데이터에는 메타데이터를 사용합니다."
        },
        "Correct Answer": "검색 가능한 데이터에는 주석을 사용하고 인덱싱할 필요가 없는 정보에는 메타데이터를 사용합니다.",
        "Explanation": "AWS X-Ray의 주석은 개발자가 추가적인 검색 가능한 키-값 쌍을 추가할 수 있도록 설계되어 있어 쿼리할 필요가 있는 데이터에 적합합니다. 반면, 메타데이터는 인덱싱이 필요하지 않은 비검색 정보에 대한 맥락을 제공하도록 설계되어 있어 개발자의 요구 사항을 효과적으로 충족합니다.",
        "Other Options": [
            "이 옵션은 메타데이터가 비검색 데이터에 사용되며 주석은 검색 가능한 키-값 쌍을 위해 특별히 설계되었기 때문에 잘못되었습니다.",
            "이 옵션은 세그먼트가 요청의 고수준 그룹화이며 검색 가능 데이터와 비검색 데이터를 구분하는 목적에 부합하지 않기 때문에 잘못되었습니다.",
            "이 옵션은 필터 표현식이 데이터를 저장하는 데 사용되지 않고, X-Ray에서 추적을 쿼리하고 필터링하는 데 사용되므로 검색 가능 또는 비검색 데이터로 분류하는 데 사용되지 않기 때문에 잘못되었습니다."
        ]
    },
    {
        "Question Number": "13",
        "Situation": "개발자가 AWS Lambda를 사용하여 서버리스 애플리케이션을 만들고 있습니다. 이 애플리케이션은 대량의 데이터를 처리하고 관리하도록 설계되었으며, 이는 리소스를 많이 소모할 수 있고 일부 작업은 오랜 시간 동안 실행될 수 있습니다. 개발자가 성능과 효율성을 최적화하는 작업을 진행하면서, AWS Lambda의 실행 시간 제한을 이해하는 것이 모든 작업이 구성된 매개변수 내에서 성공적으로 완료될 수 있도록 하는 데 중요합니다.",
        "Question": "AWS Lambda를 사용하여 서버리스 애플리케이션을 개발하는 맥락에서, 단일 AWS Lambda 함수에 대해 설정할 수 있는 최대 타임아웃 기간은 얼마입니까? 이는 긴 실행 작업을 효과적으로 처리할 수 있도록 보장합니다.",
        "Options": {
            "1": "5분",
            "2": "10분",
            "3": "15분",
            "4": "900초"
        },
        "Correct Answer": "15분",
        "Explanation": "AWS Lambda 함수에 대해 설정할 수 있는 최대 타임아웃 기간은 15분(900초)입니다. 이는 함수가 조기에 타임아웃되지 않고 추가 실행 시간이 필요한 더 복잡한 처리 작업을 처리할 수 있도록 합니다.",
        "Other Options": [
            "5분은 AWS Lambda 함수의 최대 타임아웃 한도인 15분보다 낮기 때문에 잘못된 답변입니다.",
            "10분은 유효한 타임아웃 구성일 수 있지만, AWS Lambda 함수에 대해 허용되는 최대 한도를 나타내지 않기 때문에 잘못된 답변입니다.",
            "900초는 숫적으로 15분과 동일한 기간을 나타내지만, AWS Lambda 타임아웃 설정에 대한 논의에서 덜 일반적으로 사용되기 때문에 이 맥락에서는 잘못된 답변입니다."
        ]
    },
    {
        "Question Number": "14",
        "Situation": "개발자가 AWS EC2 인스턴스를 구성하여 애플리케이션 추적을 AWS X-Ray에 효과적으로 전송하고 있습니다. 이는 인스턴스에서 작동하는 X-Ray 데몬이 추적 데이터를 업로드하고 추적 수집 및 보고 방식을 규정하는 샘플링 규칙을 사용할 수 있는 적절한 권한을 보유하도록 하는 것을 포함합니다. 할당된 권한이 AWS X-Ray 서비스와 원활하게 상호작용할 수 있도록 하는 것이 중요합니다.",
        "Question": "X-Ray 데몬이 제대로 작동할 수 있도록 하는 것이 중요하므로, 개발자가 인스턴스 역할에 첨부해야 할 IAM 정책은 무엇입니까? 이는 추적 데이터를 업로드하고 샘플링 규칙을 효과적으로 적용하는 데 필요한 권한을 보장합니다.",
        "Options": {
            "1": "AWSXrayReadOnlyAccess - 이 정책은 X-Ray 리소스에 대한 읽기 전용 액세스를 허용하지만, 추적 데이터를 업로드하는 데는 충분하지 않습니다.",
            "2": "AWSXRayDaemonWriteAccess - 이 정책은 X-Ray 데몬이 추적 데이터를 작성하고 샘플링 규칙을 효과적으로 사용할 수 있는 필요한 권한을 부여합니다.",
            "3": "AWSXrayFullAccess - 이 정책은 X-Ray 서비스에 대한 전체 액세스를 제공하지만, 데몬의 요구 사항에 비해 과도한 권한을 부여할 수 있습니다.",
            "4": "CloudWatchAgentServerPolicy - 이 정책은 CloudWatch 에이전트 작업을 위한 것이며, X-Ray 데몬 권한과는 관련이 없습니다."
        },
        "Correct Answer": "AWSXRayDaemonWriteAccess - 이 정책은 X-Ray 데몬이 추적 데이터를 작성하고 샘플링 규칙을 효과적으로 사용할 수 있는 필요한 권한을 부여합니다.",
        "Explanation": "정답은 AWSXRayDaemonWriteAccess입니다. 이 정책은 X-Ray 데몬이 추적 데이터를 업로드하고 샘플링 규칙을 효과적으로 관리하는 데 필요한 권한을 제공합니다. 이는 X-Ray 서비스의 기능적 요구 사항에 맞춰져 있으며, 데몬이 불필요한 제한 없이 작동할 수 있도록 보장합니다.",
        "Other Options": [
            "AWSXrayReadOnlyAccess는 X-Ray 리소스에 대한 읽기 전용 액세스만 허용하므로, X-Ray 데몬이 추적 데이터를 업로드하는 데 필요한 권한을 제공하지 않기 때문에 잘못된 답변입니다.",
            "AWSXrayFullAccess는 X-Ray 서비스에 대한 전체 권한을 부여하므로, X-Ray 데몬이 요구하는 것보다 더 많은 액세스를 포함하여 최소 권한 원칙을 위반할 수 있기 때문에 잘못된 답변입니다.",
            "CloudWatchAgentServerPolicy는 CloudWatch 에이전트와 관련된 권한을 위해 특별히 설계되었으므로, X-Ray 데몬이 제대로 작동하는 데 필요한 관련 권한을 제공하지 않기 때문에 잘못된 답변입니다."
        ]
    },
    {
        "Question Number": "15",
        "Situation": "개발자가 DynamoDB에서 데이터 검색 시 눈에 띄는 지연을 겪고 있으며, 이는 트래픽이 증가함에 따라 점점 더 문제가 되고 있습니다. 애플리케이션은 성능과 사용자 경험을 유지하기 위해 마이크로초 내에 완료되어야 하는 읽기 작업을 처리하도록 설계되었습니다. 트래픽이 계속 증가함에 따라 데이터 접근 시간을 효과적으로 최적화할 수 있는 솔루션을 찾는 것이 필수적입니다.",
        "Question": "현재의 높은 트래픽을 고려할 때, DynamoDB의 지연 문제를 완화하기 위해 개발자가 무엇을 구현해야 합니까?",
        "Options": {
            "1": "DynamoDB Streams를 활성화하여 데이터 수정을 관리합니다.",
            "2": "DynamoDB Accelerator (DAX)를 사용하여 읽기 작업을 가속화합니다.",
            "3": "프로비저닝된 읽기 용량을 늘려 더 많은 요청을 처리합니다.",
            "4": "조건부 읽기를 활성화하여 데이터 검색을 최적화합니다."
        },
        "Correct Answer": "DynamoDB Accelerator (DAX)를 사용하여 읽기 작업을 가속화합니다.",
        "Explanation": "DynamoDB Accelerator (DAX)는 완전 관리형 인메모리 캐싱 서비스로, 인기 있는 쿼리에 대해 마이크로초 응답 시간을 제공하여 읽기 성능을 크게 향상시킬 수 있습니다. DAX를 사용함으로써 개발자는 트래픽이 많은 기간 동안 DynamoDB 테이블에 대한 부담을 줄여 애플리케이션이 성능 요구 사항을 충족할 수 있도록 합니다.",
        "Other Options": [
            "DynamoDB Streams를 활성화하는 것은 테이블의 항목 변경 사항을 캡처하는 데 주로 사용되며, 읽기 지연 문제를 직접적으로 해결하지 않습니다.",
            "프로비저닝된 읽기 용량을 늘리면 초당 더 많은 읽기를 허용하여 도움이 될 수 있지만, 고성능 애플리케이션에 필요한 마이크로초 응답 시간을 보장하지는 않습니다.",
            "조건부 읽기를 활성화하면 각 읽기 작업에 대해 조건을 평가해야 하므로 추가 오버헤드가 발생하여 지연이 증가할 수 있습니다."
        ]
    },
    {
        "Question Number": "16",
        "Situation": "개발자는 실시간 데이터 처리를 위해 설계된 Amazon Kinesis Data Stream을 적극적으로 모니터링하고 있습니다. 이 모니터링 세션 동안, 개발자는 흥미로운 패턴을 발견합니다: 스트림 내의 특정 샤드가 지속적으로 저활용되고 있으며, 이는 데이터 트래픽을 처리하는 데 완전히 사용되지 않고 있음을 의미합니다. 반면, 다른 샤드들은 작업 부하를 고르게 효율적으로 관리하고 있습니다. 이러한 불일치는 데이터 스트림의 전반적인 성능을 향상시키고 자원이 효과적으로 사용되도록 하기 위한 최선의 조치에 대한 질문을 제기합니다.",
        "Question": "개발자는 저활용 샤드의 활용도를 최적화하고 데이터 스트림의 전반적인 효율성을 개선하기 위해 어떤 조치를 취해야 합니까?",
        "Options": {
            "1": "저활용 샤드를 분할하여 용량을 늘리고 샤드 간의 데이터 분배를 개선하는 것을 고려하십시오.",
            "2": "저활용 샤드를 인접한 샤드와 병합하여 부하를 균형 있게 하고 자원 활용도를 개선하는 것을 탐색하십시오.",
            "3": "처리 능력을 향상시키고 전체 샤드 수에 더 잘 맞추기 위해 컴퓨트 인스턴스 수를 늘리는 옵션을 평가하십시오.",
            "4": "비용을 최소화하고 데이터 스트림 관리를 간소화하기 위해 저활용 샤드를 완전히 삭제하는 것을 생각하십시오."
        },
        "Correct Answer": "저활용 샤드를 인접한 샤드와 병합하여 부하를 균형 있게 하고 자원 활용도를 개선하는 것을 탐색하십시오.",
        "Explanation": "저활용 샤드를 인접한 샤드와 병합하는 것은 샤드 간의 부하를 균형 있게 하는 전략적 조치입니다. 이 작업은 데이터 트래픽을 통합하고 자원이 보다 효과적으로 활용되도록 하여 Kinesis Data Stream의 전반적인 성능을 향상시킵니다.",
        "Other Options": [
            "저활용 샤드를 분할하는 것은 용량을 늘리는 해결책처럼 보일 수 있지만, 저활용 문제의 근본적인 원인을 해결하지 않고 더 많은 샤드를 생성하여 문제를 악화시킬 가능성이 높습니다.",
            "컴퓨트 인스턴스 수를 늘리는 것은 샤드 활용 문제를 직접적으로 해결하지 않습니다. 샤드가 최적으로 활용되지 않는다면 더 많은 컴퓨트 자원이 불필요할 수 있습니다.",
            "저활용 샤드를 삭제하는 것은 데이터 손실을 초래하고 데이터 스트림의 전체 용량을 줄여 데이터 처리에 문제를 일으킬 수 있으므로 실현 가능한 해결책이 아닙니다."
        ]
    },
    {
        "Question Number": "17",
        "Situation": "당신은 AWS에서 수신 이벤트를 효율적으로 처리할 수 있는 신뢰할 수 있는 서버리스 애플리케이션을 구축하는 임무를 맡고 있습니다.",
        "Question": "AWS에서 Lambda 함수와 API Gateway를 사용하여 서버리스 애플리케이션을 개발하고 있습니다. Lambda 함수가 수신 이벤트를 비동기적으로 처리하고, 실패 시 재시도를 처리하며, 실패한 이벤트를 Dead Letter Queue (DLQ)에 저장하도록 보장해야 합니다. 어떤 구성이 이를 가장 잘 달성할 수 있을까요?",
        "Options": {
            "1": "Lambda를 동기 호출로 구성하고 재시도 정책과 SQS와의 직접 통합을 설정하십시오.",
            "2": "Lambda를 비동기 호출로 설정하고 Lambda 함수의 설정에서 DLQ를 구성하십시오.",
            "3": "API Gateway를 사용하여 Lambda를 동기적으로 트리거하고 재시도를 위해 CloudWatch 알람을 구성하십시오.",
            "4": "EventBridge를 사용하여 Lambda를 트리거하고 EventBridge 규칙에서 직접 재시도를 구성하십시오."
        },
        "Correct Answer": "Lambda를 비동기 호출로 설정하고 Lambda 함수의 설정에서 DLQ를 구성하십시오.",
        "Explanation": "Lambda를 비동기 호출로 설정하면 함수가 응답을 기다리지 않고 이벤트를 처리할 수 있으며, 실패한 실행에 대한 재시도를 자동으로 처리하고 DLQ를 사용하여 실패한 이벤트를 캡처하고 나중에 처리할 수 있도록 보장합니다.",
        "Other Options": [
            "Lambda를 동기 호출로 구성하면 함수가 응답을 기다리게 되어 비동기 처리 요구 사항과 일치하지 않습니다.",
            "API Gateway를 사용하여 Lambda를 동기적으로 트리거하면 비동기 처리의 목적이 무색해지고 필요한 재시도 및 DLQ 기능을 제공하지 못할 수 있습니다.",
            "EventBridge를 사용하여 Lambda를 트리거할 수 있지만, Lambda 설정에서 직접 구성하는 것만큼 DLQ 지원 수준이 높지 않아 이 요구 사항에 덜 적합합니다."
        ]
    },
    {
        "Question Number": "18",
        "Situation": "개발자는 애플리케이션에 중요한 AWS Lambda 함수를 배포하는 과정에 있습니다. 이 함수는 작동에 필수적인 여러 서드파티 라이브러리에 의존하고 있습니다. 그러나 개발자는 AWS Lambda의 배포 패키지 크기에 제한이 있다는 것을 알고 있으며, 이 패키지의 크기를 최소화하여 함수를 최적화하고자 합니다. 또한, 이러한 의존성의 관리를 효율적이고 유지 관리 가능하게 하여 향후 업데이트 및 변경을 지원하고자 합니다.",
        "Question": "이러한 요구 사항을 고려할 때, 개발자가 AWS Lambda 함수의 배포를 최적화하면서 의존하는 서드파티 라이브러리를 효과적으로 관리하기 위해 따라야 할 모범 사례는 무엇입니까?",
        "Options": {
            "1": "모든 서드파티 의존성을 Lambda 배포 패키지 내에 패키징하여 함수가 올바르게 실행되도록 모든 것을 포함하십시오.",
            "2": "Lambda Layers를 활용하여 서드파티 라이브러리를 별도로 패키징하고, 효율적인 관리를 위해 함수 구성에서 이를 참조할 수 있도록 하십시오.",
            "3": "서드파티 라이브러리를 Amazon S3 버킷에 저장하고 실행 시 필요에 따라 다운로드 메커니즘을 구현하십시오.",
            "4": "서드파티 라이브러리 코드를 CloudFormation 템플릿에 직접 포함시켜 배포를 간소화하고 외부 의존성을 피하십시오."
        },
        "Correct Answer": "Lambda Layers를 활용하여 서드파티 라이브러리를 별도로 패키징하고, 효율적인 관리를 위해 함수 구성에서 이를 참조할 수 있도록 하십시오.",
        "Explanation": "Lambda Layers를 사용하는 것은 함수 코드와 의존하는 라이브러리를 분리할 수 있게 해주기 때문에 모범 사례로 간주됩니다. 이 접근 방식은 배포 패키지의 크기를 줄이는 데 도움이 될 뿐만 아니라, 의존성을 독립적으로 관리하고 업데이트하기 쉽게 만들어 줍니다. 레이어는 버전 관리가 가능하고 여러 Lambda 함수 간에 공유될 수 있습니다.",
        "Other Options": [
            "모든 의존성을 Lambda 배포 패키지 내에 패키징하면 패키지 크기가 커져 AWS Lambda의 제한을 초과할 수 있으며, 라이브러리의 향후 업데이트를 복잡하게 만들 수 있습니다.",
            "서드파티 라이브러리를 Amazon S3 버킷에 저장하고 실행 시 다운로드하는 것은 추가적인 지연과 복잡성을 초래하여 Lambda 함수의 성능에 부정적인 영향을 미치고 의존성 관리가 복잡해질 수 있습니다.",
            "서드파티 라이브러리 코드를 CloudFormation 템플릿에 직접 포함하는 것은 비현실적이며, 이는 더 큰 템플릿을 초래하고 유지 관리가 어려워지며 라이브러리 업데이트를 별도로 관리하는 데 어려움을 초래할 수 있습니다."
        ]
    },
    {
        "Question Number": "19",
        "Situation": "개발자가 30GB가 넘는 DynamoDB 테이블을 스캔하고 있으며, 스캔 작업이 완료되는 데 너무 오랜 시간이 걸리는 것을 발견했습니다. 테이블의 프로비저닝된 읽기 처리량이 완전히 활용되지 않고 있습니다.",
        "Question": "개발자가 스캔 성능을 개선하기 위해 무엇을 해야 합니까?",
        "Options": {
            "1": "스캔 대신 쿼리 작업을 사용합니다.",
            "2": "스캔 작업의 페이지 크기를 줄입니다.",
            "3": "병렬 스캔 작업을 활성화합니다.",
            "4": "스캔 작업에 속도 제한을 적용합니다."
        },
        "Correct Answer": "병렬 스캔 작업을 활성화합니다.",
        "Explanation": "병렬 스캔 작업을 활성화하면 개발자가 스캔을 여러 세그먼트로 나누어 동시에 처리할 수 있습니다. 이는 사용 가능한 읽기 처리량을 보다 효과적으로 활용하여 대형 테이블의 스캔 작업 전반의 성능을 개선합니다.",
        "Other Options": [
            "스캔 대신 쿼리 작업을 사용하는 것은 적용되지 않습니다. 쿼리는 알려진 키를 기반으로 특정 항목을 찾는 데 사용되며, 개발자는 테이블의 전체 스캔을 수행하고 있습니다.",
            "스캔 작업의 페이지 크기를 줄이면 각 요청에서 검색되는 데이터 양이 줄어들 수 있지만, 스캔의 성능이나 프로비저닝된 처리량의 활용도를 근본적으로 개선하지는 않습니다.",
            "스캔 작업에 속도 제한을 적용하면 스캔 프로세스가 더욱 느려질 가능성이 높습니다. 이는 테이블에서 데이터를 읽을 수 있는 속도를 제한하므로 스캔 성능을 개선하려는 목표와 반대됩니다."
        ]
    },
    {
        "Question Number": "20",
        "Situation": "중간 규모의 기술 회사가 현재 온프레미스 인프라와 클라우드 서비스를 결합한 하이브리드 클라우드 환경에서 운영되고 있습니다. 회사가 성장함에 따라 운영 작업을 효율적으로 관리하는 데 점점 더 많은 어려움에 직면하고 있습니다. 프로세스를 간소화하기 위해 회사는 다양한 운영 작업을 자동화할 수 있는 중앙 집중식 서비스를 찾고 있습니다. 구체적으로, 인스턴스 구성 관리, 패치 관리 자동화 및 민감한 매개변수 데이터를 안전하게 저장할 수 있는 강력한 기능을 제공하는 솔루션이 필요합니다.",
        "Question": "하이브리드 클라우드 환경 내에서 운영 작업을 효과적으로 자동화할 수 있는 중앙 집중식 서비스에 대한 회사의 요구 사항을 고려할 때, 이러한 요구를 충족하기 위한 가장 적합한 AWS 서비스는 무엇입니까?",
        "Options": {
            "1": "AWS Config는 주로 구성 변경 및 준수를 추적하는 데 중점을 두며 운영 작업 자동화에는 적합하지 않습니다.",
            "2": "AWS Systems Manager는 운영 작업을 자동화하고 인스턴스 구성을 관리하며 매개변수 데이터를 안전하게 저장하도록 설계된 종합 서비스입니다.",
            "3": "AWS CloudFormation은 코드로서의 인프라에 맞춰 자원을 배포하는 데 도움을 주지만 운영 작업 자동화에는 중점을 두지 않습니다.",
            "4": "AWS Service Catalog는 조직이 IT 서비스 카탈로그를 생성하고 관리하는 데 도움을 주지만 운영 작업을 직접 자동화하지는 않습니다."
        },
        "Correct Answer": "AWS Systems Manager는 운영 작업을 자동화하고 인스턴스 구성을 관리하며 매개변수 데이터를 안전하게 저장하도록 설계된 종합 서비스입니다.",
        "Explanation": "AWS Systems Manager는 클라우드와 온프레미스 환경 모두에서 운영 작업을 자동화하도록 특별히 설계된 이상적인 솔루션입니다. 인스턴스 구성 관리, 자동 패치 관리 및 매개변수 데이터를 안전하게 저장하고 접근할 수 있는 기능을 제공하여 회사의 하이브리드 클라우드 요구 사항에 잘 맞습니다.",
        "Other Options": [
            "AWS Config는 주로 구성 준수 모니터링 및 감사에 중점을 두므로 운영 작업 자동화에는 적합하지 않아 회사의 요구를 충족하지 않습니다.",
            "AWS CloudFormation은 사용자가 AWS 인프라를 정의하고 프로비저닝할 수 있도록 하는 코드로서의 인프라 서비스입니다. 그러나 운영 작업 자동화나 인스턴스 구성 관리 기능을 제공하지 않아 회사의 요구 사항에 적합하지 않습니다.",
            "AWS Service Catalog는 조직이 IT 서비스 카탈로그를 생성하고 관리할 수 있도록 하지만 운영 작업 자동화나 인스턴스 구성 관리 기능을 제공하지 않아 회사의 특정 요구를 충족하지 못합니다."
        ]
    },
    {
        "Question Number": "21",
        "Situation": "회사가 사용자 인증 및 프로필 관리를 처리하는 RESTful 웹 서비스를 설계하고 있습니다. 개발 팀은 서비스가 서버에서 사용자 세션 정보를 유지해야 할지, 아니면 각 요청을 독립적으로 처리하여 확장성을 개선해야 할지를 결정해야 합니다.",
        "Question": "이 맥락에서 상태 저장 설계와 무상태 설계를 가장 잘 구분하는 접근 방식은 무엇입니까?",
        "Options": {
            "1": "각 요청 간 상태를 유지하는 고유 세션 ID가 있는 서버 측 세션 저장소를 구현합니다.",
            "2": "JWT와 같은 토큰을 사용하여 각 요청 내에서 세션 정보를 인코딩하여 무상태 상호작용을 허용합니다.",
            "3": "각 사용자 세션에 대해 지속적인 데이터베이스 연결을 유지하여 서버 측 상태 관리를 요구합니다.",
            "4": "더 빠른 접근을 위해 세션 데이터를 인메모리 캐시에 저장하지만 여전히 상태 저장을 의미할 수 있습니다."
        },
        "Correct Answer": "JWT와 같은 토큰을 사용하여 각 요청 내에서 세션 정보를 인코딩하여 무상태 상호작용을 허용합니다.",
        "Explanation": "이 접근 방식은 요청 간에 서버가 세션 정보를 유지할 필요가 없기 때문에 무상태 설계를 예시합니다. 각 요청은 토큰 내에 필요한 모든 데이터를 포함하고 있어 서버 측 상태 관리 없이 독립적으로 처리할 수 있습니다.",
        "Other Options": [
            "이 옵션은 서버 측에 세션 정보를 저장해야 하므로 상태 저장 설계를 의미합니다. 즉, 서버는 각 사용자 세션의 상태를 요청 간에 기억해야 합니다.",
            "이 옵션은 지속적인 데이터베이스 연결이 서버가 사용자 세션에 대한 정보를 유지해야 함을 나타내므로 상태 저장 설계를 의미합니다.",
            "이 옵션은 세션 데이터를 인메모리 캐시에 저장하는 것이 서버가 사용자 세션을 추적하고 있음을 의미하므로 무상태 원칙에 반하는 상태 저장 설계를 제안합니다."
        ]
    },
    {
        "Question Number": "22",
        "Situation": "개발자가 Amazon SQS를 사용하여 메시지를 처리하고 있습니다. 가끔 처리 중인 메시지가 예상보다 오래 걸려, 처리가 완료되기 전에 다른 소비자에게 메시지가 다시 보이게 됩니다.",
        "Question": "이 문제를 방지하기 위해 개발자는 무엇을 해야 합니까?",
        "Options": {
            "1": "메시지 중복 제거를 사용하여 중복을 피합니다.",
            "2": "큐의 가시성 타임아웃을 더 길게 설정합니다.",
            "3": "SQS FIFO 큐를 사용하여 순서 보존을 보장합니다.",
            "4": "비용 절감을 위해 롱 폴링을 활성화합니다."
        },
        "Correct Answer": "큐의 가시성 타임아웃을 더 길게 설정합니다.",
        "Explanation": "큐의 가시성 타임아웃을 더 길게 설정하면 메시지가 처리되는 동안 다른 소비자에게 보이지 않게 유지됩니다. 이는 현재 소비자가 작업을 완료하기 전에 메시지가 재처리되는 문제를 방지하여 중복 처리가 발생할 가능성을 줄입니다.",
        "Other Options": [
            "메시지 중복 제거를 사용하면 동일한 메시지를 여러 번 처리하는 것을 피하는 데 도움이 되지만, 처리 중 메시지가 너무 빨리 보이는 문제를 해결하지는 않습니다.",
            "SQS FIFO 큐를 사용하면 메시지가 전송된 순서대로 처리되지만, 메시지 처리 기간에 중요한 가시성 타임아웃 문제를 해결하지는 않습니다.",
            "롱 폴링을 활성화하면 API 요청과 관련된 비용을 줄이는 데 도움이 될 수 있지만, 처리 중 메시지가 다른 소비자에게 너무 일찍 보이는 문제를 해결하지는 않습니다."
        ]
    },
    {
        "Question Number": "23",
        "Situation": "개발자가 Amazon ECS에서 컨테이너화된 애플리케이션을 배포하고 있으며, 제약 조건을 충족하면서 사용되는 컨테이너 인스턴스 수를 최소화하여 자원 활용도를 최적화하고 싶어합니다.",
        "Question": "자원 활용도를 최적화하기 위해 개발자가 어떤 작업 배치 전략을 사용해야 합니까?",
        "Options": {
            "1": "무작위",
            "2": "분산",
            "3": "빈팩",
            "4": "라운드 로빈"
        },
        "Correct Answer": "빈팩",
        "Explanation": "빈팩 배치 전략은 사용 가능한 CPU 또는 메모리가 가장 적은 컨테이너 인스턴스에 작업을 배치하여 인스턴스를 채운 후 다른 인스턴스로 이동함으로써 자원 활용도를 극대화하는 데 도움을 줍니다. 이는 제약 조건을 충족하면서 사용되는 컨테이너 인스턴스 수를 최소화하는 데 이상적입니다.",
        "Other Options": [
            "무작위는 자원 활용도를 고려하지 않으며, 작업이 사용 가능한 자원에 관계없이 분산될 수 있어 인스턴스의 비효율적인 사용으로 이어질 수 있습니다.",
            "분산은 사용 가능한 인스턴스에 작업을 고르게 분배하지만, 인스턴스의 용량이 다를 경우 자원 활용도가 저조해질 수 있습니다.",
            "라운드 로빈은 작업 배치를 위해 사용 가능한 인스턴스를 순환하지만, 자원 사용이 고르지 않게 되고 최소 인스턴스 최적화에 집중하지 않습니다."
        ]
    },
    {
        "Question Number": "24",
        "Situation": "개발자가 AWS SAM을 사용하여 서버리스 애플리케이션을 구축을 완료했습니다. 이제 애플리케이션을 패키징하고 AWS에 배포하고자 합니다.",
        "Question": "개발자가 애플리케이션을 배포하기 위해 어떤 AWS SAM 명령을 사용해야 합니까?",
        "Options": {
            "1": "sam build",
            "2": "sam deploy",
            "3": "sam package",
            "4": "sam transform"
        },
        "Correct Answer": "sam deploy",
        "Explanation": "'sam deploy' 명령은 AWS SAM 템플릿에 정의된 서버리스 애플리케이션을 배포하기 위해 특별히 설계되었습니다. 이 명령은 AWS 서비스에 애플리케이션을 배포하는 과정을 처리하며, 필요에 따라 리소스를 생성하거나 업데이트합니다.",
        "Other Options": [
            "'sam build'는 애플리케이션을 빌드하고 배포를 준비하는 데 사용되지만, 실제로는 아무것도 배포하지 않습니다.",
            "'sam package'는 애플리케이션에서 배포 패키지를 생성하는데, 이는 배포 전에 필요한 단계이지만 실제 배포를 수행하지는 않습니다.",
            "'sam transform'은 AWS SAM의 맥락에서 유효한 명령이 아니며, 템플릿의 변환은 패키징 또는 배포 과정 중에 발생합니다."
        ]
    },
    {
        "Question Number": "25",
        "Situation": "개발 팀은 AWS Lambda 함수에 대한 API Gateway 요청을 시뮬레이션하기 위해 JSON 형식으로 애플리케이션 테스트 이벤트를 생성해야 합니다. 이러한 JSON 테스트 페이로드는 실제 API 호출과 유사해야 하며, 정확한 테스트 결과를 보장하고 원활한 통합 테스트를 촉진해야 합니다.",
        "Question": "개발자가 이러한 JSON 테스트 페이로드를 효율적으로 생성하고 관리하기 위해 어떤 AWS 도구를 사용해야 합니까?",
        "Options": {
            "1": "AWS CloudFormation Designer는 주로 코드로서의 인프라 관리를 위해 사용되지만, 테스트 페이로드에 중점을 두지 않습니다.",
            "2": "AWS Lambda Console의 테스트 기능은 개발자가 Lambda 함수에 특정한 테스트 이벤트를 생성하고 API Gateway 요청을 시뮬레이션할 수 있게 해줍니다.",
            "3": "Amazon API Gateway Console의 메소드 테스트는 사용자 정의 요청 페이로드로 API 메소드를 직접 테스트하여 API 동작을 검증할 수 있게 해줍니다.",
            "4": "AWS Step Functions는 여러 AWS 서비스를 서버리스 워크플로우로 조정하지만, 테스트 페이로드를 생성하기 위해 특별히 설계되지 않았습니다."
        },
        "Correct Answer": "AWS Lambda Console의 테스트 기능은 개발자가 Lambda 함수에 특정한 테스트 이벤트를 생성하고 API Gateway 요청을 시뮬레이션할 수 있게 해줍니다.",
        "Explanation": "AWS Lambda Console의 테스트 기능은 Lambda 함수에 대한 다양한 시나리오를 시뮬레이션할 수 있는 테스트 이벤트를 생성하고 관리하기 위해 특별히 설계되었습니다. 개발자는 API Gateway 요청의 구조를 밀접하게 모방하는 JSON 페이로드를 입력할 수 있어, 통합 테스트를 효과적으로 수행하는 데 가장 적합한 선택입니다.",
        "Other Options": [
            "AWS CloudFormation Designer는 클라우드 리소스를 템플릿을 통해 생성하고 관리하는 데 중점을 두기 때문에 JSON 페이로드 테스트 기능을 제공하지 않으므로 잘못된 선택입니다.",
            "Amazon API Gateway Console의 메소드 테스트는 API 메소드를 테스트할 수 있지만, Lambda Console과 같은 방식으로 Lambda 테스트를 위한 JSON 페이로드를 생성하고 관리하는 데 특별히 맞춰져 있지 않기 때문에 잘못된 선택입니다.",
            "AWS Step Functions는 AWS 서비스 간의 복잡한 워크플로우를 조정하기 위해 설계되었으며, API Gateway 요청을 위한 JSON 테스트 페이로드를 생성하는 도구를 제공하지 않기 때문에 잘못된 선택입니다."
        ]
    },
    {
        "Question Number": "26",
        "Situation": "개발자는 Elastic Beanstalk에서 주기적인 백그라운드 작업을 처리하기 위해 작업자 애플리케이션을 배포하고 있습니다. 이 작업자 애플리케이션은 지정된 간격으로 실행해야 하는 작업을 처리하도록 설계되어 효율성과 적시 데이터 처리를 보장합니다. 이러한 동작을 촉진하기 위해 개발자는 특정 구성 파일이 배포에서 어떤 역할을 하는지 이해해야 합니다.",
        "Question": "이 설정에서 cron.yaml 파일의 주요 목적은 무엇이며, 특히 작업자 애플리케이션의 작업 예약과 관련하여 어떤 역할을 합니까?",
        "Options": {
            "1": "작동에 필요한 애플리케이션 환경 변수를 정의합니다.",
            "2": "작업자 애플리케이션이 실행해야 하는 주기적인 백그라운드 작업을 지정합니다.",
            "3": "배포 환경 설정을 관리하는 구성 규칙을 포함합니다.",
            "4": "자동 확장 그룹의 인스턴스 수를 조정하여 확장 매개변수를 관리합니다."
        },
        "Correct Answer": "작업자 애플리케이션이 실행해야 하는 주기적인 백그라운드 작업을 지정합니다.",
        "Explanation": "cron.yaml 파일은 작업자 애플리케이션에서 예약된 작업을 정의하기 위해 특별히 설계되었습니다. 개발자는 특정 시간이나 간격에 실행해야 하는 작업을 지정할 수 있어, 애플리케이션이 수동 개입 없이 자동으로 보고서 생성과 같은 작업을 처리할 수 있게 합니다.",
        "Other Options": [
            "이 옵션은 환경 변수가 애플리케이션 구성에 중요하지만 cron.yaml 파일 내에서 정의되지 않기 때문에 잘못된 선택입니다. 이 파일은 작업 예약에 중점을 두고 있습니다.",
            "이 옵션은 구성 규칙의 더 넓은 범위를 제안하므로 잘못된 선택입니다. cron.yaml 파일은 작업 예약에 관한 것이며 일반 환경 설정을 포함하지 않습니다.",
            "이 옵션은 자동 확장 그룹의 인스턴스 수 관리는 Elastic Beanstalk 구성 및 확장 정책에 의해 처리되므로 잘못된 선택입니다."
        ]
    },
    {
        "Question Number": "27",
        "Situation": "개발자는 명령줄 인터페이스(CLI)에서 명령을 실행하려고 할 때 어려운 문제에 직면하고 있습니다. 최선을 다했지만 오류 메시지가 나타나 진행을 방해하고 있습니다. 문제를 효과적으로 해결하기 위해 개발자는 명령 실행 과정에서 무엇이 잘못되고 있는지에 대한 통찰력을 제공할 수 있는 더 복잡한 디버깅 정보를 얻고자 합니다. 출력 세부 정보를 향상시키기 위한 여러 옵션이 있는 가운데, 개발자는 사용할 가장 적절한 CLI 옵션을 결정해야 합니다.",
        "Question": "개발자가 직면한 오류를 해결하는 데 도움이 되는 포괄적인 디버깅 정보를 받기 위해 어떤 CLI 옵션을 사용해야 합니까?",
        "Options": {
            "1": "--verbose",
            "2": "--debug",
            "3": "--dry-run",
            "4": "--trace"
        },
        "Correct Answer": "--debug",
        "Explanation": "--debug 옵션은 CLI 명령을 실행할 때 자세한 디버깅 정보를 제공하도록 특별히 설계되었습니다. 이 수준의 출력은 개발자에게 매우 중요하며, 명령 실행 중에 발생하는 오류를 해결하는 데 도움이 되는 기본 문제, 변수 상태 및 기타 중요한 정보를 드러낼 수 있습니다.",
        "Other Options": [
            "--verbose는 일반 출력보다 더 많은 정보를 제공하지만 --debug가 제공하는 세부 수준에는 미치지 못할 수 있습니다. 철저한 디버깅에는 충분하지 않을 수 있습니다.",
            "--dry-run은 실제로 실행하지 않고 어떤 작업이 수행될지를 볼 수 있는 시뮬레이션 옵션입니다. 이 옵션은 오류와 관련된 디버깅 정보를 제공하지 않습니다.",
            "--trace는 실행 흐름을 보여주고 디버깅에 사용될 수 있지만, 종종 --debug가 제공하는 상세 상태 정보보다는 작업의 순서에 중점을 둡니다."
        ]
    },
    {
        "Question Number": "28",
        "Situation": "한 회사가 AWS Lambda, Amazon SQS, Amazon DynamoDB와 같은 AWS 서비스의 기능을 활용하여 고가용성 및 내결함성이 뛰어난 서버리스 애플리케이션을 개발하는 과정에 있습니다. 이 애플리케이션의 주요 목표는 SQS 큐에서 들어오는 메시지를 효율적으로 처리하고 결과를 DynamoDB 테이블에 저장하는 것입니다. 그러나 설계의 중요한 요구 사항은 Lambda 함수가 메시지를 처리하지 못하는 경우를 적절히 처리하여 중요한 데이터 손실을 방지하는 것입니다.",
        "Question": "메시지 처리의 복원력과 신뢰성 필요성을 고려할 때, 실행 중에 처리되지 않은 메시지가 손실되지 않도록 보장하기 위해 회사가 구현해야 할 내결함성 설계 패턴은 무엇입니까?",
        "Options": {
            "1": "실패한 메시지를 저장하기 위해 데드레터 큐(DLQ)를 사용하고 Lambda가 메시지 처리를 재시도하도록 구성합니다.",
            "2": "실패한 메시지를 저장하기 위해 백업 DynamoDB 테이블을 사용하고 수동으로 처리를 재시도합니다.",
            "3": "Lambda 함수의 타임아웃을 최대 허용 기간으로 설정하고 모든 오류를 Lambda 함수 내에서 처리합니다.",
            "4": "모든 실패한 메시지 재시도에 대해 지터가 있는 지수 백오프를 사용하고 타임아웃 내에 처리할 수 없는 메시지는 폐기합니다."
        },
        "Correct Answer": "실패한 메시지를 저장하기 위해 데드레터 큐(DLQ)를 사용하고 Lambda가 메시지 처리를 재시도하도록 구성합니다.",
        "Explanation": "데드레터 큐(DLQ)를 구현하면 Lambda 함수가 처리하지 못한 메시지를 나중에 분석하고 재처리할 수 있도록 지정된 큐로 리디렉션할 수 있습니다. 이 설계 패턴은 메시지가 손실되지 않도록 보장하며, 수동 개입 없이도 메시지를 검사하고 재시도할 수 있어 메시지 처리 실패에 대한 강력한 솔루션을 제공합니다.",
        "Other Options": [
            "실패한 메시지에 대해 백업 DynamoDB 테이블을 사용하는 것은 자동 재시도의 직접적인 메커니즘을 제공하지 않으므로, 수동 개입이 지속적으로 이루어지지 않는 한 메시지 손실 위험이 증가합니다.",
            "Lambda 함수의 타임아웃을 최대 기간으로 설정하는 것은 메시지 손실 문제를 본질적으로 해결하지 않으며, 오류가 발생할 경우 여전히 처리되지 않은 메시지가 발생할 수 있고, 내부에서 오류를 처리하는 것은 메시지 손실을 방지하지 않습니다.",
            "재시도를 위한 지터가 있는 지수 백오프를 활용하는 것은 재시도를 관리하는 좋은 전략이지만, 처리할 수 없는 메시지를 폐기하는 것은 중요한 데이터 손실 위험이 있으며, 이는 내결함성을 보장하는 목표와 모순됩니다."
        ]
    },
    {
        "Question Number": "29",
        "Situation": "한 회사가 Amazon S3를 통한 저장, Amazon SNS를 통한 알림, Amazon Kinesis를 통한 실시간 데이터 스트리밍 등 다양한 출처에서 발생하는 이벤트를 효과적으로 처리하기 위해 AWS Lambda 함수를 활용한 이벤트 기반 아키텍처를 구축하고 있습니다. 아키텍처는 각 Lambda 함수가 들어오는 이벤트의 양에 따라 독립적으로 확장할 수 있도록 설계되어야 하며, 이는 효율적인 자원 활용과 수요 변동에 대한 반응성을 보장합니다.",
        "Question": "이 이벤트 기반 아키텍처를 설계하는 맥락에서, 각 Lambda 함수가 처리하는 들어오는 이벤트의 양에 따라 독립적으로 확장할 수 있도록 가장 유익한 특성은 무엇입니까?",
        "Options": {
            "1": "구성 요소 간의 긴밀한 결합은 모든 함수가 동시에 확장되고 완벽하게 동기화되도록 보장합니다.",
            "2": "중앙 집중식 오케스트레이션은 모든 Lambda 함수의 확장을 단일 단위로 관리하여 전반적으로 균일한 성능을 유지합니다.",
            "3": "느슨한 결합은 각 Lambda 함수가 개별 이벤트 부하에 따라 독립적으로 확장할 수 있도록 하여 유연성과 반응성을 향상시킵니다.",
            "4": "상태 유지 통신은 확장 중 일관된 성능을 유지하여 함수가 진행 중인 프로세스를 잃지 않도록 합니다."
        },
        "Correct Answer": "느슨한 결합은 각 Lambda 함수가 개별 이벤트 부하에 따라 독립적으로 확장할 수 있도록 하여 유연성과 반응성을 향상시킵니다.",
        "Explanation": "느슨한 결합은 이벤트 기반 아키텍처의 기본적인 측면으로, 각 구성 요소, 즉 각 Lambda 함수가 독립적으로 작동할 수 있도록 합니다. 이는 각 함수가 자신의 특정 작업량과 성능 요구 사항에 따라 확장할 수 있음을 의미하며, 다양한 이벤트 양에 대한 반응에서 더 큰 유연성과 효율성을 제공합니다.",
        "Other Options": [
            "구성 요소 간의 긴밀한 결합은 실제로 독립적인 확장을 방해하며, 모든 구성 요소가 동기화되어 함께 확장해야 하므로 다양한 이벤트 부하를 처리하는 데 필요한 유연성과 모순됩니다.",
            "중앙 집중식 오케스트레이션은 모든 Lambda 함수가 단일 엔티티로 관리된다는 것을 의미하며, 이는 다양한 출처에서 오는 서로 다른 이벤트 양을 효율적으로 처리하는 데 필요한 독립적인 확장을 허용하지 않습니다.",
            "상태 유지 통신은 일반적으로 이벤트 기반 아키텍처의 특성이 아니며, 이들은 무상태 상호작용을 선호합니다. 상태를 유지하는 것은 확장 중 복잡성과 성능 제한을 초래할 수 있으므로 독립적인 확장에 기여하지 않습니다."
        ]
    },
    {
        "Question Number": "30",
        "Situation": "한 회사가 사용자 수요에 따라 동적으로 확장할 수 있는 고트래픽 부하를 효과적으로 관리할 것으로 예상되는 새로운 애플리케이션을 AWS에서 설계하는 야심찬 프로젝트를 시작하고 있습니다. 이 애플리케이션은 서로 원활하게 통신하고 작동해야 하는 여러 독립 서비스로 구성됩니다. 계획 과정의 일환으로, 회사는 마이크로서비스 아키텍처를 채택하는 것과 전통적인 모놀리식 아키텍처를 유지하는 것의 장단점을 비교하고 있습니다. 각 접근 방식의 의미를 이해하는 것은 애플리케이션의 성공에 매우 중요합니다.",
        "Question": "고트래픽 관리 및 동적 확장 요구 사항을 고려할 때, 이 특정 사용 사례에 대해 모놀리식 아키텍처와 비교하여 마이크로서비스 아키텍처를 활용하는 주요 장점은 무엇입니까?",
        "Options": {
            "1": "마이크로서비스는 더 나은 결함 격리를 제공하고 개별 구성 요소의 독립적인 확장을 용이하게 합니다.",
            "2": "모놀리식 애플리케이션은 이동 부품이 적어 개발, 배포 및 유지 관리가 더 쉽습니다.",
            "3": "마이크로서비스는 모든 서비스가 동일한 데이터베이스를 공유할 수 있도록 하여 복잡성을 줄입니다.",
            "4": "모놀리식 아키텍처는 추가 구성 없이 트래픽 증가에 따라 자동으로 확장됩니다."
        },
        "Correct Answer": "마이크로서비스는 더 나은 결함 격리를 제공하고 개별 구성 요소의 독립적인 확장을 용이하게 합니다.",
        "Explanation": "마이크로서비스 아키텍처를 사용하는 주요 장점은 더 나은 결함 격리를 허용한다는 것입니다. 즉, 하나의 서비스가 실패하더라도 전체 애플리케이션이 중단되지 않습니다. 또한, 마이크로서비스는 수요에 따라 독립적으로 확장할 수 있어 고트래픽 부하를 효율적으로 처리하는 데 중요합니다. 이러한 유연성은 모놀리식 아키텍처보다 사용자 수요의 변동에 더 효과적으로 반응할 수 있게 합니다.",
        "Other Options": [
            "이 옵션은 잘못된 것입니다. 모놀리식 애플리케이션은 구성 요소가 적을 수 있지만, 성장함에 따라 유지 관리 및 확장이 어려워져 고트래픽 시나리오에 덜 적합해질 수 있습니다.",
            "이 옵션은 오해의 소지가 있습니다. 마이크로서비스 간에 단일 데이터베이스를 공유하는 것은 실제로 복잡성과 결합을 초래할 수 있으며, 이는 마이크로서비스 아키텍처의 원칙과 모순됩니다.",
            "이 옵션은 잘못된 것입니다. 모놀리식 아키텍처는 자동으로 확장되지 않으며, 일반적으로 증가하는 트래픽을 처리하기 위해 수동 개입이나 구성이 필요합니다. 이는 동적 확장의 목적을 무색하게 합니다."
        ]
    },
    {
        "Question Number": "31",
        "Situation": "한 회사는 미국 동부(N. Virginia) 지역에 위치한 Amazon S3 버킷에서 아시아 태평양(Mumbai) 지역에 있는 다른 버킷으로 데이터를 복제해야 하는 중요한 임무를 맡고 있습니다. 이 데이터 복제는 규정 준수 요구 사항에 의해 의무화되며, 이 복제 과정에는 새로운 객체만 포함되어야 합니다. 또한, 복제된 모든 데이터가 버전 관리를 유지하여 객체의 생애 주기 동안 변경 사항과 업데이트를 추적할 수 있도록 하는 것이 중요합니다.",
        "Question": "규정 준수와 버전 관리를 보장하면서 이러한 중요한 데이터 복제 요구 사항을 효과적으로 충족하기 위해 필요한 구체적인 구성 단계는 무엇입니까?",
        "Options": {
            "1": "소스 버킷에서만 버전 관리를 활성화하고, 교차 지역 복제가 이루어질 수 있도록 필요한 권한으로 S3 복제를 구성합니다.",
            "2": "소스 및 대상 버킷 모두에서 버전 관리를 활성화하고, 데이터 무결성과 규정 준수를 보장하기 위해 필요한 권한으로 교차 지역 복제를 설정합니다.",
            "3": "소스 버킷의 각 객체에 대해 사전 서명된 URL을 생성한 다음, 이러한 URL을 대상 버킷에 수동으로 업로드하는데, 이는 복제에 비효율적인 방법입니다.",
            "4": "S3 Select를 사용하여 새로운 객체를 필터링하고 이를 수동으로 대상 버킷에 복제하는데, 이는 복잡성과 오류 가능성을 초래합니다."
        },
        "Correct Answer": "소스 및 대상 버킷 모두에서 버전 관리를 활성화하고, 데이터 무결성과 규정 준수를 보장하기 위해 필요한 권한으로 교차 지역 복제를 설정합니다.",
        "Explanation": "새로운 객체만 복제하면서 모든 복제된 데이터가 버전 관리되도록 요구 사항을 충족하기 위해서는 소스 및 대상 버킷 모두에서 버전 관리를 활성화해야 합니다. 이는 S3 서비스가 객체가 지역 간에 복제될 때 버전을 추적할 수 있도록 합니다. 또한, 필요한 권한으로 교차 지역 복제를 구성하면 복제 과정이 원활하고 안전하게 이루어질 수 있어 규정 준수 요구 사항을 충족할 수 있습니다.",
        "Other Options": [
            "소스 버킷에서만 버전 관리를 활성화하는 것은 불충분합니다. 대상 버킷에서도 버전 관리를 활성화해야 복제된 데이터의 무결성과 추적을 유지할 수 있습니다.",
            "각 객체에 대해 사전 서명된 URL을 생성하는 것은 복제에 적합한 방법이 아니며, 새로운 객체의 자동 복제 요구 사항을 충족하지 못하고 필요한 버전 관리가 부족합니다.",
            "S3 Select를 사용하여 새로운 객체를 필터링하는 것은 그럴듯한 접근법처럼 보일 수 있지만, 수동으로 복제하는 것은 불필요한 복잡성과 오류 가능성을 초래하여 자동화된 규정 준수 요구 사항에 대한 비현실적인 솔루션이 됩니다."
        ]
    },
    {
        "Question Number": "32",
        "Situation": "개발자가 AWS CodePipeline을 사용하여 웹 애플리케이션을 배포하기 위한 CI/CD 파이프라인을 설정하고 있습니다. 그들은 데이터베이스 엔드포인트 및 API 키와 같은 환경별 구성이 안전하게 관리되도록 해야 합니다. 이러한 구성은 배포 중 중단을 방지하고 보안 모범 사례를 유지하기 위해 애플리케이션 코드와 독립적으로 업데이트할 수 있어야 합니다.",
        "Question": "개발자가 CI/CD 파이프라인에서 보안과 유연성을 모두 보장하면서 이러한 환경별 구성을 효과적으로 관리하기 위해 어떤 관행을 채택해야 합니까?",
        "Options": {
            "1": "구성을 애플리케이션 코드에 하드코딩하고 각 환경에 대해 별도의 브랜치를 사용합니다.",
            "2": "AWS CodePipeline에서 환경 변수를 사용하고 AWS Secrets Manager 또는 Parameter Store에 민감한 데이터를 저장합니다.",
            "3": "구성을 애플리케이션 코드와 동일한 리포지토리에 포함시키고 Git 브랜치로 관리합니다.",
            "4": "구성을 Amazon S3에 저장하고 암호화 없이 애플리케이션 코드에서 직접 참조합니다."
        },
        "Correct Answer": "AWS CodePipeline에서 환경 변수를 사용하고 AWS Secrets Manager 또는 Parameter Store에 민감한 데이터를 저장합니다.",
        "Explanation": "AWS CodePipeline에서 환경 변수를 사용하면 환경별 구성을 안전하게 관리할 수 있습니다. 또한, 민감한 데이터에 대해 AWS Secrets Manager 또는 Parameter Store를 활용하면 API 키 및 데이터베이스 엔드포인트와 같은 중요한 정보가 안전하게 저장되고 애플리케이션 코드와 독립적으로 업데이트될 수 있어 보안 및 구성 관리의 모범 사례를 촉진합니다.",
        "Other Options": [
            "구성을 애플리케이션 코드에 하드코딩하는 것은 민감한 데이터를 코드베이스에 노출시키고 업데이트를 복잡하게 만들기 때문에 좋지 않은 관행입니다. 특히 여러 환경이 관련된 경우 더욱 그렇습니다.",
            "구성을 애플리케이션 코드와 동일한 리포지토리에 포함시키면 보안 취약점이 발생할 수 있으며, 민감한 정보를 관리하는 데 복잡성을 초래할 수 있습니다. 특히 리포지토리가 공개적으로 접근 가능할 경우 더욱 그렇습니다.",
            "Amazon S3에 구성을 암호화 없이 저장하는 것은 민감한 데이터에 대한 무단 접근을 허용하므로 심각한 보안 위험을 초래합니다. 애플리케이션 코드에서 직접 참조하는 것도 관리하기 어려운 설정으로 이어질 수 있습니다."
        ]
    },
    {
        "Question Number": "33",
        "Situation": "개발자가 SQS 큐에서 일부 메시지가 여러 소비자에 의해 여러 번 처리되고 있음을 발견했습니다.",
        "Question": "개발자는 메시지가 여러 번 처리되지 않도록 하기 위해 무엇을 해야 합니까?",
        "Options": {
            "1": "큐의 DelaySeconds 값을 증가시킵니다.",
            "2": "메시지의 VisibilityTimeout을 증가시킵니다.",
            "3": "큐에 대한 콘텐츠 기반 중복 제거를 활성화합니다.",
            "4": "처리되지 않은 메시지에 대해 Dead Letter Queue를 사용합니다."
        },
        "Correct Answer": "큐에 대한 콘텐츠 기반 중복 제거를 활성화합니다.",
        "Explanation": "콘텐츠 기반 중복 제거를 활성화하면 동일한 콘텐츠를 가진 메시지가 한 번만 처리되도록 하여 서로 다른 소비자에 의한 중복 처리를 효과적으로 방지합니다.",
        "Other Options": [
            "DelaySeconds 값을 증가시키는 것은 메시지 전달을 연기할 뿐이며 중복 문제를 직접적으로 해결하지는 않습니다.",
            "VisibilityTimeout을 증가시키면 메시지가 더 오랜 기간 숨겨질 수 있지만, 여러 소비자가 동일한 메시지를 다시 처리하는 것을 방지하지는 않습니다.",
            "Dead Letter Queue를 사용하는 것은 실패한 메시지를 처리하는 데 유용하지만, 처음부터 중복을 방지하지는 않습니다."
        ]
    },
    {
        "Question Number": "34",
        "Situation": "개발 팀이 AWS CodePipeline을 사용하여 여러 환경에 걸쳐 애플리케이션 배포를 자동화하는 CI/CD 파이프라인을 설정하고 있습니다. 또한 배포 전에 애플리케이션이 올바르게 작동하는지 확인하기 위해 단위 테스트와 통합 테스트를 자동화해야 합니다. 팀은 자동화된 테스트를 CI/CD 파이프라인에 직접 통합하는 솔루션을 구현해야 합니다.",
        "Question": "배포 과정에서 단위 테스트와 통합 테스트를 자동으로 트리거하기 위해 팀이 구성해야 하는 것은 무엇입니까?",
        "Options": {
            "1": "각 배포 단계에서 단위 테스트를 트리거하기 위해 사용자 지정 AWS Lambda 함수를 생성합니다.",
            "2": "AWS CodePipeline을 사용하여 단위 테스트를 위해 AWS CodeBuild를 호출하고 통합 테스트를 위해 AWS CodeDeploy를 사용합니다.",
            "3": "AWS CodeBuild를 AWS CloudFormation과 통합하여 테스트를 자동으로 실행하고 애플리케이션을 배포합니다.",
            "4": "배포 후 후크를 사용하여 애플리케이션이 배포된 후 테스트를 실행하도록 AWS CodePipeline을 구성합니다."
        },
        "Correct Answer": "AWS CodePipeline을 사용하여 단위 테스트를 위해 AWS CodeBuild를 호출하고 통합 테스트를 위해 AWS CodeDeploy를 사용합니다.",
        "Explanation": "AWS CodePipeline을 사용하여 단위 테스트를 위해 AWS CodeBuild를 호출하고 통합 테스트를 위해 AWS CodeDeploy를 사용하면 배포 파이프라인 내에서 테스트의 원활한 통합이 가능합니다. 이는 테스트가 적절한 단계에서 자동으로 실행되어 애플리케이션이 프로덕션에 도달하기 전에 무결성을 검증하므로 배포 프로세스의 전반적인 신뢰성을 향상시킵니다.",
        "Other Options": [
            "단위 테스트를 트리거하기 위해 사용자 지정 AWS Lambda 함수를 생성하는 것은 CI/CD 프로세스에 잘 통합되지 않으며, 더 복잡한 설정으로 이어질 수 있고 이 목적을 위해 설계된 AWS 서비스의 내장 기능을 활용하지 않습니다.",
            "AWS CodeBuild를 AWS CloudFormation과 통합하면 테스트를 실행할 수 있지만, CodePipeline 내에서 배포 프로세스의 일환으로 테스트 자동화 필요성을 직접적으로 해결하지 않으며, 이는 지속적인 통합에 필수적입니다.",
            "AWS CodePipeline을 구성하여 애플리케이션이 배포된 후 테스트를 실행하는 것은 일반적인 CI/CD 관행에 반하며, 테스트는 배포 전에 문제를 조기에 발견하기 위해 수행되어야 합니다."
        ]
    },
    {
        "Question Number": "35",
        "Situation": "개발자가 AWS Serverless Application Model (SAM)을 사용하여 AWS Lambda 함수를 배포하는 작업을 하고 있습니다. 이 배포는 함수의 새 버전을 프로덕션으로 전환하는 중요한 작업입니다. 개발자는 새 버전의 점진적인 도입을 허용하는 특정 배포 전략을 결정했습니다. 그들의 계획은 처음에 들어오는 트래픽의 10%를 새 버전으로 라우팅하고, 성능과 기능을 면밀히 모니터링한 후 모든 것이 올바르게 작동하고 새 버전이 안정적임을 확인한 후 나머지 90%의 트래픽을 전환하는 것입니다.",
        "Question": "이 접근 방식을 고려할 때, 개발자가 처음에 트래픽의 10%를 새 버전으로 유도하고 검증 후 90%를 전환하기 위해 선택해야 할 배포 선호 유형은 무엇입니까?",
        "Options": {
            "1": "Linear",
            "2": "All-at-once",
            "3": "Canary",
            "4": "Gradual"
        },
        "Correct Answer": "Canary",
        "Explanation": "Canary 배포 선호 유형은 애플리케이션의 새 버전으로 처음에 소량의 트래픽을 라우팅하는 시나리오를 위해 특별히 설계되었습니다. 트래픽의 10%를 새 AWS Lambda 함수로 유도함으로써 개발자는 성능을 모니터링한 후 나머지 90%로 전환할 수 있으며, 이는 개발자의 전략과 완벽하게 일치합니다.",
        "Other Options": [
            "Linear 배포는 시간이 지남에 따라 트래픽을 동일한 비율로 점진적으로 증가시키는 것을 포함하며, 개발자가 필요로 하는 초기 10%와 그 후의 더 큰 전환에는 정확히 맞지 않습니다.",
            "All-at-once 배포는 전체 트래픽이 동시에 새 버전으로 리디렉션되는 것을 의미하며, 이는 개발자가 원하는 신중한 접근 방식과 모순됩니다.",
            "Gradual 배포는 일반적으로 더 긴 기간에 걸쳐 트래픽의 느린 증가를 의미하며, 초기 10% 분할 후 90%로의 큰 점프와는 다르므로 이 특정 배포 전략에 덜 적합합니다."
        ]
    },
    {
        "Question Number": "36",
        "Situation": "개발자가 Amazon DynamoDB 테이블의 레코드를 처리하도록 특별히 설계된 AWS Lambda 함수를 구성하는 프로젝트에서 작업하고 있습니다. 이 함수는 데이터 변경에 신속하고 효율적으로 반응해야 하므로 아키텍처의 중요한 부분입니다. 최적의 반응성을 달성하고 Lambda 함수가 테이블에 새 레코드가 추가될 때 효과적으로 처리할 수 있도록 하려면, 개발자는 Lambda 함수와 이러한 변경 사항을 실시간으로 캡처하는 DynamoDB 스트림 간의 신뢰할 수 있는 연결을 설정해야 합니다.",
        "Question": "AWS Lambda 함수와 DynamoDB 스트림 간의 연결을 성공적으로 활성화하기 위해 개발자가 구현해야 할 구체적인 구성은 무엇입니까?",
        "Options": {
            "1": "새 데이터가 추가될 때마다 Lambda 함수를 트리거하기 위해 Amazon S3를 통한 이벤트 알림을 설정합니다.",
            "2": "DynamoDB 스트림을 Lambda 함수에 직접 연결하는 이벤트 소스 매핑을 생성하여 실시간 처리를 가능하게 합니다.",
            "3": "Amazon Simple Notification Service (SNS)를 활용하여 DynamoDB 스트림 이벤트를 게시하고 Lambda 함수가 이를 수신하도록 합니다.",
            "4": "Amazon API Gateway를 구성하여 DynamoDB 스트림 레코드를 Lambda 함수로 전달하는 중간 계층 역할을 하도록 합니다."
        },
        "Correct Answer": "DynamoDB 스트림을 Lambda 함수에 직접 연결하는 이벤트 소스 매핑을 생성하여 실시간 처리를 가능하게 합니다.",
        "Explanation": "이벤트 소스 매핑을 생성하는 것은 DynamoDB 스트림과 Lambda 함수 간의 직접적인 연결을 설정하여 스트림의 새 레코드에 반응하여 함수가 자동으로 트리거되도록 합니다. 이 설정은 Lambda 함수가 데이터가 사용 가능해질 때 실시간으로 처리할 수 있도록 보장하며, 이는 최적의 반응성을 위해 필수적입니다.",
        "Other Options": [
            "Amazon S3를 통한 이벤트 알림을 설정하는 것은 DynamoDB 스트림과 관련이 없으므로 잘못된 것입니다; S3 알림은 S3 버킷의 객체 이벤트에 사용되며 DynamoDB의 변경 사항을 캡처하는 데 사용되지 않습니다.",
            "Amazon Simple Notification Service (SNS)를 활용하는 것은 잘못된 것으로, 이는 DynamoDB 스트림과 직접 연결되지 않는 다른 메시징 메커니즘을 포함하며, 주로 pub/sub 메시징 패턴에 사용됩니다.",
            "Amazon API Gateway를 구성하여 DynamoDB 스트림 레코드를 전달하는 것은 잘못된 것입니다. API Gateway는 HTTP 요청을 처리하도록 설계되었으며, 실시간 처리를 위해 DynamoDB 스트림과 직접 통합하기 위한 것이 아닙니다."
        ]
    },
    {
        "Question Number": "37",
        "Situation": "개발자가 Amazon API Gateway에서 데이터를 처리하는 AWS Lambda 함수에 대한 단위 테스트를 작성하고 있습니다. 테스트 중 실제 API Gateway를 호출하지 않고 함수가 올바르게 작동하는지 확인하기 위해 개발자는 모의 엔드포인트를 사용하고자 합니다.",
        "Question": "개발자가 단위 테스트 중 API Gateway 상호작용을 시뮬레이션하기 위해 어떤 테스트 접근 방식을 사용해야 합니까?",
        "Options": {
            "1": "실제 API Gateway 엔드포인트를 사용한 통합 테스트",
            "2": "API Gateway를 위한 AWS SDK 스텁을 사용한 모의 테스트",
            "3": "API Gateway와 함께하는 성능 테스트",
            "4": "AWS CloudFormation을 사용한 엔드 투 엔드 테스트"
        },
        "Correct Answer": "API Gateway를 위한 AWS SDK 스텁을 사용한 모의 테스트",
        "Explanation": "API Gateway를 위한 AWS SDK 스텁을 사용한 모의 테스트는 개발자가 실제 호출 없이 API Gateway의 동작을 모방하는 시뮬레이션 환경을 만들 수 있게 해줍니다. 이는 테스트 중인 함수를 격리하고 외부 의존성을 피할 수 있기 때문에 단위 테스트에 이상적입니다.",
        "Other Options": [
            "실제 API Gateway 엔드포인트를 사용한 통합 테스트는 실제 서비스에 대한 호출을 포함하므로 단위 테스트에 적합하지 않으며, 이는 예측할 수 없는 결과와 느린 테스트를 초래할 수 있습니다.",
            "API Gateway와 함께하는 성능 테스트는 부하 하에서 API의 응답성과 안정성을 측정하는 데 중점을 두며, 특정 기능을 검증하는 것이 아니라 단위 테스트의 목표와는 다릅니다.",
            "AWS CloudFormation을 사용한 엔드 투 엔드 테스트는 전체 애플리케이션 스택과 배포를 검증하는 데 초점을 맞추며, 개별 함수에 대한 단위 테스트의 범위를 넘어섭니다."
        ]
    },
    {
        "Question Number": "38",
        "Situation": "개발자가 AWS CodeDeploy를 사용하여 Amazon ECS에서 애플리케이션의 새 버전을 배포하고 있습니다. 팀은 성능 지표와 사용자 피드백을 면밀히 모니터링하면서 새로운 버전으로 점진적으로 트래픽을 전환하고자 합니다.",
        "Question": "개발자가 점진적인 전환을 보장하고 위험을 최소화하기 위해 어떤 배포 전략을 선택해야 합니까?",
        "Options": {
            "1": "모두 한 번에, 이는 새 버전을 모든 인스턴스에 동시에 배포하는 것으로, 모든 사용자에게 영향을 미칠 수 있는 잠재적인 문제의 위험을 초래합니다.",
            "2": "선형, 여기서 트래픽은 설정된 기간 동안 동일한 비율로 전환되지만, 이 방법은 충분한 모니터링 기회를 제공하지 않을 수 있습니다.",
            "3": "카나리, 초기에는 소수의 사용자만 새 버전에 접근할 수 있도록 하여 성능을 모니터링하고 필요시 롤백할 수 있는 기능을 제공합니다.",
            "4": "블루/그린, 평행 환경으로의 완전한 전환을 가능하게 하지만 점진적인 트래픽 전환을 촉진하지는 않습니다."
        },
        "Correct Answer": "카나리, 초기에는 소수의 사용자만 새 버전에 접근할 수 있도록 하여 성능을 모니터링하고 필요시 롤백할 수 있는 기능을 제공합니다.",
        "Explanation": "카나리 배포 전략은 개발자가 새 버전을 소수의 사용자에게 먼저 배포할 수 있게 해주기 때문에 이 시나리오에 이상적입니다. 이 접근 방식은 팀이 성능을 모니터링하고 피드백을 수집한 후 전체 사용자 기반에 변경 사항을 배포할 수 있게 하여 위험을 최소화하고 보다 원활한 전환을 보장합니다.",
        "Other Options": [
            "모두 한 번에 배포하는 것은 새 버전을 모든 인스턴스에 동시에 배포하므로, 새 버전에서 버그가 발생할 경우 광범위한 문제의 위험을 증가시킵니다.",
            "선형 방식은 점진적인 트래픽 관리를 위해 덜 효과적입니다. 이는 시간이 지남에 따라 트래픽을 동일한 비율로 전환하지만, 전환 중 성능을 면밀히 모니터링할 수 있는 유연성을 제공하지 않습니다.",
            "블루/그린 배포는 두 환경 간에 트래픽을 완전히 전환하는 것을 포함하며, 점진적인 전환을 허용하지 않으며 문제가 발생할 경우 상당한 다운타임을 초래할 수 있습니다."
        ]
    },
    {
        "Question Number": "39",
        "Situation": "한 회사가 컨테이너화를 사용하여 레거시 애플리케이션을 AWS로 마이그레이션하고 있습니다. 이 애플리케이션은 각각 별도의 Docker 컨테이너로 패키징된 여러 마이크로서비스로 구성되어 있습니다. 개발 팀은 컨테이너 이미지가 성능을 최적화하고 애플리케이션의 리소스 요구 사항을 충족하는지 확인해야 합니다.",
        "Question": "팀이 AWS에 배포하기 위해 컨테이너 이미지를 준비하기 위해 어떤 조치를 취해야 합니까?",
        "Options": {
            "1": "모든 필수 종속성이 포함되도록 큰 기본 이미지를 사용합니다.",
            "2": "Dockerfile에서 CPU 및 메모리와 같은 특정 리소스 요구 사항을 정의하고 AWS Fargate가 배포 중에 이러한 리소스를 자동으로 관리하도록 합니다.",
            "3": "Dockerfile을 최적화하여 레이어 수를 줄이고 경량 기본 이미지를 선택하며, 사용되는 오케스트레이션 서비스에서 리소스 제한을 지정합니다.",
            "4": "컨테이너 이미지를 Amazon S3에 저장하고 애플리케이션 코드에서 직접 참조하여 쉽게 접근할 수 있도록 합니다."
        },
        "Correct Answer": "Dockerfile을 최적화하여 레이어 수를 줄이고 경량 기본 이미지를 선택하며, 사용되는 오케스트레이션 서비스에서 리소스 제한을 지정합니다.",
        "Explanation": "Dockerfile을 최적화하여 레이어 수를 최소화하고 경량 기본 이미지를 사용하는 것은 컨테이너 이미지의 크기를 줄이는 데 도움이 되며, 이는 더 빠른 배포와 향상된 성능으로 이어질 수 있습니다. 리소스 제한을 지정하면 애플리케이션이 할당된 리소스 내에서 효율적으로 실행되도록 보장하며, 이는 AWS와 같은 클라우드 환경에서 매우 중요합니다.",
        "Other Options": [
            "큰 기본 이미지를 사용하는 것은 모든 종속성이 포함되도록 보장하는 것처럼 보일 수 있지만, 이는 부풀려진 이미지를 초래하여 배포 시간을 늦추고 저장 비용을 증가시켜 성능에 최적이 아닙니다.",
            "Dockerfile에서 리소스 요구 사항을 정의하는 것은 중요하지만, AWS Fargate에만 의존하여 리소스를 관리하는 것은 성능 최적화를 위한 세밀한 제어를 제공하지 않을 수 있으며, 오케스트레이션 서비스에서 수동으로 지정하는 것도 중요합니다.",
            "컨테이너 이미지를 Amazon S3에 저장하는 것은 배포를 위한 일반적인 관행이 아니며, 컨테이너 이미지는 Amazon ECR과 같은 컨테이너 레지스트리에 저장되어야 합니다. 애플리케이션 코드에서 직접 참조하는 것은 배포 프로세스를 복잡하게 만들 수 있습니다."
        ]
    },
    {
        "Question Number": "40",
        "Situation": "개발자가 EC2 인스턴스를 실제로 생성하지 않고도 해당 인스턴스를 시작할 수 있는 권한이 있는지 확인하고자 합니다.",
        "Question": "개발자가 어떤 AWS CLI 명령어를 사용해야 합니까?",
        "Options": {
            "1": "aws ec2 describe-instances --output text",
            "2": "aws ec2 run-instances --dry-run",
            "3": "aws ec2 create-instances --simulate",
            "4": "aws ec2 launch-instance --test-permissions"
        },
        "Correct Answer": "aws ec2 run-instances --dry-run",
        "Explanation": "'aws ec2 run-instances --dry-run' 명령어는 EC2 인스턴스를 실제로 생성하지 않고도 시작을 시뮬레이션하도록 특별히 설계되었습니다. 이를 통해 개발자는 비용을 발생시키거나 리소스를 배포하지 않고도 해당 작업을 수행할 수 있는 권한이 있는지 확인할 수 있습니다.",
        "Other Options": [
            "'aws ec2 describe-instances --output text' 명령어는 기존 EC2 인스턴스에 대한 정보를 검색하는 데 사용되며, 새로운 인스턴스를 시작하는 것과 관련된 권한을 확인하지 않습니다.",
            "'aws ec2 create-instances --simulate' 명령어는 유효한 AWS CLI 명령어가 아닙니다. 인스턴스 생성을 시뮬레이션하는 올바른 명령어는 'aws ec2 run-instances --dry-run'입니다.",
            "'aws ec2 launch-instance --test-permissions' 명령어도 유효한 AWS CLI 명령어가 아닙니다. 인스턴스를 시작하기 위한 권한을 테스트하는 올바른 방법은 run-instances 명령어와 함께 dry-run 옵션을 사용하는 것입니다."
        ]
    },
    {
        "Question Number": "41",
        "Situation": "개발자가 낮은 대기 시간을 유지하면서 높은 볼륨의 수신 요청을 처리해야 하는 AWS Lambda 함수를 설계하고 있습니다. 함수가 부하를 효율적으로 처리할 수 있도록 하기 위해, 개발자는 특히 피크 트래픽 시간 동안 함수가 여러 요청을 동시에 처리할 수 있도록 하는 전략을 구현해야 합니다.",
        "Question": "개발자가 이러한 동시 요청 처리의 확장을 달성하기 위해 어떤 기능을 활용해야 합니까?",
        "Options": {
            "1": "함수의 메모리 할당을 늘려 처리 능력과 속도를 향상시킵니다.",
            "2": "Lambda 함수에 대해 예약된 동시성을 구성하여 최소한의 동시 실행 수를 보장합니다.",
            "3": "Lambda 함수에 대한 자동 확장 그룹을 구현하여 수요에 따라 자동으로 확장을 관리합니다.",
            "4": "Amazon SQS를 사용하여 Lambda 함수의 수신 요청을 큐에 저장하여 제어된 속도로 처리할 수 있도록 합니다."
        },
        "Correct Answer": "Lambda 함수에 대해 예약된 동시성을 구성하여 최소한의 동시 실행 수를 보장합니다.",
        "Explanation": "Lambda 함수에 대해 예약된 동시성을 구성하면 항상 특정 수의 인스턴스가 수신 요청을 처리할 수 있도록 보장됩니다. 이를 통해 함수는 여러 요청을 동시에 처리할 수 있으며, 제한을 받지 않고 높은 부하 조건에서도 확장성과 낮은 대기 시간을 유지할 수 있습니다.",
        "Other Options": [
            "함수의 메모리 할당을 늘리는 것은 성능을 향상시킬 수 있지만, 동시 요청 처리 문제를 직접적으로 해결하지는 않습니다. 메모리 할당만으로는 여러 요청을 동시에 처리할 수 있다는 보장을 제공하지 않습니다.",
            "자동 확장 그룹을 구현하는 것은 AWS Lambda 함수에 적용되지 않으며, Lambda 함수는 수신 요청 수에 따라 자동으로 확장되도록 설계되어 있습니다.",
            "Amazon SQS를 사용하여 수신 요청을 큐에 저장하면 트래픽을 관리하는 데 도움이 될 수 있지만, Lambda 함수 자체의 동시성을 본질적으로 증가시키지는 않습니다. 요청이 처리되기 전에 큐에 저장되므로 추가적인 대기 시간이 발생합니다."
        ]
    },
    {
        "Question Number": "42",
        "Situation": "한 회사가 사용자에게 향상된 기능을 제공하기 위해 다양한 AWS 리소스를 활용하는 애플리케이션을 개발 중입니다. 애플리케이션에 대한 안전한 접근을 보장하기 위해 강력한 사용자 인증 메커니즘을 구현해야 합니다. 이 회사는 사용자 인증을 위해 OpenID Connect (OIDC)를 지원하는 외부 ID 공급자를 통합하기로 결정했습니다. 또한 애플리케이션은 AWS에 호스팅되며, 회사는 사용자 인증 관리를 위해 Amazon Cognito를 주요 서비스로 활용할 계획입니다. 애플리케이션의 중요한 요구 사항은 여러 AWS 계정에 분산된 리소스에 대한 접근을 용이하게 하는 것이며, 이를 위해 역할 할당 및 인증 관리에 대한 명확한 전략이 필요합니다.",
        "Question": "회사가 외부 ID 공급자가 사용자를 효과적으로 인증하고 다양한 AWS 계정에서 적절한 역할을 할당할 수 있도록 Amazon Cognito를 활용하여 어떤 구성을 구현해야 합니까?",
        "Options": {
            "1": "연합 인증을 위해 특별히 설계된 Cognito ID 풀을 활용하고, 인증된 사용자의 속성과 주장에 따라 IAM 역할을 동적으로 할당하기 위해 역할 기반 접근 제어(RBAC)를 구성합니다.",
            "2": "연합 인증을 위해 Cognito 사용자 풀을 배포하고, 이 풀 내에서 사용자에게 IAM 역할을 직접 할당하여 역할 할당이 간단하고 관리 가능하도록 합니다.",
            "3": "연합 인증을 위해 AWS IAM과 외부 사용자 그룹을 구현하여 사용자가 리소스 접근을 위해 필요할 때마다 AWS 계정 내에서 IAM 역할을 맡을 수 있도록 합니다.",
            "4": "외부 SAML ID 공급자를 활용하여 인증을 관리하고, 특정 AWS 서비스 역할에 사용자를 직접 매핑하여 접근 제어 및 권한 관리를 간소화합니다."
        },
        "Correct Answer": "연합 인증을 위해 특별히 설계된 Cognito ID 풀을 활용하고, 인증된 사용자의 속성과 주장에 따라 IAM 역할을 동적으로 할당하기 위해 역할 기반 접근 제어(RBAC)를 구성합니다.",
        "Explanation": "회사가 취해야 할 올바른 접근 방식은 연합 인증을 위해 특별히 설계된 Cognito ID 풀을 활용하는 것입니다. 이를 통해 애플리케이션은 외부 OIDC ID 공급자를 통해 사용자를 인증할 수 있습니다. 역할 기반 접근 제어(RBAC)를 구성함으로써, 회사는 ID 공급자로부터 받은 속성에 따라 사용자에게 IAM 역할을 동적으로 할당할 수 있어, 여러 AWS 계정에 걸쳐 리소스에 대한 적절한 접근 수준을 보장할 수 있습니다.",
        "Other Options": [
            "연합 인증을 위해 Cognito 사용자 풀을 사용하고 사용자 풀 내에서 IAM 역할을 직접 할당하는 것은 효과적이지 않습니다. 사용자 풀은 주로 사용자 가입 및 로그인 프로세스를 관리하기 위해 설계되었으며, 여러 AWS 계정에 대한 접근을 제공하기 위한 것이 아닙니다.",
            "연합 인증을 위해 AWS IAM과 외부 사용자 그룹을 구현하는 것은 사용자가 역할을 맡을 수 있도록 할 수 있지만, Cognito ID 풀을 사용할 때 제공되는 유연성과 동적 역할 할당 기능을 제공하지 않으므로 이 시나리오에 적합하지 않습니다.",
            "외부 SAML ID 공급자를 활용하여 인증을 관리하고 사용자를 특정 AWS 서비스 역할에 직접 매핑하는 것은 Amazon Cognito를 활용하지 않으며, 이는 회사의 요구 사항에 필수적입니다. 이 접근 방식은 또한 Cognito ID 풀이 제공하는 사용자 속성에 기반한 동적 역할 할당 기능이 부족합니다."
        ]
    },
    {
        "Question Number": "43",
        "Situation": "개발 팀이 AWS Serverless Application Model (AWS SAM)을 사용하여 서버리스 애플리케이션의 새 버전을 배포할 준비를 하고 있습니다. 그들은 개발, 스테이징 및 프로덕션과 같은 다양한 환경에서 일관성을 보장하기 위해 배포 프로세스를 자동화하고자 합니다.",
        "Question": "팀이 이러한 환경에서 자동화된 애플리케이션 배포를 수행하기 위해 어떤 AWS 서비스 기능을 활용해야 합니까?",
        "Options": {
            "1": "AWS CodeCommit은 버전 관리를 허용하지만 배포를 위한 수동 승인 단계를 요구하므로 자동화에는 적합하지 않습니다.",
            "2": "AWS CodeDeploy와 AWS CodePipeline이 통합되어 애플리케이션 배포를 자동화하고 다양한 환경을 효과적으로 관리하는 강력한 솔루션을 제공합니다.",
            "3": "AWS Elastic Beanstalk 환경 구성은 애플리케이션 관리에 적합하지만 여러 환경에 대한 자동화에 주로 초점을 맞추고 있지 않습니다.",
            "4": "AWS CloudFormation Change Sets는 리소스 관리를 가능하게 하지만 여러 환경에서 배포를 위한 종단 간 자동화가 부족합니다."
        },
        "Correct Answer": "AWS CodeDeploy와 AWS CodePipeline이 통합되어 애플리케이션 배포를 자동화하고 다양한 환경을 효과적으로 관리하는 강력한 솔루션을 제공합니다.",
        "Explanation": "AWS CodeDeploy는 AWS CodePipeline과 통합되어 완전 자동화된 배포 프로세스를 지원합니다. 이 설정을 통해 개발 팀은 배포 파이프라인을 정의할 수 있어, 수동 개입 없이도 다양한 환경에서 애플리케이션을 일관되게 배포할 수 있으며, 이는 신뢰성과 효율성을 보장합니다.",
        "Other Options": [
            "AWS CodeCommit은 버전 관리를 허용하지만 배포를 위한 수동 승인 단계를 요구하므로 자동화에는 적합하지 않습니다. 이는 코드 버전 관리는 가능하지만 팀이 원하는 완전한 자동화를 지원하지 않는다는 의미입니다.",
            "AWS Elastic Beanstalk 환경 구성은 애플리케이션 관리에 적합하지만 여러 환경에 대한 자동화에 주로 초점을 맞추고 있지 않습니다. 배포를 단순화하지만 CodePipeline 및 CodeDeploy와 같은 통합 및 자동화 수준을 제공하지 않습니다.",
            "AWS CloudFormation Change Sets는 리소스 관리를 가능하게 하지만 여러 환경에서 배포를 위한 종단 간 자동화가 부족합니다. 이는 애플리케이션 배포 프로세스를 자동화하기보다는 인프라 변경 관리를 더 중시합니다."
        ]
    },
    {
        "Question Number": "44",
        "Situation": "한 회사가 AWS Lambda 함수를 사용하여 서버리스 애플리케이션을 개발하고 있습니다. 이 애플리케이션은 확장성과 신뢰성을 보장하기 위해 요청 간에 세션 상태를 유지하지 않고 여러 동시 요청을 처리해야 합니다.",
        "Question": "개발자들이 이를 달성하기 위해 따라야 할 설계 원칙은 무엇입니까?",
        "Options": {
            "1": "Amazon RDS에 세션 데이터를 저장하여 상태 있는 처리를 구현합니다.",
            "2": "AWS Step Functions를 사용하여 각 요청의 상태를 관리합니다.",
            "3": "Lambda 함수를 상태가 없는(stateless) 방식으로 설계하여 인메모리 데이터에 의존하지 않도록 합니다.",
            "4": "Amazon ElastiCache for Redis에 세션 정보를 유지합니다."
        },
        "Correct Answer": "Lambda 함수를 상태가 없는(stateless) 방식으로 설계하여 인메모리 데이터에 의존하지 않도록 합니다.",
        "Explanation": "AWS Lambda 함수의 상태가 없는(stateless) 설계는 동시 요청을 효율적으로 처리할 수 있게 합니다. 인메모리 데이터나 세션 상태에 의존하지 않음으로써 각 호출이 독립적이며 이전 실행의 정보가 필요하지 않기 때문에 원활하게 확장할 수 있습니다. 이는 서버리스 아키텍처의 원칙과 일치하여 신뢰성과 확장성을 촉진합니다.",
        "Other Options": [
            "상태 있는 처리를 구현하는 것은 서버리스 패러다임에 반하며, 세션 데이터가 요청 간의 의존성을 생성하므로 동시 요청을 효과적으로 처리하는 데 어려움을 초래합니다.",
            "AWS Step Functions는 워크플로를 관리하고 여러 서비스를 조정하는 데 유용하지만 Lambda 함수 자체의 설계에서 상태가 없음을 요구하는 필요를 본질적으로 해결하지는 않습니다.",
            "Amazon ElastiCache for Redis에 세션 정보를 유지하는 것은 애플리케이션에 상태를 도입하여 서버리스 아키텍처에서 AWS Lambda의 최적 사용을 위해 요구되는 상태가 없는 설계 원칙에 반합니다."
        ]
    },
    {
        "Question Number": "45",
        "Situation": "Amazon EC2 인스턴스에서 실행되는 애플리케이션은 구성 설정의 안전한 저장 및 검색을 위한 강력한 솔루션이 필요합니다. 이러한 설정은 API 키 및 데이터베이스 자격 증명과 같은 민감한 정보를 포함하고 있어 매우 중요합니다. 회사는 이 구성 데이터가 저장될 때 암호화될 뿐만 아니라 애플리케이션이 안전하게 접근할 수 있도록 하는 데 특히 중점을 두고 있습니다. 그들은 기존 아키텍처와 쉽게 통합할 수 있으면서 이러한 보안 요구 사항을 가장 잘 충족하는 AWS 서비스를 선택하고자 합니다.",
        "Question": "API 키 및 데이터베이스 자격 증명과 같은 민감한 구성 설정의 안전한 저장 및 검색이 필요하므로, 애플리케이션이 안전하게 접근할 수 있도록 하면서도 저장 시 암호화를 보장하기 위해 개발자가 사용할 가장 적절한 AWS 서비스는 무엇입니까?",
        "Options": {
            "1": "Amazon S3는 서버 측 암호화를 제공하여 클라우드에 저장된 데이터에 대한 기본 암호화를 제공하지만 민감한 구성 관리를 위한 특수 기능이 부족할 수 있습니다.",
            "2": "AWS Secrets Manager는 민감한 정보를 안전하게 관리하기 위해 특별히 설계된 서비스로, 비밀의 자동 회전 및 세분화된 접근 제어를 제공합니다.",
            "3": "암호화가 활성화된 Amazon RDS는 데이터베이스 저장소를 보호하지만 API 키와 같은 애플리케이션 구성 설정을 저장하는 데 주로 사용되지 않습니다.",
            "4": "AWS Systems Manager Parameter Store는 구성 데이터와 비밀을 안전하게 저장할 수 있도록 하며, 암호화 및 다른 AWS 서비스와의 쉬운 통합을 제공합니다."
        },
        "Correct Answer": "AWS Secrets Manager는 민감한 정보를 안전하게 관리하기 위해 특별히 설계된 서비스로, 비밀의 자동 회전 및 세분화된 접근 제어를 제공합니다.",
        "Explanation": "AWS Secrets Manager는 API 키 및 데이터베이스 자격 증명과 같은 민감한 정보를 관리하기 위해 특별히 설계되었습니다. 자동 비밀 회전과 같은 기능을 제공하여 자격 증명을 정기적으로 변경함으로써 보안을 강화하고, 세분화된 접근 제어를 통해 권한이 있는 애플리케이션과 사용자만 비밀을 검색할 수 있도록 합니다. 이는 이 시나리오에서 구성 설정을 안전하게 저장하고 검색하는 데 가장 적합한 선택입니다.",
        "Other Options": [
            "Amazon S3는 서버 측 암호화를 제공하여 데이터의 저장 시 암호화를 가능하게 하지만, 민감한 구성 데이터를 관리하기 위해 특별히 설계되지 않았으며 자동 비밀 회전과 같은 기능이 부족합니다.",
            "암호화가 활성화된 Amazon RDS는 데이터베이스를 보호하지만 API 키와 같은 애플리케이션 구성 설정을 저장하는 데 사용되지 않으며 AWS Secrets Manager가 제공하는 특수 관리 기능이 없습니다.",
            "AWS Systems Manager Parameter Store는 구성 데이터를 안전하게 저장할 수 있으며 암호화를 지원하지만, AWS Secrets Manager에서 제공하는 자동 비밀 회전과 같은 민감한 데이터 관리에 특화된 고급 기능이 부족합니다."
        ]
    },
    {
        "Question Number": "46",
        "Situation": "개발자는 메시지가 전송된 정확한 순서대로 처리되도록 보장하면서 중복 메시지가 전달되지 않도록 하는 메시징 시스템을 만드는 임무를 맡았습니다. 이 시스템은 Amazon SQS를 사용하여 구축되며, 개발자는 이 시나리오에서 처리량을 우선시할 필요가 없습니다.",
        "Question": "개발자가 두 가지 기준을 효과적으로 충족하기 위해 어떤 유형의 SQS 큐를 사용해야 합니까?",
        "Options": {
            "1": "순서가 있고 고유한 메시지 처리를 보장하기 위해 중복 제거가 활성화된 FIFO 큐.",
            "2": "순서를 유지하지 않고 중복을 관리하기 위해 콘텐츠 기반 중복 제거를 사용하는 표준 큐.",
            "3": "중복 제거 없이 작동하는 FIFO 큐로, 순서를 유지하더라도 메시지 중복이 발생할 수 있습니다.",
            "4": "명시적 중복 제거 ID를 사용하는 표준 큐로, 메시지 순서를 보장할 수는 없습니다."
        },
        "Correct Answer": "순서가 있고 고유한 메시지 처리를 보장하기 위해 중복 제거가 활성화된 FIFO 큐.",
        "Explanation": "정답은 중복 제거가 활성화된 FIFO(선입선출) 큐입니다. 이 유형의 큐는 메시지가 전송된 정확한 순서로 처리되도록 요구 사항을 충족하며, 중복 메시지가 전달되지 않도록 보장합니다. FIFO 큐는 순서와 고유성이 중요한 시나리오를 위해 특별히 설계되었습니다.",
        "Other Options": [
            "이 옵션은 표준 큐가 메시지의 순서를 보장하지 않기 때문에 잘못되었습니다. 콘텐츠 기반 중복 제거는 중복을 관리하는 데 도움이 되지만, 메시지 순서가 없기 때문에 이 상황에 적합하지 않습니다.",
            "이 옵션은 중복 제거가 없는 FIFO 큐는 잠재적인 중복 메시지가 처리될 수 있기 때문에 잘못되었습니다. 메시지의 순서는 유지되지만, 중복 제거가 없기 때문에 중복을 방지해야 하는 필요와 모순됩니다.",
            "이 옵션은 명시적 중복 제거 ID를 사용하는 표준 큐가 메시지 순서를 보장할 수 없기 때문에 잘못되었습니다. 중복을 관리하려고 하지만, 메시지가 전송된 정확한 순서로 처리되는 요구 사항을 충족하지 못합니다."
        ]
    },
    {
        "Question Number": "47",
        "Situation": "개발자는 AWS에서 애플리케이션 로드 밸런서(ALB) 뒤에 웹 애플리케이션을 배포하는 과정에 있습니다. 이 애플리케이션은 사용자가 세션 동안 인증 상태를 유지할 수 있도록 설계되어 있으며, 반복적으로 로그인할 필요가 없습니다. 이를 달성하기 위해 ALB는 들어오는 트래픽을 백엔드의 여러 Amazon EC2 인스턴스로 지능적으로 라우팅하도록 구성되어 있어, 애플리케이션이 사용자 수요의 다양한 수준을 처리하면서 세션 연속성을 유지할 수 있도록 합니다.",
        "Question": "사용자 세션이 지속적으로 유지되어 사용자가 애플리케이션과 상호작용하는 동안 중단 없이 로그인 상태를 유지할 수 있도록 하기 위해, 개발자가 이 기능을 효과적으로 구현하기 위해 어떤 구성 단계를 수행해야 합니까?",
        "Options": {
            "1": "ALB의 사용자 세션 관리를 위해 Lambda 대상 그룹을 구성합니다.",
            "2": "ALB와 연결된 대상 그룹에 대해 스티키 세션을 활성화합니다.",
            "3": "ALB 리스너를 인스턴스 ID 대신 IP 주소를 기반으로 트래픽을 라우팅하도록 설정합니다.",
            "4": "IP 기반 대상 유형을 사용하고 백엔드 인스턴스에 Elastic IP를 연결합니다."
        },
        "Correct Answer": "ALB와 연결된 대상 그룹에 대해 스티키 세션을 활성화합니다.",
        "Explanation": "ALB와 연결된 대상 그룹에 대해 스티키 세션을 활성화하면 로드 밸런서가 사용자의 세션을 특정 인스턴스에 바인딩할 수 있습니다. 즉, 사용자가 인증되고 특정 EC2 인스턴스에 할당되면, 해당 사용자로부터의 후속 요청은 동일한 인스턴스로 전송되어 세션 지속성을 유지하고 반복 로그인을 방지합니다.",
        "Other Options": [
            "ALB의 사용자 세션 관리를 위해 Lambda 대상 그룹을 구성하는 것은 유효한 접근 방식이 아닙니다. Lambda 함수는 일반적으로 이벤트 기반 처리에 사용되며, 웹 애플리케이션에서 사용자 세션 상태를 유지하는 데 사용되지 않습니다.",
            "ALB 리스너를 인스턴스 ID 대신 IP 주소를 기반으로 트래픽을 라우팅하도록 설정하는 것은 세션 지속성을 보장하지 않습니다. IP 기반 라우팅은 사용자가 다른 인스턴스로 라우팅될 수 있어 세션의 연속성을 깨뜨릴 수 있습니다.",
            "IP 기반 대상 유형을 사용하고 백엔드 인스턴스에 Elastic IP를 연결하는 것은 사용자 세션 지속성을 유지하는 것과 직접적인 관련이 없습니다. Elastic IP는 주로 정적 IP 주소에 사용되며, 본질적으로 사용자 세션을 관리하지 않습니다."
        ]
    },
    {
        "Question Number": "48",
        "Situation": "개발자는 수백만 개의 레코드를 포함하는 Amazon DynamoDB 테이블에서 쿼리를 최적화하고 있습니다. 현재 구현은 데이터를 검색하기 위해 스캔 작업을 사용하고 있으며, 이로 인해 성능 문제가 발생하고 있습니다.",
        "Question": "DynamoDB에서 성능에 영향을 미치는 쿼리와 스캔 작업의 주요 차이점은 무엇입니까?",
        "Options": {
            "1": "쿼리 작업은 파티션 키를 지정해야 하지만, 스캔 작업은 테이블의 모든 항목을 검사합니다.",
            "2": "쿼리 작업은 특정 속성만 검색할 수 있지만, 스캔 작업은 모든 속성을 검색합니다.",
            "3": "스캔 작업은 병렬 처리를 사용하므로 더 빠르며, 쿼리 작업은 순차적입니다.",
            "4": "쿼리 작업은 전역 보조 인덱스와 함께 사용할 수 있지만, 스캔 작업은 기본 인덱스를 사용합니다."
        },
        "Correct Answer": "쿼리 작업은 파티션 키를 지정해야 하지만, 스캔 작업은 테이블의 모든 항목을 검사합니다.",
        "Explanation": "성능에 영향을 미치는 주요 차이점은 쿼리 작업이 특정 기준에 따라 항목을 검색하도록 설계되어 있으며, 파티션 키를 지정해야 한다는 것입니다. 반면에 스캔 작업은 테이블의 모든 항목을 검사하며, 특히 대량의 데이터 세트에서는 효율성이 떨어집니다.",
        "Other Options": [
            "이것은 잘못된 것입니다. 쿼리 작업과 스캔 작업 모두 특정 속성을 검색할 수 있지만, 스캔은 기본적으로 모든 속성을 검색합니다.",
            "이것은 잘못된 것입니다. 스캔 작업은 일반적으로 쿼리 작업보다 느리며, 쿼리 작업은 인덱스를 활용하고 특정 항목을 대상으로 하여 전체 테이블을 스캔하지 않습니다.",
            "이것은 잘못된 것입니다. 쿼리 작업은 기본 인덱스와 전역 보조 인덱스 모두와 함께 사용할 수 있으며, 스캔은 기본 인덱스에만 국한되지 않습니다."
        ]
    },
    {
        "Question Number": "49",
        "Situation": "클라우드 컴퓨팅 환경에서 한 회사는 Amazon RDS (관계형 데이터베이스 서비스) 인스턴스의 읽기 복제본을 전략적으로 설정하여 읽기 중심 애플리케이션을 효과적으로 관리하고 확장하고 있습니다. 예정된 정리 작업 중에 주요 데이터베이스 인스턴스를 삭제하기로 결정하였고, 이는 애플리케이션의 성능 요구를 지원하기 위해 생성된 읽기 복제본의 운명에 대한 우려를 불러일으킵니다.",
        "Question": "정리 과정에서 주요 데이터베이스가 삭제된 후 이 상황에서 읽기 복제본에 어떤 일이 발생합니까?",
        "Options": {
            "1": "주요 데이터베이스가 삭제되면 읽기 복제본이 즉시 시스템에서 자동으로 제거되어 잔여 데이터가 남지 않도록 합니다.",
            "2": "주요 데이터베이스가 삭제된 후에도 읽기 복제본은 시스템에 남아 있으며, 나중에 관리자가 수동으로 제거해야 합니다.",
            "3": "읽기 복제본이 새로운 주요 데이터베이스로 전환되어 원래의 주요 데이터베이스 인스턴스가 없는 상태에서 그 역할을 맡습니다.",
            "4": "읽기 복제본이 작동을 중단하고 이후 비활성으로 표시되어 읽기 요청을 처리할 수 없습니다."
        },
        "Correct Answer": "읽기 복제본은 계속 존재하며 수동으로 삭제해야 합니다.",
        "Explanation": "주요 데이터베이스가 삭제되면 읽기 복제본은 그대로 남아 자동으로 제거되지 않습니다. 더 이상 필요하지 않은 경우 관리자가 수동으로 삭제해야 하며, 이는 읽기 복제본이 보유하고 있는 데이터나 리소스를 적절히 관리할 수 있도록 합니다.",
        "Other Options": [
            "이 옵션은 읽기 복제본이 주요 데이터베이스가 제거될 때 자동으로 삭제되지 않기 때문에 잘못된 것입니다. 사용자가 명시적으로 삭제할 때까지 계속 존재합니다.",
            "이 옵션은 읽기 복제본이 자동으로 주요 데이터베이스의 역할을 맡을 수 없기 때문에 부정확합니다. 읽기 복제본은 여전히 원래 주요 데이터베이스에 의존하며 그렇게 독립적으로 작동할 수 없습니다.",
            "이 선택은 읽기 복제본이 단순히 작동을 중단하거나 자동으로 비활성화되지 않기 때문에 잘못된 것입니다. 읽기 복제본은 시스템에 남아 있지만 삭제된 주요 데이터베이스로부터 업데이트를 받지 않습니다."
        ]
    },
    {
        "Question Number": "50",
        "Situation": "개발자는 Amazon DynamoDB를 사용하여 애플리케이션 데이터를 효과적으로 저장하고 관리하여 최적의 성능을 달성하기 위해 열심히 작업하고 있습니다. 다양한 속성을 기반으로 데이터에 접근하는 유연성을 유지하고 효율적인 쿼리 성능을 보장하기 위해, 개발자는 애플리케이션의 요구에 가장 적합한 키와 인덱스를 사용하여 테이블을 설계하는 중요한 과제에 직면해 있습니다.",
        "Question": "저장된 데이터의 여러 속성에 대한 효율적인 쿼리를 지원하기 위해 개발자가 구현해야 할 DynamoDB 키 및 인덱싱 전략의 조합은 무엇입니까?",
        "Options": {
            "1": "보조 인덱스를 포함하지 않고 단순 기본 키를 사용하여 쿼리 기능을 제한합니다.",
            "2": "복합 기본 키를 구현하고 가장 자주 쿼리되는 속성에 대해 글로벌 보조 인덱스를 설정하여 유연성과 성능을 향상시킵니다.",
            "3": "해시 키만 채택하고 모든 쿼리를 실행하기 위해 스캔 작업에 의존하여 성능 비효율성을 초래할 수 있습니다.",
            "4": "정렬 키만 사용하고 로컬 보조 인덱스를 설정하여 복합 키 없이 추가 쿼리 기능을 제공합니다."
        },
        "Correct Answer": "복합 기본 키를 구현하고 가장 자주 쿼리되는 속성에 대해 글로벌 보조 인덱스를 설정하여 유연성과 성능을 향상시킵니다.",
        "Explanation": "DynamoDB에서 효율적인 쿼리를 위한 최적의 접근 방식은 파티션 키와 정렬 키로 구성된 복합 기본 키를 사용하는 것입니다. 이는 더 유연한 데이터 조직 및 검색을 가능하게 합니다. 또한 자주 접근되는 속성에 대해 글로벌 보조 인덱스를 생성하면 개발자가 기본 키 구조에 제한받지 않고 효율적인 쿼리를 수행할 수 있어 전체 애플리케이션 성능과 반응성을 크게 향상시킵니다.",
        "Other Options": [
            "보조 인덱스 없이 단순 기본 키를 사용하는 것은 데이터베이스의 쿼리 기능을 제한하여 기본 키 외의 속성을 기반으로 데이터를 효율적으로 검색하기 어렵게 만듭니다.",
            "해시 키에만 의존하고 모든 쿼리에 대해 스캔 작업을 수행하는 것은 비효율적입니다. 스캔은 느리고 리소스를 많이 소모할 수 있어 대규모 데이터 세트에서 특정 데이터를 검색할 때 성능 문제를 초래할 수 있습니다.",
            "정렬 키만 사용하고 파티션 키 없이 사용하면 테이블에서 항목을 고유하게 식별할 수 있는 능력이 제한되며, 로컬 보조 인덱스는 쿼리 기능을 향상시킬 수 있지만 글로벌 보조 인덱스가 있는 복합 기본 키가 제공하는 포괄적인 쿼리 기능을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "51",
        "Situation": "개발 팀은 쿼타 한도 도달 및 성공적인 배포와 같은 중요한 이벤트에 대한 즉각적인 알림을 받을 수 있도록 애플리케이션을 향상시키는 데 집중하고 있습니다. 그들은 모니터링 프로세스를 간소화하기 위해 기존의 가시성 도구와 쉽게 통합할 수 있는 솔루션을 찾고 있습니다.",
        "Question": "이러한 특정 작업에 대한 알림 경고를 구현하기 위해 팀이 사용해야 할 AWS 서비스는 무엇입니까?",
        "Options": {
            "1": "Amazon CloudWatch Alarms와 Amazon Simple Notification Service (SNS)를 결합하여 포괄적인 경고 관리를 제공합니다.",
            "2": "쿼타 한도에 도달하거나 접근할 때마다 이메일을 직접 보내도록 설정된 AWS Lambda를 사용하여 즉각적인 알림을 보장합니다.",
            "3": "Amazon S3 이벤트 알림을 사용하여 S3 버킷 내 저장된 객체에 대해 수행된 특정 작업에 따라 알림을 트리거합니다.",
            "4": "복잡한 워크플로우를 관리하기 위해 설계된 AWS Step Functions를 사용하여 알림 프로세스에 대한 구조화된 접근 방식을 제공합니다."
        },
        "Correct Answer": "Amazon CloudWatch Alarms와 Amazon Simple Notification Service (SNS)를 결합하여 포괄적인 경고 관리를 제공합니다.",
        "Explanation": "정답은 Amazon CloudWatch Alarms와 Amazon SNS입니다. 이 솔루션을 통해 개발 팀은 특정 메트릭을 기반으로 알람을 설정하고 이러한 알람이 트리거될 때 SNS를 통해 알림을 보낼 수 있어 쿼타 한도 및 배포 상태에 대한 실시간 알림에 적합합니다.",
        "Other Options": [
            "AWS Lambda는 알림을 보낼 수 있지만 사용자 정의 설정이 필요하고 CloudWatch Alarms가 제공하는 내장 모니터링 및 알림 기능을 제공하지 않기 때문에 여기서 최선의 선택이 아닙니다.",
            "Amazon S3 이벤트 알림은 S3 버킷의 변경 사항에 특정되어 있으며 쿼타 한도나 배포 완료와 같은 애플리케이션 수준 메트릭을 모니터링하는 데 적합하지 않습니다.",
            "AWS Step Functions는 주로 복잡한 워크플로우를 조정하는 데 사용되며 실시간 알림을 위해 특별히 설계되지 않았기 때문에 CloudWatch 및 SNS에 비해 팀의 요구에 덜 적합합니다."
        ]
    },
    {
        "Question Number": "52",
        "Situation": "개발자가 인증된 사용자에게 보호된 리소스에 접근하기 위해 JSON Web Tokens (JWT)를 발급하는 안전한 API를 설계하고 있습니다. API는 토큰이 유효하고 변조되지 않았음을 보장해야 하며, 이러한 토큰을 안전하게 검증할 수 있는 신뢰할 수 있는 방법이 필요합니다.",
        "Question": "개발자가 JWT를 안전하게 검증하고 그 무결성을 보장하기 위해 어떤 기술을 사용해야 합니까?",
        "Options": {
            "1": "OAuth 2.0, 이는 권한 부여를 위한 프레임워크를 제공하지만 JWT 검증을 구체적으로 다루지 않습니다.",
            "2": "AWS Security Token Service (AWS STS), 이는 주로 임시 보안 자격 증명을 위해 사용되며, JWT 검증을 위한 것이 아닙니다.",
            "3": "OpenID Connect (OIDC), OAuth 2.0 위에 구축된 신원 계층으로, 인증을 허용하고 JWT를 효과적으로 검증하는 메커니즘을 포함합니다.",
            "4": "Amazon Cognito, 사용자 세션 관리를 돕는 사용자 신원 및 접근 관리 서비스이지만 본질적으로 JWT를 검증하지 않습니다."
        },
        "Correct Answer": "OpenID Connect (OIDC), OAuth 2.0 위에 구축된 신원 계층으로, 인증을 허용하고 JWT를 효과적으로 검증하는 메커니즘을 포함합니다.",
        "Explanation": "OpenID Connect (OIDC)는 사용자를 인증하기 위해 특별히 설계되었으며, JWT를 검증하기 위한 내장 메커니즘을 제공합니다. 이를 통해 개발자는 토큰의 무결성과 진위를 확인할 수 있어, 변조되지 않았고 신뢰할 수 있는 신원 제공자에 의해 발급되었음을 보장합니다.",
        "Other Options": [
            "OAuth 2.0은 권한 부여를 위한 프레임워크로, JWT 검증을 위한 특정 기능을 제공하지 않으므로 토큰의 안전한 검증에는 불충분합니다.",
            "AWS Security Token Service (AWS STS)는 AWS 서비스에 대한 임시 보안 자격 증명을 생성하는 데 사용되지만, JWT 검증을 위한 것이 아니므로 토큰 검증 요구 사항을 충족하지 못합니다.",
            "Amazon Cognito는 사용자 신원 및 세션 관리를 위한 서비스이지만 JWT 검증을 구체적으로 다루지 않아 API의 토큰 관리에서 보안의 공백을 남깁니다."
        ]
    },
    {
        "Question Number": "53",
        "Situation": "한 회사가 AWS CloudFormation을 사용하여 애플리케이션을 배포하기 위해 AWS CodePipeline을 사용하고 있습니다. 배포 중 문제가 발견되어 회사는 다운타임과 성능 저하를 피하기 위해 애플리케이션의 이전 버전으로 롤백해야 합니다. 회사는 롤백 중 사용자에게 미치는 영향을 최소화하고자 합니다.",
        "Question": "회사가 가용성에 영향을 주지 않고 쉽게 빠르게 롤백할 수 있도록 CodePipeline에서 어떤 배포 전략을 사용해야 합니까?",
        "Options": {
            "1": "CodeDeploy와 함께 'Rolling' 배포 전략을 활용하여, 서비스 가용성을 유지하면서 한 번에 제한된 수의 인스턴스를 업데이트합니다.",
            "2": "CodeDeploy와 함께 'Blue/Green' 배포 전략을 구현하여, 이전 버전을 빠르게 롤백할 수 있도록 하면서 새로운 환경으로 즉시 트래픽을 리디렉션합니다.",
            "3": "CloudFormation과 함께 'Canary' 배포 전략을 채택하여, 새로운 버전으로 트래픽의 소량만을 유도하여 롤아웃 중 위험을 최소화합니다.",
            "4": "'All-at-once' 전략을 사용하여 모든 인스턴스를 동시에 업데이트하여 가장 빠른 롤백을 가능하게 하지만, 상당한 다운타임을 초래할 수 있습니다."
        },
        "Correct Answer": "CodeDeploy와 함께 'Blue/Green' 배포 전략을 구현하여, 이전 버전을 빠르게 롤백할 수 있도록 하면서 새로운 환경으로 즉시 트래픽을 리디렉션합니다.",
        "Explanation": "Blue/Green 배포 전략은 회사가 현재 버전(Blue)과 새로운 버전(Green)을 위한 두 개의 별도 환경을 유지할 수 있게 합니다. 새로운 버전에서 문제가 발생하면 트래픽을 즉시 이전 버전으로 리디렉션할 수 있어 사용자에게 미치는 방해를 최소화하고 빠른 롤백 프로세스를 보장합니다.",
        "Other Options": [
            "'Rolling' 배포 전략은 인스턴스를 점진적으로 업데이트하여 다운타임을 최소화할 수 있지만, 이전 버전이 별도의 환경에 보존되지 않기 때문에 Blue/Green과 같은 수준의 빠른 롤백 기능을 제공하지 않습니다.",
            "'Canary' 배포 전략은 새로운 버전으로 트래픽의 소량을 유도하여 위험을 줄이지만, 문제가 발생할 경우 모든 사용자가 이전 버전으로 즉시 롤백할 수 있도록 하지 않습니다.",
            "'All-at-once' 배포 전략을 사용하면 가능한 가장 빠른 롤아웃이 가능하지만, 롤백이 필요할 경우 전체 환경이 동시에 업데이트되므로 상당한 다운타임을 초래할 수 있습니다."
        ]
    },
    {
        "Question Number": "54",
        "Situation": "한 회사가 컨테이너화된 애플리케이션 관리를 위해 EC2 인스턴스를 활용하는 ECS (Elastic Container Service) 클러스터를 운영하고 있습니다. 운영 효율성을 높이고 자원 활용을 최적화하기 위해, 회사는 애플리케이션이 원활하고 효과적으로 실행되도록 하면서 사용 중인 인스턴스의 총 수를 줄일 방법을 찾고 있습니다.",
        "Question": "효과적인 자원 활용을 유지하면서 사용 중인 EC2 인스턴스의 수를 최소화하기 위해, 회사는 클러스터에 어떤 ECS 작업 배치 전략을 구현해야 합니까?",
        "Options": {
            "1": "Spread - 이 전략은 모든 사용 가능한 인스턴스에 작업을 고르게 분배하여 높은 가용성을 보장하지만, 사용 중인 인스턴스의 총 수를 줄이지는 않을 수 있습니다.",
            "2": "Binpack - 이 전략은 가능한 최소한의 인스턴스에 작업을 배치하는 데 중점을 두어, 추가 인스턴스를 사용하기 전에 인스턴스를 최대 용량까지 채워 자원 활용을 최적화합니다.",
            "3": "Random - 이 전략은 사용 가능한 인스턴스에 작업을 무작위로 배치하여 자원 활용의 효율성을 보장하지 않으며, 필요 이상으로 더 많은 인스턴스가 사용될 수 있습니다.",
            "4": "MemberOf - 이 전략은 인스턴스의 특정 속성을 기반으로 작업을 배치할 수 있지만, 사용 중인 인스턴스의 수를 최소화하는 데 중점을 두지 않습니다."
        },
        "Correct Answer": "Binpack - 이 전략은 가능한 최소한의 인스턴스에 작업을 배치하는 데 중점을 두어, 추가 인스턴스를 사용하기 전에 인스턴스를 최대 용량까지 채워 자원 활용을 최적화합니다.",
        "Explanation": "Binpack 전략은 사용 중인 EC2 인스턴스의 수를 최소화하려는 회사의 목표에 이상적입니다. 가능한 적은 수의 인스턴스에 작업을 배치하는 것을 우선시함으로써, 기존 인스턴스가 완전히 활용되도록 하여 새로운 인스턴스를 시작하기 전에 자원 활용을 효과적으로 최적화합니다.",
        "Other Options": [
            "Spread 전략은 모든 인스턴스에 작업을 고르게 분배하여 높은 가용성을 보장하지만, 사용 중인 인스턴스의 수를 줄이는 데 기여하지 않으므로 회사의 목표와는 반대입니다.",
            "Random 전략은 자원 활용 효율성을 고려하지 않고 작업을 배치하여, 필요 이상으로 더 많은 인스턴스가 사용될 수 있어 회사의 목표와 일치하지 않습니다.",
            "MemberOf 전략은 특정 인스턴스 속성을 기반으로 배치를 허용하지만, 인스턴스 수를 최소화하는 것을 우선시하지 않으므로 회사의 필요에 덜 적합합니다."
        ]
    },
    {
        "Question Number": "55",
        "Situation": "개발자는 민감한 데이터와 작업을 처리하기 위해 설계된 새로운 애플리케이션의 AWS Identity and Access Management (IAM) 정책을 구성하는 과정에 있습니다. 보안 팀은 각 사용자에게 할당된 작업을 효율적으로 수행하는 데 필요한 권한만 부여해야 하며, 어떤 개인도 자신의 역할에 필수적인 정보나 기능 이상에 접근할 수 없어야 한다고 명확히 요구했습니다. 이 요구 사항은 안전한 환경을 유지하고 민감한 데이터를 무단 접근으로부터 보호하는 데 매우 중요합니다.",
        "Question": "보안 팀이 제시한 보안 요구 사항을 고려할 때, 개발자가 애플리케이션의 보안 태세를 준수하고 향상시키기 위해 따라야 할 기본 보안 원칙은 무엇입니까?",
        "Options": {
            "1": "Defense in Depth, 여러 보안 조치를 겹쳐서 정보와 인프라를 다양한 위협으로부터 보호하는 방법입니다.",
            "2": "Separation of Duties, 사기나 오류의 위험을 줄이기 위해 책임을 여러 개인에게 분산시키는 관행입니다.",
            "3": "Principle of Least Privilege, 사용자는 자신의 업무를 효과적으로 수행하는 데 필요한 최소한의 접근 권한만 부여받아야 한다는 원칙입니다.",
            "4": "Need-to-Know Basis, 정보 접근을 업무에 필요한 개인으로 제한하는 보안 원칙입니다."
        },
        "Correct Answer": "Principle of Least Privilege, 사용자는 자신의 업무를 효과적으로 수행하는 데 필요한 최소한의 접근 권한만 부여받아야 한다는 원칙입니다.",
        "Explanation": "Principle of Least Privilege는 각 사용자가 특정 작업을 수행하는 데 필요한 권한만 가지도록 보장하여 보안 위험을 최소화하는 데 필수적입니다. 이 접근 방식은 권한의 우발적 또는 악의적 오용 가능성을 줄이고 애플리케이션 내의 민감한 데이터와 작업을 보호하는 데 도움이 됩니다.",
        "Other Options": [
            "Defense in Depth는 여러 계층을 통해 시스템을 보호하는 유용한 전략이지만, 개인 사용자 권한을 필요한 것만으로 제한하는 요구 사항을 직접적으로 다루지 않습니다.",
            "Separation of Duties는 책임을 분산시켜 사기와 오류를 방지하는 데 중요하지만, 각 사용자에게 필요한 최소한의 접근 권한을 제한하는 데는 구체적으로 초점을 맞추지 않습니다.",
            "Need-to-Know Basis는 필요에 따라 정보 접근을 제한하는 원칙이지만, 전체 시스템에서 사용자 권한을 관리하는 데 있어 Principle of Least Privilege만큼 포괄적이지 않습니다."
        ]
    },
    {
        "Question Number": "56",
        "Situation": "개발자는 Amazon RDS 데이터베이스와 상호작용하기 위해 설계된 AWS Lambda 함수를 작업하고 있습니다. 또한, Lambda 함수는 데이터 검색 및 기타 기능을 위해 외부 API에 접근하기 위해 인터넷에 연결할 수 있어야 합니다. 개발자는 Lambda 함수가 VPC 내의 개인 리소스와 외부 인터넷 모두와 효과적으로 통신할 수 있도록 하면서 비용을 관리할 수 있는 솔루션을 찾아야 합니다.",
        "Question": "Lambda 함수가 VPC 내의 리소스와 외부 API 호출을 위한 인터넷에 필요한 접근을 보장하기 위해 가장 비용 효율적인 구성 방법은 무엇입니까?",
        "Options": {
            "1": "Lambda 함수에 Elastic IP를 연결하여 인터넷과 직접 통신할 수 있도록 합니다.",
            "2": "Lambda 함수가 공용 서브넷과 인터넷 게이트웨이를 포함하는 VPC 내에서 작동하도록 구성하여 직접 인터넷 접근을 허용합니다.",
            "3": "Lambda 함수를 개인 서브넷으로 구성된 VPC에 설정하고 NAT 게이트웨이를 구현하여 VPC 리소스에 대한 접근을 유지하면서 인터넷 접근을 용이하게 합니다.",
            "4": "NAT 게이트웨이 없이 개인 서브넷에 Lambda 함수를 배치하여 인터넷 접근을 제한합니다."
        },
        "Correct Answer": "Lambda 함수를 개인 서브넷으로 구성된 VPC에 설정하고 NAT 게이트웨이를 구현하여 VPC 리소스에 대한 접근을 유지하면서 인터넷 접근을 용이하게 합니다.",
        "Explanation": "VPC 리소스와 인터넷 모두에 접근하기 위해 Lambda 함수를 구성하는 가장 비용 효율적인 방법은 개인 서브넷이 있는 VPC에 설정하고 NAT 게이트웨이를 사용하는 것입니다. NAT 게이트웨이는 Lambda 함수가 인터넷으로 아웃바운드 트래픽을 시작할 수 있도록 하면서도 직접적인 인바운드 인터넷 트래픽으로부터 안전하고 격리된 상태를 유지합니다. 이 구성은 요구 사항을 충족할 뿐만 아니라 불필요한 리소스를 피함으로써 비용을 최적화합니다.",
        "Other Options": [
            "Lambda 함수에 Elastic IP를 연결하는 것은 AWS Lambda가 Lambda 함수와 Elastic IP의 직접 연결을 지원하지 않기 때문에 실행 가능한 솔루션이 아닙니다. 이 접근 방식은 또한 개인 VPC 리소스에 대한 필요한 접근을 용이하게 하지 않습니다.",
            "공용 서브넷과 인터넷 게이트웨이를 포함하는 VPC 내에서 Lambda 함수를 작동하도록 구성하면 인터넷 접근이 가능하지만, 이는 개인 리소스와의 안전한 상호작용에 이상적이지 않은 직접적인 인바운드 인터넷 트래픽을 허용하여 불필요한 보안 위험에 노출될 수 있습니다.",
            "NAT 게이트웨이 없이 개인 서브넷에 Lambda 함수를 배치하면 인터넷 접근이 완전히 제한되어 함수가 외부 API를 호출할 수 없게 되며, 여전히 개인 RDS 데이터베이스와 상호작용할 수 없습니다."
        ]
    },
    {
        "Question Number": "57",
        "Situation": "여러 EC2 인스턴스가 필요한 웹 애플리케이션을 위한 CloudFormation 스택을 배포하는 과정에 있습니다. 스택 초기화의 일환으로, 각 EC2 인스턴스에 필요한 소프트웨어 패키지를 설치하고, 구성 파일을 생성하며, 필요한 서비스를 시작해야 합니다. 이 과정은 스택이 다른 리소스를 생성하거나 구성하기 전에 각 리소스가 완전히 작동하도록 보장해야 하며, 애플리케이션 배포의 무결성과 기능을 유지해야 합니다.",
        "Question": "패키지 설치, 파일 생성 및 EC2 인스턴스에서 서비스 시작을 효과적으로 관리하고, 스택이 추가 리소스 배포를 진행하기 전에 이러한 프로세스가 완료될 때까지 적절히 대기하도록 하기 위해 어떤 특정 CloudFormation 헬퍼 스크립트를 사용해야 합니까?",
        "Options": {
            "1": "cfn-signal",
            "2": "cfn-get-metadata",
            "3": "cfn-init",
            "4": "cfn-hup"
        },
        "Correct Answer": "cfn-signal",
        "Explanation": "cfn-signal 헬퍼 스크립트는 EC2 인스턴스의 초기화 프로세스가 성공적으로 완료되었음을 CloudFormation에 알리는 신호를 보내도록 설계되었습니다. 이를 통해 CloudFormation은 패키지 설치 및 서비스 시작과 같은 모든 필요한 작업이 완료될 때까지 대기한 후 스택의 다음 리소스로 이동할 수 있습니다. 따라서 스택 배포가 인스턴스가 완전히 준비된 후에만 진행되도록 효과적으로 보장합니다.",
        "Other Options": [
            "cfn-get-metadata는 CloudFormation 템플릿에서 메타데이터를 검색하는 데 사용되며, 패키지 설치나 서비스 상태 관리를 처리하지 않기 때문에 이 시나리오에 적합하지 않습니다.",
            "cfn-init은 메타데이터에 지정된 명령을 실행하여 인스턴스를 초기화하고 구성하는 데 사용되지만, 이러한 작업의 완료에 대해 CloudFormation에 신호를 보내는 방법을 제공하지 않습니다.",
            "cfn-hup은 CloudFormation 스택의 변경 사항을 감지하고 업데이트를 적용하는 데 사용할 수 있는 헬퍼 스크립트이지만, EC2 인스턴스의 초기 설정 프로세스를 관리하지 않으며 초기화 완료에 대한 신호 메커니즘을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "58",
        "Situation": "개발자가 AWS SAM을 사용하여 서버리스 애플리케이션을 구축하고 배포하고 있습니다. 애플리케이션이 올바르게 구성되고 배포 준비가 되었는지 확인하기 위해, 그들은 템플릿을 검증하고, 애플리케이션을 패키징한 후 AWS에 배포하고자 합니다. 올바른 명령어 순서를 이해하는 것은 원활한 배포 프로세스를 위해 매우 중요하며, 잠재적인 오류를 피하는 데 도움이 됩니다.",
        "Question": "개발자가 애플리케이션 템플릿을 검증하고 패키징한 후 AWS에 효과적으로 배포하기 위해 실행해야 하는 SAM CLI 명령어의 순서는 무엇인가요?",
        "Options": {
            "1": "sam build, sam validate, sam deploy",
            "2": "sam init, sam deploy, sam build",
            "3": "sam validate, sam package, sam deploy",
            "4": "sam validate, sam build, sam deploy"
        },
        "Correct Answer": "sam validate, sam package, sam deploy",
        "Explanation": "'sam validate'를 사용하여 애플리케이션 템플릿을 먼저 검증하는 것이 올바른 명령어 순서입니다. 이는 SAM 템플릿의 오류를 확인합니다. 다음으로 'sam package'를 사용하여 애플리케이션을 패키징하고 필요한 아티팩트를 S3에 업로드합니다. 마지막으로 'sam deploy'는 패키징된 애플리케이션을 AWS에 배포합니다. 이렇게 하면 애플리케이션이 올바르게 검증되고 배포 준비가 완료됩니다.",
        "Other Options": [
            "'sam build'는 템플릿을 검증하기 전에 사용할 올바른 명령어가 아니므로 이 옵션은 잘못되었습니다; 검증은 먼저 수행해야 합니다.",
            "'sam init'은 새로운 SAM 애플리케이션을 생성하는 데 사용되므로, 이미 애플리케이션이 구축되고 배포되고 있는 이 맥락에서는 필요하지 않기 때문에 이 옵션은 잘못되었습니다.",
            "'sam validate'는 올바르지만 'sam package'가 'sam deploy'보다 먼저 와야 하므로 이 옵션은 잘못된 순서입니다."
        ]
    },
    {
        "Question Number": "59",
        "Situation": "개발자가 AWS Lambda 함수를 사용하고 있으며, 이는 서버를 관리하지 않고 이벤트에 응답하여 코드를 실행하도록 설계되었습니다. 개발 과정의 일환으로, 개발자는 API 키, 데이터베이스 자격 증명 및 기타 기밀 데이터와 같은 민감한 정보가 함수의 실행 환경 내에서 안전하게 처리되도록 해야 합니다. Lambda 함수는 여러 개발자가 협업 환경에서 업데이트하고 볼 수 있기 때문에, 코드베이스에서 이 민감한 정보를 노출할 위험을 피하는 것이 중요합니다.",
        "Question": "개발자가 Lambda 함수 코드에 민감한 환경 변수를 직접 하드코딩하지 않고 안전하게 관리하기 위해 취해야 할 가장 효과적인 접근 방식은 무엇인가요?",
        "Options": {
            "1": "민감한 환경 변수를 Lambda 함수 환경 변수에 일반 텍스트로 저장합니다.",
            "2": "AWS Secrets Manager를 사용하여 민감한 환경 변수를 저장하고 Lambda 함수가 이를 프로그래밍 방식으로 검색하도록 구성합니다.",
            "3": "환경 변수를 Amazon S3에 공개 읽기 접근으로 저장하고 Lambda를 사용하여 이를 검색합니다.",
            "4": "민감한 환경 변수를 Lambda 함수 코드 내의 JSON 파일로 저장하고 코드 내에서 참조합니다."
        },
        "Correct Answer": "AWS Secrets Manager를 사용하여 민감한 환경 변수를 저장하고 Lambda 함수가 이를 프로그래밍 방식으로 검색하도록 구성합니다.",
        "Explanation": "AWS Secrets Manager를 사용하면 개발자가 API 키 및 데이터베이스 자격 증명과 같은 민감한 정보를 안전하게 저장, 관리 및 검색할 수 있습니다. Secrets Manager는 저장 및 전송 중 암호화를 제공하며, 세밀한 접근 제어를 가능하게 하여 필요한 Lambda 함수만 이러한 비밀에 접근할 수 있도록 보장합니다. 이 접근 방식은 코드베이스에 민감한 데이터를 하드코딩하는 것을 방지하고 노출 위험을 줄입니다.",
        "Other Options": [
            "민감한 환경 변수를 Lambda 함수 환경 변수에 일반 텍스트로 저장하는 것은 안전하지 않으며, 이는 Lambda 함수 구성에 접근할 수 있는 모든 사람에게 이러한 값을 노출시켜 우발적인 유출이나 무단 접근의 위험을 증가시킵니다.",
            "환경 변수를 Amazon S3에 공개 읽기 접근으로 저장하는 것은 매우 안전하지 않으며, 링크가 있는 누구나 민감한 정보를 읽을 수 있게 하여 API 키와 자격 증명을 보호하는 목적에 반합니다.",
            "민감한 환경 변수를 Lambda 함수 코드 내의 JSON 파일로 저장하는 것도 바람직하지 않으며, 이는 여전히 민감한 정보를 하드코딩하는 것을 포함합니다. 코드가 공유되거나 게시될 경우 민감한 데이터가 쉽게 노출될 수 있습니다."
        ]
    },
    {
        "Question Number": "60",
        "Situation": "개발자가 Amazon S3에 저장된 대규모 데이터 세트를 처리하는 애플리케이션의 데이터 생명 주기를 관리하는 임무를 맡고 있습니다. 규제 준수 요구 사항으로 인해 데이터는 최소 5년 동안 보존되어야 합니다. 또한, 개발자는 시간이 지남에 따라 이 데이터에 대한 접근 패턴이 변경될 것으로 예상하고 있으며, 이는 데이터가 항상 자주 접근되지 않을 수 있음을 의미하므로, 저장 관리 및 비용 효율성에 대한 신중한 접근이 필요합니다.",
        "Question": "5년 동안 데이터를 보존해야 하며 시간이 지남에 따라 변경되는 접근 패턴을 고려할 때, 개발자가 이러한 요구 사항을 비용 효율적으로 충족하기 위해 구현해야 하는 S3 저장 클래스 및 생명 주기 관리 정책은 무엇인가요?",
        "Options": {
            "1": "S3 표준 저장 클래스를 사용하고 생명 주기 관리 정책을 설정하지 않아 데이터를 자주 접근할 수 있도록 합니다.",
            "2": "S3 표준-비정기 접근(IA) 저장 클래스를 선택하고, 5년 보존 기간 후에 데이터를 S3 Glacier로 전환하는 생명 주기 정책을 결합하여 비정기적으로 접근되는 데이터의 비용을 최적화합니다.",
            "3": "S3 지능형 계층화 저장 클래스를 구현하여 접근 패턴에 따라 자동으로 저장 클래스를 조정하여 수동 개입 없이 최적의 비용 절감을 보장합니다.",
            "4": "S3 단일 영역-비정기 접근 저장 클래스를 선택하고 5년 후에 데이터를 삭제하는 생명 주기 정책을 설정하여 비용 절감을 중시하지만 데이터 가용성을 타협합니다."
        },
        "Correct Answer": "S3 표준-비정기 접근(IA) 저장 클래스를 선택하고, 5년 보존 기간 후에 데이터를 S3 Glacier로 전환하는 생명 주기 정책을 결합하여 비정기적으로 접근되는 데이터의 비용을 최적화합니다.",
        "Explanation": "정답은 S3 표준-비정기 접근(IA) 저장 클래스를 선택하고 5년 후에 데이터를 S3 Glacier로 전환하는 생명 주기 정책을 설정하는 것입니다. 이 접근 방식은 개발자가 첫 5년 동안 데이터에 대한 접근성을 낮은 저장 비용으로 유지하면서 보존 정책을 준수할 수 있도록 합니다. 5년 후 S3 Glacier로 전환하면 비정기적으로 접근되는 데이터의 장기 저장을 위한 비용 효율적인 솔루션을 제공하며, 예상되는 접근 패턴의 변화에 부합합니다.",
        "Other Options": [
            "첫 번째 옵션인 S3 표준 저장 클래스를 사용하고 생명 주기 관리 없이 데이터가 시간이 지남에 따라 비정기적으로 접근될 것이라는 점을 고려할 때 비용 효율적이지 않으며, 최적화 없이 높은 저장 비용이 발생합니다.",
            "세 번째 옵션인 S3 지능형 계층화 저장 클래스를 구현하는 것은 접근 패턴에 따라 자동으로 조정되지만, 5년 동안 보존해야 하고 이후에 더 저렴한 저장 클래스로 전환해야 하는 데이터에 대해 가장 비용 효율적인 솔루션이 아닐 수 있습니다.",
            "네 번째 옵션인 S3 단일 영역-비정기 접근 저장 클래스를 선택하고 5년 후에 데이터를 삭제하는 생명 주기 정책을 설정하는 것은 데이터 보존 요구 사항을 충족하지 못하며, 데이터는 삭제되기 전에 최소 5년 동안 보존되어야 합니다."
        ]
    },
    {
        "Question Number": "61",
        "Situation": "보안 팀은 회사의 애플리케이션에서 사용되는 암호화 키가 강력하고 지속적으로 업데이트되어 높은 수준의 보안을 유지하도록 하는 임무를 맡고 있습니다. 이를 달성하기 위해, 그들은 이러한 키를 업데이트하는 프로세스를 자동화하는 키 회전 정책의 구현을 고려하고 있습니다. 조직은 이러한 키를 효과적으로 관리하기 위해 AWS Key Management Service (KMS)를 활용하기로 결정했습니다. 팀은 클라우드 보안 및 규정 준수에 대한 모범 사례를 염두에 두고 이 자동 회전을 활성화하기 위한 가장 효율적인 방법을 선택하는 것이 중요합니다.",
        "Question": "AWS KMS에서 관리되는 암호화 키에 대한 자동 키 회전을 활성화하기 위해 보안 팀이 취해야 할 조치는 무엇입니까?",
        "Options": {
            "1": "관련 고객 마스터 키(CMK)에 대해 AWS KMS 콘솔에서 키 회전을 활성화합니다.",
            "2": "매년 새로운 키 쌍을 수동으로 생성하고 모든 애플리케이션 코드를 업데이트하여 새 키를 사용합니다.",
            "3": "AWS Lambda를 사용하여 사용자 지정 키 회전 정책을 만들고 매달 KMS 키를 수동으로 업데이트합니다.",
            "4": "KMS CMK에 대해 AWS Identity and Access Management (IAM)에서 키 회전 정책을 활성화합니다."
        },
        "Correct Answer": "관련 고객 마스터 키(CMK)에 대해 AWS KMS 콘솔에서 키 회전을 활성화합니다.",
        "Explanation": "관련 고객 마스터 키(CMK)에 대해 AWS KMS 콘솔에서 키 회전을 활성화하는 것은 올바른 조치입니다. AWS KMS는 자동 키 회전을 위한 기본 지원을 제공합니다. 이 기능을 활성화함으로써 보안 팀은 키가 매년 자동으로 회전되도록 하여 수동 개입 없이 보안과 규정 준수를 강화할 수 있습니다.",
        "Other Options": [
            "매년 새로운 키 쌍을 수동으로 생성하고 모든 애플리케이션 코드를 업데이트하는 것은 비효율적이며 인적 오류가 발생할 수 있습니다. 이 방법은 AWS KMS의 자동화 기능을 활용하지 않으며, 새로운 키를 기존 애플리케이션에 통합하는 데 상당한 오버헤드가 필요합니다.",
            "AWS Lambda를 사용하여 사용자 지정 키 회전 정책을 만들고 매달 KMS 키를 수동으로 업데이트하는 것은 불필요한 복잡성을 초래합니다. Lambda는 다양한 작업을 자동화할 수 있지만, 키를 수동으로 업데이트하는 것은 자동 회전 프로세스의 목표와 모순되며 오류의 위험을 증가시킵니다.",
            "KMS CMK에 대해 AWS Identity and Access Management (IAM)에서 키 회전 정책을 활성화하는 것은 잘못된 것입니다. IAM은 키 회전을 직접 관리하지 않습니다. 키 회전은 AWS KMS 콘솔 내에서 특별히 활성화해야 하는 기능으로, CMK 설정을 구성할 수 있는 곳입니다."
        ]
    },
    {
        "Question Number": "62",
        "Situation": "개발자는 여러 외부 API와 상호 작용하는 애플리케이션에 대한 통합 테스트를 작성하고 있습니다. 테스트가 신뢰할 수 있고 실제 외부 서비스의 가용성이나 성능에 의존하지 않도록 하기 위해, 개발자는 이러한 API의 동작을 시뮬레이션하기 위해 모의 엔드포인트를 사용하기로 결정했습니다.",
        "Question": "개발자가 통합 테스트를 위해 모의 엔드포인트를 생성하는 데 사용할 수 있는 AWS 서비스 기능은 무엇입니까?",
        "Options": {
            "1": "Amazon API Gateway의 Mock Integration을 사용하면 특정 엔드포인트에 대한 모의 응답을 정의할 수 있어 실제 백엔드 서비스 없이 테스트를 용이하게 합니다.",
            "2": "AWS Lambda 함수를 사용하여 미리 정의된 응답을 반환할 수 있지만, 실제 호출이 필요하며 정적 모의 엔드포인트로 사용되지는 않습니다.",
            "3": "Amazon SNS 주제는 알림을 보낼 수 있지만, 통합 테스트를 위한 API 응답을 시뮬레이션하는 모의 엔드포인트를 생성하는 데 적합하지 않습니다.",
            "4": "AWS Step Functions는 오케스트레이션 기능을 제공하지만 API 테스트 시나리오를 위한 모의 엔드포인트를 본래 생성하지는 않습니다."
        },
        "Correct Answer": "Amazon API Gateway의 Mock Integration을 사용하면 특정 엔드포인트에 대한 모의 응답을 정의할 수 있어 실제 백엔드 서비스 없이 테스트를 용이하게 합니다.",
        "Explanation": "Amazon API Gateway의 Mock Integration은 들어오는 요청에 따라 미리 정의된 응답을 반환할 수 있는 모의 엔드포인트를 생성하도록 특별히 설계되었습니다. 이 기능은 개발자가 실제 구현에 의존하지 않고 외부 API의 동작을 시뮬레이션하고자 할 때 이상적이며, 통합 테스트 중 일관성과 신뢰성을 보장합니다.",
        "Other Options": [
            "AWS Lambda 함수를 사용하여 미리 정의된 응답을 반환할 수 있지만, 실제 호출이 필요하여 테스트를 위한 독립적인 모의 엔드포인트를 생성하는 데 적합하지 않습니다.",
            "공용 URL과 캐시 제어 헤더에 의존하여 접근 제어를 하는 것은 파일을 무단 접근에 노출시킬 수 있으며, 이 방법은 여러 파일에 대한 안전한 접근 관리를 제공하지 않습니다.",
            "CloudFront 배포를 URL 경로 패턴으로 구성하는 것은 기존 설정을 복잡하게 만들 수 있으며, URL 구조를 변경해야 할 수도 있어 기존 URL을 변경하지 않겠다는 요구 사항과 모순됩니다."
        ]
    },
    {
        "Question Number": "63",
        "Situation": "웹 애플리케이션은 사용자가 S3 버킷에 호스팅된 파일을 다운로드할 수 있도록 합니다. 이 애플리케이션은 사용자가 기존 URL 구조를 유지하면서 여러 파일을 동시에 다운로드할 수 있도록 사용자 경험을 향상시키는 특정 요구 사항이 있습니다. 현재 URL이 수정되지 않도록 하는 것이 중요하며, 사용자가 익숙한 링크 형식에서의 중단이나 변경 없이 파일에 쉽게 접근할 수 있도록 해야 합니다.",
        "Question": "기존 URL 구조를 변경하지 않고 사용자가 여러 파일을 동시에 다운로드할 수 있도록 허용하기 위해 애플리케이션에 가장 적합한 솔루션은 무엇입니까?",
        "Options": {
            "1": "각 파일에 대해 서명된 URL을 사용하고 각 파일에 대해 별도의 다운로드를 요구합니다.",
            "2": "서명된 쿠키를 사용하여 애플리케이션/사용자가 URL 구조를 변경하지 않고 여러 파일을 다운로드할 수 있도록 합니다.",
            "3": "각 파일에 대해 공용 URL을 사용하고 접근 제어를 위해 캐시 제어 헤더에 의존합니다.",
            "4": "CloudFront 배포를 사용하고 각 파일에 대한 URL 경로 패턴을 구성합니다."
        },
        "Correct Answer": "서명된 쿠키를 사용하여 애플리케이션/사용자가 URL 구조를 변경하지 않고 여러 파일을 다운로드할 수 있도록 합니다.",
        "Explanation": "서명된 쿠키를 사용하는 것은 최적의 솔루션으로, 사용자가 현재 URL 구조를 수정하지 않고 여러 파일을 동시에 다운로드할 수 있도록 합니다. 서명된 쿠키는 파일에 대한 임시 접근을 허용하면서 URL의 무결성을 유지합니다. 이 방법은 배치 다운로드에 효율적이며 원활한 사용자 경험을 제공합니다.",
        "Other Options": [
            "각 파일에 대해 서명된 URL을 사용하는 것은 사용자가 파일을 개별적으로 다운로드해야 하므로 여러 파일을 동시에 다운로드할 수 있는 요구 사항을 충족하지 않습니다.",
            "공용 URL과 캐시 제어 헤더에 의존하여 접근 제어를 하는 것은 이 방법이 여러 파일에 대한 안전한 접근 관리를 제공하지 않기 때문에 파일을 무단 접근에 노출시킬 수 있습니다.",
            "CloudFront 배포를 URL 경로 패턴으로 구성하는 것은 기존 설정을 복잡하게 만들 수 있으며, URL 구조를 변경해야 할 수도 있어 기존 URL을 변경하지 않겠다는 요구 사항과 모순됩니다."
        ]
    },
    {
        "Question Number": "64",
        "Situation": "개발 팀이 AWS SAM을 사용하여 서버리스 애플리케이션을 배포하고 있습니다. 그들은 여러 환경(개발, 스테이징, 프로덕션)을 관리해야 하며, 각 환경이 특정 리소스 구성 및 종속성을 사용하도록 해야 합니다.",
        "Question": "이 팀이 이러한 환경 전반에 걸쳐 애플리케이션 인프라를 일관되게 정의하고 배포하기 위해 어떤 AWS 도구를 사용해야 합니까?",
        "Options": {
            "1": "AWS CloudFormation",
            "2": "AWS Elastic Beanstalk",
            "3": "AWS CodeDeploy",
            "4": "AWS OpsWorks"
        },
        "Correct Answer": "AWS CloudFormation",
        "Explanation": "AWS CloudFormation은 인프라를 코드로 정의하고 배포하는 데 적합한 도구입니다. 이 도구는 팀이 각 환경에 필요한 리소스를 지정하는 템플릿을 사용하여 여러 환경을 일관되게 관리할 수 있도록 합니다. 이를 통해 인프라가 재현 가능하고 버전 관리가 가능합니다.",
        "Other Options": [
            "AWS Elastic Beanstalk는 인프라를 코드로 관리하기보다는 애플리케이션 배포에 주로 초점을 맞추고 있어 여러 환경에 걸쳐 인프라를 정의하는 데 적합하지 않습니다.",
            "AWS CodeDeploy는 다양한 컴퓨팅 서비스에 애플리케이션 배포를 자동화하는 배포 서비스이지만, 여러 환경을 관리하는 데 필요한 인프라 정의 기능을 제공하지 않습니다.",
            "AWS OpsWorks는 Chef와 Puppet을 사용하는 구성 관리 서비스로, 더 복잡하며 여러 환경에 걸쳐 인프라를 코드로 정의하는 데 특별히 설계되지 않았습니다."
        ]
    },
    {
        "Question Number": "65",
        "Situation": "클라우드 솔루션을 전문으로 하는 기술 회사가 AWS에서 개인 API를 배포하는 과정에 있습니다. 이 배포는 보안에 강한 중점을 두고 있으며, 클라이언트와 서버가 안전한 연결을 설정하기 전에 서로의 신원을 확인할 수 있도록 상호 TLS(mTLS) 인증을 필요로 합니다. 개발 팀은 이 인증 프로세스에 필수적인 디지털 인증서를 관리하는 임무를 맡고 있으며, API의 수명 주기 전반에 걸쳐 이러한 인증서를 효율적이고 안전하게 처리할 수 있는 솔루션을 찾고 있습니다.",
        "Question": "개인 API 배포에서 상호 TLS(mTLS) 인증을 위한 디지털 인증서의 효율적이고 안전한 관리가 필요하므로, 팀이 이러한 인증서를 효과적으로 처리하기 위해 사용할 수 있는 가장 적합한 AWS 서비스는 무엇입니까?",
        "Options": {
            "1": "AWS Certificate Manager (ACM), AWS 서비스 및 내부 리소스에 사용할 SSL/TLS 인증서를 배포, 관리 및 갱신하는 과정을 간소화합니다.",
            "2": "AWS Private Certificate Authority (AWS Private CA), mTLS 및 기타 사용 사례를 위한 개인 인증서를 생성하고 관리할 수 있게 하여 인증서 수명 주기에 대한 더 많은 제어를 제공합니다.",
            "3": "AWS Identity and Access Management (IAM), AWS 서비스 및 리소스에 대한 사용자 액세스를 관리하지만 mTLS를 위한 인증서 관리를 특별히 처리하지는 않습니다.",
            "4": "Amazon Route 53, 주로 확장 가능한 도메인 이름 시스템(DNS) 웹 서비스이며 디지털 인증서 관리를 위한 기능을 제공하지 않습니다."
        },
        "Correct Answer": "AWS Private Certificate Authority (AWS Private CA), mTLS 및 기타 사용 사례를 위한 개인 인증서를 생성하고 관리할 수 있게 하여 인증서 수명 주기에 대한 더 많은 제어를 제공합니다.",
        "Explanation": "AWS Private Certificate Authority (AWS Private CA)는 개인 인증서를 관리하기 위해 특별히 설계되어 mTLS 인증이 필요한 애플리케이션에 이상적인 선택입니다. 이 서비스는 조직이 개인 인증서를 안전하게 생성, 관리 및 배포할 수 있도록 하여, 회사의 개인 API 배포에서 안전한 환경을 유지하는 데 필수적인 인증서 수명 주리에 대한 필요한 제어를 제공합니다.",
        "Other Options": [
            "AWS Certificate Manager (ACM)는 공개 SSL/TLS 인증서를 관리하고 갱신을 자동화하는 데 탁월하지만, mTLS 인증을 위해 개인 인증서를 관리하는 데 필요한 제어 및 사용자 정의 수준을 제공하지 않습니다.",
            "AWS Identity and Access Management (IAM)는 AWS 서비스 내에서 사용자 액세스 및 권한 관리를 중심으로 하며, AWS 리소스를 보호하는 데 중요하지만 디지털 인증서를 직접 관리하거나 mTLS 인증을 위한 필요한 기능을 제공하지 않습니다.",
            "Amazon Route 53은 도메인 등록 및 라우팅 기능을 제공하는 DNS 서비스입니다. AWS 내 리소스로 인터넷 트래픽을 유도하는 데 필수적이지만, 안전한 mTLS 연결에 필요한 디지털 인증서를 관리하기 위한 도구나 서비스를 제공하지 않습니다."
        ]
    }
]