[
    {
        "Question Number": "1",
        "Situation": "Uma empresa possui várias contas AWS para diferentes departamentos e deseja implementar a gestão de acesso entre contas para permitir que usuários de uma conta acessem recursos em outra conta de forma segura. O acesso precisa ser gerenciado de forma eficaz sem usar credenciais de longo prazo. Eles estão considerando vários serviços e metodologias da AWS para alcançar isso.",
        "Question": "Qual combinação de ações deve ser tomada para implementar uma gestão de acesso entre contas segura? (Selecione Dois)",
        "Options": {
            "1": "Use AWS Organizations para criar uma política de controle de serviço (SCP) que permita o acesso a recursos específicos em todas as contas.",
            "2": "Crie uma função IAM na conta de destino que conceda as permissões necessárias. Permita que usuários da conta de origem assumam essa função usando o ARN da função.",
            "3": "Crie uma política baseada em recursos nos recursos da conta de destino que conceda acesso aos usuários IAM na conta de origem.",
            "4": "Implemente um Provedor de Identidade (IdP) centralizado que federa as identidades dos usuários em todas as contas e gerencia o acesso aos recursos.",
            "5": "Configure um pool de identidade do Amazon Cognito na conta de origem e configure-o para conceder acesso aos recursos na conta de destino."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Crie uma função IAM na conta de destino que conceda as permissões necessárias. Permita que usuários da conta de origem assumam essa função usando o ARN da função.",
            "Crie uma política baseada em recursos nos recursos da conta de destino que conceda acesso aos usuários IAM na conta de origem."
        ],
        "Explanation": "Criar uma função IAM na conta de destino permite que usuários da conta de origem assumam essa função, concedendo-lhes as permissões necessárias sem precisar de credenciais de longo prazo. Além disso, implementar uma política baseada em recursos nos recursos da conta de destino permite que usuários IAM específicos da conta de origem acessem esses recursos diretamente, aumentando a segurança e a gerenciabilidade.",
        "Other Options": [
            "Configurar um pool de identidade do Amazon Cognito na conta de origem não é uma solução adequada para a gestão de acesso entre contas neste cenário, pois facilita principalmente a autenticação de usuários e não o acesso direto aos recursos da AWS em outra conta.",
            "Usar AWS Organizations com políticas de controle de serviço (SCPs) não concede acesso direto a recursos entre contas; SCPs são projetadas para controlar permissões no nível da organização, em vez de facilitar o acesso entre contas.",
            "Implementar um Provedor de Identidade (IdP) centralizado para identidades federadas é uma solução mais complexa e pode não ser necessária para o requisito de permitir que usuários específicos em uma conta acessem recursos em outra conta."
        ]
    },
    {
        "Question Number": "2",
        "Situation": "Uma empresa de serviços financeiros recentemente migrou sua infraestrutura para a AWS. Eles estão preocupados com a segurança de seu ambiente e querem garantir que possam detectar qualquer acesso não autorizado ou potenciais ameaças. Após revisar vários serviços de segurança da AWS, decidiram implementar o Amazon GuardDuty para melhorar sua postura de segurança.",
        "Question": "Qual das seguintes afirmações sobre o Amazon GuardDuty é VERDADEIRA?",
        "Options": {
            "1": "O Amazon GuardDuty analisa automaticamente os logs do AWS CloudTrail, VPC Flow Logs e logs DNS para detectar comportamentos maliciosos sem exigir configuração adicional.",
            "2": "O Amazon GuardDuty é um serviço que fornece monitoramento em tempo real para recursos da AWS, mas não analisa logs em busca de atividades suspeitas.",
            "3": "O Amazon GuardDuty requer configuração manual de fontes de inteligência de ameaças para monitorar efetivamente a atividade da rede.",
            "4": "O Amazon GuardDuty só pode detectar ameaças com base em assinaturas pré-definidas e não pode se adaptar a novas ameaças ao longo do tempo."
        },
        "Correct Answer": "O Amazon GuardDuty analisa automaticamente os logs do AWS CloudTrail, VPC Flow Logs e logs DNS para detectar comportamentos maliciosos sem exigir configuração adicional.",
        "Explanation": "O Amazon GuardDuty foi projetado para fornecer detecção contínua de ameaças, analisando automaticamente dados de log de várias fontes da AWS, incluindo CloudTrail, VPC Flow Logs e logs DNS. Esse recurso permite identificar potenciais ameaças sem a necessidade de configuração manual, tornando-o uma ferramenta valiosa para melhorar a segurança em um ambiente AWS.",
        "Other Options": [
            "Esta afirmação está incorreta porque o Amazon GuardDuty utiliza inteligência de ameaças embutida e não requer configuração manual de fontes de inteligência de ameaças para funcionar efetivamente.",
            "Esta afirmação está incorreta porque o Amazon GuardDuty utiliza mais do que apenas assinaturas pré-definidas; ele emprega aprendizado de máquina e detecção de anomalias para identificar novas e evolutivas ameaças.",
            "Esta afirmação está incorreta, pois representa mal a funcionalidade do GuardDuty. O GuardDuty analisa logs em busca de atividades suspeitas e está focado em identificar potenciais ameaças de segurança em tempo real."
        ]
    },
    {
        "Question Number": "3",
        "Situation": "Uma empresa implementou o AWS Organizations para gerenciar várias contas AWS. Eles definiram Políticas de Controle de Serviço (SCPs) para impor segurança e conformidade em suas contas membros. A equipe de segurança está preocupada com as permissões concedidas a usuários nessas contas e quer garantir que certas ações não sejam permitidas, mesmo que uma declaração de Permitir explícita exista em outras SCPs.",
        "Question": "Qual das seguintes afirmações sobre Políticas de Controle de Serviço (SCPs) é verdadeira neste cenário?",
        "Options": {
            "1": "As SCPs podem ser usadas para restringir ações para o usuário root na conta mestre.",
            "2": "Uma Permissão explícita em uma SCP pode conceder permissões independentemente de quaisquer declarações de Negar em outras SCPs.",
            "3": "Uma Negação explícita em uma SCP irá sobrepor quaisquer permissões de Permitir concedidas por outras SCPs.",
            "4": "As SCPs podem ser aplicadas para gerenciar funções vinculadas a serviços nas contas membros."
        },
        "Correct Answer": "Uma Negação explícita em uma SCP irá sobrepor quaisquer permissões de Permitir concedidas por outras SCPs.",
        "Explanation": "As Políticas de Controle de Serviço (SCPs) são projetadas para gerenciar permissões em AWS Organizations. Uma Negação explícita sempre terá precedência sobre quaisquer permissões de Permitir, garantindo que ações restritas não possam ser realizadas, mesmo que sejam permitidas em outras políticas.",
        "Other Options": [
            "Esta afirmação está incorreta porque uma Permissão explícita em uma SCP não sobrepõe uma Negação explícita na mesma ou em outra SCP. A Negação sempre tem precedência.",
            "Esta afirmação está incorreta porque as SCPs não afetam o usuário root da conta mestre. Elas se aplicam apenas às contas membros.",
            "Esta afirmação está incorreta porque as SCPs não se aplicam a funções vinculadas a serviços. Elas são gerenciadas no nível da conta e não são afetadas por SCPs."
        ]
    },
    {
        "Question Number": "4",
        "Situation": "Uma instituição financeira está migrando suas aplicações para a AWS e requer que apenas pessoal autorizado possa acessar recursos específicos. A equipe de segurança enfatiza a necessidade de estrita adesão ao princípio do menor privilégio para mitigar riscos. Como arquiteto de soluções, você é encarregado de projetar políticas de IAM que reforcem esse princípio em vários serviços e usuários.",
        "Question": "Qual das seguintes abordagens implementaria melhor o acesso de menor privilégio para usuários e funções neste ambiente AWS?",
        "Options": {
            "1": "Atribuir permissões de IAM com base no nível da conta AWS, permitindo que todos os usuários acessem todos os recursos sob essa conta.",
            "2": "Desenvolver políticas de IAM específicas para cada grupo de usuários que concedam apenas as permissões necessárias para suas funções de trabalho e aplicá-las às funções de IAM correspondentes.",
            "3": "Criar uma única função de IAM com permissões de acesso total e atribuí-la a todos os usuários que precisam acessar os recursos da AWS.",
            "4": "Utilizar um único usuário de IAM para todas as tarefas administrativas e compartilhar as credenciais entre os membros da equipe para simplificar a gestão de acesso."
        },
        "Correct Answer": "Desenvolver políticas de IAM específicas para cada grupo de usuários que concedam apenas as permissões necessárias para suas funções de trabalho e aplicá-las às funções de IAM correspondentes.",
        "Explanation": "Essa abordagem garante que cada usuário ou função tenha apenas as permissões necessárias para realizar suas funções de trabalho, aderindo ao princípio do menor privilégio. Ao personalizar as políticas de IAM para grupos de usuários, você minimiza o risco de permissões excessivas e possíveis violações de segurança.",
        "Other Options": [
            "Criar uma única função de IAM com permissões de acesso total viola o princípio do menor privilégio, pois concede permissões excessivas a todos os usuários atribuídos a essa função, aumentando os riscos de segurança.",
            "Atribuir permissões de IAM no nível da conta permite que todos os usuários tenham acesso irrestrito a todos os recursos, o que é contrário ao princípio do menor privilégio e pode levar a acessos não autorizados.",
            "Utilizar um único usuário de IAM para todas as tarefas administrativas compromete as melhores práticas de segurança, pois compartilhar credenciais pode levar a problemas de responsabilidade e aumenta o risco de exposição de credenciais."
        ]
    },
    {
        "Question Number": "5",
        "Situation": "Uma empresa multinacional de varejo está implantando suas aplicações em várias regiões na AWS. A empresa requer uma arquitetura altamente disponível que facilite a comunicação segura entre seus data centers locais e os recursos da AWS. Eles desejam implementar uma solução que aproveite o AWS Direct Connect e garantir que o tráfego seja roteado de forma eficiente entre suas VPCs da Amazon em diferentes regiões. A solução também deve fornecer redundância em caso de falha de link.",
        "Question": "Qual das seguintes opções o arquiteto de soluções deve implementar na AWS para atender aos requisitos da empresa? (Selecione duas)",
        "Options": {
            "1": "Estabelecer uma conexão redundante do Direct Connect na mesma região da AWS e configurar um Gateway Virtual Privado para failover.",
            "2": "Criar um gateway do Direct Connect e associá-lo a várias VPCs em diferentes regiões para habilitar o emparelhamento de VPC.",
            "3": "Implementar o AWS Global Accelerator para melhorar a disponibilidade e o desempenho, roteando o tráfego entre várias regiões da AWS.",
            "4": "Configurar uma VPN site a site como backup da conexão do Direct Connect para manter a conectividade em caso de falha.",
            "5": "Usar o AWS Transit Gateway para conectar várias VPCs e redes locais, fornecendo um único ponto de gerenciamento para roteamento."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Usar o AWS Transit Gateway para conectar várias VPCs e redes locais, fornecendo um único ponto de gerenciamento para roteamento.",
            "Configurar uma VPN site a site como backup da conexão do Direct Connect para manter a conectividade em caso de falha."
        ],
        "Explanation": "Usar o AWS Transit Gateway permite que a empresa gerencie de forma eficiente a conectividade entre várias VPCs e suas redes locais, possibilitando uma solução de roteamento escalável e centralizada. A VPN site a site serve como um backup confiável para a conexão do Direct Connect, garantindo que a comunicação possa continuar sem interrupções em caso de falha.",
        "Other Options": [
            "Criar um gateway do Direct Connect e associá-lo a várias VPCs não fornece redundância, pois carece de um mecanismo de failover e depende exclusivamente do Direct Connect.",
            "Estabelecer uma conexão redundante do Direct Connect na mesma região da AWS não aborda a comunicação entre regiões ou fornece uma estratégia abrangente de failover.",
            "Implementar o AWS Global Accelerator não é adequado para estabelecer uma conexão direta entre recursos locais e da AWS; ele otimiza principalmente o roteamento de tráfego para aplicações entre regiões da AWS."
        ]
    },
    {
        "Question Number": "6",
        "Situation": "Uma empresa de serviços financeiros está gerenciando sua conformidade com as regulamentações do setor usando recursos da AWS. Atualmente, eles têm o AWS Config configurado para monitorar seus recursos, mas desejam aprimorar seu framework de conformidade e governança. A equipe está considerando implementar estratégias de remediação automatizadas para garantir que qualquer desvio de configuração de recurso ou não conformidade seja corrigido automaticamente sem intervenção manual.",
        "Question": "Qual das seguintes soluções o Arquiteto de Soluções deve implementar para automatizar o monitoramento e a remediação da conformidade de recursos na AWS?",
        "Options": {
            "1": "Implementar o AWS Systems Manager Run Command para executar scripts em instâncias não conformes quando o AWS Config detectar um problema de configuração.",
            "2": "Habilitar o AWS Config para criar uma captura das configurações de recursos a cada 24 horas e revisá-las manualmente para garantir a conformidade com as políticas da empresa.",
            "3": "Configurar alarmes do Amazon CloudWatch para alertar a equipe de operações sempre que o AWS Config detectar um recurso não conforme, permitindo que eles tomem medidas manuais para resolver os problemas.",
            "4": "Criar uma função do AWS Lambda que seja acionada em violações de regras do AWS Config para remediar automaticamente os problemas revertendo os recursos para seus estados conformes."
        },
        "Correct Answer": "Criar uma função do AWS Lambda que seja acionada em violações de regras do AWS Config para remediar automaticamente os problemas revertendo os recursos para seus estados conformes.",
        "Explanation": "Essa abordagem aproveita o AWS Lambda para abordar automaticamente os problemas de conformidade à medida que surgem, garantindo que os recursos sejam rapidamente trazidos de volta à conformidade sem exigir intervenção manual. Isso apoia totalmente o objetivo de monitoramento e remediação automatizados.",
        "Other Options": [
            "Essa opção depende da revisão manual de capturas, o que não fornece remediação em tempo real e pode levar a períodos prolongados de não conformidade.",
            "Embora os alarmes do CloudWatch possam alertar a equipe sobre problemas de conformidade, eles não automatizam a remediação, exigindo intervenção manual para resolver os problemas.",
            "Usar o Systems Manager Run Command permite algum nível de automação, mas não se vincula diretamente às regras do AWS Config para remediação automática com base em violações de conformidade."
        ]
    },
    {
        "Question Number": "7",
        "Situation": "Uma empresa de serviços financeiros implantou um aplicativo web na AWS que lida com dados sensíveis de clientes. O aplicativo é executado em instâncias do Amazon EC2 atrás de um Elastic Load Balancer e utiliza o Amazon RDS para seu banco de dados. A empresa precisa garantir que a segurança seja mantida em todas as camadas da arquitetura, desde a rede até o aplicativo e os dados. Você foi encarregado de revisar as soluções implementadas e fazer recomendações para aprimorar a segurança.",
        "Question": "Quais medidas de segurança você recomendaria para garantir proteção abrangente em todas as camadas da arquitetura?",
        "Options": {
            "1": "Implementar o AWS WAF para proteger o aplicativo contra explorações web comuns e criptografar todos os dados em repouso usando o AWS Key Management Service (KMS).",
            "2": "Implementar funções IAM para instâncias do EC2 para garantir acesso com o menor privilégio e implantar uma solução de registro centralizada usando o AWS CloudTrail para monitoramento.",
            "3": "Usar o AWS Shield para proteger contra ataques DDoS e habilitar o Amazon CloudFront para armazenar em cache o conteúdo, reduzindo a carga nos servidores de aplicativos.",
            "4": "Implantar o Amazon Inspector para avaliar regularmente as instâncias do EC2 em busca de vulnerabilidades e configurar grupos de segurança para restringir o tráfego de entrada às portas necessárias."
        },
        "Correct Answer": "Implementar o AWS WAF para proteger o aplicativo contra explorações web comuns e criptografar todos os dados em repouso usando o AWS Key Management Service (KMS).",
        "Explanation": "A implementação do AWS WAF fornece uma camada robusta de segurança contra ataques baseados na web, enquanto o uso do AWS KMS para criptografar dados em repouso garante que informações sensíveis dos clientes estejam protegidas. Essa combinação assegura segurança tanto nas camadas de aplicativo quanto de dados.",
        "Other Options": [
            "Embora implantar o Amazon Inspector seja uma boa prática para avaliações de vulnerabilidade, ele não oferece o mesmo nível de proteção contra ataques web que o AWS WAF, nem aborda a criptografia de dados.",
            "Usar o AWS Shield protege contra ataques DDoS, mas não fornece medidas de segurança abrangentes para vulnerabilidades de aplicativos ou criptografia de dados em repouso.",
            "Implementar funções IAM é essencial para controle de acesso, mas sem medidas adicionais como o AWS WAF e criptografia de dados, não aborda completamente as necessidades de segurança em todas as camadas."
        ]
    },
    {
        "Question Number": "8",
        "Situation": "Uma grande plataforma de e-commerce está enfrentando frequentes ataques de Negação de Serviço Distribuída (DDoS), que estão impactando a disponibilidade e o desempenho de seu aplicativo web hospedado na AWS. A plataforma precisa de um conjunto robusto de estratégias de mitigação para garantir confiabilidade e continuidade do serviço, mantendo também uma experiência positiva para o usuário.",
        "Question": "Qual abordagem o arquiteto de soluções deve recomendar para desenvolver estratégias eficazes de mitigação de ataques para a plataforma de e-commerce?",
        "Options": {
            "1": "Utilizar o AWS Shield Advanced para proteção contra DDoS e configurar um grupo de Auto Scaling para lidar automaticamente com picos de tráfego.",
            "2": "Implementar o AWS WAF para filtrar solicitações maliciosas e usar o Amazon CloudFront para armazenar em cache conteúdo estático em locais de borda.",
            "3": "Usar o Amazon Route 53 para gerenciamento de DNS e configurar verificações de saúde para redirecionar o tráfego longe de recursos afetados.",
            "4": "Implantar um balanceador de carga de aplicativo com um firewall de aplicativo web e direcionar todo o tráfego através de uma VPN para segurança adicional."
        },
        "Correct Answer": "Utilizar o AWS Shield Advanced para proteção contra DDoS e configurar um grupo de Auto Scaling para lidar automaticamente com picos de tráfego.",
        "Explanation": "O AWS Shield Advanced fornece proteção DDoS aprimorada, adaptada para ataques complexos, enquanto o Auto Scaling garante que o aplicativo possa lidar com o aumento do tráfego ajustando automaticamente a capacidade. Essa combinação mitiga efetivamente os ataques e mantém o desempenho do aplicativo.",
        "Other Options": [
            "Implementar o AWS WAF sozinho pode não ser suficiente contra ataques DDoS em grande escala, e embora o cache com o CloudFront ajude, não aborda a questão subjacente da mitigação de ataques.",
            "Implantar um balanceador de carga de aplicativo com um firewall de aplicativo web fornece segurança adicional, mas direcionar todo o tráfego através de uma VPN introduz latência e complexidade, potencialmente degradando o desempenho.",
            "Usar o Amazon Route 53 para gerenciamento de DNS é útil para roteamento, mas por si só, não fornece a proteção DDoS necessária ou escalabilidade para garantir a disponibilidade do aplicativo sob ataque."
        ]
    },
    {
        "Question Number": "9",
        "Situation": "Uma empresa de serviços financeiros está planejando migrar seu banco de dados MySQL local para a AWS. O banco de dados precisa permanecer operacional durante o processo de migração para minimizar o tempo de inatividade de seus aplicativos. Além disso, a empresa exige que as alterações contínuas no banco de dados sejam capturadas mesmo após a migração inicial ser concluída. Qual serviço da AWS o arquiteto de soluções deve recomendar para atender a esses requisitos?",
        "Question": "Qual serviço da AWS fornece a capacidade de migrar bancos de dados garantindo o mínimo de tempo de inatividade e permite a replicação contínua de alterações após a migração?",
        "Options": {
            "1": "Amazon RDS Read Replica",
            "2": "AWS Database Migration Service (DMS)",
            "3": "Amazon Aurora Global Database",
            "4": "AWS Snowball"
        },
        "Correct Answer": "AWS Database Migration Service (DMS)",
        "Explanation": "O AWS Database Migration Service (DMS) permite a migração de banco de dados sem interrupções com mínimo de tempo de inatividade. Ele permite a replicação contínua de alterações no banco de dados, garantindo que o banco de dados de origem permaneça operacional durante todo o processo de migração.",
        "Other Options": [
            "O Amazon RDS Read Replica é projetado para escalar operações de leitura e não fornece os recursos de migração de dados contínua e captura de alterações necessários para este cenário.",
            "O AWS Snowball é um serviço de transferência de dados usado principalmente para mover grandes quantidades de dados para a AWS e não suporta migração contínua de banco de dados ou captura de dados de alterações.",
            "O Amazon Aurora Global Database é destinado a aplicativos distribuídos globalmente e não se concentra na migração de bancos de dados existentes enquanto garante o mínimo de tempo de inatividade."
        ]
    },
    {
        "Question Number": "10",
        "Situation": "Uma empresa está usando o Amazon DynamoDB para armazenar logs de atividade de usuários para um aplicativo móvel. Eles querem implementar uma solução que capture mudanças nos dados em tempo real e processe essas mudanças para atualizar uma tabela de análises separada. A empresa também deseja garantir que certas ações acionem notificações para os usuários quando eventos específicos ocorrerem na tabela do DynamoDB.",
        "Question": "Qual das seguintes opções pode ser usada para alcançar o processamento em tempo real das mudanças no DynamoDB e enviar notificações aos usuários? (Selecione duas)",
        "Options": {
            "1": "Ativar o DynamoDB Streams na tabela de logs de atividade do usuário e associar o stream a uma função AWS Lambda que envia notificações diretamente aos usuários.",
            "2": "Utilizar o Amazon SNS para publicar notificações sempre que houver mudanças na tabela do DynamoDB e fazer com que funções Lambda se inscrevam nessas notificações.",
            "3": "Usar o DynamoDB Streams para capturar mudanças na tabela e configurar uma fila Amazon SQS para processar as mensagens em vez de usar o AWS Lambda.",
            "4": "Ativar o DynamoDB Streams na tabela de logs de atividade do usuário e configurar uma função AWS Lambda para processar o stream e atualizar a tabela de análises.",
            "5": "Criar uma função AWS Lambda agendada para consultar a tabela do DynamoDB a cada minuto e verificar se há mudanças nos dados."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Ativar o DynamoDB Streams na tabela de logs de atividade do usuário e configurar uma função AWS Lambda para processar o stream e atualizar a tabela de análises.",
            "Ativar o DynamoDB Streams na tabela de logs de atividade do usuário e associar o stream a uma função AWS Lambda que envia notificações diretamente aos usuários."
        ],
        "Explanation": "Ao ativar o DynamoDB Streams e configurar uma função AWS Lambda, a empresa pode processar automaticamente as mudanças em tempo real, atualizando a tabela de análises e enviando notificações aos usuários com base nessas mudanças. Essa abordagem fornece uma maneira eficiente e escalável de lidar com modificações de dados e notificações aos usuários.",
        "Other Options": [
            "Criar uma função Lambda agendada para consultar a tabela do DynamoDB a cada minuto não é eficiente para processamento em tempo real, pois introduz latência e não responde imediatamente às mudanças.",
            "Utilizar o Amazon SNS para notificações sem usar o DynamoDB Streams não fornece um link direto para processar as mudanças nos dados; requer lógica adicional para monitorar mudanças.",
            "Usar uma fila SQS para processar mensagens do DynamoDB Streams é uma camada adicional que complica a arquitetura e é desnecessária, uma vez que a função Lambda pode processar o stream diretamente."
        ]
    },
    {
        "Question Number": "11",
        "Situation": "Uma empresa de serviços financeiros está planejando migrar seu banco de dados Oracle local para a AWS. Eles querem garantir que o processo de migração seja eficiente e que o esquema do banco de dados existente seja compatível com o serviço de banco de dados da AWS. A empresa tem uma equipe de administradores de banco de dados que são experientes com Oracle, mas não com serviços da AWS. Eles buscam ferramentas que os ajudem a avaliar o ambiente atual e facilitem a migração, minimizando o tempo de inatividade. (Selecione duas)",
        "Question": "Qual combinação de ferramentas ajudará a realizar a migração de forma eficiente?",
        "Options": {
            "1": "Empregar o AWS Database Migration Service (AWS DMS) para o processo de migração e o AWS Schema Conversion Tool (AWS SCT) para analisar e converter o esquema do banco de dados.",
            "2": "Implementar o AWS Snowball para transferência de dados e o AWS Database Migration Service (AWS DMS) para lidar com replicação contínua.",
            "3": "Usar o AWS Database Migration Service (AWS DMS) para replicar os dados e o AWS Schema Conversion Tool (AWS SCT) para converter o esquema do banco de dados.",
            "4": "Aproveitar o AWS Glue para criar trabalhos ETL para migração de dados e o AWS Schema Conversion Tool (AWS SCT) para conversão de esquema.",
            "5": "Utilizar o AWS Data Pipeline para mover dados para o Amazon RDS e o AWS Schema Conversion Tool (AWS SCT) para avaliação de esquema."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Usar o AWS Database Migration Service (AWS DMS) para replicar os dados e o AWS Schema Conversion Tool (AWS SCT) para converter o esquema do banco de dados.",
            "Empregar o AWS Database Migration Service (AWS DMS) para o processo de migração e o AWS Schema Conversion Tool (AWS SCT) para analisar e converter o esquema do banco de dados."
        ],
        "Explanation": "Ambas as respostas corretas utilizam o AWS DMS para migração de dados e o AWS SCT para conversão de esquema, que são projetados especificamente para migrar bancos de dados para a AWS de forma eficaz, garantindo a compatibilidade do esquema.",
        "Other Options": [
            "O AWS Data Pipeline é usado principalmente para orquestração de dados e não é especificamente projetado para migração de banco de dados. Não forneceria o mesmo nível de capacidades de conversão de esquema que o AWS SCT.",
            "O AWS Snowball é usado para transferência de dados em larga escala, mas não é adequado para cenários de replicação contínua. Esta opção não aborda a necessidade de conversão de esquema.",
            "O AWS Glue é um serviço ETL que não é focado principalmente em migração de banco de dados. Embora possa facilitar migrações de dados, não oferece as capacidades dedicadas de conversão de esquema fornecidas pelo AWS SCT."
        ]
    },
    {
        "Question Number": "12",
        "Situation": "Uma empresa de serviços financeiros está projetando um aplicativo seguro que requer que vários recursos da AWS sejam acessados por diferentes equipes dentro da organização. A empresa está utilizando funções IAM para gerenciar o acesso de forma segura. Eles precisam garantir que apenas usuários e serviços específicos possam assumir certas funções, além de precisar fazer upload de certificados SSL para comunicações seguras. Dadas essas exigências, qual é a melhor estratégia para gerenciar o acesso às funções e os certificados SSL?",
        "Question": "Qual das seguintes estratégias a empresa deve implementar para controlar efetivamente o acesso às funções IAM e gerenciar os certificados SSL?",
        "Options": {
            "1": "A empresa deve criar funções IAM com políticas de confiança que especifiquem quais usuários podem assumi-las. Além disso, fazer upload de certificados SSL para o AWS Certificate Manager (ACM) para o domínio do aplicativo para garantir comunicações seguras.",
            "2": "A empresa deve criar funções IAM sem especificar políticas de confiança, permitindo que qualquer conta da AWS as assuma. Os certificados SSL devem ser enviados para o IAM para gerenciamento em vez de usar o ACM.",
            "3": "A empresa deve criar várias funções IAM com políticas de confiança restritivas para cada equipe e fazer upload de certificados SSL para o IAM para comunicações seguras em vez de usar o ACM.",
            "4": "A empresa precisa criar uma única função IAM com uma política de confiança ampla permitindo que todos os usuários internos assumam a função. Eles devem gerenciar os certificados SSL fazendo upload diretamente para o servidor em vez de usar o ACM."
        },
        "Correct Answer": "A empresa deve criar funções IAM com políticas de confiança que especifiquem quais usuários podem assumi-las. Além disso, fazer upload de certificados SSL para o AWS Certificate Manager (ACM) para o domínio do aplicativo para garantir comunicações seguras.",
        "Explanation": "Esta opção segue as melhores práticas da AWS ao implementar acesso de menor privilégio por meio de políticas de confiança específicas para funções IAM, garantindo que apenas usuários designados possam assumi-las. Também sugere corretamente o uso do AWS Certificate Manager (ACM) para gerenciar certificados SSL, que é a abordagem recomendada para recursos da AWS.",
        "Other Options": [
            "Esta opção sugere uma política de confiança ampla que não segue o princípio do menor privilégio, permitindo potencialmente acesso não autorizado. Além disso, gerenciar certificados SSL diretamente no servidor é menos seguro e não utiliza os melhores serviços da AWS.",
            "Esta opção indica a criação de funções IAM sem políticas de confiança, o que deixaria as funções abertas a acesso não autorizado de qualquer conta da AWS. Também sugere erroneamente o upload de certificados SSL para o IAM, que não é a melhor prática em comparação com o uso do ACM.",
            "Esta opção propõe o uso de várias funções, mas sugere incorretamente gerenciar certificados SSL através do IAM em vez do ACM, o que não é recomendado e pode levar a complexidades desnecessárias e problemas de segurança."
        ]
    },
    {
        "Question Number": "13",
        "Situation": "Uma empresa de serviços financeiros está migrando suas aplicações para a AWS e deseja aproveitar as Spot Instances para economizar custos em seu ambiente Amazon ECS. A empresa requer uma solução que minimize as interrupções no serviço durante as interrupções das Spot Instances, garantindo que suas tarefas mantenham alta disponibilidade e desempenho. Eles querem usar as capacidades do ECS para gerenciar o ciclo de vida das tarefas em resposta às interrupções das Spot Instances.",
        "Question": "Qual das seguintes configurações garantirá que as tarefas do ECS em execução nas Spot Instances sejam encerradas e substituídas de forma adequada, sem causar interrupções no serviço?",
        "Options": {
            "1": "Configurar o ECS para executar tarefas exclusivamente em instâncias On-Demand para evitar quaisquer interrupções causadas pelo encerramento das Spot Instances, garantindo disponibilidade consistente a um custo mais alto.",
            "2": "Usar uma tarefa agendada para verificar periodicamente as interrupções das Spot Instances e substituir manualmente quaisquer tarefas encerradas por novas em instâncias saudáveis no cluster.",
            "3": "Configurar um serviço ECS com um percentual mínimo saudável que permita que algumas tarefas sejam encerradas durante as interrupções das Spot Instances, enquanto ainda mantém a capacidade geral do serviço.",
            "4": "Habilitar o esvaziamento automático de Spot Instances do ECS, permitindo que as tarefas sejam esvaziadas e encerradas de forma adequada ao receber um aviso de interrupção de dois minutos, enquanto agenda tarefas de substituição em outras instâncias."
        },
        "Correct Answer": "Habilitar o esvaziamento automático de Spot Instances do ECS, permitindo que as tarefas sejam esvaziadas e encerradas de forma adequada ao receber um aviso de interrupção de dois minutos, enquanto agenda tarefas de substituição em outras instâncias.",
        "Explanation": "Habilitar o esvaziamento automático de Spot Instances do ECS permite que as tarefas sejam encerradas de forma adequada usando a funcionalidade DRAINING inerente. Esse processo garante que as tarefas sejam interrompidas e substituídas de forma contínua, minimizando as interrupções no serviço e maximizando a eficiência do uso das Spot Instances.",
        "Other Options": [
            "Usar uma tarefa agendada para substituir manualmente as tarefas encerradas pode levar a atrasos e potenciais interrupções no serviço, pois não responde automaticamente às interrupções das Spot Instances.",
            "Configurar o ECS para executar tarefas exclusivamente em instâncias On-Demand elimina os benefícios de custo do uso das Spot Instances e não aborda como lidar com interrupções quando elas ocorrem.",
            "Configurar um percentual mínimo saudável pode levar à degradação do serviço durante as interrupções das Spot Instances, pois não garante que todas as tarefas sejam encerradas ou substituídas de forma adequada e em tempo hábil."
        ]
    },
    {
        "Question Number": "14",
        "Situation": "Uma empresa de serviços financeiros opera aplicações críticas que requerem alta disponibilidade e proteção de dados. O plano de recuperação de desastres da empresa inclui objetivos específicos de Tempo de Recuperação (RTO) e Objetivos de Ponto de Recuperação (RPO) para garantir o mínimo de tempo de inatividade e perda de dados. A equipe está considerando vários serviços da AWS para atender efetivamente a esses objetivos.",
        "Question": "Qual combinação de serviços da AWS ajudaria melhor a empresa a alcançar suas metas de RTO e RPO para suas aplicações críticas?",
        "Options": {
            "1": "Implementar o AWS Elastic Beanstalk para implantação de aplicações e o AWS Backup para proteção de dados.",
            "2": "Aproveitar o Amazon RDS com backups automáticos e implantação Multi-AZ para alta disponibilidade.",
            "3": "Usar o Amazon S3 para armazenamento de dados e o AWS Lambda para processamento de backups de dados.",
            "4": "Utilizar o Amazon EC2 com snapshots do EBS para backup e recuperação de dados."
        },
        "Correct Answer": "Aproveitar o Amazon RDS com backups automáticos e implantação Multi-AZ para alta disponibilidade.",
        "Explanation": "O Amazon RDS fornece backups automáticos integrados e implantações Multi-AZ que melhoram tanto o RTO quanto o RPO, permitindo uma rápida recuperação e recuperação em um ponto no tempo, tornando-o uma escolha adequada para aplicações críticas que requerem alta disponibilidade e mínima perda de dados.",
        "Other Options": [
            "O Amazon EC2 com snapshots do EBS pode fornecer opções de recuperação, mas a natureza manual dos snapshots pode levar a RTOs e RPOs mais longos em comparação com serviços gerenciados como o RDS.",
            "O AWS Elastic Beanstalk facilita a implantação de aplicações, mas não gerencia inherentemente backups de banco de dados ou disponibilidade, tornando-o menos adequado para requisitos rigorosos de RTO e RPO.",
            "O Amazon S3 é uma opção de armazenamento durável, mas carece de capacidades integradas para alta disponibilidade e recuperação em nível de aplicação, que são críticas para atender a metas baixas de RTO e RPO."
        ]
    },
    {
        "Question Number": "15",
        "Situation": "Uma empresa está projetando uma arquitetura sem servidor que requer vários serviços para invocar funções do AWS Lambda de forma síncrona. O arquiteto de soluções precisa identificar quais serviços podem acionar funções do Lambda diretamente de maneira síncrona para lidar com processamento de dados em tempo real e interações com usuários.",
        "Question": "Qual dos seguintes serviços pode invocar funções do AWS Lambda de forma síncrona?",
        "Options": {
            "1": "Amazon Kinesis Data Firehose, Amazon S3 Batch, Amazon CloudFront, Amazon Cognito",
            "2": "Amazon CloudFront, Amazon Lex, Elastic Load Balancing, Amazon S3 Batch",
            "3": "Amazon Lex, Amazon API Gateway, AWS Step Functions, Elastic Load Balancing",
            "4": "Amazon API Gateway, Amazon Kinesis Data Firehose, AWS Step Functions, Amazon Cognito"
        },
        "Correct Answer": "Amazon Lex, Amazon API Gateway, AWS Step Functions, Elastic Load Balancing",
        "Explanation": "Amazon Lex, Amazon API Gateway, AWS Step Functions e Elastic Load Balancing podem invocar funções do AWS Lambda de forma síncrona. Esses serviços são projetados para lidar com solicitações em tempo real e podem aguardar uma resposta da função Lambda antes de prosseguir.",
        "Other Options": [
            "A opção 1 está incorreta porque, embora o Amazon API Gateway e o AWS Step Functions possam invocar funções do Lambda de forma síncrona, o Amazon Kinesis Data Firehose é usado principalmente para streaming de dados e não invoca o Lambda de forma síncrona, e o Amazon Cognito é focado na autenticação de usuários em vez de invocação direta.",
            "A opção 2 está incorreta porque, embora o Amazon Lex possa invocar funções do Lambda, o Amazon CloudFront e o Amazon S3 Batch não invocam o Lambda de forma síncrona. O CloudFront usa o Lambda@Edge para manipulação de solicitações/respostas, e o S3 Batch opera de forma assíncrona.",
            "A opção 4 está incorreta porque, embora o Amazon Kinesis Data Firehose possa se integrar ao Lambda, ele não invoca o Lambda de forma síncrona. Além disso, o Amazon S3 Batch não é projetado para invocação síncrona de funções do Lambda."
        ]
    },
    {
        "Question Number": "16",
        "Situation": "Uma empresa de tecnologia está implantando uma nova versão de sua aplicação web usando AWS Elastic Beanstalk. A aplicação é crítica para transações de clientes, e a empresa deseja minimizar o tempo de inatividade durante o processo de implantação. Eles estão considerando várias políticas de implantação fornecidas pelo Elastic Beanstalk para alcançar seus objetivos.",
        "Question": "Quais políticas de implantação o Arquiteto de Soluções deve selecionar para garantir o mínimo de tempo de inatividade durante a implantação da aplicação? (Selecione duas)",
        "Options": {
            "1": "Blue/Green",
            "2": "RollingWithAdditionalBatch",
            "3": "Immutable",
            "4": "Rolling",
            "5": "AllAtOnce"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "RollingWithAdditionalBatch",
            "Immutable"
        ],
        "Explanation": "Tanto as políticas de implantação 'RollingWithAdditionalBatch' quanto 'Immutable' ajudam a manter a disponibilidade da aplicação durante as implantações. 'RollingWithAdditionalBatch' permite que um lote extra de instâncias seja lançado antes do início da implantação, garantindo que a capacidade seja mantida. 'Immutable' lança um novo conjunto de instâncias com a nova versão da aplicação em um grupo de Auto Scaling separado, garantindo que a versão antiga permaneça intacta até que as novas instâncias estejam prontas, proporcionando assim zero tempo de inatividade.",
        "Other Options": [
            "'AllAtOnce' implanta a nova versão em todas as instâncias simultaneamente, o que pode levar a tempo de inatividade se a implantação falhar ou se houver problemas com a nova versão.",
            "'Rolling' permite implantações padrão em rolling, mas não fornece o mesmo nível de garantia de capacidade que 'RollingWithAdditionalBatch', pois pode não ter instâncias adicionais prontas antes que as antigas sejam atualizadas.",
            "'Blue/Green' não é uma política de implantação direta no Elastic Beanstalk; em vez disso, refere-se a uma estratégia de implantação que envolve a troca de tráfego entre dois ambientes idênticos. Embora isso possa alcançar zero tempo de inatividade, não é categorizado como uma política de implantação dentro do Elastic Beanstalk em si."
        ]
    },
    {
        "Question Number": "17",
        "Situation": "Uma empresa de serviços financeiros depende de instâncias Amazon EC2 para suas cargas de trabalho de aplicação em um ambiente altamente regulamentado. A empresa precisa garantir que todas as instâncias EC2 sejam regularmente atualizadas para cumprir com os padrões de segurança. A equipe de segurança de TI criou uma política de gerenciamento de patches que especifica a frequência de atualização, tipos de patches e a necessidade de procedimentos de reversão. A empresa deseja automatizar a atualização de suas instâncias EC2 enquanto garante o mínimo de tempo de inatividade e conformidade com sua política de gerenciamento de patches.",
        "Question": "Qual é a melhor abordagem para a empresa automatizar a atualização de suas instâncias EC2 enquanto adere à sua política de gerenciamento de patches?",
        "Options": {
            "1": "Utilizar regras do AWS Config para monitorar a conformidade das instâncias EC2 com a política de gerenciamento de patches. Aplicar patches manualmente com base nos relatórios de conformidade gerados pelo AWS Config.",
            "2": "Implantar uma ferramenta de gerenciamento de patches de terceiros nas instâncias EC2 que se integra com os serviços da AWS para automatizar o processo de atualização e fornecer capacidades de relatórios.",
            "3": "Configurar uma função AWS Lambda que seja acionada em um cronograma para aplicar patches diretamente nas instâncias EC2 usando SSH. Implementar tratamento de erros para garantir que a função tente novamente em caso de falha.",
            "4": "Usar o AWS Systems Manager Patch Manager para automatizar a atualização de acordo com o cronograma de atualização definido. Configurar janelas de manutenção para especificar quando os patches devem ser aplicados. Garantir que a linha de base de patches inclua os patches necessários."
        },
        "Correct Answer": "Usar o AWS Systems Manager Patch Manager para automatizar a atualização de acordo com o cronograma de atualização definido. Configurar janelas de manutenção para especificar quando os patches devem ser aplicados. Garantir que a linha de base de patches inclua os patches necessários.",
        "Explanation": "Usar o AWS Systems Manager Patch Manager é a solução ideal para automatizar a atualização das instâncias EC2, pois se integra diretamente com os serviços da AWS, permite o agendamento de janelas de manutenção e fornece uma abordagem centralizada de gerenciamento de patches. Isso garante conformidade com a política de gerenciamento de patches da empresa enquanto minimiza o tempo de inatividade.",
        "Other Options": [
            "Configurar uma função AWS Lambda para gerenciar a atualização via SSH não é a melhor prática para automação, pois requer codificação personalizada, carece das funcionalidades de conformidade integradas do Systems Manager e pode introduzir riscos de segurança se as chaves SSH não forem gerenciadas corretamente.",
            "Utilizar regras do AWS Config para monitorar a conformidade é útil, mas não automatiza o processo de atualização em si. Ele apenas fornece visibilidade sobre o status de conformidade, o que significa que a intervenção manual ainda seria necessária para aplicar patches.",
            "Implantar uma ferramenta de gerenciamento de patches de terceiros pode adicionar complexidade e potenciais desafios de integração. Além disso, pode não fornecer o mesmo nível de integração com os serviços da AWS que o AWS Systems Manager, que é projetado especificamente para gerenciar recursos da AWS."
        ]
    },
    {
        "Question Number": "18",
        "Situation": "Uma empresa de serviços financeiros está desenvolvendo um novo aplicativo de banco online hospedado na AWS. O aplicativo precisa garantir alta disponibilidade e mínima perda de dados em caso de falhas, enquanto mantém baixa latência para os usuários finais em várias regiões.",
        "Question": "Qual das seguintes arquiteturas é a SOLUÇÃO MAIS EFETIVA para alcançar alta disponibilidade e recuperação de desastres para o aplicativo de banco online?",
        "Options": {
            "1": "Utilizar AWS Lambda para a lógica da aplicação e DynamoDB como banco de dados, ambos implantados em uma única região com throughput provisionado para lidar com cargas de pico.",
            "2": "Implementar um grupo de Auto Scaling de instâncias EC2 em várias Zonas de Disponibilidade em uma única região, usando Amazon Aurora com implantações Multi-AZ para o banco de dados e configurar o Route 53 para failover de DNS.",
            "3": "Criar uma arquitetura sem servidor usando AWS Fargate para gerenciamento de contêineres e Amazon S3 para armazenamento de dados, implantando tudo em várias Zonas de Disponibilidade dentro de uma única região.",
            "4": "Implantar o aplicativo em várias Regiões da AWS usando instâncias Amazon EC2 atrás de um Application Load Balancer. Usar Amazon RDS com Réplicas de Leitura em cada região e habilitar replicação entre regiões."
        },
        "Correct Answer": "Implantar o aplicativo em várias Regiões da AWS usando instâncias Amazon EC2 atrás de um Application Load Balancer. Usar Amazon RDS com Réplicas de Leitura em cada região e habilitar replicação entre regiões.",
        "Explanation": "Implantar o aplicativo em várias Regiões da AWS garante que o aplicativo permaneça disponível mesmo se uma região falhar. Usar instâncias EC2 com um Application Load Balancer ajuda a distribuir o tráfego de forma eficiente. Amazon RDS com Réplicas de Leitura em cada região fornece redundância de dados e acesso de baixa latência para usuários em diferentes regiões, enquanto a replicação entre regiões mitiga a perda de dados em caso de falha regional.",
        "Other Options": [
            "Usar AWS Lambda e DynamoDB em uma única região não fornece alta disponibilidade ou recuperação de desastres suficientes, pois carece de redundância entre regiões e é suscetível a interrupções regionais.",
            "Embora implementar um grupo de Auto Scaling com implantações Multi-AZ melhore a disponibilidade dentro de uma única região, não protege contra falhas regionais, o que é crítico para um aplicativo de serviços financeiros.",
            "Uma arquitetura sem servidor usando AWS Fargate e S3 em uma única região não é suficiente para alta disponibilidade e recuperação de desastres, pois carece da redundância entre regiões necessária para garantir mínimo tempo de inatividade e perda de dados."
        ]
    },
    {
        "Question Number": "19",
        "Situation": "Uma grande empresa de e-commerce está passando por um crescimento rápido e precisa redesenhar sua arquitetura para garantir escalabilidade e resiliência. A empresa visa acomodar padrões de tráfego flutuantes enquanto minimiza custos. Eles precisam de uma solução que possa ajustar automaticamente os recursos com base na demanda, sem intervenção manual, e que esteja alinhada com seus objetivos de negócios de manter alta disponibilidade e desempenho durante os períodos de pico de uso.",
        "Question": "Qual das seguintes arquiteturas atenderá melhor aos requisitos da empresa para uma solução elástica e econômica?",
        "Options": {
            "1": "Implementar grupos de autoescalonamento com instâncias EC2 atrás de um Application Load Balancer para lidar com o tráfego de entrada. Configurar políticas de escalonamento com base em métricas de utilização da CPU.",
            "2": "Configurar um serviço de orquestração de contêineres como Amazon ECS com um número fixo de tarefas em todos os nós para gerenciar o tráfego, garantindo que os recursos estejam sempre disponíveis.",
            "3": "Utilizar funções AWS Lambda para lidar com solicitações de entrada, escalonando automaticamente com o uso. Integrar o Amazon API Gateway para fornecer uma interface RESTful para o front end.",
            "4": "Implantar uma frota de instâncias EC2 com um tamanho fixo em várias Zonas de Disponibilidade para garantir alta disponibilidade. Usar o Route 53 para failover baseado em DNS sem escalonamento dinâmico."
        },
        "Correct Answer": "Implementar grupos de autoescalonamento com instâncias EC2 atrás de um Application Load Balancer para lidar com o tráfego de entrada. Configurar políticas de escalonamento com base em métricas de utilização da CPU.",
        "Explanation": "Esta opção fornece capacidades de escalonamento dinâmico, permitindo que a arquitetura se ajuste automaticamente com base na demanda em tempo real. Usar grupos de autoescalonamento com um Application Load Balancer garante que os recursos possam ser escalonados de forma eficiente para cima ou para baixo, proporcionando tanto resiliência quanto custo-efetividade durante flutuações de tráfego.",
        "Other Options": [
            "Esta opção não fornece capacidades de escalonamento dinâmico. Embora garanta alta disponibilidade ao espalhar instâncias por Zonas de Disponibilidade, não pode se ajustar a padrões de tráfego em mudança, levando a um potencial superdimensionamento e aumento de custos durante períodos de baixo tráfego.",
            "Usar funções AWS Lambda é uma solução escalável, mas esta opção não menciona o uso do Amazon API Gateway, que é essencial para uma interface RESTful bem definida. Além disso, pode não lidar com cargas de trabalho complexas tão eficientemente quanto instâncias EC2 em certos cenários.",
            "Esta opção não fornece escalonamento dinâmico. Embora o Amazon ECS possa gerenciar contêineres, ter um número fixo de tarefas limita a capacidade da arquitetura de responder ao tráfego flutuante, potencialmente levando a problemas de desempenho durante os períodos de pico."
        ]
    },
    {
        "Question Number": "20",
        "Situation": "Uma empresa de serviços financeiros está usando instâncias Amazon EC2 para executar seu aplicativo na nuvem. Eles notaram que algumas instâncias estão consistentemente subutilizadas enquanto outras estão operando em capacidade máxima. A equipe deseja analisar seus relatórios de uso para identificar quais recursos estão subutilizados e quais estão sendo superutilizados, a fim de otimizar custos e desempenho. Eles têm acesso às métricas do AWS CloudWatch e ao AWS Cost Explorer.",
        "Question": "Qual é a melhor abordagem para analisar os relatórios de uso e identificar instâncias EC2 subutilizadas e superutilizadas?",
        "Options": {
            "1": "Utilizar o AWS Trusted Advisor para revisar a utilização das instâncias e receber recomendações.",
            "2": "Analisar as métricas das instâncias EC2 no CloudWatch para identificar padrões de uso da CPU e da memória ao longo do tempo.",
            "3": "Usar o AWS Cost Explorer para avaliar os custos totais associados a cada instância e identificar anomalias.",
            "4": "Aproveitar o AWS Budgets para definir limites de gastos para cada instância EC2 e analisar os relatórios."
        },
        "Correct Answer": "Analisar as métricas das instâncias EC2 no CloudWatch para identificar padrões de uso da CPU e da memória ao longo do tempo.",
        "Explanation": "Analisar as métricas das instâncias EC2 no CloudWatch permite observar diretamente as métricas de desempenho, como utilização da CPU e da memória ao longo do tempo. Esses dados são críticos para determinar se as instâncias estão subutilizadas ou superutilizadas com base em padrões de uso reais, permitindo uma otimização eficaz dos recursos.",
        "Other Options": [
            "Embora o AWS Trusted Advisor forneça recomendações com base em melhores práticas e otimização de recursos, ele não fornece métricas detalhadas ao longo do tempo necessárias para a identificação precisa de instâncias subutilizadas ou superutilizadas.",
            "O AWS Cost Explorer é útil para entender os custos e tendências gerais, mas não fornece as métricas de uso específicas necessárias para avaliar efetivamente o desempenho de cada instância.",
            "O AWS Budgets ajuda a acompanhar os limites de gastos, mas não fornece as métricas de desempenho detalhadas necessárias para identificar subutilização ou superutilização das instâncias EC2."
        ]
    },
    {
        "Question Number": "21",
        "Situation": "Uma empresa está gerenciando uma frota de instâncias de contêiner Amazon ECS que requerem atualizações regulares de configuração e tarefas de manutenção. A equipe de operações deseja simplificar o processo de execução de comandos em várias instâncias de contêiner sem precisar fazer login em cada uma individualmente. Eles precisam de uma solução que forneça visibilidade sobre o status e os resultados desses comandos, garantindo acesso seguro às instâncias de contêiner.",
        "Question": "Qual serviço da AWS a equipe de operações deve usar para gerenciar eficientemente atualizações de configuração e tarefas administrativas em suas instâncias de contêiner ECS?",
        "Options": {
            "1": "Aproveitar o AWS CloudFormation para criar uma pilha que define o estado desejado das instâncias de contêiner ECS, garantindo que todas as configurações sejam aplicadas de forma consistente em toda a frota.",
            "2": "Utilizar o Amazon EventBridge para agendar tarefas que executem scripts localmente em cada instância de contêiner ECS para atualizações de configuração e tarefas administrativas.",
            "3": "Usar o AWS Systems Manager Run Command para executar comandos em várias instâncias de contêiner ECS simultaneamente, fornecendo uma visão centralizada do status da execução dos comandos e resultados.",
            "4": "Implementar funções AWS Lambda que sejam acionadas por eventos do CloudWatch para atualizar automaticamente as instâncias de contêiner ECS sempre que houver alterações de configuração."
        },
        "Correct Answer": "Usar o AWS Systems Manager Run Command para executar comandos em várias instâncias de contêiner ECS simultaneamente, fornecendo uma visão centralizada do status da execução dos comandos e resultados.",
        "Explanation": "O AWS Systems Manager Run Command permite gerenciar e automatizar tarefas administrativas em várias instâncias EC2 ou instâncias de contêiner ECS de forma segura e eficiente. Ele fornece uma interface centralizada para executar comandos e visualizar seu status, tornando-o ideal para o cenário apresentado.",
        "Other Options": [
            "O AWS CloudFormation é usado para infraestrutura como código e não fornece a capacidade direta de executar comandos ou gerenciar configurações em instâncias em execução existentes. Ele se concentra em provisionar e gerenciar recursos, em vez de executar comandos.",
            "As funções AWS Lambda são mais adequadas para arquiteturas orientadas a eventos. Embora possam ser usadas para acionar ações com base em eventos, não fornecem uma maneira direta de executar comandos em massa em várias instâncias ECS ou de fornecer visibilidade sobre os resultados da execução dos comandos.",
            "O Amazon EventBridge é um serviço de barramento de eventos sem servidor que pode ser usado para responder a eventos em seu ambiente AWS, mas não permite inherentemente a execução de comandos localmente em instâncias de contêiner ECS. Isso exigiria configuração adicional para executar scripts e carece dos recursos centralizados de execução de comandos e relatórios do Systems Manager."
        ]
    },
    {
        "Question Number": "22",
        "Situation": "Uma empresa de serviços financeiros está migrando suas aplicações para a AWS e precisa garantir que todos os dados sensíveis estejam criptografados tanto em repouso quanto em trânsito. A equipe está considerando vários serviços da AWS para uma gestão eficaz da criptografia, enquanto assegura a conformidade com os padrões da indústria. Eles desejam implementar uma solução que minimize a sobrecarga operacional na gestão de chaves de criptografia.",
        "Question": "Qual das seguintes estratégias a empresa deve adotar para implementar efetivamente a criptografia tanto para dados em repouso quanto para dados em trânsito?",
        "Options": {
            "1": "Utilizar o AWS CloudHSM para gerenciar chaves de criptografia e configurar a criptografia em nível de aplicação para dados em trânsito.",
            "2": "Usar o AWS Key Management Service (KMS) para gerenciar chaves de criptografia e habilitar a criptografia do lado do servidor do S3 com chaves KMS.",
            "3": "Implantar políticas de bucket do Amazon S3 para restringir o acesso e usar criptografia do lado do cliente para dados em repouso.",
            "4": "Habilitar a criptografia do Amazon RDS e usar SSL/TLS para proteger dados em trânsito sem gestão adicional de chaves."
        },
        "Correct Answer": "Usar o AWS Key Management Service (KMS) para gerenciar chaves de criptografia e habilitar a criptografia do lado do servidor do S3 com chaves KMS.",
        "Explanation": "Usar o AWS Key Management Service (KMS) simplifica a gestão de chaves de criptografia e permite uma fácil integração com os serviços da AWS. Habilitar a criptografia do lado do servidor do S3 com chaves KMS fornece criptografia forte para dados em repouso, enquanto também permite a conformidade com requisitos regulatórios. Essa abordagem efetivamente protege os dados tanto em repouso quanto em trânsito quando combinada com HTTPS.",
        "Other Options": [
            "Utilizar o AWS CloudHSM adiciona complexidade e sobrecarga operacional para a gestão de chaves, o que pode não ser necessário quando o AWS KMS pode fornecer uma solução mais simples. A criptografia em nível de aplicação também requer um esforço adicional de implementação.",
            "Habilitar a criptografia do Amazon RDS fornece proteção para dados em repouso, mas enquanto o SSL/TLS protege dados em trânsito, essa opção não aborda a gestão de chaves. Uma solução mais abrangente é necessária para ambos os aspectos.",
            "Implantar políticas de bucket do Amazon S3 pode restringir o acesso, mas não fornece criptografia para os dados em repouso em si. A criptografia do lado do cliente também coloca o ônus da gestão de chaves na aplicação, tornando-a menos eficiente."
        ]
    },
    {
        "Question Number": "23",
        "Situation": "Uma empresa de serviços financeiros requer uma arquitetura que possa se recuperar automaticamente de falhas. A arquitetura deve garantir que aplicações críticas estejam disponíveis com o mínimo de tempo de inatividade e possam gerenciar eficientemente a troca entre diferentes regiões. A empresa prefere uma solução que exija mínima intervenção manual e aproveite os serviços da AWS.",
        "Question": "Qual das seguintes soluções fornece o mecanismo de recuperação automática mais eficaz para as aplicações da empresa?",
        "Options": {
            "1": "Implantar aplicações em várias regiões da AWS e usar o Amazon Route 53 para configurar verificações de saúde e políticas de roteamento de failover. Configurar uma função AWS Lambda que acione backups do estado da aplicação em caso de falha.",
            "2": "Implementar uma arquitetura multi-região com o Amazon RDS para replicação de banco de dados. Usar o Amazon Route 53 para failover de DNS e configurar o Amazon CloudWatch para alertar quando qualquer instância de banco de dados se tornar não saudável.",
            "3": "Configurar o AWS Elastic Load Balancing em várias Zonas de Disponibilidade em uma única região. Usar instâncias do Amazon EC2 com verificações de saúde para garantir que o tráfego seja roteado apenas para instâncias saudáveis.",
            "4": "Usar o Amazon EC2 Auto Scaling para garantir que haja sempre um número mínimo de instâncias saudáveis em execução em uma única região. Configurar alarmes do CloudWatch para monitorar as instâncias e substituir automaticamente quaisquer instâncias não saudáveis."
        },
        "Correct Answer": "Implantar aplicações em várias regiões da AWS e usar o Amazon Route 53 para configurar verificações de saúde e políticas de roteamento de failover. Configurar uma função AWS Lambda que acione backups do estado da aplicação em caso de falha.",
        "Explanation": "Esta opção fornece o mecanismo de recuperação automática mais abrangente ao aproveitar a implantação multi-região, o que aumenta a disponibilidade e resiliência. O uso de verificações de saúde do Route 53 permite uma troca sem interrupções em caso de falhas específicas de região, enquanto a função Lambda garante que o estado da aplicação seja preservado e recuperável.",
        "Other Options": [
            "Esta opção depende exclusivamente do Auto Scaling dentro de uma única região, o que não fornece redundância geográfica e pode não lidar efetivamente com falhas regionais.",
            "Embora esta opção envolva uma configuração multi-região, ela se concentra principalmente na replicação de banco de dados e não aborda suficientemente os mecanismos de failover em nível de aplicação para uma recuperação abrangente de desastres.",
            "Esta opção é limitada a uma única região e se concentra no balanceamento de carga entre Zonas de Disponibilidade. Ela carece das provisões necessárias para recuperação automática em caso de falha em toda a região, tornando-a menos eficaz para os requisitos da empresa."
        ]
    },
    {
        "Question Number": "24",
        "Situation": "Uma empresa de serviços financeiros está planejando migrar suas aplicações legadas para a AWS. Essas aplicações consistem em múltiplos componentes que precisam ser analisados quanto a dependências e utilização de recursos. A empresa deseja garantir uma transição suave para a nuvem com mínima interrupção nas operações comerciais em andamento. Eles estão considerando várias ferramentas da AWS para auxiliar no processo de descoberta e migração.",
        "Question": "Qual das seguintes ferramentas seria mais eficaz na identificação das dependências e utilização de recursos das aplicações legadas existentes durante a fase de planejamento da migração?",
        "Options": {
            "1": "AWS Application Discovery Service para coletar e analisar dados sobre aplicações locais, incluindo sua utilização de recursos e dependências.",
            "2": "AWS CloudTrail para monitorar chamadas de API e atividade do usuário dentro da conta da AWS após a migração.",
            "3": "AWS Config para rastrear configurações de recursos e conformidade para as aplicações pós-migração.",
            "4": "AWS Systems Manager para gerenciar e automatizar operações de aplicações no ambiente AWS após a migração."
        },
        "Correct Answer": "AWS Application Discovery Service para coletar e analisar dados sobre aplicações locais, incluindo sua utilização de recursos e dependências.",
        "Explanation": "O AWS Application Discovery Service é especificamente projetado para ajudar organizações a planejar sua migração para a AWS, identificando automaticamente dependências de aplicações e utilização de recursos. Isso permite uma estratégia de migração mais informada.",
        "Other Options": [
            "O AWS CloudTrail é focado em registrar e monitorar a atividade de API na sua conta da AWS, o que não forneceria insights sobre dependências de aplicações locais ou utilização de recursos antes da migração.",
            "O AWS Config é usado para monitorar e gerenciar configurações de recursos da AWS, mas não é aplicável para analisar aplicações legadas antes da migração.",
            "O AWS Systems Manager é usado principalmente para gerenciar e operar aplicações na AWS, e embora forneça valiosas capacidades de gestão pós-migração, não auxilia na descoberta de dependências de aplicações locais."
        ]
    },
    {
        "Question Number": "25",
        "Situation": "Uma empresa de serviços financeiros está planejando migrar suas aplicações legadas locais para a AWS. A empresa possui várias cargas de trabalho, algumas das quais são críticas para as operações comerciais, enquanto outras são menos urgentes. Uma equipe de migração foi formada e eles precisam priorizar quais cargas de trabalho migrar primeiro. Eles querem garantir uma interrupção mínima nos negócios e maximizar os benefícios da nuvem.",
        "Question": "Qual é a abordagem mais eficaz para a equipe de migração priorizar as cargas de trabalho para migração para a AWS?",
        "Options": {
            "1": "Priorizar cargas de trabalho com base no impacto nos negócios e na complexidade da migração.",
            "2": "Migrar cargas de trabalho em ordem alfabética para manter a consistência.",
            "3": "Começar com as cargas de trabalho menos críticas para testar o processo de migração.",
            "4": "Migrar todas as cargas de trabalho de uma vez para minimizar o tempo de inatividade geral."
        },
        "Correct Answer": "Priorizar cargas de trabalho com base no impacto nos negócios e na complexidade da migração.",
        "Explanation": "Essa abordagem permite que a equipe de migração se concentre primeiro nas aplicações mais críticas, garantindo que os serviços mais importantes estejam funcionando bem no ambiente da nuvem. Também ajuda a identificar quaisquer desafios potenciais no processo de migração desde o início, permitindo um melhor planejamento para o futuro.",
        "Other Options": [
            "Essa opção pode resultar em um tempo de inatividade significativo, pois migrar todas as cargas de trabalho de uma vez pode sobrecarregar os recursos e levar a falhas potenciais.",
            "Migrar em ordem alfabética não considera as necessidades reais dos negócios ou a complexidade das aplicações, o que pode levar a interrupções e ineficiências.",
            "Começar com as cargas de trabalho menos críticas pode atrasar a realização dos benefícios da nuvem e pode levar a riscos desnecessários para os negócios, já que cargas de trabalho mais críticas ficam sem atenção."
        ]
    },
    {
        "Question Number": "26",
        "Situation": "Uma empresa de serviços financeiros está buscando aprimorar sua infraestrutura adotando novas tecnologias e serviços gerenciados para melhorar a eficiência operacional e reduzir custos. A empresa identificou várias áreas onde poderia aproveitar soluções nativas da nuvem, mas carece de uma estratégia clara para a implementação. Eles estão considerando opções para modernizar sua arquitetura enquanto garantem conformidade e segurança.",
        "Question": "Qual abordagem a empresa deve adotar para efetivamente adotar novas tecnologias e serviços gerenciados enquanto minimiza riscos?",
        "Options": {
            "1": "Realizar uma avaliação completa das cargas de trabalho atuais e identificar casos de uso específicos onde serviços gerenciados podem substituir a infraestrutura tradicional, seguida de um plano de implementação em fases.",
            "2": "Migrar todas as aplicações existentes para arquiteturas sem servidor imediatamente para aproveitar as capacidades da nuvem sem uma avaliação detalhada.",
            "3": "Implementar uma estratégia de multi-nuvem distribuindo cargas de trabalho entre vários provedores de nuvem para evitar o bloqueio de fornecedor, mesmo que isso complique a gestão.",
            "4": "Adotar uma estratégia de lift-and-shift para todas as aplicações na nuvem sem redesenhá-las, garantindo mudanças mínimas em sua infraestrutura atual."
        },
        "Correct Answer": "Realizar uma avaliação completa das cargas de trabalho atuais e identificar casos de uso específicos onde serviços gerenciados podem substituir a infraestrutura tradicional, seguida de um plano de implementação em fases.",
        "Explanation": "Realizar uma avaliação completa permite que a empresa entenda suas cargas de trabalho atuais e identifique áreas específicas que se beneficiariam de serviços gerenciados. Essa abordagem reduz os riscos associados a uma migração apressada e possibilita uma implementação estruturada e em fases que se alinha com os objetivos de negócios.",
        "Other Options": [
            "Migrar todas as aplicações existentes para arquiteturas sem servidor imediatamente sem avaliação pode levar a problemas inesperados, incompatibilidades e custos aumentados, já que nem todas as aplicações são adequadas para modelos sem servidor.",
            "Implementar uma estratégia de multi-nuvem sem uma necessidade clara pode complicar a gestão, aumentar a sobrecarga operacional e introduzir desafios em segurança e conformidade sem fornecer benefícios imediatos.",
            "Uma estratégia de lift-and-shift frequentemente leva a um desempenho subótimo e ineficiências de custo, já que as aplicações podem não estar totalmente otimizadas para ambientes de nuvem, perdendo os benefícios das características nativas da nuvem."
        ]
    },
    {
        "Question Number": "27",
        "Situation": "Uma empresa está avaliando quais tipos de instâncias EC2 são mais adequados para suas diferentes cargas de trabalho. Eles têm uma aplicação web que requer alto desempenho de I/O, um modelo de aprendizado de máquina que precisa de alta capacidade computacional e um banco de dados que necessita de uma capacidade significativa de memória para cache.",
        "Question": "Qual combinação de famílias de instâncias atenderia melhor às necessidades das cargas de trabalho da empresa? (Selecione Dois)",
        "Options": {
            "1": "Instâncias T3 para desempenho burstable.",
            "2": "Instâncias C5 para cargas de trabalho intensivas em computação.",
            "3": "Instâncias I3 para alto desempenho de I/O.",
            "4": "Instâncias M5 para cargas de trabalho de uso geral.",
            "5": "Instâncias R5 para cargas de trabalho intensivas em memória."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Instâncias I3 para alto desempenho de I/O.",
            "Instâncias C5 para cargas de trabalho intensivas em computação."
        ],
        "Explanation": "As instâncias I3 são otimizadas para alto desempenho de I/O, tornando-as ideais para cargas de trabalho que requerem acesso rápido ao armazenamento. As instâncias C5 são projetadas para tarefas intensivas em computação, fornecendo um alto nível de poder de processamento, que é adequado para modelos de aprendizado de máquina e outras aplicações que exigem muita computação.",
        "Other Options": [
            "As instâncias R5 são otimizadas para memória, o que não é o requisito principal para alto desempenho de I/O ou tarefas intensivas em computação especificadas na situação.",
            "As instâncias T3 oferecem desempenho burstable adequado para cargas de trabalho variáveis, mas não fornecem as capacidades necessárias de I/O ou computação exigidas pelas aplicações especificadas.",
            "As instâncias M5 são de uso geral e não seriam a melhor opção para cargas de trabalho que exigem capacidades especializadas de I/O ou computacionais, conforme mencionado."
        ]
    },
    {
        "Question Number": "28",
        "Situation": "Uma empresa está buscando otimizar seus custos na AWS implementando uma estratégia de etiquetagem que permita uma melhor visibilidade sobre o uso de recursos na nuvem. A empresa possui várias unidades de negócios, cada uma com orçamentos e requisitos de recursos diferentes. Você precisa garantir que os recursos sejam etiquetados de uma maneira que esteja alinhada com essas unidades de negócios e facilite o rastreamento de custos.",
        "Question": "Qual das seguintes opções pode ajudá-lo a implementar uma estratégia de etiquetagem eficaz para alocação de custos? (Selecione duas)",
        "Options": {
            "1": "Criar uma política de etiquetagem que exija o uso de etiquetas específicas para todos os recursos relacionados a cada unidade de negócios.",
            "2": "Implementar o AWS Cost Explorer para analisar os custos associados a etiquetas específicas.",
            "3": "Usar o AWS Budgets para monitorar gastos por unidade de negócios sem exigir etiquetas.",
            "4": "Utilizar o AWS CloudTrail para rastrear chamadas de API relacionadas à criação e etiquetagem de recursos.",
            "5": "Impor conformidade de etiquetagem usando regras do AWS Config que avaliam as etiquetas dos recursos."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Criar uma política de etiquetagem que exija o uso de etiquetas específicas para todos os recursos relacionados a cada unidade de negócios.",
            "Implementar o AWS Cost Explorer para analisar os custos associados a etiquetas específicas."
        ],
        "Explanation": "Criar uma política de etiquetagem garante que todos os recursos sejam etiquetados de forma consistente de acordo com as unidades de negócios, facilitando o rastreamento eficaz dos custos. O AWS Cost Explorer permite que você analise os custos com base nas etiquetas que você define, proporcionando visibilidade sobre os gastos por unidade de negócios.",
        "Other Options": [
            "O AWS Budgets pode monitorar gastos, mas não exige etiquetas para seu funcionamento, tornando-o menos eficaz para implementar uma estratégia de etiquetagem.",
            "O AWS CloudTrail é útil para auditoria de chamadas de API, mas não contribui diretamente para estratégias de etiquetagem ou alocação de custos.",
            "As regras do AWS Config podem impor conformidade de etiquetagem, mas não ajudam na análise real dos custos associados a essas etiquetas."
        ]
    },
    {
        "Question Number": "29",
        "Situation": "Uma organização de serviços financeiros está migrando suas aplicações para a AWS. A organização requer um método seguro para gerenciar identidades de usuários e permissões de acesso em várias contas da AWS. Eles desejam implementar uma solução que permita que os usuários tenham acesso de single sign-on (SSO) a vários serviços da AWS, mantendo controle de acesso detalhado. A organização já está usando um diretório corporativo para gerenciamento de usuários.",
        "Question": "Qual das seguintes abordagens atenderia melhor aos requisitos da organização para gerenciar o acesso dos usuários em várias contas da AWS?",
        "Options": {
            "1": "Criar usuários IAM em cada conta da AWS e gerenciar manualmente suas permissões de acesso. Usar o AWS Organizations para consolidar a cobrança.",
            "2": "Utilizar funções IAM da AWS e estabelecer acesso a funções entre contas para cada usuário, exigindo gerenciamento manual de credenciais para cada usuário.",
            "3": "Configurar o AWS IAM Identity Center (AWS SSO) e conectá-lo ao diretório corporativo. Criar conjuntos de permissões para definir os níveis de acesso dos usuários em várias contas da AWS.",
            "4": "Implantar uma solução de federação de identidade usando o AWS Cognito para gerenciar identidades de usuários e permissões de acesso em várias contas da AWS."
        },
        "Correct Answer": "Configurar o AWS IAM Identity Center (AWS SSO) e conectá-lo ao diretório corporativo. Criar conjuntos de permissões para definir os níveis de acesso dos usuários em várias contas da AWS.",
        "Explanation": "Usar o AWS IAM Identity Center (AWS SSO) permite o gerenciamento centralizado de identidades de usuários e permissões de acesso em várias contas com capacidades de single sign-on, o que se alinha diretamente com os requisitos da organização para segurança e facilidade de uso.",
        "Other Options": [
            "Criar usuários IAM em cada conta é ineficiente e não fornece uma solução de gerenciamento centralizado. Essa abordagem aumenta a sobrecarga administrativa e a complexidade, pois as permissões devem ser gerenciadas separadamente em cada conta.",
            "Embora o AWS Cognito possa gerenciar identidades de usuários, ele é projetado principalmente para aplicações web e móveis e não fornece o mesmo nível de integração e gerenciamento para acesso aos serviços da AWS em várias contas como o AWS IAM Identity Center.",
            "Usar funções IAM para acesso entre contas exige que os usuários gerenciem suas próprias credenciais e não fornece uma experiência SSO simples. Essa abordagem pode levar a riscos de segurança e aumentar a complexidade no gerenciamento de credenciais."
        ]
    },
    {
        "Question Number": "30",
        "Situation": "Uma empresa de serviços financeiros opera várias contas da AWS para gerenciar suas diversas unidades de negócios. Cada conta requer a capacidade de receber notificações de eventos de um tópico centralizado do Amazon SNS quando recursos específicos da AWS são modificados. O arquiteto de soluções precisa garantir que as notificações de eventos sejam entregues a todas as contas relevantes, enquanto adere às melhores práticas de segurança e gerenciamento.",
        "Question": "Qual é a maneira mais eficaz de configurar notificações de eventos em várias contas usando os serviços da AWS?",
        "Options": {
            "1": "Utilizar o AWS Lambda na conta principal para consultar eventos de cada conta membro e, em seguida, publicar esses eventos em um tópico centralizado do Amazon SNS.",
            "2": "Implantar um barramento de eventos do Amazon EventBridge em cada conta membro e configurar uma regra para enviar eventos a um tópico do Amazon SNS na conta principal.",
            "3": "Criar um tópico do Amazon SNS na conta principal e configurar permissões entre contas para cada conta membro permitir que elas se inscrevam no tópico.",
            "4": "Configurar regras do AWS Config em cada conta membro que acionem uma AWS Step Function para enviar notificações a um tópico do Amazon SNS na conta principal."
        },
        "Correct Answer": "Criar um tópico do Amazon SNS na conta principal e configurar permissões entre contas para cada conta membro permitir que elas se inscrevam no tópico.",
        "Explanation": "Criar um tópico do Amazon SNS na conta principal e configurar permissões entre contas permite que todas as contas membros se inscrevam de forma segura no tópico centralizado. Essa abordagem simplifica o processo de notificação e adere às melhores práticas para arquiteturas de várias contas.",
        "Other Options": [
            "Implantar um barramento de eventos do Amazon EventBridge em cada conta membro adiciona complexidade desnecessária, uma vez que o objetivo é centralizar as notificações na conta principal. Essa opção exigiria configurações adicionais para o encaminhamento de eventos.",
            "Usar o AWS Lambda para consultar eventos de cada conta membro cria sobrecarga e pode levar a atrasos e custos aumentados. Usar diretamente o SNS com inscrições entre contas é mais eficiente.",
            "Configurar regras do AWS Config gera eventos para alterações de recursos, mas não facilita diretamente as notificações. Essa opção carece da integração direta e eficiência proporcionadas por um tópico SNS."
        ]
    },
    {
        "Question Number": "31",
        "Situation": "Uma startup executa uma aplicação web em instâncias do Amazon EC2 que experimentam cargas de trabalho variáveis ao longo do dia. A startup está preocupada em reduzir custos enquanto garante que a aplicação permaneça responsiva durante os horários de pico. Atualmente, eles usam Instâncias Sob Demanda, mas querem explorar opções mais econômicas sem sacrificar o desempenho.",
        "Question": "Qual escolha de arquitetura o arquiteto de soluções deve recomendar para otimizar custos enquanto mantém o desempenho da aplicação?",
        "Options": {
            "1": "Migrar a aplicação para o AWS Lambda para evitar a provisão de instâncias EC2 completamente e aproveitar a precificação sem servidor.",
            "2": "Implantar todas as instâncias EC2 como Instâncias Sob Demanda e aumentar os tamanhos das instâncias durante os horários de pico para lidar com o tráfego.",
            "3": "Usar Instâncias Reservadas para todas as instâncias EC2 para garantir que a aplicação esteja sempre disponível a um custo mais baixo.",
            "4": "Implementar Auto Scaling com uma combinação de Instâncias Sob Demanda e Instâncias Spot, permitindo economias de custos durante os horários fora de pico."
        },
        "Correct Answer": "Implementar Auto Scaling com uma combinação de Instâncias Sob Demanda e Instâncias Spot, permitindo economias de custos durante os horários fora de pico.",
        "Explanation": "Usar Auto Scaling com uma combinação de Instâncias Sob Demanda e Instâncias Spot permite que a startup se adapte dinamicamente às mudanças na carga de trabalho enquanto alcança economias significativas de custos ao aproveitar as Instâncias Spot de menor custo durante períodos de menor demanda.",
        "Other Options": [
            "Migrar a aplicação para o AWS Lambda pode não ser viável se a aplicação exigir estado persistente ou tiver processos de longa duração, já que o Lambda é mais adequado para tarefas de curta duração e orientadas a eventos.",
            "Usar Instâncias Reservadas para todas as instâncias EC2 compromete a startup a um compromisso de longo prazo, o que pode não ser ideal dada a sua carga de trabalho variável e situação financeira.",
            "Implantar todas as instâncias EC2 como Instâncias Sob Demanda sem considerar Instâncias Spot ou Auto Scaling provavelmente levará a custos mais altos e não fornecerá a flexibilidade necessária durante os horários de pico e fora de pico."
        ]
    },
    {
        "Question Number": "32",
        "Situation": "Uma empresa de serviços financeiros está buscando migrar sua carga de trabalho local para a AWS. A arquitetura atual consiste em uma aplicação monolítica executando em servidores dedicados, que é difícil de escalar e manter. A empresa tem um requisito rigoroso de conformidade para integridade e segurança dos dados. Eles estão avaliando vários serviços da AWS que podem suportar uma estratégia de migração gradual e garantir mínima interrupção nas operações comerciais.",
        "Question": "Qual das seguintes opções o arquiteto de soluções deve recomendar para migrar as cargas de trabalho existentes para a AWS, abordando os requisitos de escalabilidade e conformidade?",
        "Options": {
            "1": "Levantar e transferir toda a aplicação para instâncias do Amazon EC2 enquanto implementa o AWS Shield para segurança adicional.",
            "2": "Reestruturar a aplicação usando o AWS Elastic Beanstalk com um bucket do Amazon S3 para distribuição de conteúdo estático.",
            "3": "Refatorar a aplicação em microserviços usando o AWS Lambda, com dados armazenados no Amazon RDS para integridade transacional.",
            "4": "Containerizar a aplicação usando o Amazon ECS e implantá-la com o Amazon EFS para acesso a armazenamento compartilhado."
        },
        "Correct Answer": "Refatorar a aplicação em microserviços usando o AWS Lambda, com dados armazenados no Amazon RDS para integridade transacional.",
        "Explanation": "Refatorar a aplicação em microserviços usando o AWS Lambda permite melhor escalabilidade e flexibilidade. Ao usar o Amazon RDS, a empresa pode garantir que atende aos requisitos de integridade e conformidade dos dados, enquanto também aproveita a arquitetura sem servidor para eficiência de custos e redução da carga operacional.",
        "Other Options": [
            "Levantar e transferir não aborda os problemas de escalabilidade e manutenção inerentes a uma arquitetura monolítica, e confiar apenas no AWS Shield não garante conformidade com os requisitos de integridade dos dados.",
            "Embora usar o AWS Elastic Beanstalk possa simplificar a implantação, pode não aproveitar totalmente os benefícios da arquitetura sem servidor, o que poderia limitar a escalabilidade e flexibilidade para uma aplicação em crescimento.",
            "Containerizar a aplicação com o Amazon ECS introduz complexidade relacionada à gestão e orquestração de contêineres, o que pode não estar alinhado com o objetivo de uma estratégia de migração gradual."
        ]
    },
    {
        "Question Number": "33",
        "Situation": "Uma empresa de serviços financeiros está implementando uma estratégia de recuperação de desastres (DR) para suas aplicações críticas hospedadas no Amazon EC2. Eles precisam de uma solução que garanta mínima inatividade e perda de dados em caso de desastre. A empresa está considerando várias opções para alcançar uma arquitetura de DR resiliente.",
        "Question": "Qual estratégia de recuperação de desastres o Arquiteto de Soluções deve recomendar para garantir a maior disponibilidade com mínima perda de dados?",
        "Options": {
            "1": "Configurar uma arquitetura de espera quente com uma instância EC2 executando em outra região que pode ser rapidamente escalada durante um desastre.",
            "2": "Implementar uma configuração ativa-ativa em várias regiões da AWS usando o Amazon Route 53 para distribuição de tráfego.",
            "3": "Usar o Amazon S3 para armazenamento de backup e definir uma política de ciclo de vida para excluir backups antigos após um período definido.",
            "4": "Implantar uma estratégia de DR de luz piloto mantendo uma pegada mínima da aplicação em uma região secundária que pode ser rapidamente ativada."
        },
        "Correct Answer": "Implementar uma configuração ativa-ativa em várias regiões da AWS usando o Amazon Route 53 para distribuição de tráfego.",
        "Explanation": "Uma configuração ativa-ativa garante que a aplicação esteja totalmente operacional em várias regiões, proporcionando assim a maior disponibilidade e minimizando a inatividade. Essa configuração permite a distribuição de tráfego e balanceamento de carga sem interrupções usando o Amazon Route 53, resultando em uma solução robusta de recuperação de desastres.",
        "Other Options": [
            "Usar o Amazon S3 para armazenamento de backup e implementar uma política de ciclo de vida não fornece capacidades imediatas de failover. Embora seja essencial para retenção de dados, não minimiza a inatividade durante um desastre, que é um requisito crítico.",
            "Uma arquitetura de espera quente envolve manter uma versão reduzida da aplicação que pode ser rapidamente escalada, mas ainda pode levar a alguma inatividade. Essa abordagem não garante o mesmo nível de disponibilidade que uma configuração ativa-ativa.",
            "Uma estratégia de DR de luz piloto requer mais tempo para ativar completamente o ambiente secundário em comparação com uma configuração ativa-ativa. Embora seja uma abordagem econômica, não fornece a disponibilidade imediata necessária durante um desastre, levando a potencial perda de dados e interrupção do serviço."
        ]
    },
    {
        "Question Number": "34",
        "Situation": "Uma empresa está implantando uma aplicação altamente disponível na AWS que requer baixa latência e alta taxa de transferência. Eles estão considerando usar o Elastic Load Balancing para distribuir o tráfego de entrada entre múltiplos alvos. A aplicação será acessada de várias localizações geográficas, e a empresa precisa garantir que o tráfego seja roteado de forma eficiente. Eles também desejam configurar endereços IP estáticos para melhor integração com sua rede local.",
        "Question": "Qual combinação de recursos a empresa deve aproveitar para atender a esses requisitos? (Selecione Dois)",
        "Options": {
            "1": "Implantar um Application Load Balancer para lidar apenas com conexões WebSocket.",
            "2": "Implementar um Network Load Balancer com endereços IP estáticos em cada Zona de Disponibilidade.",
            "3": "Usar um Application Load Balancer com sessões persistentes configuradas.",
            "4": "Utilizar o Network Load Balancer para criar um serviço de endpoint VPC.",
            "5": "Configurar o Network Load Balancer para usar grupos de segurança para controle de tráfego de entrada."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Implementar um Network Load Balancer com endereços IP estáticos em cada Zona de Disponibilidade.",
            "Utilizar o Network Load Balancer para criar um serviço de endpoint VPC."
        ],
        "Explanation": "Implementar um Network Load Balancer com endereços IP estáticos permite que a empresa mantenha endereços IP conhecidos para uma conectividade mais fácil a partir de sua rede local, enquanto usar o Network Load Balancer para um serviço de endpoint VPC garante o roteamento eficiente do tráfego para seus alvos de aplicação dentro da VPC.",
        "Other Options": [
            "Usar um Application Load Balancer com sessões persistentes não é adequado porque o requisito especifica a necessidade de endereços IP estáticos e alta taxa de transferência, que são melhor atendidos por um Network Load Balancer.",
            "Implantar um Application Load Balancer apenas para conexões WebSocket não aborda a necessidade de IPs estáticos e pode não fornecer o melhor desempenho para todos os tipos de tráfego.",
            "Configurar o Network Load Balancer para usar grupos de segurança está incorreto porque os Network Load Balancers não suportam grupos de segurança, pois operam no nível de conexão e não no nível de instância."
        ]
    },
    {
        "Question Number": "35",
        "Situation": "Uma empresa está usando o AWS CloudFormation para gerenciar sua infraestrutura. A empresa deseja armazenar informações sensíveis, como senhas de banco de dados e chaves de API, de forma segura, sem codificá-las nos templates. Eles decidem utilizar o Systems Manager Parameter Store para alcançar isso. O arquiteto de soluções precisa referenciar esses parâmetros no template do CloudFormation.",
        "Question": "Qual das seguintes configurações no template do CloudFormation referenciaria corretamente um parâmetro do Systems Manager?",
        "Options": {
            "1": "Parameters: MyParameter: Type: AWS::SSM::Parameter::Value<String> Default: /myapp/dbpassword",
            "2": "Parameters: MyParameter: Type: AWS::SSM::Parameter::Value<String> Value: /myapp/dbpassword",
            "3": "Parameters: MyParameter: Type: AWS::SSM::Parameter::Value<String>",
            "4": "Parameters: MyParameter: Type: String Default: /myapp/dbpassword"
        },
        "Correct Answer": "Parameters: MyParameter: Type: AWS::SSM::Parameter::Value<String> Default: /myapp/dbpassword",
        "Explanation": "A opção correta usa a sintaxe apropriada para definir um parâmetro do Systems Manager no CloudFormation. Ela especifica o tipo corretamente como AWS::SSM::Parameter::Value<String> e fornece um valor padrão válido, o que permite que o CloudFormation busque o parâmetro do Parameter Store.",
        "Other Options": [
            "Esta opção está incorreta porque não especifica um valor padrão, que é necessário para o CloudFormation recuperar o parâmetro do Systems Manager.",
            "Esta opção está incorreta porque, embora especifique o tipo corretamente, não define um valor padrão. A ausência de um valor padrão significa que o CloudFormation não pode buscar o parâmetro.",
            "Esta opção está incorreta porque a chave 'Value' não é válida neste contexto. Em vez disso, a abordagem correta é usar 'Default' para especificar a chave do parâmetro."
        ]
    },
    {
        "Question Number": "36",
        "Situation": "Uma organização está planejando migrar seu banco de dados Oracle local para o Amazon RDS para Oracle. O banco de dados possui vários recursos que são críticos para as operações da organização. O administrador de banco de dados precisa garantir que todos os recursos necessários sejam suportados no ambiente RDS.",
        "Question": "Qual dos seguintes recursos do Oracle Database NÃO é suportado ao usar o Amazon RDS para Oracle?",
        "Options": {
            "1": "Real Application Clusters (Oracle RAC)",
            "2": "Automatic Storage Management (ASM)",
            "3": "Integração com o Amazon S3 para transferência de dados",
            "4": "Replicação entre Regiões para MySQL"
        },
        "Correct Answer": "Real Application Clusters (Oracle RAC)",
        "Explanation": "O Amazon RDS para Oracle não suporta Real Application Clusters (Oracle RAC). Esta é uma limitação chave a ser considerada ao migrar um banco de dados Oracle, já que o RAC é projetado para fornecer alta disponibilidade e escalabilidade por meio de recursos de clustering, que não estão disponíveis no RDS.",
        "Other Options": [
            "Automatic Storage Management (ASM) não é suportado no Amazon RDS para Oracle, mas esta opção não é explicitamente declarada, pois a pergunta pede um recurso que é suportado. Portanto, esta opção é enganosa.",
            "A replicação entre regiões para MySQL é um recurso que é suportado no RDS, mas não está relacionado a bancos de dados Oracle e, portanto, não aborda o foco da pergunta sobre recursos do Oracle.",
            "A integração com o Amazon S3 para transferência de dados é um recurso suportado do Amazon RDS para Oracle, permitindo transferências de dados seguras e eficientes, tornando esta opção incorreta, pois não se alinha com a pergunta."
        ]
    },
    {
        "Question Number": "37",
        "Situation": "Uma empresa de mídia usa o Amazon S3 para armazenar imagens e arquivos de vídeo. Eles ativaram o versionamento em seu bucket S3 para manter várias versões de seus arquivos de mídia. O arquiteto de soluções precisa garantir que a empresa possa recuperar arquivos excluídos e gerenciar versões de forma eficaz, enquanto implementa medidas de segurança adequadas.",
        "Question": "Quando um arquivo chamado video.mp4 é carregado em um bucket S3 com versionamento ativado que já contém uma versão do mesmo arquivo, qual das seguintes afirmações é verdadeira em relação ao tratamento da versão anterior e ao novo upload?",
        "Options": {
            "1": "Uma nova versão de video.mp4 é criada, e a versão anterior permanece no bucket sem ser sobrescrita.",
            "2": "A operação de upload falha se uma versão anterior existir no bucket.",
            "3": "O marcador de exclusão é aplicado à versão anterior de video.mp4, tornando-a a versão atual.",
            "4": "A versão anterior de video.mp4 é excluída permanentemente e não pode ser recuperada."
        },
        "Correct Answer": "Uma nova versão de video.mp4 é criada, e a versão anterior permanece no bucket sem ser sobrescrita.",
        "Explanation": "Em um bucket S3 com versionamento ativado, o upload de uma nova versão de um objeto existente não exclui nem sobrescreve a versão anterior. Em vez disso, um novo ID de versão é atribuído ao novo upload, enquanto a versão mais antiga permanece acessível no bucket.",
        "Other Options": [
            "Esta opção está incorreta porque o versionamento permite a retenção de versões anteriores quando novos uploads ocorrem, impedindo qualquer exclusão permanente, a menos que solicitado especificamente.",
            "Esta opção está incorreta porque a operação de upload em um bucket versionado sempre terá sucesso, independentemente de uma versão anterior existir para a mesma chave.",
            "Esta opção está incorreta porque um marcador de exclusão é aplicado apenas quando um objeto é explicitamente excluído, não quando uma nova versão é carregada."
        ]
    },
    {
        "Question Number": "38",
        "Situation": "Uma empresa de serviços financeiros está construindo um novo aplicativo que requer processamento de transações em tempo real e análises. O aplicativo deve lidar eficientemente com altos volumes de dados com baixa latência, enquanto também garante que os dados possam ser facilmente consultados para fins de relatórios. O arquiteto de soluções está avaliando várias opções de banco de dados para atender a esses requisitos.",
        "Question": "Qual das seguintes soluções de banco de dados é a mais adequada para implementar um sistema de processamento de transações em tempo real com capacidades de consulta eficientes?",
        "Options": {
            "1": "Amazon RDS para MySQL com réplicas de leitura para lidar com alta taxa de transferência e fornecer baixa latência para análises em tempo real.",
            "2": "Amazon Redshift para armazenamento de dados, otimizado para consultas complexas, mas não adequado para processamento de transações em tempo real.",
            "3": "Amazon DynamoDB com taxa de transferência provisionada para garantir acesso de baixa latência para transações em tempo real e alta disponibilidade para análises.",
            "4": "Amazon Aurora com compatibilidade com PostgreSQL, utilizando suas capacidades serverless para escalar para altos volumes de transações enquanto mantém o desempenho das consultas."
        },
        "Correct Answer": "Amazon Aurora com compatibilidade com PostgreSQL, utilizando suas capacidades serverless para escalar para altos volumes de transações enquanto mantém o desempenho das consultas.",
        "Explanation": "Amazon Aurora com compatibilidade com PostgreSQL é projetado para alto desempenho e pode lidar com processamento de transações em tempo real de forma eficiente. Suas capacidades serverless permitem escalonamento automático com base na demanda, garantindo que possa acomodar altos volumes de transações enquanto mantém baixa latência para consultas, tornando-o ideal para este cenário.",
        "Other Options": [
            "Amazon RDS para MySQL com réplicas de leitura não é a melhor escolha para processamento de transações em tempo real, pois introduz latência devido ao atraso de replicação para análises e pode não escalar tão efetivamente quanto o Aurora.",
            "Amazon DynamoDB é adequado para acesso de baixa latência, mas pode não fornecer o mesmo nível de capacidades de consulta e junções complexas que são frequentemente necessárias para análises em comparação com um banco de dados relacional como o Aurora.",
            "Amazon Redshift é principalmente uma solução de armazenamento de dados projetada para consultas analíticas complexas, em vez de processamento de transações em tempo real, tornando-o inadequado para os requisitos deste aplicativo."
        ]
    },
    {
        "Question Number": "39",
        "Situation": "Uma corporação multinacional desenvolveu um aplicativo móvel que permite aos usuários se autenticarem usando suas contas do Google. O aplicativo precisa acessar recursos da AWS de forma segura em nome dos usuários autenticados, sem exigir que eles gerenciem credenciais da AWS diretamente. A empresa está considerando usar serviços da AWS para facilitar esse processo de autenticação e autorização.",
        "Question": "Qual das seguintes soluções permitirá que o aplicativo obtenha credenciais temporárias da AWS para usuários autenticados? (Selecione Dois)",
        "Options": {
            "1": "Implementar AssumeRoleWithWebIdentity para obter credenciais de segurança temporárias usando os tokens de autenticação do Google fornecidos pelos usuários.",
            "2": "Criar um usuário IAM para cada usuário do aplicativo e distribuir suas chaves de acesso para autenticação.",
            "3": "Utilizar um provedor de identidade personalizado que interaja com o AWS STS para emitir credenciais temporárias com base nos logins dos usuários.",
            "4": "Usar o AWS Cognito para autenticar usuários e configurar um papel que permita acesso a recursos específicos da AWS.",
            "5": "Usar o AWS SSO para gerenciar o acesso do usuário diretamente e habilitar a autenticação federada para o aplicativo."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Usar o AWS Cognito para autenticar usuários e configurar um papel que permita acesso a recursos específicos da AWS.",
            "Implementar AssumeRoleWithWebIdentity para obter credenciais de segurança temporárias usando os tokens de autenticação do Google fornecidos pelos usuários."
        ],
        "Explanation": "Tanto o AWS Cognito quanto o AssumeRoleWithWebIdentity são projetados para fornecer credenciais de segurança temporárias a usuários autenticados por meio de provedores de identidade externos, como o Google. O AWS Cognito permite fácil gerenciamento de pools de usuários e papéis, enquanto o AssumeRoleWithWebIdentity facilita diretamente a autenticação federada usando tokens de identidade da web.",
        "Other Options": [
            "Criar usuários IAM para cada usuário do aplicativo não é escalável e vai contra o propósito do acesso federado, que é projetado para evitar o gerenciamento de credenciais de longo prazo.",
            "O AWS SSO é focado em gerenciar o acesso entre contas e serviços da AWS, mas não emite diretamente credenciais temporárias usando provedores de identidade da web externos.",
            "Utilizar um provedor de identidade personalizado pode introduzir complexidade desnecessária e não é uma abordagem padrão para obter credenciais temporárias da AWS em comparação com o suporte integrado fornecido pelos serviços da AWS."
        ]
    },
    {
        "Question Number": "40",
        "Situation": "Uma empresa global de varejo online está migrando suas aplicações para a AWS para melhorar o desempenho e reduzir a latência para seus usuários internacionais. A empresa possui vários microsserviços que se comunicam entre si através de vários pontos de extremidade de serviços da AWS. O Arquiteto de Soluções precisa garantir que as aplicações possam interagir de forma contínua com os serviços da AWS, mantendo a segurança e minimizando custos.",
        "Question": "Qual das seguintes estratégias o Arquiteto de Soluções deve implementar para otimizar o uso dos pontos de extremidade de serviços da AWS? (Selecione Dois)",
        "Options": {
            "1": "Utilizar pontos de extremidade VPC para se conectar privadamente aos serviços da AWS sem atravessar a internet.",
            "2": "Implementar o AWS Global Accelerator para melhorar a disponibilidade e o desempenho das aplicações hospedadas em várias Regiões da AWS.",
            "3": "Configurar o AWS PrivateLink para acessar de forma segura serviços hospedados em outra VPC sem usar IPs públicos.",
            "4": "Aproveitar o AWS Direct Connect para estabelecer uma conexão de rede dedicada do data center local para a AWS.",
            "5": "Usar o AWS Transit Gateway para simplificar a conexão entre várias VPCs e redes locais."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Utilizar pontos de extremidade VPC para se conectar privadamente aos serviços da AWS sem atravessar a internet.",
            "Configurar o AWS PrivateLink para acessar de forma segura serviços hospedados em outra VPC sem usar IPs públicos."
        ],
        "Explanation": "O uso de pontos de extremidade VPC permite uma conexão privada aos serviços da AWS sem expor o tráfego à internet, aumentando a segurança e reduzindo a latência. O AWS PrivateLink fornece uma maneira segura de acessar serviços hospedados em outras VPCs sem utilizar endereços IP públicos, o que também contribui para a segurança e eficiência na interação com os serviços.",
        "Other Options": [
            "Implementar o AWS Global Accelerator é útil para melhorar o desempenho e a disponibilidade entre Regiões, mas não aborda especificamente a otimização do uso dos pontos de extremidade de serviços.",
            "Usar o AWS Transit Gateway simplifica a gestão de rede e a conectividade entre VPCs, mas não otimiza diretamente o uso dos pontos de extremidade de serviços.",
            "Aproveitar o AWS Direct Connect fornece uma conexão dedicada à AWS, o que é benéfico para arquiteturas híbridas, mas não se concentra na otimização do uso dos pontos de extremidade de serviços."
        ]
    },
    {
        "Question Number": "41",
        "Situation": "Uma empresa está planejando migrar suas aplicações existentes locais para a AWS para reduzir custos de infraestrutura e melhorar a escalabilidade. Eles têm uma mistura de aplicações web e serviços de backend que requerem uma solução de banco de dados robusta. A empresa está particularmente interessada em otimizar custos sem comprometer o desempenho. Eles têm uma estratégia de crescimento a longo prazo que envolve escalar sua aplicação para lidar com o aumento do tráfego de usuários e volume de dados.",
        "Question": "Qual das seguintes estratégias de planejamento de ativos melhor se alinha com os objetivos da empresa de otimização de custos e escalabilidade na AWS?",
        "Options": {
            "1": "Adotar uma arquitetura sem servidor convertendo as aplicações web em funções AWS Lambda e usando o Amazon Aurora Serverless para o banco de dados para escalar automaticamente com a demanda e reduzir custos.",
            "2": "Migrar as aplicações para a AWS implantando-as em instâncias Amazon EC2 enquanto escala manualmente os recursos com base nos padrões de tráfego, o que pode levar ao desperdício de recursos e aumento de custos.",
            "3": "Implementar uma estratégia de migração lift-and-shift movendo as máquinas virtuais existentes para instâncias Amazon EC2 sem fazer modificações nas aplicações. Usar o Amazon RDS para o banco de dados existente sem considerar a otimização de custos.",
            "4": "Re-arquitetar as aplicações para rodar no Amazon ECS com Fargate e migrar o banco de dados para o Amazon DynamoDB para melhorar a escalabilidade, mas incorrer em custos operacionais mais altos devido à complexidade da arquitetura."
        },
        "Correct Answer": "Adotar uma arquitetura sem servidor convertendo as aplicações web em funções AWS Lambda e usando o Amazon Aurora Serverless para o banco de dados para escalar automaticamente com a demanda e reduzir custos.",
        "Explanation": "Esta opção atende efetivamente aos objetivos da empresa de otimização de custos e escalabilidade. Ao utilizar uma arquitetura sem servidor com AWS Lambda, a empresa pode reduzir significativamente os custos de infraestrutura, pois paga apenas pelo tempo de computação utilizado. Além disso, o Amazon Aurora Serverless oferece uma solução de banco de dados com escalonamento automático sob demanda que ajusta a capacidade com base na carga de trabalho real, proporcionando tanto desempenho quanto eficiência de custos.",
        "Other Options": [
            "Esta opção não aborda a otimização de custos de forma eficaz, pois envolve uma abordagem lift-and-shift que pode levar a custos operacionais mais altos sem aproveitar os recursos de escalabilidade da AWS.",
            "Embora esta opção sugira uma solução escalável, o uso do Amazon DynamoDB pode não fornecer os mesmos recursos de banco de dados relacional que podem ser necessários para as aplicações existentes, e pode levar a uma complexidade aumentada.",
            "Esta abordagem pode levar a uma utilização ineficiente de recursos, uma vez que a escalabilidade manual pode resultar em superprovisionamento ou subprovisionamento de recursos, aumentando os custos sem alcançar uma escalabilidade ideal."
        ]
    },
    {
        "Question Number": "42",
        "Situation": "Uma empresa global de varejo opera tanto um data center local quanto recursos em nuvem da AWS para gerenciar seu inventário e plataforma de e-commerce. A empresa quer garantir que as consultas DNS de sua infraestrutura local possam resolver tanto nomes de domínio internos quanto externos de forma contínua. Além disso, eles querem implementar uma solução que permita recursos avançados de DNS, como encaminhamento condicional e registro de consultas DNS. Eles estão considerando usar o Amazon Route 53 Resolver para alcançar esse objetivo.",
        "Question": "Qual das seguintes opções fornece a integração MAIS eficiente do DNS local com o Amazon Route 53 Resolver, minimizando a latência e a sobrecarga de gerenciamento?",
        "Options": {
            "1": "Configurar um ponto de extremidade de entrada do Route 53 Resolver na VPC. Configurar um encaminhador condicional no servidor DNS local para encaminhar consultas para domínios hospedados na AWS para o Resolver. Implementar registro para consultas DNS no Route 53 para monitorar padrões de tráfego.",
            "2": "Criar uma zona hospedada privada do Route 53 para nomes de domínio internos e um ponto de extremidade de saída na VPC. Apontar os servidores DNS locais para o ponto de extremidade de saída para resolver recursos da AWS, mantendo a resolução de DNS externa separada.",
            "3": "Configurar uma conexão VPN entre o data center local e a AWS, e configurar o servidor DNS local para resolver nomes de domínio da AWS diretamente. Usar o Route 53 para gerenciamento de DNS externo, mas não integrar com o DNS local.",
            "4": "Implantar uma instância EC2 como um proxy DNS dentro da VPC que encaminha todas as consultas DNS para o servidor DNS local. Configurar o DNS local para encaminhar solicitações para recursos da AWS para a instância EC2. Utilizar o Amazon CloudWatch para monitorar consultas DNS."
        },
        "Correct Answer": "Configurar um ponto de extremidade de entrada do Route 53 Resolver na VPC. Configurar um encaminhador condicional no servidor DNS local para encaminhar consultas para domínios hospedados na AWS para o Resolver. Implementar registro para consultas DNS no Route 53 para monitorar padrões de tráfego.",
        "Explanation": "Ao configurar um ponto de extremidade de entrada do Route 53 Resolver, o DNS local pode encaminhar consultas para domínios hospedados na AWS diretamente para o Route 53, permitindo uma integração contínua. Isso minimiza a latência, uma vez que as consultas são resolvidas dentro do ambiente da AWS, e permite o uso de recursos avançados como encaminhamento condicional e registro de consultas, simplificando o gerenciamento.",
        "Other Options": [
            "Implantar uma instância EC2 como um proxy DNS adiciona complexidade e sobrecarga de gerenciamento desnecessárias. Aumenta a latência, pois cada consulta DNS requer roteamento através de uma camada adicional, o que não é ideal em comparação com a integração direta com o Route 53 Resolver.",
            "Configurar uma conexão VPN e permitir que o servidor DNS local resolva nomes de domínio da AWS diretamente carece dos recursos avançados do Route 53 Resolver. Esta abordagem não fornece as capacidades de encaminhamento condicional ou registro, limitando as capacidades de gerenciamento de DNS da empresa.",
            "Criar uma zona hospedada privada e um ponto de extremidade de saída permite a resolução de domínios internos, mas não facilita a integração contínua para consultas externas. Além disso, apontar os servidores DNS locais para pontos de extremidade de saída limita os benefícios do Route 53 Resolver, como o encaminhamento condicional."
        ]
    },
    {
        "Question Number": "43",
        "Situation": "Uma empresa de serviços financeiros está enfrentando padrões de uso imprevisíveis e custos crescentes para suas instâncias do Amazon EC2 e armazenamento do Amazon S3. A empresa deseja otimizar seus recursos de forma eficaz usando ferramentas de visibilidade da AWS para obter melhores insights sobre sua utilização de recursos. O arquiteto de soluções é encarregado de identificar a melhor abordagem para avaliar e otimizar o uso desses recursos.",
        "Question": "Qual das seguintes ferramentas o arquiteto de soluções deve utilizar para analisar e otimizar os recursos de computação e armazenamento de forma eficaz?",
        "Options": {
            "1": "Implementar o AWS Trusted Advisor para melhores práticas gerais e o AWS Budgets para acompanhar os gastos com recursos.",
            "2": "Utilizar o AWS Compute Optimizer para avaliar o uso das instâncias do EC2 e o Amazon S3 Storage Lens para obter insights sobre a otimização do armazenamento.",
            "3": "Usar o AWS Cost Explorer para analisar padrões de gastos e o AWS CloudTrail para monitorar o uso da API dos recursos.",
            "4": "Aproveitar o AWS Config para avaliar a conformidade e o Amazon CloudWatch para monitoramento em tempo real do desempenho dos recursos."
        },
        "Correct Answer": "Utilizar o AWS Compute Optimizer para avaliar o uso das instâncias do EC2 e o Amazon S3 Storage Lens para obter insights sobre a otimização do armazenamento.",
        "Explanation": "O AWS Compute Optimizer fornece recomendações para otimizar os tipos de instâncias do EC2 com base no uso real, enquanto o Amazon S3 Storage Lens oferece insights sobre padrões de uso de armazenamento, ajudando a identificar oportunidades de economia de custos em recursos de computação e armazenamento.",
        "Other Options": [
            "O AWS Trusted Advisor oferece melhores práticas gerais, mas não fornece insights específicos sobre a utilização ou otimização de recursos para EC2 e S3. O AWS Budgets foca no acompanhamento de custos em vez da otimização de recursos.",
            "O AWS Cost Explorer ajuda a analisar padrões de gastos, mas não fornece recomendações diretas de otimização para recursos de computação e armazenamento. O AWS CloudTrail é usado principalmente para monitorar chamadas de API e não auxilia na otimização de recursos.",
            "O AWS Config é usado para avaliar a conformidade dos recursos e garantir que atendam a certos critérios, mas não se concentra na otimização de desempenho. O Amazon CloudWatch é útil para monitoramento, mas não fornece insights específicos para otimizar a alocação de recursos ou custos."
        ]
    },
    {
        "Question Number": "44",
        "Situation": "Uma empresa está migrando seu banco de dados local para a AWS. O esquema do banco de dados é complexo e precisa ser convertido para corresponder ao formato de uma instância do Amazon RDS. A empresa decidiu usar a AWS Schema Conversion Tool (AWS SCT) para lidar com a migração de forma eficiente. Eles também planejam usar um dispositivo AWS Snowball Edge para transferir seus dados de forma segura e em etapas. Além disso, eles requerem transformações devido a diferenças significativas entre os bancos de dados de origem e destino.",
        "Question": "Qual das seguintes opções descreve melhor como a AWS Schema Conversion Tool (AWS SCT) e um agente AWS SCT podem ser usados para facilitar o processo de migração do banco de dados?",
        "Options": {
            "1": "Confiar exclusivamente na AWS SCT para realizar tanto a conversão do esquema quanto a extração de dados, eliminando a necessidade de quaisquer agentes externos no processo de migração.",
            "2": "Usar a AWS SCT para converter o esquema do banco de dados e conectar-se diretamente à instância do Amazon RDS de destino para a migração de dados, sem a necessidade de um agente.",
            "3": "Empregar a AWS SCT para conversão de esquema e usar funções AWS Lambda para transformar dados à medida que são migrados para a instância do Amazon RDS de destino.",
            "4": "Utilizar a AWS SCT para converter o esquema e implantar um agente AWS SCT em uma instância do Amazon EC2 para lidar com transformações adicionais de dados durante a migração."
        },
        "Correct Answer": "Utilizar a AWS SCT para converter o esquema e implantar um agente AWS SCT em uma instância do Amazon EC2 para lidar com transformações adicionais de dados durante a migração.",
        "Explanation": "A resposta correta destaca o uso combinado da AWS SCT para conversão de esquema e de um agente AWS SCT para transformação de dados. O agente pode realizar as transformações necessárias em uma instância do EC2, o que é essencial quando os bancos de dados de origem e destino diferem significativamente.",
        "Other Options": [
            "Esta opção está incorreta porque, embora a AWS SCT possa converter esquemas de banco de dados, ela não pode se conectar diretamente à instância do Amazon RDS de destino para migração de dados sem um agente para transformações complexas.",
            "Esta opção está incorreta, pois sugere confiar exclusivamente na AWS SCT para tanto a conversão do esquema quanto a extração de dados, o que não é viável para cenários que requerem transformações complexas.",
            "Esta opção está incorreta porque as funções AWS Lambda não estão integradas com a AWS SCT para o propósito de transformação de dados durante a migração, já que o papel do agente é especificamente projetado para essas tarefas."
        ]
    },
    {
        "Question Number": "45",
        "Situation": "Uma empresa de serviços financeiros está migrando seu aplicativo crítico para a AWS. O aplicativo requer armazenamento de baixa latência e alta taxa de transferência para lidar com grandes volumes de transações de forma eficiente. O arquiteto de soluções precisa escolher o tipo de volume do Amazon EBS mais adequado que atenda a esses requisitos de desempenho, equilibrando custo e durabilidade.",
        "Question": "Qual dos seguintes tipos de volume do Amazon EBS o arquiteto de soluções deve selecionar para garantir desempenho e durabilidade ideais para o aplicativo?",
        "Options": {
            "1": "Volumes gp2, oferecendo um equilíbrio de preço e desempenho adequado para cargas de trabalho gerais, mas que podem não atender a altas demandas de transações.",
            "2": "Volumes st1, projetados para cargas de trabalho intensivas em taxa de transferência, mas que não possuem o desempenho necessário para aplicativos de baixa latência.",
            "3": "Volumes io2, proporcionando alto desempenho, baixa latência e 99,999% de durabilidade, ideais para cargas de trabalho transacionais.",
            "4": "Volumes sc1, que são a opção de menor custo, mas não são adequados para requisitos de acesso frequente ou baixa latência."
        },
        "Correct Answer": "Volumes io2, proporcionando alto desempenho, baixa latência e 99,999% de durabilidade, ideais para cargas de trabalho transacionais.",
        "Explanation": "Os volumes io2 são especificamente projetados para cargas de trabalho transacionais sensíveis à latência, oferecendo o mais alto desempenho e durabilidade com um máximo de IOPS de 64.000 e durabilidade de 99,999%. Isso os torna a melhor escolha para o aplicativo de serviços financeiros.",
        "Other Options": [
            "Os volumes gp2 podem fornecer um bom equilíbrio para cargas de trabalho gerais, mas podem não oferecer a latência baixa e a alta taxa de transferência consistentes necessárias para aplicativos financeiros críticos.",
            "Os volumes st1 são opções de HDD de baixo custo que se destacam em taxa de transferência, mas não são projetados para cargas de trabalho de baixa latência, tornando-os inadequados para este cenário.",
            "Os volumes sc1 são otimizados para dados acessados com pouca frequência e armazenamento frio, o que não atenderia às necessidades de desempenho de um aplicativo de alta demanda e baixa latência."
        ]
    },
    {
        "Question Number": "46",
        "Situation": "Uma empresa de serviços financeiros está enfrentando problemas de desempenho com seu sistema de processamento de transações online hospedado no Amazon RDS. O aplicativo está apresentando tempos de resposta lentos durante os períodos de pico de uso, e a equipe de gestão deseja identificar e resolver os gargalos de desempenho. A empresa está considerando soluções que possam fornecer insights sobre o desempenho das consultas e a utilização de recursos, minimizando as mudanças na arquitetura existente.",
        "Question": "Qual das seguintes opções é a maneira mais eficaz de identificar gargalos de desempenho no banco de dados Amazon RDS?",
        "Options": {
            "1": "Implementar alarmes do Amazon CloudWatch para monitorar as métricas de CPU e I/O de disco da instância RDS. Quando os limites forem ultrapassados, revisar manualmente as métricas de desempenho do banco de dados para identificar possíveis gargalos.",
            "2": "Utilizar o AWS CloudTrail para registrar chamadas de API feitas à instância RDS e coletar informações sobre os padrões de uso do banco de dados. Analisar os logs para identificar quaisquer problemas de contenção de recursos durante os horários de pico.",
            "3": "Ativar o Amazon RDS Performance Insights para analisar a carga do banco de dados e identificar consultas problemáticas. Usar o painel para monitorar o uso de CPU, memória e I/O ao longo do tempo. Otimizar as consultas identificadas com base nos insights fornecidos.",
            "4": "Ativar o monitoramento aprimorado na instância RDS para capturar métricas detalhadas sobre o desempenho do sistema operacional. Revisar as métricas em nível de SO para determinar se os recursos subjacentes do servidor são a causa dos problemas de desempenho."
        },
        "Correct Answer": "Ativar o Amazon RDS Performance Insights para analisar a carga do banco de dados e identificar consultas problemáticas. Usar o painel para monitorar o uso de CPU, memória e I/O ao longo do tempo. Otimizar as consultas identificadas com base nos insights fornecidos.",
        "Explanation": "O Amazon RDS Performance Insights fornece uma ferramenta poderosa para analisar o desempenho do banco de dados. Ele oferece uma representação visual da carga do banco de dados e permite que os usuários se aprofundem em consultas específicas que podem estar causando gargalos de desempenho. Essa abordagem minimiza a necessidade de mudanças extensivas na arquitetura, enquanto fornece insights acionáveis para otimização.",
        "Other Options": [
            "O AWS CloudTrail é usado principalmente para registrar e monitorar chamadas de API. Ele não fornece insights diretos sobre o desempenho do banco de dados ou a utilização de recursos, tornando-o menos eficaz para identificar gargalos de desempenho no RDS.",
            "Embora o Amazon CloudWatch possa monitorar métricas de CPU e I/O, revisar manualmente as métricas quando os limites são ultrapassados não é tão eficaz quanto aproveitar uma ferramenta dedicada de análise de desempenho como o Performance Insights, que oferece insights mais profundos sobre o desempenho das consultas e a utilização de recursos.",
            "O monitoramento aprimorado fornece métricas em nível de SO, mas pode não se correlacionar diretamente com problemas de desempenho do banco de dados. Ele carece dos insights focados sobre o desempenho das consultas e a distribuição da carga que o Performance Insights fornece, tornando-o menos relevante para identificar gargalos no RDS."
        ]
    },
    {
        "Question Number": "47",
        "Situation": "Uma empresa possui duas contas AWS: uma conta de desenvolvimento e uma conta de produção. A conta de desenvolvimento abriga uma equipe de desenvolvedores e operadores que precisam de acesso para criar e gerenciar a infraestrutura da aplicação. Para manter a segurança e a governança, a empresa deseja fornecer acesso controlado à conta de produção, onde a aplicação está implantada. A empresa configurou grupos e usuários IAM em ambas as contas de acordo com as melhores práticas.",
        "Question": "Como a empresa deve configurar funções e políticas IAM para permitir que desenvolvedores e operadores na conta de desenvolvimento acessem a conta de produção de forma segura, enquanto adere ao princípio do menor privilégio?",
        "Options": {
            "1": "Criar uma função IAM compartilhada na conta de desenvolvimento com permissões para gerenciar a infraestrutura da aplicação e permitir que a conta de produção assuma essa função.",
            "2": "Criar um grupo IAM na conta de produção com permissões para gerenciamento de aplicações e adicionar os usuários IAM da conta de desenvolvimento diretamente a esse grupo.",
            "3": "Criar uma função IAM compartilhada na conta de produção com permissões para criar e excluir infraestrutura da aplicação. Atualizar a política de confiança para permitir que usuários da conta de desenvolvimento assumam essa função.",
            "4": "Criar um usuário IAM na conta de produção para cada desenvolvedor e operador na conta de desenvolvimento, concedendo-lhes permissões para criar e excluir infraestrutura da aplicação."
        },
        "Correct Answer": "Criar uma função IAM compartilhada na conta de produção com permissões para criar e excluir infraestrutura da aplicação. Atualizar a política de confiança para permitir que usuários da conta de desenvolvimento assumam essa função.",
        "Explanation": "Criar uma função IAM compartilhada na conta de produção com as permissões necessárias permite acesso controlado para usuários na conta de desenvolvimento. Ao atualizar a política de confiança, a função pode permitir especificamente que desenvolvedores e operadores a assumam, garantindo a adesão ao princípio do menor privilégio enquanto fornece o acesso necessário.",
        "Other Options": [
            "Criar usuários IAM na conta de produção para cada desenvolvedor e operador não é uma boa prática, pois pode levar a uma sobrecarga de gerenciamento e potenciais riscos de segurança. Em vez disso, usar funções fornece uma solução mais segura e gerenciável.",
            "Criar um grupo IAM na conta de produção e adicionar usuários IAM da conta de desenvolvimento diretamente a esse grupo não funcionaria, pois usuários IAM de uma conta não podem ser adicionados a um grupo em outra conta. Funções entre contas são o mecanismo apropriado para gerenciamento de acesso.",
            "Criar uma função IAM compartilhada na conta de desenvolvimento não ajuda os operadores e desenvolvedores a acessar a conta de produção. A função deve ser definida na conta de produção com uma política de confiança que permita à conta de desenvolvimento assumi-la."
        ]
    },
    {
        "Question Number": "48",
        "Situation": "Uma empresa está planejando migrar suas cargas de trabalho existentes no local para a AWS. A arquitetura precisa ser econômica e garantir que os recursos sejam utilizados de forma eficiente. A empresa está particularmente focada em gerenciar custos enquanto garante capacidade suficiente para cargas de trabalho sazonais. Eles querem entender os melhores modelos de preços a adotar para suas instâncias EC2 e bancos de dados RDS.",
        "Question": "Qual dos seguintes modelos de preços o Arquiteto de Soluções deve considerar para otimizar custos enquanto acomoda cargas de trabalho variáveis? (Selecione Dois)",
        "Options": {
            "1": "Combinar Savings Plans com Spot Instances para otimizar a economia de custos em cargas de trabalho.",
            "2": "Utilizar On-Demand Instances para todas as cargas de trabalho para manter a máxima flexibilidade.",
            "3": "Usar Savings Plans para opções de preços flexíveis em várias famílias de instâncias e regiões.",
            "4": "Aproveitar Spot Instances para tirar proveito da capacidade EC2 não utilizada a preços reduzidos.",
            "5": "Comprar Reserved Instances para cargas de trabalho de longo prazo e garantir a reserva de capacidade."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Usar Savings Plans para opções de preços flexíveis em várias famílias de instâncias e regiões.",
            "Combinar Savings Plans com Spot Instances para otimizar a economia de custos em cargas de trabalho."
        ],
        "Explanation": "Savings Plans oferecem flexibilidade entre tipos de instâncias e regiões, o que é benéfico para cargas de trabalho variáveis. Combiná-los com Spot Instances permite que a empresa aproveite preços mais baixos para cargas de trabalho menos críticas, otimizando os custos gerais.",
        "Other Options": [
            "Comprar Reserved Instances bloqueia a empresa em tipos de instâncias e regiões específicas, o que pode não ser ideal para cargas de trabalho variáveis que requerem flexibilidade.",
            "Utilizar On-Demand Instances para todas as cargas de trabalho pode ser caro, pois não fornece as economias de custos associadas ao uso de longo prazo ou à capacidade não utilizada.",
            "Aproveitar apenas Spot Instances pode não garantir capacidade durante os horários de pico, o que pode levar a interrupções de serviço para cargas de trabalho críticas."
        ]
    },
    {
        "Question Number": "49",
        "Situation": "Uma empresa de serviços financeiros deve cumprir requisitos regulatórios rigorosos que exigem a criptografia de dados sensíveis tanto em repouso quanto em trânsito. A empresa está migrando suas aplicações para a AWS e precisa garantir que todos os dados transmitidos para e a partir dos serviços da AWS sejam criptografados. Além disso, os dados armazenados no Amazon S3 também devem ser criptografados usando um método que permita controle de acesso granular.",
        "Question": "Qual combinação de ações garantirá a conformidade com os requisitos de criptografia?",
        "Options": {
            "1": "Utilizar o Amazon S3 Transfer Acceleration para acelerar uploads sem criptografia. Usar políticas do IAM para permitir que qualquer usuário acesse os objetos do S3. Definir políticas de retenção de dados para gerenciar os ciclos de vida dos objetos.",
            "2": "Ativar a criptografia do lado do servidor com chaves do AWS KMS para os buckets do S3. Usar HTTPS para todas as chamadas de API aos serviços da AWS. Definir políticas do IAM para restringir o acesso às chaves do KMS.",
            "3": "Implementar criptografia do lado do cliente para dados antes de enviá-los ao S3. Usar transferências de dados não criptografadas entre a AWS e os data centers locais. Confiar nas políticas do bucket S3 para controle de acesso.",
            "4": "Usar o AWS CloudHSM para gerenciar chaves de criptografia para o S3. Configurar todas as aplicações para usar HTTP não criptografado para transferência de dados. Implementar grupos de segurança para limitar o acesso ao bucket S3."
        },
        "Correct Answer": "Ativar a criptografia do lado do servidor com chaves do AWS KMS para os buckets do S3. Usar HTTPS para todas as chamadas de API aos serviços da AWS. Definir políticas do IAM para restringir o acesso às chaves do KMS.",
        "Explanation": "Ativar a criptografia do lado do servidor com chaves do AWS KMS garante que os dados em repouso no S3 sejam criptografados, e usar HTTPS garante que os dados em trânsito sejam criptografados. Definir políticas do IAM para restringir o acesso às chaves do KMS adiciona uma camada adicional de segurança e controle sobre as chaves de criptografia, atendendo assim aos requisitos regulatórios.",
        "Other Options": [
            "Usar o AWS CloudHSM para gerenciar chaves de criptografia é uma abordagem segura, mas configurar aplicações para usar HTTP não criptografado não atende ao requisito de criptografia em trânsito, tornando esta opção não conforme com as regulamentações.",
            "Utilizar o Amazon S3 Transfer Acceleration pode proporcionar benefícios de desempenho, mas não impõe criptografia. Permitir que qualquer usuário acesse objetos do S3 ignora a necessidade de controle de acesso granular, falhando em atender aos padrões de conformidade.",
            "Implementar criptografia do lado do cliente é uma estratégia válida para proteger dados antes que cheguem ao S3; no entanto, usar transferências de dados não criptografadas compromete a segurança dos dados em trânsito. Confiar apenas nas políticas do bucket S3 para controle de acesso é insuficiente para os requisitos rigorosos do quadro regulatório."
        ]
    },
    {
        "Question Number": "50",
        "Situation": "Uma empresa está construindo uma arquitetura de microserviços na AWS para suportar sua plataforma de e-commerce. Cada serviço é responsável por uma função de negócios específica e precisa se comunicar de forma contínua com outros serviços. A empresa quer garantir que os serviços sejam fracamente acoplados e possam escalar de forma independente. O Arquiteto de Soluções é encarregado de selecionar os serviços de integração de aplicações mais apropriados para facilitar a comunicação entre esses microserviços.",
        "Question": "Qual das seguintes opções o Arquiteto de Soluções deve implementar para atender aos requisitos de integração dos microserviços? (Selecione duas)",
        "Options": {
            "1": "Utilizar o AWS AppSync para conectar diretamente os microserviços às aplicações clientes.",
            "2": "Aproveitar o Amazon EventBridge para direcionar eventos entre os microserviços com base em padrões específicos.",
            "3": "Usar o Amazon Simple Queue Service (SQS) para desacoplar os serviços e permitir comunicação assíncrona.",
            "4": "Configurar o AWS Step Functions para orquestrar o fluxo de trabalho entre os microserviços.",
            "5": "Implementar o Amazon SNS para enviar notificações a vários serviços quando um evento ocorrer."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Usar o Amazon Simple Queue Service (SQS) para desacoplar os serviços e permitir comunicação assíncrona.",
            "Aproveitar o Amazon EventBridge para direcionar eventos entre os microserviços com base em padrões específicos."
        ],
        "Explanation": "Usar o Amazon SQS permite comunicação assíncrona e desacoplada entre microserviços, o que melhora a escalabilidade e a resiliência. Aproveitar o Amazon EventBridge permite arquiteturas orientadas a eventos, permitindo que os serviços reajam a eventos em tempo real enquanto mantêm um acoplamento frouxo.",
        "Other Options": [
            "Embora o Amazon SNS possa enviar notificações a vários serviços, ele não fornece o mesmo nível de desacoplamento e processamento assíncrono que o SQS.",
            "O AWS AppSync é usado principalmente para APIs GraphQL e pode não ser a melhor opção para integração de microserviços neste cenário.",
            "O AWS Step Functions é mais adequado para orquestrar fluxos de trabalho do que para fornecer comunicação direta entre microserviços."
        ]
    },
    {
        "Question Number": "51",
        "Situation": "Uma empresa de serviços financeiros está desenvolvendo um novo aplicativo que processará dados sensíveis de clientes. A empresa está comprometida com as melhores práticas de segurança e designou um arquiteto de soluções para garantir que todos os serviços e recursos da AWS estejam configurados para aderir ao princípio do acesso com o menor privilégio. O arquiteto precisa estabelecer permissões de usuário para várias funções dentro do aplicativo, garantindo que os usuários tenham acesso apenas aos recursos necessários para desempenhar suas funções específicas.",
        "Question": "Qual das seguintes ações o arquiteto de soluções deve tomar para implementar da melhor forma o princípio do acesso com o menor privilégio para os usuários do aplicativo?",
        "Options": {
            "1": "Criar funções IAM com permissões específicas para cada função de trabalho e atribuí-las aos usuários.",
            "2": "Criar uma única função IAM com permissões amplas e atribuí-la a todos os usuários.",
            "3": "Atribuir aos usuários as mesmas permissões que os administradores para garantir que tenham todo o acesso necessário.",
            "4": "Conceder a todos os usuários acesso total para garantir que não haja problemas de permissão durante o desenvolvimento do aplicativo."
        },
        "Correct Answer": "Criar funções IAM com permissões específicas para cada função de trabalho e atribuí-las aos usuários.",
        "Explanation": "Criar funções IAM com permissões específicas para cada função de trabalho garante que os usuários tenham acesso apenas aos recursos necessários para suas tarefas. Isso está alinhado com o princípio do menor privilégio e minimiza os riscos de segurança associados à concessão excessiva de permissões.",
        "Other Options": [
            "Conceder a todos os usuários acesso total compromete a segurança ao fornecer permissões desnecessárias, o que contradiz o princípio do menor privilégio.",
            "Criar uma única função IAM com permissões amplas expõe o aplicativo a riscos de segurança, pois permite que todos os usuários acessem recursos que não precisam.",
            "Atribuir aos usuários as mesmas permissões que os administradores compromete o princípio do menor privilégio e pode levar ao uso acidental ou intencional de recursos sensíveis."
        ]
    },
    {
        "Question Number": "52",
        "Situation": "Uma empresa de mídia possui um grande volume de conteúdo em vídeo que é gerado e enviado por usuários diariamente. A empresa precisa armazenar e gerenciar esse conteúdo de forma eficiente, garantindo que os vídeos sejam acessíveis para streaming. A maioria dos vídeos enviados raramente é acessada após os primeiros dias de upload, mas precisam ser mantidos por razões de conformidade. O Arquiteto de Soluções é encarregado de projetar uma solução de armazenamento que minimize os custos enquanto fornece a durabilidade e acessibilidade necessárias aos vídeos.",
        "Question": "Qual das seguintes soluções de armazenamento atenderá melhor aos requisitos da empresa para armazenamento econômico e acessibilidade do conteúdo em vídeo?",
        "Options": {
            "1": "Usar Amazon S3 Standard para todos os vídeos e implementar políticas de ciclo de vida para transferir conteúdos mais antigos para Amazon S3 Glacier para armazenamento a longo prazo.",
            "2": "Armazenar todos os vídeos no Amazon S3 Intelligent-Tiering para mover automaticamente os dados entre camadas de acesso frequente e infrequente com base em padrões de uso.",
            "3": "Utilizar Amazon EFS para todo o armazenamento de vídeo, permitindo fácil compartilhamento e acesso de várias instâncias sem se preocupar com gerenciamento de ciclo de vida.",
            "4": "Usar Amazon S3 Standard para vídeos recentemente enviados e configurar uma política de ciclo de vida para transferi-los para Amazon S3 One Zone-IA após 30 dias sem acesso."
        },
        "Correct Answer": "Usar Amazon S3 Intelligent-Tiering para mover automaticamente os dados entre camadas de acesso frequente e infrequente com base em padrões de uso.",
        "Explanation": "Amazon S3 Intelligent-Tiering é projetado para dados que têm padrões de acesso desconhecidos ou em mudança. Ele move automaticamente os dados entre duas camadas de acesso: frequente e infrequente, otimizando custos sem a necessidade de intervenção manual. Isso é ideal para a necessidade da empresa de mídia de minimizar custos enquanto garante acessibilidade para o conteúdo recém-enviado.",
        "Other Options": [
            "Usar Amazon S3 Standard para todos os vídeos pode incorrer em custos mais altos, especialmente para vídeos que raramente são acessados após o upload inicial, tornando-o menos econômico em comparação com Intelligent-Tiering.",
            "Amazon EFS não é a melhor opção para este cenário, pois geralmente é mais caro que o S3 para armazenar grandes quantidades de dados, particularmente para conteúdo que é acessado com pouca frequência.",
            "Usar Amazon S3 Standard e configurar uma política de ciclo de vida para transferir para S3 One Zone-IA após 30 dias é uma opção potencial, mas carece da otimização automatizada que Intelligent-Tiering fornece, o que é crucial dado os padrões de acesso imprevisíveis dos vídeos."
        ]
    },
    {
        "Question Number": "53",
        "Situation": "Uma empresa de serviços financeiros está migrando seus bancos de dados locais para a AWS para melhorar a escalabilidade e reduzir os custos operacionais. Eles estão lidando com um grande volume de dados transacionais que precisam ser transferidos para uma instância do Amazon RDS. A empresa deseja garantir o mínimo de tempo de inatividade durante a migração e manter a integridade dos dados. O arquiteto de soluções é encarregado de selecionar o método mais apropriado para transferir o banco de dados para a AWS.",
        "Question": "Qual das seguintes opções é a solução mais adequada para migrar o banco de dados com mínimo de tempo de inatividade e mantendo a integridade dos dados?",
        "Options": {
            "1": "Realizar um backup manual do banco de dados, transferir os arquivos de backup para o Amazon RDS e restaurar o banco de dados, garantindo que a aplicação esteja offline durante o processo.",
            "2": "Exportar o banco de dados para um arquivo plano, enviá-lo para o Amazon S3 e, em seguida, importá-lo na instância do RDS, o que exigirá um tempo de inatividade significativo.",
            "3": "Usar o AWS Database Migration Service com a instância de replicação configurada para replicação contínua de dados, permitindo uma migração com quase zero de tempo de inatividade.",
            "4": "Usar o AWS Snowball para transferir todo o banco de dados para a AWS, o que levará vários dias e resultará em um tempo de inatividade prolongado durante a migração."
        },
        "Correct Answer": "Usar o AWS Database Migration Service com a instância de replicação configurada para replicação contínua de dados, permitindo uma migração com quase zero de tempo de inatividade.",
        "Explanation": "O AWS Database Migration Service (DMS) fornece uma maneira de migrar bancos de dados com mínimo de tempo de inatividade. Ao usar uma instância de replicação, o DMS pode replicar continuamente as alterações do banco de dados de origem para a instância de RDS de destino, permitindo que a aplicação permaneça operacional até a mudança final, garantindo a integridade dos dados e mínima interrupção.",
        "Other Options": [
            "Exportar o banco de dados para um arquivo plano requer um tempo de inatividade significativo, pois o banco de dados deve estar offline durante o processo de exportação, tornando-o inadequado para minimizar o tempo de inatividade.",
            "Realizar um processo de backup e restauração manual exigiria que a aplicação estivesse offline, levando a um tempo de inatividade significativo e interrupção dos serviços durante a migração.",
            "Usar o AWS Snowball para transferência de banco de dados não é eficiente para este cenário, pois leva a um tempo de inatividade prolongado enquanto os dados estão sendo transportados fisicamente e enviados para a AWS."
        ]
    },
    {
        "Question Number": "54",
        "Situation": "Uma empresa de serviços financeiros precisa implementar uma solução de recuperação de desastres para suas aplicações críticas hospedadas na AWS. As aplicações devem permanecer disponíveis com mínimo de tempo de inatividade e perda de dados em caso de falha. A empresa está atualmente usando várias Zonas de Disponibilidade dentro de uma única região para alta disponibilidade, mas deseja aprimorar sua estratégia de recuperação de desastres. O orçamento é limitado e eles têm um requisito para um objetivo de ponto de recuperação (RPO) de menos de 1 hora.",
        "Question": "Qual das seguintes soluções de recuperação de desastres na AWS atenderia melhor aos requisitos da empresa para mínimo tempo de inatividade e baixa perda de dados?",
        "Options": {
            "1": "Implementar uma arquitetura ativa-ativa em duas regiões da AWS com replicação de dados síncrona e Route 53 para failover de DNS.",
            "2": "Estabelecer uma solução de espera quente com uma implantação do Amazon RDS Multi-AZ e fazer backups regulares dos dados para o Amazon S3 para recuperação.",
            "3": "Implantar uma arquitetura ativa-passiva com Amazon S3 para armazenamento e usar AWS Lambda para automatizar o processo de failover quando necessário.",
            "4": "Configurar uma estratégia de recuperação de desastres de luz piloto com uma réplica de leitura do Amazon RDS em outra região e utilizar o AWS CloudFormation para implantação rápida."
        },
        "Correct Answer": "Estabelecer uma solução de espera quente com uma implantação do Amazon RDS Multi-AZ e fazer backups regulares dos dados para o Amazon S3 para recuperação.",
        "Explanation": "Uma solução de espera quente com Amazon RDS Multi-AZ fornece capacidades automáticas de failover e garante alta disponibilidade, enquanto backups regulares para o Amazon S3 atendem ao requisito de RPO de menos de 1 hora, permitindo uma recuperação eficiente em caso de falha.",
        "Other Options": [
            "Implementar uma arquitetura ativa-ativa é geralmente mais complexa e cara, e embora possa fornecer mínimo tempo de inatividade, pode exceder o orçamento limitado da empresa e não é necessária dadas suas exigências.",
            "A estratégia de luz piloto, embora forneça uma solução econômica, pode não atender efetivamente ao RPO de menos de 1 hora, pois geralmente envolve mais intervenção manual e tempo de configuração durante um desastre.",
            "Uma arquitetura ativa-passiva com S3 e AWS Lambda pode introduzir atrasos no failover e não garantir a rápida disponibilidade da aplicação, tornando-a menos adequada para a exigência da empresa de mínimo tempo de inatividade."
        ]
    },
    {
        "Question Number": "55",
        "Situation": "Uma empresa de serviços financeiros precisa armazenar dados sensíveis de clientes de uma forma que garanta durabilidade, segurança e conformidade com os requisitos regulatórios. Eles estão procurando uma solução de armazenamento da AWS que possa fornecer armazenamento de objetos escalável com capacidades de gerenciamento de ciclo de vida e criptografia em repouso. A empresa também quer garantir que os dados possam ser acessados via API e que tenham um custo baixo para acesso pouco frequente.",
        "Question": "Qual serviço de armazenamento da AWS o Arquiteto de Soluções deve recomendar para atender a esses requisitos?",
        "Options": {
            "1": "Amazon S3 com Object Lock habilitado e criptografia do lado do servidor para proteção de dados.",
            "2": "Amazon FSx for Windows File Server para fornecer um sistema de arquivos Windows gerenciado com recursos avançados de segurança.",
            "3": "Amazon Elastic File System (Amazon EFS) com recursos de criptografia e backup para garantir a segurança dos dados.",
            "4": "Amazon Elastic Block Store (EBS) com snapshots para backup e criptografia de volumes para proteger os dados."
        },
        "Correct Answer": "Amazon S3 com Object Lock habilitado e criptografia do lado do servidor para proteção de dados.",
        "Explanation": "Amazon S3 fornece armazenamento de objetos escalável que pode armazenar uma vasta quantidade de dados de forma segura. Com o Object Lock habilitado, permite políticas de retenção de dados que ajudam a garantir a conformidade com os requisitos regulatórios. Além disso, a criptografia do lado do servidor protege os dados em repouso, e o S3 oferece capacidades de gerenciamento de ciclo de vida para opções de armazenamento econômicas.",
        "Other Options": [
            "Amazon Elastic File System (Amazon EFS) é projetado principalmente para armazenamento de arquivos e pode não ser tão econômico para armazenamento de objetos em larga escala, especialmente para dados acessados com pouca frequência.",
            "Amazon FSx for Windows File Server é adaptado para aplicativos Windows e pode não ser a melhor opção para necessidades de armazenamento de objetos ou requisitos de acesso via API em comparação com o Amazon S3.",
            "Amazon Elastic Block Store (EBS) é tipicamente usado para armazenamento em bloco anexado a instâncias EC2 e, embora ofereça snapshots e criptografia, não fornece as características de escalabilidade e gerenciamento de ciclo de vida adequadas para cenários de armazenamento de objetos em larga escala."
        ]
    },
    {
        "Question Number": "56",
        "Situation": "Uma organização global de varejo deseja consolidar suas contas da AWS para gerenciar melhor custos, segurança e conformidade. A organização possui vários departamentos, cada um com sua própria conta da AWS, e está considerando uma nova estrutura de contas que possa escalar com seu crescimento, garantindo que cada departamento possa manter a autonomia necessária sobre suas cargas de trabalho. O arquiteto de soluções deve recomendar uma estrutura de contas que atenda melhor aos requisitos da organização.",
        "Question": "Qual das seguintes estruturas de contas o arquiteto de soluções deve recomendar para alcançar gerenciamento de custos, segurança e conformidade, permitindo ao mesmo tempo a autonomia departamental?",
        "Options": {
            "1": "Usar uma abordagem híbrida criando contas da AWS separadas para cada departamento enquanto estabelece uma conta de gerenciamento centralizada para supervisionar faturamento e conformidade.",
            "2": "Implantar várias Organizações AWS, uma para cada departamento, o que permite total autonomia, mas complica o gerenciamento centralizado de faturamento e conformidade.",
            "3": "Criar uma única conta da AWS para toda a organização e usar funções IAM para gerenciar o acesso departamental aos recursos, garantindo que cada departamento tenha controle sobre suas próprias cargas de trabalho.",
            "4": "Criar uma Organização AWS com várias Unidades Organizacionais (OUs), atribuindo a cada departamento sua própria OU para gerenciar recursos de forma independente, mantendo o faturamento centralizado."
        },
        "Correct Answer": "Criar uma Organização AWS com várias Unidades Organizacionais (OUs), atribuindo a cada departamento sua própria OU para gerenciar recursos de forma independente, mantendo o faturamento centralizado.",
        "Explanation": "Esta opção permite que a organização utilize o AWS Organizations para criar uma estrutura hierárquica com várias OUs. Cada departamento pode gerenciar seus próprios recursos e políticas enquanto se beneficia do faturamento e gerenciamento centralizados, o que se alinha com suas necessidades de gerenciamento de custos, segurança e conformidade.",
        "Other Options": [
            "Esta opção limita a capacidade da organização de gerenciar custos e segurança de forma eficaz. Embora as funções IAM possam fornecer controle de acesso, uma única conta carece da flexibilidade e dos recursos organizacionais fornecidos pelo AWS Organizations.",
            "Esta opção cria complexidade desnecessária na gestão. Múltiplas Organizações AWS levariam a desafios no faturamento centralizado, rastreamento de conformidade e compartilhamento de recursos, o que não é ideal para uma organização que busca gerenciamento eficiente.",
            "Esta opção fornece algum nível de separação para cada departamento, mas pode levar a um gerenciamento fragmentado de faturamento e conformidade. Uma abordagem centralizada por meio do AWS Organizations é mais eficaz para os objetivos da organização."
        ]
    },
    {
        "Question Number": "57",
        "Situation": "Uma empresa implantou um aplicativo web em múltiplas camadas em várias regiões da AWS, utilizando o Amazon RDS para sua camada de banco de dados. O aplicativo é crítico para as operações comerciais, e a empresa estabeleceu um plano de recuperação de desastres para garantir um tempo de inatividade mínimo em caso de falha regional. Para validar esse plano, a empresa deseja realizar um teste de recuperação de desastres sem impactar o ambiente de produção.",
        "Question": "Qual abordagem o Arquiteto de Soluções deve recomendar para realizar testes de recuperação de desastres de forma a minimizar os riscos para o ambiente de produção?",
        "Options": {
            "1": "Implantar uma réplica de leitura do Amazon RDS em uma região diferente, promovê-la a um banco de dados autônomo e usá-la para o teste de recuperação de desastres.",
            "2": "Configurar um banco de dados Amazon RDS na mesma região da produção, mas em uma zona de disponibilidade diferente, e realizar o teste de recuperação de desastres usando esta nova instância.",
            "3": "Usar o AWS CloudFormation para replicar a infraestrutura de produção em uma conta AWS separada, e então realizar o teste de recuperação de desastres lá sem afetar os recursos de produção.",
            "4": "Criar um snapshot do banco de dados RDS de produção, restaurá-lo em um ambiente de teste dentro da mesma região e realizar o teste de recuperação de desastres com esse snapshot."
        },
        "Correct Answer": "Usar o AWS CloudFormation para replicar a infraestrutura de produção em uma conta AWS separada, e então realizar o teste de recuperação de desastres lá sem afetar os recursos de produção.",
        "Explanation": "Usar o AWS CloudFormation para replicar a infraestrutura de produção em uma conta AWS separada permite um ambiente seguro para realizar testes de recuperação de desastres sem o risco de impactar o ambiente de produção. Isso garante que o teste possa ser realizado de forma isolada enquanto valida efetivamente o plano de recuperação de desastres.",
        "Other Options": [
            "Criar um snapshot do banco de dados RDS de produção e restaurá-lo na mesma região arrisca potenciais impactos de desempenho ou problemas de consistência de dados no ambiente de produção durante o teste.",
            "Implantar uma réplica de leitura do Amazon RDS em uma região diferente e promovê-la a um banco de dados autônomo pode levar à perda de dados ou inconsistência, uma vez que depende do atraso de replicação e não é um verdadeiro teste do plano de recuperação de desastres para a configuração de produção.",
            "Configurar um banco de dados Amazon RDS na mesma região, mas em uma zona de disponibilidade diferente, não isola totalmente o teste do ambiente de produção e pode levar a consequências indesejadas se o teste impactar os recursos regionais gerais."
        ]
    },
    {
        "Question Number": "58",
        "Situation": "Uma empresa de mídia está buscando migrar seu armazenamento de vídeo local para a AWS. A empresa requer uma solução que possa armazenar grandes arquivos de vídeo e fornecer alta disponibilidade e durabilidade. Além disso, a solução deve permitir acesso imediato a vídeos frequentemente acessados, enquanto também oferece uma maneira econômica de armazenar conteúdo acessado com pouca frequência. A empresa está considerando diferentes opções de armazenamento da AWS.",
        "Question": "Qual das seguintes soluções de armazenamento da AWS atende melhor aos requisitos da empresa para alta disponibilidade, durabilidade, acesso imediato a vídeos frequentemente acessados e armazenamento econômico para conteúdo acessado com pouca frequência?",
        "Options": {
            "1": "Amazon EBS com IOPS provisionadas para acesso de alto desempenho a arquivos de vídeo.",
            "2": "Amazon S3 com a classe de armazenamento Intelligent-Tiering para vídeos frequentemente e raramente acessados.",
            "3": "Amazon S3 Glacier para arquivamento de longo prazo de todos os arquivos de vídeo.",
            "4": "Amazon FSx for Windows File Server para compartilhar arquivos de vídeo entre várias instâncias."
        },
        "Correct Answer": "Amazon S3 com a classe de armazenamento Intelligent-Tiering para vídeos frequentemente e raramente acessados.",
        "Explanation": "Amazon S3 com Intelligent-Tiering é projetado para otimizar custos, movendo automaticamente dados entre duas camadas de acesso quando os padrões de acesso mudam. Essa solução fornece alta disponibilidade e durabilidade para grandes arquivos de vídeo, enquanto também garante que vídeos frequentemente acessados possam ser recuperados imediatamente, tornando-a ideal para os requisitos da empresa de mídia.",
        "Other Options": [
            "Amazon EBS é usado principalmente para armazenamento em bloco anexado a instâncias EC2 e não oferece o mesmo nível de durabilidade e disponibilidade para grandes arquivos de vídeo como o S3. Também carece dos recursos automáticos de otimização de custos necessários para conteúdo acessado com pouca frequência.",
            "Amazon S3 Glacier é projetado para armazenamento de longo prazo e não é adequado para acesso imediato a arquivos de vídeo, pois os tempos de recuperação podem variar de minutos a horas, o que não atende ao requisito da empresa para acesso rápido a vídeos frequentemente usados.",
            "Amazon FSx for Windows File Server é um serviço de sistema de arquivos Windows totalmente gerenciado que é adequado para compartilhamento de arquivos, mas não oferece a mesma escalabilidade, durabilidade e custo-benefício para armazenamento de vídeo em grande escala como o Amazon S3."
        ]
    },
    {
        "Question Number": "59",
        "Situation": "Uma empresa de mídia está migrando seu aplicativo de streaming de vídeo para a AWS. O aplicativo precisa suportar entrega de vídeo de alta qualidade com latência mínima para usuários em várias localizações geográficas. A arquitetura atual utiliza instâncias Amazon EC2 para processamento e um bucket Amazon S3 para armazenar arquivos de vídeo. A gestão está considerando diferentes mecanismos para transferir arquivos de vídeo do armazenamento local para a AWS de forma eficiente.",
        "Question": "Qual combinação de opções fornecerá o mecanismo de transferência MAIS eficiente para arquivos de vídeo? (Selecione Dois)",
        "Options": {
            "1": "Implementar uma estratégia de upload em múltiplas partes usando o AWS SDK para upload mais rápido de arquivos de vídeo.",
            "2": "Usar AWS Storage Gateway para criar uma solução de armazenamento em nuvem híbrida para transferência de dados sem interrupções.",
            "3": "Transferir arquivos de vídeo pela internet usando AWS Transfer Family com protocolo SFTP.",
            "4": "Utilizar AWS Direct Connect para estabelecer uma conexão de rede dedicada entre o local e a AWS.",
            "5": "Aproveitar o AWS Snowball para transferir grandes volumes de arquivos de vídeo de forma segura para a AWS."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Utilizar AWS Direct Connect para estabelecer uma conexão de rede dedicada entre o local e a AWS.",
            "Aproveitar o AWS Snowball para transferir grandes volumes de arquivos de vídeo de forma segura para a AWS."
        ],
        "Explanation": "Usar o AWS Direct Connect fornece uma conexão de alta largura de banda e baixa latência, ideal para transferir grandes arquivos de vídeo, garantindo uma transferência de dados eficiente e confiável. O AWS Snowball é especificamente projetado para migrações de dados em grande escala, permitindo a transferência segura e eficiente de volumes massivos de dados diretamente para a AWS sem depender de limitações de largura de banda.",
        "Other Options": [
            "AWS Storage Gateway é mais adequado para sincronização contínua de dados do que para transferências de dados em massa, tornando-o menos eficiente para grandes vídeos inicialmente.",
            "AWS Transfer Family é eficaz para transferências de arquivos menores, mas pode não ser ideal para grandes arquivos de vídeo devido a potenciais limitações de largura de banda da internet e latência.",
            "Uma estratégia de upload em múltiplas partes é útil para melhorar as velocidades de upload via HTTP, mas para grandes volumes de dados, AWS Snowball ou Direct Connect seriam mais eficientes."
        ]
    },
    {
        "Question Number": "60",
        "Situation": "Uma organização de serviços financeiros está revisando sua arquitetura de nuvem para identificar áreas que podem se beneficiar da automação. A arquitetura inclui vários serviços da AWS, como Amazon EC2, Amazon RDS e AWS Lambda. A equipe está focada em melhorar a eficiência operacional e reduzir a intervenção manual.",
        "Question": "Qual oportunidade de automação a organização deve priorizar para melhorar a eficiência operacional em sua arquitetura da AWS?",
        "Options": {
            "1": "Monitorar manualmente os métricas de desempenho de cada serviço usando o AWS Management Console.",
            "2": "Implementar Amazon CloudWatch Events para acionar funções AWS Lambda para tarefas rotineiras entre os serviços.",
            "3": "Agendar manutenção regular de instâncias EC2 usando AWS Systems Manager Run Command sem notificações automatizadas.",
            "4": "Utilizar AWS CloudFormation para implantar alterações de infraestrutura manualmente para cada serviço."
        },
        "Correct Answer": "Implementar Amazon CloudWatch Events para acionar funções AWS Lambda para tarefas rotineiras entre os serviços.",
        "Explanation": "Implementar Amazon CloudWatch Events para acionar funções AWS Lambda permite a automação de tarefas rotineiras, melhorando a eficiência operacional ao reduzir intervenções manuais e permitindo respostas em tempo real a eventos em toda a arquitetura.",
        "Other Options": [
            "Monitorar manualmente as métricas de desempenho é uma abordagem reativa e não aproveita a automação, o que limitaria as melhorias de eficiência.",
            "Agendar manutenção regular sem notificações automatizadas pode levar a atrasos na resolução de problemas, pois carece das capacidades proativas de monitoramento e resposta que a automação fornece.",
            "Utilizar o AWS CloudFormation manualmente derrota o propósito de infraestrutura como código, que é projetado para automatizar processos de implantação e gerenciamento."
        ]
    },
    {
        "Question Number": "61",
        "Situation": "Uma grande empresa de mídia precisa migrar enormes quantidades de dados arquivados de seu data center local para a AWS. A transferência de dados deve ser segura, econômica e capaz de lidar com petabytes de dados sem impactar significativamente o desempenho da rede existente da empresa. O arquiteto de soluções deve selecionar a ferramenta de migração de dados mais adequada que atenda a esses critérios, minimizando o tempo necessário para o processo de migração.",
        "Question": "Qual dos seguintes serviços da AWS é o mais apropriado para migrar grandes volumes de dados arquivados de um data center local para a AWS de forma segura e eficiente?",
        "Options": {
            "1": "AWS Transfer Family, pois oferece uma maneira simples de transferir arquivos para e da AWS usando os protocolos FTP, SFTP e FTPS, tornando-o adequado para grandes migrações de dados.",
            "2": "AWS Snowball, pois é especificamente projetado para transferir grandes quantidades de dados fisicamente usando dispositivos seguros e robustos, o que é ideal para migrações em escala de petabytes.",
            "3": "AWS DataSync, pois fornece transferência de dados automatizada e segura pela internet com criptografia embutida e é otimizado para migrações de dados em grande escala.",
            "4": "S3 Transfer Acceleration, pois acelera o upload de conteúdo para o Amazon S3 usando as localizações de borda distribuídas globalmente do Amazon CloudFront, tornando-o eficaz para grandes conjuntos de dados."
        },
        "Correct Answer": "AWS Snowball, pois é especificamente projetado para transferir grandes quantidades de dados fisicamente usando dispositivos seguros e robustos, o que é ideal para migrações em escala de petabytes.",
        "Explanation": "AWS Snowball é a melhor escolha para migrar volumes massivos de dados arquivados devido à sua capacidade de transferir petabytes de dados de forma segura usando dispositivos físicos. Esse método evita sobrecarregar a largura de banda da internet da empresa e garante um manuseio rápido e seguro dos dados durante o processo de migração.",
        "Other Options": [
            "AWS DataSync é ótimo para transferências de dados automatizadas pela internet, mas pode não ser o mais econômico para transferir petabytes de dados quando comparado a um dispositivo físico como o Snowball.",
            "AWS Transfer Family é projetado para protocolos de transferência de arquivos, mas não é otimizado para migrações de dados em grande escala, especialmente ao lidar com petabytes de dados arquivados.",
            "S3 Transfer Acceleration pode acelerar uploads para o S3, mas depende da internet, o que pode ser um gargalo ao transferir grandes volumes de dados, tornando-o menos adequado para este cenário."
        ]
    },
    {
        "Question Number": "62",
        "Situation": "Uma empresa de serviços financeiros implantou um aplicativo em múltiplas camadas na AWS que inclui instâncias do Amazon EC2 para a camada de aplicação, Amazon RDS para a camada de banco de dados e Amazon S3 para armazenar documentos enviados pelos usuários. O arquiteto de soluções é encarregado de avaliar a arquitetura existente para identificar áreas que podem não ser suficientemente confiáveis, especialmente durante os períodos de pico de uso, quando o aplicativo enfrenta alto tráfego. A empresa não implementou nenhuma forma de redundância ou failover para seus servidores de banco de dados ou de aplicação.",
        "Question": "Qual das seguintes ações o arquiteto de soluções deve recomendar para aumentar a confiabilidade da arquitetura durante os períodos de tráfego intenso?",
        "Options": {
            "1": "Implantar o aplicativo em uma instância EC2 com um tipo de instância maior para lidar com picos de tráfego.",
            "2": "Implementar Auto Scaling para as instâncias EC2 e usar implantações Multi-AZ do Amazon RDS para garantir alta disponibilidade do banco de dados.",
            "3": "Migrar para o Amazon DynamoDB para armazenamento de dados para eliminar a necessidade de redundância e escalabilidade.",
            "4": "Migrar o aplicativo para uma única instância EC2 que utiliza IOPS provisionados para melhorias de desempenho."
        },
        "Correct Answer": "Implementar Auto Scaling para as instâncias EC2 e usar implantações Multi-AZ do Amazon RDS para garantir alta disponibilidade do banco de dados.",
        "Explanation": "Implementar Auto Scaling para as instâncias EC2 permite que o aplicativo ajuste automaticamente o número de instâncias com base nas demandas de tráfego, enquanto as implantações Multi-AZ do Amazon RDS fornecem alta disponibilidade e suporte a failover para o banco de dados, garantindo que o aplicativo permaneça operacional mesmo durante cargas altas ou interrupções.",
        "Other Options": [
            "Migrar para o Amazon DynamoDB pode melhorar o desempenho, mas não aborda diretamente as preocupações de confiabilidade da arquitetura existente e pode introduzir complexidade adicional na modelagem de dados.",
            "Migrar o aplicativo para uma única instância EC2 cria um único ponto de falha e não fornece redundância ou a capacidade de escalar durante o tráfego intenso, o que é crítico para a confiabilidade.",
            "Implantar o aplicativo em uma instância EC2 maior pode melhorar o desempenho, mas não aborda a necessidade de redundância ou failover, deixando o aplicativo vulnerável a interrupções."
        ]
    },
    {
        "Question Number": "63",
        "Situation": "Uma empresa de análise de dados está processando grandes conjuntos de dados que requerem alta taxa de transferência e baixa latência. Eles estão usando uma arquitetura de aplicativo distribuído que aproveita várias instâncias do Amazon EC2 e precisam de um sistema de arquivos compartilhado que possa oferecer desempenho rápido para cargas de trabalho que envolvem dados frequentemente acessados. A empresa está buscando otimizar custos enquanto garante que o sistema de arquivos possa se integrar perfeitamente com seu lago de dados S3 existente para necessidades temporárias de processamento de dados.",
        "Question": "Qual das seguintes soluções atenderia MELHOR aos requisitos da empresa para um sistema de arquivos compartilhado de alto desempenho enquanto se integra de forma eficiente com o Amazon S3?",
        "Options": {
            "1": "Utilizar o Amazon FSx for Lustre para criar um sistema de arquivos compartilhado de alto desempenho que carrega dados do Amazon S3 para processamento, garantindo acesso de baixa latência a dados frequentemente acessados.",
            "2": "Configurar um bucket do Amazon S3 com políticas de ciclo de vida para automaticamente transitar dados frequentemente acessados para o Amazon Glacier para economia de custos em armazenamento.",
            "3": "Implantar um sistema de arquivos Amazon FSx for Windows File Server para fornecer acesso compartilhado a dados com aplicativos baseados em Windows e integrar com o Active Directory para autenticação.",
            "4": "Implementar um Amazon Elastic File System (EFS) para fornecer armazenamento de arquivos escalável para as instâncias EC2, permitindo escalabilidade automática para acomodar cargas de trabalho flutuantes."
        },
        "Correct Answer": "Utilizar o Amazon FSx for Lustre para criar um sistema de arquivos compartilhado de alto desempenho que carrega dados do Amazon S3 para processamento, garantindo acesso de baixa latência a dados frequentemente acessados.",
        "Explanation": "O Amazon FSx for Lustre é projetado para lidar com cargas de trabalho de alto desempenho e pode se integrar diretamente com o Amazon S3, permitindo que os dados sejam acessados de forma rápida e eficiente. Isso o torna uma solução ideal para os requisitos da empresa tanto em termos de desempenho quanto de otimização de custos.",
        "Other Options": [
            "Implantar um Amazon FSx for Windows File Server não é ideal para cargas de trabalho de alto desempenho, pois é projetado para aplicativos baseados em Windows e pode não fornecer a taxa de transferência e latência necessárias para a empresa de análise.",
            "Implementar o Amazon Elastic File System (EFS) fornece escalabilidade, mas pode não atender às necessidades de alto desempenho das cargas de trabalho de análise de dados em comparação com o FSx for Lustre, especialmente ao trabalhar com grandes conjuntos de dados.",
            "Configurar um bucket do Amazon S3 com políticas de ciclo de vida para transitar dados para o Amazon Glacier não é adequado, pois o Glacier é projetado para dados acessados com pouca frequência e aumentaria a latência para a necessidade da empresa de acesso rápido e compartilhado."
        ]
    },
    {
        "Question Number": "64",
        "Situation": "Uma empresa de serviços financeiros requer uma solução de backup confiável para seus dados críticos armazenados no Amazon S3. Os dados precisam ser copiados automaticamente, devem ser econômicos e devem garantir a continuidade dos negócios em várias Zonas de Disponibilidade para evitar perda de dados em caso de uma interrupção.",
        "Question": "Qual das seguintes arquiteturas melhor atende aos requisitos da empresa para uma solução de backup automatizada e econômica que suporte a continuidade dos negócios em várias Zonas de Disponibilidade?",
        "Options": {
            "1": "Configurar uma função AWS Lambda agendada que copia objetos do bucket S3 principal para outro bucket em uma região diferente usando a API S3.",
            "2": "Implementar uma Replicação entre Regiões do Amazon S3 para um bucket em outra região e usar políticas de ciclo de vida para transferir versões mais antigas para o Amazon S3 Glacier.",
            "3": "Utilizar o Amazon S3 Object Lock com versionamento habilitado para manter várias cópias dos objetos no mesmo bucket em diferentes Zonas de Disponibilidade.",
            "4": "Usar o AWS Backup para criar um plano de backup que automaticamente faz backup dos dados do S3 para outro bucket na mesma região com versionamento habilitado."
        },
        "Correct Answer": "Implementar uma Replicação entre Regiões do Amazon S3 para um bucket em outra região e usar políticas de ciclo de vida para transferir versões mais antigas para o Amazon S3 Glacier.",
        "Explanation": "Esta opção garante que os dados não apenas sejam copiados automaticamente para outra região, aumentando a durabilidade e a disponibilidade, mas também utiliza políticas de ciclo de vida para gerenciar custos ao transferir dados para uma classe de armazenamento de menor custo.",
        "Other Options": [
            "Embora o AWS Backup forneça boa funcionalidade, fazer backup para outro bucket na mesma região não atende ao requisito de continuidade dos negócios em várias Zonas de Disponibilidade ou Regiões.",
            "Usar uma função AWS Lambda agendada para copiar dados pode introduzir complexidade e potenciais pontos de falha, tornando-a menos confiável como solução de backup em comparação com recursos integrados como a Replicação entre Regiões.",
            "O Amazon S3 Object Lock com versionamento é benéfico para retenção de dados e proteção contra exclusões acidentais, mas não fornece uma solução de backup entre regiões, que é essencial para a continuidade dos negócios."
        ]
    },
    {
        "Question Number": "65",
        "Situation": "Uma instituição financeira está usando o Amazon S3 para armazenar dados sensíveis de clientes. Devido a requisitos de conformidade regulatória, eles precisam garantir que esses dados não possam ser excluídos ou modificados por um período de retenção específico. A instituição deseja implementar uma solução que garanta a integridade desses dados, permitindo ainda acesso e recuperação eficientes quando necessário. Eles estão considerando várias opções para gerenciar a retenção e proteção de dados.",
        "Question": "Qual solução a instituição financeira deve implementar para garantir a conformidade com as políticas de retenção de dados enquanto previne a exclusão ou modificação acidental de dados sensíveis?",
        "Options": {
            "1": "Habilitar o S3 Object Lock no modo de conformidade em um bucket versionado para impedir a exclusão ou modificação de objetos por um período de retenção especificado.",
            "2": "Utilizar o Amazon S3 Transfer Acceleration para acelerar transferências de dados e melhorar o acesso, enquanto confia em políticas IAM para controlar o acesso ao bucket.",
            "3": "Implementar o AWS Backup para criar backups regulares do conteúdo do bucket S3, garantindo que versões anteriores dos objetos possam ser restauradas se excluídas.",
            "4": "Configurar o Amazon CloudTrail para monitorar o acesso ao bucket S3 e alertar sobre quaisquer ações de exclusão, permitindo que os administradores tomem medidas corretivas."
        },
        "Correct Answer": "Habilitar o S3 Object Lock no modo de conformidade em um bucket versionado para impedir a exclusão ou modificação de objetos por um período de retenção especificado.",
        "Explanation": "Habilitar o S3 Object Lock no modo de conformidade garante que os objetos não possam ser excluídos ou sobrescritos durante o período de retenção especificado, atendendo assim aos requisitos regulatórios para proteção e integridade dos dados.",
        "Other Options": [
            "Implementar o AWS Backup não impede a exclusão ou modificação de objetos; simplesmente permite a recuperação de versões anteriores, o que não atende ao requisito de prevenir alterações durante o período de retenção.",
            "Utilizar o Amazon S3 Transfer Acceleration melhora as velocidades de transferência, mas não oferece proteção contra exclusão ou modificação; não atende ao requisito de conformidade.",
            "Configurar o Amazon CloudTrail permite monitorar ações realizadas no bucket S3, mas não impede exclusões ou modificações, portanto, não satisfaz a necessidade de proteção da retenção de dados."
        ]
    },
    {
        "Question Number": "66",
        "Situation": "Uma empresa está usando o AWS CloudFormation para gerenciar sua infraestrutura como código. A empresa possui um stack que consiste em vários recursos e deseja implementar uma política de stack para garantir que apenas certos recursos possam ser atualizados durante as atualizações do stack. A empresa também precisa implantar o mesmo stack em várias contas e regiões para manter a consistência em seus ambientes.",
        "Question": "Qual das seguintes abordagens permitirá que a empresa imponha atualizações de stack enquanto também habilita a implantação de stacks do CloudFormation em várias contas e regiões?",
        "Options": {
            "1": "Criar uma política de stack que nega atualizações a todos os recursos por padrão e atribuir diferentes políticas de stack a diferentes contas AWS usando funções IAM para flexibilidade nas atualizações.",
            "2": "Implementar uma política de stack que permite atualizações a todos os recursos e utilizar o AWS CloudFormation StackSets para gerenciar a implantação em várias regiões sem restrições.",
            "3": "Usar o AWS CloudFormation StackSets para criar um único stack que inclua todos os recursos e impeça atualizações por padrão. Uma política de stack separada não pode ser implementada neste cenário.",
            "4": "Definir uma política de stack em formato JSON que permita explicitamente atualizações apenas a recursos específicos. Usar o AWS CloudFormation StackSets para implantar a política de stack e o template em todas as contas e regiões alvo."
        },
        "Correct Answer": "Definir uma política de stack em formato JSON que permita explicitamente atualizações apenas a recursos específicos. Usar o AWS CloudFormation StackSets para implantar a política de stack e o template em todas as contas e regiões alvo.",
        "Explanation": "Esta opção descreve corretamente o processo de definição de uma política de stack que permite atualizações a recursos específicos enquanto usa StackSets para implantação em várias contas e regiões. Isso adere às melhores práticas da AWS para gerenciar infraestrutura como código.",
        "Other Options": [
            "Esta opção está incorreta porque o AWS CloudFormation não permite políticas de stack diferentes para diferentes contas. Uma única política de stack se aplica a todos os usuários que tentam atualizar o stack.",
            "Esta opção é enganosa, pois sugere criar um único stack com uma política que impede atualizações. Uma política de stack que nega atualizações a todos os recursos não atenderia ao requisito de permitir atualizações a recursos específicos.",
            "Esta opção está incorreta porque implementar uma política de stack que permite atualizações a todos os recursos contradiz o requisito de proteger recursos específicos durante as atualizações do stack."
        ]
    },
    {
        "Question Number": "67",
        "Situation": "Uma empresa de serviços financeiros está buscando implementar uma solução de registro centralizado para todos os eventos de segurança em seu ambiente AWS. A empresa deseja garantir a conformidade com os requisitos regulatórios, ao mesmo tempo em que melhora os tempos de resposta a incidentes. O arquiteto de soluções deve desenvolver uma estratégia que abranja o registro de vários serviços e aplicações da AWS, garantindo que os logs sejam armazenados de forma segura e facilmente acessíveis para auditorias.",
        "Question": "Qual arquitetura melhor suportará notificações centralizadas de eventos de segurança e auditoria para a empresa?",
        "Options": {
            "1": "Configurar o AWS Config para monitorar configurações e alterações de recursos, e integrá-lo ao AWS Security Hub para enviar alertas com base em violações de conformidade. Armazenar logs no Amazon S3 para armazenamento a longo prazo.",
            "2": "Utilizar o Amazon CloudWatch Logs para agregar logs de serviços da AWS e configurar o Amazon SNS para enviar notificações para eventos de segurança específicos. Armazenar logs no Amazon S3 com políticas de ciclo de vida para gerenciar a retenção.",
            "3": "Implantar um cluster do Amazon Elasticsearch Service para indexar logs de vários serviços da AWS, usando uma solução personalizada para enviar logs para o cluster. Configurar alertas via Amazon SNS com base em consultas do Elasticsearch.",
            "4": "Implementar o AWS CloudTrail para capturar chamadas de API e transmitir logs para o Amazon Kinesis para processamento em tempo real. Usar o Amazon S3 para armazenamento de logs e configurar o AWS Lambda para acionar alertas com base em padrões de log específicos."
        },
        "Correct Answer": "Utilizar o Amazon CloudWatch Logs para agregar logs de serviços da AWS e configurar o Amazon SNS para enviar notificações para eventos de segurança específicos. Armazenar logs no Amazon S3 com políticas de ciclo de vida para gerenciar a retenção.",
        "Explanation": "Usar o Amazon CloudWatch Logs permite a agregação de logs de vários serviços da AWS, proporcionando uma visão centralizada dos eventos de segurança. Juntando isso ao Amazon SNS, é possível ter notificações oportunas para eventos específicos, melhorando a resposta a incidentes. Armazenar logs no Amazon S3 com políticas de ciclo de vida garante conformidade com os requisitos de retenção de dados, ao mesmo tempo em que otimiza os custos de armazenamento.",
        "Other Options": [
            "Implementar o AWS CloudTrail captura principalmente chamadas de API, mas não fornece uma solução de registro abrangente para todos os eventos de segurança entre os serviços. Embora o Kinesis permita processamento em tempo real, pode não ser necessário para todos os casos de uso, e adiciona complexidade sem benefícios claros para o registro centralizado.",
            "Implantar um cluster do Amazon Elasticsearch Service requer uma sobrecarga adicional de gerenciamento e não fornece, por si só, um mecanismo de notificação para eventos de segurança. A solução personalizada para enviar logs adiciona complexidade e potenciais pontos de falha, o que pode dificultar a resposta oportuna a eventos.",
            "Configurar o AWS Config é mais focado em monitorar configurações de recursos do que no registro centralizado de eventos de segurança. Embora possa fornecer alertas de conformidade, não abrange a amplitude de eventos de segurança entre os serviços da AWS, tornando-se menos adequada para uma estratégia de auditoria abrangente."
        ]
    },
    {
        "Question Number": "68",
        "Situation": "Uma empresa está desenvolvendo uma arquitetura de microserviços na AWS que requer comunicação confiável entre diferentes serviços. Os serviços precisam enviar e receber mensagens de maneira desacoplada, garantindo que as mensagens não sejam perdidas, mesmo que o serviço receptor esteja temporariamente indisponível. A arquitetura também deve suportar diferentes tipos de cargas de trabalho, incluindo aquelas que requerem processamento em tempo real de eventos.",
        "Question": "Qual dos seguintes serviços da AWS seria a MELHOR escolha para implementar um sistema de mensagens confiável entre os microserviços?",
        "Options": {
            "1": "Usar o Amazon Simple Queue Service (Amazon SQS) para criar uma fila para processamento de mensagens.",
            "2": "Usar o Amazon Kinesis Data Streams para processar e analisar fluxos de dados em tempo real.",
            "3": "Usar o AWS Step Functions para orquestrar o fluxo de trabalho entre os serviços diretamente.",
            "4": "Usar o Amazon Simple Notification Service (Amazon SNS) para enviar mensagens a todos os assinantes."
        },
        "Correct Answer": "Usar o Amazon Simple Queue Service (Amazon SQS) para criar uma fila para processamento de mensagens.",
        "Explanation": "O Amazon SQS fornece um serviço de enfileiramento de mensagens confiável, escalável e totalmente gerenciado que permite comunicação desacoplada entre microserviços. Ele garante que as mensagens não sejam perdidas e possam ser processadas de forma assíncrona, tornando-o ideal para arquiteturas de microserviços.",
        "Other Options": [
            "O Amazon SNS é projetado para mensagens pub/sub e é mais adequado para transmitir mensagens a vários assinantes do que para garantir o processamento confiável de mensagens entre serviços.",
            "O AWS Step Functions é usado principalmente para orquestrar fluxos de trabalho complexos e gerenciar o estado das aplicações, em vez de servir como um serviço de mensagens.",
            "O Amazon Kinesis Data Streams é focado em streaming e processamento de dados em tempo real, o que não é o requisito principal para mensagens confiáveis entre microserviços."
        ]
    },
    {
        "Question Number": "69",
        "Situation": "Uma empresa global de serviços financeiros possui vários data centers locais e está buscando integrar seus sistemas com a AWS, garantindo transferência de dados segura e eficiente. Eles têm dados sensíveis que requerem uma conexão segura e baixa latência para processamento em tempo real. A empresa está avaliando opções para conectar sua rede local à AWS para otimizar sua arquitetura híbrida.",
        "Question": "Qual das seguintes opções fornece a conectividade mais eficiente e segura para integrar os data centers locais da empresa com a AWS, minimizando a latência para processamento em tempo real?",
        "Options": {
            "1": "Configurar o AWS Direct Connect para estabelecer uma conexão de fibra dedicada dos data centers locais para a AWS, emparelhada com um backup de VPN para redundância. Usar o Direct Connect para toda a transferência de dados para minimizar a latência e maximizar a largura de banda.",
            "2": "Implementar um AWS Transit Gateway para conectar múltiplas VPCs e redes locais. Usar o AWS Direct Connect com uma conexão VPN como backup. Essa configuração simplifica o gerenciamento, garantindo conectividade segura e eficiente.",
            "3": "Usar o AWS VPN CloudHub para conectar vários sites remotos a uma VPC da AWS. Essa solução oferece uma conexão segura, mas pode introduzir latência adicional devido à natureza das conexões VPN baseadas na internet.",
            "4": "Estabelecer uma conexão VPN usando o AWS Site-to-Site VPN para conectar os data centers locais à AWS. Utilizar o AWS Direct Connect para criar uma conexão dedicada para altas demandas de largura de banda, garantindo que o tráfego seja roteado pela VPN para segurança."
        },
        "Correct Answer": "Configurar o AWS Direct Connect para estabelecer uma conexão de fibra dedicada dos data centers locais para a AWS, emparelhada com um backup de VPN para redundância. Usar o Direct Connect para toda a transferência de dados para minimizar a latência e maximizar a largura de banda.",
        "Explanation": "Usar o AWS Direct Connect fornece uma conexão confiável e de alta velocidade com baixa latência, ideal para processamento de dados em tempo real. Emparelhá-lo com uma VPN para redundância garante conectividade segura caso o link do Direct Connect falhe.",
        "Other Options": [
            "Estabelecer uma conexão VPN com o AWS Site-to-Site VPN juntamente com o Direct Connect introduz complexidade desnecessária. A VPN rotearia o tráfego através do link do Direct Connect, negando alguns benefícios de baixa latência.",
            "Implementar um AWS Transit Gateway simplifica o gerenciamento, mas pode adicionar sobrecarga e latência no roteamento do tráfego. É mais benéfico para arquiteturas de rede complexas do que para conectividade direta.",
            "Usar o AWS VPN CloudHub conecta sites remotos, mas depende de conexões de internet, o que pode levar a uma latência maior. Essa opção não é adequada para a necessidade da empresa de conexões de baixa latência."
        ]
    },
    {
        "Question Number": "70",
        "Situation": "Uma empresa está avaliando seu portfólio de nuvem para otimizar custos e desempenho. A arquitetura atual inclui várias instâncias EC2 executando diversos aplicativos, mas a empresa não tem certeza se está utilizando os recursos de forma eficiente. O arquiteto de soluções é encarregado de realizar uma avaliação do portfólio para identificar melhorias potenciais.",
        "Question": "Qual das seguintes ações o arquiteto de soluções deve tomar PRIMEIRO para avaliar a utilização atual dos recursos das instâncias EC2?",
        "Options": {
            "1": "Implementar grupos de Auto Scaling para todas as instâncias EC2 para melhorar a eficiência.",
            "2": "Implantar o AWS CloudWatch para monitorar a utilização de CPU e memória nas instâncias EC2.",
            "3": "Ativar o AWS Cost Explorer para analisar os padrões de gastos nos últimos seis meses.",
            "4": "Usar o AWS CloudTrail para revisar as chamadas de API feitas para as instâncias EC2 em busca de métricas de desempenho."
        },
        "Correct Answer": "Implantar o AWS CloudWatch para monitorar a utilização de CPU e memória nas instâncias EC2.",
        "Explanation": "Implantar o AWS CloudWatch para monitorar a utilização de CPU e memória fornece insights imediatos sobre como os recursos estão sendo utilizados. Esses dados são essenciais para identificar instâncias subutilizadas ou superprovisionadas, permitindo decisões informadas sobre a otimização de recursos.",
        "Other Options": [
            "Implementar grupos de Auto Scaling é uma estratégia para otimizar a alocação de recursos, mas não fornece insights imediatos sobre a utilização atual, tornando-se um passo secundário após a avaliação do uso de recursos.",
            "Usar o AWS CloudTrail é útil para fins de auditoria e segurança, mas não fornece diretamente métricas de desempenho relacionadas à utilização de recursos. Não é o melhor primeiro passo em uma avaliação de portfólio.",
            "Ativar o AWS Cost Explorer ajuda a rastrear gastos, mas não fornece dados de utilização de recursos em tempo real. Compreender como os recursos estão sendo utilizados atualmente é crítico antes de analisar os custos."
        ]
    },
    {
        "Question Number": "71",
        "Situation": "Uma empresa de serviços financeiros está avaliando seus processos de implantação atuais para identificar áreas de melhoria. Os aplicativos da empresa estão implantados em instâncias Amazon EC2, mas a equipe enfrenta desafios com escalabilidade e eficiência operacional. Eles estão considerando uma mudança para uma arquitetura mais moderna que permita melhor utilização e gerenciamento de recursos. O objetivo é melhorar o desempenho enquanto reduz os custos operacionais.",
        "Question": "Considerando os requisitos da empresa para melhorar a escalabilidade e a eficiência operacional, qual estratégia de implantação a empresa deve adotar para alcançar seus objetivos?",
        "Options": {
            "1": "Implantar os aplicativos em uma mistura de instâncias Amazon EC2 On-Demand e Reservadas, garantindo que a escalabilidade seja tratada por intervenção manual com base nas cargas de trabalho projetadas.",
            "2": "Migrar os aplicativos para o Amazon ECS com AWS Fargate para eliminar a necessidade de gerenciar instâncias EC2 manualmente e garantir escalabilidade automática com base na demanda.",
            "3": "Continuar usando instâncias Amazon EC2, mas implementar uma solução de monitoramento abrangente para otimizar o uso das instâncias e ajustar manualmente a escalabilidade com base nas métricas de desempenho observadas.",
            "4": "Refatorar os aplicativos para rodar no AWS Lambda, permitindo uma arquitetura sem servidor que escala automaticamente com base em eventos e padrões de uso."
        },
        "Correct Answer": "Migrar os aplicativos para o Amazon ECS com AWS Fargate para eliminar a necessidade de gerenciar instâncias EC2 manualmente e garantir escalabilidade automática com base na demanda.",
        "Explanation": "Migrar para o Amazon ECS com AWS Fargate permite que a empresa se concentre na implantação de aplicativos sem gerenciar as instâncias EC2 subjacentes. O Fargate fornece capacidades de escalabilidade automática, otimizando o uso de recursos e reduzindo a sobrecarga operacional, o que está alinhado com os objetivos da empresa de eficiência e redução de custos.",
        "Other Options": [
            "Continuar com instâncias Amazon EC2 pode levar a desafios contínuos com escalabilidade e gerenciamento manual de recursos, o que não atende à necessidade da empresa de melhorar a eficiência operacional.",
            "Implantar uma mistura de instâncias On-Demand e Reservadas não simplifica o gerenciamento nem fornece escalabilidade automática, potencialmente levando a custos operacionais mais altos e uma utilização de recursos menos eficiente.",
            "Refatorar aplicativos para rodar no AWS Lambda pode não ser adequado para todas as cargas de trabalho, especialmente se não forem orientadas a eventos ou exigirem processos de longa duração. Essa abordagem pode introduzir complexidade e pode não estar alinhada com a arquitetura atual."
        ]
    },
    {
        "Question Number": "72",
        "Situation": "Uma empresa de serviços financeiros está planejando migrar seus aplicativos locais para a AWS. Os aplicativos consistem em uma mistura de servidores web, servidores de aplicativos e um banco de dados. A empresa deseja garantir o mínimo de tempo de inatividade durante a migração e manter o desempenho do aplicativo. Eles estão considerando várias ferramentas de migração da AWS para facilitar o processo.",
        "Question": "Qual ferramenta da AWS é mais adequada para avaliar as dependências dos aplicativos locais e planejar a estratégia de migração?",
        "Options": {
            "1": "AWS Database Migration Service",
            "2": "AWS Server Migration Service",
            "3": "AWS Application Migration Service",
            "4": "AWS Application Discovery Service"
        },
        "Correct Answer": "AWS Application Discovery Service",
        "Explanation": "O AWS Application Discovery Service é projetado especificamente para ajudar as organizações a descobrir e entender seus aplicativos locais, incluindo suas dependências e métricas de desempenho. Essas informações são cruciais para planejar uma estratégia de migração eficaz para a AWS com o mínimo de tempo de inatividade.",
        "Other Options": [
            "O AWS Application Migration Service foca principalmente na migração automatizada de aplicativos, em vez de avaliar e planejar a estratégia de migração.",
            "O AWS Database Migration Service é voltado para a migração de bancos de dados, não para avaliar dependências de aplicativos em vários tipos de servidores.",
            "O AWS Server Migration Service é usado para automatizar a migração de servidores virtuais para a AWS, mas não fornece uma análise abrangente das dependências de aplicativos."
        ]
    },
    {
        "Question Number": "73",
        "Situation": "Uma empresa está enfrentando aumentos inesperados em sua fatura da AWS devido a padrões de uso flutuantes de seus serviços em nuvem. O arquiteto de soluções precisa projetar uma estratégia de gerenciamento de custos que inclua a configuração de alarmes de faturamento com base em padrões de uso esperados. A estratégia deve ajudar a empresa a gerenciar proativamente os custos e receber alertas antes que excedam os limites orçamentários.",
        "Question": "Qual das seguintes abordagens é a maneira mais eficaz de projetar alarmes de faturamento com base em padrões de uso esperados?",
        "Options": {
            "1": "Configurar o AWS CloudTrail para registrar todas as chamadas de API relacionadas ao faturamento e definir alertas com base nos dados registrados para monitorar picos de uso.",
            "2": "Criar AWS Budgets para definir limites personalizados de custo e uso, e usar o Amazon CloudWatch para acionar alarmes quando o limite do orçamento for excedido.",
            "3": "Implementar o AWS Cost Explorer para analisar o uso passado e definir alertas com base em padrões de uso médio, utilizando o SNS para notificações.",
            "4": "Utilizar o AWS Trusted Advisor para gerar relatórios mensais de custos e monitorar manualmente os relatórios para acionar alertas quando os limites forem alcançados."
        },
        "Correct Answer": "Criar AWS Budgets para definir limites personalizados de custo e uso, e usar o Amazon CloudWatch para acionar alarmes quando o limite do orçamento for excedido.",
        "Explanation": "Criar AWS Budgets permite que a empresa defina limites específicos de custo e uso adaptados aos seus padrões esperados. Quando combinado com o Amazon CloudWatch, a empresa pode receber alertas imediatos quando esses limites forem excedidos, possibilitando um gerenciamento proativo de custos.",
        "Other Options": [
            "Implementar o AWS Cost Explorer é útil para analisar o uso, mas não fornece capacidades de alerta em tempo real. Ele ajuda na análise retrospectiva em vez de no gerenciamento proativo de custos.",
            "Configurar o AWS CloudTrail é focado no registro de chamadas de API e não se relaciona diretamente com a gestão de limites de faturamento. É utilizado principalmente para governança, conformidade e auditoria operacional.",
            "Utilizar o AWS Trusted Advisor para relatórios de custos fornece insights, mas carece da capacidade de alerta em tempo real necessária para um gerenciamento proativo. O monitoramento manual não é eficiente para controle de custos em tempo hábil."
        ]
    },
    {
        "Question Number": "74",
        "Situation": "Uma empresa de serviços financeiros está implantando um novo aplicativo usando a AWS. O aplicativo precisa garantir que as implantações possam ser revertidas rapidamente em caso de problemas e também precisa suportar implantações blue-green para minimizar o tempo de inatividade.",
        "Question": "Qual combinação de estratégias melhor satisfaz a exigência de reversões rápidas e implantações blue-green? (Selecione Dois)",
        "Options": {
            "1": "Implementar o AWS Elastic Beanstalk com versionamento de aplicativo.",
            "2": "Implantar com o Amazon ECS usando atualizações contínuas e verificações de integridade.",
            "3": "Usar o AWS CloudFormation para provisionamento de infraestrutura com atualizações de pilha.",
            "4": "Utilizar o AWS CodeDeploy com grupos de implantação para implantação blue-green.",
            "5": "Aproveitar o AWS Lambda com API Gateway para endpoints versionados."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Utilizar o AWS CodeDeploy com grupos de implantação para implantação blue-green.",
            "Implementar o AWS Elastic Beanstalk com versionamento de aplicativo."
        ],
        "Explanation": "Utilizar o AWS CodeDeploy permite configurar implantações blue-green, o que pode facilitar reversões rápidas. Além disso, implementar o AWS Elastic Beanstalk com versionamento de aplicativo permite que você reverta rapidamente para uma versão anterior do aplicativo, se necessário.",
        "Other Options": [
            "Usar o AWS CloudFormation é benéfico para gerenciar infraestrutura como código, mas não aborda especificamente o mecanismo de reversão para implantações de aplicativos.",
            "Implantar com o Amazon ECS usando atualizações contínuas é eficaz para minimizar o tempo de inatividade, mas pode não fornecer as capacidades de reversão rápida que as implantações blue-green oferecem.",
            "Aproveitar o AWS Lambda com API Gateway é ótimo para microsserviços, mas não suporta inherentemente implantações blue-green ou estratégias de reversão rápida."
        ]
    },
    {
        "Question Number": "75",
        "Situation": "Uma empresa de serviços financeiros armazena dados sensíveis de clientes em uma única instância do Amazon RDS. O banco de dados requer backups regulares para conformidade e recuperação de desastres. No entanto, a empresa teve algumas instâncias de perda de dados devido a erro humano e precisa projetar uma solução de backup que seja tanto automatizada quanto eficiente, garantindo a integridade e disponibilidade dos dados.",
        "Question": "Qual das seguintes opções é a solução mais eficaz para implementar um processo de backup robusto para a instância do Amazon RDS?",
        "Options": {
            "1": "Usar o AWS Backup para criar backups diários da instância do RDS e configurá-lo para reter cópias de backup por 30 dias, garantindo conformidade com os requisitos regulatórios.",
            "2": "Criar manualmente snapshots da instância do RDS todos os dias e armazená-los em um bucket S3 com versionamento habilitado para recuperar versões anteriores, se necessário.",
            "3": "Implementar um cron job em uma instância EC2 para exportar o banco de dados para um bucket S3 toda semana e excluir backups mais antigos após 60 dias.",
            "4": "Habilitar backups automatizados na instância do RDS, definir um período de retenção de 35 dias e configurar implantações multi-AZ para garantir alta disponibilidade e redundância de dados."
        },
        "Correct Answer": "Habilitar backups automatizados na instância do RDS, definir um período de retenção de 35 dias e configurar implantações multi-AZ para garantir alta disponibilidade e redundância de dados.",
        "Explanation": "Habilitar backups automatizados em uma instância do RDS fornece recuperação em ponto no tempo e garante que os backups sejam criados regularmente sem intervenção manual. Definir um período de retenção de 35 dias permite que a empresa atenda aos requisitos de conformidade, enquanto as implantações multi-AZ aumentam a disponibilidade e redundância dos dados.",
        "Other Options": [
            "Embora criar snapshots manualmente possa fornecer uma solução de backup, isso introduz o risco de erro humano e falta de automação, tornando-a menos confiável para proteção contínua de dados.",
            "Usar o AWS Backup é uma boa opção, mas não é o método mais eficiente em comparação com a habilitação de backups automatizados diretamente na instância do RDS, que é projetada para esse propósito.",
            "Implementar um cron job em uma instância EC2 adiciona sobrecarga operacional e complexidade ao processo de backup, e exportar o banco de dados semanalmente pode não atender aos objetivos de tempo de recuperação em caso de perda de dados."
        ]
    }
]