[
    {
        "Question Number": "1",
        "Situation": "Uma empresa está adotando infraestrutura imutável para o deployment de suas aplicações. Eles querem garantir que todas as mudanças na infraestrutura sejam feitas substituindo recursos em vez de modificá-los no local, visando melhor consistência e rollbacks mais fáceis.",
        "Question": "Qual das seguintes opções descreve melhor o princípio da infraestrutura imutável e seus benefícios? (Escolha duas.)",
        "Options": {
            "1": "A infraestrutura imutável garante que servidores e recursos sejam sempre modificados no local, evitando a necessidade de substituição de recursos.",
            "2": "A infraestrutura imutável envolve substituir servidores ou componentes da infraestrutura completamente quando mudanças são necessárias, garantindo que nenhuma alteração seja aplicada a instâncias em execução e facilitando rollbacks mais fáceis.",
            "3": "A infraestrutura imutável elimina a necessidade de controle de versão, uma vez que cada atualização é automaticamente integrada aos recursos existentes.",
            "4": "A infraestrutura imutável depende de configurações manuais de servidores, garantindo que nenhuma automação seja utilizada durante o processo de deployment.",
            "5": "A infraestrutura imutável melhora a consistência ao garantir que todos os deployments sejam idênticos e reduz a deriva de configuração."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "A infraestrutura imutável envolve substituir servidores ou componentes da infraestrutura completamente quando mudanças são necessárias, garantindo que nenhuma alteração seja aplicada a instâncias em execução e facilitando rollbacks mais fáceis.",
            "A infraestrutura imutável melhora a consistência ao garantir que todos os deployments sejam idênticos e reduz a deriva de configuração."
        ],
        "Explanation": "A infraestrutura imutável é um princípio em que servidores ou componentes da infraestrutura são substituídos completamente quando mudanças são necessárias, em vez de serem modificados no local. Isso garante que nenhuma alteração seja aplicada a instâncias em execução, facilitando rollbacks mais fáceis. Também melhora a consistência ao garantir que todos os deployments sejam idênticos, reduzindo a deriva de configuração. Essa abordagem pode reduzir significativamente o risco de inconsistências e erros na infraestrutura, tornando-a mais confiável e mais fácil de gerenciar.",
        "Other Options": [
            "A infraestrutura imutável não envolve modificar servidores e recursos no local. Em vez disso, envolve substituí-los completamente quando mudanças são necessárias.",
            "A infraestrutura imutável não elimina a necessidade de controle de versão. Na verdade, o controle de versão é crucial em uma infraestrutura imutável para acompanhar todas as diferentes versões dos componentes da infraestrutura.",
            "A infraestrutura imutável não depende de configurações manuais de servidores. Em vez disso, muitas vezes envolve automação para garantir que todos os deployments sejam idênticos e para facilitar a substituição de servidores ou componentes da infraestrutura quando mudanças são necessárias."
        ]
    },
    {
        "Question Number": "2",
        "Situation": "Uma empresa de varejo opera um site de e-commerce em instâncias Amazon EC2 atrás de um Application Load Balancer. A empresa experimenta padrões de tráfego flutuantes e quer garantir que a aplicação escale automaticamente para lidar com cargas variáveis enquanto minimiza custos.",
        "Question": "Quais configurações um arquiteto de soluções deve implementar para atender a esses requisitos? (Escolha duas.)",
        "Options": {
            "1": "Configurar um grupo de Auto Scaling com um número fixo de instâncias EC2 e usar Reserved Instances para economia de custos.",
            "2": "Usar Spot Instances com um grupo de Auto Scaling para lidar com tráfego variável.",
            "3": "Configurar um grupo de Auto Scaling com políticas de escalonamento de rastreamento de metas baseadas na utilização da CPU.",
            "4": "Implantar a aplicação no AWS Elastic Beanstalk com políticas de escalonamento manual.",
            "5": "Implementar escalonamento preditivo usando Amazon CloudWatch para prever tráfego e ajustar a capacidade proativamente."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Usar Spot Instances com um grupo de Auto Scaling para lidar com tráfego variável.",
            "Configurar um grupo de Auto Scaling com políticas de escalonamento de rastreamento de metas baseadas na utilização da CPU."
        ],
        "Explanation": "Spot Instances com um grupo de Auto Scaling são uma escolha econômica para lidar com tráfego variável porque permitem que você aproveite a capacidade EC2 não utilizada na nuvem AWS. As Spot Instances estão disponíveis com até 90% de desconto em comparação com os preços On-Demand. Um grupo de Auto Scaling com políticas de escalonamento de rastreamento de metas baseadas na utilização da CPU permite que a aplicação escale automaticamente com base na demanda. Quando a demanda aumenta, novas instâncias são adicionadas automaticamente e, quando a demanda diminui, as instâncias são removidas automaticamente. Isso garante que você esteja usando (e pagando por) apenas o que precisa.",
        "Other Options": [
            "Configurar um grupo de Auto Scaling com um número fixo de instâncias EC2 e usar Reserved Instances para economia de custos não é a melhor opção para lidar com tráfego variável, pois não permite escalonamento automático com base na demanda. Reserved Instances oferecem economia em relação às On-Demand Instances, mas não fornecem a flexibilidade necessária para padrões de tráfego flutuantes.",
            "Implantar a aplicação no AWS Elastic Beanstalk com políticas de escalonamento manual não é a melhor opção porque não permite escalonamento automático. O escalonamento manual requer intervenção manual para adicionar ou remover instâncias, o que não é ideal para lidar com padrões de tráfego flutuantes.",
            "Implementar escalonamento preditivo usando Amazon CloudWatch para prever tráfego e ajustar a capacidade proativamente pode ser uma boa opção para alguns casos de uso, mas não é a solução mais econômica para este cenário específico. O escalonamento preditivo usa algoritmos de aprendizado de máquina para prever padrões de tráfego futuros e ajustar a capacidade de acordo, o que pode ser mais caro do que outras opções."
        ]
    },
    {
        "Question Number": "3",
        "Situation": "Uma empresa está executando uma aplicação web que experimenta tráfego flutuante. Eles precisam garantir que a aplicação possa lidar com alto tráfego durante horários de pico sem superprovisionar recursos.",
        "Question": "Qual estratégia de escalonamento a empresa deve usar para gerenciar melhor a variabilidade do tráfego e a relação custo-efetividade?",
        "Options": {
            "1": "Usar escalonamento horizontal adicionando mais instâncias EC2 atrás de um load balancer para distribuir o tráfego, garantindo que os recursos escalem em resposta a mudanças na demanda.",
            "2": "Usar escalonamento vertical aumentando o tamanho das instâncias EC2 para lidar com mais tráfego, embora isso possa não fornecer tanta flexibilidade durante picos de tráfego.",
            "3": "Usar uma combinação de escalonamento horizontal e vertical, onde o escalonamento horizontal é usado para pequenas mudanças de tráfego e o escalonamento vertical é usado para lidar com picos extremos.",
            "4": "Usar escalonamento manual, ajustando os tamanhos das instâncias EC2 e o número de instâncias com base em previsões de padrões de tráfego."
        },
        "Correct Answer": "Usar escalonamento horizontal adicionando mais instâncias EC2 atrás de um load balancer para distribuir o tráfego, garantindo que os recursos escalem em resposta a mudanças na demanda.",
        "Explanation": "O escalonamento horizontal é a estratégia mais eficaz para gerenciar tráfego flutuante porque permite que a aplicação adicione ou remova instâncias com base na demanda em tempo real. Essa abordagem garante que durante horários de pico, instâncias EC2 adicionais possam ser provisionadas para lidar com o aumento do tráfego, enquanto durante horários de menor movimento, as instâncias podem ser reduzidas para economizar custos. Essa capacidade de escalonamento dinâmico proporciona tanto flexibilidade quanto custo-efetividade, já que os recursos são utilizados apenas quando necessário.",
        "Other Options": [
            "O escalonamento vertical envolve aumentar o tamanho das instâncias EC2 existentes para lidar com mais tráfego. Embora isso possa ser eficaz, tem limitações em flexibilidade e pode levar a tempo de inatividade durante operações de escalonamento. Além disso, há um limite máximo de tamanho para as instâncias, que pode não ser suficiente durante picos extremos de tráfego.",
            "Uma combinação de escalonamento horizontal e vertical pode proporcionar benefícios, mas complica a estratégia de escalonamento e pode não ser tão eficiente quanto usar apenas o escalonamento horizontal. O escalonamento horizontal é geralmente preferido para lidar com tráfego variável porque permite um controle mais granular sobre a alocação de recursos.",
            "O escalonamento manual depende de previsões de padrões de tráfego, que podem ser imprecisas. Essa abordagem não fornece a agilidade necessária para responder a mudanças súbitas de tráfego, levando a potenciais problemas de desempenho durante picos inesperados e custos desnecessários durante períodos de baixo tráfego."
        ]
    },
    {
        "Question Number": "4",
        "Situation": "Uma organização de saúde precisa garantir que todos os dados armazenados no Amazon RDS para PostgreSQL estejam criptografados em repouso e que as chaves de criptografia sejam gerenciadas de forma segura. A organização deve cumprir requisitos regulatórios rigorosos para proteção de dados.",
        "Question": "Qual solução atenderá a esses requisitos?",
        "Options": {
            "1": "Ativar criptografia em repouso usando a criptografia do Amazon RDS e gerenciar chaves com o AWS Key Management Service (KMS).",
            "2": "Usar o Amazon S3 para armazenar backups de banco de dados e ativar a criptografia do S3.",
            "3": "Implementar SSL/TLS para dados em trânsito e confiar na criptografia padrão do RDS.",
            "4": "Criptografar os dados dentro da aplicação antes de armazená-los no banco de dados RDS."
        },
        "Correct Answer": "Ativar criptografia em repouso usando a criptografia do Amazon RDS e gerenciar chaves com o AWS Key Management Service (KMS).",
        "Explanation": "Esta opção aborda diretamente a exigência de criptografar dados em repouso no Amazon RDS para PostgreSQL. O Amazon RDS fornece capacidades de criptografia integradas que podem ser ativadas para garantir que todos os dados armazenados no banco de dados estejam criptografados. Além disso, usar o AWS Key Management Service (KMS) permite o gerenciamento seguro das chaves de criptografia, o que é crucial para a conformidade com requisitos regulatórios sobre proteção de dados. Esta solução garante tanto a criptografia quanto o gerenciamento seguro de chaves de forma integrada.",
        "Other Options": [
            "Usar o Amazon S3 para armazenar backups de banco de dados e ativar a criptografia do S3 não atende ao requisito de criptografar dados em repouso dentro do banco de dados RDS em si. Embora a criptografia do S3 seja útil para backups, não aborda a criptografia dos dados do banco de dados ativo armazenados no RDS.",
            "Implementar SSL/TLS para dados em trânsito é importante para proteger dados enquanto viajam entre o cliente e o banco de dados, mas não fornece criptografia para dados em repouso. Além disso, confiar na criptografia padrão do RDS pode não atender a requisitos regulatórios específicos, pois não permite gerenciamento de chaves personalizadas ou verificações de conformidade.",
            "Criptografar os dados dentro da aplicação antes de armazená-los no banco de dados RDS é uma abordagem válida, mas requer esforço adicional de desenvolvimento e pode complicar o acesso e gerenciamento de dados. Além disso, não utiliza os recursos de criptografia integrados do RDS, que são projetados para simplificar a conformidade com regulamentos de proteção de dados."
        ]
    },
    {
        "Question Number": "5",
        "Situation": "Uma empresa está migrando sua aplicação local para a AWS. A aplicação consiste em um servidor web, um servidor de aplicação e um servidor de banco de dados. A empresa quer garantir que o servidor de banco de dados não seja acessível diretamente da internet e que só possa ser acessado pelo servidor de aplicação.",
        "Question": "Quais configurações de rede atenderão a esses requisitos? (Escolha duas.)",
        "Options": {
            "1": "Colocar o servidor web e o servidor de aplicação em uma sub-rede pública e o servidor de banco de dados em uma sub-rede privada. Configurar grupos de segurança para permitir tráfego apenas do servidor de aplicação para o servidor de banco de dados.",
            "2": "Colocar todos os servidores em uma sub-rede pública e usar ACLs de rede para restringir o acesso ao servidor de banco de dados.",
            "3": "Colocar o servidor web em uma sub-rede pública e os servidores de aplicação e banco de dados em sub-redes privadas separadas. Usar grupos de segurança para permitir tráfego apenas do servidor web para o servidor de aplicação e do servidor de aplicação para o servidor de banco de dados.",
            "4": "Colocar o servidor web e o servidor de banco de dados em uma sub-rede pública e o servidor de aplicação em uma sub-rede privada. Usar grupos de segurança para permitir tráfego apenas do servidor web para o servidor de aplicação.",
            "5": "Usar o AWS Transit Gateway para gerenciar o roteamento entre sub-redes e restringir o acesso ao servidor de banco de dados através de tabelas de roteamento."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Colocar o servidor web e o servidor de aplicação em uma sub-rede pública e o servidor de banco de dados em uma sub-rede privada. Configurar grupos de segurança para permitir tráfego apenas do servidor de aplicação para o servidor de banco de dados.",
            "Colocar o servidor web em uma sub-rede pública e os servidores de aplicação e banco de dados em sub-redes privadas separadas. Usar grupos de segurança para permitir tráfego apenas do servidor web para o servidor de aplicação e do servidor de aplicação para o servidor de banco de dados."
        ],
        "Explanation": "As respostas corretas são opções que colocam o servidor web e o servidor de aplicação em uma sub-rede pública, e o servidor de banco de dados em uma sub-rede privada. Essa configuração garante que o servidor de banco de dados não seja acessível diretamente da internet, conforme exigido. Grupos de segurança são então usados para controlar o tráfego, permitindo apenas que o servidor de aplicação acesse o servidor de banco de dados. Na segunda opção correta, os servidores de aplicação e banco de dados estão em sub-redes privadas separadas, o que adiciona uma camada extra de segurança e isolamento.",
        "Other Options": [
            "Colocar todos os servidores em uma sub-rede pública e usar ACLs de rede para restringir o acesso ao servidor de banco de dados não é uma boa prática. Isso expõe todos os servidores à internet, o que aumenta o risco de violações de segurança.",
            "Colocar o servidor web e o servidor de banco de dados em uma sub-rede pública e o servidor de aplicação em uma sub-rede privada não atende ao requisito de que o servidor de banco de dados seja inacessível da internet.",
            "Usar o AWS Transit Gateway para gerenciar o roteamento entre sub-redes e restringir o acesso ao servidor de banco de dados através de tabelas de roteamento não é o método mais eficiente ou seguro. Pode ser complexo de gerenciar e não fornece o mesmo nível de segurança que usar sub-redes privadas e públicas com grupos de segurança."
        ]
    },
    {
        "Question Number": "6",
        "Situation": "Uma empresa de varejo opera um site de e-commerce hospedado em instâncias do Amazon EC2 atrás de um Application Load Balancer. O site apresenta padrões de tráfego flutuantes, especialmente durante as temporadas de compras de pico, e a empresa deseja garantir que a aplicação escale automaticamente para lidar com cargas variáveis sem incorrer em custos desnecessários durante períodos de baixo tráfego. A equipe está em busca de uma configuração ideal para suportar o escalonamento automático enquanto minimiza os custos de infraestrutura.",
        "Question": "Qual configuração um arquiteto de soluções deve implementar para atender a esses requisitos?",
        "Options": {
            "1": "Configurar um grupo de Auto Scaling com um número fixo de instâncias do EC2 e reservar capacidade com Reserved Instances para economia de custos a longo prazo",
            "2": "Usar Spot Instances dentro de um grupo de Auto Scaling para lidar com o tráfego flutuante, permitindo que as instâncias escalem durante cargas de pico enquanto reduzem custos",
            "3": "Configurar um grupo de Auto Scaling com políticas de escalonamento de rastreamento de metas com base na utilização da CPU para ajustar dinamicamente a capacidade de acordo com a demanda",
            "4": "Implantar a aplicação no AWS Elastic Beanstalk e usar políticas de escalonamento manual para adicionar ou remover instâncias à medida que os padrões de tráfego mudam"
        },
        "Correct Answer": "Configurar um grupo de Auto Scaling com políticas de escalonamento de rastreamento de metas com base na utilização da CPU para ajustar dinamicamente a capacidade de acordo com a demanda",
        "Explanation": "Configurar um grupo de Auto Scaling com políticas de escalonamento de rastreamento de metas permite que a aplicação ajuste automaticamente o número de instâncias do EC2 com base na demanda em tempo real, especificamente na utilização da CPU neste caso. Essa configuração garante que a aplicação possa escalar durante períodos de tráfego intenso para lidar com cargas aumentadas e escalar para baixo durante períodos de baixo tráfego para minimizar custos. As políticas de escalonamento de rastreamento de metas são simples de implementar e gerenciar, proporcionando um equilíbrio entre desempenho e eficiência de custos.",
        "Other Options": [
            "Configurar um grupo de Auto Scaling com um número fixo de instâncias do EC2 não permite escalonamento dinâmico com base nos padrões de tráfego. Embora as Reserved Instances possam proporcionar economia de custos para uso a longo prazo, essa abordagem não atende efetivamente às necessidades de tráfego flutuante, pois não escala para baixo durante períodos de baixo tráfego.",
            "Usar Spot Instances dentro de um grupo de Auto Scaling pode reduzir custos, mas as Spot Instances podem ser encerradas pela AWS com pouco aviso, o que pode levar à instabilidade da aplicação durante cargas de pico. Esta opção não é ideal para uma empresa de varejo que requer disponibilidade consistente durante as temporadas de compras de alta demanda.",
            "Implantar a aplicação no AWS Elastic Beanstalk com políticas de escalonamento manual não fornece o escalonamento automático necessário para padrões de tráfego flutuantes. O escalonamento manual requer intervenção humana para ajustar o número de instâncias, o que pode levar a atrasos e potenciais problemas de desempenho durante os períodos de pico."
        ]
    },
    {
        "Question Number": "7",
        "Situation": "Uma empresa de mídia possui várias VPCs em diferentes contas da AWS e deseja habilitar uma comunicação privada e econômica entre as VPCs sem passar pela internet pública. Eles também querem reduzir os custos de transferência de dados associados a essa configuração.",
        "Question": "Qual configuração de rede seria a solução mais econômica?",
        "Options": {
            "1": "Usar VPC Peering entre cada VPC",
            "2": "Usar AWS Transit Gateway para comunicação centralizada entre VPCs",
            "3": "Roteamento de tráfego através de NAT gateways para acesso seguro",
            "4": "Estabelecer uma conexão VPN para cada VPC"
        },
        "Correct Answer": "Usar AWS Transit Gateway para comunicação centralizada entre VPCs",
        "Explanation": "O AWS Transit Gateway é projetado para simplificar a gestão de várias VPCs e permite comunicação privada e econômica entre elas. Ele permite um modelo de hub-and-spoke onde todas as VPCs podem se conectar a um gateway central, reduzindo a complexidade e o custo associados à gestão de várias conexões de peering entre VPCs. Além disso, o Transit Gateway pode ajudar a reduzir os custos de transferência de dados, pois consolida o tráfego através de um único ponto, em vez de exigir várias conexões de peering, que podem incorrer em cobranças mais altas de transferência de dados.",
        "Other Options": [
            "Usar VPC Peering entre cada VPC pode se tornar complexo e caro à medida que o número de VPCs aumenta. Cada VPC exigiria uma conexão de peering separada, levando a uma explosão combinatória de conexões e maior sobrecarga de gestão, além de potencialmente maiores custos de transferência de dados devido à natureza do peering entre VPCs.",
            "Roteamento de tráfego através de NAT gateways não é adequado para comunicação entre VPCs, pois os NAT gateways são usados principalmente para acesso à internet a partir de sub-redes privadas. Esta opção não facilitaria a comunicação direta entre VPCs e incorreria em custos adicionais para transferência de dados através do NAT gateway.",
            "Estabelecer uma conexão VPN para cada VPC seria ineficiente e caro, especialmente ao lidar com várias VPCs. Cada conexão VPN gera custos e adiciona complexidade à arquitetura da rede. Além disso, as conexões VPN geralmente têm menor largura de banda em comparação com outras opções e podem introduzir latência."
        ]
    },
    {
        "Question Number": "8",
        "Situation": "Uma empresa está implantando uma aplicação web que deve ser protegida contra ataques comuns baseados na web, como injeção de SQL e cross-site scripting.",
        "Question": "Qual serviço da AWS deve ser usado para fornecer essa proteção?",
        "Options": {
            "1": "AWS Shield",
            "2": "AWS WAF (Web Application Firewall)",
            "3": "Amazon Macie",
            "4": "Amazon GuardDuty"
        },
        "Correct Answer": "AWS WAF (Web Application Firewall)",
        "Explanation": "O AWS WAF (Web Application Firewall) é especificamente projetado para proteger aplicações web contra ataques comuns baseados na web, como injeção de SQL e cross-site scripting (XSS). Ele permite que os usuários criem regras que filtram e monitoram solicitações HTTP com base em condições personalizáveis, bloqueando efetivamente o tráfego malicioso antes que ele chegue à aplicação. Isso o torna a escolha mais adequada para o cenário descrito.",
        "Other Options": [
            "O AWS Shield é um serviço gerenciado de proteção contra DDoS que protege aplicações contra ataques de negação de serviço distribuídos. Embora forneça recursos de segurança importantes, não aborda especificamente vulnerabilidades de injeção de SQL ou cross-site scripting.",
            "O Amazon Macie é um serviço de segurança e privacidade de dados que usa aprendizado de máquina para descobrir, classificar e proteger dados sensíveis armazenados na AWS. Não é projetado para proteger aplicações web contra ataques baseados na web.",
            "O Amazon GuardDuty é um serviço de detecção de ameaças que monitora continuamente atividades maliciosas e comportamentos não autorizados para proteger contas e cargas de trabalho da AWS. Embora melhore a segurança geral, não fornece proteção específica contra ataques de injeção de SQL ou cross-site scripting."
        ]
    },
    {
        "Question Number": "9",
        "Situation": "Uma empresa está implantando uma aplicação web em múltiplas camadas na AWS. A aplicação consiste em uma camada de front-end em instâncias do Amazon EC2 e um banco de dados backend no Amazon RDS. A empresa exige que o banco de dados não seja acessível diretamente da internet e que apenas a camada de front-end possa se comunicar com o banco de dados.",
        "Question": "Qual configuração de rede o arquiteto de soluções deve implementar?",
        "Options": {
            "1": "Colocar tanto a camada de front-end quanto a camada de banco de dados em uma sub-rede pública e usar grupos de segurança para restringir o acesso.",
            "2": "Colocar a camada de front-end em uma sub-rede pública e a camada de banco de dados em uma sub-rede privada. Configurar grupos de segurança para permitir que apenas as instâncias de front-end se comuniquem com o banco de dados.",
            "3": "Colocar ambas as camadas em sub-redes privadas e usar um NAT gateway para acesso à internet.",
            "4": "Usar um internet gateway e tabelas de roteamento para controlar o acesso entre as camadas de front-end e banco de dados."
        },
        "Correct Answer": "Colocar a camada de front-end em uma sub-rede pública e a camada de banco de dados em uma sub-rede privada. Configurar grupos de segurança para permitir que apenas as instâncias de front-end se comuniquem com o banco de dados.",
        "Explanation": "Essa configuração garante que o banco de dados não seja acessível diretamente da internet, pois reside em uma sub-rede privada. A camada de front-end, que está em uma sub-rede pública, pode se comunicar com o banco de dados através de grupos de segurança que permitem tráfego apenas das instâncias de front-end. Essa configuração adere às melhores práticas de segurança e arquitetura na AWS, garantindo que o banco de dados esteja protegido contra acesso externo, enquanto ainda é acessível à camada da aplicação que precisa dele.",
        "Other Options": [
            "Colocar tanto a camada de front-end quanto a camada de banco de dados em uma sub-rede pública expõe o banco de dados à internet, o que viola o requisito de que o banco de dados não deve ser acessível diretamente da internet.",
            "Embora colocar ambas as camadas em sub-redes privadas aumente a segurança, isso não permite que a camada de front-end se comunique com o banco de dados, a menos que configurações adicionais (como um NAT gateway) sejam implementadas, o que é desnecessário para este cenário, já que o front-end precisa ser público.",
            "Usar um internet gateway e tabelas de roteamento para controlar o acesso exporia o banco de dados à internet, o que contradiz o requisito de manter o banco de dados inacessível da internet."
        ]
    },
    {
        "Question Number": "10",
        "Situation": "Uma plataforma de e-commerce deseja migrar seu banco de dados para a AWS, mas quer minimizar as mudanças de código. O banco de dados existente on-premises é PostgreSQL, e eles precisam de uma solução gerenciada que suporte alta disponibilidade e escalabilidade de leitura.",
        "Question": "Qual mecanismo de banco de dados na AWS atenderia melhor a esses requisitos?",
        "Options": {
            "1": "Amazon DynamoDB",
            "2": "Amazon Aurora com compatibilidade com PostgreSQL",
            "3": "Amazon RDS para MySQL",
            "4": "Amazon DocumentDB"
        },
        "Correct Answer": "Amazon Aurora com compatibilidade com PostgreSQL",
        "Explanation": "O Amazon Aurora com compatibilidade com PostgreSQL é a melhor escolha para migrar de um banco de dados PostgreSQL on-premises porque é projetado para ser compatível com PostgreSQL, o que significa que requer mudanças mínimas de código durante a migração. O Aurora também oferece alta disponibilidade através de suas implantações multi-AZ e capacidades de escalabilidade de leitura com réplicas de leitura, tornando-o adequado para plataformas de e-commerce que requerem desempenho confiável e escalabilidade.",
        "Other Options": [
            "O Amazon DynamoDB é um serviço de banco de dados NoSQL que não suporta consultas SQL ou os recursos do PostgreSQL que a aplicação existente provavelmente depende. Migrar para o DynamoDB exigiria mudanças significativas de código e uma re-arquitetura completa da aplicação.",
            "O Amazon RDS para MySQL é um serviço de banco de dados relacional gerenciado, mas é baseado em MySQL, não em PostgreSQL. Migrar para o RDS para MySQL exigiria mudanças substanciais de código para adaptar a aplicação à sintaxe e recursos do MySQL, o que não é ideal para minimizar mudanças de código.",
            "O Amazon DocumentDB é um serviço de banco de dados de documentos gerenciado que é compatível com MongoDB. Assim como o DynamoDB, não é compatível com PostgreSQL e exigiria uma reformulação completa do modelo de dados e do código da aplicação, tornando-o inadequado para este cenário de migração."
        ]
    },
    {
        "Question Number": "11",
        "Situation": "Uma empresa está planejando usar o Amazon Aurora para uma solução de banco de dados altamente disponível. Eles querem garantir que tenham um desempenho de leitura rápido e uma disponibilidade melhorada sem precisar gerenciar o provisionamento de armazenamento.",
        "Question": "Quais recursos do Amazon Aurora o tornam adequado para esse requisito, e como sua arquitetura difere do RDS padrão? (Escolha dois.)",
        "Options": {
            "1": "Aurora usa um volume de cluster compartilhado em várias Zonas de Disponibilidade (AZs) com armazenamento baseado em SSD, permitindo alta IOPS e baixa latência. Inclui um endpoint de cluster para operações de gravação e endpoints de leitura para distribuir o tráfego de leitura entre réplicas, o que melhora o desempenho de leitura.",
            "2": "Aurora requer armazenamento local em cada instância, portanto, o armazenamento deve ser provisionado e gerenciado separadamente, permitindo um melhor controle sobre a distribuição de dados.",
            "3": "Aurora escala automaticamente verticalmente dentro de uma única AZ, sem precisar de várias instâncias ou réplicas, garantindo alta disponibilidade com configuração mínima.",
            "4": "Aurora depende da gestão manual de armazenamento, onde a instância primária deve lidar tanto com o tráfego de leitura quanto com o de gravação, tornando-a adequada apenas para bancos de dados menores com requisitos de I/O baixos.",
            "5": "A arquitetura do Aurora separa computação e armazenamento, permitindo a escalabilidade independente de cada um, e fornece tolerância a falhas embutida ao replicar dados em várias AZs."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Aurora usa um volume de cluster compartilhado em várias Zonas de Disponibilidade (AZs) com armazenamento baseado em SSD, permitindo alta IOPS e baixa latência. Inclui um endpoint de cluster para operações de gravação e endpoints de leitura para distribuir o tráfego de leitura entre réplicas, o que melhora o desempenho de leitura.",
            "A arquitetura do Aurora separa computação e armazenamento, permitindo a escalabilidade independente de cada um, e fornece tolerância a falhas embutida ao replicar dados em várias AZs."
        ],
        "Explanation": "O Amazon Aurora é projetado para alta disponibilidade e durabilidade. Ele usa um volume de cluster compartilhado que abrange várias Zonas de Disponibilidade, com cada AZ tendo uma cópia do banco de dados. Essa arquitetura permite alta IOPS e baixa latência, o que melhora o desempenho de leitura. O Aurora também separa computação e armazenamento, o que permite que cada um escale de forma independente. Essa separação também fornece tolerância a falhas embutida ao replicar dados em várias AZs.",
        "Other Options": [
            "Aurora não requer armazenamento local em cada instância. Em vez disso, usa um volume de armazenamento compartilhado que abrange várias AZs. Portanto, o armazenamento não precisa ser provisionado e gerenciado separadamente.",
            "Aurora não escala automaticamente verticalmente dentro de uma única AZ. Em vez disso, usa uma arquitetura distribuída que abrange várias AZs. Essa arquitetura permite alta disponibilidade e tolerância a falhas.",
            "Aurora não depende da gestão manual de armazenamento. Em vez disso, gerencia automaticamente o armazenamento, escalando-o para cima e para baixo conforme necessário. A instância primária não precisa lidar com o tráfego de leitura e gravação, pois o Aurora fornece um endpoint de cluster para operações de gravação e endpoints de leitura para operações de leitura."
        ]
    },
    {
        "Question Number": "12",
        "Situation": "Um aplicativo de mídia social armazena postagens de usuários e precisa otimizar seu banco de dados para operações de leitura de alto volume e atualizações frequentes de gravação. O aplicativo também requer análises em tempo real sobre o engajamento dos usuários.",
        "Question": "Qual solução de banco de dados o arquiteto de soluções deve recomendar para lidar de forma eficiente com os padrões de acesso mistos?",
        "Options": {
            "1": "Amazon RDS para PostgreSQL com Réplicas de Leitura e Amazon Redshift para análises.",
            "2": "Amazon DynamoDB com capacidade provisionada e DynamoDB Streams integrado com AWS Lambda para processamento em tempo real.",
            "3": "Amazon Aurora Serverless com configuração multi-master para lidar com operações de leitura e gravação.",
            "4": "Amazon S3 com Amazon Athena para consultas e Amazon Kinesis para análises em tempo real."
        },
        "Correct Answer": "Amazon DynamoDB com capacidade provisionada e DynamoDB Streams integrado com AWS Lambda para processamento em tempo real.",
        "Explanation": "O Amazon DynamoDB é um serviço de banco de dados NoSQL totalmente gerenciado que fornece alto desempenho para operações de leitura e gravação, tornando-o ideal para aplicativos com padrões de acesso mistos. Sua capacidade provisionada permite escalabilidade com base nas necessidades do aplicativo, garantindo que ele possa lidar com operações de leitura de alto volume de forma eficiente. Além disso, o DynamoDB Streams pode ser usado para capturar alterações em itens no banco de dados, que podem acionar funções do AWS Lambda para processamento e análises em tempo real sobre o engajamento dos usuários. Essa combinação permite tanto o armazenamento eficiente de dados quanto análises em tempo real, atendendo efetivamente aos requisitos do aplicativo.",
        "Other Options": [
            "Amazon RDS para PostgreSQL com Réplicas de Leitura e Amazon Redshift para análises não é a melhor escolha porque, embora o RDS possa lidar com operações de leitura com réplicas de leitura, pode não escalar tão eficientemente para operações de gravação de alto volume em comparação com o DynamoDB. Além disso, usar o Redshift para análises introduz latência, pois é otimizado para processamento em lote em vez de análises em tempo real.",
            "Amazon Aurora Serverless com configuração multi-master poderia lidar com operações de leitura e gravação, mas pode não fornecer o mesmo nível de escalabilidade e desempenho para padrões de acesso de alto volume como o DynamoDB. O Aurora também é mais adequado para dados relacionais e pode não ser tão eficiente para análises em tempo real em comparação com a integração do DynamoDB com o Lambda.",
            "Amazon S3 com Amazon Athena para consultas e Amazon Kinesis para análises em tempo real não é adequado porque o S3 é principalmente um serviço de armazenamento e não suporta operações de gravação de alta frequência de forma eficiente. Embora o Kinesis possa lidar com fluxos de dados em tempo real, a combinação não fornece uma solução robusta para padrões de acesso mistos como o DynamoDB."
        ]
    },
    {
        "Question Number": "13",
        "Situation": "Uma grande corporação com vários departamentos usa contas AWS separadas para cada unidade de negócios e deseja monitorar e controlar os custos relacionados à rede. Eles precisam de uma maneira de identificar e alocar despesas de rede, como VPC, gateway NAT e custos de transferência de dados, para os departamentos apropriados para garantir uma distribuição de custos precisa e responsabilidade em toda a organização.",
        "Question": "Qual recurso de gerenciamento de custos da AWS ajudaria melhor a alcançar isso?",
        "Options": {
            "1": "Ativar tags de alocação de custos para recursos de rede, atribuindo tags por departamento para alocar custos relacionados à rede com precisão",
            "2": "Configurar Nuvens Privadas Virtuais (VPCs) separadas para cada departamento e monitorar os custos de cada VPC individualmente",
            "3": "Usar o AWS Trusted Advisor para monitorar e otimizar regularmente o uso da rede e obter recomendações para economia de custos",
            "4": "Estabelecer diferentes Zonas de Disponibilidade para cada departamento para acompanhar os custos de transferência de dados por zona"
        },
        "Correct Answer": "Ativar tags de alocação de custos para recursos de rede, atribuindo tags por departamento para alocar custos relacionados à rede com precisão",
        "Explanation": "Ativar tags de alocação de custos para recursos de rede permite que a corporação categorize e rastreie os custos associados a departamentos específicos. Ao atribuir tags a recursos como VPCs, gateways NAT e transferências de dados, a organização pode gerar relatórios de custos detalhados que refletem as despesas incorridas por cada departamento. Esse método fornece uma maneira clara e organizada de alocar custos relacionados à rede, garantindo responsabilidade e transparência entre as unidades de negócios.",
        "Other Options": [
            "Configurar Nuvens Privadas Virtuais (VPCs) separadas para cada departamento pode ajudar a isolar recursos, mas não fornece, por si só, um mecanismo para rastrear e alocar custos. Sem tags ou uma estratégia de gerenciamento de custos, seria desafiador distribuir custos com precisão entre os departamentos.",
            "Usar o AWS Trusted Advisor pode fornecer insights e recomendações para otimizar o uso de recursos e economia de custos, mas não aloca diretamente custos a departamentos específicos. Ele se concentra mais em melhores práticas e otimização de custos do que em rastreamento e alocação detalhados de custos.",
            "Estabelecer diferentes Zonas de Disponibilidade para cada departamento não se correlaciona diretamente com o rastreamento de custos de transferência de dados. As Zonas de Disponibilidade são principalmente sobre redundância e disponibilidade, em vez de alocação de custos. Os custos de transferência de dados geralmente são incorridos com base nos recursos utilizados e suas configurações, não nas zonas em si."
        ]
    },
    {
        "Question Number": "14",
        "Situation": "Uma startup está desenvolvendo um painel em tempo real que exibe métricas ao vivo de vários dispositivos IoT. O painel requer ingestão rápida de dados e acesso de baixa latência às métricas mais recentes para garantir atualizações oportunas. A solução também deve lidar com volumes de dados variados à medida que o número de dispositivos aumenta.",
        "Question": "Qual serviço da AWS o arquiteto de soluções deve usar para atender a esses requisitos de tamanho e velocidade? (Escolha dois.)",
        "Options": {
            "1": "Amazon S3 com Amazon Athena",
            "2": "Amazon Kinesis Data Streams",
            "3": "AWS Batch com Instâncias Spot do Amazon EC2",
            "4": "Amazon RDS com réplicas de leitura",
            "5": "Amazon DynamoDB com DynamoDB Streams"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon Kinesis Data Streams",
            "Amazon DynamoDB com DynamoDB Streams"
        ],
        "Explanation": "O Amazon Kinesis Data Streams é projetado para streaming de dados em tempo real. Ele pode capturar continuamente gigabytes de dados por segundo de centenas de milhares de fontes, tornando-o uma boa opção para lidar com a ingestão rápida de dados e acesso de baixa latência exigidos pelo painel. O Amazon DynamoDB com DynamoDB Streams também é uma boa opção, pois fornece acesso de baixa latência aos dados e pode lidar com altas cargas de tráfego, o que é útil quando o número de dispositivos aumenta. O DynamoDB Streams captura uma sequência de modificações em nível de item em qualquer tabela do DynamoDB e armazena esses dados por 24 horas.",
        "Other Options": [
            "Amazon S3 com Amazon Athena: Essa combinação é mais adequada para armazenar e consultar grandes conjuntos de dados, não para ingestão de dados em tempo real e acesso de baixa latência.",
            "AWS Batch com Instâncias Spot do Amazon EC2: Isso é mais adequado para trabalhos de processamento em lote e não para ingestão de dados em tempo real e acesso de baixa latência.",
            "Amazon RDS com réplicas de leitura: Embora isso possa ajudar a distribuir o tráfego de leitura, não é projetado para ingestão de dados em tempo real ou para lidar com volumes de dados variados de potencialmente milhares de dispositivos."
        ]
    },
    {
        "Question Number": "15",
        "Situation": "Um aplicativo de mídia social tem um alto volume de solicitações de leitura, com usuários frequentemente recuperando informações de perfil e feeds de notícias. O aplicativo está enfrentando problemas de latência, pois consulta diretamente um banco de dados Amazon Aurora para cada solicitação de leitura. A equipe de desenvolvimento deseja melhorar o desempenho de leitura e reduzir o custo de carga do banco de dados de forma econômica, e está aberta a fazer pequenas alterações no aplicativo.",
        "Question": "Qual solução o arquiteto de soluções deve recomendar?",
        "Options": {
            "1": "Implementar o Amazon ElastiCache com Redis para armazenar em cache dados frequentemente acessados e reduzir consultas ao banco de dados",
            "2": "Ativar réplicas de leitura no banco de dados Amazon Aurora para distribuir a carga de leitura",
            "3": "Usar o Amazon RDS Proxy para agrupar e compartilhar conexões de banco de dados para melhorar o desempenho",
            "4": "Armazenar dados frequentemente acessados no Amazon S3 e acessá-los diretamente do aplicativo"
        },
        "Correct Answer": "Implementar o Amazon ElastiCache com Redis para armazenar em cache dados frequentemente acessados e reduzir consultas ao banco de dados",
        "Explanation": "Implementar o Amazon ElastiCache com Redis é a solução mais eficaz para melhorar o desempenho de leitura e reduzir a carga no banco de dados Amazon Aurora. Ao armazenar em cache dados frequentemente acessados, como perfis de usuários e feeds de notícias, o aplicativo pode atender às solicitações de leitura diretamente do cache em vez de consultar o banco de dados para cada solicitação. Isso reduz significativamente a latência e a carga no banco de dados, levando a economias de custo e uma experiência de usuário melhorada. O ElastiCache é projetado para recuperação de dados em alta velocidade, tornando-o ideal para aplicativos com altos volumes de solicitações de leitura.",
        "Other Options": [
            "Ativar réplicas de leitura no banco de dados Amazon Aurora pode ajudar a distribuir a carga de leitura, mas não resolve os problemas de latência tão eficazmente quanto o armazenamento em cache. As réplicas de leitura ainda podem incorrer em custos e podem não fornecer as melhorias imediatas de desempenho necessárias para solicitações de leitura de alto volume.",
            "Usar o Amazon RDS Proxy para agrupar e compartilhar conexões de banco de dados pode melhorar o desempenho ao reduzir a sobrecarga de estabelecer conexões, mas não reduz diretamente o número de consultas de leitura enviadas ao banco de dados. Essa opção pode ajudar na gestão de conexões, mas não resolve o problema subjacente de latência causado pelo alto volume de solicitações de leitura.",
            "Armazenar dados frequentemente acessados no Amazon S3 e acessá-los diretamente do aplicativo não é ideal para recuperação de dados em tempo real, pois o S3 é projetado para armazenamento de objetos e pode introduzir latência adicional. Essa abordagem é mais adequada para conteúdo estático do que para dados dinâmicos que requerem atualizações frequentes, tornando-a menos eficaz para as necessidades do aplicativo."
        ]
    },
    {
        "Question Number": "16",
        "Situation": "Uma empresa financeira requer uma solução de armazenamento de arquivos totalmente gerenciada na AWS que possa suportar alta IOPS, baixa latência e recursos nativos do sistema de arquivos do Windows para armazenar e processar dados sensíveis de clientes. O sistema deve fornecer acesso seguro via SMB e integrar-se ao Active Directory local da empresa para autenticação de usuários.",
        "Question": "Qual configuração de serviço da AWS atenderia melhor a esses requisitos? (Escolha dois.)",
        "Options": {
            "1": "Amazon S3 com Transfer Acceleration para acesso em alta velocidade",
            "2": "Amazon FSx for Windows File Server em uma implantação Multi-AZ",
            "3": "Amazon EFS com criptografia em repouso e em trânsito",
            "4": "AWS Storage Gateway com Volumes em Cache",
            "5": "Amazon FSx for NetApp ONTAP com integração ao Active Directory"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon FSx for Windows File Server em uma implantação Multi-AZ",
            "AWS Storage Gateway com Volumes em Cache"
        ],
        "Explanation": "Amazon FSx for Windows File Server em uma implantação Multi-AZ é um sistema de arquivos nativo do Microsoft Windows totalmente gerenciado que pode suportar alta IOPS, baixa latência e recursos nativos do sistema de arquivos do Windows. Ele também fornece acesso seguro via SMB e integra-se ao Active Directory local para autenticação de usuários, atendendo a todos os requisitos mencionados. AWS Storage Gateway com Volumes em Cache pode ser usado para fornecer acesso de baixa latência aos dados na AWS a partir de aplicativos locais, armazenando dados frequentemente acessados localmente enquanto mantém todos os dados no Amazon S3. Ele também suporta integração com o Active Directory local para autenticação de usuários.",
        "Other Options": [
            "Amazon S3 com Transfer Acceleration para acesso em alta velocidade não suporta recursos nativos do sistema de arquivos do Windows e protocolo SMB. Também não se integra ao Active Directory local para autenticação de usuários.",
            "Amazon EFS com criptografia em repouso e em trânsito é um sistema de arquivos totalmente gerenciado que não é projetado para alta IOPS, baixa latência e não suporta recursos nativos do sistema de arquivos do Windows ou protocolo SMB.",
            "Amazon FSx for NetApp ONTAP com integração ao Active Directory é um serviço de sistema de arquivos totalmente gerenciado que suporta protocolo SMB e integra-se ao Active Directory local, mas não suporta recursos nativos do sistema de arquivos do Windows."
        ]
    },
    {
        "Question Number": "17",
        "Situation": "Uma empresa está executando um aplicativo web em instâncias EC2 atrás de um Application Load Balancer (ALB). O aplicativo precisa direcionar o tráfego com base em caminhos de URL, com serviços específicos lidando com certos tipos de solicitações. Eles também querem garantir que o tráfego seja distribuído uniformemente entre as instâncias para evitar que uma única instância fique sobrecarregada durante períodos de alto tráfego.",
        "Question": "Qual configuração a empresa deve aplicar para alcançar um balanceamento de carga eficiente?",
        "Options": {
            "1": "Configurar o ALB com roteamento baseado em caminho para direcionar o tráfego a diferentes grupos de destino com base em caminhos de URL, garantindo que o tráfego seja equilibrado uniformemente entre as instâncias EC2 em cada grupo.",
            "2": "Configurar o ALB para direcionar todo o tráfego a uma única instância EC2 para simplicidade, mas usar Auto Scaling para aumentar o tamanho da instância durante os horários de pico de tráfego.",
            "3": "Usar um Classic Load Balancer (CLB) em vez de ALB para suportar roteamento baseado em caminho e distribuir o tráfego com base em vários pontos finais de aplicativo.",
            "4": "Configurar vários ALBs, cada um atendendo ao tráfego de um domínio de aplicativo diferente, e direcionar o tráfego manualmente para cada ALB com base nos padrões de tráfego."
        },
        "Correct Answer": "Configurar o ALB com roteamento baseado em caminho para direcionar o tráfego a diferentes grupos de destino com base em caminhos de URL, garantindo que o tráfego seja equilibrado uniformemente entre as instâncias EC2 em cada grupo.",
        "Explanation": "Configurar o ALB com roteamento baseado em caminho permite que a empresa direcione o tráfego a diferentes grupos de destino com base nos caminhos de URL das solicitações recebidas. Isso significa que serviços específicos podem lidar com tipos específicos de solicitações, o que é essencial para a arquitetura do aplicativo. Além disso, o ALB automaticamente equilibra o tráfego entre as instâncias EC2 em cada grupo de destino, garantindo que nenhuma instância única fique sobrecarregada durante períodos de alto tráfego. Essa configuração é ideal para gerenciar o tráfego de forma eficiente e manter o desempenho do aplicativo.",
        "Other Options": [
            "Configurar o ALB para direcionar todo o tráfego a uma única instância EC2 não é uma solução viável para balanceamento de carga, pois anula o propósito de usar um balanceador de carga. Isso levaria a uma sobrecarga potencial nessa única instância, especialmente durante horários de pico de tráfego, e não utilizaria os benefícios de ter várias instâncias.",
            "Usar um Classic Load Balancer (CLB) em vez de ALB está incorreto porque CLBs não suportam roteamento baseado em caminho. ALBs são especificamente projetados para recursos avançados de roteamento, incluindo roteamento baseado em caminho, que é necessário para o requisito da empresa de direcionar o tráfego com base em caminhos de URL.",
            "Configurar vários ALBs para diferentes domínios de aplicativo e direcionar manualmente o tráfego para cada ALB adiciona complexidade desnecessária à arquitetura. Seria mais eficiente usar um único ALB com roteamento baseado em caminho para gerenciar o tráfego de vários serviços, o que simplifica a configuração e reduz a sobrecarga operacional."
        ]
    },
    {
        "Question Number": "18",
        "Situation": "Uma organização usa AWS Organizations e deseja implementar um limite de permissões em várias contas para impedir certas ações, mesmo para usuários com acesso administrativo total. A organização também deseja manter a sobrecarga administrativa baixa.",
        "Question": "Qual tipo de arquitetura de Política de Controle de Serviço (SCP) atenderia melhor a esses requisitos, e qual efeito terá sobre as permissões dos usuários IAM dentro da organização?",
        "Options": {
            "1": "Usar uma arquitetura de Lista de Permissão para permitir explicitamente apenas serviços específicos, limitando todas as outras ações para melhor segurança e mais controle.",
            "2": "Usar uma arquitetura de Lista de Negação para negar ações específicas, permitindo todas as outras ações por padrão, o que minimiza a sobrecarga de gerenciamento.",
            "3": "Usar uma arquitetura de Lista de Negação para negar explicitamente todas as ações, exigindo a adição manual de permissões para cada serviço necessário.",
            "4": "Usar uma arquitetura de Lista de Permissão para permitir ações apenas para o usuário root, bloqueando permissões para todos os usuários IAM dentro da organização."
        },
        "Correct Answer": "Usar uma arquitetura de Lista de Negação para negar ações específicas, permitindo todas as outras ações por padrão, o que minimiza a sobrecarga de gerenciamento.",
        "Explanation": "Uma arquitetura de Lista de Negação é eficaz neste cenário porque permite que a organização especifique apenas as ações que devem ser negadas, enquanto todas as outras ações permanecem permitidas por padrão. Essa abordagem minimiza a sobrecarga administrativa, uma vez que a organização não precisa gerenciar uma lista extensa de ações permitidas. Em vez disso, eles podem se concentrar em identificar e negar apenas as ações específicas que representam um risco, mantendo assim a flexibilidade para que os usuários IAM realizem suas tarefas sem restrições desnecessárias.",
        "Other Options": [
            "Usar uma arquitetura de Lista de Permissão exigiria que a organização definisse e permitisse explicitamente apenas serviços específicos, o que pode levar a um aumento da sobrecarga administrativa, pois precisariam atualizar continuamente a lista de serviços permitidos sempre que novos serviços fossem introduzidos ou quando serviços existentes precisassem ser modificados.",
            "Uma arquitetura de Lista de Negação que nega explicitamente todas as ações seria excessivamente restritiva e impraticável, pois exigiria que a organização adicionasse manualmente permissões para cada serviço necessário. Isso criaria uma sobrecarga significativa de gerenciamento e poderia prejudicar a produtividade, já que os usuários seriam bloqueados de realizar ações necessárias, a menos que fossem explicitamente permitidos.",
            "Usar uma arquitetura de Lista de Permissão para permitir ações apenas para o usuário root bloquearia efetivamente as permissões para todos os usuários IAM dentro da organização, o que contradiz o requisito de permitir que usuários com acesso administrativo realizem suas funções. Isso não atenderia ao objetivo da organização de implementar um limite de permissões enquanto ainda permite ações necessárias para usuários IAM."
        ]
    },
    {
        "Question Number": "19",
        "Situation": "Uma empresa está usando o AWS Key Management Service (KMS) para proteger dados sensíveis. A empresa deseja garantir que as chaves usadas para criptografar esses dados sejam gerenciadas e armazenadas com segurança dentro da AWS, sem nunca sair do ambiente AWS.",
        "Question": "Qual característica do AWS KMS garante que as chaves de criptografia permaneçam seguras e dentro da infraestrutura da AWS, e que tipo de criptografia ele suporta?",
        "Options": {
            "1": "As chaves KMS são isoladas dentro de uma região KMS dedicada e suportam apenas criptografia simétrica.",
            "2": "As chaves KMS nunca saem do AWS KMS e suportam tanto criptografia simétrica quanto assimétrica.",
            "3": "As chaves KMS podem ser exportadas da AWS para uso externo e suportam apenas criptografia assimétrica.",
            "4": "As chaves KMS são compartilhadas entre várias contas da AWS e suportam apenas criptografia simétrica."
        },
        "Correct Answer": "As chaves KMS nunca saem do AWS KMS e suportam tanto criptografia simétrica quanto assimétrica.",
        "Explanation": "O AWS Key Management Service (KMS) é projetado para gerenciar chaves de criptografia com segurança dentro do ambiente AWS. Uma de suas características principais é que as chaves de criptografia nunca são expostas fora da infraestrutura da AWS, garantindo que permaneçam seguras. Além disso, o AWS KMS suporta tanto criptografia simétrica (onde a mesma chave é usada para criptografia e descriptografia) quanto criptografia assimétrica (onde um par de chaves é usado). Essa flexibilidade permite que os usuários escolham o método de criptografia apropriado com base em seus requisitos de segurança.",
        "Other Options": [
            "As chaves KMS são isoladas dentro de uma região KMS dedicada e suportam apenas criptografia simétrica. Esta opção está incorreta porque, embora as chaves KMS sejam de fato específicas da região, elas suportam tanto criptografia simétrica quanto assimétrica, não apenas simétrica.",
            "As chaves KMS podem ser exportadas da AWS para uso externo e suportam apenas criptografia assimétrica. Esta opção está incorreta porque as chaves KMS não podem ser exportadas para uso externo; elas são projetadas para permanecer dentro da AWS. Além disso, o KMS suporta tanto criptografia simétrica quanto assimétrica, não apenas assimétrica.",
            "As chaves KMS são compartilhadas entre várias contas da AWS e suportam apenas criptografia simétrica. Esta opção está incorreta porque, embora as chaves KMS possam ser compartilhadas entre contas por meio de políticas de recursos, elas suportam tanto criptografia simétrica quanto assimétrica, não apenas simétrica."
        ]
    },
    {
        "Question Number": "20",
        "Situation": "Uma empresa implantou um Application Load Balancer (ALB) em várias Zonas de Disponibilidade (AZs) e ativou o balanceamento de carga entre zonas para distribuir o tráfego de entrada.",
        "Question": "Como o balanceamento de carga entre zonas melhora a distribuição de carga e que benefício ele oferece para lidar com picos de tráfego em uma AZ?",
        "Options": {
            "1": "O balanceamento de carga entre zonas permite que cada nó do balanceador de carga direcione o tráfego apenas para alvos dentro de sua própria AZ, proporcionando isolamento e resiliência em caso de falha da AZ.",
            "2": "O balanceamento de carga entre zonas permite que cada nó do balanceador de carga direcione o tráfego uniformemente entre os alvos em todas as AZs, garantindo uma distribuição de carga mais equilibrada e reduzindo o risco de sobrecarregar alvos em uma AZ.",
            "3": "O balanceamento de carga entre zonas direciona o tráfego para apenas um alvo por solicitação, reduzindo a latência e melhorando o desempenho para os usuários em cada AZ.",
            "4": "O balanceamento de carga entre zonas é eficaz apenas em configurações de uma única AZ e não tem impacto quando várias AZs estão envolvidas."
        },
        "Correct Answer": "O balanceamento de carga entre zonas permite que cada nó do balanceador de carga direcione o tráfego uniformemente entre os alvos em todas as AZs, garantindo uma distribuição de carga mais equilibrada e reduzindo o risco de sobrecarregar alvos em uma AZ.",
        "Explanation": "O balanceamento de carga entre zonas permite que o Application Load Balancer distribua o tráfego de entrada uniformemente entre todos os alvos registrados em diferentes Zonas de Disponibilidade, em vez de apenas os alvos na mesma AZ que o nó do balanceador de carga. Isso significa que, se uma AZ experimentar um pico de tráfego, o balanceador de carga pode direcionar o tráfego para alvos em outras AZs, evitando que uma única AZ se torne um gargalo. Essa capacidade melhora a resiliência e o desempenho geral do aplicativo, especialmente durante picos de tráfego.",
        "Other Options": [
            "O balanceamento de carga entre zonas permite que cada nó do balanceador de carga direcione o tráfego apenas para alvos dentro de sua própria AZ, proporcionando isolamento e resiliência em caso de falha da AZ. Isso está incorreto porque o balanceamento de carga entre zonas especificamente permite que o tráfego seja direcionado entre várias AZs, que é o oposto de direcionar apenas dentro de uma única AZ.",
            "Esta opção está incorreta porque representa mal a funcionalidade do balanceamento de carga entre zonas. Embora tenha como objetivo equilibrar a carga, ele o faz distribuindo o tráfego entre todas as AZs, não apenas garantindo uma distribuição uniforme entre os alvos em uma única AZ.",
            "Esta opção está incorreta porque o balanceamento de carga entre zonas não limita o tráfego a apenas um alvo por solicitação. Em vez disso, ele distribui o tráfego entre vários alvos, o que ajuda a gerenciar a carga de forma eficaz e melhorar o desempenho."
        ]
    },
    {
        "Question Number": "21",
        "Situation": "Uma plataforma de mídia social deseja monitorar e analisar conteúdo gerado por usuários em tempo real para detectar e responder rapidamente a postagens inadequadas. A plataforma precisa de uma solução escalável para processar fluxos contínuos de dados de milhões de usuários simultaneamente.",
        "Question": "Quais serviços da AWS o arquiteto de soluções deve recomendar para o processamento de dados em streaming neste cenário? (Escolha dois.)",
        "Options": {
            "1": "Amazon Simple Queue Service (SQS)",
            "2": "Amazon Kinesis Data Streams",
            "3": "Amazon Managed Streaming for Apache Kafka (MSK)",
            "4": "AWS Lambda com gatilhos programados",
            "5": "Amazon EventBridge"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon Kinesis Data Streams",
            "Amazon Managed Streaming for Apache Kafka (MSK)"
        ],
        "Explanation": "Amazon Kinesis Data Streams é projetado para coletar, processar e analisar dados em streaming em tempo real, permitindo que você obtenha insights oportunos e reaja rapidamente a novas informações. Ele pode lidar com qualquer quantidade de dados em streaming e processar dados de centenas de milhares de fontes com latências muito baixas. Amazon Managed Streaming for Apache Kafka (MSK) é um serviço totalmente gerenciado que facilita a construção e execução de aplicações que utilizam Apache Kafka para processar dados em streaming. É altamente adequado para tarefas de processamento de dados em tempo real de alto volume.",
        "Other Options": [
            "Amazon Simple Queue Service (SQS) é um serviço de fila de mensagens totalmente gerenciado que permite desacoplar e escalar microsserviços, sistemas distribuídos e aplicações sem servidor. No entanto, não é projetado para processamento de dados em streaming em tempo real.",
            "AWS Lambda com gatilhos programados é um serviço de computação que permite executar código sem provisionar ou gerenciar servidores. Embora o Lambda possa processar alterações de arquivos em tempo real, a opção de 'gatilhos programados' não se encaixa na exigência de tempo real do cenário.",
            "Amazon EventBridge é um barramento de eventos sem servidor que facilita a conexão de aplicações usando dados de suas próprias aplicações, aplicações integradas de Software como Serviço (SaaS) e serviços da AWS. Não é especificamente projetado para processamento de dados em streaming em tempo real."
        ]
    },
    {
        "Question Number": "22",
        "Situation": "Uma empresa precisa criptografar arquivos grandes que excedem 4 KB em tamanho usando o AWS Key Management Service (KMS). O processo de criptografia deve envolver tanto uma versão em texto simples para uso imediato quanto uma versão segura para armazenar junto aos dados criptografados.",
        "Question": "Qual recurso do KMS a empresa deve usar para atender a esses requisitos e como ele lida com a criptografia de dados maiores que 4 KB?",
        "Options": {
            "1": "Usar a chave KMS diretamente para criptografar os dados, pois o KMS suporta arquivos de qualquer tamanho sem etapas adicionais.",
            "2": "Gerar uma Chave de Criptografia de Dados (DEK) com o KMS, usar a DEK em texto simples para criptografar os dados e armazenar a DEK em texto cifrado junto aos dados criptografados.",
            "3": "Usar uma chave KMS gerenciada pelo cliente com uma política personalizada para permitir a criptografia de arquivos grandes e manter cópias tanto em texto simples quanto em texto cifrado.",
            "4": "Criptografar os dados diretamente no KMS dividindo-os em partes de 4 KB, criptografando cada parte separadamente e reassemblando após a descriptografia."
        },
        "Correct Answer": "Gerar uma Chave de Criptografia de Dados (DEK) com o KMS, usar a DEK em texto simples para criptografar os dados e armazenar a DEK em texto cifrado junto aos dados criptografados.",
        "Explanation": "O AWS Key Management Service (KMS) tem um limite de 4 KB para operações de criptografia direta. Para criptografar arquivos maiores, a abordagem recomendada é gerar uma Chave de Criptografia de Dados (DEK) usando o KMS. A DEK é então usada para criptografar os dados, permitindo a criptografia de arquivos maiores que 4 KB. A DEK em texto simples pode ser usada para descriptografia imediata, enquanto a DEK em texto cifrado (criptografada com a chave KMS) é armazenada junto aos dados criptografados para acesso seguro. Este método garante que o processo de criptografia seja eficiente e escalável para arquivos grandes.",
        "Other Options": [
            "Usar a chave KMS diretamente para criptografar os dados está incorreto porque o KMS tem um limite de tamanho de 4 KB para operações de criptografia. Arquivos maiores que isso precisam ser tratados de forma diferente, como usando uma DEK.",
            "Embora gerar uma DEK esteja correto, a opção não especifica que a DEK deve ser armazenada como texto cifrado junto aos dados criptografados. Isso é crucial para manter a segurança e permitir a descriptografia posteriormente.",
            "Usar uma chave KMS gerenciada pelo cliente com uma política personalizada não aborda diretamente a limitação de tamanho da criptografia KMS. O método de criptografar arquivos grandes ainda requer o uso de uma DEK, independentemente da política de gerenciamento de chaves."
        ]
    },
    {
        "Question Number": "23",
        "Situation": "Uma empresa precisa garantir que seu ambiente AWS atenda às melhores práticas de segurança e padrões de conformidade. A empresa deseja monitoramento contínuo de seus recursos AWS para detectar potenciais vulnerabilidades de segurança e garantir conformidade.",
        "Question": "Quais serviços da AWS o arquiteto de soluções deve recomendar? (Escolha dois.)",
        "Options": {
            "1": "AWS Config",
            "2": "Amazon GuardDuty",
            "3": "AWS Security Hub",
            "4": "AWS CloudTrail",
            "5": "AWS Shield Advanced"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "AWS Security Hub",
            "Amazon GuardDuty"
        ],
        "Explanation": "AWS Security Hub fornece uma visão abrangente de seus alertas de segurança de alta prioridade e status de conformidade em contas AWS. Ele agrega, organiza e prioriza seus alertas de segurança, ou descobertas, de vários serviços AWS, como Amazon GuardDuty, Amazon Inspector e Amazon Macie, bem como de soluções de parceiros da AWS. Amazon GuardDuty é um serviço de detecção de ameaças que monitora continuamente atividades maliciosas e comportamentos não autorizados para proteger suas contas e cargas de trabalho AWS. Ele analisa bilhões de eventos de várias fontes de dados da AWS, como logs de eventos do AWS CloudTrail, logs de fluxo do Amazon VPC e logs DNS.",
        "Other Options": [
            "AWS Config é um serviço que permite avaliar, auditar e avaliar as configurações de seus recursos AWS. Não fornece monitoramento contínuo para potenciais vulnerabilidades de segurança.",
            "AWS CloudTrail é um serviço que permite governança, conformidade, auditoria operacional e auditoria de riscos de sua conta AWS. No entanto, não fornece monitoramento contínuo para potenciais vulnerabilidades de segurança.",
            "AWS Shield Advanced fornece proteção contra DDoS e proteção de custos, mas não fornece monitoramento contínuo para potenciais vulnerabilidades de segurança."
        ]
    },
    {
        "Question Number": "24",
        "Situation": "Uma empresa de e-commerce multinacional requer uma solução de banco de dados altamente disponível que ofereça acesso de leitura de baixa latência para clientes em várias regiões. Para garantir resiliência e proteção contra interrupções regionais, a empresa também requer uma configuração de recuperação de desastres entre regiões com impacto mínimo no desempenho do banco de dados primário. Além disso, eles precisam de replicação quase em tempo real para regiões secundárias para as atualizações de dados mais rápidas possíveis.",
        "Question": "Qual solução de banco de dados da AWS atenderia melhor a esses requisitos?",
        "Options": {
            "1": "Implantar Amazon RDS com Multi-AZ para melhorar a alta disponibilidade dentro de uma única Região AWS",
            "2": "Usar Aurora Global Database para habilitar réplicas de leitura entre regiões, proporcionando acesso de leitura de baixa latência e replicação quase em tempo real com impacto mínimo no banco de dados primário",
            "3": "Configurar Amazon DynamoDB Global Tables para alcançar replicação entre regiões e acesso de baixa latência para cargas de trabalho NoSQL",
            "4": "Configurar Amazon Redshift com snapshots entre regiões para criar um backup em cada região para recuperação de desastres"
        },
        "Correct Answer": "Usar Aurora Global Database para habilitar réplicas de leitura entre regiões, proporcionando acesso de leitura de baixa latência e replicação quase em tempo real com impacto mínimo no banco de dados primário",
        "Explanation": "Aurora Global Database é especificamente projetado para aplicações com uma presença global que requerem leituras de baixa latência e alta disponibilidade em várias regiões. Ele permite a replicação quase em tempo real de dados para regiões secundárias, garantindo que os clientes nessas regiões possam acessar os dados de forma rápida e eficiente. Além disso, fornece resiliência contra interrupções regionais, pois o banco de dados pode falhar para uma região secundária com impacto mínimo no desempenho do banco de dados primário. Isso o torna a melhor opção para os requisitos da empresa de alta disponibilidade, acesso de baixa latência e recuperação de desastres entre regiões.",
        "Other Options": [
            "Implantar Amazon RDS com Multi-AZ melhora a alta disponibilidade dentro de uma única Região AWS, mas não fornece replicação entre regiões ou capacidades de recuperação de desastres. Portanto, não atende ao requisito de resiliência contra interrupções regionais.",
            "Usar Aurora Global Database é a escolha correta, portanto, esta opção não é aplicável como alternativa. É a melhor solução para os requisitos declarados.",
            "Configurar Amazon DynamoDB Global Tables proporcionaria replicação entre regiões e acesso de baixa latência, mas é principalmente adequado para cargas de trabalho NoSQL. O cenário não especifica a necessidade de um banco de dados NoSQL, e Aurora Global Database é uma opção mais adequada para necessidades de banco de dados relacionais com os requisitos especificados."
        ]
    },
    {
        "Question Number": "25",
        "Situation": "Uma empresa está executando uma aplicação web crítica na AWS e precisa configurar cotas de serviço para gerenciar o uso em um ambiente de espera. Eles querem garantir que sua carga de trabalho possa escalar com base na demanda sem exceder os limites de serviço, e também desejam aplicar limitação para evitar interrupções no serviço.",
        "Question": "Quais das seguintes etapas a empresa deve seguir para gerenciar cotas de serviço e limitação para o ambiente de espera?",
        "Options": {
            "1": "Usar AWS Service Quotas para definir limites para o uso do serviço e configurar AWS Lambda para escalar automaticamente os recursos com base nessas cotas, aplicando limitação para manter a estabilidade do serviço.",
            "2": "Configurar grupos de Auto Scaling para escalar instâncias EC2 de acordo com a carga de trabalho e ajustar manualmente as cotas de serviço no AWS Management Console para lidar com o tráfego de pico.",
            "3": "Usar Amazon API Gateway para definir limites de limitação em solicitações de API e configurar o CloudWatch para monitorar o uso em todo o ambiente de espera para garantir que os limites não sejam excedidos.",
            "4": "Usar Amazon SQS para enfileirar solicitações excedentes e atrasar o processamento para evitar limitação, enquanto configura AWS Lambda para escalonamento automático."
        },
        "Correct Answer": "Usar Amazon API Gateway para definir limites de limitação em solicitações de API e configurar o CloudWatch para monitorar o uso em todo o ambiente de espera para garantir que os limites não sejam excedidos.",
        "Explanation": "Usar o Amazon API Gateway para definir limites de limitação é uma maneira eficaz de gerenciar o número de solicitações que podem ser processadas pela aplicação web, evitando assim interrupções no serviço devido a carga excessiva. O API Gateway permite que você defina planos de uso que podem limitar solicitações e definir cotas, garantindo que a aplicação permaneça estável sob cargas variáveis. Além disso, integrar o CloudWatch para monitoramento permite que a empresa acompanhe métricas de uso em tempo real, possibilitando a gestão proativa dos limites de serviço e garantindo que não excedam os limites definidos.",
        "Other Options": [
            "Usar AWS Service Quotas para definir limites para o uso do serviço e configurar AWS Lambda para escalonamento automático não aborda diretamente a limitação para solicitações de API. Embora ajude a gerenciar limites de serviço, carece das capacidades específicas de limitação que o API Gateway fornece, que são cruciais para manter a estabilidade do serviço sob carga.",
            "Configurar grupos de Auto Scaling para escalar instâncias EC2 é uma boa prática para lidar com aumentos de carga de trabalho, mas não gerencia inherentemente cotas de serviço ou aplica limitação. Ajustar manualmente as cotas de serviço pode levar a atrasos e potenciais interrupções no serviço se não for feito em tempo real, o que não é ideal para um ambiente de espera que precisa responder rapidamente a mudanças na demanda.",
            "Usar Amazon SQS para enfileirar solicitações excedentes é uma abordagem válida para gerenciar carga, mas não aplica diretamente limitação a solicitações de API. Embora o SQS possa ajudar a evitar sobrecarregar os serviços de backend, não fornece o mesmo nível de controle sobre as taxas de solicitação que o API Gateway, e pode introduzir latência no processamento de solicitações."
        ]
    },
    {
        "Question Number": "26",
        "Situation": "Uma empresa de saúde, HealthSecure, está sujeita a rigorosas regulamentações de conformidade que exigem monitoramento contínuo e documentação da configuração de seus recursos em nuvem. A HealthSecure escolheu o AWS Config para rastrear e auditar mudanças em seu ambiente AWS para garantir a conformidade com padrões como HIPAA. Eles precisam de uma solução que possa avaliar recursos em relação a regras específicas de conformidade e remediar automaticamente recursos não conformes. No entanto, a HealthSecure também quer entender as limitações do AWS Config, especificamente se ele pode prevenir ativamente mudanças de configuração ou se apenas fornece capacidades de monitoramento e alerta.",
        "Question": "Como o AWS Config suporta a gestão de conformidade e o rastreamento de configuração de recursos em uma conta AWS, e quais são algumas limitações associadas ao seu funcionamento?",
        "Options": {
            "1": "O AWS Config permite que os usuários rastreiem mudanças de configuração em recursos e impede mudanças não autorizadas, aplicando conformidade em tempo real.",
            "2": "O AWS Config monitora e registra mudanças de configuração em recursos suportados, habilita auditoria para padrões de conformidade e pode remediar automaticamente recursos não conformes através da integração com o AWS Lambda. No entanto, ele não impede ativamente que mudanças ocorram.",
            "3": "O AWS Config fornece apenas instantâneas de configuração em intervalos específicos, o que limita sua eficácia para a gestão de conformidade, já que o monitoramento em tempo real não é suportado.",
            "4": "O AWS Config funciona apenas em uma única região e não pode agregar dados entre várias contas, tornando-o adequado apenas para ambientes isolados onde os recursos permanecem estáticos."
        },
        "Correct Answer": "O AWS Config monitora e registra mudanças de configuração em recursos suportados, habilita auditoria para padrões de conformidade e pode remediar automaticamente recursos não conformes através da integração com o AWS Lambda. No entanto, ele não impede ativamente que mudanças ocorram.",
        "Explanation": "O AWS Config foi projetado para fornecer monitoramento contínuo das configurações de recursos AWS e para rastrear mudanças ao longo do tempo. Ele permite que os usuários avaliem seus recursos em relação a regras de conformidade e pode acionar ações de remediação através do AWS Lambda quando configurações não conformes são detectadas. No entanto, é importante notar que o AWS Config não tem a capacidade de prevenir ativamente mudanças de configuração; ele apenas monitora e alerta sobre mudanças que ocorrem, tornando-se uma ferramenta poderosa para a gestão de conformidade, mas não uma preventiva.",
        "Other Options": [
            "O AWS Config não impede mudanças não autorizadas em tempo real; ele apenas monitora e alerta sobre mudanças após elas ocorrerem.",
            "O AWS Config fornece monitoramento quase em tempo real e não se limita a instantâneas de configuração em intervalos específicos; ele registra continuamente mudanças de configuração.",
            "O AWS Config pode operar em várias regiões e contas quando usado com o AWS Organizations, permitindo uma visão mais abrangente das configurações de recursos em toda a organização."
        ]
    },
    {
        "Question Number": "27",
        "Situation": "Uma organização de pesquisa científica armazena grandes conjuntos de dados no Amazon S3 que são frequentemente acessados por usuários externos. Para minimizar custos, eles querem que os usuários externos cubram o custo de acesso aos dados em vez da própria organização.",
        "Question": "Qual configuração do S3 eles devem usar para atender a esse requisito?",
        "Options": {
            "1": "Ativar a Aceleração de Transferência do S3",
            "2": "Configurar um bucket S3 com o Requester Pays ativado",
            "3": "Usar a Classe de Armazenamento S3 Intelligent-Tiering",
            "4": "Ativar a Replicação entre Regiões para compartilhamento de custos"
        },
        "Correct Answer": "Configurar um bucket S3 com o Requester Pays ativado",
        "Explanation": "Ativar o Requester Pays em um bucket S3 permite que os usuários externos que acessam os dados arcassem com os custos associados a seus pedidos. Isso significa que, quando os usuários acessam os dados, eles serão cobrados pela transferência de dados e pelos pedidos, transferindo efetivamente o ônus dos custos da organização para os usuários que acessam os dados. Essa configuração é especificamente projetada para cenários onde os dados são compartilhados com partes externas, tornando-se a opção mais adequada para o requisito da organização de minimizar custos.",
        "Other Options": [
            "Ativar a Aceleração de Transferência do S3 acelera a transferência de arquivos para e do S3, mas não altera quem paga pelo acesso aos dados. Os custos de uso da Aceleração de Transferência ainda são arcados pelo proprietário do bucket, não pelo solicitante.",
            "Embora o S3 Intelligent-Tiering seja uma classe de armazenamento que move automaticamente dados entre dois níveis de acesso com base em padrões de acesso em mudança, ele não aborda a alocação de custos para acesso a dados. A organização ainda seria responsável pelos custos associados à recuperação de dados.",
            "Ativar a Replicação entre Regiões é usado para replicar automaticamente dados entre diferentes regiões da AWS para redundância e disponibilidade. Este recurso não se relaciona ao compartilhamento de custos para acesso a dados e incorreria em custos adicionais para a organização sem atender ao requisito de que usuários externos cubram os custos de acesso."
        ]
    },
    {
        "Question Number": "28",
        "Situation": "Uma empresa de serviços financeiros gerencia um banco de dados transacional que experimenta cargas de trabalho variáveis, incluindo períodos de pico que exigem alta IOPS e capacidade de armazenamento. A empresa visa otimizar custos enquanto garante desempenho durante os períodos de pico.",
        "Question": "Qual configuração de armazenamento do Amazon RDS o arquiteto de soluções deve recomendar para atender a esses requisitos?",
        "Options": {
            "1": "Provisionar armazenamento SSD de Uso Geral (gp3) com escalonamento automático ativado.",
            "2": "Usar armazenamento Magnético com backups automatizados e capacidades de instantâneas.",
            "3": "Provisionar armazenamento SSD de IOPS Provisionadas (io1) com IOPS definidas para o máximo exigido durante os períodos de pico.",
            "4": "Implementar o Amazon Aurora com suas capacidades de escalonamento de armazenamento e alto desempenho."
        },
        "Correct Answer": "Implementar o Amazon Aurora com suas capacidades de escalonamento de armazenamento e alto desempenho.",
        "Explanation": "O Amazon Aurora é projetado para alto desempenho e disponibilidade, tornando-se uma excelente escolha para aplicações com cargas de trabalho variáveis. Ele escala automaticamente o armazenamento até 128 TB conforme necessário, o que é benéfico durante períodos de pico que exigem alta IOPS e capacidade de armazenamento. O Aurora também oferece alta taxa de transferência e baixa latência, garantindo que o desempenho seja mantido mesmo sob cargas pesadas, otimizando assim os custos enquanto atende aos requisitos de desempenho.",
        "Other Options": [
            "Provisionar armazenamento SSD de Uso Geral (gp3) com escalonamento automático ativado é uma boa opção para cargas de trabalho gerais, mas pode não fornecer o mesmo nível de desempenho e escalabilidade que o Amazon Aurora durante períodos de pico, especialmente para bancos de dados transacionais que exigem IOPS altas e consistentes.",
            "Usar armazenamento Magnético com backups automatizados e capacidades de instantâneas não é adequado para requisitos de alto desempenho. O armazenamento magnético é mais lento e não fornece a IOPS necessária para cargas de trabalho transacionais, tornando-o inadequado para necessidades de desempenho em pico.",
            "Provisionar armazenamento SSD de IOPS Provisionadas (io1) com IOPS definidas para o máximo exigido durante os períodos de pico pode ser eficaz, mas pode ser caro e pode não fornecer o mesmo nível de escalonamento automático e otimização de desempenho que o Amazon Aurora, especialmente se as cargas de trabalho forem variáveis e imprevisíveis."
        ]
    },
    {
        "Question Number": "29",
        "Situation": "Uma organização de pesquisa precisa migrar 80 TB de dados científicos de seu armazenamento NFS local para o Amazon S3. Os dados são frequentemente atualizados e a organização quer garantir que quaisquer mudanças feitas localmente sejam sincronizadas incrementalmente com a AWS. Eles também estão preocupados em saturar a largura de banda de sua rede durante o horário de trabalho.",
        "Question": "Quais recursos do AWS DataSync o arquiteto de soluções deve destacar como benefícios para essa migração? (Escolha dois.)",
        "Options": {
            "1": "Validação de dados durante a transferência para garantir a integridade dos dados",
            "2": "Replicação entre regiões para recuperação de desastres",
            "3": "Limitador de largura de banda para controlar o uso da rede durante horários de pico",
            "4": "Suporte para sincronização em tempo real com zero latência",
            "5": "Recuperação automática de erros de trânsito para transferência confiável"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Validação de dados durante a transferência para garantir a integridade dos dados",
            "Limitador de largura de banda para controlar o uso da rede durante horários de pico"
        ],
        "Explanation": "A validação de dados durante a transferência é um recurso chave do AWS DataSync que garante a integridade dos dados. Ele verifica se os dados lidos da localização de origem correspondem aos dados gravados no destino, garantindo assim que os dados não sejam corrompidos durante a transferência. Isso é crucial para a organização de pesquisa, pois precisa garantir a integridade de seus dados científicos. O recurso de limitador de largura de banda permite que a organização controle o uso da rede durante horários de pico. Isso é importante, pois a organização está preocupada em saturar a largura de banda de sua rede durante o horário de trabalho. O AWS DataSync permite que os usuários definam um limite na largura de banda que o DataSync utiliza, evitando que a rede fique saturada.",
        "Other Options": [
            "A replicação entre regiões para recuperação de desastres não é um recurso do AWS DataSync. Este é um recurso do Amazon S3, não do DataSync. O DataSync é usado para transferir dados para e de serviços de armazenamento da AWS, não fornece replicação entre regiões.",
            "O suporte para sincronização em tempo real com zero latência não é um recurso do AWS DataSync. Embora o DataSync suporte tarefas de transferência de dados programadas ou sob demanda, ele não fornece sincronização em tempo real com zero latência.",
            "A recuperação automática de erros de trânsito para transferência confiável não é um recurso específico do AWS DataSync. Embora o DataSync tenha um tratamento de erros robusto, ele não fornece especificamente um recurso de 'recuperação automática de erros de trânsito'."
        ]
    },
    {
        "Question Number": "30",
        "Situation": "Uma empresa está desenvolvendo uma aplicação de análise de dados que processa grandes volumes de arquivos de log gerados por seus servidores web. A aplicação requer acesso de baixa latência a dados de log frequentemente acessados e deve suportar operações de leitura e gravação simultâneas de várias instâncias. Além disso, a solução de armazenamento deve escalar automaticamente para acomodar volumes crescentes de dados sem intervenção manual.",
        "Question": "Qual serviço de armazenamento da AWS o arquiteto de soluções deve recomendar para atender a esses requisitos?",
        "Options": {
            "1": "Amazon S3 Standard",
            "2": "Amazon Elastic File System (Amazon EFS)",
            "3": "Amazon Elastic Block Store (Amazon EBS) IOPS Provisionadas",
            "4": "Amazon FSx for Windows File Server"
        },
        "Correct Answer": "Amazon Elastic File System (Amazon EFS)",
        "Explanation": "O Amazon Elastic File System (EFS) é projetado para acesso de baixa latência e pode suportar operações de leitura e gravação simultâneas de várias instâncias, tornando-o ideal para aplicações que requerem acesso frequente a dados. O EFS escala automaticamente à medida que dados são adicionados ou removidos, o que se alinha perfeitamente com o requisito de uma solução de armazenamento que acomode volumes crescentes de dados sem intervenção manual. Além disso, o EFS fornece um sistema de arquivos gerenciado que pode ser acessado de várias instâncias EC2, garantindo alta disponibilidade e durabilidade para os dados de log.",
        "Other Options": [
            "O Amazon S3 Standard é um serviço de armazenamento de objetos que é otimizado para durabilidade e escalabilidade, mas não é projetado para acesso de baixa latência ou operações de leitura/gravação simultâneas como um sistema de arquivos. É mais adequado para armazenar grandes quantidades de dados não estruturados do que para aplicações que requerem acesso frequente e baixa latência.",
            "O Amazon Elastic Block Store (Amazon EBS) IOPS Provisionadas é um serviço de armazenamento em bloco que fornece alto desempenho para instâncias EC2. No entanto, não é projetado para acesso simultâneo de várias instâncias, pois normalmente é anexado a uma única instância EC2 por vez. Isso o torna menos adequado para os requisitos de operações de leitura e gravação simultâneas.",
            "O Amazon FSx for Windows File Server é um sistema de arquivos Windows gerenciado que fornece armazenamento de arquivos compartilhados. Embora suporte acesso simultâneo, é mais complexo e pode não escalar automaticamente da mesma forma que o EFS. Também é mais voltado para ambientes Windows, o que pode não ser necessário para a aplicação descrita."
        ]
    },
    {
        "Question Number": "31",
        "Situation": "Uma empresa está implantando uma aplicação web e deseja garantir que ela possa escalar dinamicamente enquanto fornece alta disponibilidade em várias Zonas de Disponibilidade (AZs). Eles querem usar um Application Load Balancer (ALB) para distribuir o tráfego de forma eficiente.",
        "Question": "Qual das seguintes configurações permitiria melhor que a empresa alcançasse esse objetivo?",
        "Options": {
            "1": "Usar um ALB para distribuir o tráfego com base no caminho da URL e encaminhar solicitações para diferentes grupos de destino, garantindo que o tráfego seja distribuído uniformemente entre várias instâncias EC2.",
            "2": "Usar um Classic Load Balancer (CLB) para distribuir o tráfego com base apenas no endereço IP, sem roteamento por caminho de URL.",
            "3": "Usar um ALB, mas direcionar todo o tráfego para uma única instância EC2 para reduzir a complexidade e melhorar o desempenho.",
            "4": "Usar um ALB apenas para conteúdo estático e direcionar o tráfego de conteúdo dinâmico para uma única instância EC2 para manter um balanceamento de carga eficiente."
        },
        "Correct Answer": "Usar um ALB para distribuir o tráfego com base no caminho da URL e encaminhar solicitações para diferentes grupos de destino, garantindo que o tráfego seja distribuído uniformemente entre várias instâncias EC2.",
        "Explanation": "Usar um Application Load Balancer (ALB) para distribuir o tráfego com base no caminho da URL permite capacidades de roteamento avançadas, permitindo que a aplicação lide com diferentes tipos de solicitações de forma eficiente. Ao encaminhar solicitações para diferentes grupos de destino, o ALB pode garantir que o tráfego seja distribuído uniformemente entre várias instâncias EC2, o que é essencial para escalar dinamicamente e manter alta disponibilidade em várias Zonas de Disponibilidade (AZs). Essa configuração suporta tanto a escalabilidade horizontal quanto a utilização eficiente de recursos, que são críticas para aplicações web modernas.",
        "Other Options": [
            "Usar um Classic Load Balancer (CLB) para distribuir o tráfego com base apenas no endereço IP, sem roteamento por caminho de URL, limita a flexibilidade e a eficiência da gestão de tráfego. CLBs não suportam recursos de roteamento avançados, como roteamento baseado em caminho, o que pode levar a uma distribuição desigual do tráfego e potencialmente sobrecarregar certas instâncias enquanto subutiliza outras.",
            "Roteando todo o tráfego para uma única instância EC2 compromete o propósito de usar um ALB para balanceamento de carga. Essa configuração criaria um único ponto de falha e anularia os benefícios de alta disponibilidade e escalabilidade, pois não aproveita a capacidade do ALB de distribuir o tráfego entre várias instâncias.",
            "Usar um ALB apenas para conteúdo estático e direcionar o tráfego de conteúdo dinâmico para uma única instância EC2 limita as capacidades do balanceador de carga e pode levar a gargalos de desempenho. Essa abordagem não aproveita a capacidade do ALB de distribuir tanto conteúdo estático quanto dinâmico entre várias instâncias, o que é crucial para manter alta disponibilidade e escalabilidade."
        ]
    },
    {
        "Question Number": "32",
        "Situation": "Uma empresa de manufatura opera em uma localização remota com conectividade de internet limitada. Eles precisam de recursos de computação locais para analisar dados de máquinas e executar aplicações, mas também desejam a capacidade de sincronizar dados com a AWS quando a conectividade estiver disponível.",
        "Question": "Qual opção de computação híbrida atenderia melhor a esses requisitos?",
        "Options": {
            "1": "AWS Snowball Edge",
            "2": "AWS Lambda com endpoints VPC",
            "3": "Instâncias Amazon EC2 na região AWS mais próxima",
            "4": "Amazon EKS com escalabilidade sob demanda"
        },
        "Correct Answer": "AWS Snowball Edge",
        "Explanation": "AWS Snowball Edge é projetado para computação de borda e transferência de dados em ambientes com conectividade de internet limitada ou inexistente. Ele permite que os usuários executem aplicações e analisem dados localmente no dispositivo, o que é ideal para a empresa de manufatura em uma localização remota. Além disso, o Snowball Edge suporta a sincronização de dados com a AWS quando a conectividade está disponível, tornando-o uma solução perfeita para suas necessidades.",
        "Other Options": [
            "AWS Lambda com endpoints VPC não é adequado porque requer uma conexão de internet estável para acessar os serviços da AWS. Em uma localização remota com conectividade limitada, essa opção não forneceria os recursos de computação locais necessários.",
            "Instâncias Amazon EC2 na região AWS mais próxima não atenderiam às necessidades da empresa, pois elas requerem conectividade constante com a internet para acessar essas instâncias. Essa opção não fornece recursos de computação locais para análise de dados em uma área remota.",
            "Amazon EKS com escalabilidade sob demanda também depende de uma conexão de internet estável para gerenciar clusters Kubernetes na nuvem. Essa opção não funcionaria efetivamente em uma localização remota com conectividade limitada, pois não fornece recursos de computação locais."
        ]
    },
    {
        "Question Number": "33",
        "Situation": "Uma empresa de fintech está projetando uma nova plataforma de análise de dados para processar grandes volumes de dados de transações em tempo real. Para garantir alto desempenho, a plataforma precisa processar dados à medida que chegam, com atraso mínimo, e fornecer rapidamente insights aos usuários finais.",
        "Question": "Qual escolha arquitetônica atenderia de forma mais eficaz a esses requisitos de alto desempenho?",
        "Options": {
            "1": "Processamento em lote de dados de transações em intervalos regulares",
            "2": "Arquitetura orientada a eventos com streaming de dados em tempo real",
            "3": "Armazenar todos os dados de transações em um banco de dados relacional tradicional",
            "4": "Implantar todos os componentes da aplicação em uma única zona de disponibilidade para acesso mais rápido"
        },
        "Correct Answer": "Arquitetura orientada a eventos com streaming de dados em tempo real",
        "Explanation": "A arquitetura orientada a eventos com streaming de dados em tempo real é a escolha mais eficaz para processar grandes volumes de dados de transações em tempo real. Essa arquitetura permite que o sistema reaja aos dados que chegam à medida que eles chegam, possibilitando processamento e análise imediatos. Ela suporta alta taxa de transferência e baixa latência, que são críticas para fornecer insights oportunos aos usuários finais. Ao utilizar tecnologias como filas de mensagens e frameworks de processamento de streams, a plataforma pode lidar de forma eficiente com fluxos contínuos de dados e entregar resultados sem atrasos significativos.",
        "Other Options": [
            "O processamento em lote de dados de transações em intervalos regulares não é adequado para requisitos de alto desempenho que exigem processamento em tempo real. Essa abordagem introduz latência à medida que os dados são coletados e processados em lotes, o que pode atrasar insights e a capacidade de resposta.",
            "Armazenar todos os dados de transações em um banco de dados relacional tradicional pode fornecer armazenamento de dados estruturados, mas não é otimizado para processamento em tempo real. Bancos de dados relacionais geralmente requerem mais tempo para consultas e podem não lidar eficientemente com fluxos de dados de alta velocidade, levando a gargalos de desempenho.",
            "Implantar todos os componentes da aplicação em uma única zona de disponibilidade para acesso mais rápido não melhora inerentemente o desempenho do processamento de dados. Embora possa reduzir a latência para acesso local, não aborda a necessidade de processamento de dados em tempo real e pode levar a um único ponto de falha, comprometendo a confiabilidade do sistema."
        ]
    },
    {
        "Question Number": "34",
        "Situation": "Uma empresa de desenvolvimento web hospeda várias aplicações na AWS, com padrões de tráfego variados. Para otimizar custos, eles querem pagar apenas pelo que usam e evitar gerenciar servidores diretamente.",
        "Question": "Qual abordagem atenderia melhor a esses requisitos?",
        "Options": {
            "1": "Implantar aplicações em Amazon EC2 com Auto Scaling",
            "2": "Usar contêineres no Amazon ECS com Fargate",
            "3": "Executar aplicações em Instâncias Reservadas",
            "4": "Usar Amazon S3 para conteúdo estático e Amazon RDS para bancos de dados"
        },
        "Correct Answer": "Usar contêineres no Amazon ECS com Fargate",
        "Explanation": "Usar o Amazon ECS com Fargate permite que a empresa de desenvolvimento web execute suas aplicações em contêineres sem precisar gerenciar os servidores subjacentes. O Fargate provisiona e gerencia automaticamente os recursos de computação, o que significa que a empresa paga apenas pelos recursos que realmente utiliza com base nos padrões de tráfego de suas aplicações. Essa abordagem sem servidor é ideal para otimizar custos enquanto fornece a flexibilidade de escalar com base na demanda.",
        "Other Options": [
            "Implantar aplicações em Amazon EC2 com Auto Scaling requer gerenciar instâncias EC2, mesmo que elas escalem automaticamente. Essa abordagem pode não atender completamente ao requisito de evitar a gestão direta de servidores, pois a empresa ainda precisaria lidar com o provisionamento e a manutenção das instâncias.",
            "Executar aplicações em Instâncias Reservadas envolve comprometer-se com um tipo e tamanho de instância específicos por um período de um ou três anos, o que não se alinha ao objetivo de pagar apenas pelo que usam. Essa opção é mais econômica para cargas de trabalho previsíveis, mas não fornece a flexibilidade necessária para padrões de tráfego variados.",
            "Usar Amazon S3 para conteúdo estático e Amazon RDS para bancos de dados é uma boa abordagem para casos de uso específicos, mas não atende ao requisito de hospedar aplicações dinâmicas. Essa opção separa o armazenamento e a gestão de bancos de dados, mas não fornece uma solução completa para executar aplicações com padrões de tráfego variados."
        ]
    },
    {
        "Question Number": "35",
        "Situation": "Uma organização de pesquisa precisa armazenar dados experimentais em um banco de dados para análise. Os dados são usados ativamente nos primeiros três meses, depois raramente acessados, mas retidos por cinco anos para conformidade. Eles querem minimizar os custos de armazenamento a longo prazo.",
        "Question": "Qual política de retenção de dados seria a mais econômica?",
        "Options": {
            "1": "Armazenar todos os dados em um banco de dados de alto desempenho com backups diários",
            "2": "Arquivar dados no Amazon S3 Glacier após três meses",
            "3": "Excluir dados após três meses para reduzir custos de armazenamento",
            "4": "Mover dados para um nível de banco de dados de baixo custo após três meses"
        },
        "Correct Answer": "Arquivar dados no Amazon S3 Glacier após três meses",
        "Explanation": "Arquivar dados no Amazon S3 Glacier após três meses é a solução mais econômica para armazenamento a longo prazo. O S3 Glacier é projetado para dados que são acessados raramente e oferece custos de armazenamento significativamente mais baixos em comparação com bancos de dados de alto desempenho. Como os dados serão raramente acessados após os três meses iniciais, mas precisam ser retidos para conformidade por cinco anos, o S3 Glacier fornece um equilíbrio adequado entre custo e acessibilidade, permitindo que a organização minimize despesas enquanto ainda atende aos seus requisitos de retenção.",
        "Other Options": [
            "Armazenar todos os dados em um banco de dados de alto desempenho com backups diários não é econômico para armazenamento a longo prazo, especialmente porque os dados não serão usados ativamente após os primeiros três meses. Bancos de dados de alto desempenho são tipicamente mais caros, e backups diários adicionam custos adicionais que são desnecessários para dados que serão acessados raramente.",
            "Excluir dados após três meses pode reduzir custos de armazenamento, mas não atende ao requisito de conformidade de reter os dados por cinco anos. Essa opção exporia a organização a riscos legais e regulatórios devido à não conformidade.",
            "Mover dados para um nível de banco de dados de baixo custo após três meses é uma opção melhor do que mantê-los em um banco de dados de alto desempenho, mas ainda pode ser mais caro do que arquivá-los no S3 Glacier. Níveis de banco de dados de baixo custo podem ainda incorrer em custos mais altos em comparação com soluções de arquivamento projetadas para acesso raro, tornando essa opção menos ideal para armazenamento a longo prazo."
        ]
    },
    {
        "Question Number": "36",
        "Situation": "Uma organização deve cumprir as políticas de retenção de dados que exigem que certos registros sejam armazenados por pelo menos 7 anos.",
        "Question": "Qual solução é a MAIS apropriada para garantir a conformidade enquanto minimiza os custos de armazenamento?",
        "Options": {
            "1": "Armazenar os dados no Amazon S3 Standard com uma política de ciclo de vida do S3 para transitar os dados para o S3 Glacier",
            "2": "Armazenar os dados no Amazon Elastic File System (EFS) com a criptografia ativada",
            "3": "Usar o Amazon RDS com backups automatizados configurados para reter snapshots por 7 anos",
            "4": "Armazenar os dados no Amazon DynamoDB com backups sob demanda"
        },
        "Correct Answer": "Armazenar os dados no Amazon S3 Standard com uma política de ciclo de vida do S3 para transitar os dados para o S3 Glacier",
        "Explanation": "Esta opção é a mais apropriada porque permite uma gestão de armazenamento econômica. O Amazon S3 Standard é adequado para dados acessados com frequência, enquanto o S3 Glacier é projetado para armazenamento de arquivamento a longo prazo a um custo menor. Ao implementar uma política de ciclo de vida do S3, a organização pode automaticamente transitar dados para o S3 Glacier após um período especificado, garantindo a conformidade com a política de retenção de 7 anos enquanto minimiza os custos de armazenamento ao longo do tempo.",
        "Other Options": [
            "Armazenar os dados no Amazon Elastic File System (EFS) com a criptografia ativada não é a melhor escolha para armazenamento a longo prazo devido aos custos mais altos associados ao EFS em comparação com o S3 Glacier. O EFS é projetado para acesso de baixa latência e é mais caro para armazenar dados que são acessados com pouca frequência.",
            "Usar o Amazon RDS com backups automatizados configurados para reter snapshots por 7 anos pode ser caro e pode não ser necessário para dados que não requerem os recursos de um banco de dados relacional. O RDS é tipicamente usado para dados transacionais e pode incorrer em custos mais altos para armazenamento a longo prazo em comparação com o S3 Glacier.",
            "Armazenar os dados no Amazon DynamoDB com backups sob demanda também não é a solução mais econômica para retenção a longo prazo. Embora o DynamoDB seja ótimo para aplicações de alto desempenho, seu modelo de preços para backups pode se tornar caro ao longo do tempo, especialmente para dados que precisam ser retidos por vários anos."
        ]
    },
    {
        "Question Number": "37",
        "Situation": "Uma empresa tem um bucket S3 chamado \"secretcatproject\" que contém dados sensíveis. A empresa precisa permitir o acesso a esse bucket de usuários específicos em uma conta parceira, garantindo que os dados permaneçam seguros contra acesso público.",
        "Question": "Qual método a empresa deve usar para conceder o acesso necessário enquanto impede o acesso não autorizado por usuários anônimos?",
        "Options": {
            "1": "Definir a política do bucket para permitir acesso público a todos os usuários para simplificar a gestão de acesso.",
            "2": "Usar uma política de bucket S3 que especifique os papéis IAM da conta parceira como principais com permissão para acessar o bucket.",
            "3": "Ativar \"Bloquear Acesso Público\" no bucket e usar listas de controle de acesso (ACLs) para gerenciar o acesso para a conta parceira.",
            "4": "Anexar uma política IAM diretamente ao bucket para controlar o acesso para usuários na conta parceira."
        },
        "Correct Answer": "Usar uma política de bucket S3 que especifique os papéis IAM da conta parceira como principais com permissão para acessar o bucket.",
        "Explanation": "Usar uma política de bucket S3 para especificar os papéis IAM da conta parceira como principais permite um controle preciso sobre quem pode acessar o bucket. Este método garante que apenas os usuários designados da conta parceira possam acessar os dados sensíveis, enquanto também impede qualquer acesso público. As políticas de bucket são ferramentas poderosas que podem definir permissões no nível do bucket e podem incluir condições para restringir ainda mais o acesso, tornando-as ideais para gerenciar o acesso a dados sensíveis de forma segura.",
        "Other Options": [
            "Definir a política do bucket para permitir acesso público a todos os usuários é altamente inseguro e contradiz a exigência de manter os dados seguros contra acesso público. Isso exporia os dados sensíveis a qualquer pessoa na internet, o que não é aceitável.",
            "Embora usar uma política de bucket S3 que especifique os papéis IAM da conta parceira esteja correto, esta opção não menciona explicitamente o uso de papéis IAM como principais, que é um aspecto crucial para conceder acesso de forma segura. Portanto, é menos precisa do que a resposta correta.",
            "Ativar 'Bloquear Acesso Público' é uma boa prática para prevenir acesso público, mas usar listas de controle de acesso (ACLs) não é o melhor método para gerenciar o acesso neste cenário. As ACLs podem ser mais complexas e menos flexíveis do que as políticas de bucket, e não fornecem o mesmo nível de clareza e controle sobre permissões que as políticas de bucket oferecem."
        ]
    },
    {
        "Question Number": "38",
        "Situation": "Uma empresa está usando o Amazon Route 53 para gerenciar os registros DNS de seu domínio. Eles estão preocupados com possíveis ataques DNS, como spoofing de DNS e ataques DDoS, e querem garantir que sua infraestrutura DNS esteja segura.",
        "Question": "Qual das seguintes ações a empresa deve tomar para aumentar a segurança de sua configuração do Route 53?",
        "Options": {
            "1": "Ativar DNSSEC (Extensões de Segurança do Sistema de Nomes de Domínio) em suas zonas hospedadas do Route 53 para garantir que as respostas DNS sejam assinadas criptograficamente, prevenindo ataques de spoofing de DNS.",
            "2": "Usar o Route 53 Resolver DNS Firewall para filtrar consultas maliciosas e prevenir tráfego de IPs maliciosos conhecidos, garantindo que apenas tráfego legítimo chegue aos seus recursos.",
            "3": "Configurar o Route 53 para usar apenas HTTP para consultas DNS para simplificar a segurança, já que HTTP é menos propenso a ataques DDoS em comparação com outros protocolos.",
            "4": "Configurar verificações de saúde do Route 53 para monitorar o desempenho das consultas DNS, mas não ativar nenhum recurso de segurança adicional, assumindo que a segurança DNS é coberta por outros serviços da AWS."
        },
        "Correct Answer": "Ativar DNSSEC (Extensões de Segurança do Sistema de Nomes de Domínio) em suas zonas hospedadas do Route 53 para garantir que as respostas DNS sejam assinadas criptograficamente, prevenindo ataques de spoofing de DNS.",
        "Explanation": "Ativar o DNSSEC nas zonas hospedadas do Route 53 adiciona uma camada de segurança ao permitir que as respostas DNS sejam assinadas criptograficamente. Isso garante que as respostas sejam autênticas e não tenham sido adulteradas, prevenindo efetivamente ataques de spoofing de DNS. O DNSSEC ajuda a verificar a integridade dos dados DNS, tornando muito mais difícil para os atacantes redirecionarem usuários para sites maliciosos por meio de respostas DNS forjadas.",
        "Other Options": [
            "Usar o Route 53 Resolver DNS Firewall é uma boa prática para filtrar consultas maliciosas, mas não aborda diretamente a questão do spoofing de DNS. Embora possa ajudar a mitigar algumas ameaças, não é tão eficaz quanto o DNSSEC para garantir a autenticidade das respostas DNS.",
            "Configurar o Route 53 para usar apenas HTTP para consultas DNS está incorreto porque consultas DNS normalmente usam os protocolos UDP e TCP, não HTTP. Além disso, HTTP não fornece segurança inerente contra ataques DDoS; na verdade, pode expor a infraestrutura DNS a mais riscos. Usar protocolos seguros como DNS sobre HTTPS (DoH) ou DNS sobre TLS (DoT) seria mais apropriado.",
            "Configurar verificações de saúde do Route 53 é útil para monitorar o desempenho das consultas DNS, mas não aumenta a segurança. Confiar apenas em verificações de saúde sem ativar recursos de segurança adicionais deixa a infraestrutura DNS vulnerável a ataques como spoofing e DDoS, que podem ser mitigados implementando o DNSSEC e outras medidas de segurança."
        ]
    },
    {
        "Question Number": "39",
        "Situation": "Uma empresa deseja proteger as credenciais de aplicação para uma função AWS Lambda. A função precisa se conectar a um banco de dados Amazon RDS.",
        "Question": "Qual abordagem fornecerá a maneira MAIS segura de armazenar e gerenciar as credenciais do banco de dados?",
        "Options": {
            "1": "Armazenar as credenciais do banco de dados em um arquivo de configuração em texto simples dentro da função Lambda",
            "2": "Usar papéis IAM da AWS com permissões para acessar o banco de dados diretamente",
            "3": "Armazenar as credenciais do banco de dados no AWS Secrets Manager e conceder à função Lambda permissões para recuperar os segredos",
            "4": "Armazenar as credenciais do banco de dados no Amazon S3 com criptografia do lado do servidor ativada"
        },
        "Correct Answer": "Armazenar as credenciais do banco de dados no AWS Secrets Manager e conceder à função Lambda permissões para recuperar os segredos",
        "Explanation": "Usar o AWS Secrets Manager para armazenar credenciais de banco de dados é a abordagem mais segura porque é especificamente projetada para gerenciar informações sensíveis. O Secrets Manager criptografa as credenciais em repouso e fornece controle de acesso detalhado por meio do AWS IAM. Isso permite que a função Lambda recupere as credenciais de forma segura, sem codificá-las diretamente no código ou em arquivos de configuração da função. Além disso, o Secrets Manager pode rotacionar automaticamente as credenciais, aumentando ainda mais a segurança.",
        "Other Options": [
            "Armazenar as credenciais do banco de dados em um arquivo de configuração em texto simples dentro da função Lambda é altamente inseguro. Isso expõe informações sensíveis diretamente no código, tornando-as vulneráveis a acesso não autorizado se o código for exposto ou compartilhado.",
            "Usar papéis IAM da AWS com permissões para acessar o banco de dados diretamente não aborda a necessidade de armazenar as credenciais do banco de dados de forma segura. Embora os papéis IAM possam gerenciar permissões de acesso, eles não fornecem um mecanismo para armazenar informações sensíveis como credenciais de banco de dados de forma segura.",
            "Armazenar as credenciais do banco de dados no Amazon S3 com criptografia do lado do servidor ativada é melhor do que armazenamento em texto simples, mas ainda não é tão seguro quanto usar o Secrets Manager. O S3 não é projetado para gerenciar segredos, e embora a criptografia do lado do servidor proteja os dados em repouso, não fornece o mesmo nível de controle de acesso e recursos de gerenciamento de segredos que o Secrets Manager oferece."
        ]
    },
    {
        "Question Number": "40",
        "Situation": "Imagine que você foi encarregado de construir uma conexão altamente resiliente entre seu data center local e a AWS usando o AWS Direct Connect para uma aplicação crítica.",
        "Question": "Como o Direct Connect é um link físico sem resiliência inerente, qual seria a melhor abordagem para garantir tolerância a falhas?",
        "Options": {
            "1": "Implantar duas conexões Direct Connect em locais separados (Locais DX) dentro da mesma Região AWS para fornecer caminhos redundantes caso uma conexão falhe.",
            "2": "Usar uma única conexão Direct Connect de alta largura de banda para reduzir o risco de interrupções devido a sobrecarga.",
            "3": "Implementar uma conexão Direct Connect emparelhada com um backup VPN para manter a conectividade se o link Direct Connect cair.",
            "4": "Estabelecer conexões Direct Connect em diferentes Regiões AWS para garantir conectividade se uma região encontrar um problema."
        },
        "Correct Answer": "Implementar uma conexão Direct Connect emparelhada com um backup VPN para manter a conectividade se o link Direct Connect cair.",
        "Explanation": "Implementar uma conexão Direct Connect emparelhada com um backup VPN é a melhor abordagem para garantir tolerância a falhas porque fornece um caminho secundário para transmissão de dados. Se o link Direct Connect falhar, a VPN pode assumir, garantindo conectividade contínua. Esta abordagem híbrida aproveita a confiabilidade do Direct Connect enquanto também utiliza a VPN baseada na internet como uma opção de failover, aumentando assim a resiliência geral.",
        "Other Options": [
            "Implantar duas conexões Direct Connect em locais separados dentro da mesma Região AWS poderia fornecer redundância, mas não aborda a potencialidade de uma interrupção regional ou outros problemas que podem afetar ambas as conexões. Além disso, pode não ser econômico em comparação com uma solução híbrida com uma VPN.",
            "Usar uma única conexão Direct Connect de alta largura de banda não fornece nenhuma tolerância a falhas. Se essa conexão cair, não haverá um caminho alternativo para os dados, levando a uma possível interrupção para a aplicação crítica.",
            "Estabelecer conexões Direct Connect em diferentes Regiões AWS poderia fornecer algum nível de redundância, mas pode introduzir latência e complexidade na gestão do tráfego inter-regional. Além disso, não garante que ambas as conexões estarão disponíveis simultaneamente, especialmente se houver problemas afetando as próprias regiões."
        ]
    },
    {
        "Question Number": "41",
        "Situation": "Uma empresa está planejando migrar suas aplicações para a AWS e deseja entender as responsabilidades de segurança que deve gerenciar como parte do Modelo de Responsabilidade Compartilhada da AWS. A empresa usará Amazon EC2 para seus servidores de aplicação, Amazon RDS para seus bancos de dados e Amazon S3 para armazenar dados.",
        "Question": "Quais das seguintes responsabilidades a empresa reterá e quais a AWS gerenciará?",
        "Options": {
            "1": "A empresa é responsável pela segurança da infraestrutura física subjacente, enquanto a AWS gerencia a criptografia de dados em repouso.",
            "2": "A AWS é responsável por aplicar patches nas instâncias do Amazon EC2, enquanto a empresa gerencia o filtragem de tráfego de rede usando grupos de segurança e ACLs de rede.",
            "3": "A empresa é responsável por gerenciar as configurações de segurança do Amazon RDS, incluindo a aplicação de patches no software do banco de dados, enquanto a AWS gerencia a segurança dos data centers onde as instâncias do RDS estão hospedadas.",
            "4": "A AWS gerencia a segurança dos dados dos clientes armazenados no Amazon S3, enquanto a empresa é responsável por configurar permissões de acesso e configurações de criptografia para esses dados."
        },
        "Correct Answer": "A empresa é responsável por gerenciar as configurações de segurança do Amazon RDS, incluindo a aplicação de patches no software do banco de dados, enquanto a AWS gerencia a segurança dos data centers onde as instâncias do RDS estão hospedadas.",
        "Explanation": "No Modelo de Responsabilidade Compartilhada da AWS, a AWS é responsável pela segurança da infraestrutura da nuvem, que inclui a segurança física dos data centers e o hardware que executa os serviços da AWS. No entanto, os clientes são responsáveis pela segurança de suas aplicações e dados, incluindo o gerenciamento das configurações e a aplicação de patches em serviços como o Amazon RDS. Isso significa que, enquanto a AWS protege a infraestrutura subjacente, a empresa deve garantir que suas configurações de banco de dados sejam seguras e estejam atualizadas.",
        "Other Options": [
            "A empresa é responsável pela segurança de suas aplicações e dados, não pela infraestrutura física subjacente, que é gerenciada pela AWS. A AWS gerencia a criptografia de dados em repouso, mas é responsabilidade da empresa implementá-la para seus dados.",
            "A AWS é responsável por aplicar patches na infraestrutura subjacente, mas a empresa deve gerenciar a aplicação de patches no sistema operacional e no nível da aplicação para as instâncias do Amazon EC2. A empresa também é responsável por configurar grupos de segurança e ACLs de rede para filtragem de tráfego de rede.",
            "A AWS gerencia a segurança da infraestrutura que suporta o Amazon S3, mas a empresa é responsável por gerenciar permissões de acesso e configurações de criptografia para os dados que armazena no S3. A AWS não gerencia a segurança dos dados dos clientes diretamente; ela fornece as ferramentas para que os clientes protejam seus dados."
        ]
    },
    {
        "Question Number": "42",
        "Situation": "Uma empresa está projetando uma Nuvem Privada Virtual (VPC) com várias sub-redes em várias Zonas de Disponibilidade (AZs). Eles precisam garantir que cada sub-rede seja definida de forma única, não se sobreponha a outras sub-redes e que certos endereços IP sejam reservados para funções específicas dentro de cada sub-rede.",
        "Question": "Quais das seguintes diretrizes eles devem seguir para configurar suas sub-redes corretamente e evitar conflitos de IP? (Escolha duas.)",
        "Options": {
            "1": "Defina um bloco CIDR exclusivo para cada sub-rede, garantindo que ele se sobreponha a outras sub-redes em diferentes AZs, e use endereços IP reservados para funções de rede e broadcast.",
            "2": "Use o mesmo bloco CIDR para todas as sub-redes dentro da VPC, permitindo que as sub-redes se comuniquem perfeitamente entre AZs, e reserve o primeiro endereço IP em cada sub-rede para DNS.",
            "3": "Atribua blocos CIDR não sobrepostos a cada sub-rede dentro da VPC, com uma sub-rede por AZ, e reserve endereços IP específicos (como os endereços de rede e broadcast) conforme os requisitos da AWS.",
            "4": "Alocar um único bloco CIDR grande para todas as sub-redes dentro da VPC e usar o Protocolo de Configuração Dinâmica de Host (DHCP) para evitar conflitos de IP entre sub-redes.",
            "5": "Certifique-se de que o bloco CIDR de cada sub-rede seja um subconjunto do bloco CIDR da VPC e planeje os intervalos de IP para acomodar o crescimento futuro sem sobreposição."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Atribua blocos CIDR não sobrepostos a cada sub-rede dentro da VPC, com uma sub-rede por AZ, e reserve endereços IP específicos (como os endereços de rede e broadcast) conforme os requisitos da AWS.",
            "Certifique-se de que o bloco CIDR de cada sub-rede seja um subconjunto do bloco CIDR da VPC e planeje os intervalos de IP para acomodar o crescimento futuro sem sobreposição."
        ],
        "Explanation": "As respostas corretas são as opções 3 e 5. A opção 3 está correta porque atribuir blocos CIDR não sobrepostos a cada sub-rede dentro da VPC garante que cada sub-rede seja definida de forma única e não conflite com outras sub-redes. Reservar endereços IP específicos para funções de rede e broadcast é uma prática padrão em design de rede. A opção 5 está correta porque o bloco CIDR de cada sub-rede deve ser um subconjunto do bloco CIDR da VPC. Isso garante que os endereços IP dentro da sub-rede sejam únicos dentro da VPC. Planejar os intervalos de IP para acomodar o crescimento futuro sem sobreposição é uma boa prática para evitar potenciais conflitos de IP no futuro.",
        "Other Options": [
            "Blocos CIDR sobrepostos entre sub-redes podem levar a conflitos de IP. Além disso, embora seja verdade que certos endereços IP devem ser reservados para funções de rede e broadcast, esta opção sugere incorretamente que blocos CIDR sobrepostos são uma boa prática.",
            "Usar o mesmo bloco CIDR para todas as sub-redes dentro da VPC pode levar a conflitos de IP. Embora seja verdade que o primeiro endereço IP em cada sub-rede seja tipicamente reservado para DNS, esta opção sugere incorretamente que usar o mesmo bloco CIDR para todas as sub-redes é uma boa prática.",
            "Alocar um único bloco CIDR grande para todas as sub-redes dentro da VPC pode levar a conflitos de IP. Embora o DHCP possa ajudar a gerenciar endereços IP dentro de uma sub-rede, ele não pode evitar conflitos de IP entre sub-redes que compartilham o mesmo bloco CIDR."
        ]
    },
    {
        "Question Number": "43",
        "Situation": "Uma empresa está usando Amazon RDS para suas necessidades de banco de dados, mas está preocupada com a escalabilidade e disponibilidade de suas conexões de banco de dados. Eles querem melhorar o gerenciamento das conexões de banco de dados e garantir alta disponibilidade para sua aplicação sem sobrecarregar as instâncias do RDS.",
        "Question": "Qual serviço da AWS a empresa deve usar para alcançar esse objetivo e quais são seus benefícios?",
        "Options": {
            "1": "Use Amazon RDS Proxy para gerenciar conexões de banco de dados, agrupando e multiplexando conexões para reduzir a carga nas instâncias do RDS e melhorar a escalabilidade.",
            "2": "Use Amazon CloudFront como um proxy para armazenar em cache consultas de banco de dados e reduzir a carga na instância do RDS.",
            "3": "Use Amazon SQS para enfileirar solicitações de banco de dados e processá-las sequencialmente, garantindo alta disponibilidade das conexões de banco de dados.",
            "4": "Use Amazon ElastiCache para proxy e armazenar em cache consultas de banco de dados para minimizar a carga no banco de dados."
        },
        "Correct Answer": "Use Amazon RDS Proxy para gerenciar conexões de banco de dados, agrupando e multiplexando conexões para reduzir a carga nas instâncias do RDS e melhorar a escalabilidade.",
        "Explanation": "O Amazon RDS Proxy é projetado especificamente para melhorar o gerenciamento de conexões de banco de dados para o Amazon RDS. Ele fornece agrupamento de conexões e multiplexação, o que ajuda a reduzir o número de conexões que precisam ser estabelecidas com as instâncias do RDS. Isso não apenas melhora a escalabilidade da aplicação, permitindo mais conexões simultâneas, mas também aumenta a disponibilidade ao gerenciar cenários de failover de forma transparente. Ao usar o RDS Proxy, a empresa pode garantir que suas conexões de banco de dados sejam gerenciadas de forma eficiente, reduzindo a carga nas instâncias do RDS e melhorando o desempenho geral da aplicação.",
        "Other Options": [
            "Usar Amazon CloudFront como um proxy para armazenar em cache consultas de banco de dados está incorreto porque o CloudFront é principalmente uma rede de entrega de conteúdo (CDN) projetada para armazenar em cache conteúdo estático e acelerar a entrega de aplicações web, não para gerenciar conexões de banco de dados ou armazenar em cache consultas de banco de dados.",
            "Usar Amazon SQS para enfileirar solicitações de banco de dados não é adequado para este cenário porque o SQS é um serviço de enfileiramento de mensagens projetado para desacoplar e escalar microsserviços, sistemas distribuídos e aplicações sem servidor. Ele não gerencia diretamente conexões de banco de dados ou melhora sua disponibilidade.",
            "Usar Amazon ElastiCache para proxy e armazenar em cache consultas de banco de dados não é a melhor opção neste contexto. Embora o ElastiCache possa ser usado para armazenar em cache dados frequentemente acessados para reduzir a carga no banco de dados, ele não gerencia conexões de banco de dados ou fornece agrupamento de conexões, que é a principal preocupação para escalabilidade e disponibilidade neste cenário."
        ]
    },
    {
        "Question Number": "44",
        "Situation": "Uma empresa está planejando migrar sua aplicação monolítica para uma arquitetura containerizada para melhorar a escalabilidade, portabilidade e gerenciamento de recursos. A empresa deseja dividir a aplicação monolítica em componentes menores e mais gerenciáveis para garantir escalabilidade eficiente durante picos de tráfego. Eles também precisam garantir que a aplicação possa ser facilmente movida entre ambientes e plataformas.",
        "Question": "Qual é a abordagem mais eficaz para migrar sua aplicação para contêineres?",
        "Options": {
            "1": "Containerize cada componente da aplicação criando imagens Docker para cada microsserviço e implemente os contêineres no Amazon ECS ou EKS para orquestração e gerenciamento.",
            "2": "Migre toda a aplicação como uma máquina virtual para a AWS usando Amazon EC2 e gerencie a aplicação através de um grupo de Auto Scaling do EC2.",
            "3": "Use AWS Lambda para migrar a aplicação e dividi-la em funções sem servidor para eliminar a necessidade de contêineres.",
            "4": "Armazene a aplicação no Amazon S3 e use AWS Fargate para executar a aplicação em um ambiente de contêiner gerenciado."
        },
        "Correct Answer": "Containerize cada componente da aplicação criando imagens Docker para cada microsserviço e implemente os contêineres no Amazon ECS ou EKS para orquestração e gerenciamento.",
        "Explanation": "Essa abordagem é a mais eficaz para migrar uma aplicação monolítica para uma arquitetura containerizada porque permite que a aplicação seja dividida em microsserviços menores e gerenciáveis. Ao criar imagens Docker para cada componente, a empresa pode garantir que cada microsserviço seja implantável, escalável e mantível de forma independente. Usar Amazon ECS (Elastic Container Service) ou EKS (Elastic Kubernetes Service) fornece robustas capacidades de orquestração e gerenciamento, permitindo escalabilidade eficiente durante picos de tráfego e movimentação sem problemas entre diferentes ambientes e plataformas.",
        "Other Options": [
            "Migrar toda a aplicação como uma máquina virtual para a AWS usando Amazon EC2 não aproveita totalmente os benefícios da containerização. Embora permita escalabilidade através de grupos de Auto Scaling do EC2, não divide a aplicação monolítica em microsserviços, o que é essencial para alcançar a escalabilidade e o gerenciamento de recursos desejados.",
            "Usar AWS Lambda para migrar a aplicação para funções sem servidor não é adequado para todas as aplicações, especialmente aquelas que não foram projetadas para serem sem servidor. Essa abordagem pode exigir uma re-arquitetura significativa da aplicação e não utiliza contêineres, que a empresa está especificamente buscando implementar.",
            "Armazenar a aplicação no Amazon S3 e usar AWS Fargate para executar a aplicação em um ambiente de contêiner gerenciado não é uma solução completa. Embora o Fargate permita executar contêineres sem gerenciar servidores, simplesmente armazenar a aplicação no S3 não aborda a necessidade de dividir a aplicação monolítica em microsserviços ou criar imagens Docker, que são críticas para uma efetiva containerização."
        ]
    },
    {
        "Question Number": "45",
        "Situation": "Uma empresa de serviços financeiros precisa proteger sua nova aplicação web com HTTPS para proteger os dados dos clientes. Eles querem uma solução que simplifique a emissão, implantação e renovação de certificados SSL/TLS para evitar o risco de certificados expirados causando tempo de inatividade. Com a maior parte de sua infraestrutura na AWS, eles estão considerando o AWS Certificate Manager (ACM) para gerenciar certificados em serviços como ELB, CloudFront e API Gateway.",
        "Question": "Como o AWS Certificate Manager (ACM) suporta o gerenciamento seguro e automatizado de certificados SSL/TLS para as necessidades da empresa?",
        "Options": {
            "1": "O ACM permite a emissão e renovação manual de certificados, proporcionando controle sobre o processo de renovação.",
            "2": "O ACM emite, implanta e renova automaticamente certificados, integra-se com serviços da AWS e oferece certificados gratuitamente quando usados com recursos da AWS.",
            "3": "O ACM suporta apenas certificados autoassinados, exigindo que a empresa gerencie renovações e segurança separadamente.",
            "4": "O ACM emite certificados, mas requer ferramentas de terceiros para renovações e não se integra diretamente com serviços da AWS."
        },
        "Correct Answer": "O ACM emite, implanta e renova automaticamente certificados, integra-se com serviços da AWS e oferece certificados gratuitamente quando usados com recursos da AWS.",
        "Explanation": "O AWS Certificate Manager (ACM) simplifica o gerenciamento de certificados SSL/TLS automatizando os processos de emissão, implantação e renovação. Isso significa que a empresa de serviços financeiros pode evitar o risco de certificados expirados causando tempo de inatividade, já que o ACM gerencia as renovações automaticamente. Além disso, o ACM se integra perfeitamente com vários serviços da AWS, como Elastic Load Balancing (ELB), CloudFront e API Gateway, e fornece certificados sem custo quando usados com esses serviços, tornando-se uma solução econômica para proteger sua aplicação web.",
        "Other Options": [
            "Embora o ACM permita a emissão e renovação manual de certificados, as necessidades da empresa estão focadas na automação para evitar o risco de certificados expirados. Processos manuais não simplificariam o gerenciamento de certificados conforme necessário.",
            "O ACM não suporta apenas certificados autoassinados. Ele emite principalmente certificados públicos que são confiáveis por navegadores e clientes, o que é essencial para proteger dados dos clientes em um ambiente de produção.",
            "O ACM não requer ferramentas de terceiros para renovações; ele automatiza o processo de renovação. Além disso, o ACM foi projetado para se integrar diretamente com serviços da AWS, que é uma característica chave que suporta as necessidades da infraestrutura da empresa."
        ]
    },
    {
        "Question Number": "46",
        "Situation": "",
        "Question": "Qual recurso do Amazon Redshift garante a durabilidade e resiliência dos dados ao fornecer capacidades de backup e recuperação de desastres?",
        "Options": {
            "1": "Enhanced VPC Routing, que permite uma rede personalizada dentro de uma VPC.",
            "2": "Slices em Compute Nodes, permitindo a distribuição de dados e consultas entre múltiplos nós.",
            "3": "Automatic Snapshots to S3, onde os dados são copiados a cada 8 horas ou a cada 5GB para o Amazon S3 para durabilidade.",
            "4": "Redshift Spectrum, permitindo consultas diretas de dados no S3 sem carregá-los no Redshift."
        },
        "Correct Answer": "Automatic Snapshots to S3, onde os dados são copiados a cada 8 horas ou a cada 5GB para o Amazon S3 para durabilidade.",
        "Explanation": "O Amazon Redshift fornece Automatic Snapshots to S3 como um recurso chave para garantir a durabilidade e resiliência dos dados. Este recurso faz backup automaticamente dos dados armazenados no Redshift para o Amazon S3 a cada 8 horas ou sempre que o tamanho dos dados aumentar em 5GB. Esses snapshots são cruciais para a recuperação de desastres, pois permitem que os usuários restauram seus dados a um estado anterior em caso de perda ou corrupção de dados, garantindo assim a integridade e disponibilidade dos dados.",
        "Other Options": [
            "O Enhanced VPC Routing é focado principalmente em melhorar a segurança da rede e o gerenciamento de tráfego dentro de uma Nuvem Privada Virtual (VPC) e não se relaciona diretamente com a durabilidade dos dados ou capacidades de backup.",
            "Slices em Compute Nodes referem-se à forma como os dados são distribuídos e processados entre múltiplos nós em um cluster Redshift. Embora isso melhore o desempenho e a escalabilidade, não fornece recursos de backup ou recuperação de desastres.",
            "O Redshift Spectrum permite que os usuários consultem dados diretamente no Amazon S3 sem carregá-los no Redshift, o que é útil para acessar grandes conjuntos de dados, mas não fornece capacidades de backup ou recuperação de desastres."
        ]
    },
    {
        "Question Number": "47",
        "Situation": "Uma empresa está projetando uma arquitetura de rede segura na AWS, com alguns recursos exigindo acesso público e outros restritos ao acesso privado dentro de uma VPC. Eles querem garantir que os dados sensíveis nos serviços privados estejam isolados da internet, enquanto permitem acesso seguro a certos serviços públicos da AWS.",
        "Question": "Qual das seguintes abordagens atende melhor aos seus requisitos de segurança?",
        "Options": {
            "1": "Implantar todos os recursos na Zona Pública da AWS com IPs públicos, pois isso simplifica o gerenciamento de acesso e segurança.",
            "2": "Colocar instâncias EC2 sensíveis em uma sub-rede privada dentro da Zona Privada da AWS, acessar a internet via um gateway NAT e usar uma VPN ou Direct Connect para acesso seguro ao VPC.",
            "3": "Usar sub-redes públicas para serviços sensíveis e restringir o acesso aplicando grupos de segurança para controlar o tráfego de entrada e saída.",
            "4": "Configurar serviços privados em sub-redes públicas para acessar serviços da AWS diretamente pela internet sem usar o IGW ou VPN."
        },
        "Correct Answer": "Colocar instâncias EC2 sensíveis em uma sub-rede privada dentro da Zona Privada da AWS, acessar a internet via um gateway NAT e usar uma VPN ou Direct Connect para acesso seguro ao VPC.",
        "Explanation": "Essa abordagem isola efetivamente dados e recursos sensíveis ao colocá-los em uma sub-rede privada, que não é acessível diretamente da internet. O uso de um gateway NAT permite que essas instâncias privadas iniciem tráfego de saída para a internet (para atualizações, etc.) enquanto impede o tráfego de entrada da internet, mantendo assim a segurança. Além disso, usar uma VPN ou Direct Connect fornece uma conexão segura para acesso local ao VPC, garantindo que dados sensíveis permaneçam protegidos de exposição pública.",
        "Other Options": [
            "Implantar todos os recursos na Zona Pública da AWS com IPs públicos simplifica o acesso, mas expõe todos os recursos à internet, o que é um risco significativo de segurança para dados sensíveis.",
            "Usar sub-redes públicas para serviços sensíveis contradiz o requisito de isolamento da internet. Sub-redes públicas são acessíveis da internet, o que pode levar a acessos não autorizados a dados sensíveis.",
            "Configurar serviços privados em sub-redes públicas para acessar serviços da AWS diretamente pela internet sem usar o IGW ou VPN não é viável, pois sub-redes públicas estão inerentemente expostas à internet, o que não atende ao requisito de segurança de isolar dados sensíveis."
        ]
    },
    {
        "Question Number": "48",
        "Situation": "Uma empresa está implantando um novo aplicativo baseado em microserviços na AWS. Cada microserviço está empacotado em um contêiner Docker. O aplicativo requer orquestração para gerenciar os contêineres, lidar com escalabilidade e garantir alta disponibilidade.",
        "Question": "Qual serviço da AWS o arquiteto de soluções deve recomendar para orquestração de contêineres?",
        "Options": {
            "1": "Amazon EC2 Auto Scaling",
            "2": "AWS Lambda",
            "3": "Amazon Elastic Kubernetes Service (EKS)",
            "4": "Amazon Elastic Container Service (ECS)"
        },
        "Correct Answer": "Amazon Elastic Kubernetes Service (EKS)",
        "Explanation": "O Amazon Elastic Kubernetes Service (EKS) é um serviço totalmente gerenciado que facilita a execução do Kubernetes na AWS sem a necessidade de instalar e operar seu próprio plano de controle ou nós do Kubernetes. Ele fornece a orquestração necessária para gerenciar contêineres Docker, incluindo escalabilidade e alta disponibilidade. O EKS é particularmente adequado para arquiteturas de microserviços, pois permite a implantação, escalabilidade e gerenciamento de aplicativos conteinerizados usando Kubernetes, que é uma ferramenta de orquestração amplamente adotada na indústria.",
        "Other Options": [
            "O Amazon EC2 Auto Scaling é um serviço que ajusta automaticamente o número de instâncias EC2 em resposta à demanda. Embora possa ajudar a escalar aplicativos, não fornece capacidades de orquestração de contêineres especificamente para gerenciar contêineres Docker.",
            "O AWS Lambda é um serviço de computação sem servidor que executa código em resposta a eventos e gerencia automaticamente os recursos de computação necessários. Não é projetado para orquestração de contêineres e é mais adequado para arquiteturas orientadas a eventos do que para gerenciar múltiplos microserviços em contêineres.",
            "O Amazon Elastic Container Service (ECS) é outro serviço de orquestração de contêineres fornecido pela AWS. Embora seja capaz de gerenciar contêineres Docker e possa lidar com escalabilidade e alta disponibilidade, a pergunta pede especificamente por orquestração, e o EKS é frequentemente preferido para aplicativos baseados em Kubernetes devido a seus extensos recursos e suporte da comunidade."
        ]
    },
    {
        "Question Number": "49",
        "Situation": "Uma plataforma de e-commerce em rápido crescimento deseja gerenciar eficientemente as solicitações de API recebidas à medida que expandem seus serviços de backend para lidar com altos volumes de tráfego. Eles querem garantir que as solicitações sejam autorizadas, validadas, transformadas e armazenadas em cache para desempenho ideal. Além disso, a plataforma busca monitorar ciclos de solicitação-resposta e coletar métricas detalhadas sobre o uso.",
        "Question": "Qual serviço da AWS a empresa deve usar para construir uma camada de gerenciamento de API confiável e escalável, e quais recursos específicos desse serviço apoiariam seus requisitos?",
        "Options": {
            "1": "Amazon API Gateway, pois pode lidar com autorização, limitação, armazenamento em cache e se integra perfeitamente ao AWS CloudWatch para monitoramento em tempo real e coleta de métricas.",
            "2": "AWS Lambda, uma vez que fornece capacidade de computação sem servidor e pode ser usado para lidar, autorizar e processar cada solicitação de forma independente.",
            "3": "Instâncias Amazon EC2 com NGINX para gerenciar balanceamento de carga e armazenamento em cache, enquanto aproveitam agentes do CloudWatch para métricas e registro.",
            "4": "Amazon S3 com URLs assinadas para restringir o acesso e CloudFront para armazenamento em cache, pois isso pode reduzir a carga nos serviços de backend."
        },
        "Correct Answer": "Amazon API Gateway, pois pode lidar com autorização, limitação, armazenamento em cache e se integra perfeitamente ao AWS CloudWatch para monitoramento em tempo real e coleta de métricas.",
        "Explanation": "O Amazon API Gateway é projetado especificamente para criar, implantar e gerenciar APIs em escala. Ele fornece recursos integrados para autorização (usando AWS IAM, autorizadores Lambda ou Amazon Cognito), validação de solicitações, transformação de solicitações e respostas, e armazenamento em cache para melhorar o desempenho. Além disso, ele se integra ao AWS CloudWatch, permitindo que a plataforma monitore o uso da API, rastreie ciclos de solicitação-resposta e colete métricas detalhadas, o que se alinha perfeitamente com os requisitos da empresa para gerenciar altos volumes de tráfego de forma eficiente.",
        "Other Options": [
            "O AWS Lambda é um serviço de computação sem servidor que pode processar solicitações, mas não fornece uma camada completa de gerenciamento de API. Embora possa lidar com autorização e processamento de solicitações, carece de recursos integrados para armazenamento em cache, limitação e monitoramento abrangente que o API Gateway oferece.",
            "Instâncias Amazon EC2 com NGINX podem ser configuradas para gerenciar balanceamento de carga e armazenamento em cache, mas essa abordagem requer mais configuração e gerenciamento manual em comparação com o API Gateway. Além disso, enquanto os agentes do CloudWatch podem fornecer métricas, eles não oferecem o mesmo nível de integração e facilidade de uso para gerenciamento de API que o API Gateway.",
            "Amazon S3 com URLs assinadas e CloudFront pode fornecer acesso seguro e armazenamento em cache para conteúdo estático, mas não é adequado para gerenciar solicitações de API dinâmicas. Esta solução carece dos recursos necessários para autorização, validação de solicitações e monitoramento detalhado do uso da API, que são críticos para as necessidades da plataforma de e-commerce."
        ]
    },
    {
        "Question Number": "50",
        "Situation": "Uma empresa está configurando uma VPC com múltiplas sub-redes para um aplicativo web de múltiplas camadas. A sub-rede pública do aplicativo precisa permitir acesso à internet, e a sub-rede privada deve permitir apenas tráfego de saída para a internet via um gateway NAT.",
        "Question": "Qual é a maneira mais eficiente de garantir o roteamento correto do tráfego entre essas sub-redes?",
        "Options": {
            "1": "Criar uma tabela de rotas para a sub-rede pública com uma rota padrão (0.0.0.0/0) apontando para um gateway de internet, e criar uma tabela de rotas para a sub-rede privada com uma rota para o gateway NAT.",
            "2": "Criar uma única tabela de rotas para ambas as sub-redes pública e privada e adicionar uma rota para o gateway NAT para acesso à internet de saída.",
            "3": "Criar uma tabela de rotas para a sub-rede privada que aponte diretamente para o gateway de internet para tráfego externo.",
            "4": "Usar o Amazon Route 53 para gerenciar o roteamento para ambas as sub-redes e direcionar todo o tráfego para um servidor DNS interno."
        },
        "Correct Answer": "Criar uma tabela de rotas para a sub-rede pública com uma rota padrão (0.0.0.0/0) apontando para um gateway de internet, e criar uma tabela de rotas para a sub-rede privada com uma rota para o gateway NAT.",
        "Explanation": "Esta opção configura corretamente o roteamento para ambas as sub-redes pública e privada em uma VPC. A sub-rede pública precisa de uma tabela de rotas que direcione todo o tráfego de saída (0.0.0.0/0) para o gateway de internet, permitindo que as instâncias nessa sub-rede acessem a internet diretamente. A sub-rede privada, por outro lado, não deve ter acesso direto à internet; em vez disso, deve direcionar o tráfego de saída para o gateway NAT, que lidará com o acesso à internet para as instâncias na sub-rede privada. Esta configuração garante que a sub-rede pública possa servir tráfego web enquanto mantém a segurança da sub-rede privada.",
        "Other Options": [
            "Criar uma única tabela de rotas para ambas as sub-redes pública e privada e adicionar uma rota para o gateway NAT para acesso à internet de saída está incorreto porque a sub-rede pública precisa direcionar o tráfego para o gateway de internet, não para o gateway NAT. O gateway NAT é apenas para o tráfego de saída da sub-rede privada.",
            "Criar uma tabela de rotas para a sub-rede privada que aponte diretamente para o gateway de internet para tráfego externo está incorreto porque sub-redes privadas não devem ter acesso direto à internet. Elas devem direcionar o tráfego através de um gateway NAT para manter a segurança e prevenir a exposição direta à internet.",
            "Usar o Amazon Route 53 para gerenciar o roteamento para ambas as sub-redes e direcionar todo o tráfego para um servidor DNS interno está incorreto porque o Route 53 é principalmente um serviço de DNS e não gerencia o roteamento entre sub-redes em uma VPC. O roteamento é gerenciado por tabelas de rotas, não por serviços de DNS."
        ]
    },
    {
        "Question Number": "51",
        "Situation": "Uma plataforma de compartilhamento de mídia permite que os usuários enviem vídeos, que são automaticamente transcodificados em vários formatos para uma reprodução ideal em diferentes dispositivos. A plataforma usa o Google como provedor de identidade para autenticação de usuários e, após um login bem-sucedido, os usuários podem enviar vídeos para um bucket do Amazon S3. Uma série de funções Lambda são acionadas para processar e carregar vídeos, iniciar trabalhos de transcodificação e atualizar metadados em uma tabela DynamoDB.",
        "Question": "Qual benefício essa arquitetura sem servidor oferece à plataforma?",
        "Options": {
            "1": "Processamento de vídeo garantido dentro de uma duração fixa",
            "2": "Menor sobrecarga operacional com gerenciamento mínimo de servidores necessário",
            "3": "Intervenção manual necessária para tarefas de transcodificação de vídeo",
            "4": "Servidores dedicados para lidar com alto tráfego de upload"
        },
        "Correct Answer": "Menor sobrecarga operacional com gerenciamento mínimo de servidores necessário",
        "Explanation": "A arquitetura sem servidor permite que a plataforma aproveite serviços em nuvem como AWS Lambda, S3 e DynamoDB sem a necessidade de gerenciar os servidores subjacentes. Isso resulta em menor sobrecarga operacional, pois a plataforma pode se concentrar no desenvolvimento e na escalabilidade sem se preocupar com manutenção de servidores, provisionamento ou problemas de escalabilidade. A escalabilidade automática das funções Lambda e a natureza gerenciada do S3 e DynamoDB reduzem ainda mais a necessidade de intervenção manual e gerenciamento de servidores.",
        "Other Options": [
            "O processamento de vídeo garantido dentro de uma duração fixa não é um benefício da arquitetura sem servidor. Embora as funções sem servidor possam escalar automaticamente, não há garantia sobre a duração do processamento, pois pode variar com base na carga de trabalho e outros fatores.",
            "A intervenção manual necessária para tarefas de transcodificação de vídeo contradiz os benefícios da arquitetura sem servidor, que é projetada para automatizar processos. Neste cenário, o uso de funções Lambda indica que as tarefas de transcodificação são automatizadas sem intervenção manual.",
            "Servidores dedicados para lidar com alto tráfego de upload não são uma característica da arquitetura sem servidor. Em vez disso, soluções sem servidor alocam recursos dinamicamente conforme necessário, eliminando a necessidade de servidores dedicados e permitindo uma utilização de recursos mais eficiente."
        ]
    },
    {
        "Question Number": "52",
        "Situation": "Uma empresa de serviços financeiros está usando o AWS Key Management Service (KMS) para gerenciar chaves de criptografia para dados sensíveis de clientes armazenados em várias contas da AWS. A equipe de segurança precisa implementar políticas de acesso para garantir que apenas pessoal e aplicativos autorizados possam acessar chaves específicas, enquanto previnem o acesso não autorizado. Para cumprir com os requisitos regulatórios, eles também precisam restringir o acesso com base em funções, departamentos e projetos específicos.",
        "Question": "Quais abordagens eles devem adotar para aplicar essas políticas de acesso de forma eficaz? (Escolha duas.)",
        "Options": {
            "1": "Usar políticas baseadas em recursos no KMS para definir permissões de acesso específicas para cada chave e atribuir essas permissões aos usuários, grupos e funções do IAM relevantes.",
            "2": "Criar grupos de segurança para cada departamento, anexar as chaves de criptografia relevantes e aplicar permissões em nível de rede para controlar o acesso.",
            "3": "Implementar controles de acesso através de políticas de bucket do AWS S3 para controlar quais usuários podem acessar dados criptografados pelas chaves.",
            "4": "Utilizar funções do AWS Identity and Access Management (IAM) com permissões de menor privilégio para diferentes departamentos e projetos.",
            "5": "Confiar no AWS Shield para gerenciar e aplicar políticas de acesso a chaves de criptografia em todos os recursos."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Usar políticas baseadas em recursos no KMS para definir permissões de acesso específicas para cada chave e atribuir essas permissões aos usuários, grupos e funções do IAM relevantes.",
            "Utilizar funções do AWS Identity and Access Management (IAM) com permissões de menor privilégio para diferentes departamentos e projetos."
        ],
        "Explanation": "As respostas corretas são usar políticas baseadas em recursos no KMS e utilizar funções do IAM com permissões de menor privilégio. Políticas baseadas em recursos no KMS permitem especificar quem tem acesso a quais chaves, e você pode atribuir essas permissões aos usuários, grupos e funções do IAM relevantes. Isso está alinhado com a exigência de restringir o acesso com base em funções, departamentos e projetos específicos. Funções do IAM com permissões de menor privilégio também são uma boa abordagem, pois garantem que cada departamento e projeto tenha acesso apenas aos recursos que precisam, reduzindo o risco de acesso não autorizado.",
        "Other Options": [
            "Criar grupos de segurança para cada departamento e anexar as chaves de criptografia relevantes não é uma abordagem correta, pois grupos de segurança na AWS são usados para controlar o tráfego de entrada e saída no nível da instância, não para gerenciar o acesso a chaves de criptografia.",
            "Implementar controles de acesso através de políticas de bucket do AWS S3 não é uma abordagem correta, pois embora as políticas de bucket do S3 possam controlar quem pode acessar dados dentro de um bucket, elas não gerenciam o acesso a chaves de criptografia do KMS.",
            "Confiar no AWS Shield para gerenciar e aplicar políticas de acesso a chaves de criptografia não é uma abordagem correta, pois o AWS Shield é um serviço gerenciado de proteção contra negação de serviço distribuída (DDoS), não um serviço para gerenciar o acesso a chaves de criptografia."
        ]
    },
    {
        "Question Number": "53",
        "Situation": "Uma empresa precisa de uma estratégia de recuperação de desastres (DR) para seu aplicativo crítico que garanta que o sistema possa se recuperar rapidamente de uma falha, minimizando o tempo de inatividade. A empresa deseja minimizar o objetivo de tempo de recuperação (RTO) e o objetivo de ponto de recuperação (RPO), e está disposta a implementar infraestrutura adicional em uma região secundária para manter o aplicativo em funcionamento com impacto mínimo no desempenho.",
        "Question": "Qual estratégia de DR a empresa deve implementar?",
        "Options": {
            "1": "Implementar uma estratégia de failover ativo-ativo em duas regiões, garantindo que o aplicativo esteja em execução em ambas as regiões o tempo todo e que o tráfego seja distribuído dinamicamente.",
            "2": "Implementar uma estratégia de espera quente com infraestrutura mínima em execução na região secundária e escalar recursos quando um failover for acionado.",
            "3": "Implementar uma estratégia de backup e restauração, onde os dados são copiados para o Amazon S3 e restaurados manualmente em caso de falha.",
            "4": "Implementar uma estratégia de luz piloto com infraestrutura mínima em execução na região secundária e apenas escalar para capacidade total quando necessário."
        },
        "Correct Answer": "Implementar uma estratégia de failover ativo-ativo em duas regiões, garantindo que o aplicativo esteja em execução em ambas as regiões o tempo todo e que o tráfego seja distribuído dinamicamente.",
        "Explanation": "Uma estratégia de failover ativo-ativo permite que o aplicativo funcione simultaneamente em duas regiões, o que significa que ambas as regiões podem lidar com o tráfego o tempo todo. Essa configuração minimiza significativamente o tempo de inatividade, pois não há necessidade de mudar para uma região secundária durante uma falha; o aplicativo já está operacional em ambas as localidades. Essa abordagem minimiza efetivamente tanto o objetivo de tempo de recuperação (RTO) quanto o objetivo de ponto de recuperação (RPO), uma vez que os dados são continuamente sincronizados entre as duas regiões, garantindo que os dados mais atuais estejam sempre disponíveis.",
        "Other Options": [
            "Implementar uma estratégia de espera quente envolve manter uma infraestrutura mínima na região secundária, que pode ser escalada quando um failover ocorre. Embora isso melhore os tempos de recuperação em comparação com uma espera fria, ainda requer tempo para escalar recursos, o que pode levar a um aumento do tempo de inatividade e um RTO mais alto em comparação com uma configuração ativo-ativo.",
            "Uma estratégia de backup e restauração depende de backups periódicos de dados, que são armazenados em um serviço como o Amazon S3. No caso de uma falha, o sistema deve ser restaurado manualmente a partir desses backups. Essa abordagem geralmente resulta em um RTO e RPO mais longos, pois pode levar um tempo significativo para restaurar o aplicativo e os dados, tornando-a inadequada para cenários onde o tempo de inatividade mínimo é crítico.",
            "Uma estratégia de luz piloto mantém uma versão mínima do aplicativo em execução na região secundária, que pode ser escalada para capacidade total durante um failover. Embora isso seja mais eficiente do que uma espera fria, ainda requer tempo para escalar, levando a um RTO mais longo em comparação com uma estratégia ativo-ativo, que está sempre totalmente operacional."
        ]
    },
    {
        "Question Number": "54",
        "Situation": "Uma instituição financeira usa criptografia para proteger dados de clientes armazenados na AWS e deve rotacionar regularmente as chaves de criptografia e renovar os certificados SSL para permanecer em conformidade com os requisitos regulatórios. A instituição precisa automatizar a rotação de chaves e a renovação de certificados para evitar intervenção manual e reduzir o risco de erro humano.",
        "Question": "Qual abordagem a instituição deve adotar para gerenciar de forma eficiente a rotação de chaves e a renovação de certificados em seu ambiente AWS?",
        "Options": {
            "1": "Ativar a rotação automática de chaves no AWS KMS e usar o AWS Certificate Manager (ACM) para renovar automaticamente os certificados SSL/TLS para domínios gerenciados.",
            "2": "Rotacionar manualmente as chaves do KMS a cada 90 dias e renovar os certificados SSL solicitando novos certificados de um provedor terceirizado.",
            "3": "Usar políticas do IAM para impor a rotação regular de chaves e a renovação de certificados em contas da AWS.",
            "4": "Configurar o AWS CloudTrail para rotacionar automaticamente as chaves de criptografia e renovar certificados quando estiverem próximos da expiração."
        },
        "Correct Answer": "Ativar a rotação automática de chaves no AWS KMS e usar o AWS Certificate Manager (ACM) para renovar automaticamente os certificados SSL/TLS para domínios gerenciados.",
        "Explanation": "Essa abordagem aproveita os serviços da AWS projetados para automação e conformidade. O AWS Key Management Service (KMS) permite a rotação automática de chaves, o que garante que as chaves de criptografia sejam rotacionadas regularmente sem intervenção manual, reduzindo assim o risco de erro humano. Além disso, o AWS Certificate Manager (ACM) pode renovar automaticamente os certificados SSL/TLS para domínios gerenciados, simplificando o processo e garantindo que os certificados estejam sempre atualizados. Essa combinação atende efetivamente às necessidades da instituição em termos de conformidade e segurança.",
        "Other Options": [
            "Rotacionar manualmente as chaves do KMS a cada 90 dias e renovar os certificados SSL solicitando novos certificados de um provedor terceirizado é ineficiente e propenso a erro humano. Essa abordagem não automatiza o processo, o que é crucial para manter a conformidade e reduzir o risco de descuidos.",
            "Usar políticas do IAM para impor a rotação regular de chaves e a renovação de certificados em contas da AWS não automatiza diretamente os processos. As políticas do IAM podem impor permissões e controles de acesso, mas não lidam com as tarefas reais de rotação ou renovação, tornando essa opção menos eficaz para as necessidades da instituição.",
            "Configurar o AWS CloudTrail para rotacionar automaticamente as chaves de criptografia e renovar certificados quando estiverem próximos da expiração está incorreto, pois o CloudTrail é principalmente um serviço de registro que rastreia chamadas de API e atividades na AWS. Ele não tem a capacidade de realizar rotação automática de chaves ou renovação de certificados."
        ]
    },
    {
        "Question Number": "55",
        "Situation": "Uma grande empresa com várias contas da AWS deseja simplificar seu processo de faturamento e garantir a gestão centralizada de suas contas da AWS. A organização também deseja estabelecer políticas para grupos específicos de contas para impor padrões de segurança e conformidade entre departamentos.",
        "Question": "Quais recursos da AWS eles devem usar para alcançar esses requisitos, e qual é o papel da conta de gerenciamento nessa configuração? (Escolha duas.)",
        "Options": {
            "1": "Usar o AWS Control Tower para gerenciamento de contas, com a conta de gerenciamento lidando com federação de identidade.",
            "2": "Configurar o AWS Organizations com Faturamento Consolidado, onde a conta de gerenciamento é responsável pelo faturamento e pode convidar outras contas como contas membros.",
            "3": "Usar o AWS Identity and Access Management (IAM) para gerenciar permissões para todas as contas, com a conta raiz lidando com o faturamento para cada conta.",
            "4": "Ativar o AWS Single Sign-On (SSO) e vincular cada conta, permitindo que a conta de gerenciamento gerencie o acesso de usuários e o faturamento para todas as contas vinculadas.",
            "5": "Implementar Políticas de Controle de Serviço (SCPs) dentro do AWS Organizations para impor padrões de segurança e conformidade entre contas membros."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Configurar o AWS Organizations com Faturamento Consolidado, onde a conta de gerenciamento é responsável pelo faturamento e pode convidar outras contas como contas membros.",
            "Implementar Políticas de Controle de Serviço (SCPs) dentro do AWS Organizations para impor padrões de segurança e conformidade entre contas membros."
        ],
        "Explanation": "Configurar o AWS Organizations com Faturamento Consolidado permite que a organização centralize seu processo de faturamento. A conta de gerenciamento nessa configuração é responsável por pagar todas as cobranças incorridas pelas contas membros e pode convidar ou remover outras contas. Esse recurso também permite que a organização consolide métodos de pagamento, tornando o processo de faturamento mais eficiente. Implementar Políticas de Controle de Serviço (SCPs) dentro do AWS Organizations permite que a organização gerencie centralmente permissões entre várias contas da AWS. As SCPs podem ser usadas para impor padrões de segurança e conformidade entre todas as contas membros, o que está alinhado com a exigência da organização de estabelecer políticas para grupos específicos de contas.",
        "Other Options": [
            "Embora o AWS Control Tower possa ser usado para gerenciamento de contas, ele não lida com federação de identidade. A federação de identidade é tipicamente tratada pelo AWS Identity and Access Management (IAM) ou AWS Single Sign-On (SSO).",
            "Embora o AWS Identity and Access Management (IAM) possa ser usado para gerenciar permissões, a conta raiz não lida com o faturamento para cada conta. O faturamento é tipicamente tratado pela conta de gerenciamento no AWS Organizations.",
            "Embora o AWS Single Sign-On (SSO) possa ser usado para gerenciar o acesso de usuários, ele não lida diretamente com o faturamento para todas as contas vinculadas. O faturamento é tipicamente tratado pela conta de gerenciamento no AWS Organizations."
        ]
    },
    {
        "Question Number": "56",
        "Situation": "Uma empresa precisa de uma conexão de rede segura e dedicada entre seu data center local e seu ambiente AWS para acesso de baixa latência a aplicações críticas. Eles estão preocupados com os potenciais riscos de segurança ao transmitir dados sensíveis pela internet.",
        "Question": "Qual solução da AWS oferece a melhor opção para uma conexão segura e dedicada com desempenho de rede consistente?",
        "Options": {
            "1": "Configurar um Internet Gateway (IGW) e usar grupos de segurança para restringir o acesso a aplicações locais.",
            "2": "Usar AWS VPN para estabelecer um túnel IPsec seguro pela internet, permitindo comunicação criptografada.",
            "3": "Implementar AWS Direct Connect, oferecendo um link de rede privado e dedicado entre o data center local e a AWS, com suporte para criptografia através de uma camada VPN adicional, se necessário.",
            "4": "Implantar um Elastic Load Balancer (ELB) e configurar o roteamento para o data center local para acesso seguro."
        },
        "Correct Answer": "Implementar AWS Direct Connect, oferecendo um link de rede privado e dedicado entre o data center local e a AWS, com suporte para criptografia através de uma camada VPN adicional, se necessário.",
        "Explanation": "AWS Direct Connect fornece uma conexão dedicada e privada entre o data center local e a AWS, que é ideal para acesso de baixa latência a aplicações críticas. Esta solução contorna a internet pública, reduzindo significativamente os riscos de segurança associados à transmissão de dados sensíveis pela internet. Além disso, o Direct Connect pode ser combinado com uma VPN para criptografia adicional, garantindo que os dados permaneçam seguros durante o trânsito.",
        "Other Options": [
            "Configurar um Internet Gateway (IGW) e usar grupos de segurança não fornece uma conexão dedicada; em vez disso, permite acesso aos recursos da AWS pela internet pública, o que representa riscos de segurança para dados sensíveis.",
            "Usar AWS VPN estabelece um túnel IPsec seguro pela internet, que criptografa os dados em trânsito. No entanto, ainda depende da internet pública, o que pode introduzir latência e potenciais vulnerabilidades de segurança em comparação com uma conexão dedicada.",
            "Embora AWS Direct Connect seja a escolha correta, a opção de implantar um Elastic Load Balancer (ELB) não é relevante para estabelecer uma conexão de rede dedicada. ELBs são usados para distribuir o tráfego de aplicação de entrada entre múltiplos alvos e não fornecem um link direto entre data centers locais e a AWS."
        ]
    },
    {
        "Question Number": "57",
        "Situation": "Sua equipe precisa implementar um serviço de mensagens que permita que múltiplas aplicações leiam, processem e analisem um fluxo constante de dados de alta frequência, como análises em tempo real sobre interações de usuários com seu aplicativo. O serviço deve suportar múltiplos consumidores simultaneamente, garantindo que cada um possa ler os dados dentro de uma janela deslizante definida.",
        "Question": "Qual serviço se encaixa melhor nesses requisitos e por quê?",
        "Options": {
            "1": "Amazon SQS, porque oferece desacoplamento para comunicação assíncrona com persistência de mensagens.",
            "2": "Amazon Kinesis, porque é otimizado para ingestão de dados em grande escala e múltiplos consumidores com uma janela deslizante para análises em tempo real.",
            "3": "Amazon SNS, pois suporta múltiplos consumidores e entrega em tempo real para vários endpoints.",
            "4": "AWS Lambda com S3, para ingerir e processar dados em tempo real usando gatilhos baseados em eventos."
        },
        "Correct Answer": "Amazon Kinesis, porque é otimizado para ingestão de dados em grande escala e múltiplos consumidores com uma janela deslizante para análises em tempo real.",
        "Explanation": "Amazon Kinesis é especificamente projetado para lidar com fluxos de dados em tempo real e é otimizado para ingestão de dados de alto rendimento. Ele permite que múltiplos consumidores leiam do mesmo fluxo de dados simultaneamente, o que é essencial para o requisito de ter múltiplas aplicações processando os dados de forma concorrente. Além disso, o Kinesis suporta o conceito de uma janela deslizante, permitindo que as aplicações analisem dados ao longo de um período de tempo especificado, tornando-o ideal para análises em tempo real sobre interações de usuários.",
        "Other Options": [
            "Amazon SQS é projetado principalmente para desacoplamento de microsserviços e comunicação assíncrona. Embora forneça persistência de mensagens, não suporta streaming de dados em tempo real ou o conceito de uma janela deslizante para múltiplos consumidores, tornando-o menos adequado para o caso de uso descrito.",
            "Amazon SNS é um serviço de mensagens pub/sub que permite que mensagens sejam enviadas para múltiplos assinantes. No entanto, não fornece a capacidade para consumidores lerem dados dentro de uma janela deslizante definida ou lidar efetivamente com fluxos de dados de alta frequência, o que é crucial para análises em tempo real.",
            "AWS Lambda com S3 não é um serviço de mensagens, mas sim um serviço de computação sem servidor que pode processar dados em resposta a eventos. Embora possa ser usado para processamento em tempo real, depende do S3 para armazenamento, que não é otimizado para fluxos de dados de alta frequência ou múltiplos consumidores acessando os mesmos dados simultaneamente."
        ]
    },
    {
        "Question Number": "58",
        "Situation": "Uma empresa de mídia armazena grandes arquivos de vídeo localmente e precisa migrar esses arquivos para o Amazon S3 para armazenamento escalável e acesso global. A migração deve ser automatizada e minimizar a quantidade de intervenção manual necessária.",
        "Question": "Qual serviço da AWS o arquiteto de soluções deve usar para facilitar essa transferência de dados?",
        "Options": {
            "1": "AWS Snowball",
            "2": "AWS DataSync",
            "3": "Amazon S3 Transfer Acceleration",
            "4": "AWS Direct Connect"
        },
        "Correct Answer": "AWS DataSync",
        "Explanation": "AWS DataSync é especificamente projetado para automatizar a transferência de grandes quantidades de dados entre armazenamento local e serviços da AWS como o Amazon S3. Ele simplifica e acelera o processo de migração ao gerenciar a transferência de dados de forma eficiente, permitindo agendamento e monitoramento das tarefas de transferência. Isso minimiza a intervenção manual e é ideal para o cenário descrito, onde uma empresa de mídia precisa migrar grandes arquivos de vídeo para o S3.",
        "Other Options": [
            "AWS Snowball é uma solução de transporte de dados física que é usada para transferir grandes quantidades de dados para a AWS quando a transferência pela rede não é viável. Embora possa ser usada para grandes migrações de dados, requer o envio físico de dispositivos e não é automatizada da mesma forma que o DataSync.",
            "Amazon S3 Transfer Acceleration é um recurso que acelera uploads para o S3 usando as localizações de borda distribuídas globalmente do Amazon CloudFront. No entanto, não automatiza o processo de transferência do armazenamento local; apenas acelera a transferência uma vez iniciada.",
            "AWS Direct Connect fornece uma conexão de rede dedicada do local para a AWS, o que pode melhorar a largura de banda e reduzir a latência para transferências de dados. No entanto, não automatiza o processo de migração e é mais adequado para necessidades de transferência de dados contínuas do que para migrações únicas."
        ]
    },
    {
        "Question Number": "59",
        "Situation": "Uma empresa SaaS tem múltiplas aplicações conectando-se a um banco de dados central, resultando em altas contagens de conexão durante horários de pico. Eles querem reduzir os custos associados à abertura e manutenção de conexões, garantindo ao mesmo tempo um desempenho suave do banco de dados.",
        "Question": "Qual solução atenderia melhor a esses requisitos?",
        "Options": {
            "1": "Adicionar mais instâncias de banco de dados para distribuir as conexões",
            "2": "Implementar um proxy de banco de dados para agrupar conexões",
            "3": "Habilitar implantação multi-AZ para failover",
            "4": "Usar uma camada de cache para gerenciar conexões"
        },
        "Correct Answer": "Implementar um proxy de banco de dados para agrupar conexões",
        "Explanation": "Implementar um proxy de banco de dados para agrupar conexões é a melhor solução para reduzir custos associados à abertura e manutenção de conexões, garantindo ao mesmo tempo um desempenho suave do banco de dados. Um proxy de banco de dados pode gerenciar e reutilizar conexões existentes, o que minimiza a sobrecarga de estabelecer novas conexões e reduz o número total de conexões ao banco de dados. Isso leva a uma melhor utilização de recursos e pode melhorar significativamente o desempenho durante horários de pico, permitindo que as aplicações compartilhem conexões de forma eficiente.",
        "Other Options": [
            "Adicionar mais instâncias de banco de dados para distribuir as conexões pode ajudar com balanceamento de carga, mas não aborda diretamente a questão das altas contagens de conexão. Isso pode levar a custos aumentados sem resolver o problema subjacente de gerenciamento de conexões.",
            "Habilitar a implantação multi-AZ para failover é principalmente uma estratégia para melhorar a disponibilidade e a recuperação de desastres. Embora melhore a resiliência, não reduz diretamente as contagens de conexão ou os custos associados ao gerenciamento dessas conexões.",
            "Usar uma camada de cache para gerenciar conexões pode melhorar o desempenho ao reduzir a carga no banco de dados, mas não aborda especificamente a questão do agrupamento de conexões. O cache é mais sobre armazenar dados frequentemente acessados do que gerenciar conexões de banco de dados."
        ]
    },
    {
        "Question Number": "60",
        "Situation": "Uma empresa exige que seus usuários da AWS implementem a Autenticação de Múltiplos Fatores (MFA) para maior segurança. Cada usuário deve usar um dispositivo único, como um aplicativo de celular, para gerar um código de uso único baseado em tempo. O código muda periodicamente e é necessário toda vez que eles fazem login, além de seu nome de usuário e senha.",
        "Question": "Qual das seguintes afirmações DESCREVE MELHOR o benefício de segurança proporcionado por esse tipo de configuração de MFA?",
        "Options": {
            "1": "Garante que apenas usuários que conhecem a senha da conta raiz da AWS possam fazer login.",
            "2": "Exige que os usuários se autentiquem com algo que sabem e algo que têm, reduzindo a probabilidade de acesso não autorizado.",
            "3": "Permite que os usuários contornem a senha se estiverem usando o código MFA correto.",
            "4": "Funciona apenas para usuários que têm acesso físico ao console de gerenciamento da AWS."
        },
        "Correct Answer": "Exige que os usuários se autentiquem com algo que sabem e algo que têm, reduzindo a probabilidade de acesso não autorizado.",
        "Explanation": "Esta afirmação descreve com precisão o benefício de segurança da Autenticação de Múltiplos Fatores (MFA). A MFA aumenta a segurança exigindo duas formas de verificação: algo que o usuário sabe (sua senha) e algo que o usuário tem (o código de uso único baseado em tempo gerado pelo seu dispositivo móvel). Este requisito duplo reduz significativamente o risco de acesso não autorizado, pois um invasor precisaria tanto da senha quanto do acesso ao dispositivo do usuário para obter entrada.",
        "Other Options": [
            "Esta afirmação está incorreta porque a MFA não garante especificamente que apenas usuários que conhecem a senha da conta raiz da AWS possam fazer login. A MFA se aplica a todos os usuários e aumenta a segurança além da conta raiz.",
            "Esta afirmação está incorreta porque é a resposta correta. Ela descreve com precisão o benefício de segurança da MFA, que combina algo que o usuário sabe (senha) e algo que eles têm (código MFA).",
            "Esta afirmação está incorreta porque a MFA não permite que os usuários contornem a senha. O código MFA é uma camada adicional de segurança que deve ser fornecida juntamente com a senha para autenticação bem-sucedida."
        ]
    },
    {
        "Question Number": "61",
        "Situation": "Uma organização está usando AWS CloudFormation para automatizar a implantação de sua infraestrutura, incluindo recursos relacionados à segurança, como funções IAM, grupos de segurança e volumes de armazenamento criptografados. Eles querem garantir que todas as implantações permaneçam em conformidade com as políticas de segurança e evitar alterações não autorizadas em recursos críticos.",
        "Question": "Quais são as melhores práticas que eles devem seguir para proteger seus recursos gerenciados pelo CloudFormation? (Escolha duas.)",
        "Options": {
            "1": "Ativar StackSets com detecção de desvio do CloudFormation para monitorar alterações em recursos implantados e usar políticas IAM para limitar quem pode modificar pilhas.",
            "2": "Armazenar todos os modelos do CloudFormation no S3 sem controle de versão para simplificar atualizações e revisões.",
            "3": "Usar o CloudFormation para implantar recursos apenas em sub-redes públicas, garantindo fácil acesso para todos os usuários da organização.",
            "4": "Implementar regras do AWS Config para validar pilhas do CloudFormation em relação às políticas de segurança durante a implantação.",
            "5": "Evitar o uso de funções IAM em pilhas do CloudFormation para simplificar a segurança, confiando em pares de chaves EC2 para controle de acesso."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Ativar StackSets com detecção de desvio do CloudFormation para monitorar alterações em recursos implantados e usar políticas IAM para limitar quem pode modificar pilhas.",
            "Implementar regras do AWS Config para validar pilhas do CloudFormation em relação às políticas de segurança durante a implantação."
        ],
        "Explanation": "Ativar StackSets com detecção de desvio do CloudFormation permite que a organização monitore alterações em recursos implantados. Isso ajuda a identificar quaisquer alterações não autorizadas em recursos críticos. Usar políticas IAM para limitar quem pode modificar pilhas garante que apenas pessoal autorizado possa fazer alterações na infraestrutura, aumentando assim a segurança. Implementar regras do AWS Config para validar pilhas do CloudFormation em relação às políticas de segurança durante a implantação garante que todas as implantações permaneçam em conformidade com as políticas de segurança da organização. Isso ajuda a prevenir quaisquer violações de segurança.",
        "Other Options": [
            "Armazenar todos os modelos do CloudFormation no S3 sem controle de versão simplifica atualizações e revisões, mas não fornece uma maneira de rastrear alterações ou reverter para uma versão anterior se algo der errado. Isso pode levar a vulnerabilidades de segurança e, portanto, não é uma boa prática.",
            "Usar o CloudFormation para implantar recursos apenas em sub-redes públicas não garante segurança. Embora forneça fácil acesso para todos os usuários da organização, também expõe os recursos a potenciais ameaças externas. Portanto, não é uma boa prática para proteger recursos gerenciados pelo CloudFormation.",
            "Evitar o uso de funções IAM em pilhas do CloudFormation e confiar em pares de chaves EC2 para controle de acesso simplifica a segurança, mas não fornece o controle granular que as funções IAM oferecem. As funções IAM oferecem mais flexibilidade e controle sobre quem pode acessar quais recursos, tornando-as uma escolha melhor para segurança. Portanto, isso não é uma boa prática."
        ]
    },
    {
        "Question Number": "62",
        "Situation": "Uma empresa está configurando um novo ambiente AWS multi-conta e deseja garantir uma configuração bem arquitetada com padrões de segurança e conformidade consistentes em todas as contas. Eles também querem capacidades de monitoramento e notificação automatizadas.",
        "Question": "Qual serviço da AWS eles devem usar para agilizar esse processo, e qual recurso específico os ajudará a impor regras e padrões em todas as contas neste ambiente?",
        "Options": {
            "1": "Usar AWS Organizations e implementar Políticas de Controle de Serviço (SCPs) para a imposição de regras entre contas.",
            "2": "Usar AWS Control Tower para automatizar a configuração e o gerenciamento do ambiente multi-conta, usando guardrails para impor regras e monitorar conformidade.",
            "3": "Usar AWS Config para cada conta e configurar manualmente regras de conformidade para monitorar recursos.",
            "4": "Usar AWS CloudFormation para implantar um ambiente personalizado e implementar políticas IAM para gerenciar padrões de segurança entre contas."
        },
        "Correct Answer": "Usar AWS Control Tower para automatizar a configuração e o gerenciamento do ambiente multi-conta, usando guardrails para impor regras e monitorar conformidade.",
        "Explanation": "AWS Control Tower é projetado especificamente para ajudar organizações a configurar e governar um ambiente AWS multi-conta seguro com base nas melhores práticas da AWS. Ele fornece uma maneira simplificada de criar contas, aplicar governança e garantir conformidade por meio de guardrails pré-configurados, que são regras que ajudam a impor políticas entre contas. Este serviço automatiza o processo de configuração e inclui capacidades de monitoramento para garantir que o ambiente esteja em conformidade com os padrões definidos, tornando-o a melhor escolha para os requisitos da empresa.",
        "Other Options": [
            "Usar AWS Organizations com Políticas de Controle de Serviço (SCPs) é uma abordagem válida para gerenciar permissões entre contas, mas não fornece os recursos abrangentes de automação e governança que o AWS Control Tower oferece. SCPs tratam mais de controlar o acesso do que de impor conformidade e monitoramento.",
            "AWS Config é um serviço que permite avaliar, auditar e avaliar as configurações dos seus recursos AWS. Embora possa ajudar no monitoramento de conformidade, requer configuração manual de regras para cada conta, o que não se alinha com o desejo da empresa por uma configuração automatizada e imposição consistente entre várias contas.",
            "AWS CloudFormation é um serviço para implantar infraestrutura como código, que pode ajudar a configurar ambientes de forma consistente. No entanto, não fornece inherentemente recursos de governança ou monitoramento de conformidade entre várias contas. Políticas IAM podem gerenciar padrões de segurança, mas não impõem conformidade ou fornecem capacidades de monitoramento automatizado como o AWS Control Tower."
        ]
    },
    {
        "Question Number": "63",
        "Situation": "Uma plataforma de streaming de mídia, MediaStream, depende fortemente da AWS para suportar milhões de usuários simultâneos em todo o mundo. Eles estão preocupados com o risco de ataques de Negação de Serviço Distribuída (DDoS), que poderiam interromper seu serviço de streaming. A MediaStream quer uma solução que ofereça proteção básica contra DDoS, bem como uma camada avançada para proteção adicional e visibilidade em tempo real sobre eventos DDoS. Eles estão considerando AWS Shield Standard e AWS Shield Advanced para proteger sua aplicação contra potenciais ataques em várias camadas, incluindo as camadas de rede, transporte e aplicação. A MediaStream também quer proteção contra potenciais implicações de custo se um ataque aumentar significativamente seu uso da AWS.",
        "Question": "Qual das seguintes afirmações descreve melhor a diferença entre AWS Shield Standard e AWS Shield Advanced em termos de proteção e recursos fornecidos para mitigação de DDoS na infraestrutura da AWS?",
        "Options": {
            "1": "AWS Shield Standard fornece proteção básica contra DDoS gratuitamente para todos os clientes da AWS, focando principalmente na proteção na periferia dos serviços da AWS, mas não inclui engajamento proativo ou capacidades avançadas de detecção baseada em saúde.",
            "2": "AWS Shield Advanced é um serviço gratuito disponível para todos os clientes da AWS, oferecendo proteção aprimorada contra ataques de camada de aplicação (L7) e integrando-se de forma estreita com o AWS WAF para fornecer proteção de custo e visibilidade em tempo real sobre eventos DDoS.",
            "3": "AWS Shield Standard é um serviço pago que fornece proteção automática contra ataques DDoS de camada de aplicação (L7) em todos os serviços da AWS, incluindo engajamento proativo pela equipe de resposta do AWS Shield.",
            "4": "AWS Shield Advanced é ativado automaticamente para todos os recursos da AWS com IPs Elásticos e fornece configurações de ACL da web gratuitas, proteção proativa de custo e resposta imediata da equipe de resposta do AWS Shield para todos os eventos DDoS em regiões da AWS."
        },
        "Correct Answer": "AWS Shield Standard fornece proteção básica contra DDoS gratuitamente para todos os clientes da AWS, focando principalmente na proteção na periferia dos serviços da AWS, mas não inclui engajamento proativo ou capacidades avançadas de detecção baseada em saúde.",
        "Explanation": "AWS Shield Standard é de fato um serviço gratuito que oferece proteção básica contra DDoS a todos os clientes da AWS. Ele protege principalmente contra ataques DDoS comuns e mais frequentes nas camadas de rede e transporte, focando na periferia dos serviços da AWS. No entanto, não fornece recursos avançados, como engajamento proativo da equipe de resposta do AWS Shield ou capacidades avançadas de detecção baseada em saúde, que estão disponíveis apenas com o AWS Shield Advanced. Isso torna a afirmação precisa ao descrever as limitações do AWS Shield Standard em comparação com o AWS Shield Advanced.",
        "Other Options": [
            "AWS Shield Advanced não é um serviço gratuito; é um serviço pago que fornece proteção aprimorada contra DDoS, incluindo ataques de camada de aplicação (L7) e se integra ao AWS WAF. No entanto, oferece proteção de custo e visibilidade em tempo real, mas não está disponível gratuitamente para todos os clientes da AWS.",
            "AWS Shield Standard não é um serviço pago; é gratuito e não fornece proteção automática contra ataques DDoS de camada de aplicação (L7). O engajamento proativo pela equipe de resposta do AWS Shield é um recurso do AWS Shield Advanced, não do Standard.",
            "AWS Shield Advanced não é ativado automaticamente para todos os recursos da AWS com IPs Elásticos; é necessário se inscrever. Além disso, embora forneça proteção proativa de custo e resposta imediata da equipe de resposta do AWS Shield, não oferece configurações de ACL da web gratuitas como parte de seu serviço."
        ]
    },
    {
        "Question Number": "64",
        "Situation": "Uma empresa está construindo uma aplicação baseada em microserviços usando contêineres e deseja gerenciar e orquestrar esses contêineres de forma escalável na AWS. A empresa está considerando Amazon ECS e Amazon EKS para orquestração, mas não tem certeza de qual serviço atenderá melhor às suas necessidades. Eles requerem controle detalhado sobre a orquestração, redes personalizadas e gerenciamento de contêineres.",
        "Question": "Qual das seguintes opções descreve melhor quando a empresa deve usar Amazon EKS em vez de Amazon ECS?",
        "Options": {
            "1": "Use Amazon EKS se a empresa precisar de recursos nativos do Kubernetes, como orquestração personalizada e capacidades de rede complexas.",
            "2": "Use Amazon ECS para todas as necessidades de orquestração de contêineres, pois é mais simples e mais econômico para aplicações conteinerizadas.",
            "3": "Use Amazon EKS se a empresa precisar de um serviço de contêiner totalmente gerenciado que lide com escalonamento e balanceamento de carga automaticamente para todas as cargas de trabalho conteinerizadas.",
            "4": "Use Amazon ECS apenas se a empresa estiver usando contêineres serverless, pois o Amazon EKS não suporta cargas de trabalho serverless."
        },
        "Correct Answer": "Use Amazon EKS se a empresa precisar de recursos nativos do Kubernetes, como orquestração personalizada e capacidades de rede complexas.",
        "Explanation": "Amazon EKS (Elastic Kubernetes Service) é projetado para usuários que precisam dos recursos avançados e da flexibilidade que o Kubernetes oferece. Isso inclui controle detalhado sobre a orquestração, a capacidade de implementar soluções de rede personalizadas e o uso de ferramentas e APIs nativas do Kubernetes. Se a empresa está procurando essas capacidades, o EKS é a melhor escolha em relação ao ECS (Elastic Container Service), que é mais simples e tem uma abordagem mais opinativa para a orquestração de contêineres.",
        "Other Options": [
            "Esta opção está incorreta porque, embora o Amazon EKS forneça recursos nativos do Kubernetes, não se trata apenas de simplicidade ou custo-efetividade. O ECS é mais simples e pode ser mais econômico para necessidades diretas de orquestração de contêineres, mas carece dos recursos avançados que o EKS oferece.",
            "Esta opção é enganosa porque, embora o Amazon EKS ofereça um serviço gerenciado, ele não lida automaticamente com escalonamento e balanceamento de carga para todas as cargas de trabalho da mesma forma que o ECS. O EKS requer mais configuração e compreensão do Kubernetes para alcançar resultados semelhantes.",
            "Esta opção está incorreta porque o Amazon EKS suporta cargas de trabalho serverless através do AWS Fargate, assim como o Amazon ECS. Portanto, a afirmação de que o EKS não suporta cargas de trabalho serverless é falsa."
        ]
    },
    {
        "Question Number": "65",
        "Situation": "Uma empresa está projetando uma arquitetura de Nuvem Privada Virtual (VPC) na AWS para suportar uma aplicação de múltiplas camadas. A arquitetura precisa de três zonas de disponibilidade (AZs) com uma zona extra reservada para crescimento futuro. Cada zona de disponibilidade terá sub-redes separadas para as camadas web, aplicação e banco de dados, além de uma sub-rede extra reservada para expansão futura. A empresa quer garantir que haja endereços IP suficientes para escalar a aplicação em cada camada.",
        "Question": "Qual das seguintes configurações de VPC atenderá melhor a esses requisitos, permitindo crescimento futuro?",
        "Options": {
            "1": "Usar um bloco CIDR /28 para a VPC e dividir cada zona de disponibilidade em sub-redes /30 para maximizar o uso de endereços IP dentro de cada sub-rede.",
            "2": "Configurar um bloco CIDR /16 para a VPC, fornecendo um total de 65.536 endereços IP, e atribuir sub-redes /20 para cada camada em cada zona de disponibilidade para garantir endereços IP suficientes por camada.",
            "3": "Escolher um bloco CIDR /24 para a VPC, fornecendo um total de 256 endereços IP, e usar sub-redes /26 para cada camada em cada zona de disponibilidade para otimizar o espaço de endereços.",
            "4": "Configurar um bloco CIDR /22 para a VPC para suportar 1.024 endereços IP, dividindo cada zona de disponibilidade em sub-redes /25 para cada camada para equilibrar espaço de endereços e escalabilidade."
        },
        "Correct Answer": "Configurar um bloco CIDR /16 para a VPC, fornecendo um total de 65.536 endereços IP, e atribuir sub-redes /20 para cada camada em cada zona de disponibilidade para garantir endereços IP suficientes por camada.",
        "Explanation": "Escolher um bloco CIDR /16 para a VPC permite um grande espaço de endereços de 65.536 endereços IP, o que é mais do que suficiente para a aplicação de múltiplas camadas que requer sub-redes separadas para as camadas web, aplicação e banco de dados em três zonas de disponibilidade, além de uma sub-rede adicional para crescimento futuro. Ao atribuir sub-redes /20, cada sub-rede terá 4.096 endereços IP (2^(32-20)), proporcionando amplo espaço para escalonamento dentro de cada camada, enquanto ainda permite expansão futura.",
        "Other Options": [
            "Usar um bloco CIDR /28 para a VPC fornece apenas 16 endereços IP, o que é muito limitado para uma aplicação de múltiplas camadas que requer várias sub-redes em três zonas de disponibilidade. Dividir cada AZ em sub-redes /30 reduziria ainda mais o número de endereços IP utilizáveis, tornando essa opção impraticável.",
            "Um bloco CIDR /24 fornece apenas 256 endereços IP, o que é insuficiente para os requisitos da aplicação. Usar sub-redes /26 permitiria apenas 64 endereços IP por sub-rede, o que não é suficiente para as camadas web, aplicação e banco de dados, especialmente considerando a necessidade de crescimento futuro.",
            "Configurar um bloco CIDR /22 permite 1.024 endereços IP, o que é melhor do que as opções anteriores, mas ainda pode não fornecer espaço suficiente para escalonamento. Dividir cada zona de disponibilidade em sub-redes /25 daria 128 endereços IP por sub-rede, o que pode ser limitante para as camadas da aplicação, especialmente à medida que a empresa planeja a expansão futura."
        ]
    }
]