[
    {
        "Question Number": "1",
        "Situation": "Una empresa está adoptando infraestructura inmutable para el despliegue de su aplicación. Quieren asegurarse de que todos los cambios en la infraestructura se realicen reemplazando recursos en lugar de modificarlos en su lugar, con el objetivo de lograr una mejor consistencia y facilitar las reversas.",
        "Question": "¿Cuál de las siguientes describe mejor el principio de infraestructura inmutable y sus beneficios? (Elige dos.)",
        "Options": {
            "1": "La infraestructura inmutable asegura que los servidores y recursos siempre se modifiquen en su lugar, evitando la necesidad de reemplazo de recursos.",
            "2": "La infraestructura inmutable implica reemplazar completamente servidores o componentes de infraestructura cuando se necesitan cambios, asegurando que no se apliquen cambios a las instancias en ejecución y facilitando las reversas.",
            "3": "La infraestructura inmutable elimina la necesidad de control de versiones, ya que cada actualización se integra automáticamente en los recursos existentes.",
            "4": "La infraestructura inmutable se basa en configuraciones manuales de servidores, asegurando que no se utilice automatización durante el proceso de despliegue.",
            "5": "La infraestructura inmutable mejora la consistencia al asegurar que todos los despliegues sean idénticos y reduce la deriva de configuración."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "La infraestructura inmutable implica reemplazar completamente servidores o componentes de infraestructura cuando se necesitan cambios, asegurando que no se apliquen cambios a las instancias en ejecución y facilitando las reversas.",
            "La infraestructura inmutable mejora la consistencia al asegurar que todos los despliegues sean idénticos y reduce la deriva de configuración."
        ],
        "Explanation": "La infraestructura inmutable es un principio en el que los servidores o componentes de infraestructura se reemplazan completamente cuando se necesitan cambios, en lugar de modificarlos en su lugar. Esto asegura que no se apliquen cambios a las instancias en ejecución, lo que facilita las reversas. También mejora la consistencia al asegurar que todos los despliegues sean idénticos, lo que reduce la deriva de configuración. Este enfoque puede reducir significativamente el riesgo de inconsistencias y errores en la infraestructura, haciéndola más confiable y más fácil de gestionar.",
        "Other Options": [
            "La infraestructura inmutable no implica modificar servidores y recursos en su lugar. En cambio, implica reemplazarlos completamente cuando se necesitan cambios.",
            "La infraestructura inmutable no elimina la necesidad de control de versiones. De hecho, el control de versiones es crucial en una infraestructura inmutable para hacer un seguimiento de todas las diferentes versiones de los componentes de infraestructura.",
            "La infraestructura inmutable no se basa en configuraciones manuales de servidores. En cambio, a menudo implica automatización para asegurar que todos los despliegues sean idénticos y facilitar el reemplazo de servidores o componentes de infraestructura cuando se necesitan cambios."
        ]
    },
    {
        "Question Number": "2",
        "Situation": "Una empresa de retail opera un sitio web de comercio electrónico en instancias de Amazon EC2 detrás de un Application Load Balancer. La empresa experimenta patrones de tráfico fluctuantes y quiere asegurarse de que la aplicación escale automáticamente para manejar cargas variables mientras minimiza costos.",
        "Question": "¿Qué configuraciones debería implementar un arquitecto de soluciones para cumplir con estos requisitos? (Elige dos.)",
        "Options": {
            "1": "Configurar un grupo de Auto Scaling con un número fijo de instancias de EC2 y usar Reserved Instances para ahorrar costos.",
            "2": "Usar Spot Instances con un grupo de Auto Scaling para manejar tráfico variable.",
            "3": "Configurar un grupo de Auto Scaling con políticas de escalado de seguimiento de objetivos basadas en la utilización de CPU.",
            "4": "Desplegar la aplicación en AWS Elastic Beanstalk con políticas de escalado manual.",
            "5": "Implementar escalado predictivo utilizando Amazon CloudWatch para prever el tráfico y ajustar la capacidad proactivamente."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Usar Spot Instances con un grupo de Auto Scaling para manejar tráfico variable.",
            "Configurar un grupo de Auto Scaling con políticas de escalado de seguimiento de objetivos basadas en la utilización de CPU."
        ],
        "Explanation": "Las Spot Instances con un grupo de Auto Scaling son una opción rentable para manejar tráfico variable porque permiten aprovechar la capacidad no utilizada de EC2 en la nube de AWS. Las Spot Instances están disponibles con hasta un 90% de descuento en comparación con los precios de On-Demand. Un grupo de Auto Scaling con políticas de escalado de seguimiento de objetivos basadas en la utilización de CPU permite que la aplicación escale automáticamente según la demanda. Cuando la demanda aumenta, se añaden automáticamente nuevas instancias y cuando la demanda disminuye, se eliminan instancias automáticamente. Esto asegura que solo estés utilizando (y pagando por) lo que necesitas.",
        "Other Options": [
            "Configurar un grupo de Auto Scaling con un número fijo de instancias de EC2 y usar Reserved Instances para ahorrar costos no es la mejor opción para manejar tráfico variable porque no permite el escalado automático basado en la demanda. Las Reserved Instances ofrecen un ahorro de costos sobre las instancias On-Demand, pero no proporcionan la flexibilidad necesaria para patrones de tráfico fluctuantes.",
            "Desplegar la aplicación en AWS Elastic Beanstalk con políticas de escalado manual no es la mejor opción porque no permite el escalado automático. El escalado manual requiere intervención manual para añadir o eliminar instancias, lo cual no es ideal para manejar patrones de tráfico fluctuantes.",
            "Implementar escalado predictivo utilizando Amazon CloudWatch para prever el tráfico y ajustar la capacidad proactivamente puede ser una buena opción para algunos casos de uso, pero no es la solución más rentable para este escenario en particular. El escalado predictivo utiliza algoritmos de aprendizaje automático para predecir patrones de tráfico futuros y ajustar la capacidad en consecuencia, lo que puede ser más costoso que otras opciones."
        ]
    },
    {
        "Question Number": "3",
        "Situation": "Una empresa está ejecutando una aplicación web que experimenta tráfico fluctuante. Necesitan asegurarse de que la aplicación pueda manejar un alto tráfico durante las horas pico sin sobreaprovisionar recursos.",
        "Question": "¿Qué estrategia de escalado debería utilizar la empresa para gestionar mejor la variabilidad del tráfico y la rentabilidad?",
        "Options": {
            "1": "Usar escalado horizontal añadiendo más instancias de EC2 detrás de un balanceador de carga para distribuir el tráfico, asegurando que los recursos escalen en respuesta a los cambios en la demanda.",
            "2": "Usar escalado vertical aumentando el tamaño de las instancias de EC2 para manejar más tráfico, aunque esto puede no proporcionar tanta flexibilidad durante picos de tráfico.",
            "3": "Usar una combinación de escalado horizontal y vertical, donde el escalado horizontal se utiliza para cambios menores en el tráfico, y el escalado vertical se utiliza para manejar picos extremos.",
            "4": "Usar escalado manual, ajustando los tamaños de las instancias de EC2 y el número de instancias según las previsiones de patrones de tráfico."
        },
        "Correct Answer": "Usar escalado horizontal añadiendo más instancias de EC2 detrás de un balanceador de carga para distribuir el tráfico, asegurando que los recursos escalen en respuesta a los cambios en la demanda.",
        "Explanation": "El escalado horizontal es la estrategia más efectiva para gestionar el tráfico fluctuante porque permite que la aplicación añada o elimine instancias según la demanda en tiempo real. Este enfoque asegura que durante las horas pico, se puedan aprovisionar instancias adicionales de EC2 para manejar el aumento del tráfico, mientras que durante las horas de menor actividad, se pueden reducir las instancias para ahorrar costos. Esta capacidad de escalado dinámico proporciona tanto flexibilidad como rentabilidad, ya que los recursos solo se utilizan cuando son necesarios.",
        "Other Options": [
            "El escalado vertical implica aumentar el tamaño de las instancias de EC2 existentes para manejar más tráfico. Si bien esto puede ser efectivo, tiene limitaciones en flexibilidad y puede llevar a tiempos de inactividad durante las operaciones de escalado. Además, hay un límite máximo de tamaño para las instancias, que puede no ser suficiente durante picos de tráfico extremos.",
            "Una combinación de escalado horizontal y vertical puede proporcionar beneficios, pero complica la estrategia de escalado y puede no ser tan eficiente como usar solo escalado horizontal. El escalado horizontal se prefiere generalmente para manejar tráfico variable porque permite un control más granular sobre la asignación de recursos.",
            "El escalado manual se basa en previsiones de patrones de tráfico, que pueden ser inexactas. Este enfoque no proporciona la agilidad necesaria para responder a cambios repentinos en el tráfico, lo que puede llevar a problemas de rendimiento durante picos inesperados y costos innecesarios durante períodos de bajo tráfico."
        ]
    },
    {
        "Question Number": "4",
        "Situation": "Una organización de atención médica necesita asegurarse de que todos los datos almacenados en Amazon RDS para PostgreSQL estén cifrados en reposo y que las claves de cifrado se gestionen de forma segura. La organización debe cumplir con estrictos requisitos regulatorios para la protección de datos.",
        "Question": "¿Qué solución cumplirá con estos requisitos?",
        "Options": {
            "1": "Habilitar el cifrado en reposo utilizando el cifrado de Amazon RDS y gestionar las claves con AWS Key Management Service (KMS).",
            "2": "Utilizar Amazon S3 para almacenar copias de seguridad de la base de datos y habilitar el cifrado de S3.",
            "3": "Implementar SSL/TLS para los datos en tránsito y confiar en el cifrado predeterminado de RDS.",
            "4": "Cifrar los datos dentro de la aplicación antes de almacenarlos en la base de datos de RDS."
        },
        "Correct Answer": "Habilitar el cifrado en reposo utilizando el cifrado de Amazon RDS y gestionar las claves con AWS Key Management Service (KMS).",
        "Explanation": "Esta opción aborda directamente el requisito de cifrar los datos en reposo en Amazon RDS para PostgreSQL. Amazon RDS proporciona capacidades de cifrado integradas que se pueden habilitar para garantizar que todos los datos almacenados en la base de datos estén cifrados. Además, utilizar AWS Key Management Service (KMS) permite una gestión segura de las claves de cifrado, lo cual es crucial para cumplir con los requisitos regulatorios sobre la protección de datos. Esta solución asegura tanto el cifrado como la gestión segura de claves de manera fluida.",
        "Other Options": [
            "Utilizar Amazon S3 para almacenar copias de seguridad de la base de datos y habilitar el cifrado de S3 no cumple con el requisito de cifrar los datos en reposo dentro de la base de datos de RDS en sí. Si bien el cifrado de S3 es útil para las copias de seguridad, no aborda el cifrado de los datos en vivo almacenados en RDS.",
            "Implementar SSL/TLS para los datos en tránsito es importante para asegurar los datos mientras viajan entre el cliente y la base de datos, pero no proporciona cifrado para los datos en reposo. Además, confiar en el cifrado predeterminado de RDS puede no cumplir con requisitos regulatorios específicos, ya que no permite la gestión personalizada de claves ni verificaciones de cumplimiento.",
            "Cifrar los datos dentro de la aplicación antes de almacenarlos en la base de datos de RDS es un enfoque válido, pero requiere un esfuerzo de desarrollo adicional y puede complicar el acceso y la gestión de datos. Además, no utiliza las características de cifrado integradas de RDS, que están diseñadas para simplificar el cumplimiento de las regulaciones de protección de datos."
        ]
    },
    {
        "Question Number": "5",
        "Situation": "Una empresa está migrando su aplicación local a AWS. La aplicación consiste en un servidor web, un servidor de aplicaciones y un servidor de bases de datos. La empresa quiere asegurarse de que el servidor de bases de datos no sea accesible directamente desde Internet y que solo pueda ser accedido por el servidor de aplicaciones.",
        "Question": "¿Qué configuraciones de red cumplirán con estos requisitos? (Elija dos.)",
        "Options": {
            "1": "Colocar el servidor web y el servidor de aplicaciones en una subred pública y el servidor de bases de datos en una subred privada. Configurar grupos de seguridad para permitir el tráfico solo desde el servidor de aplicaciones al servidor de bases de datos.",
            "2": "Colocar todos los servidores en una subred pública y usar ACL de red para restringir el acceso al servidor de bases de datos.",
            "3": "Colocar el servidor web en una subred pública y los servidores de aplicaciones y bases de datos en subredes privadas separadas. Usar grupos de seguridad para permitir el tráfico solo desde el servidor web al servidor de aplicaciones y desde el servidor de aplicaciones al servidor de bases de datos.",
            "4": "Colocar el servidor web y el servidor de bases de datos en una subred pública y el servidor de aplicaciones en una subred privada. Usar grupos de seguridad para permitir el tráfico solo desde el servidor web al servidor de aplicaciones.",
            "5": "Usar AWS Transit Gateway para gestionar el enrutamiento entre subredes y restringir el acceso al servidor de bases de datos a través de tablas de rutas."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Colocar el servidor web y el servidor de aplicaciones en una subred pública y el servidor de bases de datos en una subred privada. Configurar grupos de seguridad para permitir el tráfico solo desde el servidor de aplicaciones al servidor de bases de datos.",
            "Colocar el servidor web en una subred pública y los servidores de aplicaciones y bases de datos en subredes privadas separadas. Usar grupos de seguridad para permitir el tráfico solo desde el servidor web al servidor de aplicaciones y desde el servidor de aplicaciones al servidor de bases de datos."
        ],
        "Explanation": "Las respuestas correctas son opciones que colocan el servidor web y el servidor de aplicaciones en una subred pública, y el servidor de bases de datos en una subred privada. Esta configuración asegura que el servidor de bases de datos no sea accesible directamente desde Internet, como se requiere. Luego, se utilizan grupos de seguridad para controlar el tráfico, permitiendo solo que el servidor de aplicaciones acceda al servidor de bases de datos. En la segunda opción correcta, los servidores de aplicaciones y bases de datos están en subredes privadas separadas, lo que añade una capa adicional de seguridad y aislamiento.",
        "Other Options": [
            "Colocar todos los servidores en una subred pública y usar ACL de red para restringir el acceso al servidor de bases de datos no es una buena práctica. Expone todos los servidores a Internet, lo que aumenta el riesgo de brechas de seguridad.",
            "Colocar el servidor web y el servidor de bases de datos en una subred pública y el servidor de aplicaciones en una subred privada no cumple con el requisito de que el servidor de bases de datos sea inaccesible desde Internet.",
            "Usar AWS Transit Gateway para gestionar el enrutamiento entre subredes y restringir el acceso al servidor de bases de datos a través de tablas de rutas no es el método más eficiente o seguro. Puede ser complejo de gestionar y no proporciona el mismo nivel de seguridad que usar subredes privadas y públicas con grupos de seguridad."
        ]
    },
    {
        "Question Number": "6",
        "Situation": "Una empresa minorista opera un sitio web de comercio electrónico alojado en instancias de Amazon EC2 detrás de un Application Load Balancer. El sitio web experimenta patrones de tráfico fluctuantes, especialmente durante las temporadas de compras pico, y la empresa quiere asegurarse de que la aplicación escale automáticamente para manejar cargas variables sin incurrir en costos innecesarios durante períodos de bajo tráfico. El equipo está buscando una configuración óptima para soportar el escalado automático mientras minimiza sus costos de infraestructura.",
        "Question": "¿Qué configuración debería implementar un arquitecto de soluciones para cumplir con estos requisitos?",
        "Options": {
            "1": "Configurar un grupo de Auto Scaling con un número fijo de instancias de EC2 y reservar capacidad con Reserved Instances para ahorros de costos a largo plazo.",
            "2": "Usar Spot Instances dentro de un grupo de Auto Scaling para manejar el tráfico fluctuante, permitiendo que las instancias escalen durante cargas pico mientras se reducen costos.",
            "3": "Configurar un grupo de Auto Scaling con políticas de escalado de seguimiento de objetivos basadas en la utilización de CPU para ajustar dinámicamente la capacidad según la demanda.",
            "4": "Desplegar la aplicación en AWS Elastic Beanstalk y usar políticas de escalado manual para agregar o quitar instancias a medida que cambian los patrones de tráfico."
        },
        "Correct Answer": "Configurar un grupo de Auto Scaling con políticas de escalado de seguimiento de objetivos basadas en la utilización de CPU para ajustar dinámicamente la capacidad según la demanda.",
        "Explanation": "Configurar un grupo de Auto Scaling con políticas de escalado de seguimiento de objetivos permite que la aplicación ajuste automáticamente el número de instancias de EC2 según la demanda en tiempo real, específicamente la utilización de CPU en este caso. Esta configuración asegura que la aplicación pueda escalar durante períodos de tráfico pico para manejar cargas aumentadas y escalar hacia abajo durante períodos de bajo tráfico para minimizar costos. Las políticas de escalado de seguimiento de objetivos son sencillas de implementar y gestionar, proporcionando un equilibrio entre rendimiento y eficiencia de costos.",
        "Other Options": [
            "Configurar un grupo de Auto Scaling con un número fijo de instancias de EC2 no permite el escalado dinámico basado en patrones de tráfico. Si bien las Reserved Instances pueden proporcionar ahorros de costos para el uso a largo plazo, este enfoque no aborda efectivamente las necesidades de tráfico fluctuante, ya que no escala hacia abajo durante períodos de bajo tráfico.",
            "Usar Spot Instances dentro de un grupo de Auto Scaling puede reducir costos, pero las Spot Instances pueden ser terminadas por AWS con poco aviso, lo que puede llevar a inestabilidad de la aplicación durante cargas pico. Esta opción no es ideal para una empresa minorista que requiere disponibilidad constante durante las temporadas de compras de alta demanda.",
            "Desplegar la aplicación en AWS Elastic Beanstalk con políticas de escalado manual no proporciona el escalado automático necesario para patrones de tráfico fluctuantes. El escalado manual requiere intervención humana para ajustar el número de instancias, lo que puede llevar a retrasos y posibles problemas de rendimiento durante los momentos pico."
        ]
    },
    {
        "Question Number": "7",
        "Situation": "Una empresa de medios tiene múltiples VPCs en diferentes cuentas de AWS y quiere habilitar una comunicación privada y rentable entre las VPCs sin pasar por Internet público. También desea reducir los costos de transferencia de datos asociados con esta configuración.",
        "Question": "¿Qué configuración de red sería la solución más rentable?",
        "Options": {
            "1": "Usar VPC Peering entre cada VPC",
            "2": "Usar AWS Transit Gateway para la comunicación centralizada entre VPCs",
            "3": "Enrutar el tráfico a través de NAT gateways para un acceso seguro",
            "4": "Establecer una conexión VPN para cada VPC"
        },
        "Correct Answer": "Usar AWS Transit Gateway para la comunicación centralizada entre VPCs",
        "Explanation": "AWS Transit Gateway está diseñado para simplificar la gestión de múltiples VPCs y permite una comunicación privada y rentable entre ellas. Permite un modelo de hub-and-spoke donde todas las VPCs pueden conectarse a una puerta de enlace central, reduciendo la complejidad y el costo asociado con la gestión de múltiples conexiones de peering entre VPCs. Además, Transit Gateway puede ayudar a reducir los costos de transferencia de datos al consolidar el tráfico a través de un único punto en lugar de requerir múltiples conexiones de peering, que pueden incurrir en cargos más altos por transferencia de datos.",
        "Other Options": [
            "Usar VPC Peering entre cada VPC puede volverse complejo y costoso a medida que aumenta el número de VPCs. Cada VPC requeriría una conexión de peering separada, lo que llevaría a una explosión combinatoria de conexiones y mayores costos de gestión, así como potencialmente mayores costos de transferencia de datos debido a la naturaleza del peering entre VPCs.",
            "Enrutar el tráfico a través de NAT gateways no es adecuado para la comunicación entre VPCs, ya que los NAT gateways se utilizan principalmente para el acceso a Internet saliente desde subredes privadas. Esta opción no facilitaría la comunicación directa entre VPCs y generaría costos adicionales por la transferencia de datos a través del NAT gateway.",
            "Establecer una conexión VPN para cada VPC sería ineficiente y costoso, especialmente al tratar con múltiples VPCs. Cada conexión VPN incurre en costos y añade complejidad a la arquitectura de red. Además, las conexiones VPN suelen tener un menor rendimiento en comparación con otras opciones y pueden introducir latencia."
        ]
    },
    {
        "Question Number": "8",
        "Situation": "Una empresa está desplegando una aplicación web que debe estar protegida contra ataques comunes basados en la web, como inyección SQL y scripting entre sitios.",
        "Question": "¿Qué servicio de AWS debería utilizarse para proporcionar esta protección?",
        "Options": {
            "1": "AWS Shield",
            "2": "AWS WAF (Web Application Firewall)",
            "3": "Amazon Macie",
            "4": "Amazon GuardDuty"
        },
        "Correct Answer": "AWS WAF (Web Application Firewall)",
        "Explanation": "AWS WAF (Web Application Firewall) está diseñado específicamente para proteger aplicaciones web de ataques comunes basados en la web, como inyección SQL y scripting entre sitios (XSS). Permite a los usuarios crear reglas que filtran y monitorean las solicitudes HTTP en función de condiciones personalizables, bloqueando efectivamente el tráfico malicioso antes de que llegue a la aplicación. Esto lo convierte en la opción más adecuada para el escenario descrito.",
        "Other Options": [
            "AWS Shield es un servicio de protección DDoS gestionado que salvaguarda aplicaciones de ataques de Denegación de Servicio Distribuida. Si bien proporciona características de seguridad importantes, no aborda específicamente las vulnerabilidades de inyección SQL o scripting entre sitios.",
            "Amazon Macie es un servicio de seguridad y privacidad de datos que utiliza aprendizaje automático para descubrir, clasificar y proteger datos sensibles almacenados en AWS. No está diseñado para proteger aplicaciones web de ataques basados en la web.",
            "Amazon GuardDuty es un servicio de detección de amenazas que monitorea continuamente la actividad maliciosa y el comportamiento no autorizado para proteger cuentas y cargas de trabajo de AWS. Si bien mejora la seguridad general, no proporciona específicamente protección contra ataques de inyección SQL o scripting entre sitios."
        ]
    },
    {
        "Question Number": "9",
        "Situation": "Una empresa está desplegando una aplicación web de múltiples capas en AWS. La aplicación consiste en una capa de front-end en instancias de Amazon EC2 y una base de datos de backend en Amazon RDS. La empresa requiere que la base de datos no sea accesible directamente desde Internet y que solo la capa de front-end pueda comunicarse con la base de datos.",
        "Question": "¿Qué configuración de red debería implementar el arquitecto de soluciones?",
        "Options": {
            "1": "Colocar tanto la capa de front-end como la de base de datos en una subred pública y usar grupos de seguridad para restringir el acceso.",
            "2": "Colocar la capa de front-end en una subred pública y la capa de base de datos en una subred privada. Configurar grupos de seguridad para permitir que solo las instancias de front-end se comuniquen con la base de datos.",
            "3": "Colocar ambas capas en subredes privadas y usar un NAT gateway para acceso a Internet.",
            "4": "Usar una puerta de enlace de Internet y tablas de enrutamiento para controlar el acceso entre las capas de front-end y base de datos."
        },
        "Correct Answer": "Colocar la capa de front-end en una subred pública y la capa de base de datos en una subred privada. Configurar grupos de seguridad para permitir que solo las instancias de front-end se comuniquen con la base de datos.",
        "Explanation": "Esta configuración asegura que la base de datos no sea accesible directamente desde Internet, ya que reside en una subred privada. La capa de front-end, que está en una subred pública, puede comunicarse con la base de datos a través de grupos de seguridad que permiten el tráfico solo desde las instancias de front-end. Esta configuración se adhiere a las mejores prácticas de seguridad y arquitectura en AWS, asegurando que la base de datos esté protegida del acceso externo mientras sigue siendo accesible para la capa de aplicación que la necesita.",
        "Other Options": [
            "Colocar tanto la capa de front-end como la de base de datos en una subred pública expone la base de datos a Internet, lo que viola el requisito de que la base de datos no debe ser accesible directamente desde Internet.",
            "Si bien colocar ambas capas en subredes privadas mejora la seguridad, no permite que la capa de front-end se comunique con la base de datos a menos que se implementen configuraciones adicionales (como un NAT gateway), lo cual es innecesario para este escenario ya que el front-end necesita ser público.",
            "Usar una puerta de enlace de Internet y tablas de enrutamiento para controlar el acceso expondría la base de datos a Internet, lo que contradice el requisito de mantener la base de datos inaccesible desde Internet."
        ]
    },
    {
        "Question Number": "10",
        "Situation": "Una plataforma de comercio electrónico quiere migrar su base de datos a AWS pero desea minimizar los cambios en el código. Su base de datos actual en las instalaciones es PostgreSQL, y necesitan una solución gestionada que soporte alta disponibilidad y escalado de lectura.",
        "Question": "¿Qué motor de base de datos en AWS cumpliría mejor con estos requisitos?",
        "Options": {
            "1": "Amazon DynamoDB",
            "2": "Amazon Aurora con compatibilidad con PostgreSQL",
            "3": "Amazon RDS para MySQL",
            "4": "Amazon DocumentDB"
        },
        "Correct Answer": "Amazon Aurora con compatibilidad con PostgreSQL",
        "Explanation": "Amazon Aurora con compatibilidad con PostgreSQL es la mejor opción para migrar desde una base de datos PostgreSQL en las instalaciones porque está diseñada para ser compatible con PostgreSQL, lo que significa que requiere cambios mínimos en el código durante la migración. Aurora también ofrece alta disponibilidad a través de sus implementaciones multi-AZ y capacidades de escalado de lectura con réplicas de lectura, lo que la hace adecuada para plataformas de comercio electrónico que requieren un rendimiento y escalabilidad fiables.",
        "Other Options": [
            "Amazon DynamoDB es un servicio de base de datos NoSQL que no soporta consultas SQL ni las características de PostgreSQL de las que probablemente dependa la aplicación existente. Migrar a DynamoDB requeriría cambios significativos en el código y una re-arquitectura completa de la aplicación.",
            "Amazon RDS para MySQL es un servicio de base de datos relacional gestionado, pero se basa en MySQL, no en PostgreSQL. Migrar a RDS para MySQL requeriría cambios sustanciales en el código para adaptar la aplicación a la sintaxis y características de MySQL, lo cual no es ideal para minimizar los cambios en el código.",
            "Amazon DocumentDB es un servicio de base de datos de documentos gestionado que es compatible con MongoDB. Al igual que DynamoDB, no es compatible con PostgreSQL y requeriría una revisión completa del modelo de datos y del código de la aplicación, lo que lo hace inadecuado para este escenario de migración."
        ]
    },
    {
        "Question Number": "11",
        "Situation": "Una empresa está planeando usar Amazon Aurora para una solución de base de datos altamente disponible. Quieren asegurarse de tener un rendimiento de lectura rápido y una disponibilidad mejorada sin tener que gestionar la provisión de almacenamiento.",
        "Question": "¿Qué características de Amazon Aurora la hacen adecuada para este requisito, y cómo difiere su arquitectura de la RDS estándar? (Elige dos.)",
        "Options": {
            "1": "Aurora utiliza un volumen de clúster compartido a través de múltiples Zonas de Disponibilidad (AZ) con almacenamiento basado en SSD, lo que permite un alto IOPS y baja latencia. Incluye un punto final de clúster para operaciones de escritura y puntos finales de lectura para distribuir el tráfico de lectura entre réplicas, lo que mejora el rendimiento de lectura.",
            "2": "Aurora requiere almacenamiento local en cada instancia, por lo que el almacenamiento debe ser provisionado y gestionado por separado, lo que permite un mejor control sobre la distribución de datos.",
            "3": "Aurora escala automáticamente de forma vertical dentro de una sola AZ, sin necesidad de múltiples instancias o réplicas, asegurando alta disponibilidad con una configuración mínima.",
            "4": "Aurora se basa en la gestión manual del almacenamiento, donde la instancia principal debe manejar tanto el tráfico de lectura como el de escritura, lo que la hace adecuada solo para bases de datos más pequeñas con bajos requisitos de I/O.",
            "5": "La arquitectura de Aurora separa el cómputo y el almacenamiento, permitiendo el escalado independiente de cada uno, y proporciona tolerancia a fallos incorporada al replicar datos a través de múltiples AZ."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Aurora utiliza un volumen de clúster compartido a través de múltiples Zonas de Disponibilidad (AZ) con almacenamiento basado en SSD, lo que permite un alto IOPS y baja latencia. Incluye un punto final de clúster para operaciones de escritura y puntos finales de lectura para distribuir el tráfico de lectura entre réplicas, lo que mejora el rendimiento de lectura.",
            "La arquitectura de Aurora separa el cómputo y el almacenamiento, permitiendo el escalado independiente de cada uno, y proporciona tolerancia a fallos incorporada al replicar datos a través de múltiples AZ."
        ],
        "Explanation": "Amazon Aurora está diseñada para alta disponibilidad y durabilidad. Utiliza un volumen de clúster compartido que abarca múltiples Zonas de Disponibilidad, con cada AZ teniendo una copia de la base de datos. Esta arquitectura permite un alto IOPS y baja latencia, lo que mejora el rendimiento de lectura. Aurora también separa el cómputo y el almacenamiento, lo que permite que cada uno escale de forma independiente. Esta separación también proporciona tolerancia a fallos incorporada al replicar datos a través de múltiples AZ.",
        "Other Options": [
            "Aurora no requiere almacenamiento local en cada instancia. En su lugar, utiliza un volumen de almacenamiento compartido que abarca múltiples AZ. Por lo tanto, el almacenamiento no necesita ser provisionado y gestionado por separado.",
            "Aurora no escala automáticamente de forma vertical dentro de una sola AZ. En su lugar, utiliza una arquitectura distribuida que abarca múltiples AZ. Esta arquitectura permite alta disponibilidad y tolerancia a fallos.",
            "Aurora no se basa en la gestión manual del almacenamiento. En su lugar, gestiona automáticamente el almacenamiento, escalándolo hacia arriba y hacia abajo según sea necesario. La instancia principal no tiene que manejar tanto el tráfico de lectura como el de escritura, ya que Aurora proporciona un punto final de clúster para operaciones de escritura y puntos finales de lectura para operaciones de lectura."
        ]
    },
    {
        "Question Number": "12",
        "Situation": "Una aplicación de redes sociales almacena publicaciones de usuarios y necesita optimizar su base de datos tanto para operaciones de lectura de alto volumen como para actualizaciones de escritura frecuentes. La aplicación también requiere análisis en tiempo real sobre el compromiso de los usuarios.",
        "Question": "¿Qué solución de base de datos debería recomendar el arquitecto de soluciones para manejar eficientemente los patrones de acceso mixtos?",
        "Options": {
            "1": "Amazon RDS para PostgreSQL con Réplicas de Lectura y Amazon Redshift para análisis.",
            "2": "Amazon DynamoDB con capacidad provisionada y DynamoDB Streams integrado con AWS Lambda para procesamiento en tiempo real.",
            "3": "Amazon Aurora Serverless con configuración multi-master para manejar operaciones de lectura y escritura.",
            "4": "Amazon S3 con Amazon Athena para consultas y Amazon Kinesis para análisis en tiempo real."
        },
        "Correct Answer": "Amazon DynamoDB con capacidad provisionada y DynamoDB Streams integrado con AWS Lambda para procesamiento en tiempo real.",
        "Explanation": "Amazon DynamoDB es un servicio de base de datos NoSQL totalmente gestionado que proporciona un alto rendimiento tanto para operaciones de lectura como de escritura, lo que lo hace ideal para aplicaciones con patrones de acceso mixtos. Su capacidad provisionada permite escalar según las necesidades de la aplicación, asegurando que pueda manejar operaciones de lectura de alto volumen de manera eficiente. Además, DynamoDB Streams se puede utilizar para capturar cambios en los elementos de la base de datos, lo que puede activar funciones de AWS Lambda para procesamiento y análisis en tiempo real sobre el compromiso de los usuarios. Esta combinación permite tanto un almacenamiento de datos eficiente como análisis en tiempo real, cumpliendo efectivamente con los requisitos de la aplicación.",
        "Other Options": [
            "Amazon RDS para PostgreSQL con Réplicas de Lectura y Amazon Redshift para análisis no es la mejor opción porque, aunque RDS puede manejar operaciones de lectura con réplicas de lectura, puede no escalar tan eficientemente para operaciones de escritura de alto volumen en comparación con DynamoDB. Además, usar Redshift para análisis introduce latencia, ya que está optimizado para procesamiento por lotes en lugar de análisis en tiempo real.",
            "Amazon Aurora Serverless con configuración multi-master podría manejar operaciones de lectura y escritura, pero puede no proporcionar el mismo nivel de escalabilidad y rendimiento para patrones de acceso de alto volumen como DynamoDB. Aurora también está más orientada a datos relacionales y puede no ser tan eficiente para análisis en tiempo real en comparación con la integración de DynamoDB con Lambda.",
            "Amazon S3 con Amazon Athena para consultas y Amazon Kinesis para análisis en tiempo real no es adecuado porque S3 es principalmente un servicio de almacenamiento y no soporta operaciones de escritura de alta frecuencia de manera eficiente. Aunque Kinesis puede manejar flujos de datos en tiempo real, la combinación no proporciona una solución robusta para patrones de acceso mixtos como lo hace DynamoDB."
        ]
    },
    {
        "Question Number": "13",
        "Situation": "Una gran corporación con múltiples departamentos utiliza cuentas de AWS separadas para cada unidad de negocio y desea monitorear y controlar los costos relacionados con la red. Necesitan una forma de identificar y asignar los gastos de red, como los costos de VPC, NAT gateway y transferencia de datos, a los departamentos apropiados para garantizar una distribución de costos precisa y responsabilidad en toda la organización.",
        "Question": "¿Qué función de gestión de costos de AWS les ayudaría mejor a lograr esto?",
        "Options": {
            "1": "Habilitar etiquetas de asignación de costos para recursos de red, asignando etiquetas por departamento para asignar con precisión los costos relacionados con la red",
            "2": "Configurar Nubes Privadas Virtuales (VPC) separadas para cada departamento y monitorear los costos de cada VPC individualmente",
            "3": "Utilizar AWS Trusted Advisor para monitorear y optimizar regularmente el uso de la red y obtener recomendaciones para el ahorro de costos",
            "4": "Establecer diferentes Zonas de Disponibilidad para cada departamento para hacer un seguimiento de los costos de transferencia de datos por zona"
        },
        "Correct Answer": "Habilitar etiquetas de asignación de costos para recursos de red, asignando etiquetas por departamento para asignar con precisión los costos relacionados con la red",
        "Explanation": "Habilitar etiquetas de asignación de costos para recursos de red permite a la corporación categorizar y rastrear los costos asociados con departamentos específicos. Al asignar etiquetas a recursos como VPCs, NAT gateways y transferencia de datos, la organización puede generar informes de costos detallados que reflejan los gastos incurridos por cada departamento. Este método proporciona una forma clara y organizada de asignar costos relacionados con la red, asegurando responsabilidad y transparencia en todas las unidades de negocio.",
        "Other Options": [
            "Configurar Nubes Privadas Virtuales (VPC) separadas para cada departamento puede ayudar a aislar recursos, pero no proporciona inherentemente un mecanismo para rastrear y asignar costos. Sin etiquetado o una estrategia de gestión de costos, sería difícil distribuir con precisión los costos entre departamentos.",
            "Utilizar AWS Trusted Advisor puede proporcionar información y recomendaciones para optimizar el uso de recursos y el ahorro de costos, pero no asigna directamente costos a departamentos específicos. Se centra más en las mejores prácticas y la optimización de costos que en el seguimiento y la asignación detallada de costos.",
            "Establecer diferentes Zonas de Disponibilidad para cada departamento no se correlaciona directamente con el seguimiento de los costos de transferencia de datos. Las Zonas de Disponibilidad se centran principalmente en la redundancia y la disponibilidad en lugar de la asignación de costos. Los costos de transferencia de datos generalmente se incurren en función de los recursos utilizados y sus configuraciones, no de las zonas en sí."
        ]
    },
    {
        "Question Number": "14",
        "Situation": "Una startup está desarrollando un panel en tiempo real que muestra métricas en vivo de varios dispositivos IoT. El panel requiere una rápida ingesta de datos y acceso de baja latencia a las métricas más recientes para asegurar actualizaciones oportunas. La solución también debe manejar volúmenes de datos variables a medida que aumenta el número de dispositivos.",
        "Question": "¿Qué servicio de AWS debería utilizar el arquitecto de soluciones para cumplir con estos requisitos de tamaño y velocidad? (Elija dos.)",
        "Options": {
            "1": "Amazon S3 con Amazon Athena",
            "2": "Amazon Kinesis Data Streams",
            "3": "AWS Batch con Amazon EC2 Spot Instances",
            "4": "Amazon RDS con réplicas de lectura",
            "5": "Amazon DynamoDB con DynamoDB Streams"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon Kinesis Data Streams",
            "Amazon DynamoDB con DynamoDB Streams"
        ],
        "Explanation": "Amazon Kinesis Data Streams está diseñado para la transmisión de datos en tiempo real. Puede capturar continuamente gigabytes de datos por segundo de cientos de miles de fuentes, lo que lo convierte en una buena opción para manejar la rápida ingesta de datos y el acceso de baja latencia requeridos por el panel. Amazon DynamoDB con DynamoDB Streams también es una buena opción, ya que proporciona acceso de baja latencia a los datos y puede manejar altas cargas de tráfico, lo cual es útil cuando aumenta el número de dispositivos. DynamoDB Streams captura una secuencia ordenada en el tiempo de modificaciones a nivel de ítem en cualquier tabla de DynamoDB y almacena estos datos durante 24 horas.",
        "Other Options": [
            "Amazon S3 con Amazon Athena: Esta combinación es más adecuada para almacenar y consultar grandes conjuntos de datos, no para la ingesta de datos en tiempo real y el acceso de baja latencia.",
            "AWS Batch con Amazon EC2 Spot Instances: Esto es más adecuado para trabajos de procesamiento por lotes y no para la ingesta de datos en tiempo real y el acceso de baja latencia.",
            "Amazon RDS con réplicas de lectura: Aunque esto puede ayudar a distribuir el tráfico de lectura, no está diseñado para la ingesta de datos en tiempo real o para manejar volúmenes de datos variables de potencialmente miles de dispositivos."
        ]
    },
    {
        "Question Number": "15",
        "Situation": "Una aplicación de redes sociales tiene un alto volumen de solicitudes de lectura, con usuarios que frecuentemente recuperan información de perfil y feeds de noticias. La aplicación está enfrentando problemas de latencia ya que consulta directamente una base de datos de Amazon Aurora para cada solicitud de lectura. El equipo de desarrollo quiere mejorar el rendimiento de lectura y reducir la carga de la base de datos de manera rentable, y están abiertos a realizar pequeños cambios en la aplicación.",
        "Question": "¿Qué solución debería recomendar el arquitecto de soluciones?",
        "Options": {
            "1": "Implementar Amazon ElastiCache con Redis para almacenar en caché los datos de acceso frecuente y reducir las consultas a la base de datos",
            "2": "Habilitar réplicas de lectura en la base de datos de Amazon Aurora para distribuir la carga de lectura",
            "3": "Utilizar Amazon RDS Proxy para agrupar y compartir conexiones de base de datos para mejorar el rendimiento",
            "4": "Almacenar datos de acceso frecuente en Amazon S3 y acceder a ellos directamente desde la aplicación"
        },
        "Correct Answer": "Implementar Amazon ElastiCache con Redis para almacenar en caché los datos de acceso frecuente y reducir las consultas a la base de datos",
        "Explanation": "Implementar Amazon ElastiCache con Redis es la solución más efectiva para mejorar el rendimiento de lectura y reducir la carga en la base de datos de Amazon Aurora. Al almacenar en caché los datos de acceso frecuente, como perfiles de usuario y feeds de noticias, la aplicación puede atender las solicitudes de lectura directamente desde la caché en lugar de consultar la base de datos para cada solicitud. Esto reduce significativamente la latencia y la carga de la base de datos, lo que lleva a ahorros de costos y mejora la experiencia del usuario. ElastiCache está diseñado para la recuperación de datos a alta velocidad, lo que lo hace ideal para aplicaciones con altos volúmenes de solicitudes de lectura.",
        "Other Options": [
            "Habilitar réplicas de lectura en la base de datos de Amazon Aurora puede ayudar a distribuir la carga de lectura, pero no aborda los problemas de latencia tan eficazmente como el almacenamiento en caché. Las réplicas de lectura aún pueden incurrir en costos y pueden no proporcionar las mejoras de rendimiento inmediatas necesarias para solicitudes de lectura de alto volumen.",
            "Utilizar Amazon RDS Proxy para agrupar y compartir conexiones de base de datos puede mejorar el rendimiento al reducir la sobrecarga de establecer conexiones, pero no reduce directamente el número de consultas de lectura enviadas a la base de datos. Esta opción puede ayudar con la gestión de conexiones, pero no resuelve el problema subyacente de latencia causado por altos volúmenes de solicitudes de lectura.",
            "Almacenar datos de acceso frecuente en Amazon S3 y acceder a ellos directamente desde la aplicación no es ideal para la recuperación de datos en tiempo real, ya que S3 está diseñado para almacenamiento de objetos y puede introducir latencia adicional. Este enfoque es más adecuado para contenido estático que para datos dinámicos que requieren actualizaciones frecuentes, lo que lo hace menos efectivo para las necesidades de la aplicación."
        ]
    },
    {
        "Question Number": "16",
        "Situation": "Una empresa financiera requiere una solución de almacenamiento de archivos completamente gestionada en AWS que pueda soportar altas IOPS, baja latencia y características nativas del sistema de archivos de Windows para almacenar y procesar datos sensibles de clientes. El sistema debe proporcionar acceso seguro a través de SMB e integrarse con el Active Directory local de la empresa para la autenticación de usuarios.",
        "Question": "¿Qué configuración de servicio de AWS cumpliría mejor con estos requisitos? (Elija dos.)",
        "Options": {
            "1": "Amazon S3 con Transfer Acceleration para acceso de alta velocidad",
            "2": "Amazon FSx for Windows File Server en un despliegue Multi-AZ",
            "3": "Amazon EFS con cifrado en reposo y en tránsito",
            "4": "AWS Storage Gateway con Volúmenes en Caché",
            "5": "Amazon FSx for NetApp ONTAP con integración de Active Directory"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon FSx for Windows File Server en un despliegue Multi-AZ",
            "AWS Storage Gateway con Volúmenes en Caché"
        ],
        "Explanation": "Amazon FSx for Windows File Server en un despliegue Multi-AZ es un sistema de archivos nativo de Microsoft Windows completamente gestionado que puede soportar altas IOPS, baja latencia y características nativas del sistema de archivos de Windows. También proporciona acceso seguro a través de SMB e integra con Active Directory local para la autenticación de usuarios, lo que cumple con todos los requisitos establecidos. AWS Storage Gateway con Volúmenes en Caché se puede utilizar para proporcionar acceso de baja latencia a los datos en AWS desde aplicaciones locales, almacenando datos de acceso frecuente localmente mientras se retiene toda la información en Amazon S3. También admite la integración con Active Directory local para la autenticación de usuarios.",
        "Other Options": [
            "Amazon S3 con Transfer Acceleration para acceso de alta velocidad no admite características nativas del sistema de archivos de Windows ni el protocolo SMB. Tampoco se integra con Active Directory local para la autenticación de usuarios.",
            "Amazon EFS con cifrado en reposo y en tránsito es un sistema de archivos completamente gestionado que no está diseñado para altas IOPS, baja latencia y no admite características nativas del sistema de archivos de Windows ni el protocolo SMB.",
            "Amazon FSx for NetApp ONTAP con integración de Active Directory es un servicio de sistema de archivos completamente gestionado que admite el protocolo SMB e integra con Active Directory local, pero no admite características nativas del sistema de archivos de Windows."
        ]
    },
    {
        "Question Number": "17",
        "Situation": "Una empresa está ejecutando una aplicación web en instancias de EC2 detrás de un Application Load Balancer (ALB). La aplicación necesita enrutar el tráfico en función de las rutas de URL, con servicios específicos manejando ciertos tipos de solicitudes. También quieren asegurarse de que el tráfico se distribuya de manera uniforme entre las instancias para evitar que una sola instancia se sobrecargue durante períodos de alto tráfico.",
        "Question": "¿Qué configuración debería aplicar la empresa para lograr un balanceo de carga eficiente?",
        "Options": {
            "1": "Configurar el ALB con enrutamiento basado en rutas para dirigir el tráfico a diferentes grupos de destino según las rutas de URL, asegurando que el tráfico esté equilibrado de manera uniforme entre las instancias de EC2 en cada grupo.",
            "2": "Configurar el ALB para enrutar todo el tráfico a una sola instancia de EC2 por simplicidad, pero usar Auto Scaling para aumentar el tamaño de la instancia durante los picos de tráfico.",
            "3": "Usar un Classic Load Balancer (CLB) en lugar de ALB para soportar el enrutamiento basado en rutas y distribuir el tráfico en función de múltiples puntos finales de la aplicación.",
            "4": "Configurar múltiples ALBs, cada uno sirviendo tráfico para un dominio de aplicación diferente, y dirigir el tráfico manualmente a cada ALB según los patrones de tráfico."
        },
        "Correct Answer": "Configurar el ALB con enrutamiento basado en rutas para dirigir el tráfico a diferentes grupos de destino según las rutas de URL, asegurando que el tráfico esté equilibrado de manera uniforme entre las instancias de EC2 en cada grupo.",
        "Explanation": "Configurar el ALB con enrutamiento basado en rutas permite a la empresa dirigir el tráfico a diferentes grupos de destino según las rutas de URL de las solicitudes entrantes. Esto significa que servicios específicos pueden manejar tipos específicos de solicitudes, lo cual es esencial para la arquitectura de la aplicación. Además, el ALB equilibra automáticamente el tráfico entre las instancias de EC2 en cada grupo de destino, asegurando que ninguna instancia se sobrecargue durante períodos de alto tráfico. Esta configuración es óptima para gestionar el tráfico de manera eficiente y mantener el rendimiento de la aplicación.",
        "Other Options": [
            "Configurar el ALB para enrutar todo el tráfico a una sola instancia de EC2 no es una solución viable para el balanceo de carga, ya que contradice el propósito de usar un balanceador de carga. Esto llevaría a una posible sobrecarga en esa única instancia, especialmente durante los picos de tráfico, y no aprovecharía los beneficios de tener múltiples instancias.",
            "Usar un Classic Load Balancer (CLB) en lugar de ALB es incorrecto porque los CLBs no soportan el enrutamiento basado en rutas. Los ALBs están diseñados específicamente para características avanzadas de enrutamiento, incluido el enrutamiento basado en rutas, que es necesario para el requisito de la empresa de dirigir el tráfico según las rutas de URL.",
            "Configurar múltiples ALBs para diferentes dominios de aplicación y dirigir manualmente el tráfico a cada ALB añade complejidad innecesaria a la arquitectura. Sería más eficiente usar un solo ALB con enrutamiento basado en rutas para gestionar el tráfico de múltiples servicios, lo que simplifica la configuración y reduce la carga operativa."
        ]
    },
    {
        "Question Number": "18",
        "Situation": "Una organización utiliza AWS Organizations y quiere implementar un límite de permisos en múltiples cuentas para prevenir ciertas acciones, incluso para usuarios con acceso administrativo completo. La organización también quiere mantener baja la carga administrativa.",
        "Question": "¿Qué tipo de arquitectura de Política de Control de Servicio (SCP) cumpliría mejor con estos requisitos, y qué efecto tendrá sobre los permisos de los usuarios de IAM dentro de la organización?",
        "Options": {
            "1": "Usar una arquitectura de Lista de Permisos para permitir explícitamente solo servicios específicos, limitando todas las demás acciones para una mejor seguridad y más control.",
            "2": "Usar una arquitectura de Lista de Denegaciones para denegar acciones específicas, permitiendo todas las demás acciones por defecto, lo que minimiza la carga de gestión.",
            "3": "Usar una arquitectura de Lista de Denegaciones para denegar explícitamente todas las acciones, requiriendo la adición manual de permisos para cada servicio necesario.",
            "4": "Usar una arquitectura de Lista de Permisos para permitir acciones solo para el usuario root, bloqueando permisos para todos los usuarios de IAM dentro de la organización."
        },
        "Correct Answer": "Usar una arquitectura de Lista de Denegaciones para denegar acciones específicas, permitiendo todas las demás acciones por defecto, lo que minimiza la carga de gestión.",
        "Explanation": "Una arquitectura de Lista de Denegaciones es efectiva en este escenario porque permite a la organización especificar solo las acciones que deben ser denegadas, mientras que todas las demás acciones permanecen permitidas por defecto. Este enfoque minimiza la carga administrativa ya que la organización no necesita gestionar una extensa lista de acciones permitidas. En su lugar, pueden centrarse en identificar y denegar solo las acciones específicas que representan un riesgo, manteniendo así la flexibilidad para que los usuarios de IAM realicen sus tareas sin restricciones innecesarias.",
        "Other Options": [
            "Usar una arquitectura de Lista de Permisos requeriría que la organización definiera y permitiera explícitamente solo servicios específicos, lo que puede llevar a una mayor carga administrativa, ya que tendrían que actualizar continuamente la lista de servicios permitidos cada vez que se introducen nuevos servicios o cuando se necesitan modificar servicios existentes.",
            "Una arquitectura de Lista de Denegaciones que deniega explícitamente todas las acciones sería excesivamente restrictiva e impráctica, ya que requeriría que la organización añadiera manualmente permisos para cada servicio necesario. Esto crearía una carga significativa de gestión y podría obstaculizar la productividad, ya que los usuarios estarían bloqueados de realizar acciones necesarias a menos que se les permitiera explícitamente.",
            "Usar una arquitectura de Lista de Permisos para permitir acciones solo para el usuario root bloquearía efectivamente los permisos para todos los usuarios de IAM dentro de la organización, lo que contradice el requisito de permitir que los usuarios con acceso administrativo realicen sus funciones. Esto no cumpliría con el objetivo de la organización de implementar un límite de permisos mientras se habilitan acciones necesarias para los usuarios de IAM."
        ]
    },
    {
        "Question Number": "19",
        "Situation": "Una empresa está utilizando AWS Key Management Service (KMS) para asegurar datos sensibles. La empresa quiere asegurarse de que las claves utilizadas para cifrar estos datos se gestionen y almacenen de forma segura dentro de AWS, sin salir nunca del entorno de AWS.",
        "Question": "¿Qué característica de AWS KMS garantiza que las claves de cifrado permanezcan seguras y dentro de la infraestructura de AWS, y qué tipo de cifrado admite?",
        "Options": {
            "1": "Las claves de KMS están aisladas dentro de una región KMS dedicada y solo admiten cifrado simétrico.",
            "2": "Las claves de KMS nunca salen de AWS KMS y admiten tanto cifrado simétrico como asimétrico.",
            "3": "Las claves de KMS se pueden exportar de AWS para uso externo y solo admiten cifrado asimétrico.",
            "4": "Las claves de KMS se comparten entre múltiples cuentas de AWS y solo admiten cifrado simétrico."
        },
        "Correct Answer": "Las claves de KMS nunca salen de AWS KMS y admiten tanto cifrado simétrico como asimétrico.",
        "Explanation": "AWS Key Management Service (KMS) está diseñado para gestionar claves de cifrado de forma segura dentro del entorno de AWS. Una de sus características clave es que las claves de cifrado nunca se exponen fuera de la infraestructura de AWS, asegurando que permanezcan seguras. Además, AWS KMS admite tanto cifrado simétrico (donde se utiliza la misma clave para cifrado y descifrado) como cifrado asimétrico (donde se utiliza un par de claves). Esta flexibilidad permite a los usuarios elegir el método de cifrado apropiado según sus requisitos de seguridad.",
        "Other Options": [
            "Las claves de KMS están aisladas dentro de una región KMS dedicada y solo admiten cifrado simétrico. Esta opción es incorrecta porque, aunque las claves de KMS son específicas de la región, admiten tanto cifrado simétrico como asimétrico, no solo simétrico.",
            "Las claves de KMS se pueden exportar de AWS para uso externo y solo admiten cifrado asimétrico. Esta opción es incorrecta porque las claves de KMS no se pueden exportar para uso externo; están diseñadas para permanecer dentro de AWS. Además, KMS admite tanto cifrado simétrico como asimétrico, no solo asimétrico.",
            "Las claves de KMS se comparten entre múltiples cuentas de AWS y solo admiten cifrado simétrico. Esta opción es incorrecta porque, aunque las claves de KMS se pueden compartir entre cuentas a través de políticas de recursos, admiten tanto cifrado simétrico como asimétrico, no solo simétrico."
        ]
    },
    {
        "Question Number": "20",
        "Situation": "Una empresa ha desplegado un Application Load Balancer (ALB) en múltiples Zonas de Disponibilidad (AZ) y ha habilitado el balanceo de carga entre zonas para distribuir el tráfico entrante.",
        "Question": "¿Cómo mejora el balanceo de carga entre zonas la distribución de la carga, y qué beneficio ofrece para manejar picos de tráfico en una AZ?",
        "Options": {
            "1": "El balanceo de carga entre zonas permite que cada nodo del balanceador de carga dirija el tráfico solo a los objetivos dentro de su propia AZ, proporcionando aislamiento y resiliencia en caso de fallo de la AZ.",
            "2": "El balanceo de carga entre zonas permite que cada nodo del balanceador de carga dirija el tráfico de manera uniforme entre los objetivos en todas las AZ, asegurando una distribución de carga más equilibrada y reduciendo el riesgo de sobrecargar objetivos en una AZ.",
            "3": "El balanceo de carga entre zonas dirige el tráfico a solo un objetivo por solicitud, reduciendo la latencia y mejorando el rendimiento para los usuarios en cada AZ.",
            "4": "El balanceo de carga entre zonas solo es efectivo en configuraciones de una sola AZ y no tiene impacto cuando se involucran múltiples AZ."
        },
        "Correct Answer": "El balanceo de carga entre zonas permite que cada nodo del balanceador de carga dirija el tráfico de manera uniforme entre los objetivos en todas las AZ, asegurando una distribución de carga más equilibrada y reduciendo el riesgo de sobrecargar objetivos en una AZ.",
        "Explanation": "El balanceo de carga entre zonas permite que el Application Load Balancer distribuya el tráfico entrante de manera uniforme entre todos los objetivos registrados en diferentes Zonas de Disponibilidad, en lugar de solo entre los objetivos en la misma AZ que el nodo del balanceador de carga. Esto significa que si una AZ experimenta un pico de tráfico, el balanceador de carga puede dirigir el tráfico a objetivos en otras AZ, evitando que una sola AZ se convierta en un cuello de botella. Esta capacidad mejora la resiliencia y el rendimiento general de la aplicación, especialmente durante picos de tráfico.",
        "Other Options": [
            "El balanceo de carga entre zonas permite que cada nodo del balanceador de carga dirija el tráfico solo a los objetivos dentro de su propia AZ, proporcionando aislamiento y resiliencia en caso de fallo de la AZ. Esto es incorrecto porque el balanceo de carga entre zonas permite específicamente que el tráfico se dirija a través de múltiples AZ, lo cual es lo opuesto a dirigir solo dentro de una sola AZ.",
            "Esta opción es incorrecta porque tergiversa la funcionalidad del balanceo de carga entre zonas. Si bien busca equilibrar la carga, lo hace distribuyendo el tráfico entre todas las AZ, no solo asegurando una distribución uniforme entre los objetivos en una sola AZ.",
            "Esta opción es incorrecta porque el balanceo de carga entre zonas no limita el tráfico a solo un objetivo por solicitud. En cambio, distribuye el tráfico entre múltiples objetivos, lo que ayuda a gestionar la carga de manera efectiva y mejorar el rendimiento."
        ]
    },
    {
        "Question Number": "21",
        "Situation": "Una plataforma de redes sociales quiere monitorear y analizar contenido generado por los usuarios en tiempo real para detectar y responder rápidamente a publicaciones inapropiadas. La plataforma necesita una solución escalable para procesar flujos continuos de datos de millones de usuarios simultáneamente.",
        "Question": "¿Qué servicios de AWS debería recomendar el arquitecto de soluciones para el procesamiento de datos en streaming en este escenario? (Elija dos.)",
        "Options": {
            "1": "Amazon Simple Queue Service (SQS)",
            "2": "Amazon Kinesis Data Streams",
            "3": "Amazon Managed Streaming for Apache Kafka (MSK)",
            "4": "AWS Lambda con disparadores programados",
            "5": "Amazon EventBridge"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon Kinesis Data Streams",
            "Amazon Managed Streaming for Apache Kafka (MSK)"
        ],
        "Explanation": "Amazon Kinesis Data Streams está diseñado para recopilar, procesar y analizar datos en streaming en tiempo real para que puedas obtener información oportuna y reaccionar rápidamente a nueva información. Puede manejar cualquier cantidad de datos en streaming y procesar datos de cientos de miles de fuentes con latencias muy bajas. Amazon Managed Streaming for Apache Kafka (MSK) es un servicio completamente gestionado que facilita la construcción y ejecución de aplicaciones que utilizan Apache Kafka para procesar datos en streaming. Es altamente adecuado para tareas de procesamiento de datos en tiempo real de alto volumen.",
        "Other Options": [
            "Amazon Simple Queue Service (SQS) es un servicio de colas de mensajes completamente gestionado que te permite desacoplar y escalar microservicios, sistemas distribuidos y aplicaciones sin servidor. Sin embargo, no está diseñado para el procesamiento de datos en streaming en tiempo real.",
            "AWS Lambda con disparadores programados es un servicio de computación que te permite ejecutar código sin aprovisionar o gestionar servidores. Si bien Lambda puede procesar cambios de archivos en tiempo real, la opción de 'disparadores programados' no se ajusta al requisito de tiempo real del escenario.",
            "Amazon EventBridge es un bus de eventos sin servidor que facilita la conexión de aplicaciones utilizando datos de tus propias aplicaciones, aplicaciones de Software como Servicio (SaaS) integradas y servicios de AWS. No está diseñado específicamente para el procesamiento de datos en streaming en tiempo real."
        ]
    },
    {
        "Question Number": "22",
        "Situation": "Una empresa necesita cifrar archivos grandes que superan los 4 KB de tamaño utilizando AWS Key Management Service (KMS). El proceso de cifrado debe involucrar tanto una versión en texto plano para uso inmediato como una versión segura para almacenar junto a los datos cifrados.",
        "Question": "¿Qué característica de KMS debería utilizar la empresa para cumplir con estos requisitos y cómo maneja el cifrado de datos mayores de 4 KB?",
        "Options": {
            "1": "Utilizar la clave de KMS directamente para cifrar los datos, ya que KMS admite archivos de cualquier tamaño sin pasos adicionales.",
            "2": "Generar una Clave de Cifrado de Datos (DEK) con KMS, usar la DEK en texto plano para cifrar los datos y almacenar la DEK en texto cifrado junto a los datos cifrados.",
            "3": "Utilizar una clave de KMS gestionada por el cliente con una política personalizada para permitir el cifrado de archivos grandes y mantener copias tanto en texto plano como en texto cifrado.",
            "4": "Cifrar los datos directamente en KMS dividiéndolos en fragmentos de 4 KB, cifrando cada fragmento por separado y reensamblando después de la descifrado."
        },
        "Correct Answer": "Generar una Clave de Cifrado de Datos (DEK) con KMS, usar la DEK en texto plano para cifrar los datos y almacenar la DEK en texto cifrado junto a los datos cifrados.",
        "Explanation": "AWS Key Management Service (KMS) tiene un límite de 4 KB para operaciones de cifrado directo. Para cifrar archivos más grandes, el enfoque recomendado es generar una Clave de Cifrado de Datos (DEK) utilizando KMS. La DEK se utiliza para cifrar los datos, lo que permite el cifrado de archivos mayores de 4 KB. La DEK en texto plano se puede utilizar para la descifrado inmediata, mientras que la DEK en texto cifrado (cifrada con la clave de KMS) se almacena junto a los datos cifrados para un acceso seguro. Este método asegura que el proceso de cifrado sea eficiente y escalable para archivos grandes.",
        "Other Options": [
            "Utilizar la clave de KMS directamente para cifrar los datos es incorrecto porque KMS tiene un límite de tamaño de 4 KB para operaciones de cifrado. Los archivos más grandes deben manejarse de manera diferente, como utilizando una DEK.",
            "Si bien generar una DEK es correcto, la opción no especifica que la DEK debe almacenarse como texto cifrado junto a los datos cifrados. Esto es crucial para mantener la seguridad y permitir la descifrado más tarde.",
            "Utilizar una clave de KMS gestionada por el cliente con una política personalizada no aborda directamente la limitación de tamaño del cifrado de KMS. El método de cifrado de archivos grandes aún requiere el uso de una DEK, independientemente de la política de gestión de claves."
        ]
    },
    {
        "Question Number": "23",
        "Situation": "Una empresa necesita asegurarse de que su entorno de AWS cumpla con las mejores prácticas de seguridad y estándares de cumplimiento. La empresa desea un monitoreo continuo de sus recursos de AWS para detectar posibles vulnerabilidades de seguridad y garantizar el cumplimiento.",
        "Question": "¿Qué servicios de AWS debería recomendar el arquitecto de soluciones? (Elija dos.)",
        "Options": {
            "1": "AWS Config",
            "2": "Amazon GuardDuty",
            "3": "AWS Security Hub",
            "4": "AWS CloudTrail",
            "5": "AWS Shield Advanced"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "AWS Security Hub",
            "Amazon GuardDuty"
        ],
        "Explanation": "AWS Security Hub proporciona una vista integral de sus alertas de seguridad de alta prioridad y el estado de cumplimiento en las cuentas de AWS. Agrega, organiza y prioriza sus alertas de seguridad, o hallazgos, de múltiples servicios de AWS, como Amazon GuardDuty, Amazon Inspector y Amazon Macie, así como de soluciones de socios de AWS. Amazon GuardDuty es un servicio de detección de amenazas que monitorea continuamente la actividad maliciosa y el comportamiento no autorizado para proteger sus cuentas y cargas de trabajo de AWS. Analiza miles de millones de eventos de múltiples fuentes de datos de AWS, como los registros de eventos de AWS CloudTrail, los registros de flujo de Amazon VPC y los registros DNS.",
        "Other Options": [
            "AWS Config es un servicio que le permite evaluar, auditar y evaluar las configuraciones de sus recursos de AWS. No proporciona monitoreo continuo para posibles vulnerabilidades de seguridad.",
            "AWS CloudTrail es un servicio que permite la gobernanza, el cumplimiento, la auditoría operativa y la auditoría de riesgos de su cuenta de AWS. Sin embargo, no proporciona monitoreo continuo para posibles vulnerabilidades de seguridad.",
            "AWS Shield Advanced proporciona protección contra DDoS y protección de costos, pero no proporciona monitoreo continuo para posibles vulnerabilidades de seguridad."
        ]
    },
    {
        "Question Number": "24",
        "Situation": "Una empresa multinacional de comercio electrónico requiere una solución de base de datos altamente disponible que ofrezca acceso de lectura de baja latencia a clientes en múltiples regiones. Para garantizar la resiliencia y protegerse contra cortes regionales, la empresa también requiere una configuración de recuperación ante desastres entre regiones con un impacto mínimo en el rendimiento de la base de datos principal. Además, necesitan replicación casi en tiempo real a regiones secundarias para las actualizaciones de datos más rápidas posibles.",
        "Question": "¿Qué solución de base de datos de AWS cumpliría mejor con estos requisitos?",
        "Options": {
            "1": "Desplegar Amazon RDS con Multi-AZ para mejorar la alta disponibilidad dentro de una sola región de AWS",
            "2": "Utilizar Aurora Global Database para habilitar réplicas de lectura entre regiones, proporcionando acceso de lectura de baja latencia y replicación casi en tiempo real con un impacto mínimo en la base de datos principal",
            "3": "Configurar Amazon DynamoDB Global Tables para lograr replicación entre regiones y acceso de baja latencia para cargas de trabajo NoSQL",
            "4": "Configurar Amazon Redshift con instantáneas entre regiones para crear una copia de seguridad en cada región para recuperación ante desastres"
        },
        "Correct Answer": "Utilizar Aurora Global Database para habilitar réplicas de lectura entre regiones, proporcionando acceso de lectura de baja latencia y replicación casi en tiempo real con un impacto mínimo en la base de datos principal",
        "Explanation": "Aurora Global Database está diseñado específicamente para aplicaciones con una huella global que requieren lecturas de baja latencia y alta disponibilidad en múltiples regiones. Permite la replicación casi en tiempo real de datos a regiones secundarias, lo que asegura que los clientes en esas regiones puedan acceder a los datos de manera rápida y eficiente. Además, proporciona resiliencia contra cortes regionales, ya que la base de datos puede cambiar a una región secundaria con un impacto mínimo en el rendimiento de la base de datos principal. Esto lo convierte en la mejor opción para los requisitos de la empresa de alta disponibilidad, acceso de baja latencia y recuperación ante desastres entre regiones.",
        "Other Options": [
            "Desplegar Amazon RDS con Multi-AZ mejora la alta disponibilidad dentro de una sola región de AWS, pero no proporciona replicación entre regiones ni capacidades de recuperación ante desastres. Por lo tanto, no cumple con el requisito de resiliencia contra cortes regionales.",
            "Utilizar Aurora Global Database es la elección correcta, por lo que esta opción no es aplicable como alternativa. Es la mejor solución para los requisitos establecidos.",
            "Configurar Amazon DynamoDB Global Tables proporcionaría replicación entre regiones y acceso de baja latencia, pero está principalmente diseñado para cargas de trabajo NoSQL. El escenario no especifica la necesidad de una base de datos NoSQL, y Aurora Global Database es una opción más adecuada para necesidades de bases de datos relacionales con los requisitos especificados."
        ]
    },
    {
        "Question Number": "25",
        "Situation": "Una empresa está ejecutando una aplicación web crítica en AWS y necesita configurar cuotas de servicio para gestionar el uso en un entorno de espera. Quieren asegurarse de que su carga de trabajo pueda escalar según la demanda sin exceder los límites de servicio, y también desean aplicar limitaciones para evitar interrupciones en el servicio.",
        "Question": "¿Qué pasos debería seguir la empresa para gestionar las cuotas de servicio y las limitaciones en el entorno de espera?",
        "Options": {
            "1": "Utilizar AWS Service Quotas para establecer límites para el uso del servicio y configurar AWS Lambda para escalar automáticamente los recursos según estas cuotas, aplicando limitaciones para mantener la estabilidad del servicio.",
            "2": "Configurar grupos de Auto Scaling para escalar instancias de EC2 según la carga de trabajo y ajustar manualmente las cuotas de servicio en la Consola de Gestión de AWS para manejar el tráfico máximo.",
            "3": "Utilizar Amazon API Gateway para establecer límites de limitación en las solicitudes de API y configurar CloudWatch para monitorear el uso en el entorno de espera para asegurar que los límites no se excedan.",
            "4": "Utilizar Amazon SQS para encolar solicitudes excesivas y retrasar el procesamiento para prevenir limitaciones, mientras se configura AWS Lambda para el escalado automático."
        },
        "Correct Answer": "Utilizar Amazon API Gateway para establecer límites de limitación en las solicitudes de API y configurar CloudWatch para monitorear el uso en el entorno de espera para asegurar que los límites no se excedan.",
        "Explanation": "Utilizar Amazon API Gateway para establecer límites de limitación es una forma efectiva de gestionar el número de solicitudes que pueden ser procesadas por la aplicación web, evitando así interrupciones en el servicio debido a una carga excesiva. API Gateway permite definir planes de uso que pueden limitar las solicitudes y establecer cuotas, asegurando que la aplicación se mantenga estable bajo cargas variables. Además, integrar CloudWatch para el monitoreo permite a la empresa rastrear métricas de uso en tiempo real, lo que facilita la gestión proactiva de los límites de servicio y asegura que no se excedan los umbrales definidos.",
        "Other Options": [
            "Utilizar AWS Service Quotas para establecer límites para el uso del servicio y configurar AWS Lambda para el escalado automático no aborda directamente las limitaciones para las solicitudes de API. Si bien ayuda a gestionar los límites de servicio, carece de las capacidades específicas de limitación que proporciona API Gateway, las cuales son cruciales para mantener la estabilidad del servicio bajo carga.",
            "Configurar grupos de Auto Scaling para escalar instancias de EC2 es una buena práctica para manejar aumentos en la carga de trabajo, pero no gestiona inherentemente las cuotas de servicio ni aplica limitaciones. Ajustar manualmente las cuotas de servicio puede llevar a retrasos y potenciales interrupciones en el servicio si no se hace en tiempo real, lo cual no es ideal para un entorno de espera que necesita responder rápidamente a cambios en la demanda.",
            "Utilizar Amazon SQS para encolar solicitudes excesivas es un enfoque válido para gestionar la carga, pero no aplica directamente limitaciones a las solicitudes de API. Si bien SQS puede ayudar a prevenir la sobrecarga de los servicios de backend, no proporciona el mismo nivel de control sobre las tasas de solicitud como lo hace API Gateway, y puede introducir latencia en el procesamiento de solicitudes."
        ]
    },
    {
        "Question Number": "26",
        "Situation": "Una empresa de atención médica, HealthSecure, está sujeta a estrictas regulaciones de cumplimiento que requieren monitoreo continuo y documentación de la configuración de sus recursos en la nube. HealthSecure ha elegido AWS Config para rastrear y auditar cambios en su entorno de AWS para asegurar el cumplimiento de estándares como HIPAA. Necesitan una solución que pueda evaluar recursos contra reglas de cumplimiento específicas y remediar automáticamente los recursos no conformes. Sin embargo, HealthSecure también quiere entender las limitaciones de AWS Config, específicamente si puede prevenir activamente cambios en la configuración o si solo proporciona capacidades de monitoreo y alerta.",
        "Question": "¿Cómo apoya AWS Config la gestión de cumplimiento y el rastreo de configuración de recursos en una cuenta de AWS, y cuáles son algunas limitaciones asociadas a su funcionamiento?",
        "Options": {
            "1": "AWS Config permite a los usuarios rastrear cambios en la configuración de los recursos y previene cambios no autorizados al hacer cumplir el cumplimiento en tiempo real.",
            "2": "AWS Config monitorea y registra cambios en la configuración de los recursos soportados, habilita auditorías para estándares de cumplimiento y puede remediar automáticamente recursos no conformes a través de la integración con AWS Lambda. Sin embargo, no previene activamente que ocurran cambios.",
            "3": "AWS Config solo proporciona instantáneas de configuración en intervalos específicos, lo que limita su efectividad para la gestión de cumplimiento, ya que no se admite el monitoreo en tiempo real.",
            "4": "AWS Config solo funciona en una única región y no puede agregar datos a través de múltiples cuentas, lo que lo hace adecuado solo para entornos aislados donde los recursos permanecen estáticos."
        },
        "Correct Answer": "AWS Config monitorea y registra cambios en la configuración de los recursos soportados, habilita auditorías para estándares de cumplimiento y puede remediar automáticamente recursos no conformes a través de la integración con AWS Lambda. Sin embargo, no previene activamente que ocurran cambios.",
        "Explanation": "AWS Config está diseñado para proporcionar monitoreo continuo de las configuraciones de recursos de AWS y para rastrear cambios a lo largo del tiempo. Permite a los usuarios evaluar sus recursos contra reglas de cumplimiento y puede activar acciones de remediación a través de AWS Lambda cuando se detectan configuraciones no conformes. Sin embargo, es importante señalar que AWS Config no tiene la capacidad de prevenir activamente cambios en la configuración; solo monitorea y alerta sobre los cambios que ocurren, lo que lo convierte en una herramienta poderosa para la gestión de cumplimiento, pero no preventiva.",
        "Other Options": [
            "AWS Config no previene cambios no autorizados en tiempo real; solo monitorea y alerta sobre cambios después de que ocurren.",
            "AWS Config proporciona monitoreo casi en tiempo real y no se limita a instantáneas de configuración en intervalos específicos; registra continuamente cambios en la configuración.",
            "AWS Config puede operar en múltiples regiones y cuentas cuando se utiliza con AWS Organizations, lo que permite una vista más completa de las configuraciones de recursos en toda una organización."
        ]
    },
    {
        "Question Number": "27",
        "Situation": "Una organización de investigación científica almacena grandes conjuntos de datos en Amazon S3 que son frecuentemente accedidos por usuarios externos. Para minimizar costos, quieren que los usuarios externos cubran el costo del acceso a los datos en lugar de la organización misma.",
        "Question": "¿Qué configuración de S3 deberían usar para cumplir con este requisito?",
        "Options": {
            "1": "Habilitar S3 Transfer Acceleration",
            "2": "Configurar un bucket de S3 con Requester Pays habilitado",
            "3": "Utilizar S3 Intelligent-Tiering para la clase de almacenamiento",
            "4": "Habilitar Cross-Region Replication para compartir costos"
        },
        "Correct Answer": "Configurar un bucket de S3 con Requester Pays habilitado",
        "Explanation": "Habilitar Requester Pays en un bucket de S3 permite a los usuarios externos que acceden a los datos incurrir en los costos asociados con sus solicitudes. Esto significa que cuando los usuarios acceden a los datos, se les cobrará por la transferencia de datos y las solicitudes, trasladando efectivamente la carga de costos de la organización a los usuarios que acceden a los datos. Esta configuración está específicamente diseñada para escenarios donde los datos se comparten con partes externas, lo que la convierte en la opción más adecuada para el requisito de la organización de minimizar costos.",
        "Other Options": [
            "Habilitar S3 Transfer Acceleration acelera la transferencia de archivos hacia y desde S3, pero no cambia quién paga por el acceso a los datos. Los costos por usar Transfer Acceleration siguen siendo asumidos por el propietario del bucket, no por el solicitante.",
            "Si bien S3 Intelligent-Tiering es una clase de almacenamiento que mueve automáticamente los datos entre dos niveles de acceso según los patrones de acceso cambiantes, no aborda la asignación de costos por el acceso a los datos. La organización seguiría siendo responsable de los costos asociados con la recuperación de datos.",
            "Habilitar Cross-Region Replication se utiliza para replicar automáticamente datos a través de diferentes regiones de AWS para redundancia y disponibilidad. Esta función no se relaciona con el compartir costos por el acceso a los datos y generaría costos adicionales para la organización sin abordar el requisito de que los usuarios externos cubran los costos de acceso."
        ]
    },
    {
        "Question Number": "28",
        "Situation": "Una empresa de servicios financieros gestiona una base de datos transaccional que experimenta cargas de trabajo variables, incluyendo períodos pico que requieren un alto IOPS y capacidad de almacenamiento. La empresa tiene como objetivo optimizar costos mientras asegura el rendimiento durante los momentos de máxima demanda.",
        "Question": "¿Qué configuración de almacenamiento de Amazon RDS debería recomendar el arquitecto de soluciones para cumplir con estos requisitos?",
        "Options": {
            "1": "Provisionar almacenamiento SSD de propósito general (gp3) con escalado automático habilitado.",
            "2": "Utilizar almacenamiento magnético con copias de seguridad automatizadas y capacidades de instantáneas.",
            "3": "Provisionar almacenamiento SSD de IOPS aprovisionados (io1) con IOPS configurados al máximo requerido durante los períodos pico.",
            "4": "Implementar Amazon Aurora con su escalado de almacenamiento incorporado y capacidades de alto rendimiento."
        },
        "Correct Answer": "Implementar Amazon Aurora con su escalado de almacenamiento incorporado y capacidades de alto rendimiento.",
        "Explanation": "Amazon Aurora está diseñado para un alto rendimiento y disponibilidad, lo que lo convierte en una excelente opción para aplicaciones con cargas de trabajo variables. Escala automáticamente el almacenamiento hasta 128 TB según sea necesario, lo cual es beneficioso durante los períodos pico que requieren un alto IOPS y capacidad de almacenamiento. Aurora también ofrece un alto rendimiento y baja latencia, asegurando que el rendimiento se mantenga incluso bajo cargas pesadas, optimizando así los costos mientras se cumplen los requisitos de rendimiento.",
        "Other Options": [
            "Provisionar almacenamiento SSD de propósito general (gp3) con escalado automático habilitado es una buena opción para cargas de trabajo generales, pero puede no proporcionar el mismo nivel de rendimiento y escalabilidad que Amazon Aurora durante los períodos pico, especialmente para bases de datos transaccionales que requieren un IOPS alto y consistente.",
            "Utilizar almacenamiento magnético con copias de seguridad automatizadas y capacidades de instantáneas no es adecuado para requisitos de alto rendimiento. El almacenamiento magnético es más lento y no proporciona el IOPS necesario para cargas de trabajo transaccionales, lo que lo hace inadecuado para necesidades de rendimiento pico.",
            "Provisionar almacenamiento SSD de IOPS aprovisionados (io1) con IOPS configurados al máximo requerido durante los períodos pico puede ser efectivo, pero puede ser costoso y puede no proporcionar el mismo nivel de escalado automático y optimización del rendimiento que Amazon Aurora, especialmente si las cargas de trabajo son variables e impredecibles."
        ]
    },
    {
        "Question Number": "29",
        "Situation": "Una organización de investigación necesita migrar 80 TB de datos científicos de su almacenamiento NFS local a Amazon S3. Los datos se actualizan con frecuencia, y la organización quiere asegurarse de que cualquier cambio realizado en las instalaciones se sincronice de forma incremental con AWS. También están preocupados por saturar su ancho de banda de red durante las horas laborales.",
        "Question": "¿Qué características de AWS DataSync debería resaltar el arquitecto de soluciones como beneficios para esta migración? (Elija dos.)",
        "Options": {
            "1": "Validación de datos durante la transferencia para asegurar la integridad de los datos",
            "2": "Replicación en múltiples regiones para recuperación ante desastres",
            "3": "Limitador de ancho de banda para controlar el uso de la red durante las horas pico",
            "4": "Soporte para sincronización en tiempo real con cero latencia",
            "5": "Recuperación automática de errores de tránsito para una transferencia confiable"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Validación de datos durante la transferencia para asegurar la integridad de los datos",
            "Limitador de ancho de banda para controlar el uso de la red durante las horas pico"
        ],
        "Explanation": "La validación de datos durante la transferencia es una característica clave de AWS DataSync que asegura la integridad de los datos. Verifica que los datos leídos de la ubicación de origen coincidan con los datos escritos en el destino, asegurando así que los datos no se corrompan durante la transferencia. Esto es crucial para la organización de investigación, ya que necesita garantizar la integridad de sus datos científicos. La característica del limitador de ancho de banda permite a la organización controlar el uso de la red durante las horas pico. Esto es importante ya que la organización está preocupada por saturar su ancho de banda de red durante las horas laborales. AWS DataSync permite a los usuarios establecer un límite en el ancho de banda que utiliza DataSync, evitando que la red se sature.",
        "Other Options": [
            "La replicación en múltiples regiones para recuperación ante desastres no es una característica de AWS DataSync. Esta es una característica de Amazon S3, no de DataSync. DataSync se utiliza para transferir datos hacia y desde los servicios de almacenamiento de AWS, no proporciona replicación en múltiples regiones.",
            "El soporte para sincronización en tiempo real con cero latencia no es una característica de AWS DataSync. Si bien DataSync admite tareas de transferencia de datos programadas o bajo demanda, no proporciona sincronización en tiempo real con cero latencia.",
            "La recuperación automática de errores de tránsito para una transferencia confiable no es una característica específica de AWS DataSync. Si bien DataSync tiene un manejo de errores robusto, no proporciona específicamente una característica de 'recuperación automática de errores de tránsito'."
        ]
    },
    {
        "Question Number": "30",
        "Situation": "Una empresa está desarrollando una aplicación de análisis de datos que procesa grandes volúmenes de archivos de registro generados por sus servidores web. La aplicación requiere acceso de baja latencia a datos de registro que se acceden con frecuencia y debe soportar operaciones de lectura y escritura concurrentes desde múltiples instancias. Además, la solución de almacenamiento debe escalar automáticamente para acomodar volúmenes de datos en crecimiento sin intervención manual.",
        "Question": "¿Qué servicio de almacenamiento de AWS debería recomendar el arquitecto de soluciones para cumplir con estos requisitos?",
        "Options": {
            "1": "Amazon S3 Standard",
            "2": "Amazon Elastic File System (Amazon EFS)",
            "3": "Amazon Elastic Block Store (Amazon EBS) con IOPS aprovisionados",
            "4": "Amazon FSx for Windows File Server"
        },
        "Correct Answer": "Amazon Elastic File System (Amazon EFS)",
        "Explanation": "Amazon Elastic File System (EFS) está diseñado para acceso de baja latencia y puede soportar operaciones de lectura y escritura concurrentes desde múltiples instancias, lo que lo hace ideal para aplicaciones que requieren acceso frecuente a datos. EFS escala automáticamente a medida que se añaden o eliminan datos, lo que se alinea perfectamente con el requisito de una solución de almacenamiento que acomode volúmenes de datos en crecimiento sin intervención manual. Además, EFS proporciona un sistema de archivos gestionado que puede ser accedido desde múltiples instancias de EC2, asegurando alta disponibilidad y durabilidad para los datos de registro.",
        "Other Options": [
            "Amazon S3 Standard es un servicio de almacenamiento de objetos que está optimizado para durabilidad y escalabilidad, pero no está diseñado para acceso de baja latencia o operaciones de lectura/escritura concurrentes como un sistema de archivos. Es más adecuado para almacenar grandes cantidades de datos no estructurados en lugar de aplicaciones que requieren acceso frecuente y baja latencia.",
            "Amazon Elastic Block Store (Amazon EBS) con IOPS aprovisionados es un servicio de almacenamiento en bloques que proporciona alto rendimiento para instancias de EC2. Sin embargo, no está diseñado para acceso concurrente desde múltiples instancias, ya que generalmente se adjunta a una sola instancia de EC2 a la vez. Esto lo hace menos adecuado para los requisitos de operaciones de lectura y escritura concurrentes.",
            "Amazon FSx for Windows File Server es un sistema de archivos de Windows gestionado que proporciona almacenamiento de archivos compartido. Si bien admite acceso concurrente, es más complejo y puede no escalar automáticamente de la misma manera que EFS. También está más orientado a entornos de Windows, lo que puede no ser necesario para la aplicación descrita."
        ]
    },
    {
        "Question Number": "31",
        "Situation": "Una empresa está implementando una aplicación web y quiere asegurarse de que pueda escalar dinámicamente mientras proporciona alta disponibilidad en múltiples Zonas de Disponibilidad (AZs). Quieren utilizar un Application Load Balancer (ALB) para distribuir el tráfico de manera eficiente.",
        "Question": "¿Cuál de las siguientes configuraciones permitiría mejor a la empresa alcanzar este objetivo?",
        "Options": {
            "1": "Usar un ALB para distribuir el tráfico basado en la ruta de URL y redirigir las solicitudes a diferentes grupos de destino, asegurando que el tráfico se distribuya de manera uniforme entre múltiples instancias de EC2.",
            "2": "Usar un Classic Load Balancer (CLB) para distribuir el tráfico únicamente basado en la dirección IP sin enrutamiento por ruta de URL.",
            "3": "Usar un ALB pero redirigir todo el tráfico a una sola instancia de EC2 para reducir la complejidad y mejorar el rendimiento.",
            "4": "Usar un ALB solo para contenido estático y dirigir el tráfico de contenido dinámico a una sola instancia de EC2 para mantener un balanceo de carga eficiente."
        },
        "Correct Answer": "Usar un ALB para distribuir el tráfico basado en la ruta de URL y redirigir las solicitudes a diferentes grupos de destino, asegurando que el tráfico se distribuya de manera uniforme entre múltiples instancias de EC2.",
        "Explanation": "Usar un Application Load Balancer (ALB) para distribuir el tráfico basado en la ruta de URL permite capacidades de enrutamiento avanzadas, lo que permite a la aplicación manejar diferentes tipos de solicitudes de manera eficiente. Al redirigir las solicitudes a diferentes grupos de destino, el ALB puede asegurar que el tráfico se distribuya de manera uniforme entre múltiples instancias de EC2, lo cual es esencial para escalar dinámicamente y mantener alta disponibilidad en múltiples Zonas de Disponibilidad (AZs). Esta configuración soporta tanto el escalado horizontal como la utilización eficiente de recursos, que son críticos para las aplicaciones web modernas.",
        "Other Options": [
            "Usar un Classic Load Balancer (CLB) para distribuir el tráfico únicamente basado en la dirección IP sin enrutamiento por ruta de URL limita la flexibilidad y eficiencia de la gestión del tráfico. Los CLBs no soportan características de enrutamiento avanzadas como el enrutamiento basado en la ruta, lo que puede llevar a una distribución desigual del tráfico y potencialmente sobrecargar ciertas instancias mientras subutiliza otras.",
            "Redirigir todo el tráfico a una sola instancia de EC2 socava el propósito de usar un ALB para el balanceo de carga. Esta configuración crearía un único punto de fallo y negaría los beneficios de alta disponibilidad y escalabilidad, ya que no aprovecha la capacidad del ALB para distribuir el tráfico entre múltiples instancias.",
            "Usar un ALB solo para contenido estático y dirigir el tráfico de contenido dinámico a una sola instancia de EC2 limita las capacidades del balanceador de carga y puede llevar a cuellos de botella en el rendimiento. Este enfoque no aprovecha la capacidad del ALB para distribuir tanto contenido estático como dinámico entre múltiples instancias, lo cual es crucial para mantener alta disponibilidad y escalabilidad."
        ]
    },
    {
        "Question Number": "32",
        "Situation": "Una empresa de fabricación opera en una ubicación remota con conectividad a internet limitada. Necesitan recursos de computación locales para analizar datos de máquinas y ejecutar aplicaciones, pero también quieren la capacidad de sincronizar datos con AWS cuando la conectividad esté disponible.",
        "Question": "¿Cuál opción de computación híbrida satisfaría mejor estos requisitos?",
        "Options": {
            "1": "AWS Snowball Edge",
            "2": "AWS Lambda con puntos de enlace de VPC",
            "3": "Instancias de Amazon EC2 en la región de AWS más cercana",
            "4": "Amazon EKS con escalado bajo demanda"
        },
        "Correct Answer": "AWS Snowball Edge",
        "Explanation": "AWS Snowball Edge está diseñado para computación en el borde y transferencia de datos en entornos con conectividad a internet limitada o nula. Permite a los usuarios ejecutar aplicaciones y analizar datos localmente en el dispositivo, lo que es ideal para la empresa de fabricación en una ubicación remota. Además, Snowball Edge soporta la sincronización de datos con AWS cuando la conectividad está disponible, lo que lo convierte en una opción perfecta para sus requisitos.",
        "Other Options": [
            "AWS Lambda con puntos de enlace de VPC no es adecuado porque requiere una conexión a internet estable para acceder a los servicios de AWS. En una ubicación remota con conectividad limitada, esta opción no proporcionaría los recursos de computación locales necesarios.",
            "Las instancias de Amazon EC2 en la región de AWS más cercana no satisfacerían las necesidades de la empresa ya que requieren conectividad constante a internet para acceder a estas instancias. Esta opción no proporciona recursos de computación locales para el análisis de datos en un área remota.",
            "Amazon EKS con escalado bajo demanda también depende de una conexión a internet estable para gestionar clústeres de Kubernetes en la nube. Esta opción no funcionaría de manera efectiva en una ubicación remota con conectividad limitada, ya que no proporciona recursos de computación locales."
        ]
    },
    {
        "Question Number": "33",
        "Situation": "Una empresa fintech está diseñando una nueva plataforma de análisis de datos para procesar grandes volúmenes de datos de transacciones en tiempo real. Para garantizar un alto rendimiento, la plataforma necesita procesar los datos a medida que llegan, con un retraso mínimo, y proporcionar rápidamente información a los usuarios finales.",
        "Question": "¿Cuál opción arquitectónica cumpliría de manera más efectiva con estos requisitos de alto rendimiento?",
        "Options": {
            "1": "Procesamiento por lotes de datos de transacciones a intervalos regulares",
            "2": "Arquitectura impulsada por eventos con transmisión de datos en tiempo real",
            "3": "Almacenar todos los datos de transacciones en una base de datos relacional tradicional",
            "4": "Desplegar todos los componentes de la aplicación en una sola zona de disponibilidad para un acceso más rápido"
        },
        "Correct Answer": "Arquitectura impulsada por eventos con transmisión de datos en tiempo real",
        "Explanation": "La arquitectura impulsada por eventos con transmisión de datos en tiempo real es la opción más efectiva para procesar grandes volúmenes de datos de transacciones en tiempo real. Esta arquitectura permite que el sistema reaccione a los datos entrantes a medida que llegan, lo que permite un procesamiento y análisis inmediatos. Soporta un alto rendimiento y baja latencia, que son críticos para proporcionar información oportuna a los usuarios finales. Al utilizar tecnologías como colas de mensajes y marcos de procesamiento de flujos, la plataforma puede manejar de manera eficiente flujos de datos continuos y entregar resultados sin retrasos significativos.",
        "Other Options": [
            "El procesamiento por lotes de datos de transacciones a intervalos regulares no es adecuado para requisitos de alto rendimiento que exigen procesamiento en tiempo real. Este enfoque introduce latencia a medida que los datos se recopilan y procesan en lotes, lo que puede retrasar la información y la capacidad de respuesta.",
            "Almacenar todos los datos de transacciones en una base de datos relacional tradicional puede proporcionar almacenamiento de datos estructurado, pero no está optimizado para el procesamiento en tiempo real. Las bases de datos relacionales generalmente requieren más tiempo para las consultas y pueden no manejar flujos de datos de alta velocidad de manera eficiente, lo que lleva a cuellos de botella en el rendimiento.",
            "Desplegar todos los componentes de la aplicación en una sola zona de disponibilidad para un acceso más rápido no mejora inherentemente el rendimiento del procesamiento de datos. Si bien puede reducir la latencia para el acceso local, no aborda la necesidad de procesamiento de datos en tiempo real y podría llevar a un único punto de fallo, comprometiendo la fiabilidad del sistema."
        ]
    },
    {
        "Question Number": "34",
        "Situation": "Una empresa de desarrollo web aloja múltiples aplicaciones en AWS, con patrones de tráfico variables. Para optimizar costos, quieren pagar solo por lo que utilizan y evitar gestionar servidores directamente.",
        "Question": "¿Qué enfoque cumpliría mejor con estos requisitos?",
        "Options": {
            "1": "Desplegar aplicaciones en Amazon EC2 con Auto Scaling",
            "2": "Usar contenedores en Amazon ECS con Fargate",
            "3": "Ejecutar aplicaciones en Instancias Reservadas",
            "4": "Usar Amazon S3 para contenido estático y Amazon RDS para bases de datos"
        },
        "Correct Answer": "Usar contenedores en Amazon ECS con Fargate",
        "Explanation": "Usar Amazon ECS con Fargate permite a la empresa de desarrollo web ejecutar sus aplicaciones en contenedores sin tener que gestionar los servidores subyacentes. Fargate aprovisiona y gestiona automáticamente los recursos de computación, lo que significa que la empresa solo paga por los recursos que realmente utiliza según los patrones de tráfico de sus aplicaciones. Este enfoque sin servidor es ideal para optimizar costos mientras proporciona la flexibilidad de escalar según la demanda.",
        "Other Options": [
            "Desplegar aplicaciones en Amazon EC2 con Auto Scaling requiere gestionar instancias de EC2, incluso si escalan automáticamente. Este enfoque puede no cumplir completamente con el requisito de evitar la gestión directa de servidores, ya que la empresa aún necesitaría manejar el aprovisionamiento y mantenimiento de instancias.",
            "Ejecutar aplicaciones en Instancias Reservadas implica comprometerse con un tipo y tamaño de instancia específicos por un período de uno o tres años, lo que no se alinea con el objetivo de pagar solo por lo que utilizan. Esta opción es más rentable para cargas de trabajo predecibles, pero no proporciona la flexibilidad necesaria para patrones de tráfico variables.",
            "Usar Amazon S3 para contenido estático y Amazon RDS para bases de datos es un buen enfoque para casos de uso específicos, pero no aborda el requisito de alojar aplicaciones dinámicas. Esta opción separa la gestión de almacenamiento y bases de datos, pero no proporciona una solución completa para ejecutar aplicaciones con patrones de tráfico variables."
        ]
    },
    {
        "Question Number": "35",
        "Situation": "Una organización de investigación necesita almacenar datos experimentales en una base de datos para su análisis. Los datos se utilizan activamente durante los primeros tres meses, luego se accede a ellos raramente pero se retienen durante cinco años por cumplimiento. Quieren minimizar costos para el almacenamiento a largo plazo.",
        "Question": "¿Cuál sería la política de retención de datos más rentable?",
        "Options": {
            "1": "Almacenar todos los datos en una base de datos de alto rendimiento con copias de seguridad diarias",
            "2": "Archivar datos en Amazon S3 Glacier después de tres meses",
            "3": "Eliminar datos después de tres meses para reducir costos de almacenamiento",
            "4": "Mover datos a un nivel de base de datos de bajo costo después de tres meses"
        },
        "Correct Answer": "Archivar datos en Amazon S3 Glacier después de tres meses",
        "Explanation": "Archivar datos en Amazon S3 Glacier después de tres meses es la solución más rentable para el almacenamiento a largo plazo. S3 Glacier está diseñado para datos que se acceden raramente y ofrece costos de almacenamiento significativamente más bajos en comparación con bases de datos de alto rendimiento. Dado que los datos se accederán raramente después de los tres meses iniciales pero deben retenerse por cumplimiento durante cinco años, S3 Glacier proporciona un equilibrio adecuado entre costo y accesibilidad, permitiendo a la organización minimizar gastos mientras cumple con sus requisitos de retención.",
        "Other Options": [
            "Almacenar todos los datos en una base de datos de alto rendimiento con copias de seguridad diarias no es rentable para el almacenamiento a largo plazo, especialmente dado que los datos no se utilizarán activamente después de los primeros tres meses. Las bases de datos de alto rendimiento son típicamente más caras, y las copias de seguridad diarias añaden costos adicionales que son innecesarios para datos que se accederán raramente.",
            "Eliminar datos después de tres meses puede reducir costos de almacenamiento, pero no cumple con el requisito de cumplimiento de retener los datos durante cinco años. Esta opción expondría a la organización a riesgos legales y regulatorios debido a la falta de cumplimiento.",
            "Mover datos a un nivel de base de datos de bajo costo después de tres meses es una mejor opción que mantenerlos en una base de datos de alto rendimiento, pero aún puede ser más caro que archivarlos en S3 Glacier. Los niveles de base de datos de bajo costo pueden incurrir en costos más altos en comparación con las soluciones de archivo diseñadas para acceso poco frecuente, lo que hace que esta opción sea menos óptima para el almacenamiento a largo plazo."
        ]
    },
    {
        "Question Number": "36",
        "Situation": "Una organización debe cumplir con políticas de retención de datos que requieren que ciertos registros se almacenen durante al menos 7 años.",
        "Question": "¿Cuál es la solución MÁS apropiada para garantizar el cumplimiento mientras se minimizan los costos de almacenamiento?",
        "Options": {
            "1": "Almacenar los datos en Amazon S3 Standard con una política de ciclo de vida de S3 para trasladar los datos a S3 Glacier",
            "2": "Almacenar los datos en Amazon Elastic File System (EFS) con cifrado habilitado",
            "3": "Usar Amazon RDS con copias de seguridad automatizadas configuradas para retener instantáneas durante 7 años",
            "4": "Almacenar los datos en Amazon DynamoDB con copias de seguridad bajo demanda"
        },
        "Correct Answer": "Almacenar los datos en Amazon S3 Standard con una política de ciclo de vida de S3 para trasladar los datos a S3 Glacier",
        "Explanation": "Esta opción es la más apropiada porque permite una gestión de almacenamiento rentable. Amazon S3 Standard es adecuado para datos de acceso frecuente, mientras que S3 Glacier está diseñado para almacenamiento de archivo a largo plazo a un costo más bajo. Al implementar una política de ciclo de vida de S3, la organización puede trasladar automáticamente los datos a S3 Glacier después de un período específico, asegurando el cumplimiento con la política de retención de 7 años mientras minimiza los costos de almacenamiento a lo largo del tiempo.",
        "Other Options": [
            "Almacenar los datos en Amazon Elastic File System (EFS) con cifrado habilitado no es la mejor opción para almacenamiento a largo plazo debido a los costos más altos asociados con EFS en comparación con S3 Glacier. EFS está diseñado para acceso de baja latencia y es más caro para almacenar datos que se acceden raramente.",
            "Usar Amazon RDS con copias de seguridad automatizadas configuradas para retener instantáneas durante 7 años puede ser costoso y puede no ser necesario para datos que no requieren las características de una base de datos relacional. RDS se utiliza típicamente para datos transaccionales y puede incurrir en costos más altos para almacenamiento a largo plazo en comparación con S3 Glacier.",
            "Almacenar los datos en Amazon DynamoDB con copias de seguridad bajo demanda tampoco es la solución más rentable para la retención a largo plazo. Si bien DynamoDB es excelente para aplicaciones de alto rendimiento, su modelo de precios para copias de seguridad puede volverse costoso con el tiempo, especialmente para datos que necesitan ser retenidos durante varios años."
        ]
    },
    {
        "Question Number": "37",
        "Situation": "Una empresa tiene un bucket S3 llamado \"secretcatproject\" que contiene datos sensibles. La empresa necesita permitir el acceso a este bucket desde usuarios específicos en una cuenta asociada, asegurando que los datos permanezcan seguros y no sean accesibles públicamente.",
        "Question": "¿Qué método debería utilizar la empresa para otorgar el acceso necesario mientras previene el acceso no autorizado por parte de usuarios anónimos?",
        "Options": {
            "1": "Establecer la política del bucket para permitir el acceso público a todos los usuarios para simplificar la gestión de acceso.",
            "2": "Utilizar una política de bucket S3 que especifique los roles IAM de la cuenta asociada como principales con permiso para acceder al bucket.",
            "3": "Habilitar \"Bloquear el acceso público\" en el bucket y utilizar listas de control de acceso (ACLs) para gestionar el acceso de la cuenta asociada.",
            "4": "Adjuntar una política IAM directamente al bucket para controlar el acceso de los usuarios en la cuenta asociada."
        },
        "Correct Answer": "Utilizar una política de bucket S3 que especifique los roles IAM de la cuenta asociada como principales con permiso para acceder al bucket.",
        "Explanation": "Utilizar una política de bucket S3 para especificar los roles IAM de la cuenta asociada como principales permite un control preciso sobre quién puede acceder al bucket. Este método asegura que solo los usuarios designados de la cuenta asociada puedan acceder a los datos sensibles, al mismo tiempo que previene cualquier acceso público. Las políticas de bucket son herramientas poderosas que pueden definir permisos a nivel de bucket e incluir condiciones para restringir aún más el acceso, lo que las hace ideales para gestionar el acceso a datos sensibles de manera segura.",
        "Other Options": [
            "Establecer la política del bucket para permitir el acceso público a todos los usuarios es altamente inseguro y contradice el requisito de mantener los datos seguros frente al acceso público. Esto expondría los datos sensibles a cualquier persona en Internet, lo cual no es aceptable.",
            "Si bien utilizar una política de bucket S3 que especifique los roles IAM de la cuenta asociada es correcto, esta opción no menciona explícitamente el uso de roles IAM como principales, que es un aspecto crucial para otorgar acceso de manera segura. Por lo tanto, es menos precisa que la respuesta correcta.",
            "Habilitar 'Bloquear el acceso público' es una buena práctica para prevenir el acceso público, pero utilizar listas de control de acceso (ACLs) no es el mejor método para gestionar el acceso en este escenario. Las ACLs pueden ser más complejas y menos flexibles que las políticas de bucket, y no proporcionan el mismo nivel de claridad y control sobre los permisos que las políticas de bucket."
        ]
    },
    {
        "Question Number": "38",
        "Situation": "Una empresa está utilizando Amazon Route 53 para gestionar los registros DNS de su dominio. Tienen preocupaciones sobre posibles ataques DNS, como el spoofing DNS y ataques DDoS, y quieren asegurarse de que su infraestructura DNS sea segura.",
        "Question": "¿Cuál de las siguientes acciones debería tomar la empresa para mejorar la seguridad de su configuración de Route 53?",
        "Options": {
            "1": "Habilitar DNSSEC (Extensiones de Seguridad del Sistema de Nombres de Dominio) en sus zonas alojadas de Route 53 para asegurar que las respuestas DNS estén firmadas criptográficamente, previniendo ataques de spoofing DNS.",
            "2": "Utilizar Route 53 Resolver DNS Firewall para filtrar consultas maliciosas y prevenir el tráfico de IPs maliciosas conocidas, asegurando que solo el tráfico legítimo llegue a sus recursos.",
            "3": "Configurar Route 53 para utilizar solo HTTP para consultas DNS para simplificar la seguridad, ya que HTTP es menos propenso a ataques DDoS en comparación con otros protocolos.",
            "4": "Configurar verificaciones de salud de Route 53 para monitorear el rendimiento de las consultas DNS, pero no habilitar ninguna característica de seguridad adicional, asumiendo que la seguridad DNS está cubierta por otros servicios de AWS."
        },
        "Correct Answer": "Habilitar DNSSEC (Extensiones de Seguridad del Sistema de Nombres de Dominio) en sus zonas alojadas de Route 53 para asegurar que las respuestas DNS estén firmadas criptográficamente, previniendo ataques de spoofing DNS.",
        "Explanation": "Habilitar DNSSEC en las zonas alojadas de Route 53 añade una capa de seguridad al permitir que las respuestas DNS sean firmadas criptográficamente. Esto asegura que las respuestas sean auténticas y no hayan sido manipuladas, previniendo efectivamente ataques de spoofing DNS. DNSSEC ayuda a verificar la integridad de los datos DNS, haciendo mucho más difícil que los atacantes redirijan a los usuarios a sitios maliciosos a través de respuestas DNS falsificadas.",
        "Other Options": [
            "Utilizar Route 53 Resolver DNS Firewall es una buena práctica para filtrar consultas maliciosas, pero no aborda directamente el problema del spoofing DNS. Si bien puede ayudar a mitigar algunas amenazas, no es tan efectivo como DNSSEC para asegurar la autenticidad de las respuestas DNS.",
            "Configurar Route 53 para utilizar solo HTTP para consultas DNS es incorrecto porque las consultas DNS típicamente utilizan los protocolos UDP y TCP, no HTTP. Además, HTTP no proporciona inherentemente seguridad contra ataques DDoS; más bien, puede exponer la infraestructura DNS a más riesgos. Utilizar protocolos seguros como DNS sobre HTTPS (DoH) o DNS sobre TLS (DoT) sería más apropiado.",
            "Configurar verificaciones de salud de Route 53 es útil para monitorear el rendimiento de las consultas DNS, pero no mejora la seguridad. Confiar únicamente en las verificaciones de salud sin habilitar características de seguridad adicionales deja la infraestructura DNS vulnerable a ataques como el spoofing y DDoS, que pueden ser mitigados implementando DNSSEC y otras medidas de seguridad."
        ]
    },
    {
        "Question Number": "39",
        "Situation": "Una empresa quiere asegurar las credenciales de aplicación para una función de AWS Lambda. La función necesita conectarse a una base de datos de Amazon RDS.",
        "Question": "¿Qué enfoque proporcionará la forma MÁS segura de almacenar y gestionar las credenciales de la base de datos?",
        "Options": {
            "1": "Almacenar las credenciales de la base de datos en un archivo de configuración en texto plano dentro de la función Lambda.",
            "2": "Utilizar roles IAM de AWS con permisos para acceder a la base de datos directamente.",
            "3": "Almacenar las credenciales de la base de datos en AWS Secrets Manager y otorgar a la función Lambda permisos para recuperar los secretos.",
            "4": "Almacenar las credenciales de la base de datos en Amazon S3 con cifrado del lado del servidor habilitado."
        },
        "Correct Answer": "Almacenar las credenciales de la base de datos en AWS Secrets Manager y otorgar a la función Lambda permisos para recuperar los secretos.",
        "Explanation": "Utilizar AWS Secrets Manager para almacenar las credenciales de la base de datos es el enfoque más seguro porque está diseñado específicamente para gestionar información sensible. Secrets Manager cifra las credenciales en reposo y proporciona un control de acceso detallado a través de AWS IAM. Esto permite que la función Lambda recupere las credenciales de forma segura sin codificarlas en el código de la función o en archivos de configuración. Además, Secrets Manager puede rotar automáticamente las credenciales, mejorando aún más la seguridad.",
        "Other Options": [
            "Almacenar las credenciales de la base de datos en un archivo de configuración en texto plano dentro de la función Lambda es altamente inseguro. Expone información sensible directamente en el código, haciéndola vulnerable a accesos no autorizados si el código alguna vez se expone o comparte.",
            "Utilizar roles IAM de AWS con permisos para acceder a la base de datos directamente no aborda la necesidad de almacenar las credenciales de la base de datos de forma segura. Si bien los roles IAM pueden gestionar permisos de acceso, no proporcionan un mecanismo para almacenar de forma segura información sensible como las credenciales de la base de datos.",
            "Almacenar las credenciales de la base de datos en Amazon S3 con cifrado del lado del servidor habilitado es mejor que el almacenamiento en texto plano, pero aún no es tan seguro como usar Secrets Manager. S3 no está diseñado para gestionar secretos, y aunque el cifrado del lado del servidor protege los datos en reposo, no proporciona el mismo nivel de control de acceso y características de gestión de secretos que ofrece Secrets Manager."
        ]
    },
    {
        "Question Number": "40",
        "Situation": "Imagina que se te encarga construir una conexión altamente resiliente entre tu centro de datos local y AWS utilizando AWS Direct Connect para una aplicación crítica.",
        "Question": "Dado que Direct Connect es un enlace físico sin resiliencia inherente, ¿cuál sería el mejor enfoque para garantizar la tolerancia a fallos?",
        "Options": {
            "1": "Desplegar dos conexiones de Direct Connect en ubicaciones separadas (DX Locations) dentro de la misma región de AWS para proporcionar rutas redundantes en caso de que una conexión falle.",
            "2": "Utilizar una única conexión de Direct Connect de alta capacidad para reducir el riesgo de interrupciones debido a sobrecarga.",
            "3": "Implementar una conexión de Direct Connect emparejada con una copia de seguridad de VPN para mantener la conectividad si el enlace de Direct Connect falla.",
            "4": "Establecer conexiones de Direct Connect en diferentes regiones de AWS para asegurar la conectividad si una región encuentra un problema."
        },
        "Correct Answer": "Implementar una conexión de Direct Connect emparejada con una copia de seguridad de VPN para mantener la conectividad si el enlace de Direct Connect falla.",
        "Explanation": "Implementar una conexión de Direct Connect emparejada con una copia de seguridad de VPN es el mejor enfoque para garantizar la tolerancia a fallos porque proporciona un camino secundario para la transmisión de datos. Si el enlace de Direct Connect falla, la VPN puede tomar el control, asegurando conectividad continua. Este enfoque híbrido aprovecha la fiabilidad de Direct Connect mientras también utiliza la VPN basada en internet como opción de conmutación por error, mejorando así la resiliencia general.",
        "Other Options": [
            "Desplegar dos conexiones de Direct Connect en ubicaciones separadas dentro de la misma región de AWS podría proporcionar redundancia, pero no aborda el potencial de una interrupción regional u otros problemas que pueden afectar ambas conexiones. Además, puede no ser rentable en comparación con una solución híbrida con una VPN.",
            "Utilizar una única conexión de Direct Connect de alta capacidad no proporciona ninguna tolerancia a fallos. Si esa conexión falla, no habría un camino alternativo para los datos, lo que podría llevar a un tiempo de inactividad para la aplicación crítica.",
            "Establecer conexiones de Direct Connect en diferentes regiones de AWS podría proporcionar cierto nivel de redundancia, pero puede introducir latencia y complejidad en la gestión del tráfico interregional. Además, no garantiza que ambas conexiones estén disponibles simultáneamente, especialmente si hay problemas que afectan a las regiones en sí."
        ]
    },
    {
        "Question Number": "41",
        "Situation": "Una empresa está planeando migrar sus aplicaciones a AWS y quiere entender las responsabilidades de seguridad que debe gestionar como parte del Modelo de Responsabilidad Compartida de AWS. La empresa utilizará Amazon EC2 para sus servidores de aplicaciones, Amazon RDS para sus bases de datos y Amazon S3 para almacenar datos.",
        "Question": "¿Cuáles de las siguientes responsabilidades retendrá la empresa y cuáles gestionará AWS?",
        "Options": {
            "1": "La empresa es responsable de la seguridad de la infraestructura física subyacente, mientras que AWS gestiona la encriptación de datos en reposo.",
            "2": "AWS es responsable de aplicar parches a las instancias de Amazon EC2, mientras que la empresa gestiona el filtrado del tráfico de red utilizando grupos de seguridad y ACLs de red.",
            "3": "La empresa es responsable de gestionar las configuraciones de seguridad de Amazon RDS, incluyendo la aplicación de parches al software de la base de datos, mientras que AWS gestiona la seguridad de los centros de datos donde se alojan las instancias de RDS.",
            "4": "AWS gestiona la seguridad de los datos de los clientes almacenados en Amazon S3, mientras que la empresa es responsable de configurar los permisos de acceso y las configuraciones de encriptación para esos datos."
        },
        "Correct Answer": "La empresa es responsable de gestionar las configuraciones de seguridad de Amazon RDS, incluyendo la aplicación de parches al software de la base de datos, mientras que AWS gestiona la seguridad de los centros de datos donde se alojan las instancias de RDS.",
        "Explanation": "En el Modelo de Responsabilidad Compartida de AWS, AWS es responsable de la seguridad de la infraestructura de la nube, que incluye la seguridad física de los centros de datos y el hardware que ejecuta los servicios de AWS. Sin embargo, los clientes son responsables de la seguridad de sus aplicaciones y datos, incluyendo la gestión de las configuraciones y la aplicación de parches a servicios como Amazon RDS. Esto significa que, mientras AWS asegura la infraestructura subyacente, la empresa debe asegurarse de que sus configuraciones de base de datos sean seguras y estén actualizadas.",
        "Other Options": [
            "La empresa es responsable de la seguridad de sus aplicaciones y datos, no de la infraestructura física subyacente, que es gestionada por AWS. AWS gestiona la encriptación de datos en reposo, pero es responsabilidad de la empresa implementarla para sus datos.",
            "AWS es responsable de aplicar parches a la infraestructura subyacente, pero la empresa debe gestionar la aplicación de parches a nivel de sistema operativo y aplicación para las instancias de Amazon EC2. La empresa también es responsable de configurar grupos de seguridad y ACLs de red para el filtrado del tráfico de red.",
            "AWS gestiona la seguridad de la infraestructura que soporta Amazon S3, pero la empresa es responsable de gestionar los permisos de acceso y las configuraciones de encriptación para los datos que almacena en S3. AWS no gestiona directamente la seguridad de los datos de los clientes; proporciona las herramientas para que los clientes aseguren sus datos."
        ]
    },
    {
        "Question Number": "42",
        "Situation": "Una empresa está diseñando una Nube Privada Virtual (VPC) con múltiples subredes a través de varias Zonas de Disponibilidad (AZs). Necesitan asegurarse de que cada subred esté definida de manera única, no se superponga con otras subredes y que ciertas direcciones IP estén reservadas para funciones específicas dentro de cada subred.",
        "Question": "¿Cuáles de las siguientes directrices deberían seguir para configurar correctamente sus subredes y evitar conflictos de IP? (Elige dos.)",
        "Options": {
            "1": "Definir un bloque CIDR único para cada subred, asegurarse de que se superponga con otras subredes en diferentes AZs y utilizar direcciones IP reservadas para funciones de red y difusión.",
            "2": "Utilizar el mismo bloque CIDR para todas las subredes dentro de la VPC, permitiendo que las subredes se comuniquen sin problemas a través de las AZs, y reservar la primera dirección IP en cada subred para DNS.",
            "3": "Asignar bloques CIDR no superpuestos a cada subred dentro de la VPC, con una subred por AZ, y reservar direcciones IP específicas (como las direcciones de red y difusión) según los requisitos de AWS.",
            "4": "Asignar un único bloque CIDR grande para todas las subredes dentro de la VPC y utilizar el Protocolo de Configuración Dinámica de Host (DHCP) para prevenir conflictos de IP entre subredes.",
            "5": "Asegurarse de que el bloque CIDR de cada subred sea un subconjunto del bloque CIDR de la VPC y planificar los rangos de IP para acomodar el crecimiento futuro sin superposición."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Asignar bloques CIDR no superpuestos a cada subred dentro de la VPC, con una subred por AZ, y reservar direcciones IP específicas (como las direcciones de red y difusión) según los requisitos de AWS.",
            "Asegurarse de que el bloque CIDR de cada subred sea un subconjunto del bloque CIDR de la VPC y planificar los rangos de IP para acomodar el crecimiento futuro sin superposición."
        ],
        "Explanation": "Las respuestas correctas son las opciones 3 y 5. La opción 3 es correcta porque asignar bloques CIDR no superpuestos a cada subred dentro de la VPC asegura que cada subred esté definida de manera única y no entre en conflicto con otras subredes. Reservar direcciones IP específicas para funciones de red y difusión es una práctica estándar en el diseño de redes. La opción 5 es correcta porque el bloque CIDR de cada subred debe ser un subconjunto del bloque CIDR de la VPC. Esto asegura que las direcciones IP dentro de la subred sean únicas dentro de la VPC. Planificar los rangos de IP para acomodar el crecimiento futuro sin superposición es una buena práctica para evitar posibles conflictos de IP en el futuro.",
        "Other Options": [
            "Los bloques CIDR superpuestos entre subredes pueden llevar a conflictos de IP. Además, aunque es cierto que ciertas direcciones IP deben ser reservadas para funciones de red y difusión, esta opción sugiere incorrectamente que los bloques CIDR superpuestos son una buena práctica.",
            "Utilizar el mismo bloque CIDR para todas las subredes dentro de la VPC puede llevar a conflictos de IP. Aunque es cierto que la primera dirección IP en cada subred se reserva típicamente para DNS, esta opción sugiere incorrectamente que utilizar el mismo bloque CIDR para todas las subredes es una buena práctica.",
            "Asignar un único bloque CIDR grande para todas las subredes dentro de la VPC puede llevar a conflictos de IP. Aunque DHCP puede ayudar a gestionar direcciones IP dentro de una subred, no puede prevenir conflictos de IP entre subredes que comparten el mismo bloque CIDR."
        ]
    },
    {
        "Question Number": "43",
        "Situation": "Una empresa está utilizando Amazon RDS para sus necesidades de base de datos, pero está preocupada por la escalabilidad y disponibilidad de sus conexiones de base de datos. Quieren mejorar la gestión de las conexiones de base de datos y asegurar una alta disponibilidad para su aplicación sin sobrecargar las instancias de RDS.",
        "Question": "¿Qué servicio de AWS debería utilizar la empresa para lograr este objetivo y cuáles son sus beneficios?",
        "Options": {
            "1": "Utilizar Amazon RDS Proxy para gestionar las conexiones de base de datos, agrupando y multiplexando conexiones para reducir la carga en las instancias de RDS y mejorar la escalabilidad.",
            "2": "Utilizar Amazon CloudFront como proxy para almacenar en caché las consultas de base de datos y reducir la carga en la instancia de RDS.",
            "3": "Utilizar Amazon SQS para poner en cola las solicitudes de base de datos y procesarlas secuencialmente, asegurando una alta disponibilidad de las conexiones de base de datos.",
            "4": "Utilizar Amazon ElastiCache para hacer proxy y almacenar en caché las consultas de base de datos para minimizar la carga en la base de datos."
        },
        "Correct Answer": "Utilizar Amazon RDS Proxy para gestionar las conexiones de base de datos, agrupando y multiplexando conexiones para reducir la carga en las instancias de RDS y mejorar la escalabilidad.",
        "Explanation": "Amazon RDS Proxy está diseñado específicamente para mejorar la gestión de las conexiones de base de datos para Amazon RDS. Proporciona agrupamiento y multiplexación de conexiones, lo que ayuda a reducir el número de conexiones que deben establecerse con las instancias de RDS. Esto no solo mejora la escalabilidad de la aplicación al permitir más conexiones concurrentes, sino que también mejora la disponibilidad al gestionar de manera fluida los escenarios de conmutación por error. Al utilizar RDS Proxy, la empresa puede asegurarse de que sus conexiones de base de datos se gestionen de manera eficiente, reduciendo la carga en las instancias de RDS y mejorando el rendimiento general de la aplicación.",
        "Other Options": [
            "Utilizar Amazon CloudFront como proxy para almacenar en caché las consultas de base de datos es incorrecto porque CloudFront es principalmente una red de entrega de contenido (CDN) diseñada para almacenar en caché contenido estático y acelerar la entrega de aplicaciones web, no para gestionar conexiones de base de datos o almacenar en caché consultas de base de datos.",
            "Utilizar Amazon SQS para poner en cola las solicitudes de base de datos no es adecuado para este escenario porque SQS es un servicio de colas de mensajes diseñado para desacoplar y escalar microservicios, sistemas distribuidos y aplicaciones sin servidor. No gestiona directamente las conexiones de base de datos ni mejora su disponibilidad.",
            "Utilizar Amazon ElastiCache para hacer proxy y almacenar en caché las consultas de base de datos no es la mejor opción en este contexto. Aunque ElastiCache puede utilizarse para almacenar en caché datos de acceso frecuente y reducir la carga en la base de datos, no gestiona las conexiones de base de datos ni proporciona agrupamiento de conexiones, que es la principal preocupación para la escalabilidad y disponibilidad en este escenario."
        ]
    },
    {
        "Question Number": "44",
        "Situation": "Una empresa está planeando migrar su aplicación monolítica a una arquitectura en contenedores para mejorar la escalabilidad, portabilidad y gestión de recursos. La empresa quiere descomponer la aplicación monolítica en componentes más pequeños y manejables para asegurar una escalabilidad eficiente durante los picos de tráfico. También necesitan asegurarse de que la aplicación pueda trasladarse fácilmente entre entornos y plataformas.",
        "Question": "¿Cuál es el enfoque más efectivo para migrar su aplicación a contenedores?",
        "Options": {
            "1": "Contenerizar cada componente de la aplicación creando imágenes de Docker para cada microservicio y desplegar los contenedores en Amazon ECS o EKS para orquestación y gestión.",
            "2": "Migrar toda la aplicación como una máquina virtual a AWS utilizando Amazon EC2 y gestionar la aplicación a través de un grupo de Auto Scaling de EC2.",
            "3": "Utilizar AWS Lambda para migrar la aplicación y descomponerla en funciones sin servidor para eliminar la necesidad de contenedores.",
            "4": "Almacenar la aplicación en Amazon S3 y utilizar AWS Fargate para ejecutar la aplicación en un entorno de contenedor gestionado."
        },
        "Correct Answer": "Contenerizar cada componente de la aplicación creando imágenes de Docker para cada microservicio y desplegar los contenedores en Amazon ECS o EKS para orquestación y gestión.",
        "Explanation": "Este enfoque es el más efectivo para migrar una aplicación monolítica a una arquitectura en contenedores porque permite descomponer la aplicación en microservicios más pequeños y manejables. Al crear imágenes de Docker para cada componente, la empresa puede asegurarse de que cada microservicio sea desplegable, escalable y mantenible de forma independiente. Utilizar Amazon ECS (Elastic Container Service) o EKS (Elastic Kubernetes Service) proporciona capacidades robustas de orquestación y gestión, permitiendo una escalabilidad eficiente durante los picos de tráfico y un movimiento fluido entre diferentes entornos y plataformas.",
        "Other Options": [
            "Migrar toda la aplicación como una máquina virtual a AWS utilizando Amazon EC2 no aprovecha completamente las ventajas de la contenedorización. Aunque permite escalar a través de grupos de Auto Scaling de EC2, no descompone la aplicación monolítica en microservicios, lo cual es esencial para lograr la escalabilidad y gestión de recursos deseadas.",
            "Utilizar AWS Lambda para migrar la aplicación a funciones sin servidor no es adecuado para todas las aplicaciones, especialmente aquellas que no están diseñadas para ser sin servidor. Este enfoque puede requerir una re-arquitectura significativa de la aplicación y no utiliza contenedores, que es lo que la empresa busca implementar.",
            "Almacenar la aplicación en Amazon S3 y utilizar AWS Fargate para ejecutar la aplicación en un entorno de contenedor gestionado no es una solución completa. Aunque Fargate permite ejecutar contenedores sin gestionar servidores, simplemente almacenar la aplicación en S3 no aborda la necesidad de descomponer la aplicación monolítica en microservicios o crear imágenes de Docker, que son críticas para una contenedorización efectiva."
        ]
    },
    {
        "Question Number": "45",
        "Situation": "Una empresa de servicios financieros necesita asegurar su nueva aplicación web con HTTPS para proteger los datos de los clientes. Quieren una solución que simplifique la emisión, implementación y renovación de certificados SSL/TLS para evitar el riesgo de que certificados caducados causen tiempo de inactividad. Con la mayor parte de su infraestructura en AWS, están considerando AWS Certificate Manager (ACM) para gestionar certificados a través de servicios como ELB, CloudFront y API Gateway.",
        "Question": "¿Cómo apoya AWS Certificate Manager (ACM) la gestión segura y automatizada de certificados SSL/TLS para las necesidades de la empresa?",
        "Options": {
            "1": "ACM permite la emisión y renovación manual de certificados, proporcionando control sobre el proceso de renovación.",
            "2": "ACM emite, implementa y renueva automáticamente certificados, se integra con servicios de AWS y ofrece certificados de forma gratuita cuando se utilizan con recursos de AWS.",
            "3": "ACM solo admite certificados autofirmados, lo que requiere que la empresa gestione las renovaciones y la seguridad por separado.",
            "4": "ACM emite certificados pero requiere herramientas de terceros para las renovaciones y no se integra directamente con los servicios de AWS."
        },
        "Correct Answer": "ACM emite, implementa y renueva automáticamente certificados, se integra con servicios de AWS y ofrece certificados de forma gratuita cuando se utilizan con recursos de AWS.",
        "Explanation": "AWS Certificate Manager (ACM) simplifica la gestión de certificados SSL/TLS al automatizar los procesos de emisión, implementación y renovación. Esto significa que la empresa de servicios financieros puede evitar el riesgo de que certificados caducados causen tiempo de inactividad, ya que ACM gestiona las renovaciones automáticamente. Además, ACM se integra sin problemas con varios servicios de AWS como Elastic Load Balancing (ELB), CloudFront y API Gateway, y proporciona certificados sin costo cuando se utilizan con estos servicios, lo que lo convierte en una solución rentable para asegurar su aplicación web.",
        "Other Options": [
            "Si bien ACM permite la emisión y renovación manual de certificados, las necesidades de la empresa se centran en la automatización para evitar el riesgo de certificados caducados. Los procesos manuales no simplificarían su gestión de certificados como se requiere.",
            "ACM no solo admite certificados autofirmados. Principalmente emite certificados públicos que son confiables por navegadores y clientes, lo cual es esencial para asegurar los datos de los clientes en un entorno de producción.",
            "ACM no requiere herramientas de terceros para las renovaciones; automatiza el proceso de renovación. Además, ACM está diseñado para integrarse directamente con los servicios de AWS, lo cual es una característica clave que apoya las necesidades de infraestructura de la empresa."
        ]
    },
    {
        "Question Number": "46",
        "Situation": "",
        "Question": "¿Qué característica de Amazon Redshift garantiza la durabilidad y resiliencia de los datos al proporcionar capacidades de respaldo y recuperación ante desastres?",
        "Options": {
            "1": "Enhanced VPC Routing, que permite una red personalizada dentro de una VPC.",
            "2": "Slices en Compute Nodes, que permiten la distribución de datos y consultas a través de múltiples nodos.",
            "3": "Automatic Snapshots to S3, donde los datos se respaldan cada 8 horas o en incrementos de 5GB a Amazon S3 para durabilidad.",
            "4": "Redshift Spectrum, que permite consultar datos directamente en S3 sin cargarlos en Redshift."
        },
        "Correct Answer": "Automatic Snapshots to S3, donde los datos se respaldan cada 8 horas o en incrementos de 5GB a Amazon S3 para durabilidad.",
        "Explanation": "Amazon Redshift proporciona Automatic Snapshots to S3 como una característica clave para garantizar la durabilidad y resiliencia de los datos. Esta función respalda automáticamente los datos almacenados en Redshift a Amazon S3 cada 8 horas o siempre que el tamaño de los datos aumente en 5GB. Estas instantáneas son cruciales para la recuperación ante desastres, ya que permiten a los usuarios restaurar sus datos a un estado anterior en caso de pérdida o corrupción de datos, asegurando así la integridad y disponibilidad de los datos.",
        "Other Options": [
            "Enhanced VPC Routing se centra principalmente en mejorar la seguridad de la red y la gestión del tráfico dentro de una Nube Privada Virtual (VPC) y no se relaciona directamente con la durabilidad de los datos o las capacidades de respaldo.",
            "Slices en Compute Nodes se refiere a la forma en que se distribuyen y procesan los datos a través de múltiples nodos en un clúster de Redshift. Si bien esto mejora el rendimiento y la escalabilidad, no proporciona características de respaldo o recuperación ante desastres.",
            "Redshift Spectrum permite a los usuarios consultar datos directamente en Amazon S3 sin cargarlos en Redshift, lo que es útil para acceder a grandes conjuntos de datos, pero no proporciona capacidades de respaldo o recuperación ante desastres."
        ]
    },
    {
        "Question Number": "47",
        "Situation": "Una empresa está diseñando una arquitectura de red segura en AWS, con algunos recursos que requieren acceso público y otros restringidos a acceso privado dentro de una VPC. Quieren asegurarse de que los datos sensibles en los servicios privados estén aislados de Internet mientras permiten el acceso seguro a ciertos servicios públicos de AWS.",
        "Question": "¿Cuál de los siguientes enfoques cumple mejor con sus requisitos de seguridad?",
        "Options": {
            "1": "Desplegar todos los recursos en la Zona Pública de AWS con IPs públicas, ya que esto simplifica la gestión de acceso y seguridad.",
            "2": "Colocar instancias EC2 sensibles en una subred privada dentro de la Zona Privada de AWS, acceder a Internet a través de una puerta de enlace NAT y usar una VPN o Direct Connect para acceso seguro a las instalaciones a la VPC.",
            "3": "Usar subredes públicas para servicios sensibles y restringir el acceso aplicando grupos de seguridad para controlar el tráfico entrante y saliente.",
            "4": "Configurar servicios privados en subredes públicas para acceder a los servicios de AWS directamente a través de Internet sin usar el IGW o VPN."
        },
        "Correct Answer": "Colocar instancias EC2 sensibles en una subred privada dentro de la Zona Privada de AWS, acceder a Internet a través de una puerta de enlace NAT y usar una VPN o Direct Connect para acceso seguro a las instalaciones a la VPC.",
        "Explanation": "Este enfoque aísla efectivamente los datos y recursos sensibles al colocarlos en una subred privada, que no es accesible directamente desde Internet. El uso de una puerta de enlace NAT permite que estas instancias privadas inicien tráfico saliente hacia Internet (para actualizaciones, etc.) mientras se evita el tráfico entrante desde Internet, manteniendo así la seguridad. Además, usar una VPN o Direct Connect proporciona una conexión segura para el acceso a las instalaciones a la VPC, asegurando que los datos sensibles permanezcan protegidos de la exposición pública.",
        "Other Options": [
            "Desplegar todos los recursos en la Zona Pública de AWS con IPs públicas simplifica el acceso, pero expone todos los recursos a Internet, lo que representa un riesgo de seguridad significativo para los datos sensibles.",
            "Usar subredes públicas para servicios sensibles contradice el requisito de aislamiento de Internet. Las subredes públicas son accesibles desde Internet, lo que podría llevar a un acceso no autorizado a datos sensibles.",
            "Configurar servicios privados en subredes públicas para acceder a los servicios de AWS directamente a través de Internet sin usar el IGW o VPN no es factible, ya que las subredes públicas están inherentemente expuestas a Internet, lo que no cumple con el requisito de seguridad de aislar datos sensibles."
        ]
    },
    {
        "Question Number": "48",
        "Situation": "Una empresa está desplegando una nueva aplicación basada en microservicios en AWS. Cada microservicio está empaquetado en un contenedor Docker. La aplicación requiere orquestación para gestionar los contenedores, manejar la escalabilidad y asegurar alta disponibilidad.",
        "Question": "¿Qué servicio de AWS debería recomendar el arquitecto de soluciones para la orquestación de contenedores?",
        "Options": {
            "1": "Amazon EC2 Auto Scaling",
            "2": "AWS Lambda",
            "3": "Amazon Elastic Kubernetes Service (EKS)",
            "4": "Amazon Elastic Container Service (ECS)"
        },
        "Correct Answer": "Amazon Elastic Kubernetes Service (EKS)",
        "Explanation": "Amazon Elastic Kubernetes Service (EKS) es un servicio completamente gestionado que facilita la ejecución de Kubernetes en AWS sin necesidad de instalar y operar su propio plano de control o nodos de Kubernetes. Proporciona la orquestación necesaria para gestionar contenedores Docker, incluyendo escalabilidad y alta disponibilidad. EKS es particularmente adecuado para arquitecturas de microservicios, ya que permite el despliegue, escalado y gestión de aplicaciones en contenedores utilizando Kubernetes, que es una herramienta de orquestación ampliamente adoptada en la industria.",
        "Other Options": [
            "Amazon EC2 Auto Scaling es un servicio que ajusta automáticamente el número de instancias EC2 en respuesta a la demanda. Si bien puede ayudar a escalar aplicaciones, no proporciona capacidades de orquestación de contenedores específicamente para gestionar contenedores Docker.",
            "AWS Lambda es un servicio de computación sin servidor que ejecuta código en respuesta a eventos y gestiona automáticamente los recursos de computación requeridos. No está diseñado para la orquestación de contenedores y es más adecuado para arquitecturas impulsadas por eventos en lugar de gestionar múltiples microservicios en contenedores.",
            "Amazon Elastic Container Service (ECS) es otro servicio de orquestación de contenedores proporcionado por AWS. Si bien es capaz de gestionar contenedores Docker y puede manejar escalabilidad y alta disponibilidad, la pregunta pide específicamente orquestación, y EKS es a menudo preferido para aplicaciones basadas en Kubernetes debido a sus extensas características y soporte comunitario."
        ]
    },
    {
        "Question Number": "49",
        "Situation": "Una plataforma de comercio electrónico de rápido crecimiento quiere gestionar las solicitudes de API entrantes de manera eficiente mientras expande sus servicios backend para manejar altos volúmenes de tráfico. Quieren asegurarse de que las solicitudes estén autorizadas, validadas, transformadas y almacenadas en caché para un rendimiento óptimo. Además, la plataforma busca monitorear los ciclos de solicitud-respuesta y recopilar métricas detalladas sobre el uso.",
        "Question": "¿Qué servicio de AWS debería utilizar la empresa para construir una capa de gestión de API fiable y escalable, y qué características específicas de este servicio apoyarían sus requisitos?",
        "Options": {
            "1": "Amazon API Gateway, ya que puede manejar autorización, limitación, almacenamiento en caché e integrarse sin problemas con AWS CloudWatch para el monitoreo en tiempo real y la recopilación de métricas.",
            "2": "AWS Lambda, ya que proporciona capacidad de computación sin servidor y puede utilizarse para manejar, autorizar y procesar cada solicitud de manera independiente.",
            "3": "Instancias de Amazon EC2 con NGINX para gestionar el balanceo de carga y el almacenamiento en caché, aprovechando los agentes de CloudWatch para métricas y registros.",
            "4": "Amazon S3 con URLs firmadas para restringir el acceso y CloudFront para almacenamiento en caché, ya que esto puede reducir la carga en los servicios backend."
        },
        "Correct Answer": "Amazon API Gateway, ya que puede manejar autorización, limitación, almacenamiento en caché e integrarse sin problemas con AWS CloudWatch para el monitoreo en tiempo real y la recopilación de métricas.",
        "Explanation": "Amazon API Gateway está diseñado específicamente para crear, implementar y gestionar APIs a gran escala. Proporciona características integradas para autorización (utilizando AWS IAM, autorizadores de Lambda o Amazon Cognito), validación de solicitudes, transformación de solicitudes y respuestas, y almacenamiento en caché para mejorar el rendimiento. Además, se integra con AWS CloudWatch, lo que permite a la plataforma monitorear el uso de la API, rastrear ciclos de solicitud-respuesta y recopilar métricas detalladas, lo que se alinea perfectamente con los requisitos de la empresa para gestionar altos volúmenes de tráfico de manera eficiente.",
        "Other Options": [
            "AWS Lambda es un servicio de computación sin servidor que puede procesar solicitudes, pero no proporciona una capa completa de gestión de API. Aunque puede manejar autorización y procesamiento de solicitudes, carece de características integradas para almacenamiento en caché, limitación y monitoreo integral que ofrece API Gateway.",
            "Las instancias de Amazon EC2 con NGINX pueden configurarse para gestionar el balanceo de carga y el almacenamiento en caché, pero este enfoque requiere más configuración y gestión manual en comparación con API Gateway. Además, aunque los agentes de CloudWatch pueden proporcionar métricas, no ofrecen el mismo nivel de integración y facilidad de uso para la gestión de API como lo hace API Gateway.",
            "Amazon S3 con URLs firmadas y CloudFront puede proporcionar acceso seguro y almacenamiento en caché para contenido estático, pero no es adecuado para gestionar solicitudes de API dinámicas. Esta solución carece de las características necesarias para autorización, validación de solicitudes y monitoreo detallado del uso de la API, que son críticas para las necesidades de la plataforma de comercio electrónico."
        ]
    },
    {
        "Question Number": "50",
        "Situation": "Una empresa está configurando una VPC con múltiples subredes para una aplicación web de múltiples capas. La subred pública de la aplicación necesita permitir el acceso a Internet, y la subred privada solo debe permitir tráfico saliente a Internet a través de una puerta de enlace NAT.",
        "Question": "¿Cuál es la forma más eficiente de asegurar el enrutamiento correcto del tráfico entre estas subredes?",
        "Options": {
            "1": "Crear una tabla de rutas para la subred pública con una ruta predeterminada (0.0.0.0/0) que apunte a una puerta de enlace de Internet, y crear una tabla de rutas para la subred privada con una ruta a la puerta de enlace NAT.",
            "2": "Crear una única tabla de rutas para ambas subredes pública y privada y agregar una ruta a la puerta de enlace NAT para el acceso a Internet saliente.",
            "3": "Crear una tabla de rutas para la subred privada que apunte directamente a la puerta de enlace de Internet para tráfico externo.",
            "4": "Utilizar Amazon Route 53 para manejar el enrutamiento de ambas subredes y dirigir todo el tráfico a un servidor DNS interno."
        },
        "Correct Answer": "Crear una tabla de rutas para la subred pública con una ruta predeterminada (0.0.0.0/0) que apunte a una puerta de enlace de Internet, y crear una tabla de rutas para la subred privada con una ruta a la puerta de enlace NAT.",
        "Explanation": "Esta opción configura correctamente el enrutamiento para ambas subredes, pública y privada, en una VPC. La subred pública necesita una tabla de rutas que dirija todo el tráfico saliente (0.0.0.0/0) a la puerta de enlace de Internet, permitiendo que las instancias en esa subred accedan a Internet directamente. La subred privada, por otro lado, no debe tener acceso directo a Internet; en su lugar, debe enrutar el tráfico saliente a la puerta de enlace NAT, que manejará el acceso a Internet para las instancias en la subred privada. Esta configuración asegura que la subred pública pueda servir tráfico web mientras mantiene la seguridad de la subred privada.",
        "Other Options": [
            "Crear una única tabla de rutas para ambas subredes pública y privada y agregar una ruta a la puerta de enlace NAT para el acceso a Internet saliente es incorrecto porque la subred pública necesita enrutar el tráfico a la puerta de enlace de Internet, no a la puerta de enlace NAT. La puerta de enlace NAT es solo para el tráfico saliente de la subred privada.",
            "Crear una tabla de rutas para la subred privada que apunte directamente a la puerta de enlace de Internet para tráfico externo es incorrecto porque las subredes privadas no deben tener acceso directo a Internet. Deben enrutar el tráfico a través de una puerta de enlace NAT para mantener la seguridad y prevenir la exposición directa a Internet.",
            "Utilizar Amazon Route 53 para manejar el enrutamiento de ambas subredes y dirigir todo el tráfico a un servidor DNS interno es incorrecto porque Route 53 es principalmente un servicio DNS y no gestiona el enrutamiento entre subredes en una VPC. El enrutamiento es manejado por tablas de rutas, no por servicios DNS."
        ]
    },
    {
        "Question Number": "51",
        "Situation": "Una plataforma de intercambio de medios permite a los usuarios subir videos, que luego se transcodifican automáticamente en múltiples formatos para una reproducción óptima en diferentes dispositivos. La plataforma utiliza Google como proveedor de identidad para la autenticación de usuarios, y tras un inicio de sesión exitoso, los usuarios pueden subir videos a un bucket de Amazon S3. Se activan una serie de funciones de Lambda para procesar y cargar videos, iniciar trabajos de transcodificación y actualizar metadatos en una tabla de DynamoDB.",
        "Question": "¿Qué beneficio proporciona esta arquitectura sin servidor a la plataforma?",
        "Options": {
            "1": "Procesamiento de video garantizado dentro de una duración fija",
            "2": "Menor carga operativa con mínima gestión de servidores requerida",
            "3": "Intervención manual requerida para tareas de transcodificación de video",
            "4": "Servidores dedicados para manejar alto tráfico de carga"
        },
        "Correct Answer": "Menor carga operativa con mínima gestión de servidores requerida",
        "Explanation": "La arquitectura sin servidor permite a la plataforma aprovechar servicios en la nube como AWS Lambda, S3 y DynamoDB sin necesidad de gestionar los servidores subyacentes. Esto resulta en una menor carga operativa, ya que la plataforma puede centrarse en el desarrollo y la escalabilidad sin preocuparse por el mantenimiento de servidores, aprovisionamiento o problemas de escalado. La escalabilidad automática de las funciones de Lambda y la naturaleza gestionada de S3 y DynamoDB reducen aún más la necesidad de intervención manual y gestión de servidores.",
        "Other Options": [
            "El procesamiento de video garantizado dentro de una duración fija no es un beneficio de la arquitectura sin servidor. Aunque las funciones sin servidor pueden escalar automáticamente, no hay garantía sobre la duración del procesamiento, ya que puede variar según la carga de trabajo y otros factores.",
            "La intervención manual requerida para tareas de transcodificación de video contradice los beneficios de la arquitectura sin servidor, que está diseñada para automatizar procesos. En este escenario, el uso de funciones de Lambda indica que las tareas de transcodificación están automatizadas sin intervención manual.",
            "Servidores dedicados para manejar alto tráfico de carga no es una característica de la arquitectura sin servidor. En cambio, las soluciones sin servidor asignan recursos dinámicamente según sea necesario, eliminando la necesidad de servidores dedicados y permitiendo una utilización más eficiente de los recursos."
        ]
    },
    {
        "Question Number": "52",
        "Situation": "Una empresa de servicios financieros está utilizando AWS Key Management Service (KMS) para gestionar las claves de cifrado de datos sensibles de clientes almacenados en múltiples cuentas de AWS. El equipo de seguridad necesita implementar políticas de acceso para garantizar que solo el personal y las aplicaciones autorizadas puedan acceder a claves específicas, mientras se previene el acceso no autorizado. Para cumplir con los requisitos regulatorios, también necesitan restringir el acceso en función de roles, departamentos y proyectos específicos.",
        "Question": "¿Qué enfoques deberían adoptar para hacer cumplir estas políticas de acceso de manera efectiva? (Elija dos.)",
        "Options": {
            "1": "Utilizar políticas basadas en recursos en KMS para definir permisos de acceso específicos para cada clave y asignar estos permisos a los usuarios, grupos y roles de IAM relevantes.",
            "2": "Crear grupos de seguridad para cada departamento, adjuntar las claves de cifrado relevantes y aplicar permisos a nivel de red para controlar el acceso.",
            "3": "Implementar controles de acceso a través de políticas de bucket de AWS S3 para controlar qué usuarios pueden acceder a los datos cifrados por las claves.",
            "4": "Utilizar roles de AWS Identity and Access Management (IAM) con permisos de menor privilegio para diferentes departamentos y proyectos.",
            "5": "Confiar en AWS Shield para gestionar y hacer cumplir las políticas de acceso a las claves de cifrado en todos los recursos."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Utilizar políticas basadas en recursos en KMS para definir permisos de acceso específicos para cada clave y asignar estos permisos a los usuarios, grupos y roles de IAM relevantes.",
            "Utilizar roles de AWS Identity and Access Management (IAM) con permisos de menor privilegio para diferentes departamentos y proyectos."
        ],
        "Explanation": "Las respuestas correctas son utilizar políticas basadas en recursos en KMS y utilizar roles de IAM con permisos de menor privilegio. Las políticas basadas en recursos en KMS permiten especificar quién tiene acceso a qué claves, y se pueden asignar estos permisos a los usuarios, grupos y roles de IAM relevantes. Esto se alinea con el requisito de restringir el acceso en función de roles, departamentos y proyectos específicos. Los roles de IAM con permisos de menor privilegio también son un buen enfoque porque aseguran que cada departamento y proyecto solo tenga acceso a los recursos que necesitan, reduciendo el riesgo de acceso no autorizado.",
        "Other Options": [
            "Crear grupos de seguridad para cada departamento y adjuntar las claves de cifrado relevantes no es un enfoque correcto porque los grupos de seguridad en AWS se utilizan para controlar el tráfico entrante y saliente a nivel de instancia, no para gestionar el acceso a las claves de cifrado.",
            "Implementar controles de acceso a través de políticas de bucket de AWS S3 no es un enfoque correcto porque, aunque las políticas de bucket de S3 pueden controlar quién puede acceder a los datos dentro de un bucket, no gestionan el acceso a las claves de cifrado de KMS.",
            "Confiar en AWS Shield para gestionar y hacer cumplir las políticas de acceso a las claves de cifrado no es un enfoque correcto porque AWS Shield es un servicio de protección contra ataques de Denegación de Servicio Distribuido (DDoS), no un servicio para gestionar el acceso a las claves de cifrado."
        ]
    },
    {
        "Question Number": "53",
        "Situation": "Una empresa necesita una estrategia de recuperación ante desastres (DR) para su aplicación crítica que asegure que el sistema pueda recuperarse rápidamente de una falla mientras minimiza el tiempo de inactividad. La empresa quiere minimizar el objetivo de tiempo de recuperación (RTO) y el objetivo de punto de recuperación (RPO), y está dispuesta a implementar infraestructura adicional en una región secundaria para mantener la aplicación en funcionamiento con un impacto mínimo en el rendimiento.",
        "Question": "¿Qué estrategia de DR debería implementar la empresa?",
        "Options": {
            "1": "Implementar una estrategia de conmutación por error activa-activa en dos regiones, asegurando que la aplicación esté en funcionamiento en ambas regiones en todo momento y que el tráfico se distribuya dinámicamente.",
            "2": "Implementar una estrategia de espera en caliente con infraestructura mínima en la región secundaria, y escalar los recursos cuando se active la conmutación por error.",
            "3": "Implementar una estrategia de copia de seguridad y restauración, donde los datos se respaldan en Amazon S3 y se restauran manualmente en caso de falla.",
            "4": "Implementar una estrategia de luz piloto con infraestructura mínima en la región secundaria y solo escalar a plena capacidad cuando sea necesario."
        },
        "Correct Answer": "Implementar una estrategia de conmutación por error activa-activa en dos regiones, asegurando que la aplicación esté en funcionamiento en ambas regiones en todo momento y que el tráfico se distribuya dinámicamente.",
        "Explanation": "Una estrategia de conmutación por error activa-activa permite que la aplicación funcione simultáneamente en dos regiones, lo que significa que ambas regiones pueden manejar el tráfico en todo momento. Esta configuración minimiza significativamente el tiempo de inactividad, ya que no hay necesidad de cambiar a una región secundaria durante una falla; la aplicación ya está operativa en ambas ubicaciones. Este enfoque minimiza efectivamente tanto el objetivo de tiempo de recuperación (RTO) como el objetivo de punto de recuperación (RPO) ya que los datos se sincronizan continuamente entre las dos regiones, asegurando que los datos más actuales estén siempre disponibles.",
        "Other Options": [
            "Implementar una estrategia de espera en caliente implica mantener una infraestructura mínima en la región secundaria, que puede escalarse cuando ocurre una conmutación por error. Si bien esto mejora los tiempos de recuperación en comparación con una espera fría, aún requiere tiempo para escalar los recursos, lo que puede llevar a un aumento del tiempo de inactividad y un RTO más alto en comparación con una configuración activa-activa.",
            "Una estrategia de copia de seguridad y restauración depende de copias de seguridad periódicas de datos, que se almacenan en un servicio como Amazon S3. En caso de falla, el sistema debe restaurarse manualmente desde estas copias de seguridad. Este enfoque generalmente resulta en un RTO y RPO más largos, ya que puede llevar un tiempo significativo restaurar la aplicación y los datos, lo que lo hace inadecuado para escenarios donde el tiempo de inactividad mínimo es crítico.",
            "Una estrategia de luz piloto mantiene una versión mínima de la aplicación en funcionamiento en la región secundaria, que puede escalarse a plena capacidad durante una conmutación por error. Si bien esto es más eficiente que una espera fría, aún requiere tiempo para escalar, lo que lleva a un RTO más largo en comparación con una estrategia activa-activa, que siempre está completamente operativa."
        ]
    },
    {
        "Question Number": "54",
        "Situation": "Una institución financiera utiliza cifrado para proteger los datos de los clientes almacenados en AWS y debe rotar regularmente las claves de cifrado y renovar los certificados SSL para mantenerse conforme con los requisitos regulatorios. La institución necesita automatizar la rotación de claves y la renovación de certificados para evitar la intervención manual y reducir el riesgo de error humano.",
        "Question": "¿Qué enfoque debería adoptar la institución para gestionar de manera eficiente la rotación de claves y la renovación de certificados en su entorno de AWS?",
        "Options": {
            "1": "Habilitar la rotación automática de claves en AWS KMS y utilizar AWS Certificate Manager (ACM) para renovar automáticamente los certificados SSL/TLS para dominios gestionados.",
            "2": "Rotar manualmente las claves de KMS cada 90 días y renovar los certificados SSL solicitando nuevos certificados a un proveedor externo.",
            "3": "Utilizar políticas de IAM para hacer cumplir la rotación regular de claves y la renovación de certificados en las cuentas de AWS.",
            "4": "Configurar AWS CloudTrail para rotar automáticamente las claves de cifrado y renovar los certificados cuando se acerquen a la expiración."
        },
        "Correct Answer": "Habilitar la rotación automática de claves en AWS KMS y utilizar AWS Certificate Manager (ACM) para renovar automáticamente los certificados SSL/TLS para dominios gestionados.",
        "Explanation": "Este enfoque aprovecha los servicios de AWS diseñados para la automatización y el cumplimiento. AWS Key Management Service (KMS) permite la rotación automática de claves, lo que garantiza que las claves de cifrado se roten regularmente sin intervención manual, reduciendo así el riesgo de error humano. Además, AWS Certificate Manager (ACM) puede renovar automáticamente los certificados SSL/TLS para dominios gestionados, agilizando el proceso y asegurando que los certificados estén siempre actualizados. Esta combinación satisface eficazmente las necesidades de cumplimiento y seguridad de la institución.",
        "Other Options": [
            "Rotar manualmente las claves de KMS cada 90 días y renovar los certificados SSL solicitando nuevos certificados a un proveedor externo es ineficiente y propenso a errores humanos. Este enfoque no automatiza el proceso, lo cual es crucial para mantener el cumplimiento y reducir el riesgo de descuidos.",
            "Utilizar políticas de IAM para hacer cumplir la rotación regular de claves y la renovación de certificados en las cuentas de AWS no automatiza directamente los procesos. Las políticas de IAM pueden hacer cumplir permisos y controles de acceso, pero no manejan las tareas reales de rotación o renovación, lo que hace que esta opción sea menos efectiva para las necesidades de la institución.",
            "Configurar AWS CloudTrail para rotar automáticamente las claves de cifrado y renovar los certificados cuando se acerquen a la expiración es incorrecto porque CloudTrail es principalmente un servicio de registro que rastrea las llamadas a la API y las actividades en AWS. No tiene la capacidad de realizar rotaciones automáticas de claves o renovaciones de certificados."
        ]
    },
    {
        "Question Number": "55",
        "Situation": "Una gran empresa con múltiples cuentas de AWS quiere optimizar su proceso de facturación y asegurar una gestión centralizada de sus cuentas de AWS. La organización también desea establecer políticas para grupos específicos de cuentas para hacer cumplir los estándares de seguridad y cumplimiento en todos los departamentos.",
        "Question": "¿Qué características de AWS deberían utilizar para lograr estos requisitos, y qué papel juega la cuenta de gestión en esta configuración? (Elige dos.)",
        "Options": {
            "1": "Utilizar AWS Control Tower para la gestión de cuentas, con la cuenta de gestión manejando la federación de identidades.",
            "2": "Configurar AWS Organizations con Consolidated Billing, donde la cuenta de gestión es responsable de la facturación y puede invitar a otras cuentas como cuentas miembros.",
            "3": "Utilizar AWS Identity and Access Management (IAM) para gestionar permisos para todas las cuentas, con la cuenta raíz manejando la facturación de cada cuenta.",
            "4": "Habilitar AWS Single Sign-On (SSO) y vincular cada cuenta, permitiendo que la cuenta de gestión gestione el acceso de usuarios y la facturación para todas las cuentas vinculadas.",
            "5": "Implementar AWS Service Control Policies (SCPs) dentro de AWS Organizations para hacer cumplir los estándares de seguridad y cumplimiento en todas las cuentas miembros."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Configurar AWS Organizations con Consolidated Billing, donde la cuenta de gestión es responsable de la facturación y puede invitar a otras cuentas como cuentas miembros.",
            "Implementar AWS Service Control Policies (SCPs) dentro de AWS Organizations para hacer cumplir los estándares de seguridad y cumplimiento en todas las cuentas miembros."
        ],
        "Explanation": "Configurar AWS Organizations con Consolidated Billing permite a la organización centralizar su proceso de facturación. La cuenta de gestión en esta configuración es responsable de pagar todos los cargos que incurren las cuentas miembros, y puede invitar o eliminar otras cuentas. Esta característica también permite a la organización consolidar métodos de pago, haciendo que el proceso de facturación sea más eficiente. Implementar AWS Service Control Policies (SCPs) dentro de AWS Organizations permite a la organización gestionar centralmente los permisos en múltiples cuentas de AWS. Las SCPs pueden ser utilizadas para hacer cumplir los estándares de seguridad y cumplimiento en todas las cuentas miembros, lo que se alinea con el requisito de la organización de establecer políticas para grupos específicos de cuentas.",
        "Other Options": [
            "Si bien AWS Control Tower puede ser utilizado para la gestión de cuentas, no maneja la federación de identidades. La federación de identidades es típicamente manejada por AWS Identity and Access Management (IAM) o AWS Single Sign-On (SSO).",
            "Si bien AWS Identity and Access Management (IAM) puede ser utilizado para gestionar permisos, la cuenta raíz no maneja la facturación de cada cuenta. La facturación es típicamente manejada por la cuenta de gestión en AWS Organizations.",
            "Si bien AWS Single Sign-On (SSO) puede ser utilizado para gestionar el acceso de usuarios, no maneja directamente la facturación para todas las cuentas vinculadas. La facturación es típicamente manejada por la cuenta de gestión en AWS Organizations."
        ]
    },
    {
        "Question Number": "56",
        "Situation": "Una empresa necesita una conexión de red segura y dedicada entre su centro de datos local y su entorno de AWS para un acceso de baja latencia a aplicaciones críticas. Están preocupados por los posibles riesgos de seguridad de transmitir datos sensibles a través de Internet.",
        "Question": "¿Qué solución de AWS proporciona la mejor opción para una conexión segura y dedicada con un rendimiento de red consistente?",
        "Options": {
            "1": "Configurar un Internet Gateway (IGW) y usar grupos de seguridad para restringir el acceso a aplicaciones locales.",
            "2": "Utilizar AWS VPN para establecer un túnel IPsec seguro a través de Internet, permitiendo comunicación cifrada.",
            "3": "Implementar AWS Direct Connect, ofreciendo un enlace de red privado y dedicado entre el centro de datos local y AWS, con soporte para cifrado a través de una capa VPN adicional si es necesario.",
            "4": "Desplegar un Elastic Load Balancer (ELB) y configurar el enrutamiento hacia el centro de datos local para un acceso seguro."
        },
        "Correct Answer": "Implementar AWS Direct Connect, ofreciendo un enlace de red privado y dedicado entre el centro de datos local y AWS, con soporte para cifrado a través de una capa VPN adicional si es necesario.",
        "Explanation": "AWS Direct Connect proporciona una conexión dedicada y privada entre el centro de datos local y AWS, lo cual es ideal para un acceso de baja latencia a aplicaciones críticas. Esta solución evita Internet pública, reduciendo significativamente los riesgos de seguridad asociados con la transmisión de datos sensibles a través de Internet. Además, Direct Connect puede combinarse con una VPN para un cifrado adicional, asegurando que los datos permanezcan seguros durante el tránsito.",
        "Other Options": [
            "Configurar un Internet Gateway (IGW) y usar grupos de seguridad no proporciona una conexión dedicada; en cambio, permite el acceso a recursos de AWS a través de Internet pública, lo que plantea riesgos de seguridad para datos sensibles.",
            "Utilizar AWS VPN establece un túnel IPsec seguro a través de Internet, que cifra los datos en tránsito. Sin embargo, aún depende de Internet pública, lo que puede introducir latencia y posibles vulnerabilidades de seguridad en comparación con una conexión dedicada.",
            "Si bien AWS Direct Connect es la opción correcta, la opción de desplegar un Elastic Load Balancer (ELB) no es relevante para establecer una conexión de red dedicada. Los ELBs se utilizan para distribuir el tráfico de aplicaciones entrantes entre múltiples destinos y no proporcionan un enlace directo entre centros de datos locales y AWS."
        ]
    },
    {
        "Question Number": "57",
        "Situation": "Tu equipo necesita implementar un servicio de mensajería que permita a múltiples aplicaciones leer, procesar y analizar un flujo constante de datos de alta frecuencia, como análisis en tiempo real sobre interacciones de usuarios con tu aplicación. El servicio debe soportar múltiples consumidores simultáneamente, asegurando que cada uno pueda leer los datos dentro de una ventana deslizante definida.",
        "Question": "¿Qué servicio se adapta mejor a estos requisitos, y por qué?",
        "Options": {
            "1": "Amazon SQS, porque ofrece desacoplamiento para comunicación asíncrona con persistencia de mensajes.",
            "2": "Amazon Kinesis, porque está optimizado para la ingestión de datos a gran escala y múltiples consumidores con una ventana deslizante para análisis en tiempo real.",
            "3": "Amazon SNS, ya que soporta múltiples consumidores y entrega en tiempo real a varios puntos finales.",
            "4": "AWS Lambda con S3, para ingerir y procesar datos en tiempo real utilizando disparadores basados en eventos."
        },
        "Correct Answer": "Amazon Kinesis, porque está optimizado para la ingestión de datos a gran escala y múltiples consumidores con una ventana deslizante para análisis en tiempo real.",
        "Explanation": "Amazon Kinesis está diseñado específicamente para manejar flujos de datos en tiempo real y está optimizado para la ingestión de datos de alto rendimiento. Permite que múltiples consumidores lean del mismo flujo de datos simultáneamente, lo cual es esencial para el requisito de que múltiples aplicaciones procesen los datos de manera concurrente. Además, Kinesis soporta el concepto de una ventana deslizante, permitiendo a las aplicaciones analizar datos durante un marco de tiempo especificado, lo que lo hace ideal para análisis en tiempo real sobre interacciones de usuarios.",
        "Other Options": [
            "Amazon SQS está diseñado principalmente para desacoplar microservicios y comunicación asíncrona. Si bien proporciona persistencia de mensajes, no soporta flujos de datos en tiempo real ni el concepto de una ventana deslizante para múltiples consumidores, lo que lo hace menos adecuado para el caso de uso descrito.",
            "Amazon SNS es un servicio de mensajería pub/sub que permite que los mensajes sean enviados a múltiples suscriptores. Sin embargo, no proporciona la capacidad para que los consumidores lean datos dentro de una ventana deslizante definida o maneje flujos de datos de alta frecuencia de manera efectiva, lo cual es crucial para análisis en tiempo real.",
            "AWS Lambda con S3 no es un servicio de mensajería, sino un servicio de computación sin servidor que puede procesar datos en respuesta a eventos. Si bien puede ser utilizado para procesamiento en tiempo real, depende de S3 para almacenamiento, que no está optimizado para flujos de datos de alta frecuencia o para que múltiples consumidores accedan a los mismos datos simultáneamente."
        ]
    },
    {
        "Question Number": "58",
        "Situation": "Una empresa de medios almacena grandes archivos de video en sus instalaciones y necesita migrar estos archivos a Amazon S3 para un almacenamiento escalable y acceso global. La migración debe ser automatizada y minimizar la cantidad de intervención manual requerida.",
        "Question": "¿Qué servicio de AWS debería utilizar el arquitecto de soluciones para facilitar esta transferencia de datos?",
        "Options": {
            "1": "AWS Snowball",
            "2": "AWS DataSync",
            "3": "Amazon S3 Transfer Acceleration",
            "4": "AWS Direct Connect"
        },
        "Correct Answer": "AWS DataSync",
        "Explanation": "AWS DataSync está diseñado específicamente para automatizar la transferencia de grandes cantidades de datos entre el almacenamiento local y los servicios de AWS como Amazon S3. Simplifica y acelera el proceso de migración al manejar la transferencia de datos de manera eficiente, permitiendo la programación y el monitoreo de las tareas de transferencia. Esto minimiza la intervención manual y es ideal para el escenario descrito, donde una empresa de medios necesita migrar grandes archivos de video a S3.",
        "Other Options": [
            "AWS Snowball es una solución de transporte de datos física que se utiliza para transferir grandes cantidades de datos a AWS cuando la transferencia por red no es factible. Aunque se puede utilizar para migraciones de datos grandes, requiere el envío físico de dispositivos y no está automatizada de la misma manera que DataSync.",
            "Amazon S3 Transfer Acceleration es una función que acelera las cargas a S3 utilizando las ubicaciones de borde distribuidas globalmente de Amazon CloudFront. Sin embargo, no automatiza el proceso de transferencia desde el almacenamiento local; solo acelera la transferencia una vez iniciada.",
            "AWS Direct Connect proporciona una conexión de red dedicada desde las instalaciones a AWS, lo que puede mejorar el ancho de banda y reducir la latencia para las transferencias de datos. Sin embargo, no automatiza el proceso de migración y es más adecuado para necesidades de transferencia de datos continuas en lugar de migraciones únicas."
        ]
    },
    {
        "Question Number": "59",
        "Situation": "Una empresa SaaS tiene múltiples aplicaciones conectándose a una base de datos central, lo que resulta en un alto número de conexiones durante las horas pico. Quieren reducir los costos asociados con la apertura y el mantenimiento de conexiones mientras aseguran un rendimiento fluido de la base de datos.",
        "Question": "¿Qué solución cumpliría mejor con estos requisitos?",
        "Options": {
            "1": "Agregar más instancias de base de datos para distribuir las conexiones",
            "2": "Implementar un proxy de base de datos para agrupar conexiones",
            "3": "Habilitar la implementación multi-AZ para conmutación por error",
            "4": "Usar una capa de caché para manejar conexiones"
        },
        "Correct Answer": "Implementar un proxy de base de datos para agrupar conexiones",
        "Explanation": "Implementar un proxy de base de datos para agrupar conexiones es la mejor solución para reducir los costos asociados con la apertura y el mantenimiento de conexiones mientras se asegura un rendimiento fluido de la base de datos. Un proxy de base de datos puede gestionar y reutilizar conexiones existentes, lo que minimiza la sobrecarga de establecer nuevas conexiones y reduce el número total de conexiones a la base de datos. Esto conduce a una mejor utilización de los recursos y puede mejorar significativamente el rendimiento durante las horas pico al permitir que las aplicaciones compartan conexiones de manera eficiente.",
        "Other Options": [
            "Agregar más instancias de base de datos para distribuir las conexiones puede ayudar con el balanceo de carga, pero no aborda directamente el problema del alto número de conexiones. Podría llevar a costos incrementados sin resolver el problema subyacente de la gestión de conexiones.",
            "Habilitar la implementación multi-AZ para conmutación por error es principalmente una estrategia para mejorar la disponibilidad y la recuperación ante desastres. Aunque mejora la resiliencia, no reduce directamente el número de conexiones ni los costos asociados con la gestión de esas conexiones.",
            "Usar una capa de caché para manejar conexiones puede mejorar el rendimiento al reducir la carga en la base de datos, pero no aborda específicamente el problema de agrupamiento de conexiones. La caché se trata más de almacenar datos de acceso frecuente que de gestionar conexiones de base de datos."
        ]
    },
    {
        "Question Number": "60",
        "Situation": "Una empresa requiere que sus usuarios de AWS implementen la Autenticación Multifactor (MFA) para una mayor seguridad. Cada usuario debe usar un dispositivo único, como una aplicación de teléfono móvil, para generar un código de un solo uso basado en el tiempo. El código cambia periódicamente y se requiere cada vez que inician sesión, además de su nombre de usuario y contraseña.",
        "Question": "¿Cuál de las siguientes afirmaciones describe MEJOR el beneficio de seguridad proporcionado por este tipo de configuración de MFA?",
        "Options": {
            "1": "Asegura que solo los usuarios que conocen la contraseña de la cuenta raíz de AWS pueden iniciar sesión.",
            "2": "Requiere que los usuarios se autentiquen con algo que saben y algo que tienen, reduciendo la probabilidad de acceso no autorizado.",
            "3": "Permite a los usuarios omitir la contraseña si están usando el código MFA correcto.",
            "4": "Solo funciona para usuarios que tienen acceso físico a la consola de administración de AWS."
        },
        "Correct Answer": "Requiere que los usuarios se autentiquen con algo que saben y algo que tienen, reduciendo la probabilidad de acceso no autorizado.",
        "Explanation": "Esta afirmación describe con precisión el beneficio de seguridad de la Autenticación Multifactor (MFA). MFA mejora la seguridad al requerir dos formas de verificación: algo que el usuario sabe (su contraseña) y algo que el usuario tiene (el código de un solo uso basado en el tiempo generado por su dispositivo móvil). Este requisito dual reduce significativamente el riesgo de acceso no autorizado, ya que un atacante necesitaría tanto la contraseña como el acceso al dispositivo del usuario para obtener entrada.",
        "Other Options": [
            "Esta afirmación es incorrecta porque MFA no asegura específicamente que solo los usuarios que conocen la contraseña de la cuenta raíz de AWS puedan iniciar sesión. MFA se aplica a todos los usuarios y mejora la seguridad más allá de solo la cuenta raíz.",
            "Esta afirmación es incorrecta porque es la respuesta correcta. Describe con precisión el beneficio de seguridad de MFA, que combina algo que el usuario sabe (contraseña) y algo que tiene (código MFA).",
            "Esta afirmación es incorrecta porque MFA no permite a los usuarios omitir la contraseña. El código MFA es una capa adicional de seguridad que debe proporcionarse junto con la contraseña para una autenticación exitosa."
        ]
    },
    {
        "Question Number": "61",
        "Situation": "Una organización está utilizando AWS CloudFormation para automatizar el despliegue de su infraestructura, incluidos recursos relacionados con la seguridad como roles de IAM, grupos de seguridad y volúmenes de almacenamiento cifrados. Quieren asegurarse de que todos los despliegues cumplan con las políticas de seguridad y prevenir cambios no autorizados en recursos críticos.",
        "Question": "¿Cuáles son las mejores prácticas que deben seguir para asegurar sus recursos gestionados por CloudFormation? (Elige dos.)",
        "Options": {
            "1": "Habilitar StackSets con detección de desviaciones de CloudFormation para monitorear cambios en los recursos desplegados y usar políticas de IAM para limitar quién puede modificar pilas.",
            "2": "Almacenar todas las plantillas de CloudFormation en S3 sin ningún control de versiones para simplificar actualizaciones y revisiones.",
            "3": "Usar CloudFormation para desplegar recursos solo en subredes públicas, asegurando un fácil acceso para todos los usuarios de la organización.",
            "4": "Implementar reglas de AWS Config para validar las pilas de CloudFormation contra las políticas de seguridad durante el despliegue.",
            "5": "Evitar el uso de roles de IAM en las pilas de CloudFormation para simplificar la seguridad, confiando en su lugar en pares de claves de EC2 para el control de acceso."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Habilitar StackSets con detección de desviaciones de CloudFormation para monitorear cambios en los recursos desplegados y usar políticas de IAM para limitar quién puede modificar pilas.",
            "Implementar reglas de AWS Config para validar las pilas de CloudFormation contra las políticas de seguridad durante el despliegue."
        ],
        "Explanation": "Habilitar StackSets con detección de desviaciones de CloudFormation permite a la organización monitorear cambios en los recursos desplegados. Esto ayuda a identificar cualquier cambio no autorizado en recursos críticos. Usar políticas de IAM para limitar quién puede modificar pilas asegura que solo el personal autorizado pueda realizar cambios en la infraestructura, mejorando así la seguridad. Implementar reglas de AWS Config para validar las pilas de CloudFormation contra las políticas de seguridad durante el despliegue asegura que todos los despliegues cumplan con las políticas de seguridad de la organización. Esto ayuda a prevenir cualquier violación de seguridad.",
        "Other Options": [
            "Almacenar todas las plantillas de CloudFormation en S3 sin ningún control de versiones simplifica actualizaciones y revisiones, pero no proporciona una forma de rastrear cambios o revertir a una versión anterior si algo sale mal. Esto puede llevar a vulnerabilidades de seguridad y, por lo tanto, no es una mejor práctica.",
            "Usar CloudFormation para desplegar recursos solo en subredes públicas no asegura la seguridad. Aunque proporciona un fácil acceso para todos los usuarios de la organización, también expone los recursos a posibles amenazas externas. Por lo tanto, no es una mejor práctica para asegurar los recursos gestionados por CloudFormation.",
            "Evitar el uso de roles de IAM en las pilas de CloudFormation y confiar en su lugar en pares de claves de EC2 para el control de acceso simplifica la seguridad, pero no proporciona el control granular que ofrecen los roles de IAM. Los roles de IAM ofrecen más flexibilidad y control sobre quién puede acceder a qué recursos, lo que los convierte en una mejor opción para la seguridad. Por lo tanto, esta no es una mejor práctica."
        ]
    },
    {
        "Question Number": "62",
        "Situation": "Una empresa está configurando un nuevo entorno multi-cuenta de AWS y quiere asegurarse de tener una configuración bien arquitectada con estándares de seguridad y cumplimiento consistentes en todas las cuentas. También desean capacidades de monitoreo y notificación automatizadas.",
        "Question": "¿Qué servicio de AWS deberían usar para agilizar este proceso, y qué característica específica les ayudará a hacer cumplir reglas y estándares en todas las cuentas de este entorno?",
        "Options": {
            "1": "Usar AWS Organizations e implementar Políticas de Control de Servicio (SCP) para hacer cumplir reglas entre cuentas.",
            "2": "Usar AWS Control Tower para automatizar la configuración y gestión del entorno multi-cuenta, utilizando guardrails para hacer cumplir reglas y monitorear el cumplimiento.",
            "3": "Usar AWS Config para cada cuenta y configurar manualmente reglas de cumplimiento para monitorear recursos.",
            "4": "Usar AWS CloudFormation para desplegar un entorno personalizado e implementar políticas de IAM para gestionar estándares de seguridad entre cuentas."
        },
        "Correct Answer": "Usar AWS Control Tower para automatizar la configuración y gestión del entorno multi-cuenta, utilizando guardrails para hacer cumplir reglas y monitorear el cumplimiento.",
        "Explanation": "AWS Control Tower está diseñado específicamente para ayudar a las organizaciones a configurar y gobernar un entorno multi-cuenta de AWS seguro basado en las mejores prácticas de AWS. Proporciona una forma simplificada de crear cuentas, aplicar gobernanza y asegurar el cumplimiento a través de guardrails preconfigurados, que son reglas que ayudan a hacer cumplir políticas entre cuentas. Este servicio automatiza el proceso de configuración e incluye capacidades de monitoreo para asegurar que el entorno se adhiera a los estándares definidos, lo que lo convierte en la mejor opción para los requisitos de la empresa.",
        "Other Options": [
            "Usar AWS Organizations con Políticas de Control de Servicio (SCP) es un enfoque válido para gestionar permisos entre cuentas, pero no proporciona las características de automatización y gobernanza integrales que ofrece AWS Control Tower. Las SCP se centran más en controlar el acceso que en hacer cumplir el cumplimiento y el monitoreo.",
            "AWS Config es un servicio que permite evaluar, auditar y evaluar las configuraciones de sus recursos de AWS. Aunque puede ayudar con el monitoreo de cumplimiento, requiere la configuración manual de reglas para cada cuenta, lo que no se alinea con el deseo de la empresa de una configuración automatizada y un cumplimiento consistente entre múltiples cuentas.",
            "AWS CloudFormation es un servicio para desplegar infraestructura como código, que puede ayudar a configurar entornos de manera consistente. Sin embargo, no proporciona inherentemente características de gobernanza o monitoreo de cumplimiento entre múltiples cuentas. Las políticas de IAM pueden gestionar estándares de seguridad, pero no hacen cumplir el cumplimiento ni proporcionan capacidades de monitoreo automatizado como lo hace AWS Control Tower."
        ]
    },
    {
        "Question Number": "63",
        "Situation": "Una plataforma de streaming de medios, MediaStream, depende en gran medida de AWS para soportar millones de usuarios concurrentes en todo el mundo. Están preocupados por el riesgo de ataques de Denegación de Servicio Distribuida (DDoS), que podrían interrumpir su servicio de streaming. MediaStream quiere una solución que ofrezca protección básica contra DDoS, así como una capa avanzada para protección adicional y visibilidad en tiempo real de los eventos DDoS. Están considerando AWS Shield Standard y AWS Shield Advanced para asegurar su aplicación contra posibles ataques en varias capas, incluidas las capas de red, transporte y aplicación. MediaStream también quiere protección contra posibles implicaciones de costos si un ataque aumenta significativamente su uso de AWS.",
        "Question": "¿Cuál de las siguientes afirmaciones describe mejor la diferencia entre AWS Shield Standard y AWS Shield Advanced en términos de protección y características proporcionadas para la mitigación de DDoS en la infraestructura de AWS?",
        "Options": {
            "1": "AWS Shield Standard proporciona protección básica contra DDoS de forma gratuita a todos los clientes de AWS, centrándose principalmente en la protección en el perímetro de los servicios de AWS, pero no incluye participación proactiva ni capacidades avanzadas de detección basada en salud.",
            "2": "AWS Shield Advanced es un servicio gratuito disponible para todos los clientes de AWS, que ofrece protección mejorada contra ataques de capa de aplicación (L7) e integra estrechamente con AWS WAF para proporcionar protección de costos y visibilidad en tiempo real de los eventos DDoS.",
            "3": "AWS Shield Standard es un servicio de pago que proporciona protección automática contra ataques DDoS de capa de aplicación (L7) en todos los servicios de AWS, incluida la participación proactiva del equipo de respuesta de AWS Shield.",
            "4": "AWS Shield Advanced se habilita automáticamente para todos los recursos de AWS con IPs Elásticas y proporciona configuraciones de ACL web gratuitas, protección proactiva de costos y respuesta inmediata del equipo de respuesta de AWS Shield para todos los eventos DDoS en todas las regiones de AWS."
        },
        "Correct Answer": "AWS Shield Standard proporciona protección básica contra DDoS de forma gratuita a todos los clientes de AWS, centrándose principalmente en la protección en el perímetro de los servicios de AWS, pero no incluye participación proactiva ni capacidades avanzadas de detección basada en salud.",
        "Explanation": "AWS Shield Standard es, de hecho, un servicio gratuito que ofrece protección básica contra DDoS a todos los clientes de AWS. Protege principalmente contra ataques DDoS comunes y más frecuentes en las capas de red y transporte, centrándose en el perímetro de los servicios de AWS. Sin embargo, no proporciona características avanzadas como la participación proactiva del equipo de respuesta de AWS Shield o capacidades avanzadas de detección basada en salud, que solo están disponibles con AWS Shield Advanced. Esto hace que la afirmación sea precisa al describir las limitaciones de AWS Shield Standard en comparación con AWS Shield Advanced.",
        "Other Options": [
            "AWS Shield Advanced no es un servicio gratuito; es un servicio de pago que proporciona protección mejorada contra DDoS, incluidos ataques de capa de aplicación (L7) e integra con AWS WAF. Sin embargo, ofrece protección de costos y visibilidad en tiempo real, pero no está disponible de forma gratuita para todos los clientes de AWS.",
            "AWS Shield Standard no es un servicio de pago; es gratuito y no proporciona protección automática contra ataques DDoS de capa de aplicación (L7). La participación proactiva del equipo de respuesta de AWS Shield es una característica de AWS Shield Advanced, no de Standard.",
            "AWS Shield Advanced no se habilita automáticamente para todos los recursos de AWS con IPs Elásticas; debe suscribirse. Además, aunque proporciona protección proactiva de costos y respuesta inmediata del equipo de respuesta de AWS Shield, no ofrece configuraciones de ACL web gratuitas como parte de su servicio."
        ]
    },
    {
        "Question Number": "64",
        "Situation": "Una empresa está construyendo una aplicación basada en microservicios utilizando contenedores y quiere gestionar y orquestar estos contenedores de manera escalable en AWS. La empresa está considerando Amazon ECS y Amazon EKS para la orquestación, pero no está segura de qué servicio se adaptará mejor a sus necesidades. Requieren un control detallado sobre la orquestación, redes personalizadas y gestión de contenedores.",
        "Question": "¿Cuál de las siguientes opciones describe mejor cuándo debería la empresa usar Amazon EKS en lugar de Amazon ECS?",
        "Options": {
            "1": "Usa Amazon EKS si la empresa requiere características nativas de Kubernetes, como orquestación personalizada y capacidades de red complejas.",
            "2": "Usa Amazon ECS para todas las necesidades de orquestación de contenedores, ya que es más simple y rentable para aplicaciones en contenedores.",
            "3": "Usa Amazon EKS si la empresa necesita un servicio de contenedores completamente gestionado que maneje automáticamente la escalabilidad y el balanceo de carga para todas las cargas de trabajo en contenedores.",
            "4": "Usa Amazon ECS solo si la empresa está utilizando contenedores sin servidor, ya que Amazon EKS no admite cargas de trabajo sin servidor."
        },
        "Correct Answer": "Usa Amazon EKS si la empresa requiere características nativas de Kubernetes, como orquestación personalizada y capacidades de red complejas.",
        "Explanation": "Amazon EKS (Elastic Kubernetes Service) está diseñado para usuarios que necesitan las características avanzadas y la flexibilidad que ofrece Kubernetes. Esto incluye un control detallado sobre la orquestación, la capacidad de implementar soluciones de red personalizadas y el uso de herramientas y API nativas de Kubernetes. Si la empresa busca estas capacidades, EKS es la mejor opción frente a ECS (Elastic Container Service), que es más simple y tiene un enfoque más definido en su orquestación de contenedores.",
        "Other Options": [
            "Esta opción es incorrecta porque, aunque Amazon EKS proporciona características nativas de Kubernetes, no se trata únicamente de simplicidad o rentabilidad. ECS es más simple y puede ser más rentable para necesidades de orquestación de contenedores sencillas, pero carece de las características avanzadas que ofrece EKS.",
            "Esta opción es engañosa porque, aunque Amazon EKS ofrece un servicio gestionado, no maneja automáticamente la escalabilidad y el balanceo de carga para todas las cargas de trabajo de la misma manera que lo hace ECS. EKS requiere más configuración y comprensión de Kubernetes para lograr resultados similares.",
            "Esta opción es incorrecta porque Amazon EKS sí admite cargas de trabajo sin servidor a través de AWS Fargate, al igual que Amazon ECS. Por lo tanto, la afirmación de que EKS no admite cargas de trabajo sin servidor es falsa."
        ]
    },
    {
        "Question Number": "65",
        "Situation": "Una empresa está diseñando una arquitectura de Nube Privada Virtual (VPC) en AWS para soportar una aplicación de múltiples niveles. La arquitectura necesita tres zonas de disponibilidad (AZ) con una zona adicional de reserva para el crecimiento futuro. Cada zona de disponibilidad tendrá subredes separadas para los niveles web, de aplicación y de base de datos, además de una subred extra reservada para futuras expansiones. La empresa quiere asegurarse de que haya suficientes direcciones IP para escalar la aplicación en cada nivel.",
        "Question": "¿Cuál de las siguientes configuraciones de VPC satisfará mejor estos requisitos mientras permite el crecimiento futuro?",
        "Options": {
            "1": "Usa un bloque CIDR /28 para la VPC y divide cada zona de disponibilidad en subredes /30 para maximizar el uso de direcciones IP dentro de cada subred.",
            "2": "Configura un bloque CIDR /16 para la VPC, proporcionando un total de 65,536 direcciones IP, y asigna subredes /20 para cada nivel en cada zona de disponibilidad para asegurar suficientes direcciones IP por nivel.",
            "3": "Elige un bloque CIDR /24 para la VPC, proporcionando un total de 256 direcciones IP, y usa subredes /26 para cada nivel en cada zona de disponibilidad para optimizar el espacio de direcciones.",
            "4": "Configura un bloque CIDR /22 para la VPC para soportar 1,024 direcciones IP, dividiendo cada zona de disponibilidad en subredes /25 para cada nivel para equilibrar el espacio de direcciones y la escalabilidad."
        },
        "Correct Answer": "Configura un bloque CIDR /16 para la VPC, proporcionando un total de 65,536 direcciones IP, y asigna subredes /20 para cada nivel en cada zona de disponibilidad para asegurar suficientes direcciones IP por nivel.",
        "Explanation": "Elegir un bloque CIDR /16 para la VPC permite un amplio espacio de direcciones de 65,536 direcciones IP, lo cual es más que suficiente para la aplicación de múltiples niveles que requiere subredes separadas para los niveles web, de aplicación y de base de datos en tres zonas de disponibilidad, además de una subred adicional para el crecimiento futuro. Al asignar subredes /20, cada subred tendrá 4,096 direcciones IP (2^(32-20)), proporcionando un amplio margen para escalar dentro de cada nivel mientras se permite la expansión futura.",
        "Other Options": [
            "Usar un bloque CIDR /28 para la VPC solo proporciona 16 direcciones IP, lo cual es demasiado limitado para una aplicación de múltiples niveles que requiere múltiples subredes en tres zonas de disponibilidad. Dividir cada AZ en subredes /30 reduciría aún más el número de direcciones IP utilizables, haciendo que esta opción sea impráctica.",
            "Un bloque CIDR /24 proporciona solo 256 direcciones IP, lo cual es insuficiente para los requisitos de la aplicación. Usar subredes /26 solo permitiría 64 direcciones IP por subred, lo cual no es suficiente para los niveles web, de aplicación y de base de datos, especialmente considerando la necesidad de crecimiento futuro.",
            "Configurar un bloque CIDR /22 permite 1,024 direcciones IP, lo cual es mejor que las opciones anteriores, pero aún puede no proporcionar suficiente espacio para escalar. Dividir cada zona de disponibilidad en subredes /25 daría 128 direcciones IP por subred, lo cual podría ser limitante para los niveles de la aplicación, especialmente a medida que la empresa planea una expansión futura."
        ]
    }
]