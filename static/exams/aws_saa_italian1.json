[
    {
        "Question Number": "1",
        "Situation": "Un'azienda sta adottando un'infrastruttura immutabile per il deployment delle proprie applicazioni. Vuole assicurarsi che tutte le modifiche all'infrastruttura vengano effettuate sostituendo le risorse invece di modificarle in loco, puntando a una maggiore coerenza e a rollback più semplici.",
        "Question": "Quale delle seguenti opzioni descrive meglio il principio dell'infrastruttura immutabile e i suoi benefici? (Scegli due.)",
        "Options": {
            "1": "L'infrastruttura immutabile garantisce che i server e le risorse vengano sempre modificati in loco, evitando la necessità di sostituire le risorse.",
            "2": "L'infrastruttura immutabile prevede la sostituzione totale di server o componenti dell'infrastruttura quando sono necessarie modifiche, assicurando che nessuna modifica venga applicata alle istanze in esecuzione e facilitando rollback più semplici.",
            "3": "L'infrastruttura immutabile elimina la necessità di controllo delle versioni, poiché ogni aggiornamento viene automaticamente integrato nelle risorse esistenti.",
            "4": "L'infrastruttura immutabile si basa su configurazioni manuali dei server, assicurando che non venga utilizzata alcuna automazione durante il processo di deployment.",
            "5": "L'infrastruttura immutabile migliora la coerenza garantendo che tutti i deployment siano identici e riduce la deriva di configurazione."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "L'infrastruttura immutabile prevede la sostituzione totale di server o componenti dell'infrastruttura quando sono necessarie modifiche, assicurando che nessuna modifica venga applicata alle istanze in esecuzione e facilitando rollback più semplici.",
            "L'infrastruttura immutabile migliora la coerenza garantendo che tutti i deployment siano identici e riduce la deriva di configurazione."
        ],
        "Explanation": "L'infrastruttura immutabile è un principio in cui i server o i componenti dell'infrastruttura vengono sostituiti completamente quando sono necessarie modifiche, piuttosto che modificarli in loco. Questo assicura che nessuna modifica venga applicata alle istanze in esecuzione, facilitando rollback più semplici. Inoltre, migliora la coerenza garantendo che tutti i deployment siano identici, riducendo così la deriva di configurazione. Questo approccio può ridurre significativamente il rischio di incoerenze ed errori nell'infrastruttura, rendendola più affidabile e più facile da gestire.",
        "Other Options": [
            "L'infrastruttura immutabile non prevede la modifica di server e risorse in loco. Invece, prevede la loro sostituzione totale quando sono necessarie modifiche.",
            "L'infrastruttura immutabile non elimina la necessità di controllo delle versioni. Infatti, il controllo delle versioni è cruciale in un'infrastruttura immutabile per tenere traccia di tutte le diverse versioni dei componenti dell'infrastruttura.",
            "L'infrastruttura immutabile non si basa su configurazioni manuali dei server. Invece, spesso coinvolge l'automazione per garantire che tutti i deployment siano identici e per facilitare la sostituzione di server o componenti dell'infrastruttura quando sono necessarie modifiche."
        ]
    },
    {
        "Question Number": "2",
        "Situation": "Un'azienda di vendita al dettaglio gestisce un sito web di e-commerce su istanze Amazon EC2 dietro un Application Load Balancer. L'azienda sperimenta modelli di traffico fluttuanti e vuole assicurarsi che l'applicazione si scaldi automaticamente per gestire carichi variabili, minimizzando i costi.",
        "Question": "Quali configurazioni dovrebbe implementare un architetto di soluzioni per soddisfare questi requisiti? (Scegli due.)",
        "Options": {
            "1": "Configurare un gruppo di Auto Scaling con un numero fisso di istanze EC2 e utilizzare le istanze riservate per risparmiare sui costi.",
            "2": "Utilizzare Spot Instances con un gruppo di Auto Scaling per gestire il traffico variabile.",
            "3": "Impostare un gruppo di Auto Scaling con politiche di scaling basate sul tracciamento degli obiettivi in base all'utilizzo della CPU.",
            "4": "Distribuire l'applicazione su AWS Elastic Beanstalk con politiche di scaling manuali.",
            "5": "Implementare lo scaling predittivo utilizzando Amazon CloudWatch per prevedere il traffico e regolare proattivamente la capacità."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Utilizzare Spot Instances con un gruppo di Auto Scaling per gestire il traffico variabile.",
            "Impostare un gruppo di Auto Scaling con politiche di scaling basate sul tracciamento degli obiettivi in base all'utilizzo della CPU."
        ],
        "Explanation": "Le Spot Instances con un gruppo di Auto Scaling sono una scelta economica per gestire il traffico variabile perché consentono di sfruttare la capacità EC2 inutilizzata nel cloud AWS. Le Spot Instances sono disponibili con uno sconto fino al 90% rispetto ai prezzi On-Demand. Un gruppo di Auto Scaling con politiche di scaling basate sul tracciamento degli obiettivi in base all'utilizzo della CPU consente all'applicazione di scalare automaticamente in base alla domanda. Quando la domanda aumenta, nuove istanze vengono aggiunte automaticamente e quando la domanda diminuisce, le istanze vengono rimosse automaticamente. Questo assicura che si utilizzi (e si paghi) solo ciò di cui si ha bisogno.",
        "Other Options": [
            "Configurare un gruppo di Auto Scaling con un numero fisso di istanze EC2 e utilizzare istanze riservate per risparmiare sui costi non è la migliore opzione per gestire il traffico variabile perché non consente scaling automatico in base alla domanda. Le istanze riservate offrono un risparmio rispetto alle istanze On-Demand, ma non forniscono la flessibilità necessaria per modelli di traffico fluttuanti.",
            "Distribuire l'applicazione su AWS Elastic Beanstalk con politiche di scaling manuali non è la migliore opzione perché non consente scaling automatico. Lo scaling manuale richiede intervento manuale per aggiungere o rimuovere istanze, il che non è ideale per gestire modelli di traffico fluttuanti.",
            "Implementare lo scaling predittivo utilizzando Amazon CloudWatch per prevedere il traffico e regolare proattivamente la capacità può essere una buona opzione per alcuni casi d'uso, ma non è la soluzione più economica per questo particolare scenario. Lo scaling predittivo utilizza algoritmi di machine learning per prevedere i modelli di traffico futuri e regolare la capacità di conseguenza, il che può essere più costoso rispetto ad altre opzioni."
        ]
    },
    {
        "Question Number": "3",
        "Situation": "Un'azienda sta gestendo un'applicazione web che sperimenta traffico fluttuante. Deve assicurarsi che l'applicazione possa gestire un alto traffico durante le ore di punta senza sovraprovisionare le risorse.",
        "Question": "Quale strategia di scaling dovrebbe utilizzare l'azienda per gestire al meglio la variabilità del traffico e l'efficacia dei costi?",
        "Options": {
            "1": "Utilizzare lo scaling orizzontale aggiungendo più istanze EC2 dietro un load balancer per distribuire il traffico, assicurando che le risorse scalino in risposta ai cambiamenti nella domanda.",
            "2": "Utilizzare lo scaling verticale aumentando la dimensione delle istanze EC2 per gestire più traffico, anche se questo potrebbe non fornire tanta flessibilità durante i picchi di traffico.",
            "3": "Utilizzare una combinazione di scaling orizzontale e verticale, dove lo scaling orizzontale è utilizzato per piccole variazioni di traffico e lo scaling verticale è utilizzato per gestire picchi estremi.",
            "4": "Utilizzare lo scaling manuale, regolando le dimensioni delle istanze EC2 e il numero di istanze in base alle previsioni dei modelli di traffico."
        },
        "Correct Answer": "Utilizzare lo scaling orizzontale aggiungendo più istanze EC2 dietro un load balancer per distribuire il traffico, assicurando che le risorse scalino in risposta ai cambiamenti nella domanda.",
        "Explanation": "Lo scaling orizzontale è la strategia più efficace per gestire il traffico fluttuante perché consente all'applicazione di aggiungere o rimuovere istanze in base alla domanda in tempo reale. Questo approccio assicura che durante le ore di punta, possano essere provisionate istanze EC2 aggiuntive per gestire il traffico aumentato, mentre durante le ore di bassa affluenza, le istanze possono essere ridotte per risparmiare sui costi. Questa capacità di scaling dinamico fornisce sia flessibilità che efficacia in termini di costi, poiché le risorse vengono utilizzate solo quando necessario.",
        "Other Options": [
            "Lo scaling verticale comporta l'aumento della dimensione delle istanze EC2 esistenti per gestire più traffico. Sebbene questo possa essere efficace, ha limitazioni in termini di flessibilità e può portare a inattività durante le operazioni di scaling. Inoltre, esiste un limite massimo di dimensione per le istanze, che potrebbe non essere sufficiente durante picchi di traffico estremi.",
            "Una combinazione di scaling orizzontale e verticale può fornire vantaggi, ma complica la strategia di scaling e potrebbe non essere così efficiente come utilizzare solo lo scaling orizzontale. Lo scaling orizzontale è generalmente preferito per gestire il traffico variabile perché consente un controllo più granulare sull'allocazione delle risorse.",
            "Lo scaling manuale si basa su previsioni dei modelli di traffico, che possono essere imprecise. Questo approccio non fornisce l'agilità necessaria per rispondere a cambiamenti improvvisi nel traffico, portando a potenziali problemi di prestazioni durante picchi imprevisti e costi non necessari durante periodi di basso traffico."
        ]
    },
    {
        "Question Number": "4",
        "Situation": "Un'organizzazione sanitaria deve garantire che tutti i dati memorizzati in Amazon RDS per PostgreSQL siano crittografati a riposo e che le chiavi di crittografia siano gestite in modo sicuro. L'organizzazione deve conformarsi a rigorosi requisiti normativi per la protezione dei dati.",
        "Question": "Quale soluzione soddisferà questi requisiti?",
        "Options": {
            "1": "Abilitare la crittografia a riposo utilizzando la crittografia di Amazon RDS e gestire le chiavi con AWS Key Management Service (KMS).",
            "2": "Utilizzare Amazon S3 per memorizzare i backup del database e abilitare la crittografia S3.",
            "3": "Implementare SSL/TLS per i dati in transito e fare affidamento sulla crittografia predefinita di RDS.",
            "4": "Crittografare i dati all'interno dell'applicazione prima di memorizzarli nel database RDS."
        },
        "Correct Answer": "Abilitare la crittografia a riposo utilizzando la crittografia di Amazon RDS e gestire le chiavi con AWS Key Management Service (KMS).",
        "Explanation": "Questa opzione affronta direttamente il requisito di crittografare i dati a riposo in Amazon RDS per PostgreSQL. Amazon RDS fornisce capacità di crittografia integrate che possono essere abilitate per garantire che tutti i dati memorizzati nel database siano crittografati. Inoltre, utilizzare AWS Key Management Service (KMS) consente una gestione sicura delle chiavi di crittografia, fondamentale per la conformità ai requisiti normativi riguardanti la protezione dei dati. Questa soluzione garantisce sia la crittografia che la gestione sicura delle chiavi in modo fluido.",
        "Other Options": [
            "Utilizzare Amazon S3 per memorizzare i backup del database e abilitare la crittografia S3 non soddisfa il requisito di crittografare i dati a riposo all'interno del database RDS stesso. Sebbene la crittografia S3 sia utile per i backup, non affronta la crittografia dei dati del database attivo memorizzati in RDS.",
            "Implementare SSL/TLS per i dati in transito è importante per proteggere i dati mentre viaggiano tra il client e il database, ma non fornisce crittografia per i dati a riposo. Inoltre, fare affidamento sulla crittografia predefinita di RDS potrebbe non soddisfare requisiti normativi specifici, poiché non consente una gestione personalizzata delle chiavi o controlli di conformità.",
            "Crittografare i dati all'interno dell'applicazione prima di memorizzarli nel database RDS è un approccio valido, ma richiede uno sforzo di sviluppo aggiuntivo e potrebbe complicare l'accesso e la gestione dei dati. Inoltre, non utilizza le funzionalità di crittografia integrate di RDS, progettate per semplificare la conformità alle normative sulla protezione dei dati."
        ]
    },
    {
        "Question Number": "5",
        "Situation": "Un'azienda sta migrando la propria applicazione on-premises su AWS. L'applicazione è composta da un server web, un server applicativo e un server di database. L'azienda vuole assicurarsi che il server di database non sia accessibile direttamente da Internet e possa essere accessibile solo dal server applicativo.",
        "Question": "Quali configurazioni di rete soddisferanno questi requisiti? (Scegli due.)",
        "Options": {
            "1": "Posizionare il server web e il server applicativo in una subnet pubblica e il server di database in una subnet privata. Configurare i gruppi di sicurezza per consentire il traffico solo dal server applicativo al server di database.",
            "2": "Posizionare tutti i server in una subnet pubblica e utilizzare le ACL di rete per limitare l'accesso al server di database.",
            "3": "Posizionare il server web in una subnet pubblica e i server applicativo e di database in subnet private separate. Utilizzare i gruppi di sicurezza per consentire il traffico solo dal server web al server applicativo e dal server applicativo al server di database.",
            "4": "Posizionare il server web e il server di database in una subnet pubblica e il server applicativo in una subnet privata. Utilizzare i gruppi di sicurezza per consentire il traffico solo dal server web al server applicativo.",
            "5": "Utilizzare AWS Transit Gateway per gestire il routing tra le subnet e limitare l'accesso al server di database tramite tabelle di routing."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Posizionare il server web e il server applicativo in una subnet pubblica e il server di database in una subnet privata. Configurare i gruppi di sicurezza per consentire il traffico solo dal server applicativo al server di database.",
            "Posizionare il server web in una subnet pubblica e i server applicativo e di database in subnet private separate. Utilizzare i gruppi di sicurezza per consentire il traffico solo dal server web al server applicativo e dal server applicativo al server di database."
        ],
        "Explanation": "Le risposte corrette sono opzioni che posizionano il server web e il server applicativo in una subnet pubblica, e il server di database in una subnet privata. Questa configurazione assicura che il server di database non sia accessibile direttamente da Internet, come richiesto. I gruppi di sicurezza vengono quindi utilizzati per controllare il traffico, consentendo solo al server applicativo di accedere al server di database. Nella seconda opzione corretta, i server applicativo e di database sono in subnet private separate, il che aggiunge un ulteriore livello di sicurezza e isolamento.",
        "Other Options": [
            "Posizionare tutti i server in una subnet pubblica e utilizzare le ACL di rete per limitare l'accesso al server di database non è una buona pratica. Espone tutti i server a Internet, aumentando il rischio di violazioni della sicurezza.",
            "Posizionare il server web e il server di database in una subnet pubblica e il server applicativo in una subnet privata non soddisfa il requisito che il server di database sia inaccessibile da Internet.",
            "Utilizzare AWS Transit Gateway per gestire il routing tra le subnet e limitare l'accesso al server di database tramite tabelle di routing non è il metodo più efficiente o sicuro. Può essere complesso da gestire e non fornisce lo stesso livello di sicurezza dell'utilizzo di subnet private e pubbliche con gruppi di sicurezza."
        ]
    },
    {
        "Question Number": "6",
        "Situation": "Un'azienda di vendita al dettaglio gestisce un sito web di e-commerce ospitato su istanze Amazon EC2 dietro un Application Load Balancer. Il sito web presenta modelli di traffico fluttuanti, specialmente durante le stagioni di shopping di punta, e l'azienda desidera garantire che l'applicazione si scaldi automaticamente per gestire carichi variabili senza incorrere in costi inutili durante i periodi di bassa affluenza. Il team sta cercando una configurazione ottimale per supportare lo scaling automatico riducendo al minimo i costi dell'infrastruttura.",
        "Question": "Quale configurazione dovrebbe implementare un architetto di soluzioni per soddisfare questi requisiti?",
        "Options": {
            "1": "Configurare un gruppo di Auto Scaling con un numero fisso di istanze EC2 e riservare capacità con Reserved Instances per risparmi sui costi a lungo termine",
            "2": "Utilizzare Spot Instances all'interno di un gruppo di Auto Scaling per gestire il traffico fluttuante, consentendo alle istanze di scalare durante i carichi di punta riducendo i costi",
            "3": "Impostare un gruppo di Auto Scaling con politiche di scaling basate sul tracciamento degli obiettivi in base all'utilizzo della CPU per regolare dinamicamente la capacità in base alla domanda",
            "4": "Distribuire l'applicazione su AWS Elastic Beanstalk e utilizzare politiche di scaling manuale per aggiungere o rimuovere istanze man mano che i modelli di traffico cambiano"
        },
        "Correct Answer": "Impostare un gruppo di Auto Scaling con politiche di scaling basate sul tracciamento degli obiettivi in base all'utilizzo della CPU per regolare dinamicamente la capacità in base alla domanda",
        "Explanation": "Impostare un gruppo di Auto Scaling con politiche di scaling basate sul tracciamento degli obiettivi consente all'applicazione di regolare automaticamente il numero di istanze EC2 in base alla domanda in tempo reale, specificamente all'utilizzo della CPU in questo caso. Questa configurazione garantisce che l'applicazione possa scalare durante i periodi di traffico intenso per gestire carichi aumentati e scalare durante i periodi di bassa affluenza per ridurre i costi. Le politiche di scaling basate sul tracciamento degli obiettivi sono semplici da implementare e gestire, fornendo un equilibrio tra prestazioni ed efficienza dei costi.",
        "Other Options": [
            "Configurare un gruppo di Auto Scaling con un numero fisso di istanze EC2 non consente uno scaling dinamico in base ai modelli di traffico. Sebbene le Reserved Instances possano fornire risparmi sui costi per un utilizzo a lungo termine, questo approccio non affronta efficacemente le esigenze di traffico fluttuante, poiché non si scalano durante i periodi di bassa affluenza.",
            "Utilizzare Spot Instances all'interno di un gruppo di Auto Scaling può ridurre i costi, ma le Spot Instances possono essere terminate da AWS con poco preavviso, il che può portare a instabilità dell'applicazione durante i carichi di punta. Questa opzione non è ideale per un'azienda di vendita al dettaglio che richiede disponibilità costante durante le stagioni di shopping ad alta affluenza.",
            "Distribuire l'applicazione su AWS Elastic Beanstalk con politiche di scaling manuale non fornisce lo scaling automatico necessario per i modelli di traffico fluttuante. Lo scaling manuale richiede intervento umano per regolare il numero di istanze, il che può portare a ritardi e potenziali problemi di prestazioni durante i periodi di punta."
        ]
    },
    {
        "Question Number": "7",
        "Situation": "Un'azienda media ha più VPC in diversi account AWS e desidera abilitare una comunicazione privata e conveniente tra le VPC senza passare attraverso Internet pubblico. Vuole anche ridurre i costi di trasferimento dati associati a questa configurazione.",
        "Question": "Quale configurazione di rete sarebbe la soluzione più conveniente?",
        "Options": {
            "1": "Utilizzare VPC Peering tra ciascuna VPC",
            "2": "Utilizzare AWS Transit Gateway per la comunicazione centralizzata tra VPC",
            "3": "Instradare il traffico attraverso NAT gateways per un accesso sicuro",
            "4": "Stabilire una connessione VPN per ciascuna VPC"
        },
        "Correct Answer": "Utilizzare AWS Transit Gateway per la comunicazione centralizzata tra VPC",
        "Explanation": "AWS Transit Gateway è progettato per semplificare la gestione di più VPC e consente una comunicazione privata e conveniente tra di essi. Permette un modello hub-and-spoke in cui tutte le VPC possono connettersi a un gateway centrale, riducendo la complessità e i costi associati alla gestione di più connessioni di peering tra VPC. Inoltre, Transit Gateway può aiutare a ridurre i costi di trasferimento dati poiché consolida il traffico attraverso un unico punto piuttosto che richiedere più connessioni di peering, che possono comportare costi di trasferimento dati più elevati.",
        "Other Options": [
            "Utilizzare VPC Peering tra ciascuna VPC può diventare complesso e costoso man mano che aumenta il numero di VPC. Ogni VPC richiederebbe una connessione di peering separata, portando a un'esplosione combinatoria di connessioni e a un maggiore sovraccarico di gestione, oltre a potenziali costi di trasferimento dati più elevati a causa della natura del peering tra VPC.",
            "Instradare il traffico attraverso NAT gateways non è adatto per la comunicazione VPC-to-VPC poiché i NAT gateways sono utilizzati principalmente per l'accesso a Internet in uscita da subnet private. Questa opzione non faciliterebbe la comunicazione diretta tra le VPC e comporterebbe costi aggiuntivi per il trasferimento dati attraverso il NAT gateway.",
            "Stabilire una connessione VPN per ciascuna VPC sarebbe inefficiente e costoso, specialmente quando si gestiscono più VPC. Ogni connessione VPN comporta costi e aggiunge complessità all'architettura di rete. Inoltre, le connessioni VPN hanno tipicamente una larghezza di banda inferiore rispetto ad altre opzioni e possono introdurre latenza."
        ]
    },
    {
        "Question Number": "8",
        "Situation": "Un'azienda sta distribuendo un'applicazione web che deve essere protetta da attacchi comuni basati sul web come SQL injection e cross-site scripting.",
        "Question": "Quale servizio AWS dovrebbe essere utilizzato per fornire questa protezione?",
        "Options": {
            "1": "AWS Shield",
            "2": "AWS WAF (Web Application Firewall)",
            "3": "Amazon Macie",
            "4": "Amazon GuardDuty"
        },
        "Correct Answer": "AWS WAF (Web Application Firewall)",
        "Explanation": "AWS WAF (Web Application Firewall) è specificamente progettato per proteggere le applicazioni web da attacchi comuni basati sul web come SQL injection e cross-site scripting (XSS). Consente agli utenti di creare regole che filtrano e monitorano le richieste HTTP in base a condizioni personalizzabili, bloccando efficacemente il traffico malevolo prima che raggiunga l'applicazione. Questo lo rende la scelta più adatta per lo scenario descritto.",
        "Other Options": [
            "AWS Shield è un servizio di protezione DDoS gestito che protegge le applicazioni dagli attacchi di Distributed Denial of Service. Sebbene fornisca importanti funzionalità di sicurezza, non affronta specificamente le vulnerabilità di SQL injection o cross-site scripting.",
            "Amazon Macie è un servizio di sicurezza e privacy dei dati che utilizza l'apprendimento automatico per scoprire, classificare e proteggere i dati sensibili memorizzati in AWS. Non è progettato per proteggere le applicazioni web dagli attacchi basati sul web.",
            "Amazon GuardDuty è un servizio di rilevamento delle minacce che monitora continuamente attività malevole e comportamenti non autorizzati per proteggere gli account e i carichi di lavoro AWS. Sebbene migliori la sicurezza complessiva, non fornisce specificamente protezione contro attacchi di SQL injection o cross-site scripting."
        ]
    },
    {
        "Question Number": "9",
        "Situation": "Un'azienda sta distribuendo un'applicazione web multi-tier su AWS. L'applicazione consiste in uno strato front-end su istanze Amazon EC2 e un database di backend su Amazon RDS. L'azienda richiede che il database non sia accessibile direttamente da Internet e che solo lo strato front-end possa comunicare con il database.",
        "Question": "Quale configurazione di rete dovrebbe implementare l'architetto di soluzioni?",
        "Options": {
            "1": "Posizionare sia lo strato front-end che quello del database in una subnet pubblica e utilizzare gruppi di sicurezza per limitare l'accesso.",
            "2": "Posizionare lo strato front-end in una subnet pubblica e lo strato del database in una subnet privata. Configurare i gruppi di sicurezza per consentire solo alle istanze front-end di comunicare con il database.",
            "3": "Posizionare entrambi gli strati in subnet private e utilizzare un NAT gateway per l'accesso a Internet.",
            "4": "Utilizzare un internet gateway e tabelle di routing per controllare l'accesso tra gli strati front-end e del database."
        },
        "Correct Answer": "Posizionare lo strato front-end in una subnet pubblica e lo strato del database in una subnet privata. Configurare i gruppi di sicurezza per consentire solo alle istanze front-end di comunicare con il database.",
        "Explanation": "Questa configurazione garantisce che il database non sia accessibile direttamente da Internet, poiché risiede in una subnet privata. Lo strato front-end, che si trova in una subnet pubblica, può comunicare con il database attraverso gruppi di sicurezza che consentono il traffico solo dalle istanze front-end. Questa configurazione rispetta le migliori pratiche per la sicurezza e l'architettura in AWS, garantendo che il database sia protetto dall'accesso esterno pur essendo accessibile allo strato dell'applicazione che ne ha bisogno.",
        "Other Options": [
            "Posizionare sia lo strato front-end che quello del database in una subnet pubblica espone il database a Internet, il che viola il requisito che il database non debba essere accessibile direttamente da Internet.",
            "Sebbene posizionare entrambi gli strati in subnet private migliori la sicurezza, non consente allo strato front-end di comunicare con il database a meno che non vengano implementate configurazioni aggiuntive (come un NAT gateway), il che è superfluo per questo scenario poiché il front-end deve essere pubblico.",
            "Utilizzare un internet gateway e tabelle di routing per controllare l'accesso esporrebbe il database a Internet, il che contraddice il requisito di mantenere il database inaccessibile da Internet."
        ]
    },
    {
        "Question Number": "10",
        "Situation": "Una piattaforma di e-commerce desidera migrare il proprio database su AWS ma vuole minimizzare le modifiche al codice. Il loro attuale database on-premises è PostgreSQL e necessitano di una soluzione gestita che supporti alta disponibilità e scalabilità in lettura.",
        "Question": "Quale motore di database su AWS soddisferebbe meglio questi requisiti?",
        "Options": {
            "1": "Amazon DynamoDB",
            "2": "Amazon Aurora con compatibilità PostgreSQL",
            "3": "Amazon RDS per MySQL",
            "4": "Amazon DocumentDB"
        },
        "Correct Answer": "Amazon Aurora con compatibilità PostgreSQL",
        "Explanation": "Amazon Aurora con compatibilità PostgreSQL è la scelta migliore per migrare da un database PostgreSQL on-premises perché è progettato per essere compatibile con PostgreSQL, il che significa che richiede modifiche minime al codice durante la migrazione. Aurora offre anche alta disponibilità attraverso le sue distribuzioni multi-AZ e capacità di scalabilità in lettura con repliche di lettura, rendendolo adatto per piattaforme di e-commerce che richiedono prestazioni affidabili e scalabilità.",
        "Other Options": [
            "Amazon DynamoDB è un servizio di database NoSQL che non supporta query SQL o le funzionalità di PostgreSQL su cui l'applicazione esistente si basa probabilmente. La migrazione a DynamoDB richiederebbe significative modifiche al codice e una completa ristrutturazione dell'applicazione.",
            "Amazon RDS per MySQL è un servizio di database relazionale gestito, ma è basato su MySQL, non su PostgreSQL. La migrazione a RDS per MySQL richiederebbe sostanziali modifiche al codice per adattare l'applicazione alla sintassi e alle funzionalità di MySQL, il che non è ideale per minimizzare le modifiche al codice.",
            "Amazon DocumentDB è un servizio di database documentale gestito compatibile con MongoDB. Come DynamoDB, non è compatibile con PostgreSQL e richiederebbe una completa revisione del modello di dati e del codice dell'applicazione, rendendolo inadatto per questo scenario di migrazione."
        ]
    },
    {
        "Question Number": "11",
        "Situation": "Un'azienda sta pianificando di utilizzare Amazon Aurora per una soluzione di database altamente disponibile. Vogliono assicurarsi di avere prestazioni di lettura rapide e una disponibilità migliorata senza dover gestire la fornitura di archiviazione.",
        "Question": "Quali caratteristiche di Amazon Aurora lo rendono adatto a questo requisito e come differisce la sua architettura da quella di RDS standard? (Scegli due.)",
        "Options": {
            "1": "Aurora utilizza un volume di cluster condiviso attraverso più Availability Zones (AZ) con archiviazione basata su SSD, consentendo alti IOPS e bassa latenza. Include un endpoint di cluster per le operazioni di scrittura e endpoint di lettura per distribuire il traffico di lettura tra le repliche, migliorando le prestazioni di lettura.",
            "2": "Aurora richiede archiviazione locale su ogni istanza, quindi l'archiviazione deve essere fornita e gestita separatamente, consentendo un migliore controllo sulla distribuzione dei dati.",
            "3": "Aurora scala automaticamente verticalmente all'interno di una singola AZ, senza necessità di più istanze o repliche, garantendo alta disponibilità con una configurazione minima.",
            "4": "Aurora si basa sulla gestione manuale dell'archiviazione, dove l'istanza primaria deve gestire sia il traffico di lettura che di scrittura, rendendola adatta solo per database più piccoli con requisiti di I/O ridotti.",
            "5": "L'architettura di Aurora separa il calcolo e l'archiviazione, consentendo la scalabilità indipendente di ciascuno e fornisce tolleranza agli errori integrata replicando i dati attraverso più AZ."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Aurora utilizza un volume di cluster condiviso attraverso più Availability Zones (AZ) con archiviazione basata su SSD, consentendo alti IOPS e bassa latenza. Include un endpoint di cluster per le operazioni di scrittura e endpoint di lettura per distribuire il traffico di lettura tra le repliche, migliorando le prestazioni di lettura.",
            "L'architettura di Aurora separa il calcolo e l'archiviazione, consentendo la scalabilità indipendente di ciascuno e fornisce tolleranza agli errori integrata replicando i dati attraverso più AZ."
        ],
        "Explanation": "Amazon Aurora è progettato per alta disponibilità e durabilità. Utilizza un volume di cluster condiviso che si estende su più Availability Zones, con ogni AZ che ha una copia del database. Questa architettura consente alti IOPS e bassa latenza, migliorando le prestazioni di lettura. Aurora separa anche il calcolo e l'archiviazione, il che consente a ciascuno di scalare in modo indipendente. Questa separazione fornisce anche tolleranza agli errori integrata replicando i dati attraverso più AZ.",
        "Other Options": [
            "Aurora non richiede archiviazione locale su ogni istanza. Invece, utilizza un volume di archiviazione condiviso che si estende su più AZ. Pertanto, l'archiviazione non deve essere fornita e gestita separatamente.",
            "Aurora non scala automaticamente verticalmente all'interno di una singola AZ. Invece, utilizza un'architettura distribuita che si estende su più AZ. Questa architettura consente alta disponibilità e tolleranza agli errori.",
            "Aurora non si basa sulla gestione manuale dell'archiviazione. Invece, gestisce automaticamente l'archiviazione, scalando su e giù secondo necessità. L'istanza primaria non deve gestire sia il traffico di lettura che di scrittura poiché Aurora fornisce un endpoint di cluster per le operazioni di scrittura e endpoint di lettura per le operazioni di lettura."
        ]
    },
    {
        "Question Number": "12",
        "Situation": "Un'applicazione di social media memorizza i post degli utenti e deve ottimizzare il suo database per operazioni di lettura ad alto volume e aggiornamenti frequenti. L'applicazione richiede anche analisi in tempo reale sull'engagement degli utenti.",
        "Question": "Quale soluzione di database dovrebbe raccomandare l'architetto delle soluzioni per gestire in modo efficiente i modelli di accesso misti?",
        "Options": {
            "1": "Amazon RDS per PostgreSQL con Read Replicas e Amazon Redshift per analisi.",
            "2": "Amazon DynamoDB con capacità fornita e DynamoDB Streams integrato con AWS Lambda per l'elaborazione in tempo reale.",
            "3": "Amazon Aurora Serverless con configurazione multi-master per gestire operazioni di lettura e scrittura.",
            "4": "Amazon S3 con Amazon Athena per interrogazioni e Amazon Kinesis per analisi in tempo reale."
        },
        "Correct Answer": "Amazon DynamoDB con capacità fornita e DynamoDB Streams integrato con AWS Lambda per l'elaborazione in tempo reale.",
        "Explanation": "Amazon DynamoDB è un servizio di database NoSQL completamente gestito che fornisce alte prestazioni sia per le operazioni di lettura che di scrittura, rendendolo ideale per applicazioni con modelli di accesso misti. La sua capacità fornita consente di scalare in base alle esigenze dell'applicazione, garantendo che possa gestire operazioni di lettura ad alto volume in modo efficiente. Inoltre, DynamoDB Streams può essere utilizzato per catturare le modifiche agli elementi nel database, che possono quindi attivare funzioni AWS Lambda per l'elaborazione e l'analisi in tempo reale sull'engagement degli utenti. Questa combinazione consente sia un'archiviazione dati efficiente che analisi in tempo reale, soddisfacendo efficacemente i requisiti dell'applicazione.",
        "Other Options": [
            "Amazon RDS per PostgreSQL con Read Replicas e Amazon Redshift per analisi non è la scelta migliore perché, sebbene RDS possa gestire operazioni di lettura con repliche di lettura, potrebbe non scalare altrettanto efficientemente per operazioni di scrittura ad alto volume rispetto a DynamoDB. Inoltre, l'uso di Redshift per analisi introduce latenza, poiché è ottimizzato per l'elaborazione batch piuttosto che per analisi in tempo reale.",
            "Amazon Aurora Serverless con configurazione multi-master potrebbe gestire operazioni di lettura e scrittura, ma potrebbe non fornire lo stesso livello di scalabilità e prestazioni per modelli di accesso ad alto volume come DynamoDB. Aurora è anche più adatta per dati relazionali e potrebbe non essere altrettanto efficiente per analisi in tempo reale rispetto all'integrazione di DynamoDB con Lambda.",
            "Amazon S3 con Amazon Athena per interrogazioni e Amazon Kinesis per analisi in tempo reale non è adatto perché S3 è principalmente un servizio di archiviazione e non supporta operazioni di scrittura ad alta frequenza in modo efficiente. Sebbene Kinesis possa gestire flussi di dati in tempo reale, la combinazione non fornisce una soluzione robusta per modelli di accesso misti come fa DynamoDB."
        ]
    },
    {
        "Question Number": "13",
        "Situation": "Una grande azienda con più dipartimenti utilizza account AWS separati per ogni unità aziendale e desidera monitorare e controllare i costi legati alla rete. Hanno bisogno di un modo per identificare e allocare le spese di rete, come VPC, gateway NAT e costi di trasferimento dati, ai dipartimenti appropriati per garantire una distribuzione e responsabilità dei costi accurata in tutta l'organizzazione.",
        "Question": "Quale funzionalità di gestione dei costi AWS li aiuterebbe meglio a raggiungere questo obiettivo?",
        "Options": {
            "1": "Abilitare i tag di allocazione dei costi per le risorse di rete, assegnando tag per dipartimento per allocare accuratamente i costi legati alla rete.",
            "2": "Impostare VPC separati per ogni dipartimento e monitorare i costi di ciascun VPC individualmente.",
            "3": "Utilizzare AWS Trusted Advisor per monitorare e ottimizzare regolarmente l'uso della rete e ottenere raccomandazioni per il risparmio sui costi.",
            "4": "Stabilire diverse Availability Zones per ogni dipartimento per tenere traccia dei costi di trasferimento dati per zona."
        },
        "Correct Answer": "Abilitare i tag di allocazione dei costi per le risorse di rete, assegnando tag per dipartimento per allocare accuratamente i costi legati alla rete.",
        "Explanation": "Abilitare i tag di allocazione dei costi per le risorse di rete consente all'azienda di categorizzare e monitorare i costi associati a dipartimenti specifici. Assegnando tag alle risorse come VPC, gateway NAT e trasferimento dati, l'organizzazione può generare report di costo dettagliati che riflettono le spese sostenute da ciascun dipartimento. Questo metodo fornisce un modo chiaro e organizzato per allocare i costi legati alla rete, garantendo responsabilità e trasparenza tra le unità aziendali.",
        "Other Options": [
            "Impostare VPC separati per ogni dipartimento può aiutare a isolare le risorse, ma non fornisce intrinsecamente un meccanismo per monitorare e allocare i costi. Senza tagging o una strategia di gestione dei costi, sarebbe difficile distribuire accuratamente i costi tra i dipartimenti.",
            "Utilizzare AWS Trusted Advisor può fornire informazioni e raccomandazioni per ottimizzare l'uso delle risorse e il risparmio sui costi, ma non allocano direttamente i costi a dipartimenti specifici. Si concentra più sulle migliori pratiche e sull'ottimizzazione dei costi piuttosto che sul monitoraggio e sull'allocazione dettagliata dei costi.",
            "Stabilire diverse Availability Zones per ogni dipartimento non si correla direttamente con il monitoraggio dei costi di trasferimento dati. Le Availability Zones riguardano principalmente la ridondanza e la disponibilità piuttosto che l'allocazione dei costi. I costi di trasferimento dati sono tipicamente sostenuti in base alle risorse utilizzate e alle loro configurazioni, non alle zone stesse."
        ]
    },
    {
        "Question Number": "14",
        "Situation": "Una startup sta sviluppando un dashboard in tempo reale che visualizza metriche live da vari dispositivi IoT. Il dashboard richiede un'ingestione rapida dei dati e accesso a bassa latenza alle ultime metriche per garantire aggiornamenti tempestivi. La soluzione deve anche gestire volumi di dati variabili man mano che il numero di dispositivi aumenta.",
        "Question": "Quale servizio AWS dovrebbe utilizzare l'architetto delle soluzioni per soddisfare questi requisiti di dimensione e velocità? (Scegli due.)",
        "Options": {
            "1": "Amazon S3 con Amazon Athena",
            "2": "Amazon Kinesis Data Streams",
            "3": "AWS Batch con Amazon EC2 Spot Instances",
            "4": "Amazon RDS con repliche di lettura",
            "5": "Amazon DynamoDB con DynamoDB Streams"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon Kinesis Data Streams",
            "Amazon DynamoDB con DynamoDB Streams"
        ],
        "Explanation": "Amazon Kinesis Data Streams è progettato per lo streaming di dati in tempo reale. Può catturare continuamente gigabyte di dati al secondo da centinaia di migliaia di fonti, rendendolo adatto per gestire l'ingestione rapida dei dati e l'accesso a bassa latenza richiesti dal dashboard. Amazon DynamoDB con DynamoDB Streams è anche una buona scelta poiché fornisce accesso a bassa latenza ai dati e può gestire carichi di traffico elevati, utile quando il numero di dispositivi aumenta. DynamoDB Streams cattura una sequenza temporale di modifiche a livello di elemento in qualsiasi tabella DynamoDB e memorizza questi dati per 24 ore.",
        "Other Options": [
            "Amazon S3 con Amazon Athena: Questa combinazione è più adatta per memorizzare e interrogare grandi dataset, non per l'ingestione di dati in tempo reale e accesso a bassa latenza.",
            "AWS Batch con Amazon EC2 Spot Instances: Questo è più adatto per lavori di elaborazione batch e non per l'ingestione di dati in tempo reale e accesso a bassa latenza.",
            "Amazon RDS con repliche di lettura: Sebbene questo possa aiutare a distribuire il traffico di lettura, non è progettato per l'ingestione di dati in tempo reale o per gestire volumi di dati variabili provenienti da potenzialmente migliaia di dispositivi."
        ]
    },
    {
        "Question Number": "15",
        "Situation": "Un'applicazione di social media ha un alto volume di richieste di lettura, con utenti che recuperano frequentemente informazioni sui profili e feed di notizie. L'applicazione sta attualmente affrontando problemi di latenza poiché interroga direttamente un database Amazon Aurora per ogni richiesta di lettura. Il team di sviluppo vuole migliorare le prestazioni di lettura e ridurre il carico sul database in modo economico, ed è aperto a fare piccole modifiche all'applicazione.",
        "Question": "Quale soluzione dovrebbe raccomandare l'architetto delle soluzioni?",
        "Options": {
            "1": "Implementare Amazon ElastiCache con Redis per memorizzare nella cache i dati frequentemente accessibili e ridurre le interrogazioni al database.",
            "2": "Abilitare repliche di lettura sul database Amazon Aurora per distribuire il carico di lettura.",
            "3": "Utilizzare Amazon RDS Proxy per raggruppare e condividere le connessioni al database per migliorare le prestazioni.",
            "4": "Memorizzare i dati frequentemente accessibili in Amazon S3 e accedervi direttamente dall'applicazione."
        },
        "Correct Answer": "Implementare Amazon ElastiCache con Redis per memorizzare nella cache i dati frequentemente accessibili e ridurre le interrogazioni al database.",
        "Explanation": "Implementare Amazon ElastiCache con Redis è la soluzione più efficace per migliorare le prestazioni di lettura e ridurre il carico sul database Amazon Aurora. Memorizzando nella cache i dati frequentemente accessibili, come profili utente e feed di notizie, l'applicazione può servire le richieste di lettura direttamente dalla cache invece di interrogare il database per ogni richiesta. Questo riduce significativamente la latenza e il carico sul database, portando a risparmi sui costi e a un'esperienza utente migliorata. ElastiCache è progettato per un recupero dati ad alta velocità, rendendolo ideale per applicazioni con volumi elevati di richieste di lettura.",
        "Other Options": [
            "Abilitare repliche di lettura sul database Amazon Aurora può aiutare a distribuire il carico di lettura, ma non affronta i problemi di latenza altrettanto efficacemente quanto la memorizzazione nella cache. Le repliche di lettura possono comunque comportare costi e potrebbero non fornire i miglioramenti di prestazioni immediati necessari per richieste di lettura ad alto volume.",
            "Utilizzare Amazon RDS Proxy per raggruppare e condividere le connessioni al database può migliorare le prestazioni riducendo l'overhead di stabilire connessioni, ma non riduce direttamente il numero di interrogazioni di lettura inviate al database. Questa opzione può aiutare nella gestione delle connessioni, ma non risolve il problema di latenza sottostante causato da volumi elevati di richieste di lettura.",
            "Memorizzare i dati frequentemente accessibili in Amazon S3 e accedervi direttamente dall'applicazione non è ideale per il recupero di dati in tempo reale, poiché S3 è progettato per l'archiviazione di oggetti e potrebbe introdurre latenza aggiuntiva. Questo approccio è più adatto per contenuti statici piuttosto che per dati dinamici che richiedono aggiornamenti frequenti, rendendolo meno efficace per le esigenze dell'applicazione."
        ]
    },
    {
        "Question Number": "16",
        "Situation": "Una società finanziaria richiede una soluzione di archiviazione file completamente gestita su AWS che possa supportare IOPS elevati, bassa latenza e funzionalità native del file system Windows per memorizzare e elaborare dati sensibili dei clienti. Il sistema deve fornire accesso sicuro tramite SMB e integrarsi con l'Active Directory locale dell'azienda per l'autenticazione degli utenti.",
        "Question": "Quale configurazione del servizio AWS soddisferebbe meglio questi requisiti? (Scegli due.)",
        "Options": {
            "1": "Amazon S3 con Transfer Acceleration per accesso ad alta velocità",
            "2": "Amazon FSx for Windows File Server in un deployment Multi-AZ",
            "3": "Amazon EFS con crittografia a riposo e in transito",
            "4": "AWS Storage Gateway con Cached Volumes",
            "5": "Amazon FSx for NetApp ONTAP con integrazione Active Directory"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon FSx for Windows File Server in un deployment Multi-AZ",
            "AWS Storage Gateway con Cached Volumes"
        ],
        "Explanation": "Amazon FSx for Windows File Server in un deployment Multi-AZ è un file system nativo Microsoft Windows completamente gestito che può supportare IOPS elevati, bassa latenza e funzionalità native del file system Windows. Fornisce anche accesso sicuro tramite SMB e si integra con l'Active Directory locale per l'autenticazione degli utenti, soddisfacendo tutti i requisiti indicati. AWS Storage Gateway con Cached Volumes può essere utilizzato per fornire accesso a bassa latenza ai dati in AWS dalle applicazioni locali memorizzando i dati frequentemente accessibili localmente, mantenendo tutti i dati in Amazon S3. Supporta anche l'integrazione con l'Active Directory locale per l'autenticazione degli utenti.",
        "Other Options": [
            "Amazon S3 con Transfer Acceleration per accesso ad alta velocità non supporta le funzionalità native del file system Windows e il protocollo SMB. Non si integra nemmeno con l'Active Directory locale per l'autenticazione degli utenti.",
            "Amazon EFS con crittografia a riposo e in transito è un file system completamente gestito che non è progettato per IOPS elevati, bassa latenza e non supporta le funzionalità native del file system Windows o il protocollo SMB.",
            "Amazon FSx for NetApp ONTAP con integrazione Active Directory è un servizio di file system completamente gestito che supporta il protocollo SMB e si integra con l'Active Directory locale, ma non supporta le funzionalità native del file system Windows."
        ]
    },
    {
        "Question Number": "17",
        "Situation": "Un'azienda sta eseguendo un'applicazione web su istanze EC2 dietro un Application Load Balancer (ALB). L'applicazione deve instradare il traffico in base ai percorsi URL, con servizi specifici che gestiscono determinati tipi di richieste. Vogliono anche garantire che il traffico sia distribuito uniformemente tra le istanze per evitare che una singola istanza venga sovraccaricata durante i periodi di alto traffico.",
        "Question": "Quale configurazione dovrebbe applicare l'azienda per ottenere un bilanciamento del carico efficiente?",
        "Options": {
            "1": "Configurare l'ALB con instradamento basato su percorso per indirizzare il traffico a diversi gruppi di destinazione in base ai percorsi URL, assicurando che il traffico sia bilanciato uniformemente tra le istanze EC2 in ciascun gruppo.",
            "2": "Configurare l'ALB per instradare tutto il traffico a un'unica istanza EC2 per semplicità, ma utilizzare Auto Scaling per aumentare la dimensione dell'istanza durante i picchi di traffico.",
            "3": "Utilizzare un Classic Load Balancer (CLB) invece di ALB per supportare l'instradamento basato su percorso e distribuire il traffico in base a più endpoint dell'applicazione.",
            "4": "Impostare più ALB, ciascuno che serve traffico per un diverso dominio applicativo, e indirizzare manualmente il traffico a ciascun ALB in base ai modelli di traffico."
        },
        "Correct Answer": "Configurare l'ALB con instradamento basato su percorso per indirizzare il traffico a diversi gruppi di destinazione in base ai percorsi URL, assicurando che il traffico sia bilanciato uniformemente tra le istanze EC2 in ciascun gruppo.",
        "Explanation": "Configurare l'ALB con instradamento basato su percorso consente all'azienda di indirizzare il traffico a diversi gruppi di destinazione in base ai percorsi URL delle richieste in arrivo. Ciò significa che servizi specifici possono gestire tipi specifici di richieste, essenziale per l'architettura dell'applicazione. Inoltre, l'ALB bilancia automaticamente il traffico tra le istanze EC2 in ciascun gruppo di destinazione, assicurando che nessuna singola istanza diventi sovraccaricata durante i periodi di alto traffico. Questa configurazione è ottimale per gestire il traffico in modo efficiente e mantenere le prestazioni dell'applicazione.",
        "Other Options": [
            "Configurare l'ALB per instradare tutto il traffico a un'unica istanza EC2 non è una soluzione praticabile per il bilanciamento del carico, poiché contraddice lo scopo di utilizzare un bilanciatore di carico. Ciò porterebbe a un potenziale sovraccarico su quell'unica istanza, specialmente durante i picchi di traffico, e non sfrutterebbe i vantaggi di avere più istanze.",
            "Utilizzare un Classic Load Balancer (CLB) invece di ALB è errato perché i CLB non supportano l'instradamento basato su percorso. Gli ALB sono progettati specificamente per funzionalità di instradamento avanzate, incluso l'instradamento basato su percorso, necessario per il requisito dell'azienda di indirizzare il traffico in base ai percorsi URL.",
            "Impostare più ALB per diversi domini applicativi e indirizzare manualmente il traffico a ciascun ALB aggiunge complessità non necessaria all'architettura. Sarebbe più efficiente utilizzare un singolo ALB con instradamento basato su percorso per gestire il traffico per più servizi, semplificando la configurazione e riducendo il carico operativo."
        ]
    },
    {
        "Question Number": "18",
        "Situation": "Un'organizzazione utilizza AWS Organizations e desidera implementare un confine di autorizzazione su più account per prevenire determinate azioni, anche per gli utenti con accesso amministrativo completo. L'organizzazione desidera anche mantenere basso il carico amministrativo.",
        "Question": "Quale tipo di architettura di Service Control Policy (SCP) soddisferebbe meglio questi requisiti e quale effetto avrà sulle autorizzazioni degli utenti IAM all'interno dell'organizzazione?",
        "Options": {
            "1": "Utilizzare un'architettura Allow List per consentire esplicitamente solo servizi specifici, limitando tutte le altre azioni per una maggiore sicurezza e controllo.",
            "2": "Utilizzare un'architettura Deny List per negare azioni specifiche, consentendo tutte le altre azioni per impostazione predefinita, il che riduce il carico di gestione.",
            "3": "Utilizzare un'architettura Deny List per negare esplicitamente tutte le azioni, richiedendo l'aggiunta manuale di autorizzazioni per ciascun servizio necessario.",
            "4": "Utilizzare un'architettura Allow List per consentire azioni solo per l'utente root, bloccando le autorizzazioni per tutti gli utenti IAM all'interno dell'organizzazione."
        },
        "Correct Answer": "Utilizzare un'architettura Deny List per negare azioni specifiche, consentendo tutte le altre azioni per impostazione predefinita, il che riduce il carico di gestione.",
        "Explanation": "Un'architettura Deny List è efficace in questo scenario perché consente all'organizzazione di specificare solo le azioni che devono essere negate, mentre tutte le altre azioni rimangono permesse per impostazione predefinita. Questo approccio riduce il carico amministrativo poiché l'organizzazione non deve gestire un elenco esteso di azioni consentite. Invece, possono concentrarsi sull'identificazione e negazione solo delle azioni specifiche che rappresentano un rischio, mantenendo così la flessibilità per gli utenti IAM di svolgere i loro compiti senza restrizioni inutili.",
        "Other Options": [
            "Utilizzare un'architettura Allow List richiederebbe all'organizzazione di definire esplicitamente e consentire solo servizi specifici, il che può portare a un aumento del carico amministrativo poiché dovrebbero continuamente aggiornare l'elenco dei servizi consentiti ogni volta che vengono introdotti nuovi servizi o quando i servizi esistenti devono essere modificati.",
            "Un'architettura Deny List che nega esplicitamente tutte le azioni sarebbe eccessivamente restrittiva e impraticabile, poiché richiederebbe all'organizzazione di aggiungere manualmente autorizzazioni per ciascun servizio necessario. Questo creerebbe un significativo carico di gestione e potrebbe ostacolare la produttività, poiché gli utenti sarebbero bloccati dall'eseguire azioni necessarie a meno che non siano esplicitamente consentite.",
            "Utilizzare un'architettura Allow List per consentire azioni solo per l'utente root bloccherebbe effettivamente le autorizzazioni per tutti gli utenti IAM all'interno dell'organizzazione, il che contraddice il requisito di consentire agli utenti con accesso amministrativo di svolgere i propri compiti. Questo non soddisferebbe l'obiettivo dell'organizzazione di implementare un confine di autorizzazione mantenendo comunque le azioni necessarie per gli utenti IAM."
        ]
    },
    {
        "Question Number": "19",
        "Situation": "Un'azienda sta utilizzando AWS Key Management Service (KMS) per proteggere dati sensibili. L'azienda desidera garantire che le chiavi utilizzate per crittografare questi dati siano gestite e memorizzate in modo sicuro all'interno di AWS, senza mai lasciare l'ambiente AWS.",
        "Question": "Quale caratteristica di AWS KMS garantisce che le chiavi di crittografia rimangano sicure e all'interno dell'infrastruttura AWS, e che tipo di crittografia supporta?",
        "Options": {
            "1": "Le chiavi KMS sono isolate all'interno di una regione KMS dedicata e supportano solo crittografia simmetrica.",
            "2": "Le chiavi KMS non lasciano mai AWS KMS e supportano sia crittografia simmetrica che asimmetrica.",
            "3": "Le chiavi KMS possono essere esportate da AWS per uso esterno e supportano solo crittografia asimmetrica.",
            "4": "Le chiavi KMS sono condivise tra più account AWS e supportano solo crittografia simmetrica."
        },
        "Correct Answer": "Le chiavi KMS non lasciano mai AWS KMS e supportano sia crittografia simmetrica che asimmetrica.",
        "Explanation": "AWS Key Management Service (KMS) è progettato per gestire le chiavi di crittografia in modo sicuro all'interno dell'ambiente AWS. Una delle sue caratteristiche principali è che le chiavi di crittografia non vengono mai esposte al di fuori dell'infrastruttura AWS, garantendo che rimangano sicure. Inoltre, AWS KMS supporta sia la crittografia simmetrica (dove viene utilizzata la stessa chiave per la crittografia e la decrittografia) sia la crittografia asimmetrica (dove viene utilizzata una coppia di chiavi). Questa flessibilità consente agli utenti di scegliere il metodo di crittografia appropriato in base ai loro requisiti di sicurezza.",
        "Other Options": [
            "Le chiavi KMS sono isolate all'interno di una regione KMS dedicata e supportano solo crittografia simmetrica. Questa opzione è errata perché, sebbene le chiavi KMS siano specifiche per regione, supportano sia crittografia simmetrica che asimmetrica, non solo simmetrica.",
            "Le chiavi KMS possono essere esportate da AWS per uso esterno e supportano solo crittografia asimmetrica. Questa opzione è errata perché le chiavi KMS non possono essere esportate per uso esterno; sono progettate per rimanere all'interno di AWS. Inoltre, KMS supporta sia crittografia simmetrica che asimmetrica, non solo asimmetrica.",
            "Le chiavi KMS sono condivise tra più account AWS e supportano solo crittografia simmetrica. Questa opzione è errata perché, sebbene le chiavi KMS possano essere condivise tra account tramite politiche delle risorse, supportano sia crittografia simmetrica che asimmetrica, non solo simmetrica."
        ]
    },
    {
        "Question Number": "20",
        "Situation": "Un'azienda ha distribuito un Application Load Balancer (ALB) su più Availability Zones (AZ) e ha abilitato il bilanciamento del carico tra zone per distribuire il traffico in arrivo.",
        "Question": "In che modo il bilanciamento del carico tra zone migliora la distribuzione del carico e quale vantaggio offre per gestire i picchi di traffico in una AZ?",
        "Options": {
            "1": "Il bilanciamento del carico tra zone consente a ciascun nodo del bilanciatore di carico di instradare il traffico solo verso obiettivi all'interno della propria AZ, fornendo isolamento e resilienza in caso di guasto della AZ.",
            "2": "Il bilanciamento del carico tra zone consente a ciascun nodo del bilanciatore di carico di instradare il traffico uniformemente tra obiettivi in tutte le AZ, garantendo una distribuzione del carico più equilibrata e riducendo il rischio di sovraccaricare obiettivi in una AZ.",
            "3": "Il bilanciamento del carico tra zone instrada il traffico verso un solo obiettivo per richiesta, riducendo la latenza e migliorando le prestazioni per gli utenti in ciascuna AZ.",
            "4": "Il bilanciamento del carico tra zone è efficace solo in configurazioni a singola AZ e non ha impatto quando sono coinvolte più AZ."
        },
        "Correct Answer": "Il bilanciamento del carico tra zone consente a ciascun nodo del bilanciatore di carico di instradare il traffico uniformemente tra obiettivi in tutte le AZ, garantendo una distribuzione del carico più equilibrata e riducendo il rischio di sovraccaricare obiettivi in una AZ.",
        "Explanation": "Il bilanciamento del carico tra zone consente all'Application Load Balancer di distribuire il traffico in arrivo uniformemente tra tutti gli obiettivi registrati in diverse Availability Zones, piuttosto che solo verso gli obiettivi nella stessa AZ del nodo del bilanciatore di carico. Ciò significa che se una AZ sperimenta un picco di traffico, il bilanciatore di carico può indirizzare il traffico verso obiettivi in altre AZ, prevenendo che una singola AZ diventi un collo di bottiglia. Questa capacità migliora la resilienza e le prestazioni complessive dell'applicazione, specialmente durante i picchi di traffico.",
        "Other Options": [
            "Il bilanciamento del carico tra zone consente a ciascun nodo del bilanciatore di carico di instradare il traffico solo verso obiettivi all'interno della propria AZ, fornendo isolamento e resilienza in caso di guasto della AZ. Questo è errato perché il bilanciamento del carico tra zone consente specificamente di instradare il traffico attraverso più AZ, che è l'opposto di instradare solo all'interno di una singola AZ.",
            "Questa opzione è errata perché rappresenta male la funzionalità del bilanciamento del carico tra zone. Sebbene miri a bilanciare il carico, lo fa distribuendo il traffico tra tutte le AZ, non solo garantendo una distribuzione uniforme tra gli obiettivi in una singola AZ.",
            "Questa opzione è errata perché il bilanciamento del carico tra zone non limita il traffico a un solo obiettivo per richiesta. Invece, distribuisce il traffico tra più obiettivi, il che aiuta a gestire il carico in modo efficace e migliorare le prestazioni."
        ]
    },
    {
        "Question Number": "21",
        "Situation": "Una piattaforma di social media desidera monitorare e analizzare i contenuti generati dagli utenti in tempo reale per rilevare e rispondere rapidamente a post inappropriati. La piattaforma ha bisogno di una soluzione scalabile per elaborare flussi continui di dati da milioni di utenti simultaneamente.",
        "Question": "Quali servizi AWS dovrebbe raccomandare l'architetto delle soluzioni per l'elaborazione dei dati in streaming in questo scenario? (Scegli due.)",
        "Options": {
            "1": "Amazon Simple Queue Service (SQS)",
            "2": "Amazon Kinesis Data Streams",
            "3": "Amazon Managed Streaming for Apache Kafka (MSK)",
            "4": "AWS Lambda con trigger programmati",
            "5": "Amazon EventBridge"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon Kinesis Data Streams",
            "Amazon Managed Streaming for Apache Kafka (MSK)"
        ],
        "Explanation": "Amazon Kinesis Data Streams è progettato per raccogliere, elaborare e analizzare dati in streaming in tempo reale, consentendo di ottenere informazioni tempestive e reagire rapidamente a nuove informazioni. Può gestire qualsiasi quantità di dati in streaming e elaborare dati provenienti da centinaia di migliaia di fonti con latenze molto basse. Amazon Managed Streaming for Apache Kafka (MSK) è un servizio completamente gestito che facilita la creazione e l'esecuzione di applicazioni che utilizzano Apache Kafka per elaborare dati in streaming. È altamente adatto per compiti di elaborazione di dati in tempo reale ad alto volume.",
        "Other Options": [
            "Amazon Simple Queue Service (SQS) è un servizio di messaggistica completamente gestito che consente di disaccoppiare e scalare microservizi, sistemi distribuiti e applicazioni serverless. Tuttavia, non è progettato per l'elaborazione di dati in streaming in tempo reale.",
            "AWS Lambda con trigger programmati è un servizio di calcolo che consente di eseguire codice senza dover provisionare o gestire server. Sebbene Lambda possa elaborare modifiche ai file in tempo reale, l'opzione 'trigger programmati' non si adatta ai requisiti in tempo reale dello scenario.",
            "Amazon EventBridge è un bus di eventi serverless che facilita la connessione di applicazioni utilizzando dati dalle proprie applicazioni, applicazioni Software-as-a-Service (SaaS) integrate e servizi AWS. Non è specificamente progettato per l'elaborazione di dati in streaming in tempo reale."
        ]
    },
    {
        "Question Number": "22",
        "Situation": "Un'azienda ha bisogno di crittografare file di grandi dimensioni che superano i 4 KB utilizzando AWS Key Management Service (KMS). Il processo di crittografia deve coinvolgere sia una versione in chiaro per un uso immediato che una versione sicura da memorizzare insieme ai dati crittografati.",
        "Question": "Quale funzionalità di KMS dovrebbe utilizzare l'azienda per soddisfare questi requisiti e come gestisce la crittografia di dati più grandi di 4 KB?",
        "Options": {
            "1": "Utilizzare direttamente la chiave KMS per crittografare i dati, poiché KMS supporta file di qualsiasi dimensione senza passaggi aggiuntivi.",
            "2": "Generare una Data Encryption Key (DEK) con KMS, utilizzare la DEK in chiaro per crittografare i dati e memorizzare la DEK in forma crittografata insieme ai dati crittografati.",
            "3": "Utilizzare una chiave KMS gestita dal cliente con una policy personalizzata per consentire la crittografia di file di grandi dimensioni e mantenere sia copie in chiaro che crittografate.",
            "4": "Crittografare i dati direttamente in KMS suddividendoli in blocchi di 4 KB, crittografando ogni blocco separatamente e riunendoli dopo la decrittazione."
        },
        "Correct Answer": "Generare una Data Encryption Key (DEK) con KMS, utilizzare la DEK in chiaro per crittografare i dati e memorizzare la DEK in forma crittografata insieme ai dati crittografati.",
        "Explanation": "AWS Key Management Service (KMS) ha un limite di 4 KB per le operazioni di crittografia diretta. Per crittografare file più grandi, l'approccio raccomandato è generare una Data Encryption Key (DEK) utilizzando KMS. La DEK viene quindi utilizzata per crittografare i dati, consentendo la crittografia di file più grandi di 4 KB. La DEK in chiaro può essere utilizzata per la decrittazione immediata, mentre la DEK crittografata (crittografata con la chiave KMS) è memorizzata insieme ai dati crittografati per un accesso sicuro. Questo metodo garantisce che il processo di crittografia sia efficiente e scalabile per file di grandi dimensioni.",
        "Other Options": [
            "Utilizzare direttamente la chiave KMS per crittografare i dati è errato perché KMS ha un limite di dimensione di 4 KB per le operazioni di crittografia. I file più grandi di questo devono essere gestiti in modo diverso, ad esempio utilizzando una DEK.",
            "Sebbene generare una DEK sia corretto, l'opzione non specifica che la DEK dovrebbe essere memorizzata in forma crittografata insieme ai dati crittografati. Questo è cruciale per mantenere la sicurezza e consentire la decrittazione successiva.",
            "Utilizzare una chiave KMS gestita dal cliente con una policy personalizzata non affronta direttamente la limitazione di dimensione della crittografia KMS. Il metodo di crittografia di file di grandi dimensioni richiede comunque l'uso di una DEK, indipendentemente dalla policy di gestione delle chiavi."
        ]
    },
    {
        "Question Number": "23",
        "Situation": "Un'azienda deve garantire che il proprio ambiente AWS aderisca alle migliori pratiche di sicurezza e agli standard di conformità. L'azienda desidera un monitoraggio continuo delle proprie risorse AWS per rilevare potenziali vulnerabilità di sicurezza e garantire la conformità.",
        "Question": "Quali servizi AWS dovrebbe raccomandare l'architetto delle soluzioni? (Scegli due.)",
        "Options": {
            "1": "AWS Config",
            "2": "Amazon GuardDuty",
            "3": "AWS Security Hub",
            "4": "AWS CloudTrail",
            "5": "AWS Shield Advanced"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "AWS Security Hub",
            "Amazon GuardDuty"
        ],
        "Explanation": "AWS Security Hub fornisce una visione completa degli avvisi di sicurezza ad alta priorità e dello stato di conformità attraverso gli account AWS. Aggrega, organizza e prioritizza i tuoi avvisi di sicurezza, o risultati, provenienti da più servizi AWS, come Amazon GuardDuty, Amazon Inspector e Amazon Macie, così come da soluzioni partner AWS. Amazon GuardDuty è un servizio di rilevamento delle minacce che monitora continuamente l'attività malevola e il comportamento non autorizzato per proteggere i tuoi account e carichi di lavoro AWS. Analizza miliardi di eventi provenienti da più fonti di dati AWS, come i log degli eventi di AWS CloudTrail, i log di flusso di Amazon VPC e i log DNS.",
        "Other Options": [
            "AWS Config è un servizio che consente di valutare, auditare e valutare le configurazioni delle tue risorse AWS. Non fornisce monitoraggio continuo per potenziali vulnerabilità di sicurezza.",
            "AWS CloudTrail è un servizio che consente la governance, la conformità, l'audit operativo e l'audit del rischio del tuo account AWS. Tuttavia, non fornisce monitoraggio continuo per potenziali vulnerabilità di sicurezza.",
            "AWS Shield Advanced fornisce protezione DDoS e protezione dei costi, ma non fornisce monitoraggio continuo per potenziali vulnerabilità di sicurezza."
        ]
    },
    {
        "Question Number": "24",
        "Situation": "Un'azienda di e-commerce multinazionale richiede una soluzione di database altamente disponibile che offra accesso in lettura a bassa latenza ai clienti in più regioni. Per garantire resilienza e proteggere contro interruzioni regionali, l'azienda richiede anche una configurazione di disaster recovery cross-region con un impatto minimo sulle prestazioni del database primario. Inoltre, hanno bisogno di una replicazione quasi in tempo reale nelle regioni secondarie per gli aggiornamenti dei dati più rapidi possibile.",
        "Question": "Quale soluzione di database AWS soddisferebbe meglio questi requisiti?",
        "Options": {
            "1": "Distribuire Amazon RDS con Multi-AZ per migliorare l'alta disponibilità all'interno di una singola regione AWS",
            "2": "Utilizzare Aurora Global Database per abilitare repliche in lettura cross-region, fornendo accesso in lettura a bassa latenza e replicazione quasi in tempo reale con un impatto minimo sul database primario",
            "3": "Configurare Amazon DynamoDB Global Tables per ottenere replicazione multi-regione e accesso a bassa latenza per carichi di lavoro NoSQL",
            "4": "Impostare Amazon Redshift con snapshot cross-region per creare un backup in ogni regione per il disaster recovery"
        },
        "Correct Answer": "Utilizzare Aurora Global Database per abilitare repliche in lettura cross-region, fornendo accesso in lettura a bassa latenza e replicazione quasi in tempo reale con un impatto minimo sul database primario",
        "Explanation": "Aurora Global Database è specificamente progettato per applicazioni con una presenza globale che richiedono letture a bassa latenza e alta disponibilità in più regioni. Consente la replicazione quasi in tempo reale dei dati nelle regioni secondarie, garantendo che i clienti in quelle regioni possano accedere ai dati rapidamente ed efficientemente. Inoltre, fornisce resilienza contro interruzioni regionali, poiché il database può passare a una regione secondaria con un impatto minimo sulle prestazioni del database primario. Questo lo rende la soluzione migliore per i requisiti dell'azienda in termini di alta disponibilità, accesso a bassa latenza e disaster recovery cross-region.",
        "Other Options": [
            "Distribuire Amazon RDS con Multi-AZ migliora l'alta disponibilità all'interno di una singola regione AWS, ma non fornisce replicazione cross-region o capacità di disaster recovery. Pertanto, non soddisfa il requisito di resilienza contro interruzioni regionali.",
            "Utilizzare Aurora Global Database è la scelta corretta, quindi questa opzione non è applicabile come alternativa. È la migliore soluzione per i requisiti dichiarati.",
            "Configurare Amazon DynamoDB Global Tables fornirebbe replicazione multi-regione e accesso a bassa latenza, ma è principalmente adatto per carichi di lavoro NoSQL. Lo scenario non specifica la necessità di un database NoSQL, e Aurora Global Database è un'opzione più adatta per le esigenze di database relazionali con i requisiti specificati."
        ]
    },
    {
        "Question Number": "25",
        "Situation": "Un'azienda sta eseguendo un'applicazione web critica in AWS e ha bisogno di configurare le quote di servizio per gestire l'uso in un ambiente di standby. Vuole garantire che il proprio carico di lavoro possa scalare in base alla domanda senza superare i limiti di servizio e desidera anche applicare throttling per evitare interruzioni del servizio.",
        "Question": "Quali dei seguenti passaggi dovrebbe seguire l'azienda per gestire le quote di servizio e il throttling per l'ambiente di standby?",
        "Options": {
            "1": "Utilizzare AWS Service Quotas per impostare limiti per l'uso del servizio e configurare AWS Lambda per scalare automaticamente le risorse in base a queste quote, applicando throttling per mantenere la stabilità del servizio.",
            "2": "Configurare gruppi di Auto Scaling per scalare le istanze EC2 in base al carico di lavoro e regolare manualmente le quote di servizio nella Console di gestione AWS per gestire il traffico di picco.",
            "3": "Utilizzare Amazon API Gateway per impostare limiti di throttling sulle richieste API e configurare CloudWatch per monitorare l'uso nell'ambiente di standby per garantire che i limiti non vengano superati.",
            "4": "Utilizzare Amazon SQS per mettere in coda le richieste in eccesso e ritardare l'elaborazione per prevenire il throttling, mentre si configura AWS Lambda per la scalabilità automatica."
        },
        "Correct Answer": "Utilizzare Amazon API Gateway per impostare limiti di throttling sulle richieste API e configurare CloudWatch per monitorare l'uso nell'ambiente di standby per garantire che i limiti non vengano superati.",
        "Explanation": "Utilizzare Amazon API Gateway per impostare limiti di throttling è un modo efficace per gestire il numero di richieste che possono essere elaborate dall'applicazione web, prevenendo così interruzioni del servizio dovute a carichi eccessivi. API Gateway consente di definire piani di utilizzo che possono limitare le richieste e impostare quote, garantendo che l'applicazione rimanga stabile sotto carichi variabili. Inoltre, integrare CloudWatch per il monitoraggio consente all'azienda di tracciare le metriche di utilizzo in tempo reale, consentendo una gestione proattiva dei limiti di servizio e garantendo che non vengano superati le soglie definite.",
        "Other Options": [
            "Utilizzare AWS Service Quotas per impostare limiti per l'uso del servizio e configurare AWS Lambda per la scalabilità automatica non affronta direttamente il throttling per le richieste API. Sebbene aiuti a gestire i limiti di servizio, manca delle specifiche capacità di throttling che fornisce API Gateway, che sono cruciali per mantenere la stabilità del servizio sotto carico.",
            "Configurare gruppi di Auto Scaling per scalare le istanze EC2 è una buona pratica per gestire gli aumenti del carico di lavoro, ma non gestisce intrinsecamente le quote di servizio o applica throttling. Regolare manualmente le quote di servizio può portare a ritardi e potenziali interruzioni del servizio se non fatto in tempo reale, il che non è ideale per un ambiente di standby che deve rispondere rapidamente ai cambiamenti della domanda.",
            "Utilizzare Amazon SQS per mettere in coda le richieste in eccesso è un approccio valido per gestire il carico, ma non applica direttamente il throttling alle richieste API. Sebbene SQS possa aiutare a prevenire il sovraccarico dei servizi backend, non fornisce lo stesso livello di controllo sui tassi di richiesta di API Gateway e potrebbe introdurre latenza nell'elaborazione delle richieste."
        ]
    },
    {
        "Question Number": "26",
        "Situation": "Un'azienda sanitaria, HealthSecure, è soggetta a rigorose normative di conformità che richiedono un monitoraggio e una documentazione continui della configurazione delle proprie risorse cloud. HealthSecure ha scelto AWS Config per tracciare e auditare le modifiche nel proprio ambiente AWS per garantire la conformità a standard come HIPAA. Hanno bisogno di una soluzione che possa valutare le risorse rispetto a specifiche regole di conformità e riparare automaticamente le risorse non conformi. Tuttavia, HealthSecure desidera anche comprendere i limiti di AWS Config, in particolare se può prevenire attivamente le modifiche di configurazione o se fornisce solo capacità di monitoraggio e allerta.",
        "Question": "In che modo AWS Config supporta la gestione della conformità e il tracciamento della configurazione delle risorse in un account AWS, e quali sono alcune limitazioni associate al suo funzionamento?",
        "Options": {
            "1": "AWS Config consente agli utenti di tracciare le modifiche di configurazione tra le risorse e previene modifiche non autorizzate applicando la conformità in tempo reale.",
            "2": "AWS Config monitora e registra le modifiche di configurazione tra le risorse supportate, abilita l'audit per gli standard di conformità e può riparare automaticamente le risorse non conformi tramite integrazione con AWS Lambda. Tuttavia, non previene attivamente le modifiche.",
            "3": "AWS Config fornisce solo istantanee di configurazione a intervalli specifici, il che limita la sua efficacia per la gestione della conformità, poiché il monitoraggio in tempo reale non è supportato.",
            "4": "AWS Config funziona solo in una singola regione e non può aggregare dati tra più account, rendendolo adatto solo per ambienti isolati in cui le risorse rimangono statiche."
        },
        "Correct Answer": "AWS Config monitora e registra le modifiche di configurazione tra le risorse supportate, abilita l'audit per gli standard di conformità e può riparare automaticamente le risorse non conformi tramite integrazione con AWS Lambda. Tuttavia, non previene attivamente le modifiche.",
        "Explanation": "AWS Config è progettato per fornire un monitoraggio continuo delle configurazioni delle risorse AWS e per tracciare le modifiche nel tempo. Consente agli utenti di valutare le proprie risorse rispetto alle regole di conformità e può attivare azioni di riparazione tramite AWS Lambda quando vengono rilevate configurazioni non conformi. Tuttavia, è importante notare che AWS Config non ha la capacità di prevenire attivamente le modifiche di configurazione; monitora e avvisa solo sulle modifiche che si verificano, rendendolo uno strumento potente per la gestione della conformità ma non preventivo.",
        "Other Options": [
            "AWS Config non previene modifiche non autorizzate in tempo reale; monitora e avvisa solo sulle modifiche dopo che si sono verificate.",
            "AWS Config fornisce monitoraggio quasi in tempo reale e non si limita a istantanee di configurazione a intervalli specifici; registra continuamente le modifiche di configurazione.",
            "AWS Config può operare in più regioni e account quando utilizzato con AWS Organizations, consentendo una visione più completa delle configurazioni delle risorse in tutta l'organizzazione."
        ]
    },
    {
        "Question Number": "27",
        "Situation": "Un'organizzazione di ricerca scientifica memorizza grandi set di dati in Amazon S3 che vengono frequentemente accessibili da utenti esterni. Per minimizzare i costi, vogliono che gli utenti esterni coprano il costo dell'accesso ai dati invece che l'organizzazione stessa.",
        "Question": "Quale configurazione S3 dovrebbero utilizzare per soddisfare questo requisito?",
        "Options": {
            "1": "Abilitare S3 Transfer Acceleration",
            "2": "Impostare un bucket S3 con Requester Pays abilitato",
            "3": "Utilizzare S3 Intelligent-Tiering per la classe di archiviazione",
            "4": "Abilitare la replica tra regioni per la condivisione dei costi"
        },
        "Correct Answer": "Impostare un bucket S3 con Requester Pays abilitato",
        "Explanation": "Abilitare Requester Pays su un bucket S3 consente agli utenti esterni che accedono ai dati di sostenere i costi associati alle loro richieste. Ciò significa che quando gli utenti accedono ai dati, verranno addebitati per il trasferimento dei dati e le richieste, spostando effettivamente il peso dei costi dall'organizzazione agli utenti che accedono ai dati. Questa configurazione è specificamente progettata per scenari in cui i dati sono condivisi con parti esterne, rendendola l'opzione più adatta per il requisito dell'organizzazione di minimizzare i costi.",
        "Other Options": [
            "Abilitare S3 Transfer Acceleration accelera il trasferimento di file da e verso S3, ma non cambia chi paga per l'accesso ai dati. I costi per l'utilizzo di Transfer Acceleration sono comunque a carico del proprietario del bucket, non del richiedente.",
            "Sebbene S3 Intelligent-Tiering sia una classe di archiviazione che sposta automaticamente i dati tra due livelli di accesso in base ai modelli di accesso che cambiano, non affronta l'allocazione dei costi per l'accesso ai dati. L'organizzazione sarebbe comunque responsabile dei costi associati al recupero dei dati.",
            "Abilitare la replica tra regioni viene utilizzato per replicare automaticamente i dati tra diverse regioni AWS per ridondanza e disponibilità. Questa funzionalità non è correlata alla condivisione dei costi per l'accesso ai dati e comporterebbe costi aggiuntivi per l'organizzazione senza affrontare il requisito di avere utenti esterni che coprono i costi di accesso."
        ]
    },
    {
        "Question Number": "28",
        "Situation": "Un'azienda di servizi finanziari gestisce un database transazionale che presenta carichi di lavoro variabili, inclusi periodi di picco che richiedono elevate IOPS e capacità di archiviazione. L'azienda mira a ottimizzare i costi garantendo prestazioni durante i periodi di picco.",
        "Question": "Quale configurazione di archiviazione Amazon RDS dovrebbe raccomandare l'architetto delle soluzioni per soddisfare questi requisiti?",
        "Options": {
            "1": "Provisionare archiviazione SSD a scopo generale (gp3) con scalabilità automatica abilitata.",
            "2": "Utilizzare archiviazione magnetica con backup automatici e capacità di snapshot.",
            "3": "Provisionare archiviazione SSD IOPS provisionati (io1) con IOPS impostati al massimo richiesto durante i periodi di picco.",
            "4": "Implementare Amazon Aurora con le sue capacità di scalabilità dello storage e alte prestazioni."
        },
        "Correct Answer": "Implementare Amazon Aurora con le sue capacità di scalabilità dello storage e alte prestazioni.",
        "Explanation": "Amazon Aurora è progettato per alte prestazioni e disponibilità, rendendolo un'ottima scelta per applicazioni con carichi di lavoro variabili. Scala automaticamente lo storage fino a 128 TB secondo necessità, il che è vantaggioso durante i periodi di picco che richiedono elevate IOPS e capacità di archiviazione. Aurora offre anche un'elevata larghezza di banda e bassa latenza, garantendo che le prestazioni siano mantenute anche sotto carichi pesanti, ottimizzando così i costi mentre soddisfa i requisiti di prestazione.",
        "Other Options": [
            "Provisionare archiviazione SSD a scopo generale (gp3) con scalabilità automatica abilitata è una buona opzione per carichi di lavoro generali, ma potrebbe non fornire lo stesso livello di prestazioni e scalabilità di Amazon Aurora durante i periodi di picco, specialmente per database transazionali che richiedono IOPS elevate e costanti.",
            "Utilizzare archiviazione magnetica con backup automatici e capacità di snapshot non è adatto per requisiti di alte prestazioni. L'archiviazione magnetica è più lenta e non fornisce le necessarie IOPS per carichi di lavoro transazionali, rendendola inadeguata per le esigenze di prestazioni di picco.",
            "Provisionare archiviazione SSD IOPS provisionati (io1) con IOPS impostati al massimo richiesto durante i periodi di picco può essere efficace, ma può essere costoso e potrebbe non fornire lo stesso livello di scalabilità automatica e ottimizzazione delle prestazioni di Amazon Aurora, specialmente se i carichi di lavoro sono variabili e imprevedibili."
        ]
    },
    {
        "Question Number": "29",
        "Situation": "Un'organizzazione di ricerca deve migrare 80 TB di dati scientifici dal proprio storage NFS on-premises ad Amazon S3. I dati vengono frequentemente aggiornati e l'organizzazione desidera garantire che eventuali modifiche apportate on-premises siano sincronizzate in modo incrementale su AWS. Sono anche preoccupati di saturare la larghezza di banda della rete durante l'orario lavorativo.",
        "Question": "Quali funzionalità di AWS DataSync dovrebbe evidenziare l'architetto delle soluzioni come vantaggi per questa migrazione? (Scegli due.)",
        "Options": {
            "1": "Validazione dei dati durante il trasferimento per garantire l'integrità dei dati",
            "2": "Replica multi-regione per disaster recovery",
            "3": "Limitatore di larghezza di banda per controllare l'uso della rete durante le ore di punta",
            "4": "Supporto per la sincronizzazione in tempo reale con zero latenza",
            "5": "Recupero automatico da errori di transito per un trasferimento affidabile"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Validazione dei dati durante il trasferimento per garantire l'integrità dei dati",
            "Limitatore di larghezza di banda per controllare l'uso della rete durante le ore di punta"
        ],
        "Explanation": "La validazione dei dati durante il trasferimento è una funzionalità chiave di AWS DataSync che garantisce l'integrità dei dati. Verifica che i dati letti dalla posizione sorgente corrispondano ai dati scritti nella destinazione, garantendo così che i dati non siano corrotti durante il trasferimento. Questo è cruciale per l'organizzazione di ricerca poiché deve garantire l'integrità dei propri dati scientifici. La funzionalità del limitatore di larghezza di banda consente all'organizzazione di controllare l'uso della rete durante le ore di punta. Questo è importante poiché l'organizzazione è preoccupata di saturare la larghezza di banda della rete durante l'orario lavorativo. AWS DataSync consente agli utenti di impostare un limite sulla larghezza di banda utilizzata da DataSync, evitando che la rete si saturi.",
        "Other Options": [
            "La replica multi-regione per disaster recovery non è una funzionalità di AWS DataSync. Questa è una funzionalità di Amazon S3, non di DataSync. DataSync viene utilizzato per trasferire dati verso e da servizi di archiviazione AWS, non fornisce replica multi-regione.",
            "Il supporto per la sincronizzazione in tempo reale con zero latenza non è una funzionalità di AWS DataSync. Sebbene DataSync supporti attività di trasferimento dati programmate o su richiesta, non fornisce sincronizzazione in tempo reale con zero latenza.",
            "Il recupero automatico da errori di transito per un trasferimento affidabile non è una funzionalità specifica di AWS DataSync. Sebbene DataSync abbia una gestione degli errori robusta, non fornisce specificamente una funzionalità di 'recupero automatico da errori di transito'."
        ]
    },
    {
        "Question Number": "30",
        "Situation": "Un'azienda sta sviluppando un'applicazione di analisi dei dati che elabora grandi volumi di file di log generati dai propri server web. L'applicazione richiede accesso a bassa latenza ai dati di log frequentemente accessibili e deve supportare operazioni di lettura e scrittura concorrenti da più istanze. Inoltre, la soluzione di archiviazione dovrebbe scalare automaticamente per adattarsi ai crescenti volumi di dati senza intervento manuale.",
        "Question": "Quale servizio di archiviazione AWS dovrebbe raccomandare l'architetto delle soluzioni per soddisfare questi requisiti?",
        "Options": {
            "1": "Amazon S3 Standard",
            "2": "Amazon Elastic File System (Amazon EFS)",
            "3": "Amazon Elastic Block Store (Amazon EBS) IOPS provisionati",
            "4": "Amazon FSx for Windows File Server"
        },
        "Correct Answer": "Amazon Elastic File System (Amazon EFS)",
        "Explanation": "Amazon Elastic File System (EFS) è progettato per un accesso a bassa latenza e può supportare operazioni di lettura e scrittura concorrenti da più istanze, rendendolo ideale per applicazioni che richiedono accesso frequente ai dati. EFS scala automaticamente man mano che i dati vengono aggiunti o rimossi, il che si allinea perfettamente con il requisito di una soluzione di archiviazione che si adatti ai crescenti volumi di dati senza intervento manuale. Inoltre, EFS fornisce un file system gestito che può essere accessibile da più istanze EC2, garantendo alta disponibilità e durabilità per i dati di log.",
        "Other Options": [
            "Amazon S3 Standard è un servizio di archiviazione a oggetti ottimizzato per durabilità e scalabilità, ma non è progettato per accesso a bassa latenza o operazioni di lettura/scrittura concorrenti come un file system. È più adatto per memorizzare grandi quantità di dati non strutturati piuttosto che per applicazioni che richiedono accesso frequente e bassa latenza.",
            "Amazon Elastic Block Store (Amazon EBS) IOPS provisionati è un servizio di archiviazione a blocchi che fornisce alte prestazioni per le istanze EC2. Tuttavia, non è progettato per accesso concorrente da più istanze, poiché è tipicamente collegato a una singola istanza EC2 alla volta. Questo lo rende meno adatto per i requisiti di operazioni di lettura e scrittura concorrenti.",
            "Amazon FSx for Windows File Server è un file system Windows gestito che fornisce archiviazione di file condivisi. Sebbene supporti l'accesso concorrente, è più complesso e potrebbe non scalare automaticamente nello stesso modo di EFS. È anche più orientato verso ambienti Windows, il che potrebbe non essere necessario per l'applicazione descritta."
        ]
    },
    {
        "Question Number": "31",
        "Situation": "Un'azienda sta implementando un'applicazione web e vuole assicurarsi che possa scalare dinamicamente garantendo un'alta disponibilità attraverso più Availability Zones (AZ). Vogliono utilizzare un Application Load Balancer (ALB) per distribuire il traffico in modo efficiente.",
        "Question": "Quale delle seguenti configurazioni consentirebbe all'azienda di raggiungere meglio questo obiettivo?",
        "Options": {
            "1": "Utilizzare un ALB per distribuire il traffico in base al percorso URL e inoltrare le richieste a diversi gruppi di destinazione, assicurando che il traffico sia distribuito uniformemente su più istanze EC2.",
            "2": "Utilizzare un Classic Load Balancer (CLB) per distribuire il traffico esclusivamente in base all'indirizzo IP senza instradamento del percorso URL.",
            "3": "Utilizzare un ALB ma instradare tutto il traffico a un'unica istanza EC2 per ridurre la complessità e migliorare le prestazioni.",
            "4": "Utilizzare un ALB solo per contenuti statici e indirizzare il traffico dei contenuti dinamici a un'unica istanza EC2 per mantenere un bilanciamento del carico efficiente."
        },
        "Correct Answer": "Utilizzare un ALB per distribuire il traffico in base al percorso URL e inoltrare le richieste a diversi gruppi di destinazione, assicurando che il traffico sia distribuito uniformemente su più istanze EC2.",
        "Explanation": "Utilizzare un Application Load Balancer (ALB) per distribuire il traffico in base al percorso URL consente funzionalità di instradamento avanzate, permettendo all'applicazione di gestire diversi tipi di richieste in modo efficiente. Inoltrando le richieste a diversi gruppi di destinazione, l'ALB può garantire che il traffico sia distribuito uniformemente su più istanze EC2, il che è essenziale per scalare dinamicamente e mantenere un'alta disponibilità attraverso più Availability Zones (AZ). Questa configurazione supporta sia la scalabilità orizzontale che un utilizzo efficiente delle risorse, che sono critiche per le moderne applicazioni web.",
        "Other Options": [
            "Utilizzare un Classic Load Balancer (CLB) per distribuire il traffico esclusivamente in base all'indirizzo IP senza instradamento del percorso URL limita la flessibilità e l'efficienza della gestione del traffico. I CLB non supportano funzionalità di instradamento avanzate come l'instradamento basato su percorso, il che può portare a una distribuzione disomogenea del traffico e potenzialmente sovraccaricare alcune istanze mentre altre rimangono sottoutilizzate.",
            "Instradare tutto il traffico a un'unica istanza EC2 mina lo scopo di utilizzare un ALB per il bilanciamento del carico. Questa configurazione creerebbe un singolo punto di guasto e annullerebbe i benefici di alta disponibilità e scalabilità, poiché non sfrutta la capacità dell'ALB di distribuire il traffico su più istanze.",
            "Utilizzare un ALB solo per contenuti statici e indirizzare il traffico dei contenuti dinamici a un'unica istanza EC2 limita le capacità del bilanciatore di carico e può portare a colli di bottiglia nelle prestazioni. Questo approccio non sfrutta la capacità dell'ALB di distribuire sia contenuti statici che dinamici su più istanze, il che è cruciale per mantenere alta disponibilità e scalabilità."
        ]
    },
    {
        "Question Number": "32",
        "Situation": "Un'azienda manifatturiera opera in una località remota con connettività internet limitata. Hanno bisogno di risorse di calcolo locali per analizzare i dati delle macchine e eseguire applicazioni, ma vogliono anche la possibilità di sincronizzare i dati con AWS quando la connettività è disponibile.",
        "Question": "Quale opzione di calcolo ibrido soddisferebbe meglio questi requisiti?",
        "Options": {
            "1": "AWS Snowball Edge",
            "2": "AWS Lambda con endpoint VPC",
            "3": "Istanze Amazon EC2 nella regione AWS più vicina",
            "4": "Amazon EKS con scalabilità on-demand"
        },
        "Correct Answer": "AWS Snowball Edge",
        "Explanation": "AWS Snowball Edge è progettato per il calcolo edge e il trasferimento di dati in ambienti con connettività internet limitata o assente. Consente agli utenti di eseguire applicazioni e analizzare dati localmente sul dispositivo, il che è ideale per l'azienda manifatturiera in una località remota. Inoltre, Snowball Edge supporta la sincronizzazione dei dati con AWS quando la connettività è disponibile, rendendolo una soluzione perfetta per i loro requisiti.",
        "Other Options": [
            "AWS Lambda con endpoint VPC non è adatto perché richiede una connessione internet stabile per accedere ai servizi AWS. In una località remota con connettività limitata, questa opzione non fornirebbe le necessarie risorse di calcolo locali.",
            "Le istanze Amazon EC2 nella regione AWS più vicina non soddisferebbero le esigenze dell'azienda poiché richiedono una connettività internet costante per accedere a queste istanze. Questa opzione non fornisce risorse di calcolo locali per l'analisi dei dati in un'area remota.",
            "Amazon EKS con scalabilità on-demand dipende anch'esso da una connessione internet stabile per gestire i cluster Kubernetes nel cloud. Questa opzione non funzionerebbe efficacemente in una località remota con connettività limitata, poiché non fornisce risorse di calcolo locali."
        ]
    },
    {
        "Question Number": "33",
        "Situation": "Un'azienda fintech sta progettando una nuova piattaforma di analisi dei dati per elaborare grandi volumi di dati transazionali in tempo reale. Per garantire alte prestazioni, la piattaforma deve elaborare i dati man mano che arrivano, con un ritardo minimo, e fornire rapidamente informazioni agli utenti finali.",
        "Question": "Quale scelta architetturale soddisferebbe più efficacemente questi requisiti di alta prestazione?",
        "Options": {
            "1": "Elaborazione batch dei dati transazionali a intervalli regolari",
            "2": "Architettura basata su eventi con streaming di dati in tempo reale",
            "3": "Memorizzare tutti i dati transazionali in un database relazionale tradizionale",
            "4": "Distribuire tutti i componenti dell'applicazione in una singola availability zone per un accesso più veloce"
        },
        "Correct Answer": "Architettura basata su eventi con streaming di dati in tempo reale",
        "Explanation": "L'architettura basata su eventi con streaming di dati in tempo reale è la scelta più efficace per elaborare grandi volumi di dati transazionali in tempo reale. Questa architettura consente al sistema di reagire ai dati in arrivo man mano che arrivano, abilitando l'elaborazione e l'analisi immediata. Supporta un alto throughput e una bassa latenza, che sono critici per fornire informazioni tempestive agli utenti finali. Utilizzando tecnologie come code di messaggi e framework di elaborazione dei flussi, la piattaforma può gestire in modo efficiente flussi di dati continui e fornire risultati senza ritardi significativi.",
        "Other Options": [
            "L'elaborazione batch dei dati transazionali a intervalli regolari non è adatta per requisiti di alta prestazione che richiedono elaborazione in tempo reale. Questo approccio introduce latenza poiché i dati vengono raccolti ed elaborati in batch, il che può ritardare le informazioni e la reattività.",
            "Memorizzare tutti i dati transazionali in un database relazionale tradizionale può fornire una memorizzazione dei dati strutturata, ma non è ottimizzato per l'elaborazione in tempo reale. I database relazionali richiedono tipicamente più tempo per le query e potrebbero non gestire flussi di dati ad alta velocità in modo efficiente, portando a colli di bottiglia nelle prestazioni.",
            "Distribuire tutti i componenti dell'applicazione in una singola availability zone per un accesso più veloce non migliora intrinsecamente le prestazioni di elaborazione dei dati. Sebbene possa ridurre la latenza per l'accesso locale, non affronta la necessità di elaborazione dei dati in tempo reale e potrebbe portare a un singolo punto di guasto, compromettendo l'affidabilità del sistema."
        ]
    },
    {
        "Question Number": "34",
        "Situation": "Un'azienda di sviluppo web ospita più applicazioni su AWS, con modelli di traffico variabili. Per ottimizzare i costi, vogliono pagare solo per ciò che usano ed evitare di gestire direttamente i server.",
        "Question": "Quale approccio soddisferebbe meglio questi requisiti?",
        "Options": {
            "1": "Distribuire applicazioni su Amazon EC2 con Auto Scaling",
            "2": "Utilizzare contenitori su Amazon ECS con Fargate",
            "3": "Eseguire applicazioni su Istanze Riservate",
            "4": "Utilizzare Amazon S3 per contenuti statici e Amazon RDS per database"
        },
        "Correct Answer": "Utilizzare contenitori su Amazon ECS con Fargate",
        "Explanation": "Utilizzare Amazon ECS con Fargate consente all'azienda di sviluppo web di eseguire le proprie applicazioni in contenitori senza dover gestire i server sottostanti. Fargate provvede automaticamente alle risorse di calcolo, il che significa che l'azienda paga solo per le risorse che effettivamente utilizza in base ai modelli di traffico delle proprie applicazioni. Questo approccio serverless è ideale per ottimizzare i costi fornendo al contempo la flessibilità di scalare in base alla domanda.",
        "Other Options": [
            "Distribuire applicazioni su Amazon EC2 con Auto Scaling richiede di gestire le istanze EC2, anche se scalano automaticamente. Questo approccio potrebbe non soddisfare completamente il requisito di evitare la gestione diretta dei server, poiché l'azienda dovrebbe comunque occuparsi della provisioning e della manutenzione delle istanze.",
            "Eseguire applicazioni su Istanze Riservate comporta l'impegno a un tipo e dimensione di istanza specifici per un termine di uno o tre anni, il che non si allinea con l'obiettivo di pagare solo per ciò che usano. Questa opzione è più conveniente per carichi di lavoro prevedibili ma non fornisce la flessibilità necessaria per modelli di traffico variabili.",
            "Utilizzare Amazon S3 per contenuti statici e Amazon RDS per database è un buon approccio per casi d'uso specifici, ma non affronta il requisito di ospitare applicazioni dinamiche. Questa opzione separa la gestione dello storage e del database ma non fornisce una soluzione completa per eseguire applicazioni con modelli di traffico variabili."
        ]
    },
    {
        "Question Number": "35",
        "Situation": "Un'organizzazione di ricerca ha bisogno di memorizzare dati sperimentali in un database per l'analisi. I dati vengono utilizzati attivamente per i primi tre mesi, poi raramente accessibili ma conservati per cinque anni per conformità. Vogliono minimizzare i costi per lo storage a lungo termine.",
        "Question": "Quale politica di retention dei dati sarebbe la più conveniente?",
        "Options": {
            "1": "Memorizzare tutti i dati in un database ad alte prestazioni con backup giornalieri",
            "2": "Archiviare i dati in Amazon S3 Glacier dopo tre mesi",
            "3": "Eliminare i dati dopo tre mesi per ridurre i costi di storage",
            "4": "Spostare i dati in un livello di database a basso costo dopo tre mesi"
        },
        "Correct Answer": "Archiviare i dati in Amazon S3 Glacier dopo tre mesi",
        "Explanation": "Archiviare i dati in Amazon S3 Glacier dopo tre mesi è la soluzione più conveniente per lo storage a lungo termine. S3 Glacier è progettato per dati che vengono accessibili raramente e offre costi di storage significativamente inferiori rispetto ai database ad alte prestazioni. Poiché i dati saranno raramente accessibili dopo i primi tre mesi ma devono essere conservati per conformità per cinque anni, S3 Glacier fornisce un equilibrio adeguato tra costo e accessibilità, consentendo all'organizzazione di minimizzare le spese pur soddisfacendo i requisiti di retention.",
        "Other Options": [
            "Memorizzare tutti i dati in un database ad alte prestazioni con backup giornalieri non è conveniente per lo storage a lungo termine, specialmente poiché i dati non saranno utilizzati attivamente dopo i primi tre mesi. I database ad alte prestazioni sono tipicamente più costosi, e i backup giornalieri aggiungono costi ulteriori che sono superflui per dati che saranno accessibili raramente.",
            "Eliminare i dati dopo tre mesi può ridurre i costi di storage, ma non soddisfa il requisito di conformità di conservare i dati per cinque anni. Questa opzione esporrebbe l'organizzazione a rischi legali e normativi a causa della non conformità.",
            "Spostare i dati in un livello di database a basso costo dopo tre mesi è un'opzione migliore rispetto a mantenerli in un database ad alte prestazioni, ma potrebbe comunque essere più costosa rispetto all'archiviazione in S3 Glacier. I livelli di database a basso costo potrebbero comunque comportare costi più elevati rispetto alle soluzioni di archiviazione progettate per accessi rari, rendendo questa opzione meno ottimale per lo storage a lungo termine."
        ]
    },
    {
        "Question Number": "36",
        "Situation": "Un'organizzazione deve conformarsi alle politiche di conservazione dei dati che richiedono che alcuni documenti siano archiviati per almeno 7 anni.",
        "Question": "Quale soluzione è la più appropriata per garantire la conformità riducendo al minimo i costi di archiviazione?",
        "Options": {
            "1": "Archiviare i dati in Amazon S3 Standard con una policy di Lifecycle S3 per trasferire i dati a S3 Glacier",
            "2": "Archiviare i dati in Amazon Elastic File System (EFS) con la crittografia abilitata",
            "3": "Utilizzare Amazon RDS con backup automatici configurati per mantenere gli snapshot per 7 anni",
            "4": "Archiviare i dati in Amazon DynamoDB con backup on-demand"
        },
        "Correct Answer": "Archiviare i dati in Amazon S3 Standard con una policy di Lifecycle S3 per trasferire i dati a S3 Glacier",
        "Explanation": "Questa opzione è la più appropriata perché consente una gestione dei costi di archiviazione efficace. Amazon S3 Standard è adatto per dati accessibili frequentemente, mentre S3 Glacier è progettato per l'archiviazione a lungo termine a un costo inferiore. Implementando una policy di Lifecycle S3, l'organizzazione può automaticamente trasferire i dati a S3 Glacier dopo un periodo specificato, garantendo la conformità con la politica di conservazione di 7 anni e riducendo i costi di archiviazione nel tempo.",
        "Other Options": [
            "Archiviare i dati in Amazon Elastic File System (EFS) con la crittografia abilitata non è la scelta migliore per l'archiviazione a lungo termine a causa dei costi più elevati associati a EFS rispetto a S3 Glacier. EFS è progettato per accessi a bassa latenza ed è più costoso per archiviare dati che vengono accessibili raramente.",
            "Utilizzare Amazon RDS con backup automatici configurati per mantenere gli snapshot per 7 anni può essere costoso e potrebbe non essere necessario per dati che non richiedono le funzionalità di un database relazionale. RDS è tipicamente utilizzato per dati transazionali e potrebbe comportare costi più elevati per l'archiviazione a lungo termine rispetto a S3 Glacier.",
            "Archiviare i dati in Amazon DynamoDB con backup on-demand non è nemmeno la soluzione più economica per la conservazione a lungo termine. Sebbene DynamoDB sia ottimo per applicazioni ad alte prestazioni, il suo modello di prezzo per i backup può diventare costoso nel tempo, specialmente per i dati che devono essere conservati per diversi anni."
        ]
    },
    {
        "Question Number": "37",
        "Situation": "Un'azienda ha un bucket S3 chiamato \"secretcatproject\" che contiene dati sensibili. L'azienda deve consentire l'accesso a questo bucket da parte di utenti specifici in un account partner, garantendo al contempo che i dati rimangano sicuri da accessi pubblici.",
        "Question": "Quale metodo dovrebbe utilizzare l'azienda per concedere l'accesso necessario prevenendo accessi non autorizzati da parte di utenti anonimi?",
        "Options": {
            "1": "Impostare la policy del bucket per consentire l'accesso pubblico a tutti gli utenti per semplificare la gestione degli accessi.",
            "2": "Utilizzare una policy del bucket S3 che specifica i ruoli IAM dell'account partner come principali con permessi per accedere al bucket.",
            "3": "Abilitare \"Block Public Access\" sul bucket e utilizzare le liste di controllo degli accessi (ACL) per gestire l'accesso per l'account partner.",
            "4": "Allegare una policy IAM direttamente al bucket per controllare l'accesso per gli utenti nell'account partner."
        },
        "Correct Answer": "Utilizzare una policy del bucket S3 che specifica i ruoli IAM dell'account partner come principali con permessi per accedere al bucket.",
        "Explanation": "Utilizzare una policy del bucket S3 per specificare i ruoli IAM dell'account partner come principali consente un controllo preciso su chi può accedere al bucket. Questo metodo garantisce che solo gli utenti designati dell'account partner possano accedere ai dati sensibili, prevenendo anche qualsiasi accesso pubblico. Le policy del bucket sono strumenti potenti che possono definire permessi a livello di bucket e possono includere condizioni per ulteriori restrizioni di accesso, rendendole ideali per gestire l'accesso a dati sensibili in modo sicuro.",
        "Other Options": [
            "Impostare la policy del bucket per consentire l'accesso pubblico a tutti gli utenti è altamente insicuro e contraddice il requisito di mantenere i dati sicuri da accessi pubblici. Questo esporrebbe i dati sensibili a chiunque su Internet, il che non è accettabile.",
            "Sebbene utilizzare una policy del bucket S3 che specifica i ruoli IAM dell'account partner sia corretto, questa opzione non menziona esplicitamente l'uso dei ruoli IAM come principali, che è un aspetto cruciale per concedere l'accesso in modo sicuro. Pertanto, è meno precisa rispetto alla risposta corretta.",
            "Abilitare 'Block Public Access' è una buona pratica per prevenire l'accesso pubblico, ma utilizzare le liste di controllo degli accessi (ACL) non è il metodo migliore per gestire l'accesso in questo scenario. Le ACL possono essere più complesse e meno flessibili rispetto alle policy del bucket, e non forniscono lo stesso livello di chiarezza e controllo sui permessi come fanno le policy del bucket."
        ]
    },
    {
        "Question Number": "38",
        "Situation": "Un'azienda sta utilizzando Amazon Route 53 per gestire i record DNS del proprio dominio. Sono preoccupati per potenziali attacchi DNS, come il DNS spoofing e gli attacchi DDoS, e vogliono garantire che la loro infrastruttura DNS sia sicura.",
        "Question": "Quale delle seguenti azioni dovrebbe intraprendere l'azienda per migliorare la sicurezza della propria configurazione Route 53?",
        "Options": {
            "1": "Abilitare DNSSEC (Domain Name System Security Extensions) sulle loro zone ospitate da Route 53 per garantire che le risposte DNS siano firmate crittograficamente, prevenendo attacchi di spoofing DNS.",
            "2": "Utilizzare Route 53 Resolver DNS Firewall per filtrare le query dannose e prevenire il traffico da IP noti come dannosi, garantendo che solo il traffico legittimo raggiunga le loro risorse.",
            "3": "Configurare Route 53 per utilizzare solo HTTP per le query DNS per semplificare la sicurezza, poiché HTTP è meno soggetto ad attacchi DDoS rispetto ad altri protocolli.",
            "4": "Impostare controlli di salute Route 53 per monitorare le prestazioni delle query DNS, ma non abilitare alcuna funzionalità di sicurezza aggiuntiva, assumendo che la sicurezza DNS sia coperta da altri servizi AWS."
        },
        "Correct Answer": "Abilitare DNSSEC (Domain Name System Security Extensions) sulle loro zone ospitate da Route 53 per garantire che le risposte DNS siano firmate crittograficamente, prevenendo attacchi di spoofing DNS.",
        "Explanation": "Abilitare DNSSEC sulle zone ospitate da Route 53 aggiunge un ulteriore livello di sicurezza consentendo alle risposte DNS di essere firmate crittograficamente. Questo garantisce che le risposte siano autentiche e non siano state manomesse, prevenendo efficacemente attacchi di spoofing DNS. DNSSEC aiuta a verificare l'integrità dei dati DNS, rendendo molto più difficile per gli attaccanti reindirizzare gli utenti verso siti dannosi tramite risposte DNS contraffatte.",
        "Other Options": [
            "Utilizzare Route 53 Resolver DNS Firewall è una buona pratica per filtrare le query dannose, ma non affronta direttamente il problema dello spoofing DNS. Sebbene possa aiutare a mitigare alcune minacce, non è efficace come DNSSEC per garantire l'autenticità delle risposte DNS.",
            "Configurare Route 53 per utilizzare solo HTTP per le query DNS è errato perché le query DNS utilizzano tipicamente i protocolli UDP e TCP, non HTTP. Inoltre, HTTP non fornisce intrinsecamente sicurezza contro gli attacchi DDoS; piuttosto, può esporre l'infrastruttura DNS a maggiori rischi. Utilizzare protocolli sicuri come DNS over HTTPS (DoH) o DNS over TLS (DoT) sarebbe più appropriato.",
            "Impostare controlli di salute Route 53 è utile per monitorare le prestazioni delle query DNS, ma non migliora la sicurezza. Fare affidamento esclusivamente sui controlli di salute senza abilitare funzionalità di sicurezza aggiuntive lascia l'infrastruttura DNS vulnerabile ad attacchi come spoofing e DDoS, che possono essere mitigati implementando DNSSEC e altre misure di sicurezza."
        ]
    },
    {
        "Question Number": "39",
        "Situation": "Un'azienda vuole proteggere le credenziali dell'applicazione per una funzione AWS Lambda. La funzione deve connettersi a un database Amazon RDS.",
        "Question": "Quale approccio fornirà il modo più sicuro per memorizzare e gestire le credenziali del database?",
        "Options": {
            "1": "Memorizzare le credenziali del database in un file di configurazione in testo semplice all'interno della funzione Lambda",
            "2": "Utilizzare i ruoli IAM di AWS con permessi per accedere direttamente al database",
            "3": "Memorizzare le credenziali del database in AWS Secrets Manager e concedere alla funzione Lambda permessi per recuperare i segreti",
            "4": "Memorizzare le credenziali del database in Amazon S3 con crittografia lato server abilitata"
        },
        "Correct Answer": "Memorizzare le credenziali del database in AWS Secrets Manager e concedere alla funzione Lambda permessi per recuperare i segreti",
        "Explanation": "Utilizzare AWS Secrets Manager per memorizzare le credenziali del database è l'approccio più sicuro perché è specificamente progettato per gestire informazioni sensibili. Secrets Manager crittografa le credenziali a riposo e fornisce un controllo degli accessi dettagliato tramite AWS IAM. Questo consente alla funzione Lambda di recuperare le credenziali in modo sicuro senza codificarle nel codice della funzione o nei file di configurazione. Inoltre, Secrets Manager può ruotare automaticamente le credenziali, migliorando ulteriormente la sicurezza.",
        "Other Options": [
            "Memorizzare le credenziali del database in un file di configurazione in testo semplice all'interno della funzione Lambda è altamente insicuro. Espone informazioni sensibili direttamente nel codice, rendendole vulnerabili ad accessi non autorizzati se il codice viene mai esposto o condiviso.",
            "Utilizzare i ruoli IAM di AWS con permessi per accedere direttamente al database non affronta la necessità di memorizzare in modo sicuro le credenziali del database. Sebbene i ruoli IAM possano gestire i permessi di accesso, non forniscono un meccanismo per memorizzare in modo sicuro informazioni sensibili come le credenziali del database.",
            "Memorizzare le credenziali del database in Amazon S3 con crittografia lato server abilitata è meglio rispetto alla memorizzazione in testo semplice, ma non è ancora sicuro come utilizzare Secrets Manager. S3 non è progettato per gestire segreti e, sebbene la crittografia lato server protegga i dati a riposo, non fornisce lo stesso livello di controllo degli accessi e funzionalità di gestione dei segreti che offre Secrets Manager."
        ]
    },
    {
        "Question Number": "40",
        "Situation": "Immagina di essere incaricato di costruire una connessione altamente resiliente tra il tuo data center on-premises e AWS utilizzando AWS Direct Connect per un'applicazione critica.",
        "Question": "Poiché Direct Connect è un collegamento fisico senza resilienza intrinseca, qual è il miglior approccio per garantire la tolleranza ai guasti?",
        "Options": {
            "1": "Implementare due connessioni Direct Connect in luoghi separati (DX Locations) all'interno della stessa regione AWS per fornire percorsi ridondanti nel caso in cui una connessione fallisca.",
            "2": "Utilizzare una singola connessione Direct Connect ad alta larghezza di banda per ridurre il rischio di interruzioni a causa di sovraccarico.",
            "3": "Implementare una connessione Direct Connect abbinata a un backup VPN per mantenere la connettività se il collegamento Direct Connect si interrompe.",
            "4": "Stabilire connessioni Direct Connect in diverse regioni AWS per garantire la connettività se una regione incontra un problema."
        },
        "Correct Answer": "Implementare una connessione Direct Connect abbinata a un backup VPN per mantenere la connettività se il collegamento Direct Connect si interrompe.",
        "Explanation": "Implementare una connessione Direct Connect abbinata a un backup VPN è il miglior approccio per garantire la tolleranza ai guasti perché fornisce un percorso secondario per la trasmissione dei dati. Se il collegamento Direct Connect fallisce, la VPN può subentrare, garantendo una connettività continua. Questo approccio ibrido sfrutta l'affidabilità di Direct Connect mentre utilizza anche la VPN basata su Internet come opzione di failover, migliorando così la resilienza complessiva.",
        "Other Options": [
            "Implementare due connessioni Direct Connect in luoghi separati all'interno della stessa regione AWS potrebbe fornire ridondanza, ma non affronta il potenziale per un'interruzione regionale o altri problemi che potrebbero influenzare entrambe le connessioni. Inoltre, potrebbe non essere conveniente rispetto a una soluzione ibrida con una VPN.",
            "Utilizzare una singola connessione Direct Connect ad alta larghezza di banda non fornisce alcuna tolleranza ai guasti. Se quella connessione si interrompe, non ci sarebbe alcun percorso alternativo per i dati, portando a potenziali tempi di inattività per l'applicazione critica.",
            "Stabilire connessioni Direct Connect in diverse regioni AWS potrebbe fornire un certo livello di ridondanza, ma potrebbe introdurre latenza e complessità nella gestione del traffico interregionale. Inoltre, non garantisce che entrambe le connessioni siano disponibili simultaneamente, specialmente se ci sono problemi che influenzano le regioni stesse."
        ]
    },
    {
        "Question Number": "41",
        "Situation": "Un'azienda sta pianificando di migrare le proprie applicazioni su AWS e desidera comprendere le responsabilità di sicurezza che deve gestire come parte del Modello di Responsabilità Condivisa di AWS. L'azienda utilizzerà Amazon EC2 per i propri server applicativi, Amazon RDS per i propri database e Amazon S3 per l'archiviazione dei dati.",
        "Question": "Quali delle seguenti responsabilità manterrà l'azienda e quali gestirà AWS?",
        "Options": {
            "1": "L'azienda è responsabile della sicurezza dell'infrastruttura fisica sottostante, mentre AWS gestisce la crittografia dei dati a riposo.",
            "2": "AWS è responsabile della patching delle istanze Amazon EC2, mentre l'azienda gestisce il filtraggio del traffico di rete utilizzando gruppi di sicurezza e ACL di rete.",
            "3": "L'azienda è responsabile della gestione delle configurazioni di sicurezza di Amazon RDS, inclusa la patching del software del database, mentre AWS gestisce la sicurezza dei data center in cui sono ospitate le istanze RDS.",
            "4": "AWS gestisce la sicurezza dei dati dei clienti archiviati in Amazon S3, mentre l'azienda è responsabile della configurazione delle autorizzazioni di accesso e delle impostazioni di crittografia per tali dati."
        },
        "Correct Answer": "L'azienda è responsabile della gestione delle configurazioni di sicurezza di Amazon RDS, inclusa la patching del software del database, mentre AWS gestisce la sicurezza dei data center in cui sono ospitate le istanze RDS.",
        "Explanation": "Nel Modello di Responsabilità Condivisa di AWS, AWS è responsabile della sicurezza dell'infrastruttura cloud, che include la sicurezza fisica dei data center e l'hardware che esegue i servizi AWS. Tuttavia, i clienti sono responsabili della sicurezza delle proprie applicazioni e dati, inclusa la gestione delle configurazioni e la patching di servizi come Amazon RDS. Ciò significa che mentre AWS protegge l'infrastruttura sottostante, l'azienda deve garantire che le configurazioni del proprio database siano sicure e aggiornate.",
        "Other Options": [
            "L'azienda è responsabile della sicurezza delle proprie applicazioni e dati, non dell'infrastruttura fisica sottostante, che è gestita da AWS. AWS gestisce la crittografia dei dati a riposo, ma è responsabilità dell'azienda implementarla per i propri dati.",
            "AWS è responsabile della patching dell'infrastruttura sottostante, ma l'azienda deve gestire la patching del sistema operativo e a livello di applicazione per le istanze Amazon EC2. L'azienda è anche responsabile della configurazione dei gruppi di sicurezza e delle ACL di rete per il filtraggio del traffico di rete.",
            "AWS gestisce la sicurezza dell'infrastruttura che supporta Amazon S3, ma l'azienda è responsabile della gestione delle autorizzazioni di accesso e delle impostazioni di crittografia per i dati che archivia in S3. AWS non gestisce direttamente la sicurezza dei dati dei clienti; fornisce gli strumenti per consentire ai clienti di proteggere i propri dati."
        ]
    },
    {
        "Question Number": "42",
        "Situation": "Un'azienda sta progettando una Virtual Private Cloud (VPC) con più sottoreti in diverse Availability Zone (AZ). Devono garantire che ogni sottorete sia definita in modo univoco, non si sovrapponga ad altre sottoreti e che alcuni indirizzi IP siano riservati per funzioni specifiche all'interno di ciascuna sottorete.",
        "Question": "Quali delle seguenti linee guida dovrebbero seguire per configurare correttamente le loro sottoreti ed evitare conflitti IP? (Scegli due.)",
        "Options": {
            "1": "Definire un blocco CIDR unico per ciascuna sottorete, assicurarsi che si sovrapponga ad altre sottoreti in diverse AZ e utilizzare indirizzi IP riservati per funzioni di rete e broadcast.",
            "2": "Utilizzare lo stesso blocco CIDR per tutte le sottoreti all'interno della VPC, consentendo alle sottoreti di comunicare senza problemi tra le AZ e riservare il primo indirizzo IP in ciascuna sottorete per DNS.",
            "3": "Assegnare blocchi CIDR non sovrapposti a ciascuna sottorete all'interno della VPC, con una sottorete per AZ, e riservare indirizzi IP specifici (come gli indirizzi di rete e broadcast) secondo i requisiti di AWS.",
            "4": "Allocare un singolo grande blocco CIDR per tutte le sottoreti all'interno della VPC e utilizzare il Dynamic Host Configuration Protocol (DHCP) per prevenire conflitti IP tra le sottoreti.",
            "5": "Assicurarsi che il blocco CIDR di ciascuna sottorete sia un sottoinsieme del blocco CIDR della VPC e pianificare gli intervalli IP per accogliere la crescita futura senza sovrapposizioni."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Assegnare blocchi CIDR non sovrapposti a ciascuna sottorete all'interno della VPC, con una sottorete per AZ, e riservare indirizzi IP specifici (come gli indirizzi di rete e broadcast) secondo i requisiti di AWS.",
            "Assicurarsi che il blocco CIDR di ciascuna sottorete sia un sottoinsieme del blocco CIDR della VPC e pianificare gli intervalli IP per accogliere la crescita futura senza sovrapposizioni."
        ],
        "Explanation": "Le risposte corrette sono le opzioni 3 e 5. L'opzione 3 è corretta perché assegnare blocchi CIDR non sovrapposti a ciascuna sottorete all'interno della VPC garantisce che ogni sottorete sia definita in modo univoco e non confligga con altre sottoreti. Riservare indirizzi IP specifici per funzioni di rete e broadcast è una prassi standard nella progettazione di reti. L'opzione 5 è corretta perché il blocco CIDR di ciascuna sottorete dovrebbe essere un sottoinsieme del blocco CIDR della VPC. Questo garantisce che gli indirizzi IP all'interno della sottorete siano unici all'interno della VPC. Pianificare gli intervalli IP per accogliere la crescita futura senza sovrapposizioni è una buona prassi per evitare potenziali conflitti IP in futuro.",
        "Other Options": [
            "I blocchi CIDR sovrapposti tra le sottoreti possono portare a conflitti IP. Inoltre, sebbene sia vero che alcuni indirizzi IP debbano essere riservati per funzioni di rete e broadcast, questa opzione suggerisce erroneamente che i blocchi CIDR sovrapposti siano una buona prassi.",
            "Utilizzare lo stesso blocco CIDR per tutte le sottoreti all'interno della VPC può portare a conflitti IP. Sebbene sia vero che il primo indirizzo IP in ciascuna sottorete sia tipicamente riservato per DNS, questa opzione suggerisce erroneamente che utilizzare lo stesso blocco CIDR per tutte le sottoreti sia una buona prassi.",
            "Allocare un singolo grande blocco CIDR per tutte le sottoreti all'interno della VPC può portare a conflitti IP. Sebbene il DHCP possa aiutare a gestire gli indirizzi IP all'interno di una sottorete, non può prevenire conflitti IP tra sottoreti che condividono lo stesso blocco CIDR."
        ]
    },
    {
        "Question Number": "43",
        "Situation": "Un'azienda sta utilizzando Amazon RDS per le proprie esigenze di database, ma è preoccupata per la scalabilità e la disponibilità delle proprie connessioni al database. Vogliono migliorare la gestione delle connessioni al database e garantire un'alta disponibilità per la propria applicazione senza sovraccaricare le istanze RDS.",
        "Question": "Quale servizio AWS dovrebbe utilizzare l'azienda per raggiungere questo obiettivo e quali sono i suoi vantaggi?",
        "Options": {
            "1": "Utilizzare Amazon RDS Proxy per gestire le connessioni al database, raggruppando e multiplexando le connessioni per ridurre il carico sulle istanze RDS e migliorare la scalabilità.",
            "2": "Utilizzare Amazon CloudFront come proxy per memorizzare nella cache le query del database e ridurre il carico sull'istanza RDS.",
            "3": "Utilizzare Amazon SQS per mettere in coda le richieste al database e elaborarle in modo sequenziale, garantendo un'alta disponibilità delle connessioni al database.",
            "4": "Utilizzare Amazon ElastiCache per proxy e memorizzare nella cache le query del database per ridurre al minimo il carico sul database."
        },
        "Correct Answer": "Utilizzare Amazon RDS Proxy per gestire le connessioni al database, raggruppando e multiplexando le connessioni per ridurre il carico sulle istanze RDS e migliorare la scalabilità.",
        "Explanation": "Amazon RDS Proxy è specificamente progettato per migliorare la gestione delle connessioni al database per Amazon RDS. Fornisce pooling e multiplexing delle connessioni, il che aiuta a ridurre il numero di connessioni che devono essere stabilite con le istanze RDS. Questo non solo migliora la scalabilità dell'applicazione consentendo più connessioni concorrenti, ma migliora anche la disponibilità gestendo senza problemi gli scenari di failover. Utilizzando RDS Proxy, l'azienda può garantire che le proprie connessioni al database siano gestite in modo efficiente, riducendo il carico sulle istanze RDS e migliorando le prestazioni complessive dell'applicazione.",
        "Other Options": [
            "Utilizzare Amazon CloudFront come proxy per memorizzare nella cache le query del database è errato perché CloudFront è principalmente una rete di distribuzione dei contenuti (CDN) progettata per memorizzare nella cache contenuti statici e accelerare la consegna delle applicazioni web, non per gestire le connessioni al database o memorizzare nella cache le query del database.",
            "Utilizzare Amazon SQS per mettere in coda le richieste al database non è adatto per questo scenario perché SQS è un servizio di messaggistica progettato per disaccoppiare e scalare microservizi, sistemi distribuiti e applicazioni serverless. Non gestisce direttamente le connessioni al database o migliora la loro disponibilità.",
            "Utilizzare Amazon ElastiCache per proxy e memorizzare nella cache le query del database non è la migliore opzione in questo contesto. Sebbene ElastiCache possa essere utilizzato per memorizzare nella cache i dati frequentemente accessibili per ridurre il carico sul database, non gestisce le connessioni al database o fornisce pooling delle connessioni, che è la principale preoccupazione per la scalabilità e la disponibilità in questo scenario."
        ]
    },
    {
        "Question Number": "44",
        "Situation": "Un'azienda sta pianificando di migrare la propria applicazione monolitica a un'architettura containerizzata per migliorare la scalabilità, la portabilità e la gestione delle risorse. L'azienda desidera suddividere l'applicazione monolitica in componenti più piccoli e gestibili per garantire una scalabilità efficiente durante i picchi di traffico. Devono anche garantire che l'applicazione possa essere facilmente spostata tra ambienti e piattaforme.",
        "Question": "Qual è l'approccio più efficace per migrare la loro applicazione in contenitori?",
        "Options": {
            "1": "Containerizzare ciascun componente dell'applicazione creando immagini Docker per ciascun microservizio e distribuire i contenitori su Amazon ECS o EKS per orchestrazione e gestione.",
            "2": "Migrare l'intera applicazione come macchina virtuale su AWS utilizzando Amazon EC2 e gestire l'applicazione tramite un gruppo di Auto Scaling EC2.",
            "3": "Utilizzare AWS Lambda per migrare l'applicazione e suddividerla in funzioni serverless per eliminare la necessità di contenitori.",
            "4": "Archiviare l'applicazione in Amazon S3 e utilizzare AWS Fargate per eseguire l'applicazione in un ambiente containerizzato gestito."
        },
        "Correct Answer": "Containerizzare ciascun componente dell'applicazione creando immagini Docker per ciascun microservizio e distribuire i contenitori su Amazon ECS o EKS per orchestrazione e gestione.",
        "Explanation": "Questo approccio è il più efficace per migrare un'applicazione monolitica a un'architettura containerizzata perché consente di suddividere l'applicazione in microservizi più piccoli e gestibili. Creando immagini Docker per ciascun componente, l'azienda può garantire che ogni microservizio sia indipendentemente distribuibile, scalabile e manutenibile. Utilizzare Amazon ECS (Elastic Container Service) o EKS (Elastic Kubernetes Service) fornisce robuste capacità di orchestrazione e gestione, consentendo una scalabilità efficiente durante i picchi di traffico e un movimento senza soluzione di continuità tra diversi ambienti e piattaforme.",
        "Other Options": [
            "Migrare l'intera applicazione come macchina virtuale su AWS utilizzando Amazon EC2 non sfrutta appieno i vantaggi della containerizzazione. Sebbene consenta la scalabilità tramite gruppi di Auto Scaling EC2, non suddivide l'applicazione monolitica in microservizi, il che è essenziale per raggiungere la scalabilità e la gestione delle risorse desiderate.",
            "Utilizzare AWS Lambda per migrare l'applicazione in funzioni serverless non è adatto per tutte le applicazioni, specialmente quelle che non sono progettate per essere serverless. Questo approccio potrebbe richiedere una significativa riprogettazione dell'applicazione e non utilizza contenitori, che l'azienda sta specificamente cercando di implementare.",
            "Archiviare l'applicazione in Amazon S3 e utilizzare AWS Fargate per eseguire l'applicazione in un ambiente containerizzato gestito non è una soluzione completa. Sebbene Fargate consenta di eseguire contenitori senza gestire server, semplicemente archiviare l'applicazione in S3 non affronta la necessità di suddividere l'applicazione monolitica in microservizi o creare immagini Docker, che sono critiche per una containerizzazione efficace."
        ]
    },
    {
        "Question Number": "45",
        "Situation": "Un'azienda di servizi finanziari deve proteggere la propria nuova applicazione web con HTTPS per proteggere i dati dei clienti. Vogliono una soluzione che semplifichi l'emissione, il deployment e il rinnovo dei certificati SSL/TLS per evitare il rischio di certificati scaduti che causano inattività. Con la maggior parte della loro infrastruttura su AWS, stanno considerando AWS Certificate Manager (ACM) per gestire i certificati attraverso servizi come ELB, CloudFront e API Gateway.",
        "Question": "Come supporta AWS Certificate Manager (ACM) la gestione sicura e automatizzata dei certificati SSL/TLS per le esigenze dell'azienda?",
        "Options": {
            "1": "ACM consente l'emissione e il rinnovo manuale dei certificati, fornendo controllo sul processo di rinnovo.",
            "2": "ACM emette, distribuisce e rinnova automaticamente i certificati, si integra con i servizi AWS e offre certificati gratuiti quando utilizzati con le risorse AWS.",
            "3": "ACM supporta solo certificati autofirmati, richiedendo all'azienda di gestire i rinnovi e la sicurezza separatamente.",
            "4": "ACM emette certificati ma richiede strumenti di terze parti per i rinnovi e non si integra direttamente con i servizi AWS."
        },
        "Correct Answer": "ACM emette, distribuisce e rinnova automaticamente i certificati, si integra con i servizi AWS e offre certificati gratuiti quando utilizzati con le risorse AWS.",
        "Explanation": "AWS Certificate Manager (ACM) semplifica la gestione dei certificati SSL/TLS automatizzando i processi di emissione, distribuzione e rinnovo. Ciò significa che l'azienda di servizi finanziari può evitare il rischio di certificati scaduti che causano inattività, poiché ACM gestisce automaticamente i rinnovi. Inoltre, ACM si integra perfettamente con vari servizi AWS come Elastic Load Balancing (ELB), CloudFront e API Gateway, e fornisce certificati senza costi quando utilizzati con questi servizi, rendendolo una soluzione economica per proteggere la loro applicazione web.",
        "Other Options": [
            "Sebbene ACM consenta l'emissione e il rinnovo manuale dei certificati, le esigenze dell'azienda sono focalizzate sull'automazione per evitare il rischio di certificati scaduti. I processi manuali non semplificherebbero la loro gestione dei certificati come richiesto.",
            "ACM non supporta solo certificati autofirmati. Emissione principalmente certificati pubblici che sono fidati dai browser e dai clienti, il che è essenziale per proteggere i dati dei clienti in un ambiente di produzione.",
            "ACM non richiede strumenti di terze parti per i rinnovi; automatizza il processo di rinnovo. Inoltre, ACM è progettato per integrarsi direttamente con i servizi AWS, che è una caratteristica chiave che supporta le esigenze infrastrutturali dell'azienda."
        ]
    },
    {
        "Question Number": "46",
        "Situation": "",
        "Question": "Quale funzionalità di Amazon Redshift garantisce la durabilità e la resilienza dei dati fornendo capacità di backup e recupero in caso di disastro?",
        "Options": {
            "1": "Enhanced VPC Routing, che consente una rete personalizzata all'interno di una VPC.",
            "2": "Slices nei nodi di calcolo, che abilitano la distribuzione dei dati e delle query su più nodi.",
            "3": "Automatic Snapshots to S3, dove i dati vengono salvati ogni 8 ore o a incrementi di 5GB su Amazon S3 per la durabilità.",
            "4": "Redshift Spectrum, che consente di interrogare direttamente i dati in S3 senza caricarli in Redshift."
        },
        "Correct Answer": "Automatic Snapshots to S3, dove i dati vengono salvati ogni 8 ore o a incrementi di 5GB su Amazon S3 per la durabilità.",
        "Explanation": "Amazon Redshift fornisce Automatic Snapshots to S3 come funzionalità chiave per garantire la durabilità e la resilienza dei dati. Questa funzionalità esegue automaticamente il backup dei dati memorizzati in Redshift su Amazon S3 ogni 8 ore o ogni volta che la dimensione dei dati aumenta di 5GB. Questi snapshot sono cruciali per il recupero in caso di disastro, poiché consentono agli utenti di ripristinare i propri dati a uno stato precedente in caso di perdita o corruzione dei dati, garantendo così l'integrità e la disponibilità dei dati.",
        "Other Options": [
            "Enhanced VPC Routing è principalmente focalizzato sul miglioramento della sicurezza della rete e della gestione del traffico all'interno di una Virtual Private Cloud (VPC) e non si riferisce direttamente alla durabilità dei dati o alle capacità di backup.",
            "Slices nei nodi di calcolo si riferiscono al modo in cui i dati vengono distribuiti e elaborati su più nodi in un cluster Redshift. Sebbene questo migliori le prestazioni e la scalabilità, non fornisce funzionalità di backup o recupero in caso di disastro.",
            "Redshift Spectrum consente agli utenti di interrogare i dati direttamente in Amazon S3 senza caricarli in Redshift, il che è utile per accedere a grandi set di dati, ma non fornisce capacità di backup o recupero in caso di disastro."
        ]
    },
    {
        "Question Number": "47",
        "Situation": "Un'azienda sta progettando un'architettura di rete sicura su AWS, con alcune risorse che richiedono accesso pubblico e altre limitate all'accesso privato all'interno di una VPC. Vogliono garantire che i dati sensibili nei servizi privati siano isolati da Internet, consentendo al contempo l'accesso sicuro a determinati servizi pubblici di AWS.",
        "Question": "Quale delle seguenti soluzioni soddisfa meglio i loro requisiti di sicurezza?",
        "Options": {
            "1": "Distribuire tutte le risorse nella AWS Public Zone con IP pubblici, poiché ciò semplifica la gestione dell'accesso e della sicurezza.",
            "2": "Posizionare istanze EC2 sensibili in una subnet privata all'interno della AWS Private Zone, accedere a Internet tramite un gateway NAT e utilizzare una VPN o Direct Connect per un accesso sicuro on-premises alla VPC.",
            "3": "Utilizzare subnet pubbliche per servizi sensibili e limitare l'accesso applicando gruppi di sicurezza per controllare il traffico in entrata e in uscita.",
            "4": "Configurare servizi privati in subnet pubbliche per accedere direttamente ai servizi AWS tramite Internet senza utilizzare l'IGW o la VPN."
        },
        "Correct Answer": "Posizionare istanze EC2 sensibili in una subnet privata all'interno della AWS Private Zone, accedere a Internet tramite un gateway NAT e utilizzare una VPN o Direct Connect per un accesso sicuro on-premises alla VPC.",
        "Explanation": "Questo approccio isola efficacemente i dati e le risorse sensibili posizionandoli in una subnet privata, che non è direttamente accessibile da Internet. L'uso di un gateway NAT consente a queste istanze private di avviare traffico in uscita verso Internet (per aggiornamenti, ecc.) mentre impedisce il traffico in entrata da Internet, mantenendo così la sicurezza. Inoltre, utilizzare una VPN o Direct Connect fornisce una connessione sicura per l'accesso on-premises alla VPC, garantendo che i dati sensibili rimangano protetti da esposizione pubblica.",
        "Other Options": [
            "Distribuire tutte le risorse nella AWS Public Zone con IP pubblici semplifica l'accesso ma espone tutte le risorse a Internet, il che rappresenta un rischio significativo per la sicurezza dei dati sensibili.",
            "Utilizzare subnet pubbliche per servizi sensibili contraddice il requisito di isolamento da Internet. Le subnet pubbliche sono accessibili da Internet, il che potrebbe portare a accessi non autorizzati ai dati sensibili.",
            "Configurare servizi privati in subnet pubbliche per accedere direttamente ai servizi AWS tramite Internet senza utilizzare l'IGW o la VPN non è fattibile, poiché le subnet pubbliche sono intrinsecamente esposte a Internet, il che non soddisfa il requisito di sicurezza di isolare i dati sensibili."
        ]
    },
    {
        "Question Number": "48",
        "Situation": "Un'azienda sta distribuendo una nuova applicazione basata su microservizi su AWS. Ogni microservizio è confezionato in un contenitore Docker. L'applicazione richiede orchestrazione per gestire i contenitori, gestire la scalabilità e garantire alta disponibilità.",
        "Question": "Quale servizio AWS dovrebbe raccomandare l'architetto delle soluzioni per l'orchestrazione dei contenitori?",
        "Options": {
            "1": "Amazon EC2 Auto Scaling",
            "2": "AWS Lambda",
            "3": "Amazon Elastic Kubernetes Service (EKS)",
            "4": "Amazon Elastic Container Service (ECS)"
        },
        "Correct Answer": "Amazon Elastic Kubernetes Service (EKS)",
        "Explanation": "Amazon Elastic Kubernetes Service (EKS) è un servizio completamente gestito che semplifica l'esecuzione di Kubernetes su AWS senza la necessità di installare e gestire il proprio piano di controllo o nodi Kubernetes. Fornisce l'orchestrazione necessaria per gestire i contenitori Docker, inclusa la scalabilità e l'alta disponibilità. EKS è particolarmente adatto per architetture a microservizi, poiché consente il deployment, la scalabilità e la gestione di applicazioni containerizzate utilizzando Kubernetes, che è uno strumento di orchestrazione ampiamente adottato nel settore.",
        "Other Options": [
            "Amazon EC2 Auto Scaling è un servizio che regola automaticamente il numero di istanze EC2 in risposta alla domanda. Sebbene possa aiutare a scalare le applicazioni, non fornisce capacità di orchestrazione dei contenitori specificamente per gestire i contenitori Docker.",
            "AWS Lambda è un servizio di calcolo serverless che esegue codice in risposta a eventi e gestisce automaticamente le risorse di calcolo necessarie. Non è progettato per l'orchestrazione dei contenitori ed è più adatto per architetture basate su eventi piuttosto che per gestire più microservizi in contenitori.",
            "Amazon Elastic Container Service (ECS) è un altro servizio di orchestrazione dei contenitori fornito da AWS. Sebbene sia in grado di gestire i contenitori Docker e possa gestire scalabilità e alta disponibilità, la domanda richiede specificamente l'orchestrazione, e EKS è spesso preferito per le applicazioni basate su Kubernetes grazie alle sue ampie funzionalità e al supporto della comunità."
        ]
    },
    {
        "Question Number": "49",
        "Situation": "Una piattaforma di e-commerce in rapida crescita desidera gestire in modo efficiente le richieste API in arrivo mentre espande i propri servizi backend per gestire alti volumi di traffico. Vogliono garantire che le richieste siano autorizzate, validate, trasformate e memorizzate nella cache per prestazioni ottimali. Inoltre, la piattaforma cerca di monitorare i cicli di richiesta-risposta e raccogliere metriche dettagliate sull'uso.",
        "Question": "Quale servizio AWS dovrebbe utilizzare l'azienda per costruire uno strato di gestione API affidabile e scalabile, e quali funzionalità specifiche di questo servizio supporterebbero i loro requisiti?",
        "Options": {
            "1": "Amazon API Gateway, poiché può gestire autorizzazione, limitazione, memorizzazione nella cache e si integra perfettamente con AWS CloudWatch per il monitoraggio in tempo reale e la raccolta di metriche.",
            "2": "AWS Lambda, poiché fornisce capacità di calcolo serverless e può essere utilizzato per gestire, autorizzare e elaborare ogni richiesta in modo indipendente.",
            "3": "Istanze Amazon EC2 con NGINX per gestire il bilanciamento del carico e la memorizzazione nella cache, sfruttando gli agenti CloudWatch per metriche e registrazione.",
            "4": "Amazon S3 con URL firmati per limitare l'accesso e CloudFront per la memorizzazione nella cache, poiché questo può ridurre il carico sui servizi backend."
        },
        "Correct Answer": "Amazon API Gateway, poiché può gestire autorizzazione, limitazione, memorizzazione nella cache e si integra perfettamente con AWS CloudWatch per il monitoraggio in tempo reale e la raccolta di metriche.",
        "Explanation": "Amazon API Gateway è specificamente progettato per creare, distribuire e gestire API su larga scala. Fornisce funzionalità integrate per autorizzazione (utilizzando AWS IAM, autorizzatori Lambda o Amazon Cognito), validazione delle richieste, trasformazione di richieste e risposte e memorizzazione nella cache per migliorare le prestazioni. Inoltre, si integra con AWS CloudWatch, consentendo alla piattaforma di monitorare l'uso delle API, tracciare i cicli di richiesta-risposta e raccogliere metriche dettagliate, il che si allinea perfettamente con i requisiti dell'azienda per gestire in modo efficiente alti volumi di traffico.",
        "Other Options": [
            "AWS Lambda è un servizio di calcolo serverless che può elaborare richieste ma non fornisce un completo strato di gestione API. Sebbene possa gestire autorizzazione e elaborazione delle richieste, manca delle funzionalità integrate per la memorizzazione nella cache, la limitazione e il monitoraggio completo che offre API Gateway.",
            "Le istanze Amazon EC2 con NGINX possono essere configurate per gestire il bilanciamento del carico e la memorizzazione nella cache, ma questo approccio richiede una configurazione e una gestione più manuali rispetto a API Gateway. Inoltre, mentre gli agenti CloudWatch possono fornire metriche, non offrono lo stesso livello di integrazione e facilità d'uso per la gestione delle API come API Gateway.",
            "Amazon S3 con URL firmati e CloudFront può fornire accesso sicuro e memorizzazione nella cache per contenuti statici, ma non è adatto per gestire richieste API dinamiche. Questa soluzione manca delle funzionalità necessarie per autorizzazione, validazione delle richieste e monitoraggio dettagliato dell'uso delle API, che sono critiche per le esigenze della piattaforma di e-commerce."
        ]
    },
    {
        "Question Number": "50",
        "Situation": "Un'azienda sta configurando una VPC con più subnet per un'applicazione web multi-tier. La subnet pubblica dell'applicazione deve consentire l'accesso a Internet, mentre la subnet privata dovrebbe consentire solo il traffico in uscita verso Internet tramite un gateway NAT.",
        "Question": "Qual è il modo più efficiente per garantire il corretto instradamento del traffico tra queste subnet?",
        "Options": {
            "1": "Creare una tabella di routing per la subnet pubblica con una rotta predefinita (0.0.0.0/0) che punta a un internet gateway, e creare una tabella di routing per la subnet privata con una rotta verso il gateway NAT.",
            "2": "Creare una singola tabella di routing per entrambe le subnet pubbliche e private e aggiungere una rotta verso il gateway NAT per l'accesso a Internet in uscita.",
            "3": "Creare una tabella di routing per la subnet privata che punta direttamente all'internet gateway per il traffico esterno.",
            "4": "Utilizzare Amazon Route 53 per gestire l'instradamento per entrambe le subnet e instradare tutto il traffico verso un server DNS interno."
        },
        "Correct Answer": "Creare una tabella di routing per la subnet pubblica con una rotta predefinita (0.0.0.0/0) che punta a un internet gateway, e creare una tabella di routing per la subnet privata con una rotta verso il gateway NAT.",
        "Explanation": "Questa opzione configura correttamente l'instradamento per entrambe le subnet pubbliche e private in una VPC. La subnet pubblica ha bisogno di una tabella di routing che diriga tutto il traffico in uscita (0.0.0.0/0) verso l'internet gateway, consentendo alle istanze in quella subnet di accedere direttamente a Internet. La subnet privata, d'altra parte, non dovrebbe avere accesso diretto a Internet; invece, dovrebbe instradare il traffico in uscita verso il gateway NAT, che gestirà quindi l'accesso a Internet per le istanze nella subnet privata. Questa configurazione garantisce che la subnet pubblica possa servire il traffico web mantenendo la sicurezza della subnet privata.",
        "Other Options": [
            "Creare una singola tabella di routing per entrambe le subnet pubbliche e private e aggiungere una rotta verso il gateway NAT per l'accesso a Internet in uscita è errato perché la subnet pubblica deve instradare il traffico verso l'internet gateway, non verso il gateway NAT. Il gateway NAT è solo per il traffico in uscita della subnet privata.",
            "Creare una tabella di routing per la subnet privata che punta direttamente all'internet gateway per il traffico esterno è errato perché le subnet private non dovrebbero avere accesso diretto a Internet. Dovrebbero instradare il traffico attraverso un gateway NAT per mantenere la sicurezza e prevenire l'esposizione diretta a Internet.",
            "Utilizzare Amazon Route 53 per gestire l'instradamento per entrambe le subnet e instradare tutto il traffico verso un server DNS interno è errato perché Route 53 è principalmente un servizio DNS e non gestisce l'instradamento tra le subnet in una VPC. L'instradamento è gestito dalle tabelle di routing, non dai servizi DNS."
        ]
    },
    {
        "Question Number": "51",
        "Situation": "Una piattaforma di condivisione media consente agli utenti di caricare video, che vengono poi automaticamente transcodificati in più formati per una riproduzione ottimale su diversi dispositivi. La piattaforma utilizza Google come fornitore di identità per l'autenticazione degli utenti e, dopo un accesso riuscito, gli utenti possono caricare video in un bucket Amazon S3. Una serie di funzioni Lambda vengono attivate per elaborare e caricare video, avviare lavori di transcodifica e aggiornare i metadati in una tabella DynamoDB.",
        "Question": "Quale beneficio fornisce questa architettura serverless alla piattaforma?",
        "Options": {
            "1": "Elaborazione video garantita entro una durata fissa",
            "2": "Minore onere operativo con una gestione server minima richiesta",
            "3": "Intervento manuale richiesto per i compiti di transcodifica video",
            "4": "Server dedicati per gestire un alto traffico di upload"
        },
        "Correct Answer": "Minore onere operativo con una gestione server minima richiesta",
        "Explanation": "L'architettura serverless consente alla piattaforma di sfruttare servizi cloud come AWS Lambda, S3 e DynamoDB senza la necessità di gestire i server sottostanti. Questo si traduce in un minore onere operativo poiché la piattaforma può concentrarsi sullo sviluppo e sulla scalabilità senza preoccuparsi della manutenzione dei server, della fornitura o dei problemi di scalabilità. La scalabilità automatica delle funzioni Lambda e la natura gestita di S3 e DynamoDB riducono ulteriormente la necessità di intervento manuale e gestione dei server.",
        "Other Options": [
            "L'elaborazione video garantita entro una durata fissa non è un beneficio dell'architettura serverless. Sebbene le funzioni serverless possano scalare automaticamente, non c'è garanzia sulla durata dell'elaborazione poiché può variare in base al carico di lavoro e ad altri fattori.",
            "L'intervento manuale richiesto per i compiti di transcodifica video contraddice i benefici dell'architettura serverless, progettata per automatizzare i processi. In questo scenario, l'uso delle funzioni Lambda indica che i compiti di transcodifica sono automatizzati senza intervento manuale.",
            "Server dedicati per gestire un alto traffico di upload non è una caratteristica dell'architettura serverless. Invece, le soluzioni serverless allocano dinamicamente le risorse secondo necessità, eliminando la necessità di server dedicati e consentendo un utilizzo delle risorse più efficiente."
        ]
    },
    {
        "Question Number": "52",
        "Situation": "Un'azienda di servizi finanziari sta utilizzando AWS Key Management Service (KMS) per gestire le chiavi di crittografia per dati sensibili dei clienti memorizzati su più account AWS. Il team di sicurezza deve implementare politiche di accesso per garantire che solo il personale e le applicazioni autorizzate possano accedere a chiavi specifiche, prevenendo l'accesso non autorizzato. Per conformarsi ai requisiti normativi, devono anche limitare l'accesso in base a ruoli, dipartimenti e progetti specifici.",
        "Question": "Quali approcci dovrebbero adottare per applicare efficacemente queste politiche di accesso? (Scegli due.)",
        "Options": {
            "1": "Utilizzare politiche basate sulle risorse in KMS per definire permessi di accesso specifici per ogni chiave e assegnare questi permessi agli utenti IAM, ai gruppi e ai ruoli pertinenti.",
            "2": "Creare gruppi di sicurezza per ogni dipartimento, allegare le chiavi di crittografia pertinenti e applicare permessi a livello di rete per controllare l'accesso.",
            "3": "Implementare controlli di accesso tramite politiche di bucket AWS S3 per controllare quali utenti possono accedere ai dati crittografati dalle chiavi.",
            "4": "Utilizzare ruoli di AWS Identity and Access Management (IAM) con permessi di minimo privilegio per diversi dipartimenti e progetti.",
            "5": "Fare affidamento su AWS Shield per gestire e applicare politiche di accesso alle chiavi di crittografia su tutte le risorse."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Utilizzare politiche basate sulle risorse in KMS per definire permessi di accesso specifici per ogni chiave e assegnare questi permessi agli utenti IAM, ai gruppi e ai ruoli pertinenti.",
            "Utilizzare ruoli di AWS Identity and Access Management (IAM) con permessi di minimo privilegio per diversi dipartimenti e progetti."
        ],
        "Explanation": "Le risposte corrette sono utilizzare politiche basate sulle risorse in KMS e utilizzare ruoli IAM con permessi di minimo privilegio. Le politiche basate sulle risorse in KMS consentono di specificare chi ha accesso a quali chiavi e si possono assegnare questi permessi agli utenti IAM, ai gruppi e ai ruoli pertinenti. Questo è in linea con il requisito di limitare l'accesso in base a ruoli, dipartimenti e progetti specifici. I ruoli IAM con permessi di minimo privilegio sono anche un buon approccio perché garantiscono che ogni dipartimento e progetto abbia accesso solo alle risorse di cui ha bisogno, riducendo il rischio di accesso non autorizzato.",
        "Other Options": [
            "Creare gruppi di sicurezza per ogni dipartimento e allegare le chiavi di crittografia pertinenti non è un approccio corretto perché i gruppi di sicurezza in AWS vengono utilizzati per controllare il traffico in entrata e in uscita a livello di istanza, non per gestire l'accesso alle chiavi di crittografia.",
            "Implementare controlli di accesso tramite politiche di bucket AWS S3 non è un approccio corretto perché, sebbene le politiche di bucket S3 possano controllare chi può accedere ai dati all'interno di un bucket, non gestiscono l'accesso alle chiavi di crittografia KMS.",
            "Fare affidamento su AWS Shield per gestire e applicare politiche di accesso alle chiavi di crittografia non è un approccio corretto perché AWS Shield è un servizio di protezione DDoS gestito, non un servizio per gestire l'accesso alle chiavi di crittografia."
        ]
    },
    {
        "Question Number": "53",
        "Situation": "Un'azienda ha bisogno di una strategia di disaster recovery (DR) per la sua applicazione critica che garantisca che il sistema possa recuperare rapidamente da un guasto minimizzando il downtime. L'azienda desidera ridurre al minimo l'obiettivo di tempo di recupero (RTO) e l'obiettivo di punto di recupero (RPO) ed è disposta a implementare infrastrutture aggiuntive in una regione secondaria per mantenere l'applicazione in esecuzione con un impatto minimo sulle prestazioni.",
        "Question": "Quale strategia DR dovrebbe implementare l'azienda?",
        "Options": {
            "1": "Implementare una strategia di failover attivo-attivo su due regioni, garantendo che l'applicazione sia in esecuzione in entrambe le regioni in ogni momento e che il traffico sia distribuito dinamicamente.",
            "2": "Implementare una strategia di standby caldo con infrastruttura minima in esecuzione nella regione secondaria e scalare le risorse quando viene attivato un failover.",
            "3": "Implementare una strategia di backup e ripristino, dove i dati vengono salvati su Amazon S3 e ripristinati manualmente in caso di guasto.",
            "4": "Implementare una strategia di pilot light con infrastruttura minima in esecuzione nella regione secondaria e scalare solo a piena capacità quando necessario."
        },
        "Correct Answer": "Implementare una strategia di failover attivo-attivo su due regioni, garantendo che l'applicazione sia in esecuzione in entrambe le regioni in ogni momento e che il traffico sia distribuito dinamicamente.",
        "Explanation": "Una strategia di failover attivo-attivo consente all'applicazione di funzionare simultaneamente in due regioni, il che significa che entrambe le regioni possono gestire il traffico in ogni momento. Questa configurazione minimizza significativamente il downtime, poiché non è necessario passare a una regione secondaria durante un guasto; l'applicazione è già operativa in entrambe le posizioni. Questo approccio riduce efficacemente sia l'obiettivo di tempo di recupero (RTO) che l'obiettivo di punto di recupero (RPO) poiché i dati sono continuamente sincronizzati tra le due regioni, garantendo che i dati più recenti siano sempre disponibili.",
        "Other Options": [
            "Implementare una strategia di standby caldo implica mantenere un'infrastruttura minima nella regione secondaria, che può essere scalata quando si verifica un failover. Sebbene questo migliori i tempi di recupero rispetto a un standby freddo, richiede comunque tempo per scalare le risorse, il che può portare a un aumento del downtime e a un RTO più elevato rispetto a una configurazione attivo-attivo.",
            "Una strategia di backup e ripristino si basa su backup periodici dei dati, che vengono memorizzati in un servizio come Amazon S3. In caso di guasto, il sistema deve essere ripristinato manualmente da questi backup. Questo approccio comporta tipicamente un RTO e un RPO più lunghi, poiché può richiedere tempo significativo per ripristinare l'applicazione e i dati, rendendolo inadatto per scenari in cui il downtime minimo è critico.",
            "Una strategia di pilot light mantiene una versione minima dell'applicazione in esecuzione nella regione secondaria, che può essere scalata a piena capacità durante un failover. Sebbene questo sia più efficiente rispetto a un standby freddo, richiede comunque tempo per scalare, portando a un RTO più lungo rispetto a una strategia attivo-attivo, che è sempre completamente operativa."
        ]
    },
    {
        "Question Number": "54",
        "Situation": "Un'istituzione finanziaria utilizza la crittografia per proteggere i dati dei clienti memorizzati su AWS e deve ruotare regolarmente le chiavi di crittografia e rinnovare i certificati SSL per rimanere conforme ai requisiti normativi. L'istituzione deve automatizzare la rotazione delle chiavi e il rinnovo dei certificati per evitare interventi manuali e ridurre il rischio di errore umano.",
        "Question": "Quale approccio dovrebbe adottare l'istituzione per gestire in modo efficiente la rotazione delle chiavi e il rinnovo dei certificati nel proprio ambiente AWS?",
        "Options": {
            "1": "Abilitare la rotazione automatica delle chiavi in AWS KMS e utilizzare AWS Certificate Manager (ACM) per rinnovare automaticamente i certificati SSL/TLS per i domini gestiti.",
            "2": "Ruotare manualmente le chiavi KMS ogni 90 giorni e rinnovare i certificati SSL richiedendo nuovi certificati a un fornitore di terze parti.",
            "3": "Utilizzare politiche IAM per imporre la rotazione regolare delle chiavi e il rinnovo dei certificati su tutti gli account AWS.",
            "4": "Impostare AWS CloudTrail per ruotare automaticamente le chiavi di crittografia e rinnovare i certificati quando si avvicinano alla scadenza."
        },
        "Correct Answer": "Abilitare la rotazione automatica delle chiavi in AWS KMS e utilizzare AWS Certificate Manager (ACM) per rinnovare automaticamente i certificati SSL/TLS per i domini gestiti.",
        "Explanation": "Questo approccio sfrutta i servizi AWS progettati per l'automazione e la conformità. AWS Key Management Service (KMS) consente la rotazione automatica delle chiavi, che garantisce che le chiavi di crittografia vengano ruotate regolarmente senza intervento manuale, riducendo così il rischio di errore umano. Inoltre, AWS Certificate Manager (ACM) può rinnovare automaticamente i certificati SSL/TLS per i domini gestiti, semplificando il processo e garantendo che i certificati siano sempre aggiornati. Questa combinazione soddisfa efficacemente le esigenze dell'istituzione in termini di conformità e sicurezza.",
        "Other Options": [
            "Ruotare manualmente le chiavi KMS ogni 90 giorni e rinnovare i certificati SSL richiedendo nuovi certificati a un fornitore di terze parti è inefficiente e soggetto a errore umano. Questo approccio non automatizza il processo, il che è cruciale per mantenere la conformità e ridurre il rischio di oversight.",
            "Utilizzare politiche IAM per imporre la rotazione regolare delle chiavi e il rinnovo dei certificati su tutti gli account AWS non automatizza direttamente i processi. Le politiche IAM possono imporre permessi e controlli di accesso, ma non gestiscono i compiti reali di rotazione o rinnovo, rendendo questa opzione meno efficace per le esigenze dell'istituzione.",
            "Impostare AWS CloudTrail per ruotare automaticamente le chiavi di crittografia e rinnovare i certificati quando si avvicinano alla scadenza è errato perché CloudTrail è principalmente un servizio di registrazione che traccia le chiamate API e le attività in AWS. Non ha la capacità di eseguire la rotazione automatica delle chiavi o il rinnovo dei certificati."
        ]
    },
    {
        "Question Number": "55",
        "Situation": "Una grande azienda con più account AWS desidera semplificare il proprio processo di fatturazione e garantire una gestione centralizzata dei propri account AWS. L'organizzazione desidera anche impostare politiche per gruppi specifici di account per imporre standard di sicurezza e conformità tra i dipartimenti.",
        "Question": "Quali funzionalità AWS dovrebbero utilizzare per raggiungere questi requisiti e quale ruolo svolge l'account di gestione in questa configurazione? (Scegli due.)",
        "Options": {
            "1": "Utilizzare AWS Control Tower per la gestione degli account, con l'account di gestione che gestisce la federazione dell'identità.",
            "2": "Impostare AWS Organizations con Consolidated Billing, dove l'account di gestione è responsabile della fatturazione e può invitare altri account come account membri.",
            "3": "Utilizzare AWS Identity and Access Management (IAM) per gestire i permessi per tutti gli account, con l'account root che gestisce la fatturazione per ogni account.",
            "4": "Abilitare AWS Single Sign-On (SSO) e collegare ogni account, consentendo all'account di gestione di gestire l'accesso degli utenti e la fatturazione per tutti gli account collegati.",
            "5": "Implementare AWS Service Control Policies (SCP) all'interno di AWS Organizations per imporre standard di sicurezza e conformità tra gli account membri."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Impostare AWS Organizations con Consolidated Billing, dove l'account di gestione è responsabile della fatturazione e può invitare altri account come account membri.",
            "Implementare AWS Service Control Policies (SCP) all'interno di AWS Organizations per imporre standard di sicurezza e conformità tra gli account membri."
        ],
        "Explanation": "Impostare AWS Organizations con Consolidated Billing consente all'organizzazione di centralizzare il proprio processo di fatturazione. L'account di gestione in questa configurazione è responsabile del pagamento di tutte le spese sostenute dagli account membri e può invitare o rimuovere altri account. Questa funzionalità consente anche all'organizzazione di consolidare i metodi di pagamento, rendendo il processo di fatturazione più efficiente. Implementare AWS Service Control Policies (SCP) all'interno di AWS Organizations consente all'organizzazione di gestire centralmente i permessi tra più account AWS. Le SCP possono essere utilizzate per imporre standard di sicurezza e conformità tra tutti gli account membri, il che è in linea con il requisito dell'organizzazione di impostare politiche per gruppi specifici di account.",
        "Other Options": [
            "Sebbene AWS Control Tower possa essere utilizzato per la gestione degli account, non gestisce la federazione dell'identità. La federazione dell'identità è tipicamente gestita da AWS Identity and Access Management (IAM) o AWS Single Sign-On (SSO).",
            "Sebbene AWS Identity and Access Management (IAM) possa essere utilizzato per gestire i permessi, l'account root non gestisce la fatturazione per ogni account. La fatturazione è tipicamente gestita dall'account di gestione in AWS Organizations.",
            "Sebbene AWS Single Sign-On (SSO) possa essere utilizzato per gestire l'accesso degli utenti, non gestisce direttamente la fatturazione per tutti gli account collegati. La fatturazione è tipicamente gestita dall'account di gestione in AWS Organizations."
        ]
    },
    {
        "Question Number": "56",
        "Situation": "Un'azienda ha bisogno di una connessione di rete sicura e dedicata tra il proprio data center on-premises e il proprio ambiente AWS per un accesso a bassa latenza alle applicazioni critiche. Sono preoccupati per i potenziali rischi di sicurezza legati alla trasmissione di dati sensibili su Internet.",
        "Question": "Quale soluzione AWS offre la migliore opzione per una connessione sicura e dedicata con prestazioni di rete costanti?",
        "Options": {
            "1": "Impostare un Internet Gateway (IGW) e utilizzare i gruppi di sicurezza per limitare l'accesso alle applicazioni on-premises.",
            "2": "Utilizzare AWS VPN per stabilire un tunnel IPsec sicuro su Internet, consentendo comunicazioni criptate.",
            "3": "Implementare AWS Direct Connect, che offre un collegamento di rete privato e dedicato tra il data center on-premises e AWS, con supporto per la crittografia tramite un ulteriore livello VPN se necessario.",
            "4": "Distribuire un Elastic Load Balancer (ELB) e configurare il routing verso il data center on-premises per un accesso sicuro."
        },
        "Correct Answer": "Implementare AWS Direct Connect, che offre un collegamento di rete privato e dedicato tra il data center on-premises e AWS, con supporto per la crittografia tramite un ulteriore livello VPN se necessario.",
        "Explanation": "AWS Direct Connect fornisce una connessione dedicata e privata tra il data center on-premises e AWS, ideale per un accesso a bassa latenza alle applicazioni critiche. Questa soluzione bypassa Internet pubblico, riducendo significativamente i rischi di sicurezza associati alla trasmissione di dati sensibili su Internet. Inoltre, Direct Connect può essere combinato con una VPN per una crittografia aggiuntiva, garantendo che i dati rimangano sicuri durante il transito.",
        "Other Options": [
            "Impostare un Internet Gateway (IGW) e utilizzare i gruppi di sicurezza non fornisce una connessione dedicata; piuttosto, consente l'accesso alle risorse AWS tramite Internet pubblico, il che comporta rischi di sicurezza per i dati sensibili.",
            "Utilizzare AWS VPN stabilisce un tunnel IPsec sicuro su Internet, che cripta i dati in transito. Tuttavia, si basa ancora su Internet pubblico, il che può introdurre latenza e potenziali vulnerabilità di sicurezza rispetto a una connessione dedicata.",
            "Sebbene AWS Direct Connect sia la scelta corretta, l'opzione di distribuire un Elastic Load Balancer (ELB) non è pertinente per stabilire una connessione di rete dedicata. Gli ELB vengono utilizzati per distribuire il traffico delle applicazioni in entrata su più destinazioni e non forniscono un collegamento diretto tra i data center on-premises e AWS."
        ]
    },
    {
        "Question Number": "57",
        "Situation": "Il tuo team deve implementare un servizio di messaggistica che consenta a più applicazioni di leggere, elaborare e analizzare un flusso costante di dati ad alta frequenza, come analisi in tempo reale sulle interazioni degli utenti con la tua app. Il servizio deve supportare più consumatori simultaneamente, garantendo che ciascuno possa leggere i dati all'interno di una finestra mobile definita.",
        "Question": "Quale servizio si adatta meglio a questi requisiti e perché?",
        "Options": {
            "1": "Amazon SQS, perché offre disaccoppiamento per comunicazioni asincrone con persistenza dei messaggi.",
            "2": "Amazon Kinesis, perché è ottimizzato per l'ingestione di dati su larga scala e per più consumatori con una finestra mobile per analisi in tempo reale.",
            "3": "Amazon SNS, poiché supporta più consumatori e la consegna in tempo reale a vari endpoint.",
            "4": "AWS Lambda con S3, per ingerire e elaborare dati in tempo reale utilizzando trigger basati su eventi."
        },
        "Correct Answer": "Amazon Kinesis, perché è ottimizzato per l'ingestione di dati su larga scala e per più consumatori con una finestra mobile per analisi in tempo reale.",
        "Explanation": "Amazon Kinesis è specificamente progettato per gestire flussi di dati in tempo reale ed è ottimizzato per l'ingestione di dati ad alta capacità. Consente a più consumatori di leggere dallo stesso flusso di dati simultaneamente, il che è essenziale per la necessità di avere più applicazioni che elaborano i dati in modo concorrente. Inoltre, Kinesis supporta il concetto di finestra mobile, consentendo alle applicazioni di analizzare i dati su un intervallo di tempo specificato, rendendolo ideale per analisi in tempo reale sulle interazioni degli utenti.",
        "Other Options": [
            "Amazon SQS è principalmente progettato per disaccoppiare microservizi e comunicazioni asincrone. Sebbene fornisca persistenza dei messaggi, non supporta lo streaming di dati in tempo reale o il concetto di finestra mobile per più consumatori, rendendolo meno adatto per il caso d'uso descritto.",
            "Amazon SNS è un servizio di messaggistica pub/sub che consente di inviare messaggi a più abbonati. Tuttavia, non fornisce la capacità per i consumatori di leggere i dati all'interno di una finestra mobile definita o di gestire efficacemente flussi di dati ad alta frequenza, il che è cruciale per analisi in tempo reale.",
            "AWS Lambda con S3 non è un servizio di messaggistica ma piuttosto un servizio di calcolo serverless che può elaborare dati in risposta a eventi. Sebbene possa essere utilizzato per l'elaborazione in tempo reale, si basa su S3 per l'archiviazione, che non è ottimizzato per flussi di dati ad alta frequenza o per più consumatori che accedono agli stessi dati simultaneamente."
        ]
    },
    {
        "Question Number": "58",
        "Situation": "Un'azienda media archivia grandi file video on-premises e ha bisogno di migrare questi file su Amazon S3 per un'archiviazione scalabile e accesso globale. La migrazione dovrebbe essere automatizzata e ridurre al minimo l'intervento manuale richiesto.",
        "Question": "Quale servizio AWS dovrebbe utilizzare l'architetto delle soluzioni per facilitare questo trasferimento di dati?",
        "Options": {
            "1": "AWS Snowball",
            "2": "AWS DataSync",
            "3": "Amazon S3 Transfer Acceleration",
            "4": "AWS Direct Connect"
        },
        "Correct Answer": "AWS DataSync",
        "Explanation": "AWS DataSync è specificamente progettato per automatizzare il trasferimento di grandi quantità di dati tra l'archiviazione on-premises e i servizi AWS come Amazon S3. Semplifica e accelera il processo di migrazione gestendo il trasferimento dei dati in modo efficiente, consentendo la pianificazione e il monitoraggio delle attività di trasferimento. Questo riduce al minimo l'intervento manuale ed è ideale per lo scenario descritto, in cui un'azienda media deve migrare grandi file video su S3.",
        "Other Options": [
            "AWS Snowball è una soluzione di trasporto dati fisica utilizzata per trasferire grandi quantità di dati su AWS quando il trasferimento tramite rete non è fattibile. Sebbene possa essere utilizzato per grandi migrazioni di dati, richiede la spedizione fisica dei dispositivi e non è automatizzato nello stesso modo di DataSync.",
            "Amazon S3 Transfer Acceleration è una funzionalità che accelera i caricamenti su S3 utilizzando le posizioni edge distribuite globalmente di Amazon CloudFront. Tuttavia, non automatizza il processo di trasferimento dall'archiviazione on-premises; accelera solo il trasferimento una volta avviato.",
            "AWS Direct Connect fornisce una connessione di rete dedicata da on-premises a AWS, che può migliorare la larghezza di banda e ridurre la latenza per i trasferimenti di dati. Tuttavia, non automatizza il processo di migrazione ed è più adatto per esigenze di trasferimento dati continuative piuttosto che per migrazioni una tantum."
        ]
    },
    {
        "Question Number": "59",
        "Situation": "Un'azienda SaaS ha più applicazioni che si connettono a un database centrale, risultando in un alto numero di connessioni durante le ore di punta. Vogliono ridurre i costi associati all'apertura e al mantenimento delle connessioni, garantendo al contempo prestazioni fluide del database.",
        "Question": "Quale soluzione soddisferebbe meglio questi requisiti?",
        "Options": {
            "1": "Aggiungere più istanze di database per distribuire le connessioni",
            "2": "Implementare un proxy di database per raggruppare le connessioni",
            "3": "Abilitare il deployment multi-AZ per il failover",
            "4": "Utilizzare uno strato di caching per gestire le connessioni"
        },
        "Correct Answer": "Implementare un proxy di database per raggruppare le connessioni",
        "Explanation": "Implementare un proxy di database per raggruppare le connessioni è la migliore soluzione per ridurre i costi associati all'apertura e al mantenimento delle connessioni, garantendo al contempo prestazioni fluide del database. Un proxy di database può gestire e riutilizzare le connessioni esistenti, riducendo l'overhead di stabilire nuove connessioni e diminuendo il numero totale di connessioni al database. Questo porta a una migliore utilizzazione delle risorse e può migliorare significativamente le prestazioni durante le ore di punta consentendo alle applicazioni di condividere le connessioni in modo efficiente.",
        "Other Options": [
            "Aggiungere più istanze di database per distribuire le connessioni può aiutare con il bilanciamento del carico, ma non affronta direttamente il problema dell'alto numero di connessioni. Potrebbe portare a costi maggiori senza risolvere il problema sottostante della gestione delle connessioni.",
            "Abilitare il deployment multi-AZ per il failover è principalmente una strategia per migliorare la disponibilità e il recupero da disastri. Sebbene migliori la resilienza, non riduce direttamente il numero di connessioni o i costi associati alla gestione di tali connessioni.",
            "Utilizzare uno strato di caching per gestire le connessioni può migliorare le prestazioni riducendo il carico sul database, ma non affronta specificamente il problema del raggruppamento delle connessioni. Il caching riguarda più lo stoccaggio di dati frequentemente accessibili piuttosto che la gestione delle connessioni al database."
        ]
    },
    {
        "Question Number": "60",
        "Situation": "Un'azienda richiede ai propri utenti AWS di implementare l'Autenticazione a Fattore Multiplo (MFA) per una maggiore sicurezza. Ogni utente deve utilizzare un dispositivo unico, come un'app per telefono cellulare, per generare un codice temporaneo. Il codice cambia periodicamente ed è richiesto ogni volta che accedono, oltre al loro nome utente e password.",
        "Question": "Quale delle seguenti affermazioni DESCRIVE MEGLIO il beneficio di sicurezza fornito da questo tipo di configurazione MFA?",
        "Options": {
            "1": "Garantisce che solo gli utenti che conoscono la password dell'account root AWS possano accedere.",
            "2": "Richiede agli utenti di autenticarsi con qualcosa che conoscono e qualcosa che possiedono, riducendo la probabilità di accesso non autorizzato.",
            "3": "Consente agli utenti di bypassare la password se utilizzano il codice MFA corretto.",
            "4": "Funziona solo per gli utenti che hanno accesso fisico alla console di gestione AWS."
        },
        "Correct Answer": "Richiede agli utenti di autenticarsi con qualcosa che conoscono e qualcosa che possiedono, riducendo la probabilità di accesso non autorizzato.",
        "Explanation": "Questa affermazione descrive accuratamente il beneficio di sicurezza dell'Autenticazione a Fattore Multiplo (MFA). La MFA migliora la sicurezza richiedendo due forme di verifica: qualcosa che l'utente conosce (la propria password) e qualcosa che l'utente possiede (il codice temporaneo generato dal proprio dispositivo mobile). Questo requisito duale riduce significativamente il rischio di accesso non autorizzato, poiché un attaccante avrebbe bisogno sia della password che dell'accesso al dispositivo dell'utente per ottenere l'accesso.",
        "Other Options": [
            "Questa affermazione è errata perché la MFA non garantisce specificamente che solo gli utenti che conoscono la password dell'account root AWS possano accedere. La MFA si applica a tutti gli utenti e migliora la sicurezza oltre il solo account root.",
            "Questa affermazione è errata perché è la risposta corretta. Descrive accuratamente il beneficio di sicurezza della MFA, che combina qualcosa che l'utente conosce (password) e qualcosa che possiede (codice MFA).",
            "Questa affermazione è errata perché la MFA non consente agli utenti di bypassare la password. Il codice MFA è un ulteriore livello di sicurezza che deve essere fornito insieme alla password per un'autenticazione riuscita."
        ]
    },
    {
        "Question Number": "61",
        "Situation": "Un'organizzazione sta utilizzando AWS CloudFormation per automatizzare il deployment della propria infrastruttura, inclusi risorse legate alla sicurezza come ruoli IAM, gruppi di sicurezza e volumi di archiviazione crittografati. Vogliono garantire che tutti i deployment rimangano conformi alle politiche di sicurezza e prevenire modifiche non autorizzate a risorse critiche.",
        "Question": "Quali sono le migliori pratiche che dovrebbero seguire per proteggere le loro risorse gestite da CloudFormation? (Scegli due.)",
        "Options": {
            "1": "Abilitare StackSets con rilevamento delle deviazioni di CloudFormation per monitorare le modifiche nelle risorse distribuite e utilizzare politiche IAM per limitare chi può modificare gli stack.",
            "2": "Memorizzare tutti i modelli di CloudFormation in S3 senza alcun controllo di versione per semplificare aggiornamenti e revisioni.",
            "3": "Utilizzare CloudFormation per distribuire risorse solo in subnet pubbliche, garantendo un facile accesso a tutti gli utenti dell'organizzazione.",
            "4": "Implementare regole AWS Config per convalidare gli stack di CloudFormation rispetto alle politiche di sicurezza durante il deployment.",
            "5": "Evitare di utilizzare ruoli IAM negli stack di CloudFormation per semplificare la sicurezza, facendo invece affidamento su coppie di chiavi EC2 per il controllo degli accessi."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Abilitare StackSets con rilevamento delle deviazioni di CloudFormation per monitorare le modifiche nelle risorse distribuite e utilizzare politiche IAM per limitare chi può modificare gli stack.",
            "Implementare regole AWS Config per convalidare gli stack di CloudFormation rispetto alle politiche di sicurezza durante il deployment."
        ],
        "Explanation": "Abilitare StackSets con rilevamento delle deviazioni di CloudFormation consente all'organizzazione di monitorare le modifiche nelle risorse distribuite. Questo aiuta a identificare eventuali modifiche non autorizzate a risorse critiche. Utilizzare politiche IAM per limitare chi può modificare gli stack garantisce che solo il personale autorizzato possa apportare modifiche all'infrastruttura, migliorando così la sicurezza. Implementare regole AWS Config per convalidare gli stack di CloudFormation rispetto alle politiche di sicurezza durante il deployment garantisce che tutti i deployment rimangano conformi alle politiche di sicurezza dell'organizzazione. Questo aiuta a prevenire eventuali violazioni della sicurezza.",
        "Other Options": [
            "Memorizzare tutti i modelli di CloudFormation in S3 senza alcun controllo di versione semplifica aggiornamenti e revisioni, ma non fornisce un modo per tracciare le modifiche o tornare a una versione precedente se qualcosa va storto. Questo può portare a vulnerabilità di sicurezza e quindi non è una migliore pratica.",
            "Utilizzare CloudFormation per distribuire risorse solo in subnet pubbliche non garantisce sicurezza. Sebbene fornisca un facile accesso a tutti gli utenti dell'organizzazione, espone anche le risorse a potenziali minacce esterne. Pertanto, non è una migliore pratica per proteggere le risorse gestite da CloudFormation.",
            "Evitare di utilizzare ruoli IAM negli stack di CloudFormation e fare affidamento su coppie di chiavi EC2 per il controllo degli accessi semplifica la sicurezza, ma non fornisce il controllo granulare che offrono i ruoli IAM. I ruoli IAM offrono maggiore flessibilità e controllo su chi può accedere a quali risorse, rendendoli una scelta migliore per la sicurezza. Pertanto, questa non è una migliore pratica."
        ]
    },
    {
        "Question Number": "62",
        "Situation": "Un'azienda sta impostando un nuovo ambiente AWS multi-account e vuole garantire una configurazione ben architettata con standard di sicurezza e conformità coerenti in tutti gli account. Vogliono anche capacità di monitoraggio e notifica automatizzate.",
        "Question": "Quale servizio AWS dovrebbero utilizzare per semplificare questo processo e quale caratteristica specifica li aiuterà a far rispettare regole e standard in tutti gli account di questo ambiente?",
        "Options": {
            "1": "Utilizzare AWS Organizations e implementare Service Control Policies (SCP) per l'applicazione delle regole tra gli account.",
            "2": "Utilizzare AWS Control Tower per automatizzare la configurazione e la gestione dell'ambiente multi-account, utilizzando guardrails per far rispettare le regole e monitorare la conformità.",
            "3": "Utilizzare AWS Config per ogni account e configurare manualmente le regole di conformità per monitorare le risorse.",
            "4": "Utilizzare AWS CloudFormation per distribuire un ambiente personalizzato e implementare politiche IAM per gestire gli standard di sicurezza tra gli account."
        },
        "Correct Answer": "Utilizzare AWS Control Tower per automatizzare la configurazione e la gestione dell'ambiente multi-account, utilizzando guardrails per far rispettare le regole e monitorare la conformità.",
        "Explanation": "AWS Control Tower è progettato specificamente per aiutare le organizzazioni a configurare e governare un ambiente AWS multi-account sicuro basato sulle migliori pratiche AWS. Fornisce un modo semplificato per creare account, applicare governance e garantire conformità attraverso guardrails preconfigurati, che sono regole che aiutano a far rispettare le politiche tra gli account. Questo servizio automatizza il processo di configurazione e include capacità di monitoraggio per garantire che l'ambiente aderisca agli standard definiti, rendendolo la scelta migliore per le esigenze dell'azienda.",
        "Other Options": [
            "Utilizzare AWS Organizations con Service Control Policies (SCP) è un approccio valido per gestire le autorizzazioni tra gli account, ma non fornisce le funzionalità complete di automazione e governance che offre AWS Control Tower. Le SCP riguardano più il controllo degli accessi piuttosto che l'applicazione della conformità e il monitoraggio.",
            "AWS Config è un servizio che consente di valutare, auditare e valutare le configurazioni delle risorse AWS. Sebbene possa aiutare con il monitoraggio della conformità, richiede la configurazione manuale delle regole per ogni account, il che non si allinea con il desiderio dell'azienda di una configurazione automatizzata e di un'applicazione coerente tra più account.",
            "AWS CloudFormation è un servizio per distribuire infrastruttura come codice, che può aiutare a configurare ambienti in modo coerente. Tuttavia, non fornisce intrinsecamente funzionalità di governance o monitoraggio della conformità tra più account. Le politiche IAM possono gestire gli standard di sicurezza, ma non fanno rispettare la conformità o forniscono capacità di monitoraggio automatizzato come fa AWS Control Tower."
        ]
    },
    {
        "Question Number": "63",
        "Situation": "Una piattaforma di streaming media, MediaStream, si affida fortemente ad AWS per supportare milioni di utenti simultanei in tutto il mondo. Sono preoccupati per il rischio di attacchi Distributed Denial of Service (DDoS), che potrebbero interrompere il loro servizio di streaming. MediaStream desidera una soluzione che offra protezione DDoS di base, nonché uno strato avanzato per ulteriore protezione e visibilità in tempo reale sugli eventi DDoS. Stanno considerando AWS Shield Standard e AWS Shield Advanced per proteggere la loro applicazione da potenziali attacchi su vari livelli, inclusi i livelli di rete, trasporto e applicazione. MediaStream desidera anche protezione contro le potenziali implicazioni di costo se un attacco aumenta significativamente il loro utilizzo di AWS.",
        "Question": "Quale delle seguenti affermazioni descrive meglio la differenza tra AWS Shield Standard e AWS Shield Advanced in termini di protezione e funzionalità fornite per la mitigazione DDoS sull'infrastruttura AWS?",
        "Options": {
            "1": "AWS Shield Standard fornisce protezione DDoS di base gratuitamente a tutti i clienti AWS, concentrandosi principalmente sulla protezione al perimetro dei servizi AWS, ma non include coinvolgimento proattivo o capacità avanzate di rilevamento basato sulla salute.",
            "2": "AWS Shield Advanced è un servizio gratuito disponibile per tutti i clienti AWS, offrendo protezione DDoS avanzata per attacchi a livello di applicazione (L7) e integrandosi strettamente con AWS WAF per fornire protezione dei costi e visibilità in tempo reale sugli eventi DDoS.",
            "3": "AWS Shield Standard è un servizio a pagamento che fornisce protezione automatica contro attacchi DDoS a livello di applicazione (L7) su tutti i servizi AWS, inclusi coinvolgimento proattivo da parte del team di risposta AWS Shield.",
            "4": "AWS Shield Advanced è automaticamente abilitato per tutte le risorse AWS con Elastic IP e fornisce configurazioni gratuite di web ACL, protezione proattiva dei costi e risposta immediata dal team di risposta AWS Shield per tutti gli eventi DDoS in tutte le regioni AWS."
        },
        "Correct Answer": "AWS Shield Standard fornisce protezione DDoS di base gratuitamente a tutti i clienti AWS, concentrandosi principalmente sulla protezione al perimetro dei servizi AWS, ma non include coinvolgimento proattivo o capacità avanzate di rilevamento basato sulla salute.",
        "Explanation": "AWS Shield Standard è infatti un servizio gratuito che offre protezione DDoS di base a tutti i clienti AWS. Protegge principalmente contro attacchi DDoS comuni e più frequentemente occorrenti ai livelli di rete e trasporto, concentrandosi sul perimetro dei servizi AWS. Tuttavia, non fornisce funzionalità avanzate come il coinvolgimento proattivo del team di risposta AWS Shield o capacità avanzate di rilevamento basato sulla salute, che sono disponibili solo con AWS Shield Advanced. Questo rende l'affermazione accurata nel descrivere i limiti di AWS Shield Standard rispetto a AWS Shield Advanced.",
        "Other Options": [
            "AWS Shield Advanced non è un servizio gratuito; è un servizio a pagamento che fornisce protezione DDoS avanzata, inclusi attacchi a livello di applicazione (L7) e si integra con AWS WAF. Tuttavia, offre protezione dei costi e visibilità in tempo reale, ma non è disponibile gratuitamente per tutti i clienti AWS.",
            "AWS Shield Standard non è un servizio a pagamento; è gratuito e non fornisce protezione automatica contro attacchi DDoS a livello di applicazione (L7). Il coinvolgimento proattivo da parte del team di risposta AWS Shield è una funzionalità di AWS Shield Advanced, non Standard.",
            "AWS Shield Advanced non è automaticamente abilitato per tutte le risorse AWS con Elastic IP; deve essere sottoscritto. Inoltre, sebbene fornisca protezione proattiva dei costi e risposta immediata dal team di risposta AWS Shield, non offre configurazioni gratuite di web ACL come parte del suo servizio."
        ]
    },
    {
        "Question Number": "64",
        "Situation": "Un'azienda sta costruendo un'applicazione basata su microservizi utilizzando container e desidera gestire e orchestrare questi container in modo scalabile su AWS. L'azienda sta considerando Amazon ECS e Amazon EKS per l'orchestrazione, ma non è sicura su quale servizio si adatti meglio alle proprie esigenze. Richiedono un controllo dettagliato sull'orchestrazione, networking personalizzato e gestione dei container.",
        "Question": "Quale delle seguenti descrizioni indica meglio quando l'azienda dovrebbe utilizzare Amazon EKS invece di Amazon ECS?",
        "Options": {
            "1": "Utilizzare Amazon EKS se l'azienda richiede funzionalità native di Kubernetes, come orchestrazione personalizzata e capacità di networking complesse.",
            "2": "Utilizzare Amazon ECS per tutte le esigenze di orchestrazione dei container, poiché è più semplice e più conveniente per le applicazioni containerizzate.",
            "3": "Utilizzare Amazon EKS se l'azienda ha bisogno di un servizio di container completamente gestito che gestisca automaticamente scaling e bilanciamento del carico per tutti i carichi di lavoro containerizzati.",
            "4": "Utilizzare Amazon ECS solo se l'azienda sta utilizzando container serverless, poiché Amazon EKS non supporta carichi di lavoro serverless."
        },
        "Correct Answer": "Utilizzare Amazon EKS se l'azienda richiede funzionalità native di Kubernetes, come orchestrazione personalizzata e capacità di networking complesse.",
        "Explanation": "Amazon EKS (Elastic Kubernetes Service) è progettato per gli utenti che necessitano delle funzionalità avanzate e della flessibilità che offre Kubernetes. Questo include controllo dettagliato sull'orchestrazione, la possibilità di implementare soluzioni di networking personalizzate e l'uso di strumenti e API native di Kubernetes. Se l'azienda cerca queste capacità, EKS è la scelta migliore rispetto a ECS (Elastic Container Service), che è più semplice e ha un approccio più definito all'orchestrazione dei container.",
        "Other Options": [
            "Questa opzione è scorretta perché, sebbene Amazon EKS fornisca funzionalità native di Kubernetes, non riguarda solo la semplicità o la convenienza. ECS è più semplice e potrebbe essere più conveniente per esigenze di orchestrazione dei container dirette, ma manca delle funzionalità avanzate che fornisce EKS.",
            "Questa opzione è fuorviante perché, sebbene Amazon EKS offra un servizio gestito, non gestisce automaticamente scaling e bilanciamento del carico per tutti i carichi di lavoro nello stesso modo in cui lo fa ECS. EKS richiede più configurazione e comprensione di Kubernetes per ottenere risultati simili.",
            "Questa opzione è scorretta perché Amazon EKS supporta carichi di lavoro serverless attraverso AWS Fargate, proprio come Amazon ECS. Pertanto, l'affermazione che EKS non supporta carichi di lavoro serverless è falsa."
        ]
    },
    {
        "Question Number": "65",
        "Situation": "Un'azienda sta progettando un'architettura di Virtual Private Cloud (VPC) in AWS per supportare un'applicazione multi-tier. L'architettura necessita di tre zone di disponibilità (AZ) con una zona di riserva aggiuntiva per la crescita futura. Ogni zona di disponibilità avrà subnet separate per i livelli web, applicazione e database, più una subnet extra riservata per l'espansione futura. L'azienda vuole garantire che ci siano abbastanza indirizzi IP per scalare l'applicazione in ogni livello.",
        "Question": "Quale delle seguenti configurazioni VPC soddisferà meglio questi requisiti consentendo al contempo una crescita futura?",
        "Options": {
            "1": "Utilizzare un blocco CIDR /28 per la VPC e dividere ogni zona di disponibilità in subnet /30 per massimizzare l'uso degli indirizzi IP all'interno di ogni subnet.",
            "2": "Impostare un blocco CIDR /16 per la VPC, fornendo un totale di 65.536 indirizzi IP, e assegnare subnet /20 per ogni livello in ogni zona di disponibilità per garantire indirizzi IP sufficienti per livello.",
            "3": "Scegliere un blocco CIDR /24 per la VPC, fornendo un totale di 256 indirizzi IP, e utilizzare subnet /26 per ogni livello in ogni zona di disponibilità per ottimizzare lo spazio degli indirizzi.",
            "4": "Configurare un blocco CIDR /22 per la VPC per supportare 1.024 indirizzi IP, dividendo ogni zona di disponibilità in subnet /25 per ogni livello per bilanciare spazio degli indirizzi e scalabilità."
        },
        "Correct Answer": "Impostare un blocco CIDR /16 per la VPC, fornendo un totale di 65.536 indirizzi IP, e assegnare subnet /20 per ogni livello in ogni zona di disponibilità per garantire indirizzi IP sufficienti per livello.",
        "Explanation": "Scegliere un blocco CIDR /16 per la VPC consente di avere un ampio spazio di indirizzi di 65.536 indirizzi IP, che è più che sufficiente per l'applicazione multi-tier che richiede subnet separate per i livelli web, applicazione e database attraverso tre zone di disponibilità, più una subnet aggiuntiva per la crescita futura. Assegnando subnet /20, ogni subnet avrà 4.096 indirizzi IP (2^(32-20)), fornendo ampio spazio per la scalabilità all'interno di ogni livello, consentendo comunque l'espansione futura.",
        "Other Options": [
            "Utilizzare un blocco CIDR /28 per la VPC fornisce solo 16 indirizzi IP, che è troppo limitato per un'applicazione multi-tier che richiede più subnet in tre zone di disponibilità. Dividere ogni AZ in subnet /30 ridurrebbe ulteriormente il numero di indirizzi IP utilizzabili, rendendo questa opzione impraticabile.",
            "Un blocco CIDR /24 fornisce solo 256 indirizzi IP, che non è sufficiente per i requisiti dell'applicazione. Utilizzare subnet /26 consentirebbe solo 64 indirizzi IP per subnet, che non è abbastanza per i livelli web, applicazione e database, specialmente considerando la necessità di crescita futura.",
            "Configurare un blocco CIDR /22 consente di avere 1.024 indirizzi IP, che è meglio delle opzioni precedenti ma potrebbe comunque non fornire spazio sufficiente per la scalabilità. Dividere ogni zona di disponibilità in subnet /25 darebbe 128 indirizzi IP per subnet, che potrebbe essere limitante per i livelli dell'applicazione, specialmente poiché l'azienda pianifica l'espansione futura."
        ]
    }
]