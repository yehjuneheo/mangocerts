[
    {
        "Question Number": "1",
        "Situation": "한 머신러닝 엔지니어가 프로덕션 환경에서 이미지 분류를 위한 대규모 신경망 모델을 배포하는 임무를 맡았습니다. 이 모델은 지연 시간과 비용에 영향을 미치는 상당한 크기를 가지고 있습니다. 이러한 문제를 해결하기 위해 엔지니어는 성능을 유지하면서 모델 크기를 줄이기를 원합니다.",
        "Question": "정확성에 큰 영향을 미치지 않으면서 모델 크기를 효과적으로 줄이기 위해 엔지니어가 구현해야 할 기술은 무엇입니까?",
        "Options": {
            "1": "모델의 학습 능력을 향상시키기 위해 입력 데이터셋에 더 많은 기능을 추가합니다.",
            "2": "모델 가중치를 int8 또는 float16과 같은 낮은 정밀도 형식으로 양자화합니다.",
            "3": "데이터의 복잡한 패턴을 포착하기 위해 더 복잡한 모델 아키텍처를 사용합니다.",
            "4": "모델의 성능을 향상시키기 위해 레이어 수를 증가시킵니다."
        },
        "Correct Answer": "모델 가중치를 int8 또는 float16과 같은 낮은 정밀도 형식으로 양자화합니다.",
        "Explanation": "양자화는 가중치를 고정밀 형식에서 저정밀 형식으로 변환하여 모델 크기를 줄이고 메모리 사용량을 감소시키며 추론 속도를 증가시키면서 모델의 정확성을 대부분 유지하는 데 도움을 줍니다.",
        "Other Options": [
            "레이어 수를 증가시키면 일반적으로 모델 크기가 커지고 과적합이 발생할 수 있으므로 모델 크기를 줄이는 목표와는 반대입니다.",
            "더 많은 기능을 추가하면 모델이 복잡해지고 크기가 증가할 수 있어 모델 크기를 줄이는 목표와 모순됩니다.",
            "더 복잡한 모델 아키텍처를 사용하면 일반적으로 모델이 더 커지므로 크기를 최소화하는 목표에 역효과를 줍니다."
        ]
    },
    {
        "Question Number": "2",
        "Situation": "한 소매 회사가 고객 이탈을 예측하기 위해 머신러닝 모델을 개발했습니다. 그들은 모델의 정확성을 유지하기 위해 주기적으로 새로운 데이터로 모델을 업데이트하고 싶어합니다.",
        "Question": "새로운 데이터로 모델을 재훈련하는 메커니즘을 통합하기 위한 가장 효과적인 전략은 무엇입니까?",
        "Options": {
            "1": "성능을 모니터링하지 않고 모든 사용 가능한 데이터로 모델을 재훈련하는 월간 배치 작업을 예약합니다.",
            "2": "데이터의 관련성이나 모델의 성능에 관계없이 새로운 데이터가 있을 때마다 모델을 재훈련합니다.",
            "3": "성능 메트릭에 따라 모델을 재훈련하는 자동화된 파이프라인을 사용하여 모델의 정확도가 임계값 이하로 떨어질 때만 업데이트되도록 합니다.",
            "4": "새로운 데이터가 수집될 때마다 재훈련을 시작하는 트리거를 구현하되, 모델의 현재 성능을 평가하지 않습니다."
        },
        "Correct Answer": "성능 메트릭에 따라 모델을 재훈련하는 자동화된 파이프라인을 사용하여 모델의 정확도가 임계값 이하로 떨어질 때만 업데이트되도록 합니다.",
        "Explanation": "이 접근 방식은 모델이 필요할 때만 재훈련되도록 하여 최적의 성능을 유지하고 불필요한 계산 자원을 줄이는 데 도움을 줍니다. 이는 효과적인 머신러닝 워크플로우에 중요한 성능 모니터링을 강조합니다.",
        "Other Options": [
            "성능을 모니터링하지 않고 월간 배치 작업을 예약하면 모델이 여전히 잘 작동하고 있을 때도 재훈련될 수 있어 자원이 낭비되고 성능이 저하될 수 있습니다.",
            "모델의 성능을 평가하지 않고 새로운 데이터가 수집될 때마다 재훈련하는 트리거를 구현하면 모델이 즉각적인 업데이트가 필요하지 않을 수 있어 과적합이나 불안정성을 초래할 수 있습니다.",
            "새로운 데이터가 있을 때마다 모델을 재훈련하는 것은 모델 성능의 중요성을 무시하며 자원의 비효율적인 사용과 모델 정확성 유지에 대한 집중 부족을 초래할 수 있습니다."
        ]
    },
    {
        "Question Number": "3",
        "Situation": "한 머신러닝 엔지니어가 AWS에 배포된 ML 모델의 성능 모니터링을 생성하고 유지하는 임무를 맡았습니다. 엔지니어는 모델이 효과적으로 작동하고 있는지 확인하고 이상을 식별하기 위해 주요 성능 메트릭을 시각화해야 합니다.",
        "Question": "성능 메트릭 모니터링을 위한 대시보드를 설정하기 위해 머신러닝 엔지니어가 사용해야 할 AWS 서비스 조합은 무엇입니까? (두 개 선택)",
        "Options": {
            "1": "Amazon CloudWatch",
            "2": "Amazon SageMaker Studio",
            "3": "Amazon QuickSight",
            "4": "AWS Config",
            "5": "AWS CloudTrail"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon QuickSight",
            "Amazon CloudWatch"
        ],
        "Explanation": "Amazon QuickSight는 시각화 및 대시보드를 생성할 수 있는 비즈니스 분석 서비스로, 성능 메트릭 모니터링에 적합합니다. Amazon CloudWatch는 메트릭과 로그를 제공하는 모니터링 및 관찰 가능성 서비스로, ML 모델을 포함한 AWS 리소스와 애플리케이션의 성능을 추적하는 데 필수적입니다.",
        "Other Options": [
            "AWS CloudTrail은 주로 AWS 계정 내 API 호출을 기록하고 모니터링하는 데 사용되지만, ML 모델에 대한 실시간 성능 메트릭이나 시각화를 제공하지 않습니다.",
            "AWS Config는 AWS 리소스의 구성을 평가, 감사 및 평가할 수 있는 서비스입니다. 준수 및 거버넌스에 중요하지만 성능 메트릭을 직접 모니터링하는 목적에는 부합하지 않습니다.",
            "Amazon SageMaker Studio는 머신러닝을 위한 통합 개발 환경이지만, 다양한 서비스의 성능 메트릭을 모니터링하기 위한 대시보드 기능을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "4",
        "Situation": "기계 학습 엔지니어가 고객 이탈을 예측하는 모델을 훈련하기 위한 데이터셋을 준비하고 있습니다. 데이터셋에는 결측값과 범주형 변수가 포함된 여러 특성이 있습니다. 엔지니어는 Amazon SageMaker에 모델 훈련을 위해 데이터를 공급하기 전에 AWS 서비스를 활용하여 데이터를 효율적으로 정리하고 전처리하고자 합니다.",
        "Question": "엔지니어가 데이터 정리 및 변환 프로세스를 자동화하면서 변경 사항을 쉽게 시각화할 수 있도록 하려면 어떤 AWS 서비스를 사용해야 합니까?",
        "Options": {
            "1": "Amazon EMR에서 Apache Spark를 사용하여 데이터 변환을 위한 사용자 정의 스크립트를 실행합니다.",
            "2": "Amazon SageMaker 환경 내에서 데이터를 직접 전처리하기 위해 Amazon SageMaker Data Wrangler를 사용합니다.",
            "3": "코드를 작성하지 않고 데이터셋을 시각적으로 정리하고 변환하기 위해 AWS Glue DataBrew를 사용합니다.",
            "4": "ETL 작업을 수행하고 데이터 준비를 자동화하기 위해 AWS Glue를 사용합니다."
        },
        "Correct Answer": "코드를 작성하지 않고 데이터셋을 시각적으로 정리하고 변환하기 위해 AWS Glue DataBrew를 사용합니다.",
        "Explanation": "AWS Glue DataBrew는 데이터를 정리하고 변환하는 데 필요한 시각적 도구를 제공하는 데이터 준비 작업에 특별히 설계되었습니다. 사용자는 코딩 없이 데이터 품질 문제를 쉽게 식별하고 수정할 수 있어, 설명된 시나리오에 이상적인 선택입니다.",
        "Other Options": [
            "AWS Glue는 ETL 작업에 적합하지만 DataBrew에 비해 데이터 변환을 설정하고 시각화하는 데 더 많은 기술 전문 지식이 필요할 수 있습니다.",
            "Amazon EMR에서 Apache Spark는 데이터 처리에 강력하지만 사용자 정의 스크립트를 작성해야 하므로 코드 없는 솔루션을 찾는 사용자에게는 비효율적일 수 있습니다.",
            "Amazon SageMaker Data Wrangler는 전처리에 효과적이지만 주로 SageMaker 워크플로우 내에서 통합되어 있으며 DataBrew와 같은 수준의 시각화 및 데이터 탐색을 제공하지 않을 수 있습니다."
        ]
    },
    {
        "Question Number": "5",
        "Situation": "조직이 고객 이탈을 예측하기 위해 기계 학습 모델을 배포했습니다. ML 엔지니어는 모델 드리프트와 예측에 영향을 미치는 수신 데이터의 품질에 대해 우려하고 있습니다. 엔지니어는 데이터 품질과 모델 성능을 지속적으로 모니터링하는 솔루션을 구현하고자 합니다.",
        "Question": "ML 엔지니어가 데이터 품질과 모델 성능을 효과적으로 모니터링하기 위해 어떤 접근 방식을 취해야 합니까?",
        "Options": {
            "1": "Amazon CloudWatch를 사용하여 모델 성능 및 데이터 품질에 대한 사용자 정의 메트릭을 생성합니다.",
            "2": "Amazon S3를 활용하여 수신 데이터를 저장하고 수동 검사를 통해 품질을 평가합니다.",
            "3": "Amazon SageMaker Model Monitor를 활용하여 데이터 품질과 모델 성능을 자동으로 모니터링합니다.",
            "4": "AWS Lambda 함수를 구현하여 새로운 데이터에 대해 모델을 자동으로 재훈련합니다."
        },
        "Correct Answer": "Amazon SageMaker Model Monitor를 활용하여 데이터 품질과 모델 성능을 자동으로 모니터링합니다.",
        "Explanation": "Amazon SageMaker Model Monitor는 데이터 품질과 모델 성능을 자동으로 모니터링하는 내장 솔루션을 제공하여 모델 드리프트나 데이터 분포의 변화와 같은 문제를 사전 탐지할 수 있게 합니다. 이는 프로덕션 환경에서 기계 학습 예측의 신뢰성을 유지하는 데 필수적입니다.",
        "Other Options": [
            "Amazon CloudWatch를 사용하여 사용자 정의 메트릭을 생성하는 것은 가능하지만 각 메트릭에 대한 수동 설정이 필요하며 SageMaker Model Monitor가 제공하는 ML 모델에 특화된 자동 모니터링 기능을 제공하지 않습니다.",
            "자동 재훈련을 위한 AWS Lambda 함수를 구현하는 것은 데이터 품질이나 모델 성능의 지속적인 모니터링을 해결하지 않으며, 필요성을 평가하지 않고 빈번한 재훈련으로 이어질 수 있습니다.",
            "Amazon S3를 데이터 저장소로 활용하고 수동 검사를 수행하는 것은 비효율적이며 실시간 모니터링에는 비현실적입니다. 이 접근 방식은 프로덕션 수준의 ML 솔루션에 필수적인 자동화 및 지속적인 모니터링 이점을 제공하지 못합니다."
        ]
    },
    {
        "Question Number": "6",
        "Situation": "ML 엔지니어가 기계 학습 작업을 지원하는 인프라에 대한 비용 모니터링 전략을 구현할 준비를 하고 있습니다. 그들은 비용을 쉽게 추적하고 보고할 수 있도록 하기를 원합니다.",
        "Question": "엔지니어가 어떤 태깅 전략을 구현해야 합니까? (두 개 선택)",
        "Options": {
            "1": "Environment: Production",
            "2": "Cost-Center: Marketing",
            "3": "Department: Research",
            "4": "Project: ML-Model-Training",
            "5": "Owner: Team-Alpha"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Project: ML-Model-Training",
            "Cost-Center: Marketing"
        ],
        "Explanation": "‘Project: ML-Model-Training’과 같은 태그를 구현하면 엔지니어가 기계 학습 프로젝트와 관련된 비용을 구체적으로 추적할 수 있습니다. 또한 ‘Cost-Center: Marketing’으로 태그를 지정하면 특정 비즈니스 유닛에 비용을 귀속시키는 데 도움이 되어 재무 책임을 강화할 수 있습니다.",
        "Other Options": [
            "‘Environment: Production’ 태그는 환경을 구분하는 데 유용하지만 기계 학습 프로젝트에 대한 비용 할당에 대한 구체적인 정보를 제공하지 않습니다.",
            "‘Owner: Team-Alpha’ 태그는 자원의 책임자를 식별하지만 프로젝트 간의 비용 분포를 이해하는 데 기여하지 않습니다.",
            "‘Department: Research’ 태그는 자원을 사용하는 부서를 나타내지만 기계 학습 이니셔티브와 관련된 비용을 효과적으로 모니터링하기에는 너무 광범위합니다."
        ]
    },
    {
        "Question Number": "7",
        "Situation": "ML 엔지니어가 예측 분석 프로젝트를 위한 데이터셋을 준비하고 있으며, 대량의 구조화된 데이터와 반구조화된 데이터를 효율적으로 처리할 수 있는 AWS 저장 옵션을 선택해야 합니다. 엔지니어는 또한 높은 비용을 들이지 않고 데이터에 대해 복잡한 쿼리를 수행할 수 있는 옵션이 필요합니다.",
        "Question": "기계 학습에서 데이터 준비를 위한 이러한 요구 사항을 가장 잘 충족하는 AWS 저장 서비스는 무엇입니까?",
        "Options": {
            "1": "Amazon DynamoDB",
            "2": "Amazon S3 with Athena",
            "3": "Amazon Elastic File System (EFS)",
            "4": "Amazon RDS for PostgreSQL"
        },
        "Correct Answer": "Amazon S3 with Athena",
        "Explanation": "Amazon S3와 AWS Athena를 결합하면 엔지니어가 S3에 대량의 데이터를 저장하고 해당 데이터에 대해 SQL 유사 쿼리를 직접 수행할 수 있습니다. 이 설정은 구조화된 데이터와 반구조화된 데이터를 모두 지원하며, 전체 데이터베이스 관리 시스템을 설정할 필요 없이 대규모 데이터셋을 쿼리하는 데 비용 효율적입니다.",
        "Other Options": [
            "Amazon RDS for PostgreSQL은 구조화된 데이터에 적합한 관계형 데이터베이스 서비스이지만, 반구조화된 데이터의 대량 처리를 효율적으로 수행하지 못할 수 있으며, 더 높은 비용과 복잡성을 초래할 수 있습니다.",
            "Amazon DynamoDB는 구조화된 데이터에 대한 고가용성 및 저지연 액세스에 적합한 NoSQL 데이터베이스 서비스이지만, S3 with Athena와 같은 대규모 데이터셋에 대한 복잡한 쿼리에 최적화되어 있지 않습니다.",
            "Amazon Elastic File System (EFS)은 EC2 인스턴스를 위한 파일 저장 서비스로, 확장 가능한 저장소를 제공합니다. 그러나 Amazon S3 with Athena와 같은 수준의 쿼리 기능을 제공하지 않으며, 대규모 데이터셋에 대해 가장 비용 효율적인 옵션이 아닐 수 있습니다."
        ]
    },
    {
        "Question Number": "8",
        "Situation": "데이터 엔지니어가 기계 학습 모델을 위한 데이터셋을 준비하고 있습니다. 이 데이터셋에는 결측값이 있는 여러 특성과 모델의 성능에 영향을 줄 수 있는 몇 가지 이상치가 포함되어 있습니다. 목표는 모델에 데이터를 제공하기 전에 데이터를 효과적으로 정리하고 변환하는 것입니다.",
        "Question": "데이터 엔지니어가 데이터셋의 결측값을 처리하기 위해 우선적으로 고려해야 할 기술은 무엇입니까?",
        "Options": {
            "1": "결측값이 포함된 모든 행을 제거합니다.",
            "2": "특성의 평균을 사용하여 결측값을 대체합니다.",
            "3": "결측값을 0과 같은 상수 값으로 대체합니다.",
            "4": "결측값을 예측하기 위해 더 복잡한 모델을 사용합니다."
        },
        "Correct Answer": "특성의 평균을 사용하여 결측값을 대체합니다.",
        "Explanation": "특성의 평균을 사용하여 결측값을 대체하는 것은 결측 데이터를 처리하기 위한 일반적이고 효과적인 기술입니다. 이 방법은 대부분의 데이터를 유지하면서 결측값에 대한 합리적인 추정을 제공하여 모델 훈련을 위한 데이터셋의 전체 무결성을 유지하는 데 도움이 됩니다.",
        "Other Options": [
            "결측값이 포함된 모든 행을 제거하면 데이터의 상당한 손실이 발생할 수 있으며, 이는 모델에 편향을 초래하거나 데이터셋이 작아져 예측력을 감소시킬 수 있습니다.",
            "결측값을 0과 같은 상수 값으로 대체하면 데이터의 기본 분포를 반영하지 않기 때문에 편향을 초래할 수 있으며, 이는 모델 성능에 부정적인 영향을 미칠 수 있습니다.",
            "결측값을 예측하기 위해 더 복잡한 모델을 사용하는 것은 계산 비용이 많이 들 수 있으며, 데이터에 과적합될 수 있습니다. 복잡한 모델링에 의존하기 전에 더 간단한 대체 방법을 사용하는 것이 종종 더 좋습니다."
        ]
    },
    {
        "Question Number": "9",
        "Situation": "한 의료 기관이 환자 재입원율을 예측하기 위해 기계 학습 모델을 배포하고자 합니다. 그들은 실시간 예측을 위한 저지연 응답이 필요하며, 배포가 고가용성을 유지하고 수요에 따라 확장할 수 있도록 하기를 원합니다.",
        "Question": "이 시나리오에서 기계 학습 모델을 배포하기에 가장 적합한 AWS 서비스는 무엇입니까?",
        "Options": {
            "1": "Amazon Elastic Container Service",
            "2": "Amazon Elastic Kubernetes Service",
            "3": "Amazon SageMaker Endpoints",
            "4": "AWS Lambda"
        },
        "Correct Answer": "Amazon SageMaker Endpoints",
        "Explanation": "Amazon SageMaker Endpoints는 실시간 추론을 위한 기계 학습 모델 호스팅을 위해 특별히 설계되었습니다. 이 서비스는 확장성과 가용성을 처리하는 완전 관리형 서비스를 제공하여 저지연 응답이 필요한 애플리케이션에 이상적입니다.",
        "Other Options": [
            "Amazon Elastic Container Service는 컨테이너화된 애플리케이션에 더 적합하지만, SageMaker Endpoints와 같이 기계 학습 모델 배포를 위해 특별히 맞춤화된 통합 및 기능을 제공하지 않습니다.",
            "AWS Lambda는 서버리스 애플리케이션 실행에 적합하지만 실행 시간에 제한이 있으며, 더 많은 리소스가 필요할 수 있는 장기 실행 기계 학습 추론 작업을 제공하는 데 이상적이지 않습니다.",
            "Amazon Elastic Kubernetes Service는 Kubernetes를 위한 강력한 오케스트레이션 서비스이지만, ML 모델 배포를 위해 특별히 최적화된 Amazon SageMaker Endpoints에 비해 관리 오버헤드가 더 많이 필요합니다."
        ]
    },
    {
        "Question Number": "10",
        "Situation": "한 팀이 고객 이탈을 예측하기 위해 역사적 데이터를 기반으로 기계 학습 모델을 개발하려고 합니다. 고객 인구 통계, 거래 이력 및 고객 서비스 상호작용을 포함한 다양한 데이터 소스가 있지만, 문제의 복잡성과 데이터 품질이 실행 가능한 ML 솔루션을 허용할지 확신이 서지 않습니다.",
        "Question": "고객 이탈 예측을 위한 기계 학습 모델 개발의 실행 가능성을 판단하기 위해 팀이 가장 먼저 평가해야 할 것은 무엇인가요?",
        "Options": {
            "1": "예측에 사용할 모델 아키텍처의 복잡성, 더 복잡한 모델이 더 나은 정확도를 제공하기 때문입니다.",
            "2": "훈련에 충분한지 확인하기 위해 다양한 소스에서 제공되는 데이터의 양과 다양성.",
            "3": "모델 구현으로 인한 잠재적 투자 수익률(ROI)과 개발에 관련된 비용을 비교합니다.",
            "4": "운영 부하를 처리할 수 있도록 기계 학습 모델을 배포하기 위한 기존 인프라."
        },
        "Correct Answer": "훈련에 충분한지 확인하기 위해 다양한 소스에서 제공되는 데이터의 양과 다양성.",
        "Explanation": "기계 학습 모델을 개발하기 전에 데이터의 품질, 양 및 다양성을 평가하는 것이 중요합니다. 이 평가를 통해 데이터가 고객 이탈을 정확하게 예측하기 위한 모델 훈련에 충분하고 적합한지 판단할 수 있습니다. 적절한 데이터가 없으면 가장 복잡한 모델도 성능이 저하됩니다.",
        "Other Options": [
            "모델 아키텍처의 복잡성이 성능에 영향을 미칠 수 있지만, 데이터의 품질과 가용성보다 중요하지 않습니다. 데이터가 적합하지 않으면 어떤 모델 아키텍처도 효과적이지 않습니다.",
            "잠재적 ROI를 평가하는 것은 중요하지만 데이터와 모델의 실행 가능성을 평가한 후에 이루어져야 합니다. 데이터 문제로 인해 모델을 구축할 수 없다면 고려할 ROI가 없습니다.",
            "배포를 위한 기존 인프라는 관련이 있지만, 사용 가능한 데이터로 실행 가능한 모델을 만들 수 있다는 것을 확인한 후에 고려해야 합니다."
        ]
    },
    {
        "Question Number": "11",
        "Situation": "한 ML 엔지니어가 기계 학습 모델 훈련을 위한 대규모 데이터 세트를 준비하는 임무를 맡았습니다. 데이터는 Amazon S3의 CSV 파일과 Amazon RDS의 구조화된 데이터를 포함하여 여러 AWS 서비스에 다양한 형식으로 저장되어 있습니다. 엔지니어는 준비 단계에서 데이터에 효율적으로 접근하고 처리하며 확장할 수 있도록 하면서 비용을 최소화해야 합니다.",
        "Question": "ML 엔지니어가 최적의 데이터 준비를 위해 어떤 AWS 서비스 조합을 활용해야 하나요?",
        "Options": {
            "1": "데이터 관리를 위해 Amazon FSx for NetApp ONTAP를 사용하고, 실시간 데이터 처리를 위해 Amazon Kinesis를 활용합니다.",
            "2": "모든 데이터를 Amazon Elastic File System (EFS)에 저장하여 쉽게 접근하고 AWS Batch를 사용하여 처리합니다.",
            "3": "AWS Glue를 사용하여 Amazon S3와 Amazon RDS의 데이터를 카탈로그한 다음, Amazon EMR로 처리합니다.",
            "4": "Amazon S3에 저장된 데이터를 정리하고 변환하기 위해 Amazon SageMaker Data Wrangler를 활용합니다."
        },
        "Correct Answer": "AWS Glue를 사용하여 Amazon S3와 Amazon RDS의 데이터를 카탈로그한 다음, Amazon EMR로 처리합니다.",
        "Explanation": "AWS Glue를 사용하면 효율적인 데이터 카탈로깅이 가능하여 다양한 소스에서 데이터 세트를 발견하고 접근하는 과정을 단순화합니다. 이를 Amazon EMR과 결합하여 처리하면 대규모 데이터 준비 작업을 위한 확장 가능하고 비용 효율적인 솔루션을 제공합니다.",
        "Other Options": [
            "모든 데이터를 Amazon Elastic File System (EFS)에 저장하는 것은 대규모 데이터 세트에 대해 비용 효율적이지 않을 수 있으며, AWS Batch는 Glue와 EMR을 사용하는 것에 비해 데이터 준비에 최적화되어 있지 않습니다.",
            "Amazon FSx for NetApp ONTAP는 기계 학습 워크플로우에서 데이터 준비에 일반적으로 사용되지 않으며, Amazon Kinesis는 실시간 데이터 스트리밍에 뛰어나지만 배치 데이터 준비 요구에 효과적이지 않을 수 있습니다.",
            "Amazon SageMaker Data Wrangler는 데이터 전처리에 강력한 도구이지만, 작은 데이터 세트에 가장 적합하며 대규모 데이터 준비 작업에 필요한 규모를 Glue와 EMR 조합만큼 효과적으로 처리하지 못할 수 있습니다."
        ]
    },
    {
        "Question Number": "12",
        "Situation": "한 ML 엔지니어가 프로덕션에 배포된 ML 모델의 신뢰성과 성능을 보장하는 임무를 맡았습니다. 엔지니어는 인프라를 최적화하고 시간이 지남에 따라 모델의 효율성을 유지하기 위해 주요 성능 지표를 모니터링해야 합니다.",
        "Question": "ML 인프라가 서비스 저하 없이 다양한 작업 부하를 처리할 수 있도록 보장하는 데 가장 중요한 주요 성능 지표는 무엇인가요?",
        "Options": {
            "1": "확장성",
            "2": "활용도",
            "3": "장애 내성",
            "4": "처리량"
        },
        "Correct Answer": "확장성",
        "Explanation": "확장성은 ML 인프라에 필수적이며, 시스템이 자원을 조정하여 증가된 부하를 효율적으로 처리할 수 있도록 보장합니다. 이 기능은 서비스 품질을 저하시키지 않으면서 피크 사용 시간 동안 성능을 유지하는 데 중요합니다.",
        "Other Options": [
            "처리량은 주어진 시간 내에 처리된 작업 수를 나타내며 중요하지만, 필요할 때 시스템이 자원을 확장할 수 있는 능력과는 직접적인 관련이 없습니다.",
            "활용도는 현재 자원이 얼마나 효과적으로 사용되고 있는지를 측정하지만, 인프라가 미래의 수요를 충족하기 위해 확장할 수 있다는 보장은 없습니다.",
            "장애 내성은 시스템이 실패에도 불구하고 계속 작동할 수 있는 능력을 나타내며, 신뢰성에 중요하지만 작업 부하 변동 관리를 직접적으로 다루지는 않습니다."
        ]
    },
    {
        "Question Number": "13",
        "Situation": "한 회사가 민감한 고객 데이터를 처리하는 머신 러닝 모델을 배포하고 있습니다. 그들은 ML 리소스가 안전하게 보호되고 오직 권한이 있는 인원만이 접근할 수 있도록 해야 합니다. 팀은 이러한 리소스에 대한 네트워크 접근을 관리하기 위한 다양한 통제를 평가하고 있습니다.",
        "Question": "머신 러닝 리소스에 대한 네트워크 접근을 안전하게 하기 위한 권장 관행은 무엇입니까?",
        "Options": {
            "1": "가상 사설 클라우드(VPC) 피어링 구현",
            "2": "내부 IP 주소에서 모든 트래픽 허용",
            "3": "IAM 역할을 사용하여 접근 제어",
            "4": "네트워크 트래픽에 대한 암호화 비활성화"
        },
        "Correct Answer": "IAM 역할을 사용하여 접근 제어",
        "Explanation": "IAM 역할을 사용하여 접근을 제어하는 것은 오직 권한이 있는 사용자와 서비스만이 머신 러닝 리소스와 상호작용할 수 있도록 보장하는 데 필수적입니다. 이는 세밀한 접근 제어를 가능하게 하고 최소 권한 원칙을 준수하게 합니다.",
        "Other Options": [
            "VPC 피어링을 구현하는 것은 ML 리소스에 대한 접근을 직접적으로 안전하게 하지 않으며, 인증 및 권한 부여 문제를 해결하지 않고 VPC 간의 네트워크 통신만 용이하게 합니다.",
            "내부 IP 주소에서 모든 트래픽을 허용하면 ML 리소스가 무단 접근에 노출될 수 있으며, 이는 엄격한 접근 제어 또는 인증 조치를 시행하지 않기 때문입니다.",
            "네트워크 트래픽에 대한 암호화를 비활성화하면 데이터 가로채기 및 무단 접근의 위험이 크게 증가하며, 이는 민감한 데이터를 안전하게 보호하기 위한 모범 사례에 반합니다."
        ]
    },
    {
        "Question Number": "14",
        "Situation": "한 머신 러닝 엔지니어가 Amazon SageMaker를 사용하여 예측 모델을 위한 데이터셋을 준비하는 임무를 맡고 있습니다. 데이터셋에는 여러 개의 특성이 포함되어 있으며, 그 중 일부는 중복되거나 분산이 낮습니다. 모델의 성능을 향상시키고 훈련 시간을 줄이기 위해 엔지니어는 특성을 효과적으로 생성하고 관리해야 합니다.",
        "Question": "머신 러닝 엔지니어가 예측 모델을 위한 특성 집합을 최적화하기 위해 어떤 접근 방식을 취해야 합니까?",
        "Options": {
            "1": "Amazon SageMaker Data Wrangler를 사용하여 상관관계를 기반으로 관련 특성을 시각화하고 선택합니다.",
            "2": "모델에 미치는 영향을 평가하지 않고 데이터셋에서 특성을 수동으로 제거합니다.",
            "3": "AWS Glue를 활용하여 ETL 작업을 수행하고 관련성을 분석하지 않고 새로운 특성을 생성합니다.",
            "4": "SageMaker Feature Store를 구현하여 모델 훈련을 위해 특성을 효율적으로 저장, 관리 및 검색합니다."
        },
        "Correct Answer": "SageMaker Feature Store를 구현하여 모델 훈련을 위해 특성을 효율적으로 저장, 관리 및 검색합니다.",
        "Explanation": "가장 좋은 접근 방식은 SageMaker Feature Store를 사용하는 것입니다. 이를 통해 엔지니어는 특성을 효과적으로 생성, 관리 및 검색할 수 있습니다. 버전 관리를 지원하며, 다양한 모델에서 재사용할 수 있는 조직적인 특성 관리 프로세스를 유지하는 데 도움이 됩니다.",
        "Other Options": [
            "Amazon SageMaker Data Wrangler를 사용하여 특성을 시각화하고 선택하는 것은 유익하지만, 향후 모델 훈련을 위해 특성을 효율적으로 관리하고 검색하는 솔루션을 제공하지 않습니다.",
            "영향을 평가하지 않고 특성을 수동으로 제거하면 잠재적으로 유용한 정보가 손실되어 모델 성능에 부정적인 영향을 미칠 수 있습니다.",
            "AWS Glue를 활용하여 ETL 작업을 수행하면 새로운 특성을 생성할 수 있지만, 특성을 관리하고 검색하는 데 중점을 두지 않으므로 모델 훈련 최적화에 필수적입니다."
        ]
    },
    {
        "Question Number": "15",
        "Situation": "한 금융 기관이 대출 채무 불이행을 예측하는 머신 러닝 모델을 위한 데이터셋을 준비하고 있습니다. 데이터셋에는 소득, 대출 금액, 신용 점수 등 다양한 수치적 특성이 포함되어 있습니다. 모델 성능을 향상시키기 위해 데이터 과학 팀은 다양한 특성 엔지니어링 기법을 고려하고 있습니다.",
        "Question": "수치적 특성이 모델 성능에 동등하게 기여하도록 보장하기 위해 가장 효과적인 특성 엔지니어링 기법은 무엇입니까?",
        "Options": {
            "1": "특성 분할을 구현하여 새로운 범주형 변수를 생성합니다.",
            "2": "최소-최대 정규화를 사용하여 특성을 0과 1 사이로 스케일링합니다.",
            "3": "왜곡된 수치적 특성에 로그 변환을 적용합니다.",
            "4": "바이닝을 수행하여 수치적 특성을 이산 범위로 그룹화합니다."
        },
        "Correct Answer": "최소-최대 정규화를 사용하여 특성을 0과 1 사이로 스케일링합니다.",
        "Explanation": "최소-최대 정규화는 특성을 일반적인 범위, 보통 0과 1 사이로 재조정하여 모든 수치적 특성이 모델 훈련 과정에 동등하게 기여하도록 보장합니다. 이는 KNN이나 신경망과 같은 거리 기반 알고리즘에 특히 중요합니다.",
        "Other Options": [
            "로그 변환은 매우 왜곡된 데이터의 왜곡을 줄이는 데 유용하지만, 스케일 측면에서 특성 간의 동등한 기여를 보장하지는 않습니다.",
            "특성 분할은 새로운 변수를 생성하지만, 수치적 특성의 스케일링 문제를 해결하지 않으며, 이는 많은 머신 러닝 알고리즘에 필수적입니다.",
            "바이닝은 연속 변수를 범주형 변수로 변환하지만, 이는 귀중한 정보를 잃게 할 수 있으며 특성 스케일을 표준화하지 않습니다."
        ]
    },
    {
        "Question Number": "16",
        "Situation": "ML 엔지니어는 Amazon SageMaker에 배포된 머신러닝 모델의 신뢰성을 보장하는 책임이 있습니다. 모델은 입력 데이터 분포의 변화에 민감하여 시간이 지남에 따라 성능이 저하될 수 있습니다. 엔지니어는 모델의 정확성과 신뢰성에 영향을 미칠 수 있는 데이터 변화를 효과적으로 모니터링하고 감지할 수 있는 솔루션이 필요합니다.",
        "Question": "Amazon SageMaker에서 머신러닝 모델의 성능에 영향을 미칠 수 있는 입력 데이터 분포의 변화를 감지하기 위해 어떤 도구를 사용할 수 있습니까?",
        "Options": {
            "1": "Amazon SageMaker Clarify",
            "2": "Amazon SageMaker Model Monitor",
            "3": "AWS Lambda",
            "4": "Amazon CloudWatch"
        },
        "Correct Answer": "Amazon SageMaker Model Monitor",
        "Explanation": "Amazon SageMaker Model Monitor는 입력 데이터를 모니터링하고 그 분포의 변화를 감지하여 머신러닝 모델의 성능을 추적하도록 특별히 설계되었습니다. 이는 모델의 성능에 대한 통찰력을 제공하고 정확성에 영향을 미칠 수 있는 변화를 식별하는 데 도움을 줍니다.",
        "Other Options": [
            "Amazon SageMaker Clarify는 머신러닝 모델의 편향 및 투명성을 감지하는 데 주로 초점을 맞추고 있으며, 입력 데이터 분포의 변화를 모니터링하는 데는 적합하지 않습니다.",
            "AWS Lambda는 이벤트에 응답하여 코드를 실행하는 서버리스 컴퓨팅 서비스입니다. 머신러닝 워크플로우에서 사용할 수 있지만, 데이터 분포 변화 모니터링을 위한 특정 기능을 제공하지 않습니다.",
            "Amazon CloudWatch는 AWS 리소스 및 애플리케이션을 위한 모니터링 서비스이지만, 모델 성능에 영향을 미치는 데이터 분포의 변화를 감지하는 데 필요한 전문 기능을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "17",
        "Situation": "데이터 과학 팀은 고객 세분화 작업을 위한 머신러닝 모델을 개발하고 있습니다. 그들은 모델이 훈련 데이터에서는 잘 작동하지만 검증 세트에서는 성능이 저조하다는 것을 발견했습니다. 팀은 모델이 새로운 데이터로 업데이트될 때 잘 일반화되도록 보장하고, 동시에 재앙적 망각의 위험을 해결하고자 합니다.",
        "Question": "팀이 과적합을 효과적으로 방지하고 모델이 새로운 데이터로 업데이트될 때 성능을 유지하도록 하기 위해 어떤 기술을 구현해야 합니까?",
        "Options": {
            "1": "전처리 없이 더 큰 레이블이 있는 데이터셋을 사용합니다.",
            "2": "모델 훈련 중 드롭아웃 정규화를 적용합니다.",
            "3": "모델 아키텍처의 복잡성을 증가시킵니다.",
            "4": "검증 손실을 기반으로 조기 중지를 구현합니다."
        },
        "Correct Answer": "모델 훈련 중 드롭아웃 정규화를 적용합니다.",
        "Explanation": "모델 훈련 중 드롭아웃 정규화를 적용하는 것은 훈련 중 무작위로 유닛을 드롭하여 과적합을 방지하는 효과적인 방법입니다. 이는 모델이 보지 못한 데이터에 대해 더 잘 일반화하는 데 도움을 줍니다. 이 기술은 훈련 데이터를 기억하는 경향이 있는 복잡한 모델에서 특히 유용합니다.",
        "Other Options": [
            "모델 아키텍처의 복잡성을 증가시키면 더 높은 과적합으로 이어질 수 있습니다. 복잡한 모델은 훈련 데이터의 노이즈를 포착할 수 있기 때문입니다.",
            "전처리 없이 더 큰 레이블이 있는 데이터셋을 사용하는 것은 과적합이나 재앙적 망각을 직접적으로 해결하지 않습니다. 적절한 특성 선택이나 정리가 없으면 추가 데이터가 일반화를 개선하지 않을 수 있습니다.",
            "검증 손실을 기반으로 조기 중지를 구현하는 것은 과적합을 방지하는 데 도움이 되지만, 모델이 새로운 데이터로 업데이트될 때 재앙적 망각을 해결하지는 않습니다. 이 기술은 성능 유지를 위한 것이라기보다는 훈련을 모니터링하고 중단하는 것에 더 가깝습니다."
        ]
    },
    {
        "Question Number": "18",
        "Situation": "한 의료 기관이 환자 재입원율을 예측하기 위해 머신러닝 모델을 배포했습니다. 몇 주간 운영한 후 모델의 성능이 저하되고 있는 것으로 보입니다. ML 엔지니어는 모델이 환자 인구 통계나 치료 프로토콜의 변화로 인해 데이터 드리프트를 경험하고 있는지 확인해야 합니다.",
        "Question": "ML 엔지니어가 배포된 모델에서 드리프트를 모니터링하기 위한 최선의 접근 방식은 무엇입니까?",
        "Options": {
            "1": "Amazon SageMaker Model Monitor를 사용하여 데이터 품질을 추적하고 드리프트를 감지합니다.",
            "2": "AWS CloudTrail을 구현하여 API 호출을 기록하고 사용 패턴을 모니터링합니다.",
            "3": "분석 없이 최신 환자 데이터로 모델을 정기적으로 재훈련합니다.",
            "4": "드리프트를 피하기 위해 각 환자 인구 통계에 대해 별도의 모델을 배포합니다."
        },
        "Correct Answer": "Amazon SageMaker Model Monitor를 사용하여 데이터 품질을 추적하고 드리프트를 감지합니다.",
        "Explanation": "Amazon SageMaker Model Monitor는 입력 데이터와 모델 예측을 시간에 따라 자동으로 분석할 수 있는 기능을 제공하여 입력 데이터 분포와 성능 메트릭의 드리프트를 감지할 수 있게 합니다. 이는 데이터 패턴이 변화함에 따라 모델의 정확성을 유지하는 데 중요합니다.",
        "Other Options": [
            "AWS CloudTrail을 구현하는 것은 API 호출을 기록하는 데 초점을 맞추고 있으며, 모델 성능이나 데이터 분포 변화에 대한 통찰력을 제공하지 않으므로 드리프트 감지에 적합하지 않습니다.",
            "분석 없이 모델을 정기적으로 재훈련하는 것은 드리프트의 근본적인 문제를 해결하지 못할 수 있습니다. 재훈련된 모델이 실제로 개선되고 있는지 아니면 단순히 과거 성능을 반복하고 있는지를 평가하지 않기 때문입니다.",
            "각 환자 인구 통계에 대해 별도의 모델을 배포하는 것은 복잡성과 유지 관리 오버헤드를 증가시킬 수 있으며, 드리프트 문제를 통합된 방식으로 효과적으로 해결하지 못할 수 있습니다."
        ]
    },
    {
        "Question Number": "19",
        "Situation": "한 회사가 AWS에서 여러 머신 러닝 모델을 배포하고 있으며 비용을 효과적으로 관리하고자 합니다. 엔지니어링 팀은 지출이 예산 한도에 가까워질 때 알림을 설정하고, 시간이 지남에 따라 비용을 최적화하기 위해 지출 패턴에 대한 통찰력을 얻어야 합니다. 그들은 비용 추적 및 예산 관리 기능을 모두 제공하는 솔루션을 찾고 있습니다.",
        "Question": "어떤 AWS 서비스가 팀이 비용 할당량을 설정하고 지출이 해당 할당량에 가까워질 때 알림을 받을 수 있도록 하며, 전체 지출 패턴에 대한 통찰력을 제공합니까?",
        "Options": {
            "1": "AWS Budgets",
            "2": "AWS Cost Management Dashboard",
            "3": "AWS Trusted Advisor",
            "4": "AWS Cost Explorer"
        },
        "Correct Answer": "AWS Budgets",
        "Explanation": "AWS Budgets는 사용자가 맞춤형 비용 및 사용 예산을 설정하고 비용이 이 예산을 초과하거나 초과할 것으로 예상될 때 알림을 받을 수 있도록 합니다. 이는 팀이 할당량을 설정하고 이를 면밀히 모니터링하여 지출을 관리하는 데 특히 도움이 됩니다.",
        "Other Options": [
            "AWS Trusted Advisor는 비용 최적화를 위한 모범 사례와 권장 사항을 제공하지만 비용 할당량이나 알림을 설정하는 기능은 제공하지 않습니다.",
            "AWS Cost Explorer는 지출 패턴에 대한 상세한 보고서와 시각화를 제공하지만 예산 임계값에 대한 내장 알림은 제공하지 않습니다.",
            "AWS Cost Management Dashboard는 여러 도구를 지칭할 수 있는 일반적인 용어이지만 AWS Budgets와 같은 예산 설정 기능을 구체적으로 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "20",
        "Situation": "한 기술 회사가 여러 머신 러닝 모델을 프로덕션에 배포했습니다. 가동 시간과 성능을 보장하기 위해 모델의 건강 상태와 성능 지표를 효과적으로 모니터링하고자 합니다.",
        "Question": "Amazon CloudWatch의 어떤 기능이 회사가 머신 러닝 모델을 모니터링하고 문제를 해결하는 데 도움이 될까요? (두 가지 선택)",
        "Options": {
            "1": "CloudWatch Alarms는 메트릭 임계값에 따라 자동으로 작업을 트리거할 수 있습니다.",
            "2": "CloudWatch는 ML 모델에 대한 자동 리소스 스케일링을 제공합니다.",
            "3": "CloudWatch Logs는 실시간 로그 분석 및 시각화를 허용합니다.",
            "4": "CloudWatch Events는 리소스 상태의 변화를 추적하는 데 도움이 될 수 있습니다.",
            "5": "CloudWatch는 모든 모니터링 작업에 대해 수동 개입이 필요합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "CloudWatch Logs는 실시간 로그 분석 및 시각화를 허용합니다.",
            "CloudWatch Alarms는 메트릭 임계값에 따라 자동으로 작업을 트리거할 수 있습니다."
        ],
        "Explanation": "CloudWatch Logs는 머신 러닝 모델에서 생성된 로그를 실시간으로 분석할 수 있게 하여 문제를 신속하게 식별하는 데 도움을 줍니다. CloudWatch Alarms는 특정 메트릭을 모니터링하고 미리 정의된 임계값이 초과될 때 알림을 보내거나 리소스를 스케일링하는 등의 작업을 자동으로 트리거하도록 설정할 수 있습니다.",
        "Other Options": [
            "CloudWatch는 모니터링 작업에 대해 수동 개입이 필요하지 않으며 자동화된 모니터링 솔루션을 제공합니다.",
            "CloudWatch는 ML 모델에 대한 자동 리소스 스케일링을 제공하지 않으며, 이는 일반적으로 Auto Scaling 또는 Amazon SageMaker와 같은 서비스에서 처리됩니다.",
            "CloudWatch Events는 리소스 상태 변화를 추적할 수 있지만 모델의 건강 상태와 성능을 모니터링하거나 문제를 해결하는 데 직접적으로 도움을 주지는 않습니다."
        ]
    },
    {
        "Question Number": "21",
        "Situation": "한 ML 엔지니어가 AWS에서 코드로서의 인프라(IaC) 솔루션을 사용하여 머신 러닝 워크플로우를 배포하는 임무를 맡았습니다. 팀은 리소스 배포를 관리하면서 개발의 용이성과 다양한 AWS 서비스와의 통합 유연성을 고려해야 합니다.",
        "Question": "엔지니어가 머신 러닝 워크플로우를 배포하기 위해 고려해야 할 IaC 옵션은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "AWS OpsWorks",
            "2": "AWS Lambda",
            "3": "AWS CloudFormation",
            "4": "AWS Elastic Beanstalk",
            "5": "AWS CDK"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "AWS CloudFormation",
            "AWS CDK"
        ],
        "Explanation": "AWS CloudFormation은 AWS 리소스를 모델링하고 설정하는 방법을 제공하여 리소스 관리에 소요되는 시간을 줄이고 애플리케이션에 더 많은 시간을 집중할 수 있게 합니다. AWS CDK는 개발자가 친숙한 프로그래밍 언어를 사용하여 클라우드 인프라를 정의할 수 있게 하여 개발을 가속화할 수 있는 유연성과 사용 용이성을 제공합니다.",
        "Other Options": [
            "AWS Elastic Beanstalk는 애플리케이션 배포를 간소화하는 플랫폼 서비스(PaaS)지만 CloudFormation 및 CDK와 같은 인프라 리소스를 관리하는 IaC 도구로 직접 사용되지는 않습니다.",
            "AWS OpsWorks는 Chef 및 Puppet의 관리 인스턴스를 제공하는 구성 관리 서비스로, 인프라 코드보다는 애플리케이션 관리에 더 중점을 둡니다.",
            "AWS Lambda는 이벤트에 응답하여 코드를 실행하는 서버리스 컴퓨팅 서비스입니다. ML 워크플로우의 일부가 될 수 있지만 IaC 도구가 아니며 리소스 관리 기능을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "22",
        "Situation": "금융 서비스 회사가 대출 신청자의 신용 위험을 평가하기 위한 예측 모델을 개발하고 있습니다. 이들은 모델 개발 프로세스를 가속화하기 위해 Amazon SageMaker의 내장 알고리즘을 활용하고자 합니다.",
        "Question": "이러한 유형의 예측 모델링에 가장 적합한 Amazon SageMaker 내장 알고리즘은 무엇인가요? (두 가지 선택)",
        "Options": {
            "1": "Object Detection은 이미지 분석 작업을 위해 설계되었습니다.",
            "2": "K-Means는 레이블이 없는 데이터를 클러스터링하는 데 적용됩니다.",
            "3": "XGBoost는 표 형식 데이터 및 순위 작업에 효과적입니다.",
            "4": "BlazingText는 자연어 처리 작업에 최적화되어 있습니다.",
            "5": "Linear Learner는 이진 분류 문제에 사용할 수 있습니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "XGBoost는 표 형식 데이터 및 순위 작업에 효과적입니다.",
            "Linear Learner는 이진 분류 문제에 사용할 수 있습니다."
        ],
        "Explanation": "XGBoost는 회귀 및 분류 작업에 강력한 알고리즘으로, 신용 평가와 같은 구조화된 데이터에 특히 적합합니다. Linear Learner 또한 이진 분류 작업에 적합하여, 두 알고리즘 모두 대출 신청에서 신용 위험을 예측하는 데 적합합니다.",
        "Other Options": [
            "BlazingText는 주로 자연어 처리에 사용되며 신용 위험 평가에 관련된 표 형식 데이터에는 가장 적합하지 않습니다.",
            "Object Detection은 이미지 처리 작업을 위해 특별히 설계되었으며, 신용 위험 모델에서 일반적으로 사용되는 수치 및 범주형 데이터에는 적용되지 않습니다.",
            "K-Means는 클러스터링 알고리즘으로, 신용 위험 예측과 같은 감독 학습 작업에는 일반적으로 사용되지 않으며, 탐색적 데이터 분석에 더 적합합니다."
        ]
    },
    {
        "Question Number": "23",
        "Situation": "ML 엔지니어가 관계형 데이터베이스와 NoSQL 데이터베이스를 포함한 다양한 출처의 데이터를 병합해야 하는 머신러닝 모델을 위한 데이터셋을 준비하는 임무를 맡았습니다. 엔지니어는 복잡한 변환 및 조인을 처리할 수 있는 확장 가능하고 효율적인 솔루션이 필요합니다.",
        "Question": "이 시나리오에서 여러 출처의 데이터를 병합하고 변환하는 데 가장 적합한 AWS 서비스는 무엇인가요?",
        "Options": {
            "1": "Amazon S3",
            "2": "AWS Glue",
            "3": "Amazon RDS",
            "4": "Amazon Athena"
        },
        "Correct Answer": "AWS Glue",
        "Explanation": "AWS Glue는 분석을 위한 데이터 준비를 쉽게 해주는 완전 관리형 ETL 서비스입니다. 관계형 및 NoSQL 데이터베이스를 포함한 다양한 데이터 소스와 함께 작동하도록 특별히 설계되어, 효율적인 데이터 병합 및 변환 프로세스를 가능하게 합니다.",
        "Other Options": [
            "Amazon S3는 주로 저장 서비스이며 데이터 변환 및 병합 기능을 직접 제공하지 않습니다. 데이터를 저장할 수는 있지만 ETL 작업을 수행할 수는 없습니다.",
            "Amazon RDS는 관계형 데이터를 저장하고 관리하는 데 사용되는 관계형 데이터베이스 서비스입니다. 데이터를 보유할 수는 있지만, 다양한 출처의 데이터를 병합하고 변환하는 내장 기능을 제공하지 않습니다.",
            "Amazon Athena는 S3에 저장된 데이터를 표준 SQL을 사용하여 쿼리할 수 있는 대화형 쿼리 서비스입니다. 그러나 여러 출처에서 데이터를 병합해야 하는 복잡한 ETL 프로세스에는 적합하지 않습니다."
        ]
    },
    {
        "Question Number": "24",
        "Situation": "금융 기관이 Amazon SageMaker를 사용하여 대출 채무 불이행을 예측하는 머신러닝 모델을 개발했습니다. 팀은 다양한 트래픽 부하를 처리할 수 있고 비용 효율적인 실시간 예측을 위해 모델을 배포하고자 합니다.",
        "Question": "Amazon SageMaker에서 실시간 예측 모델의 비용 및 확장성을 최적화하기 위해 팀이 활용해야 할 배포 전략은 무엇인가요?",
        "Options": {
            "1": "유연성과 제어를 위해 SageMaker 노트북 인스턴스에서 모델을 호스팅합니다.",
            "2": "비용 관리를 위해 실시간 예측에 SageMaker 배치 변환을 사용합니다.",
            "3": "높은 가용성을 보장하기 위해 각 모델 버전마다 별도의 엔드포인트를 생성합니다.",
            "4": "동적 확장을 위해 모델을 다중 모델 엔드포인트로 배포합니다."
        },
        "Correct Answer": "모델을 다중 모델 엔드포인트로 배포합니다.",
        "Explanation": "다중 모델 엔드포인트를 사용하면 팀이 단일 엔드포인트에서 여러 모델을 호스팅할 수 있으며, 트래픽에 따라 모델을 동적으로 로드하고 언로드할 수 있습니다. 이 접근 방식은 자원 활용을 최적화하고 비용을 절감하며 다양한 트래픽 부하에 대한 확장성을 보장합니다.",
        "Other Options": [
            "각 모델 버전마다 별도의 엔드포인트를 생성하면 사용량에 관계없이 각 엔드포인트가 전용 자원을 소모하므로 비용이 증가하고 자원이 낭비될 수 있습니다.",
            "SageMaker 배치 변환을 사용하는 것은 실시간 예측에 적합하지 않으며, 이는 대량 데이터 세트를 배치 모드로 처리하기 위해 설계되었고 즉각적인 요청에 대한 추론에는 적합하지 않습니다.",
            "SageMaker 노트북 인스턴스에서 모델을 호스팅하는 것은 생산 배포에 이상적이지 않으며, 노트북 인스턴스는 일반적으로 실험 및 개발에 사용되므로 확장 가능한 실시간 추론에는 적합하지 않습니다."
        ]
    },
    {
        "Question Number": "25",
        "Situation": "한 ML 엔지니어가 Amazon SageMaker를 사용하여 머신러닝 모델을 개발하고 있으며, 훈련 데이터가 공정하고 편향되지 않도록 보장하고자 합니다. 엔지니어는 SageMaker Clarify를 활용하여 훈련 데이터와 모델 예측에 대한 통찰력을 얻기로 결정했습니다.",
        "Question": "SageMaker Clarify에서 제공하는 다음 메트릭 중 어떤 것이 엔지니어가 훈련 데이터셋의 잠재적 편향을 식별하는 데 도움이 될 수 있습니까?",
        "Options": {
            "1": "특징 중요도 점수",
            "2": "모델 예측에 대한 Shapley 값",
            "3": "공정성 메트릭",
            "4": "데이터 드리프트 분석 결과"
        },
        "Correct Answer": "공정성 메트릭",
        "Explanation": "SageMaker Clarify는 훈련 데이터셋의 잠재적 편향을 식별하는 데 도움이 되는 공정성 메트릭을 제공합니다. 이를 통해 엔지니어는 모델의 예측이 특정 특징이나 데이터 내 그룹에 의해 불공정하게 영향을 받을 수 있는지를 평가할 수 있습니다.",
        "Other Options": [
            "특징 중요도 점수는 모델의 예측에 영향을 미치는 특징에 대한 통찰력을 제공하지만, 데이터셋의 공정성이나 편향을 직접적으로 평가하지는 않습니다.",
            "데이터 드리프트 분석 결과는 입력 데이터의 분포가 시간이 지남에 따라 변경되었는지를 나타내지만, 훈련 데이터의 공정성을 구체적으로 다루지는 않습니다.",
            "모델 예측에 대한 Shapley 값은 각 특징이 모델의 예측에 기여하는 정도를 설명하지만, 훈련 데이터셋에 존재하는 전반적인 공정성이나 편향을 평가하지는 않습니다."
        ]
    },
    {
        "Question Number": "26",
        "Situation": "한 소매 회사가 고객 구매 예측을 위한 머신러닝 모델을 배포할 계획입니다. 그들은 현재 모델에서 새로운 모델로의 원활한 전환을 보장하고 다운타임의 위험을 최소화하며 문제가 발생할 경우 롤백 기능을 보장하고자 합니다. ML 엔지니어는 다양한 배포 전략을 고려하고 있습니다.",
        "Question": "회사가 새로운 모델을 소수의 사용자와 테스트하면서 나머지 사용자에게는 현재 모델을 유지하고, 문제가 발생할 경우 안전한 롤백 옵션을 제공할 수 있는 배포 전략은 무엇입니까?",
        "Options": {
            "1": "새로운 모델이 병렬로 실행되지만 사용자에게 영향을 미치지 않는 섀도우 배포 전략을 채택하여 실제 조건에서 성능을 테스트하기 어렵게 만듭니다.",
            "2": "모든 사용자에게 새로운 모델을 점진적으로 배포하는 선형 배포 전략을 사용하여, 문제가 발생할 경우 이전 모델로 신속하게 되돌리기 어렵게 만듭니다.",
            "3": "새로운 모델이 현재 모델과 함께 배포되고 트래픽이 모두 한 번에 새로운 모델로 전환되는 블루/그린 배포 전략을 구현합니다.",
            "4": "전체 롤아웃 전에 새로운 모델을 소수의 사용자에게 배포하여 모니터링하고 필요시 신속하게 롤백할 수 있는 카나리 배포 전략을 활용합니다."
        },
        "Correct Answer": "전체 롤아웃 전에 새로운 모델을 소수의 사용자에게 배포하여 모니터링하고 필요시 신속하게 롤백할 수 있는 카나리 배포 전략을 활용합니다.",
        "Explanation": "카나리 배포 전략은 회사가 새로운 모델을 소수의 사용자에게 배포하면서 기존 모델을 대다수 사용자에게 활성 상태로 유지할 수 있게 합니다. 이 접근 방식은 팀이 새로운 모델의 성능을 모니터링하고 문제가 발생할 경우 신속하게 이전 모델로 되돌릴 수 있게 합니다.",
        "Other Options": [
            "블루/그린 배포 전략은 새로운 모델을 전체적으로 배포하고 모든 트래픽을 한 번에 전환하는 방식으로, 문제가 발생할 경우 모든 사용자에게 동시에 영향을 미치기 때문에 위험이 증가합니다.",
            "선형 배포 전략은 새로운 모델을 모든 사용자에게 단계적으로 배포하지만, 이는 롤백 프로세스를 복잡하게 만들고 더 많은 사용자들이 잠재적 문제에 더 오랜 시간 노출될 수 있습니다.",
            "섀도우 배포 전략은 새로운 모델이 기존 모델과 함께 실행되도록 하여 사용자에게 영향을 미치지 않지만, 실제 사용자 피드백이나 신속한 롤백 기능을 제공하지 않기 때문에 사용자와 직접적으로 상호작용하지 않습니다."
        ]
    },
    {
        "Question Number": "27",
        "Situation": "한 머신러닝 엔지니어가 예측 분석 모델을 위한 대규모 데이터셋을 준비하는 임무를 맡았습니다. 데이터셋은 숫자, 범주형 및 텍스트 데이터를 포함한 다양한 특징으로 구성되어 있습니다. 엔지니어는 모델 성능을 높이기 위해 데이터를 효과적으로 정리하고 변환하며 시각화해야 합니다.",
        "Question": "이 시나리오에서 데이터 탐색, 변환 및 시각화에 가장 적합한 AWS 서비스는 무엇입니까?",
        "Options": {
            "1": "Amazon QuickSight",
            "2": "AWS Glue DataBrew",
            "3": "Amazon SageMaker Data Wrangler",
            "4": "AWS Glue"
        },
        "Correct Answer": "Amazon SageMaker Data Wrangler",
        "Explanation": "Amazon SageMaker Data Wrangler는 머신러닝 모델 훈련 전에 데이터셋을 정리하고 변환하며 시각화하는 작업을 위해 특별히 설계되었습니다. 데이터 과학자들이 효율적으로 작업 흐름을 간소화할 수 있도록 사용자 친화적인 인터페이스를 제공합니다.",
        "Other Options": [
            "AWS Glue DataBrew는 주로 분석을 위한 데이터 준비에 중점을 두지만, SageMaker Data Wrangler에 비해 데이터 시각화 및 변환에 대한 고급 기능이 부족합니다.",
            "AWS Glue는 완전 관리형 ETL 서비스이지만, 머신러닝을 위한 데이터 준비에 필수적인 대화형 데이터 탐색 및 시각화 도구를 제공하지 않습니다.",
            "Amazon QuickSight는 데이터 시각화에 뛰어난 비즈니스 인텔리전스 서비스이지만, 머신러닝 프로젝트를 위한 데이터 변환 및 준비에 필요한 도구를 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "28",
        "Situation": "한 금융 서비스 회사가 Amazon SageMaker를 사용하여 고객 신용 위험을 예측하는 머신러닝 모델을 배포하고 있습니다. 그들은 민감한 고객 데이터의 보안과 규정 준수에 대해 우려하고 있습니다. 모델 훈련 및 추론 중 데이터 프라이버시를 보장하고 접근 제어를 구현하는 솔루션이 필요합니다.",
        "Question": "Amazon SageMaker의 어떤 기능이 회사의 보안 및 규정 준수 문제를 가장 잘 해결할 수 있습니까?",
        "Options": {
            "1": "자동화된 모델 훈련을 위한 SageMaker Autopilot",
            "2": "데이터 전처리를 위한 SageMaker Data Wrangler",
            "3": "안전한 데이터 전송을 위한 SageMaker PrivateLink",
            "4": "협업 개발을 위한 SageMaker Studio"
        },
        "Correct Answer": "안전한 데이터 전송을 위한 SageMaker PrivateLink",
        "Explanation": "SageMaker PrivateLink는 가상 사설 클라우드(VPC) 내에서 SageMaker 리소스에 안전하고 비공식적인 방법으로 접근할 수 있도록 하여 민감한 데이터가 공용 인터넷에 노출되지 않도록 보장합니다. 이 기능은 데이터 프라이버시를 유지하고 규정 준수를 위한 데 매우 중요합니다.",
        "Other Options": [
            "SageMaker Studio는 협업 및 개발을 촉진하지만 데이터 프라이버시와 관련된 보안 및 규정 준수 요구 사항을 특별히 해결하지는 않습니다.",
            "SageMaker Data Wrangler는 데이터 전처리에 유용하지만 데이터 전송이나 접근 제어를 위한 보안 기능을 제공하지 않습니다.",
            "SageMaker Autopilot은 모델 훈련 프로세스를 자동화하지만 훈련이나 추론 중 민감한 고객 데이터를 보호하기 위한 보안 기능을 본질적으로 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "29",
        "Situation": "한 기술 회사의 데이터 과학 팀이 분당 수천 건의 요청을 처리할 머신러닝 모델을 배포하고 있습니다. 그들은 다양한 부하에서 애플리케이션이 최적의 성능을 발휘하도록 하기 위해 최상의 스케일링 정책을 결정해야 합니다.",
        "Question": "팀이 비용을 최소화하면서 성능을 유지하기 위해 고려해야 할 스케일링 정책은 무엇입니까?",
        "Options": {
            "1": "미리 정의된 시간 간격에 따라 리소스를 자동으로 조정하는 예약 스케일링 정책 선택",
            "2": "필요에 따라 리소스를 조정하기 위해 팀의 개입이 필요한 수동 스케일링 정책 채택",
            "3": "수요에 관계없이 일정한 수의 인스턴스를 유지하는 고정 스케일링 정책 활용",
            "4": "미래 수요 예측에 따라 리소스를 조정하는 예측 스케일링 정책 구현"
        },
        "Correct Answer": "미래 수요 예측에 따라 리소스를 조정하는 예측 스케일링 정책 구현",
        "Explanation": "예측 스케일링 정책은 과거 데이터를 사용하여 수요의 급증을 예측하고 그에 따라 리소스를 조정합니다. 이 접근 방식은 애플리케이션이 반응성을 유지하면서 저조한 트래픽 시간 동안 리소스를 과도하게 할당하지 않도록 비용을 최적화합니다.",
        "Other Options": [
            "고정 스케일링 정책은 수요의 변동을 고려하지 않으므로 피크 부하 동안 과소 할당되거나 저사용 기간 동안 과다 할당되어 불필요한 비용이 발생할 수 있습니다.",
            "수동 스케일링 정책은 팀의 지속적인 모니터링과 개입이 필요하므로 리소스 조정에 지연이 발생하고 예기치 않은 수요 급증 시 성능에 부정적인 영향을 미칠 수 있습니다.",
            "예약 스케일링 정책은 예측 가능한 작업에 잘 작동하지만 미리 정의된 일정 외의 갑작스러운 수요 변화에 효과적으로 대응하지 못할 수 있어 성능 문제를 일으킬 수 있습니다."
        ]
    },
    {
        "Question Number": "30",
        "Situation": "데이터 과학 팀이 고객 이탈 예측 모델 훈련을 위한 데이터셋을 준비하고 있습니다. 그들은 인구 통계 정보와 사용 패턴을 포함한 다양한 고객 상호작용 데이터를 수집했습니다. 예측의 품질을 향상시키기 위해 데이터셋이 잘 준비되어 잠재적인 예측 편향을 최소화해야 합니다.",
        "Question": "데이터셋을 준비하여 예측 편향을 줄이기 위한 가장 효과적인 전략은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "데이터셋을 훈련, 검증 및 테스트 세트로 분할",
            "2": "영향을 분석하지 않고 이상치를 제거",
            "3": "분할 전에 데이터셋을 무작위로 섞기",
            "4": "검증 없이 전체 데이터셋을 훈련에 사용",
            "5": "데이터셋 크기를 늘리기 위해 데이터 증강 기법 사용"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "데이터셋을 훈련, 검증 및 테스트 세트로 분할",
            "분할 전에 데이터셋을 무작위로 섞기"
        ],
        "Explanation": "데이터셋을 훈련, 검증 및 테스트 세트로 분할하면 모델 성능을 공정하게 평가할 수 있으며 과적합을 방지하는 데 도움이 됩니다. 데이터셋을 무작위로 섞으면 데이터가 대표성을 가지게 되고 모델이 데이터 순서에 따라 의도하지 않은 패턴을 학습하지 않도록 보장합니다.",
        "Other Options": [
            "데이터셋 크기를 늘리기 위해 데이터 증강 기법을 사용하는 것은 유용하지만 주로 제한된 데이터 문제를 해결하기 위한 것이지 직접적으로 예측 편향을 줄이는 것은 아닙니다.",
            "영향을 분석하지 않고 이상치를 제거하면 귀중한 정보를 잃을 수 있으며, 이상치가 실제로 문제와 관련이 있다면 편향을 초래할 수 있습니다.",
            "검증 없이 전체 데이터셋을 훈련에 사용하는 것은 모델 성능을 적절히 평가할 수 없게 하여 과적합과 일반화 부족을 초래할 수 있습니다."
        ]
    },
    {
        "Question Number": "31",
        "Situation": "한 회사가 실시간 예측을 위한 ML 모델을 배포했으며, 사용량이 많은 시간대에 지연 문제를 경험하기 시작했습니다. 팀은 모델의 성능을 모니터링하고 사용자 경험을 저하시키지 않으면서 증가된 부하를 처리하기 위해 자원을 효과적으로 확장할 방법을 찾아야 합니다.",
        "Question": "지연 및 확장 문제를 해결하면서 프로덕션에서 ML 모델의 지속적인 모니터링을 제공하는 가장 좋은 솔루션은 무엇입니까?",
        "Options": {
            "1": "AWS Lambda를 사용하여 예측을 처리하고 AWS CloudTrail을 통해 지연을 모니터링합니다.",
            "2": "Amazon CloudWatch를 설정하여 모델의 성능을 모니터링하고 기본 인프라에 대한 자동 확장을 구성합니다.",
            "3": "모델을 Amazon EC2 인스턴스에 배포하고 사용자 정의 스크립트로 지연을 수동으로 모니터링합니다.",
            "4": "Amazon SageMaker Batch Transform을 구현하여 피크 시간 동안 요청을 일괄 처리합니다."
        },
        "Correct Answer": "Amazon CloudWatch를 설정하여 모델의 성능을 모니터링하고 기본 인프라에 대한 자동 확장을 구성합니다.",
        "Explanation": "Amazon CloudWatch를 사용하면 지연 및 처리량과 같은 ML 모델의 성능 지표를 실시간으로 모니터링할 수 있습니다. 이를 자동 확장과 결합하면 인프라가 증가된 부하에 동적으로 조정될 수 있어 지연 문제를 효과적으로 해결할 수 있습니다.",
        "Other Options": [
            "모델을 Amazon EC2 인스턴스에 배포하고 사용자 정의 스크립트로 수동으로 모니터링하는 것은 비효율적이며 확장 요구에 대한 응답 지연을 초래할 수 있습니다. 이는 CloudWatch가 제공하는 자동화 및 실시간 모니터링 수준을 제공하지 않습니다.",
            "예측을 위해 AWS Lambda를 사용하는 것은 이 맥락에서 실시간 지연 문제에 적합하지 않습니다. Lambda는 콜드 스타트 문제를 가지고 있으며 고빈도 실시간 요청을 효과적으로 처리하도록 설계되지 않았습니다.",
            "Amazon SageMaker Batch Transform을 구현하는 것은 데이터를 일괄 처리하므로 실시간 시나리오에 적합하지 않으며, 피크 사용 시간 동안 지연 문제를 해결하는 데 도움이 되지 않습니다."
        ]
    },
    {
        "Question Number": "32",
        "Situation": "한 ML 엔지니어가 AWS 서비스를 사용하여 엔드 투 엔드 머신 러닝 워크플로우를 배포하는 임무를 맡았습니다. 그들은 모델 코드의 버전 관리를 위해 코드 저장소를 설정하고 AWS CodePipeline을 사용하여 지속적인 통합 및 배포를 하고 있습니다. 엔지니어는 코드 저장소에 푸시된 변경 사항이 수동 개입 없이 자동으로 모델의 새로운 배포를 트리거하도록 보장하고 싶어합니다.",
        "Question": "다음 구성 중 워크플로우가 제대로 자동화되도록 보장하는 것은 무엇입니까?",
        "Options": {
            "1": "코드 저장소에 웹훅을 설정하여 파이프라인을 트리거합니다.",
            "2": "저장소의 변경 사항을 확인하는 Lambda 함수를 생성합니다.",
            "3": "배포 프로세스를 실행하기 위해 로컬 스크립트를 사용합니다.",
            "4": "변경 사항이 있을 때마다 모델을 수동으로 배포합니다."
        },
        "Correct Answer": "코드 저장소에 웹훅을 설정하여 파이프라인을 트리거합니다.",
        "Explanation": "코드 저장소에 웹훅을 설정하면 저장소에 변경 사항이 푸시될 때마다 CodePipeline이 자동으로 트리거됩니다. 이는 수동 개입 없이 원활한 통합 및 배포 프로세스를 보장합니다.",
        "Other Options": [
            "변경 사항이 있을 때마다 모델을 수동으로 배포하는 것은 인적 오류의 위험을 초래하고 배포 프로세스를 지연시켜 자동화의 목표에 반합니다.",
            "저장소의 변경 사항을 확인하는 Lambda 함수를 생성하는 것은 불필요한 복잡성을 초래합니다. 웹훅은 이 목적을 위해 특별히 설계되었으며 더 효율적입니다.",
            "배포 프로세스를 실행하기 위해 로컬 스크립트를 사용하는 것은 CI/CD 원칙에 부합하지 않으며 수동 실행이 필요하므로 자동화의 목적을 무색하게 만듭니다."
        ]
    },
    {
        "Question Number": "33",
        "Situation": "한 금융 서비스 회사가 데이터 수집, 모델 훈련 및 예측 제공을 포함하는 머신 러닝 파이프라인에 대한 지속적인 배포 전략을 구현하고 있습니다. 그들은 생산 환경에 대한 중단을 최소화하면서 원활한 통합 및 배포를 허용하는 브랜칭 전략을 채택하고자 합니다.",
        "Question": "이 머신 러닝 파이프라인을 호출하기 위한 가장 효과적인 지속적인 배포 흐름 구조는 무엇입니까? (두 개 선택)",
        "Options": {
            "1": "빠른 반복과 머신 러닝 모델의 빈번한 배포를 지원하기 위해 트렁크 기반 개발 접근 방식을 채택합니다.",
            "2": "재배포 없이 머신 러닝 모델의 서로 다른 버전 간 전환을 위해 기능 토글을 사용합니다.",
            "3": "워크플로우를 시각화하고 머신 러닝 파이프라인의 배포를 관리하기 위해 칸반 접근 방식을 활용합니다.",
            "4": "기능 개발을 관리하고 데이터 처리 및 모델 훈련을 위한 안정적인 릴리스를 보장하기 위해 Gitflow를 구현합니다.",
            "5": "모델 제공 환경에 대한 변경 사항을 배포하기 위한 간소화된 프로세스를 유지하기 위해 GitHub Flow를 활용합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "기능 개발을 관리하고 데이터 처리 및 모델 훈련을 위한 안정적인 릴리스를 보장하기 위해 Gitflow를 구현합니다.",
            "모델 제공 환경에 대한 변경 사항을 배포하기 위한 간소화된 프로세스를 유지하기 위해 GitHub Flow를 활용합니다."
        ],
        "Explanation": "Gitflow와 GitHub Flow는 버전 관리 및 배포를 위한 구조화된 접근 방식을 제공하여 머신 러닝 워크플로우의 변경 사항 관리를 위한 적합한 방법입니다. Gitflow는 여러 기능과 릴리스를 안전하게 관리할 수 있도록 하며, GitHub Flow는 더 간단하고 빠른 배포 주기를 위해 설계되어 지속적인 배포에 필수적입니다.",
        "Other Options": [
            "트렁크 기반 개발은 트렁크로의 빠른 병합에 더 중점을 두며 대규모 머신 러닝 프로젝트에 필요한 복잡한 브랜칭 전략을 충분히 지원하지 않을 수 있습니다.",
            "기능 토글은 모델 버전 간 전환을 허용하지만, 워크플로우를 효과적으로 관리하기 위한 구조화된 배포 전략을 본질적으로 제공하지 않습니다.",
            "칸반은 작업 및 워크플로우를 시각화하기 위한 프로젝트 관리 접근 방식이지만, 머신 러닝 파이프라인의 지속적인 배포를 직접적으로 다루지 않습니다."
        ]
    },
    {
        "Question Number": "34",
        "Situation": "데이터 과학 팀이 Amazon SageMaker에서 다양한 AWS 서비스에 접근해야 하는 머신 러닝 모델을 배포하고 있습니다. 이 서비스에는 데이터 저장을 위한 S3와 모니터링을 위한 CloudWatch가 포함됩니다. 보안과 적절한 접근 관리를 보장하기 위해, 그들은 최소 권한 원칙을 준수하면서 필요한 권한을 부여하는 강력한 IAM 정책을 만들어야 합니다.",
        "Question": "다음 IAM 구성 중 SageMaker 모델에 필요한 AWS 서비스에 대한 안전한 접근을 보장하면서 모범 사례를 준수하는 데 가장 적합한 것은 무엇입니까?",
        "Options": {
            "1": "모든 AWS 서비스에 대한 전체 접근 권한을 가진 단일 IAM 사용자를 생성합니다.",
            "2": "조직의 모든 사용자에게 단순성을 위해 동일한 정책을 할당합니다.",
            "3": "모델에 대한 무제한 접근을 허용하는 공개 IAM 역할을 사용합니다.",
            "4": "특정 권한이 정의된 IAM 역할을 만들고 이를 SageMaker 노트북 인스턴스에 연결합니다."
        },
        "Correct Answer": "특정 권한이 정의된 IAM 역할을 만들고 이를 SageMaker 노트북 인스턴스에 연결합니다.",
        "Explanation": "특정 권한이 정의된 IAM 역할을 생성하면 SageMaker 인스턴스가 필요한 서비스에만 접근할 수 있어 보안 위험을 최소화하고 IAM 관리의 모범 사례를 준수할 수 있습니다.",
        "Other Options": [
            "단일 IAM 사용자를 생성하여 전체 접근 권한을 부여하는 것은 최소 권한 원칙을 위반하며, SageMaker 모델의 운영에 필요하지 않은 과도한 권한을 부여합니다.",
            "공개 IAM 역할을 사용하는 것은 무제한 접근을 허용하여 보안을 위협하며, 모델과 관련 리소스가 잠재적인 오용에 노출될 수 있습니다.",
            "조직의 모든 사용자에게 동일한 정책을 할당하는 것은 모범 사례가 아니며, 최소 권한 원칙을 고려하지 않아 민감한 리소스에 대한 무단 접근으로 이어질 수 있습니다."
        ]
    },
    {
        "Question Number": "35",
        "Situation": "머신 러닝 엔지니어가 Amazon SageMaker 외부에서 TensorFlow를 사용하여 모델을 개발했습니다. 엔지니어는 SageMaker의 엔드포인트 관리 및 모니터링과 같은 기능을 활용하여 이 모델을 확장 가능한 방식으로 배포하고자 합니다. 엔지니어는 TensorFlow 모델을 SageMaker에 통합하여 배포하는 최선의 방법을 찾고 있습니다.",
        "Question": "머신 러닝 엔지니어가 TensorFlow 모델을 SageMaker에 통합하기 위해 어떤 방법을 사용해야 합니까?",
        "Options": {
            "1": "TensorFlow 모델을 Docker 컨테이너에 패키징하고, Amazon ECR에 업로드한 후 SageMaker를 사용하여 배포합니다.",
            "2": "EC2 인스턴스에 TensorFlow를 수동으로 설치한 다음, 해당 인스턴스를 사용하여 모델의 SageMaker 엔드포인트를 생성합니다.",
            "3": "SageMaker의 내장 TensorFlow 컨테이너를 사용하고 모델 파일을 지정된 S3 버킷에 직접 업로드합니다.",
            "4": "TensorFlow 모델 코드를 사용하여 SageMaker 학습 작업을 생성하고 이를 실행하여 새로운 모델 아티팩트를 생성합니다."
        },
        "Correct Answer": "TensorFlow 모델을 Docker 컨테이너에 패키징하고, Amazon ECR에 업로드한 후 SageMaker를 사용하여 배포합니다.",
        "Explanation": "TensorFlow 모델을 Docker 컨테이너에 패키징하면 모델이 실행되는 환경을 완전히 제어할 수 있습니다. 이 컨테이너를 Amazon ECR에 푸시함으로써, 엔지니어는 SageMaker에서 쉽게 배포할 수 있으며, 모든 종속성이 충족되고 모델이 적절하게 확장될 수 있도록 보장합니다.",
        "Other Options": [
            "SageMaker의 내장 TensorFlow 컨테이너를 사용하고 모델 파일을 S3에 직접 업로드하는 것은 환경이나 종속성을 사용자 정의할 수 있는 기능이 부족하여 배포에 충분하지 않습니다.",
            "TensorFlow 모델 코드를 사용하여 SageMaker 학습 작업을 생성하는 것은 모델이 이미 훈련된 경우 불필요합니다. 이 접근 방식은 기존 모델을 배포하기보다는 훈련에 더 적합합니다.",
            "EC2 인스턴스에 TensorFlow를 수동으로 설치하는 것은 SageMaker의 기능을 활용하지 않으며, 인스턴스와 환경을 관리하는 데 더 많은 운영 오버헤드가 필요합니다."
        ]
    },
    {
        "Question Number": "36",
        "Situation": "머신 러닝 엔지니어가 AWS 환경에서 기존 프로덕션 변형과 함께 배포된 새로운 섀도우 변형 모델을 평가하는 임무를 맡았습니다. 목표는 두 모델의 성능을 비교하여 새로운 변형이 사용자 경험에 부정적인 영향을 미치지 않으면서 예측 정확도를 향상시키는지 확인하는 것입니다.",
        "Question": "머신 러닝 엔지니어가 섀도우 변형의 성능을 프로덕션 변형과 비교하기 위해 분석해야 할 메트릭은 무엇입니까? (두 개 선택)",
        "Options": {
            "1": "정밀도",
            "2": "훈련 시간",
            "3": "지연 시간",
            "4": "F1 점수",
            "5": "모델 복잡성"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "정밀도",
            "F1 점수"
        ],
        "Explanation": "정밀도와 F1 점수는 분류 모델의 성능을 평가하는 데 중요한 메트릭입니다. 정밀도는 긍정적인 예측의 정확성을 측정하고, F1 점수는 정밀도와 재현율 간의 균형을 제공하여 모델 성능의 트레이드오프를 이해하는 데 중요합니다.",
        "Other Options": [
            "모델 복잡성은 직접적인 성능 메트릭이 아니며, 모델의 구조와 용량을 나타내는 것이지 예측 정확성이나 효과성을 나타내지 않습니다.",
            "지연 시간은 모델이 예측을 수행하는 데 걸리는 시간을 측정하지만, 예측의 품질이나 정확성에 대한 통찰력을 제공하지 않습니다.",
            "훈련 시간은 모델을 훈련하는 데 걸리는 시간을 나타내지만, 모델이 프로덕션 환경에 배포된 후 얼마나 잘 수행되는지를 반영하지 않습니다."
        ]
    },
    {
        "Question Number": "37",
        "Situation": "머신러닝 엔지니어가 로컬 환경에서 개발 및 훈련된 모델을 배포하는 임무를 맡았습니다. 목표는 버전 관리 및 CI/CD 파이프라인에 대한 모범 사례를 활용하여 프로덕션으로의 원활한 전환을 보장하는 것입니다.",
        "Question": "프로덕션 환경에서 머신러닝 모델을 배포하기 위해 코드 리포지토리와 CI/CD 파이프라인을 가장 잘 통합하는 접근 방식은 무엇입니까?",
        "Options": {
            "1": "버전 관리 및 배포를 위해 AWS CodePipeline과 AWS CodeCommit을 활용합니다.",
            "2": "버전 관리 또는 CI/CD 도구를 사용하지 않고 모델을 수동으로 배포합니다.",
            "3": "Docker 컨테이너를 생성하고 CI/CD 파이프라인 없이 직접 배포합니다.",
            "4": "CI/CD와 통합하지 않고 모델 아티팩트를 저장하기 위해 Amazon S3를 사용합니다."
        },
        "Correct Answer": "버전 관리 및 배포를 위해 AWS CodePipeline과 AWS CodeCommit을 활용합니다.",
        "Explanation": "AWS CodePipeline과 AWS CodeCommit을 활용하면 자동화된 배포 및 버전 관리를 가능하게 하여 모델에 대한 변경 사항을 추적하고 필요 시 쉽게 롤백할 수 있습니다. 이 접근 방식은 DevOps의 모범 사례와 일치하며 배포 프로세스의 신뢰성을 향상시킵니다.",
        "Other Options": [
            "모델을 수동으로 배포하면 자동화 및 변경 사항 추적이 부족하여 버전 관리 및 재현성과 관련된 위험이 발생합니다.",
            "모델 아티팩트를 저장하기 위해 Amazon S3를 사용하는 것은 자동화된 배포 및 버전 관리에 필수적인 CI/CD 프로세스와의 통합을 제공하지 않습니다.",
            "Docker 컨테이너를 생성하고 CI/CD 파이프라인 없이 직접 배포하면 CI/CD가 제공하는 자동화, 테스트 및 버전 관리의 기회를 놓치게 되어 배포에 어려움이 발생할 수 있습니다."
        ]
    },
    {
        "Question Number": "38",
        "Situation": "금융 서비스 회사가 고객 거래를 처리하기 위해 다양한 머신러닝 모델을 프로덕션에 배포하고 있습니다. 그들은 요구 사항에 따라 다양한 모델의 성능을 최적화하기 위해 CPU 및 GPU 컴퓨팅 리소스가 필요합니다. ML 엔지니어는 이러한 리소스를 효과적으로 프로비저닝하기 위해 적절한 AWS 서비스를 결정해야 합니다.",
        "Question": "ML 엔지니어가 CPU 및 GPU 환경을 위한 컴퓨팅 리소스를 프로비저닝하기 위해 활용해야 할 두 가지 AWS 서비스는 무엇입니까? (두 개 선택)",
        "Options": {
            "1": "특정 CPU 및 GPU 요구 사항에 따라 AWS Management Console을 사용하여 EC2 인스턴스를 직접 프로비저닝합니다.",
            "2": "AWS Batch를 사용하여 다양한 컴퓨팅 리소스에서 배치 처리 작업을 관리하고 예약합니다.",
            "3": "Amazon SageMaker를 사용하여 자동 확장 옵션이 있는 훈련 및 호스팅 환경을 생성합니다.",
            "4": "Amazon Elastic Kubernetes Service (EKS)를 활용하여 GPU 지원이 있는 컨테이너화된 ML 워크로드를 조정합니다.",
            "5": "AWS Lambda를 활용하여 GPU 가속이 필요한 추론 작업을 실행합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon SageMaker를 사용하여 자동 확장 옵션이 있는 훈련 및 호스팅 환경을 생성합니다.",
            "Amazon Elastic Kubernetes Service (EKS)를 활용하여 GPU 지원이 있는 컨테이너화된 ML 워크로드를 조정합니다."
        ],
        "Explanation": "Amazon SageMaker는 CPU 및 GPU 인스턴스를 지원하는 머신러닝 모델을 구축, 훈련 및 배포하기 위한 통합 환경을 제공합니다. 또한 리소스 사용을 최적화하기 위한 자동 확장 기능을 제공합니다. Amazon EKS는 ML 워크로드를 포함한 컨테이너화된 애플리케이션의 조정을 가능하게 하며, 훈련 및 추론을 위한 GPU 인스턴스를 지원하여 유연한 리소스 할당이 필요한 시나리오에 적합합니다.",
        "Other Options": [
            "EC2 인스턴스를 직접 프로비저닝하는 것은 SageMaker나 EKS와 같은 관리 및 자동화 수준을 제공하지 않으므로 확장 가능한 ML 워크플로우에 덜 효율적입니다.",
            "AWS Lambda는 GPU 인스턴스를 지원하지 않으므로 복잡한 ML 모델에 대한 GPU 가속이 필요한 작업을 처리하는 능력이 제한될 수 있습니다.",
            "AWS Batch는 배치 작업 예약에 유용하지만, 실시간 추론 작업이나 빠른 리소스 확장이 필요한 대화형 훈련 세션을 위해 특별히 설계되지 않았습니다."
        ]
    },
    {
        "Question Number": "39",
        "Situation": "머신러닝 팀이 AWS 인프라에서 모델 배포를 평가하고 있습니다. 그들은 ML 워크로드의 특정 요구 사항에 따라 성능을 최적화하기 위해 가장 적합한 인스턴스 유형을 선택해야 합니다.",
        "Question": "팀이 고유한 워크로드 요구 사항에 따라 성능을 극대화하기 위해 고려해야 할 두 가지 인스턴스 유형은 무엇입니까? (두 개 선택)",
        "Options": {
            "1": "높은 데이터 처리량을 위한 메모리 최적화 인스턴스",
            "2": "높은 I/O 성능을 위한 스토리지 최적화 인스턴스",
            "3": "균형 잡힌 성능을 위한 일반 목적 인스턴스",
            "4": "집약적인 계산을 위한 컴퓨트 최적화 인스턴스",
            "5": "실시간 예측을 위한 추론 최적화 인스턴스"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "높은 데이터 처리량을 위한 메모리 최적화 인스턴스",
            "집약적인 계산을 위한 컴퓨트 최적화 인스턴스"
        ],
        "Explanation": "메모리 최적화 인스턴스는 대량의 메모리를 요구하는 워크로드에 대해 빠른 성능을 제공하도록 설계되어 데이터 처리 작업에 이상적입니다. 컴퓨트 최적화 인스턴스는 계산 집약적인 애플리케이션에 맞춰져 있으며, 복잡한 ML 모델 훈련과 같이 상당한 처리 능력을 요구하는 작업에 대해 높은 성능을 제공합니다.",
        "Other Options": [
            "일반 목적 인스턴스는 다재다능하지만 메모리 또는 계산 집약적인 작업과 같은 특수한 워크로드에 필요한 특정 성능 향상을 제공하지 않을 수 있습니다.",
            "추론 최적화 인스턴스는 낮은 대기 시간을 중시하여 프로덕션에서 모델을 배포하기 위해 특별히 설계되었지만, 훈련이나 무거운 계산 작업에는 최선의 선택이 아닐 수 있습니다.",
            "스토리지 최적화 인스턴스는 높은 디스크 처리량이 필요한 워크로드에 주로 유용하며, 계산 또는 메모리 집약적인 작업과는 직접적인 관련이 없습니다."
        ]
    },
    {
        "Question Number": "40",
        "Situation": "한 소매 회사가 고객 서비스 향상을 위해 고객 서비스 통화를 자동으로 텍스트로 전사하여 분석하고자 합니다. 그들은 음성 언어를 정확하게 서면 텍스트로 변환할 수 있는 AWS 서비스를 찾고 있으며, 이를 통해 일반적인 문제를 식별하고 서비스를 개선하고자 합니다.",
        "Question": "회사가 오디오 통화를 텍스트로 전사하기 위해 어떤 AWS 서비스를 사용해야 합니까?",
        "Options": {
            "1": "Amazon Transcribe",
            "2": "Amazon Translate",
            "3": "Amazon Rekognition",
            "4": "Amazon Polly"
        },
        "Correct Answer": "Amazon Transcribe",
        "Explanation": "Amazon Transcribe는 음성을 텍스트로 변환하기 위해 특별히 설계되어 있어, 고객 서비스 통화를 분석하기 위해 전사할 필요가 있는 소매 회사에 이상적인 선택입니다. 이는 정확하고 실시간 전사 기능을 제공하여 고객 서비스 통찰력을 크게 향상시킬 수 있습니다.",
        "Other Options": [
            "Amazon Rekognition은 주로 이미지 및 비디오 분석, 예를 들어 객체 및 장면 감지에 사용되며, 오디오 전사에는 적합하지 않습니다.",
            "Amazon Translate는 텍스트를 한 언어에서 다른 언어로 번역하는 서비스이며, 오디오 데이터나 전사를 처리하지 않습니다.",
            "Amazon Polly는 서면 텍스트를 음성 언어로 변환하는 텍스트-투-스피치 서비스로, 회사가 오디오를 전사하는 데 필요한 것과는 반대입니다."
        ]
    },
    {
        "Question Number": "41",
        "Situation": "한 머신 러닝 엔지니어가 Amazon SageMaker를 사용하여 구축된 이진 분류 모델을 평가하고 있습니다. 모델의 성능은 비즈니스 요구 사항을 충족하는지 확인하기 위해 적절한 메트릭을 사용하여 평가해야 합니다. 엔지니어는 특히 잘못된 긍정 및 잘못된 부정과 관련된 비용을 고려하여 정밀도와 재현율 간의 균형을 이해하는 데 관심이 있습니다.",
        "Question": "모델의 성능을 효과적으로 평가하기 위해 엔지니어가 집중해야 할 두 가지 메트릭은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "Precision",
            "2": "F1 Score",
            "3": "Receiver Operating Characteristic (ROC)",
            "4": "Area Under the ROC Curve (AUC)",
            "5": "Root Mean Square Error (RMSE)"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Precision",
            "F1 Score"
        ],
        "Explanation": "Precision은 모델이 만든 모든 긍정 예측 중 실제 긍정 예측의 비율을 나타내며, 잘못된 긍정의 비용이 높은 경우 필수적입니다. F1 Score는 정밀도와 재현율 간의 균형을 제공하여, 잘못된 긍정과 잘못된 부정이 비즈니스에 중대한 영향을 미칠 때의 균형을 이해할 수 있게 합니다.",
        "Other Options": [
            "Root Mean Square Error (RMSE)는 주로 회귀 평가에 사용되며, 연속 출력의 평균 오류 크기를 측정하기 때문에 분류 작업에 적합하지 않습니다.",
            "Receiver Operating Characteristic (ROC)는 모델 성능을 시각화하는 데 유용한 메트릭이지만, 정밀도나 F1 Score와 같은 단일 효과 측정치를 제공하지 않습니다.",
            "Area Under the ROC Curve (AUC)는 모든 분류 임계값에 대한 성능의 집계 측정이지만, 정밀도와 재현율 간의 균형에 대한 직접적인 통찰을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "42",
        "Situation": "한 머신 러닝 엔지니어가 새로 배포된 모델의 성능을 기존 버전과 비교하여 모니터링하는 임무를 맡고 있습니다. 엔지니어는 정확도와 사용자 참여 측면에서 어떤 모델이 더 나은 성능을 보이는지 평가하기 위해 A/B 테스트를 구현하고자 합니다. 이 솔루션은 효율적이어야 하며, 결과를 신속하게 분석하여 향후 결정을 내리는 데 도움이 되어야 합니다.",
        "Question": "엔지니어가 A/B 테스트를 사용하여 모델의 성능을 효과적으로 모니터링하기 위해 어떤 접근 방식을 취해야 합니까?",
        "Options": {
            "1": "Amazon SageMaker의 내장 A/B 테스트 기능을 활용하여 두 모델 간의 트래픽을 분할하고 성능 메트릭을 자동으로 추적합니다.",
            "2": "AWS Lambda 함수를 사용하여 트래픽을 라우팅하고 두 모델의 성능 메트릭을 기록하는 맞춤형 A/B 테스트 프레임워크를 만듭니다.",
            "3": "단일 엔드포인트에 두 모델을 배포한 후 Amazon CloudWatch를 사용하여 메트릭을 모니터링하고 시각화합니다.",
            "4": "두 모델을 별도의 Amazon SageMaker 엔드포인트에 배포하고 두 엔드포인트의 정보를 집계하여 메트릭을 수동으로 모니터링합니다."
        },
        "Correct Answer": "Amazon SageMaker의 내장 A/B 테스트 기능을 활용하여 두 모델 간의 트래픽을 분할하고 성능 메트릭을 자동으로 추적합니다.",
        "Explanation": "Amazon SageMaker의 내장 A/B 테스트 기능을 사용하면 트래픽 분할과 자동 성능 추적이 원활하게 이루어집니다. 이 접근 방식은 효율적이며 모니터링의 수동 오버헤드를 줄여 엔지니어가 결과를 신속하게 분석하고 정보에 기반한 결정을 내릴 수 있도록 합니다.",
        "Other Options": [
            "두 모델을 별도의 Amazon SageMaker 엔드포인트에 배포하면 수동 모니터링이 필요하여 효율성이 떨어지고 성능 메트릭 분석에 지연이 발생할 수 있습니다.",
            "별도의 엔드포인트에서 메트릭을 모니터링하기 위해 Amazon CloudWatch를 사용하는 것은 효율적으로 트래픽을 분할하고 성능 추적을 자동화할 수 있는 기능이 부족하므로 직접적인 A/B 테스트 메커니즘을 제공하지 않습니다.",
            "AWS Lambda로 맞춤형 A/B 테스트 프레임워크를 만드는 것은 가능하지만 추가적인 복잡성과 잠재적인 실패 지점을 도입하여 SageMaker의 내장 기능을 사용하는 것보다 효율성이 떨어집니다."
        ]
    },
    {
        "Question Number": "43",
        "Situation": "데이터 과학 팀이 구독 기반 서비스의 고객 이탈을 예측하는 머신 러닝 모델을 개발하고 있습니다. 그들은 모델을 배포하여 변동하는 트래픽을 처리하고 비용 효율성을 유지하며 관리가 용이하도록 해야 합니다.",
        "Question": "머신 러닝 모델의 확장 가능하고 비용 효율적인 배포를 달성하기 위해 사용할 수 있는 AWS 서비스와 전략은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "모델 추론을 위한 AWS Lambda",
            "2": "Amazon EC2 예약 인스턴스",
            "3": "Amazon SageMaker 자동 스케일링",
            "4": "Amazon SageMaker 다중 모델 엔드포인트",
            "5": "컨테이너화된 배포를 위한 Amazon ECS"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon SageMaker 자동 스케일링",
            "Amazon SageMaker 다중 모델 엔드포인트"
        ],
        "Explanation": "Amazon SageMaker 자동 스케일링은 엔드포인트가 들어오는 트래픽에 따라 자동으로 조정되어 효율적인 자원 활용을 보장합니다. Amazon SageMaker 다중 모델 엔드포인트는 여러 모델을 단일 엔드포인트에서 호스팅할 수 있게 하여 인프라 비용과 관리 오버헤드를 줄이고 필요에 따라 동적으로 모델을 로드할 수 있도록 합니다.",
        "Other Options": [
            "Amazon EC2 예약 인스턴스는 인스턴스에 대한 고정 약정을 요구하므로 트래픽이 매우 변동성이 큰 경우 비용 효율적이지 않을 수 있으며, 동적 스케일링에 필요한 유연성을 제공하지 않습니다.",
            "모델 추론을 위한 AWS Lambda는 특정 사용 사례에 사용할 수 있지만, 대규모 실시간 추론보다는 소규모 모델이나 배치 처리에 더 적합합니다.",
            "컨테이너화된 배포를 위한 Amazon ECS는 마이크로서비스 아키텍처에 유용하지만, SageMaker가 제공하는 머신 러닝 모델 배포 및 스케일링의 고유한 요구 사항을 특별히 다루지 않습니다."
        ]
    },
    {
        "Question Number": "44",
        "Situation": "머신 러닝 팀이 AWS SageMaker를 사용하여 실시간 예측 서비스를 배포하는 임무를 맡고 있습니다. 그들은 솔루션이 들어오는 트래픽에 따라 자동으로 스케일링되면서 비용을 최적화할 수 있도록 해야 합니다. 팀은 높은 가용성과 성능을 유지하기 위해 다양한 배포 전략과 모범 사례를 고려하고 있습니다.",
        "Question": "팀이 SageMaker에서 ML 모델의 자동 스케일링 및 비용 최적화를 달성하기 위해 구현해야 할 배포 전략은 무엇입니까?",
        "Options": {
            "1": "모델 추론을 위해 AWS Lambda를 사용하여 들어오는 요청에 따라 자동으로 스케일링할 수 있도록 합니다.",
            "2": "들어오는 요청에 따라 메모리에 모델을 로드하는 SageMaker의 다중 모델 엔드포인트를 구현합니다.",
            "3": "일정한 성능 수준을 유지하기 위해 고정된 수의 인스턴스가 있는 EC2 인스턴스에 모델을 배포합니다.",
            "4": "CPU 및 메모리 활용도 메트릭에 따라 자동 스케일링 정책으로 SageMaker 엔드포인트를 구성합니다."
        },
        "Correct Answer": "CPU 및 메모리 활용도 메트릭에 따라 자동 스케일링 정책으로 SageMaker 엔드포인트를 구성합니다.",
        "Explanation": "SageMaker 엔드포인트를 자동 스케일링 정책으로 구성하면 서비스가 작업 부하에 따라 인스턴스 수를 동적으로 조정할 수 있어, 다양한 트래픽 조건에서도 성능을 유지하면서 효율적인 자원 사용과 비용 효율성을 보장합니다.",
        "Other Options": [
            "고정된 EC2 인스턴스에 모델을 배포하면 스케일링의 유연성이 없으며, 자원의 과소 활용 또는 과다 활용으로 이어져 불필요한 비용 증가를 초래할 수 있습니다.",
            "모델 추론을 위한 AWS Lambda 사용은 저용량 트래픽에 대해 비용 효율적일 수 있지만, SageMaker 엔드포인트에 비해 높은 동시성이나 대규모 모델 크기를 효율적으로 처리하지 못할 수 있습니다.",
            "다중 모델 엔드포인트 구현은 여러 모델을 제공하는 데 유용하지만, 트래픽에 따라 자동 스케일링의 필요성을 직접적으로 해결하지 않으며, 이는 성능 유지와 비용 최적화에 중요합니다."
        ]
    },
    {
        "Question Number": "45",
        "Situation": "데이터 과학자가 Amazon SageMaker를 사용하여 딥 러닝 모델을 훈련하고 있습니다. 그들은 모델의 손실 함수가 예상대로 수렴하지 않는 것을 발견했습니다. 문제를 해결하고 훈련 과정에 대한 통찰력을 얻기 위해 데이터 과학자는 SageMaker 모델 디버거를 사용하여 모델 수렴에 영향을 미치는 잠재적 문제를 식별하기로 결정했습니다.",
        "Question": "모델 훈련에서 문제를 식별하는 데 도움이 되는 SageMaker 모델 디버거의 주요 기능은 무엇입니까?",
        "Options": {
            "1": "자동 하이퍼파라미터 조정",
            "2": "훈련 메트릭 시각화",
            "3": "데이터 전처리 자동화",
            "4": "실시간 데이터 검증"
        },
        "Correct Answer": "훈련 메트릭 시각화",
        "Explanation": "SageMaker 모델 디버거는 손실, 기울기 및 가중치와 같은 훈련 메트릭을 분석하기 위한 시각화 도구를 제공하여 수렴 문제를 식별하고 훈련 과정을 효과적으로 최적화하는 데 도움을 줍니다.",
        "Other Options": [
            "실시간 데이터 검증은 훈련 전에 데이터 품질과 일관성을 확인하는 데 중점을 두지만, 훈련 과정에서 수렴 문제를 진단하는 데는 도움이 되지 않습니다.",
            "자동 하이퍼파라미터 조정은 모델 매개변수를 최적화하지만, 모델의 훈련 동역학이나 수렴 행동에 대한 직접적인 통찰력을 제공하지 않습니다.",
            "데이터 전처리 자동화는 데이터 준비 단계를 간소화하지만, 모델의 훈련 수렴 모니터링이나 디버깅에 기여하지 않습니다."
        ]
    },
    {
        "Question Number": "46",
        "Situation": "한 헬스케어 스타트업이 퇴원 후 30일 이내에 재입원 위험이 있는 환자를 식별하기 위한 예측 분석 모델을 개발하고 있습니다. 이들은 개발 시간을 최소화하고 예측 성능을 극대화하기 위해 Amazon SageMaker의 내장 알고리즘을 활용하고자 합니다.",
        "Question": "스타트업이 환자의 재입원 여부를 예측하는 이진 분류 모델을 구현하기 위해 어떤 내장 알고리즘을 사용해야 합니까?",
        "Options": {
            "1": "Amazon SageMaker Object Detection",
            "2": "Amazon SageMaker Linear Learner",
            "3": "Amazon SageMaker K-Means",
            "4": "Amazon SageMaker XGBoost"
        },
        "Correct Answer": "Amazon SageMaker Linear Learner",
        "Explanation": "Amazon SageMaker Linear Learner 알고리즘은 이진 분류 작업을 위해 설계되어 환자의 재입원 여부를 예측하는 데 적합합니다. 이 알고리즘은 대규모 데이터셋에서 효율적인 훈련과 좋은 성능을 제공하며, 이는 헬스케어 분석에 필수적입니다.",
        "Other Options": [
            "Amazon SageMaker XGBoost는 이진 분류도 수행할 수 있는 강력한 앙상블 방법이지만, 더 복잡하며 단순성과 해석 가능성이 우선시될 수 있는 이 특정 작업에는 필요하지 않을 수 있습니다.",
            "Amazon SageMaker K-Means는 클러스터링을 위한 비지도 학습 알고리즘으로, 이진 분류 작업에 적합하지 않으므로 환자의 재입원 예측과는 관련이 없습니다.",
            "Amazon SageMaker Object Detection은 이미지 내에서 객체를 감지하고 분류하기 위해 특별히 설계되었으며, 구조화된 데이터를 기반으로 환자의 재입원을 예측하는 작업에는 적용되지 않습니다."
        ]
    },
    {
        "Question Number": "47",
        "Situation": "한 소매업체가 기계 학습을 활용하여 예측 분석 기능을 향상시키고자 합니다. 이들은 ML 모델을 위한 기능을 효율적으로 관리하고 검색하고자 합니다. 이 회사는 기존 데이터셋에서 파생된 기능의 저장, 검색 및 관리를 용이하게 할 기능 저장소를 만들기 위해 AWS 서비스를 사용하는 것을 고려하고 있습니다.",
        "Question": "ML 엔지니어가 기계 학습 모델을 위한 기능 저장소를 생성하고 관리하기 위해 어떤 두 가지 AWS 서비스를 사용해야 합니까? (두 가지 선택)",
        "Options": {
            "1": "Amazon DynamoDB를 활용하여 지속적인 기능 저장소를 생성합니다.",
            "2": "Amazon Redshift를 사용하여 공식적인 기능 저장소 없이 기능을 분석합니다.",
            "3": "AWS Glue Data Catalog를 활용하여 기능에 대한 메타데이터를 유지합니다.",
            "4": "Amazon S3를 구현하여 기능을 관리하지 않고 원시 데이터를 저장합니다.",
            "5": "Amazon SageMaker Feature Store를 사용하여 기능을 저장하고 관리합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon SageMaker Feature Store를 사용하여 기능을 저장하고 관리합니다.",
            "AWS Glue Data Catalog를 활용하여 기능에 대한 메타데이터를 유지합니다."
        ],
        "Explanation": "Amazon SageMaker Feature Store는 기계 학습 워크플로우에서 기능을 관리하기 위해 특별히 설계되어 기능의 효율적인 저장, 검색 및 버전 관리를 가능하게 합니다. AWS Glue Data Catalog는 데이터 소스 및 기능에 대한 메타데이터를 유지하기 위한 중앙 저장소를 제공하여 데이터 거버넌스 및 발견을 지원합니다.",
        "Other Options": [
            "Amazon DynamoDB는 다양한 데이터 저장 요구에 사용될 수 있지만, 기능 저장소로 특별히 설계되지 않았으며 ML 기능 관리를 위한 전문 기능이 부족합니다.",
            "Amazon S3는 주로 원시 데이터를 저장하는 데 사용되며, 일반적인 기계 학습 워크플로우에서 기능을 관리하기 위한 필요한 기능을 제공하지 않습니다.",
            "Amazon Redshift는 데이터 웨어하우징 서비스로, 기능 관리를 위해 특별히 설계되지 않았습니다. 데이터 분석은 가능하지만 기능 저장소의 역할을 수행하지 않습니다."
        ]
    },
    {
        "Question Number": "48",
        "Situation": "한 소매업체가 매장 위치, 프로모션 및 계절적 요인과 같은 다양한 기능을 기반으로 판매를 예측하는 기계 학습 모델을 구축하기 위해 데이터셋을 준비하고 있습니다. 데이터에는 다양한 스케일을 가진 수치적 기능과 변환이 필요한 범주형 기능이 포함되어 있습니다.",
        "Question": "회사가 수치적 기능이 비교 가능하고 기계 학습 모델에 입력하기에 적합하도록 보장하기 위해 주로 적용해야 할 기능 엔지니어링 기법은 무엇입니까?",
        "Options": {
            "1": "로그 변환",
            "2": "빈닝",
            "3": "정규화",
            "4": "기능 분할"
        },
        "Correct Answer": "정규화",
        "Explanation": "정규화는 수치적 기능을 일반적으로 0과 1 사이의 공통 스케일로 재조정합니다. 이 기법은 모델이 각 기능을 동등하게 처리할 수 있게 하며, 특히 입력 기능의 단위나 스케일이 다를 때 유용합니다. 이는 경량 경량화 기반 모델과 같이 입력 기능의 스케일에 민감한 알고리즘에 적합합니다.",
        "Other Options": [
            "로그 변환은 데이터의 왜곡을 줄이고 분포를 더 정규적으로 만드는 데 유용하지만, 기능이 비교 가능한 스케일에 있도록 보장하지는 않습니다.",
            "빈닝은 연속 기능을 이산 범주로 변환하는 것으로, 모델을 단순화할 수 있지만 정보 손실로 이어질 수 있으며 주로 스케일링에 초점을 맞추지 않습니다.",
            "기능 분할은 단일 기능을 여러 구성 요소로 나누는 것을 의미하며, 새로운 기능을 생성하는 데 유용할 수 있지만 수치적 스케일 비교 문제를 해결하지는 않습니다."
        ]
    },
    {
        "Question Number": "49",
        "Situation": "한 회사가 새로운 데이터에 기반하여 자주 재훈련이 필요한 머신러닝(ML) 모델을 개발하고 있습니다. 그들은 AWS 서비스를 사용하여 훈련 작업을 관리하고 모델을 효율적으로 배포하는 과정을 자동화하고자 합니다.",
        "Question": "ML 모델의 재훈련 및 배포를 자동화하기 위해 가장 적합한 AWS 서비스 조합은 무엇입니까?",
        "Options": {
            "1": "Amazon SageMaker Pipelines를 활용하여 모델 훈련 및 배포 프로세스를 자동화합니다.",
            "2": "AWS Step Functions를 사용하여 훈련 작업을 조정하고 AWS Lambda를 배포 트리거로 활용합니다.",
            "3": "AWS Batch를 훈련 작업에 사용하고 Amazon EC2 인스턴스를 통해 ML 모델의 배포를 관리합니다.",
            "4": "Amazon EventBridge 규칙을 구현하여 훈련 작업을 트리거하고 Amazon S3를 통해 ML 모델을 호스팅합니다."
        },
        "Correct Answer": "Amazon SageMaker Pipelines를 활용하여 모델 훈련 및 배포 프로세스를 자동화합니다.",
        "Explanation": "Amazon SageMaker Pipelines는 훈련 작업 및 모델 배포의 조정을 포함하여 ML 워크플로우를 자동화하기 위한 완전 관리형 서비스를 제공하므로 이 시나리오에 이상적인 선택입니다.",
        "Other Options": [
            "AWS Step Functions는 워크플로우를 조정할 수 있지만 ML 모델 훈련 및 배포를 위해 특별히 설계되지 않아 SageMaker Pipelines에 비해 최적이 아닙니다.",
            "AWS Batch는 배치 처리에 적합하지만 SageMaker Pipelines만큼 ML 모델 생애 주기 관리를 효과적으로 통합하지 않습니다.",
            "Amazon EventBridge를 사용하여 작업을 트리거하는 것은 유용하지만 SageMaker Pipelines가 제공하는 모델 관리 및 배포에 대한 포괄적인 기능이 부족합니다."
        ]
    },
    {
        "Question Number": "50",
        "Situation": "한 머신러닝 엔지니어가 고객 정보를 포함하는 민감한 금융 애플리케이션을 위한 데이터셋을 준비하고 있습니다. 이 데이터셋에는 데이터 프라이버시 규정을 준수하기 위해 보호해야 하는 개인 식별 정보(PII)가 포함되어 있습니다. 엔지니어는 민감한 정보를 노출하지 않으면서도 데이터로부터 모델이 효과적으로 학습할 수 있도록 해야 합니다.",
        "Question": "엔지니어가 PII를 보호하면서도 모델이 데이터로부터 효과적으로 학습할 수 있도록 하기 위해 어떤 데이터 준비 기술을 사용해야 합니까?",
        "Options": {
            "1": "데이터를 암호화하여 키 없이는 읽을 수 없도록 합니다.",
            "2": "민감도에 따라 데이터를 다양한 유형으로 분류합니다.",
            "3": "데이터셋에서 모든 식별 정보를 제거하여 데이터 익명화를 수행합니다.",
            "4": "민감한 정보를 허구지만 현실적인 데이터로 대체하는 데이터 마스킹을 사용합니다."
        },
        "Correct Answer": "민감한 정보를 허구지만 현실적인 데이터로 대체하는 데이터 마스킹을 사용합니다.",
        "Explanation": "데이터 마스킹은 민감한 정보를 허구지만 현실적인 데이터로 대체하여 PII를 보호하면서 모델이 효과적으로 훈련할 수 있도록 합니다. 이 기술은 데이터가 실제 민감한 정보의 노출 위험 없이 머신러닝 목적에 유용성을 유지하도록 보장합니다.",
        "Other Options": [
            "데이터 익명화는 식별 가능한 정보를 완전히 제거하므로 중요한 맥락적 특성이 손실될 수 있어 모델이 데이터로부터 효과적으로 학습하는 능력을 제한할 수 있습니다.",
            "데이터 분류는 민감도에 따라 데이터를 분류하지만 모델 훈련 중 PII 보호 문제를 직접적으로 해결하지 않으므로 데이터 준비를 위한 실용적인 솔루션을 제공하지 않습니다.",
            "데이터 암호화는 데이터를 보호하지만 복호화 없이는 모델 훈련에 사용할 수 없게 되어 ML 모델 구축 시 즉각적인 사용 가능성의 필요성과 모순됩니다."
        ]
    },
    {
        "Question Number": "51",
        "Situation": "한 머신러닝 팀이 AWS 서비스를 사용하여 모델 훈련 파이프라인을 배포하고 있습니다. 그들은 지속적인 통합 및 배포(CI/CD) 프로세스가 효율적이고 확장 가능하며 모델과 관련된 코드베이스의 여러 업데이트를 처리할 수 있도록 해야 합니다. 팀은 오케스트레이션 및 배포를 위해 AWS 서비스를 최적으로 활용하는 방법을 고려하고 있습니다.",
        "Question": "머신러닝 모델의 배포를 자동화하고 CI/CD 파이프라인을 효과적으로 관리하기 위해 어떤 AWS 서비스를 사용할 수 있습니까?",
        "Options": {
            "1": "AWS Lambda",
            "2": "AWS Step Functions",
            "3": "Amazon S3",
            "4": "AWS CodePipeline"
        },
        "Correct Answer": "AWS CodePipeline",
        "Explanation": "AWS CodePipeline은 릴리스 프로세스의 빌드, 테스트 및 배포 단계를 자동화하기 위해 특별히 설계되어 머신러닝 워크플로우의 CI/CD 관리를 위한 이상적인 선택입니다.",
        "Other Options": [
            "AWS Lambda는 이벤트에 응답하여 코드를 실행하는 서버리스 컴퓨팅 서비스입니다. CI/CD 프로세스의 일부가 될 수 있지만 배포 파이프라인을 위한 완전한 오케스트레이션 솔루션을 제공하지 않습니다.",
            "Amazon S3는 훈련 데이터셋 및 모델 아티팩트를 저장하는 데 적합한 객체 저장 서비스이지만 배포 오케스트레이션 기능을 제공하지 않습니다.",
            "AWS Step Functions는 분산 애플리케이션의 구성 요소를 조정하는 서비스이지만 CI/CD 프로세스에 주로 초점을 맞추지 않으며 배포 파이프라인의 특정 기능이 부족합니다."
        ]
    },
    {
        "Question Number": "52",
        "Situation": "ML 엔지니어가 내재된 편향이 있는 데이터셋을 사용하여 예측 모델을 구축하는 임무를 맡았습니다. 모델의 예측이 견고하고 편향되지 않도록 하기 위해 엔지니어는 효과적인 데이터 준비 기술을 구현해야 합니다.",
        "Question": "엔지니어가 데이터셋을 효과적으로 준비하기 위해 어떤 전략을 사용해야 합니까? (두 가지 선택)",
        "Options": {
            "1": "순서 편향을 피하기 위해 분할하기 전에 데이터셋을 섞습니다.",
            "2": "데이터 유출을 최소화하기 위해 모델 평가에 훈련 세트만 사용합니다.",
            "3": "데이터셋의 다양성과 복잡성을 증가시키기 위해 데이터 증강 기술을 구현합니다.",
            "4": "모델 훈련을 개선하기 위해 데이터셋에서 이상치를 제외합니다.",
            "5": "적절한 평가를 보장하기 위해 데이터셋을 훈련, 검증 및 테스트 세트로 분할합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "적절한 평가를 보장하기 위해 데이터셋을 훈련, 검증 및 테스트 세트로 분할합니다.",
            "순서 편향을 피하기 위해 분할하기 전에 데이터셋을 섞습니다."
        ],
        "Explanation": "데이터셋을 훈련, 검증 및 테스트 세트로 분할함으로써 엔지니어는 모델이 보지 못한 데이터에서 평가되도록 할 수 있으며, 이는 과적합을 줄이고 모델 성능에 대한 더 명확한 그림을 제공합니다. 또한, 분할하기 전에 데이터셋을 섞으면 데이터의 순서로 인해 발생할 수 있는 잠재적 편향을 최소화하여 보다 견고한 모델 훈련 프로세스를 촉진합니다.",
        "Other Options": [
            "데이터 증강은 데이터셋의 크기와 다양성을 증가시키는 데 유용하지만, 모델 성능을 정확하게 평가해야 하는 필요성을 직접적으로 해결하지 않으며, 이는 예측 편향을 줄이는 데 중요합니다.",
            "모델 평가에 훈련 세트만 사용하는 것은 잘못된 것으로, 이는 과적합을 초래하고 모델이 보지 못한 데이터에서 어떻게 수행될지를 진정으로 측정하지 못합니다.",
            "이상치를 제외하는 것이 모델 성능을 개선할 수 있지만, 이는 모델이 어려운 사례에서 학습하는 데 도움이 될 수 있는 귀중한 정보를 제거할 수 있어 편향된 예측으로 이어질 수 있습니다."
        ]
    },
    {
        "Question Number": "53",
        "Situation": "ML 엔지니어가 Amazon SageMaker에서 제공하는 다양한 알고리즘을 사용하여 고객 이탈 예측 모델을 개발하는 임무를 맡았습니다. 그러나 엔지니어는 예산 제약 내에서 각 알고리즘과 관련된 계산 비용을 고려해야 합니다.",
        "Question": "고객 이탈 예측과 같은 이진 분류 작업에 효과적이면서도 계산 비용을 최소화하기 위해 엔지니어가 선택해야 할 알고리즘은 무엇입니까?",
        "Options": {
            "1": "나무 수가 많은 랜덤 포레스트",
            "2": "방사 기저 함수 커널을 사용하는 서포트 벡터 머신(SVM)",
            "3": "L1 정규화가 적용된 로지스틱 회귀",
            "4": "여러 개의 숨겨진 층을 가진 심층 신경망"
        },
        "Correct Answer": "L1 정규화가 적용된 로지스틱 회귀",
        "Explanation": "L1 정규화가 적용된 로지스틱 회귀는 계산적으로 효율적이며 이진 분류 작업에 적합합니다. 일반적으로 SVM의 RBF나 심층 신경망과 같은 더 복잡한 모델에 비해 처리 능력과 메모리를 덜 요구하므로 비용 효율적인 선택입니다.",
        "Other Options": [
            "방사 기저 함수 커널을 사용하는 서포트 벡터 머신(SVM)은 비선형 문제에서 계산 집약적일 수 있으며, 이는 더 높은 비용으로 이어질 수 있습니다.",
            "나무 수가 많은 랜덤 포레스트는 상당한 계산 자원과 메모리를 요구하는 경향이 있어, 확장 시 비용이 증가할 수 있습니다.",
            "여러 개의 숨겨진 층을 가진 심층 신경망은 종종 광범위한 훈련 시간과 계산 능력을 요구하므로 자원 소비 측면에서 더 비싼 옵션 중 하나입니다."
        ]
    },
    {
        "Question Number": "54",
        "Situation": "데이터 과학자가 구독 기반 서비스의 고객 이탈을 예측하기 위한 머신 러닝 모델을 작업하고 있습니다. 그들은 다양한 하이퍼파라미터를 조정하여 모델 성능을 최적화하고자 합니다. 데이터 과학자는 Amazon SageMaker에 접근할 수 있으며, 이를 사용하여 하이퍼파라미터 조정 프로세스를 자동화하고자 합니다.",
        "Question": "데이터 과학자가 하이퍼파라미터 조정을 효율적으로 수행하기 위해 사용해야 할 SageMaker 기능은 무엇입니까?",
        "Options": {
            "1": "SageMaker 자동 모델 조정",
            "2": "SageMaker 배치 변환",
            "3": "SageMaker 데이터 랭글러",
            "4": "SageMaker 그라운드 트루스"
        },
        "Correct Answer": "SageMaker 자동 모델 조정",
        "Explanation": "SageMaker 자동 모델 조정(하이퍼파라미터 조정이라고도 함)은 사용자가 머신 러닝 모델에 대한 최적의 하이퍼파라미터를 자동으로 검색할 수 있도록 합니다. 이 기능은 하이퍼파라미터 공간을 효율적으로 탐색하여 모델 성능을 크게 향상시킬 수 있습니다.",
        "Other Options": [
            "SageMaker 배치 변환은 하이퍼파라미터 조정이 아닌 배치 추론에 사용됩니다. 이는 사용자가 훈련된 모델을 사용하여 대규모 데이터셋에 대한 예측을 받을 수 있도록 합니다.",
            "SageMaker 데이터 랭글러는 데이터 준비 및 특성 엔지니어링을 위한 도구이지만, 하이퍼파라미터 조정을 수행하지 않습니다.",
            "SageMaker 그라운드 트루스는 훈련 데이터셋을 구축하고 관리하기 위한 서비스이지만, 모델의 하이퍼파라미터를 조정하는 기능은 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "55",
        "Situation": "기계 학습 엔지니어가 훈련 작업을 위해 대량의 데이터를 Amazon S3에 수집하기 위한 ETL 파이프라인을 준비하고 있습니다. 데이터는 여러 형식을 포함하고 있으며, 향후 1년 동안 크게 증가할 것으로 예상됩니다. 엔지니어는 데이터 수집 프로세스가 확장 가능하고 다양한 데이터 부하를 효율적으로 처리할 수 있도록 해야 합니다.",
        "Question": "이 시나리오에서 효과적인 데이터 수집 및 저장 확장성을 보장하기 위해 엔지니어가 구현해야 할 전략은 무엇입니까?",
        "Options": {
            "1": "데이터 저장을 위해 Amazon RDS를 사용하여 높은 가용성을 보장합니다.",
            "2": "Amazon Kinesis Data Streams를 활용하여 데이터를 수집하고 S3에 저장합니다.",
            "3": "AWS Lambda를 사용하여 데이터를 실시간으로 처리하고 S3에 직접 기록합니다.",
            "4": "정해진 간격으로 데이터를 S3에 기록하는 배치 처리 시스템을 구현합니다."
        },
        "Correct Answer": "Amazon Kinesis Data Streams를 활용하여 데이터를 수집하고 S3에 저장합니다.",
        "Explanation": "Amazon Kinesis Data Streams를 활용하면 실시간 데이터 수집이 가능하며, 가변 데이터 부하를 효율적으로 처리할 수 있습니다. 이는 대량의 데이터를 수용하는 데 필요한 확장성을 제공하며, 추가 처리를 위해 데이터를 S3로 직접 스트리밍할 수 있습니다.",
        "Other Options": [
            "AWS Lambda를 사용한 실시간 처리는 좋은 전략이 될 수 있지만, 대량의 데이터가 포함된 고처리량 시나리오에는 이상적이지 않을 수 있습니다. Lambda는 실행 시간과 동시 실행에 제한이 있어 확장성을 저해할 수 있습니다.",
            "데이터 저장을 위해 Amazon RDS를 사용하는 것은 대규모 데이터 수집 프로세스에 적합하지 않습니다. RDS는 주로 관계형 데이터베이스 서비스로, 비구조적 또는 반구조적 데이터 형식이나 높은 데이터 수집 속도를 효율적으로 처리하지 못할 수 있습니다.",
            "배치 처리 시스템을 구현하는 것은 유용할 수 있지만, 데이터 가용성에 지연을 초래할 수 있습니다. 이 접근 방식은 Kinesis와 같은 실시간 솔루션에 비해 데이터 볼륨의 갑작스러운 급증을 처리하는 데 덜 유연합니다."
        ]
    },
    {
        "Question Number": "56",
        "Situation": "금융 서비스 회사가 스트리밍 거래 데이터를 수집하고 변환하는 실시간 사기 탐지 시스템을 구축하고 있습니다. 이 시스템은 기계 학습 모델을 준비하는 동안 낮은 지연 시간과 높은 가용성을 보장해야 합니다.",
        "Question": "기계 학습 목적으로 이 스트리밍 데이터를 변환하는 데 가장 효과적인 AWS 서비스 조합은 무엇입니까?",
        "Options": {
            "1": "Amazon S3와 AWS Glue",
            "2": "AWS Lambda와 Amazon Kinesis Data Firehose",
            "3": "Amazon EMR과 Apache Spark",
            "4": "Amazon RDS와 AWS Step Functions"
        },
        "Correct Answer": "AWS Lambda와 Amazon Kinesis Data Firehose",
        "Explanation": "AWS Lambda는 스트리밍 데이터를 실시간으로 처리하고 수신 데이터에 따라 작업을 트리거할 수 있으며, Amazon Kinesis Data Firehose는 스트리밍 데이터를 다양한 저장소로 효율적으로 변환하고 로드할 수 있어, 낮은 지연 시간 요구 사항을 가진 기계 학습 애플리케이션을 준비하는 데 이상적인 조합입니다.",
        "Other Options": [
            "Amazon S3와 AWS Glue는 실시간 스트리밍 데이터 처리보다는 데이터의 배치 처리 및 변환에 더 적합합니다.",
            "Amazon EMR과 Apache Spark는 대량의 데이터 세트를 처리할 수 있지만, AWS Lambda와 Kinesis의 서버리스 아키텍처에 비해 더 높은 지연 시간을 초래할 수 있습니다.",
            "Amazon RDS와 AWS Step Functions는 실시간 스트리밍 데이터 처리를 위해 설계되지 않았으며, 트랜잭션 데이터베이스 작업 및 워크플로 오케스트레이션에 더 적합합니다."
        ]
    },
    {
        "Question Number": "57",
        "Situation": "기계 학습 팀이 새로운 모델 버전을 프로덕션에 배포할 준비를 하고 있습니다. 그들은 배포 프로세스가 견고하여 문제가 발생할 경우 빠른 롤백이 가능하도록 하기를 원합니다. 그들은 ML 워크플로의 배포 및 오케스트레이션을 위한 다양한 모범 사례를 고려하고 있습니다.",
        "Question": "기계 학습 모델의 신뢰할 수 있는 배포와 효과적인 롤백 메커니즘을 보장하기 위해 팀이 구현해야 할 전략은 무엇입니까?",
        "Options": {
            "1": "새 모델 버전을 점진적으로 배포하면서 성능을 모니터링하기 위해 카나리 배포 전략을 사용합니다.",
            "2": "구형 및 신형 모델 버전 간에 원활하게 전환하기 위해 블루-그린 배포를 구현합니다.",
            "3": "시스템의 모든 구성 요소를 함께 배포하는 단일 배포 접근 방식을 채택합니다.",
            "4": "롤백 계획 없이 새로운 모델 버전을 직접 배포하여 다운타임 없이 보장합니다."
        },
        "Correct Answer": "새 모델 버전을 점진적으로 배포하면서 성능을 모니터링하기 위해 카나리 배포 전략을 사용합니다.",
        "Explanation": "카나리 배포 전략은 새로운 모델 버전을 점진적으로 출시할 수 있도록 하여 팀이 성능과 영향을 모니터링한 후 완전히 배포할 수 있게 합니다. 이 접근 방식은 위험을 최소화하고 문제가 발생할 경우 빠른 롤백 기회를 제공합니다.",
        "Other Options": [
            "블루-그린 배포를 구현하는 것은 다운타임을 최소화하는 좋은 전략이지만, ML 모델을 다룰 때 중요한 모니터링 및 점진적 롤아웃을 제공하지 않을 수 있습니다.",
            "롤백 계획 없이 새로운 모델 버전을 직접 배포하는 것은 위험하며, 새로운 모델이 실패하거나 성능이 저조할 경우 수정 조치를 취할 수 없습니다.",
            "단일 배포 접근 방식은 문제가 발생할 경우 상당한 다운타임과 복잡성을 초래할 수 있어, 유연성과 확장성이 필요한 기계 학습 워크플로에는 적합하지 않습니다."
        ]
    },
    {
        "Question Number": "58",
        "Situation": "ML 엔지니어가 AWS 서비스를 사용하여 머신 러닝 모델을 배포할 준비를 하고 있습니다. 엔지니어는 Amazon SageMaker의 미리 구축된 컨테이너를 사용할지, 아니면 배포를 위해 사용자 정의 컨테이너를 만들지 고민하고 있습니다. 모델은 미리 구축된 컨테이너가 제공되는 인기 있는 딥 러닝 프레임워크를 기반으로 하고 있습니다. 그러나 엔지니어는 모델이 시간이 지남에 따라 발전함에 따라 컨테이너를 쉽게 업데이트할 수 있도록 하고 싶어합니다.",
        "Question": "ML 엔지니어가 사용의 용이성과 향후 업데이트의 유연성을 균형 있게 유지하기 위해 어떤 접근 방식을 취해야 합니까?",
        "Options": {
            "1": "모델의 다양한 측면을 위해 여러 개의 미리 구축된 컨테이너를 사용하여 모든 기능을 커버합니다.",
            "2": "미리 구축된 컨테이너를 기반으로 사용자 정의 컨테이너를 생성하여 일부 내장 기능을 유지하면서 수정할 수 있도록 합니다.",
            "3": "시간과 노력을 절약하기 위해 초기 배포를 위해 Amazon SageMaker의 미리 구축된 컨테이너를 사용합니다.",
            "4": "환경에 대한 완전한 제어를 보장하기 위해 완전히 새로운 사용자 정의 컨테이너를 처음부터 개발합니다."
        },
        "Correct Answer": "미리 구축된 컨테이너를 기반으로 사용자 정의 컨테이너를 생성하여 일부 내장 기능을 유지하면서 수정할 수 있도록 합니다.",
        "Explanation": "미리 구축된 컨테이너를 기반으로 사용자 정의 컨테이너를 생성하면 ML 엔지니어는 기존의 최적화 및 기능을 활용하면서 모델이 발전함에 따라 필요한 업데이트 및 수정을 할 수 있는 유연성을 유지할 수 있습니다. 이 접근 방식은 배포의 용이성과 향후 적응성 간의 균형을 이룹니다.",
        "Other Options": [
            "미리 구축된 컨테이너를 사용하면 초기에는 시간을 절약할 수 있지만, 향후 업데이트나 수정의 가능성을 제한하여 유연성을 감소시킵니다.",
            "여러 개의 미리 구축된 컨테이너를 사용하는 것은 배포 프로세스를 복잡하게 만들 수 있으며, 단일 사용자 정의 솔루션에 비해 상당한 이점을 제공하지 않으면서 불필요한 복잡성을 도입할 수 있습니다.",
            "완전히 새로운 사용자 정의 컨테이너를 처음부터 개발하는 것은 시간이 많이 소요될 수 있으며, 이미 미리 구축된 컨테이너에 존재하는 최적화를 놓칠 수 있어 배포 효율성에 부정적인 영향을 미칠 수 있습니다."
        ]
    },
    {
        "Question Number": "59",
        "Situation": "ML 엔지니어가 배포 후 추천 시스템의 성능을 개선하는 임무를 맡고 있습니다. 새로운 모델 버전의 효과를 현재 모델과 비교하기 위해 엔지니어는 A/B 테스트를 구현하고자 합니다. 목표는 새로운 모델이 사용자 경험에 부정적인 영향을 미치지 않으면서 성능을 정확하게 측정하는 것입니다.",
        "Question": "ML 엔지니어가 추천 시스템을 위한 A/B 테스트를 설정하기 위해 어떤 접근 방식을 취해야 합니까?",
        "Options": {
            "1": "사용자가 추천을 위해 어떤 모델을 사용할지 선택할 수 있도록 애플리케이션에 기능을 구현합니다.",
            "2": "Amazon SageMaker Batch Transform을 사용하여 사용자 요청을 처리하고 결과를 수동으로 비교합니다.",
            "3": "기존 엔드포인트에 새로운 모델을 통합하고 사용자 ID에 따라 모델 간 전환합니다.",
            "4": "새로운 모델을 별도의 엔드포인트로 배포하고 사용자 요청의 50%를 각 모델로 무작위로 라우팅합니다."
        },
        "Correct Answer": "새로운 모델을 별도의 엔드포인트로 배포하고 사용자 요청의 50%를 각 모델로 무작위로 라우팅합니다.",
        "Explanation": "새로운 모델을 별도의 엔드포인트로 배포하면 두 모델 간의 사용자 상호작용 및 성능 지표를 직접 비교할 수 있습니다. 요청을 무작위로 라우팅하면 각 모델이 효과성을 입증할 수 있는 공정하고 동등한 기회를 제공하여 A/B 테스트의 신뢰할 수 있는 결과를 제공합니다.",
        "Other Options": [
            "새로운 모델을 기존 엔드포인트에 통합하면 성능 지표의 명확한 분리를 허용하지 않기 때문에 비교가 복잡해질 수 있습니다. 이 설정은 어떤 모델이 어떤 결과를 제공하는지에 대한 혼란을 초래할 수 있습니다.",
            "Amazon SageMaker Batch Transform을 사용하는 것은 실시간 A/B 테스트에 적합하지 않으며, 데이터 배치 처리로 인해 사용자 상호작용에 대한 즉각적인 피드백을 제공하지 않습니다. 이 옵션은 성능 평가를 지연시키며 활성 추천 시스템의 요구와 일치하지 않습니다.",
            "사용자 선택 기능을 구현하면 사용자가 전체 모델 성능을 반영하지 않는 선호도를 가질 수 있어 편향을 초래할 수 있습니다. 이 접근 방식은 결과 분석을 복잡하게 만들고 성능 지표를 왜곡할 수 있습니다."
        ]
    },
    {
        "Question Number": "60",
        "Situation": "한 회사가 Amazon SageMaker를 사용하여 머신 러닝 모델을 배포했으며, 시간이 지남에 따라 모델이 성능 기준을 준수하도록 보장하고자 합니다. 그들은 특히 모델의 성능 지표를 모니터링하고 운영 중 발생할 수 있는 잠재적인 문제를 이해하는 데 관심이 있습니다.",
        "Question": "회사가 배포된 머신 러닝 모델의 성능을 지속적으로 모니터링하고 기준을 충족하도록 보장하기 위한 최선의 접근 방식은 무엇입니까?",
        "Options": {
            "1": "Amazon SageMaker Model Monitor를 구현하여 성능 지표를 추적하고 기준선에서의 편차를 감지합니다.",
            "2": "모든 추론 요청을 기록하고 성능 문제를 수동으로 분석하는 사용자 정의 로깅 솔루션을 배포합니다.",
            "3": "모델의 엔드포인트 지연 시간 및 호출 수에 대한 경고를 설정하기 위해 Amazon CloudWatch를 사용하되 정확도는 모니터링하지 않습니다.",
            "4": "Amazon SageMaker Debugger를 활용하여 훈련 작업을 모니터링하고 모델이 배포된 후 메트릭을 캡처합니다."
        },
        "Correct Answer": "Amazon SageMaker Model Monitor를 구현하여 성능 지표를 추적하고 기준선에서의 편차를 감지합니다.",
        "Explanation": "Amazon SageMaker Model Monitor는 생산 환경에서 머신 러닝 모델을 자동으로 모니터링하도록 설계되어 있어 사용자가 성능 지표를 추적하고 데이터 및 개념 변화를 감지하여 시간이 지남에 따라 성능 기준을 준수하도록 보장합니다.",
        "Other Options": [
            "Amazon CloudWatch를 사용하여 경고를 설정하는 것은 주로 지연 시간 및 호출 수와 같은 운영 지표에 초점을 맞추며, 모델의 정확도나 성능 지표에 대한 통찰력을 제공하지 않아 모델 효과성을 평가하는 데 중요합니다.",
            "사용자 정의 로깅 솔루션은 추론 요청에 대한 통찰력을 제공할 수 있지만, SageMaker Model Monitor의 자동화된 기능이 부족하여 지속적인 성능 모니터링 및 분석에 비효율적입니다.",
            "Amazon SageMaker Debugger는 배포된 모델이 아닌 훈련 작업을 모니터링하기 위한 것이므로 생산 환경에서 성능 지표를 평가하는 데 필요한 도구를 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "61",
        "Situation": "소매 회사가 예측 판매 모델의 정확성 문제를 겪고 있습니다. ML 팀은 다가오는 휴가 시즌 전에 모델의 성능을 개선하는 임무를 맡았습니다.",
        "Question": "ML 엔지니어가 모델의 예측 정확성을 향상시키기 위해 우선적으로 어떤 방법을 선택해야 합니까?",
        "Options": {
            "1": "신경망에 더 많은 레이어를 추가하여 모델의 복잡성을 증가시킵니다.",
            "2": "훈련 프로세스를 가속화하기 위해 훈련 데이터셋의 크기를 줄입니다.",
            "3": "데이터에서 더 많은 고품질 특성을 수집하여 특성 표현을 개선합니다.",
            "4": "모델의 활성화 함수를 덜 일반적인 것으로 변경합니다."
        },
        "Correct Answer": "데이터에서 더 많은 고품질 특성을 수집하여 특성 표현을 개선합니다.",
        "Explanation": "더 많은 고품질 특성을 수집하여 특성 표현을 개선하면 모델 성능을 크게 향상시킬 수 있습니다. 이는 모델이 데이터 내의 패턴에 대한 더 나은 통찰력을 제공받기 때문입니다.",
        "Other Options": [
            "모델의 복잡성을 증가시키면 데이터가 충분하지 않을 경우 과적합으로 이어질 수 있으며, 이는 보지 못한 데이터에 대한 일반화를 감소시킬 수 있습니다.",
            "훈련 데이터셋의 크기를 줄이는 것은 모델이 학습할 수 있는 정보의 양을 제한하므로 비효율적이며, 궁극적으로 정확성을 저하시킵니다.",
            "정당한 이유 없이 덜 일반적인 활성화 함수로 변경하면 모델의 학습 과정에 부정적인 영향을 미칠 수 있으며, 더 익숙한 함수가 더 나은 결과를 내는 경우가 많습니다."
        ]
    },
    {
        "Question Number": "62",
        "Situation": "한 머신 러닝 엔지니어가 AWS에서 여러 모델을 운영하는 비용을 최적화하는 임무를 맡았습니다. 그들은 정기적으로 지출을 분석하고 다양한 AWS 서비스에서 잠재적인 절감을 식별해야 합니다. 엔지니어는 AWS에서 사용할 수 있는 여러 비용 관리 도구에 익숙합니다. 그들은 비용 최적화 및 모니터링을 위해 올바른 도구를 활용하고 있는지 확인하고 싶어합니다.",
        "Question": "엔지니어가 역사적 지출 추세를 시각화하고 미래 비용을 예측하기 위해 어떤 AWS 도구를 사용해야 합니까?",
        "Options": {
            "1": "AWS Cost and Usage Report",
            "2": "AWS Trusted Advisor",
            "3": "AWS Budgets",
            "4": "AWS Cost Explorer"
        },
        "Correct Answer": "AWS Cost Explorer",
        "Explanation": "AWS Cost Explorer는 사용자가 역사적 지출을 시각화하고 미래 비용을 예측하는 데 특별히 설계되어 있어 이 시나리오에 가장 적합한 선택입니다.",
        "Other Options": [
            "AWS Budgets는 미리 정의된 예산에 대한 비용을 추적할 수 있지만, 역사적 데이터와 예측의 시각화를 제공하지 않습니다.",
            "AWS Cost and Usage Report는 상세한 청구 정보를 제공하지만 시각화에 중점을 두지 않으며, 심층 분석에 더 적합합니다.",
            "AWS Trusted Advisor는 서비스 사용 및 비용 최적화에 대한 모범 사례를 추천하지만, 비용 시각화 및 예측에 중점을 두지 않습니다."
        ]
    },
    {
        "Question Number": "63",
        "Situation": "한 데이터 과학자가 분류 작업의 성능을 개선하기 위해 신경망 모델을 조정하고 있습니다. 모델의 아키텍처에는 서로 다른 수의 뉴런을 가진 여러 레이어가 포함되어 있습니다. 데이터 과학자는 레이어와 뉴런의 수가 모델의 정확성과 훈련 시간에 어떤 영향을 미칠 수 있는지 고려하고 있습니다.",
        "Question": "신경망 모델에서 레이어 수를 증가시키는 잠재적인 영향은 무엇입니까?",
        "Options": {
            "1": "다른 요인에 관계없이 항상 모델의 정확성을 향상시킵니다.",
            "2": "모델을 더 쉽게 해석하고 이해할 수 있게 만듭니다.",
            "3": "모델의 계산 복잡성과 훈련 시간을 줄입니다.",
            "4": "더 나은 특성 추출로 이어질 수 있지만 과적합을 초래할 수도 있습니다."
        },
        "Correct Answer": "더 나은 특성 추출로 이어질 수 있지만 과적합을 초래할 수도 있습니다.",
        "Explanation": "신경망의 레이어 수를 증가시키면 모델이 데이터에서 더 복잡한 특성을 학습할 수 있어 성능이 향상될 수 있습니다. 그러나 더 깊은 네트워크는 훈련 데이터가 제한적일 경우 과적합의 위험을 증가시킵니다. 모델이 훈련 데이터를 암기하기 시작할 수 있기 때문입니다.",
        "Other Options": [
            "레이어를 추가하면 정확성이 향상될 수 있지만, 데이터 품질과 양과 같은 다른 요인에 따라 달라지므로 개선이 보장되지는 않습니다.",
            "레이어를 증가시키면 일반적으로 계산 복잡성과 훈련 시간이 증가하며, 더 많은 매개변수를 최적화해야 하기 때문입니다.",
            "더 많은 레이어는 모델의 해석을 복잡하게 만들어 이해하기 어렵게 만들며, 오히려 해석하기 쉽게 만들지 않습니다."
        ]
    },
    {
        "Question Number": "64",
        "Situation": "ML 엔지니어가 AWS에서 실행되는 여러 기계 학습 작업의 비용 효율성을 최적화하는 임무를 맡았습니다. 엔지니어는 지출 패턴을 시각화하고 시간에 따른 비용 절감 기회를 식별할 수 있는 솔루션이 필요합니다.",
        "Question": "어떤 도구가 엔지니어가 AWS에서 기계 학습 작업과 관련된 비용을 이해하고 관리하는 데 가장 도움이 될까요?",
        "Options": {
            "1": "AWS Cost Explorer를 구현하여 지출 추세를 분석하고 미래 비용을 예측합니다.",
            "2": "AWS Trusted Advisor를 사용하여 모든 AWS 서비스에 대한 비용 최적화 권장 사항을 받습니다.",
            "3": "AWS Budgets를 활용하여 프로젝트에 대한 맞춤형 지출 한도를 설정합니다.",
            "4": "AWS Billing and Cost Management를 활용하여 리소스 사용에 대한 상세한 청구서를 생성합니다."
        },
        "Correct Answer": "AWS Cost Explorer를 구현하여 지출 추세를 분석하고 미래 비용을 예측합니다.",
        "Explanation": "AWS Cost Explorer는 사용자가 AWS 서비스에 대한 지출을 시각화하고 분석하는 데 도움을 주기 위해 특별히 설계되었습니다. 시간에 따른 비용 추세에 대한 통찰력을 제공하고 미래 비용을 예측하는 데 도움을 주어 엔지니어의 요구에 가장 적합한 도구입니다.",
        "Other Options": [
            "AWS Budgets는 사용자가 지출 한도를 설정할 수 있지만 시간에 따른 지출 추세에 대한 상세한 분석을 제공하지 않습니다.",
            "AWS Trusted Advisor는 비용 최적화에 대한 권장 사항을 제공하지만 비용 분석이나 추세 시각화에만 집중하지 않습니다.",
            "AWS Billing and Cost Management는 주로 청구 프로세스를 관리하는 데 사용되며, 비용의 상세한 분석이나 예측을 위한 것이 아닙니다."
        ]
    },
    {
        "Question Number": "65",
        "Situation": "데이터 과학자가 기계 학습 모델의 성능을 최적화하고 있으며 모델의 크기에 영향을 줄 수 있는 다양한 요소를 고려하고 있습니다. 그들은 모델이 정확성을 유지하면서 효율성을 유지하기를 원합니다.",
        "Question": "개발 중 기계 학습 모델의 크기에 직접적인 영향을 미칠 가능성이 가장 높은 요소는 무엇인가요?",
        "Options": {
            "1": "훈련 데이터셋에서 사용되는 특성의 수.",
            "2": "모델의 훈련 기간.",
            "3": "모델에 선택된 알고리즘의 유형.",
            "4": "사용 가능한 훈련 데이터의 양."
        },
        "Correct Answer": "훈련 데이터셋에서 사용되는 특성의 수.",
        "Explanation": "특성의 수는 모델 크기에 직접적인 영향을 미치며, 각 특성이 모델에 복잡성과 차원을 추가하기 때문입니다. 일반적으로 더 많은 특성은 더 많은 매개변수를 요구하여 모델 크기를 증가시킵니다.",
        "Other Options": [
            "선택된 알고리즘의 유형은 성능과 훈련 시간에 영향을 줄 수 있지만, 특성의 수만큼 모델 크기를 결정짓지는 않습니다.",
            "훈련 기간은 모델이 데이터에서 학습하는 시간을 영향을 미치지만, 모델의 크기에 직접적인 영향을 미치지 않습니다. 모델은 크기를 변경하지 않고도 오랜 시간 동안 훈련될 수 있습니다.",
            "사용 가능한 훈련 데이터의 양은 모델의 일반화 능력과 성능에 영향을 미칠 수 있지만, 모델의 크기와는 직접적인 상관관계가 없습니다. 더 많은 데이터는 동일한 모델에 의해 처리될 수 있으며, 크기를 증가시키지 않습니다."
        ]
    }
]