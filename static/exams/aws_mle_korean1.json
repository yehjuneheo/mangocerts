[
    {
        "Question Number": "1",
        "Situation": "한 금융 서비스 회사가 사기 거래를 탐지하기 위해 머신 러닝 솔루션을 구현하고 있습니다. 그들은 성능, 이상 징후 및 보안 위협에 대해 인프라가 지속적으로 모니터링되도록 하기를 원합니다. 이를 달성하기 위해 AWS 서비스를 사용하는 것을 고려하고 있습니다.",
        "Question": "어떤 AWS 서비스가 회사가 머신 러닝 인프라를 효과적으로 모니터링하는 데 도움이 될 수 있습니까? (두 가지 선택)",
        "Options": {
            "1": "역사적 모니터링 데이터를 저장하기 위한 Amazon S3.",
            "2": "일정에 따라 서버리스 기능을 실행하기 위한 AWS Lambda.",
            "3": "애플리케이션 배포 자동화를 위한 AWS CodeDeploy.",
            "4": "이벤트 기반 모니터링 및 알림을 위한 Amazon EventBridge.",
            "5": "API 호출 및 사용자 활동 모니터링을 위한 AWS CloudTrail."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "API 호출 및 사용자 활동 모니터링을 위한 AWS CloudTrail.",
            "이벤트 기반 모니터링 및 알림을 위한 Amazon EventBridge."
        ],
        "Explanation": "AWS CloudTrail은 사용자, 역할 또는 AWS 서비스에 의해 수행된 작업의 기록을 제공하여 회사가 API 사용을 추적하고 무단 활동을 탐지하는 데 도움을 줍니다. Amazon EventBridge는 이벤트 기반 아키텍처를 가능하게 하여 회사가 인프라의 변화에 반응하고 특정 이벤트에 따라 알림을 보낼 수 있도록 하며, 이는 실시간 모니터링에 매우 중요합니다.",
        "Other Options": [
            "AWS Lambda는 주로 이벤트에 응답하여 코드를 실행하는 데 사용되지만, 전용 모니터링 도구가 아니며 인프라 성능이나 보안에 대한 통찰력을 제공하지 않습니다.",
            "Amazon S3는 저장 서비스이며 실시간 모니터링 기능을 제공하지 않습니다; 로그를 저장할 수 있지만 인프라를 적극적으로 모니터링하지는 않습니다.",
            "AWS CodeDeploy는 배포 자동화에 중점을 두며 인프라의 모니터링이나 보안 유지에 기여하지 않습니다."
        ]
    },
    {
        "Question Number": "2",
        "Situation": "한 머신 러닝 엔지니어가 다양한 예측 작업을 처리하기 위해 여러 모델을 확장 가능한 방식으로 배포하는 임무를 맡고 있습니다. 팀은 다중 모델 또는 다중 컨테이너 배포 전략을 사용할지 고려하고 있습니다.",
        "Question": "다음 시나리오 중 머신 러닝 모델에 대해 다중 컨테이너 배포보다 다중 모델 배포 전략을 사용하는 것을 가장 잘 정당화하는 것은 무엇입니까?",
        "Options": {
            "1": "다중 컨테이너 배포는 각 모델에 대해 더 나은 격리 및 보안을 제공합니다.",
            "2": "모델들이 유사한 리소스 요구 사항을 공유하며 동시에 메모리에 로드될 수 있습니다.",
            "3": "모델들이 근본적으로 다르며 서로 다른 기본 프레임워크가 필요합니다.",
            "4": "각 모델은 공유할 수 없는 독특한 런타임 환경이 필요합니다."
        },
        "Correct Answer": "모델들이 유사한 리소스 요구 사항을 공유하며 동시에 메모리에 로드될 수 있습니다.",
        "Explanation": "다중 모델 배포는 여러 모델이 유사한 리소스 요구 사항으로 인해 동시에 메모리에 로드될 수 있을 때 유리하며, 이는 효율적인 리소스 활용을 가능하게 하고 각 모델을 별도의 컨테이너에서 실행하는 것에 비해 오버헤드를 줄입니다.",
        "Other Options": [
            "이 옵션은 잘못된 것입니다. 서로 다른 런타임 환경이 있다는 것은 다중 컨테이너 배포의 필요성을 시사하며, 이는 환경을 공유할 수 없는 모델에 대해 더 나은 격리를 제공합니다.",
            "이 옵션은 잘못된 것입니다. 다중 컨테이너 배포가 항상 격리 및 보안 측면에서 우수하다고 제안하지만, 모델들이 리소스를 공유할 때 다중 모델 배포가 더 효율적일 수 있습니다.",
            "이 옵션은 잘못된 것입니다. 근본적으로 다르며 서로 다른 프레임워크가 필요한 모델은 다중 모델 배포가 아닌 다중 컨테이너 배포에 더 적합합니다."
        ]
    },
    {
        "Question Number": "3",
        "Situation": "한 전자 상거래 플랫폼이 고객 구매 행동을 예측하기 위해 머신 러닝 모델을 구현하고자 합니다. 그들은 성능과 비용의 균형을 맞추면서 실시간 사용자 상호작용에 기반한 즉각적인 예측을 가능하게 하는 배포 전략을 선택해야 합니다.",
        "Question": "실시간 사용자 상호작용에 기반한 즉각적인 예측을 제공하기에 가장 적합한 배포 전략은 무엇입니까?",
        "Options": {
            "1": "실시간 추론을 위해 Amazon SageMaker 엔드포인트에 모델을 구현합니다.",
            "2": "일정된 작업을 수행하기 위해 Amazon EMR을 활용하여 매일 예측을 수행합니다.",
            "3": "사용자 활동 로그를 기반으로 모델 예측을 트리거하기 위해 Lambda 함수를 설정합니다.",
            "4": "역사적 데이터를 주기적으로 분석하기 위해 배치 처리 접근 방식을 사용하여 모델을 배포합니다."
        },
        "Correct Answer": "실시간 추론을 위해 Amazon SageMaker 엔드포인트에 모델을 구현합니다.",
        "Explanation": "Amazon SageMaker 엔드포인트를 사용하여 모델을 배포하면 실시간 추론이 가능해지며, 이는 사용자 상호작용에 기반한 즉각적인 예측에 매우 중요합니다. 이 접근 방식은 모델이 사용자 행동에 동적으로 그리고 효율적으로 반응할 수 있도록 보장합니다.",
        "Other Options": [
            "배치 처리 접근 방식을 사용하면 예측이 주기적으로만 이루어지므로 실시간 상호작용에 기반한 즉각적인 예측 요구를 충족하지 못합니다.",
            "Amazon EMR을 일정된 작업에 활용하면 예측을 얻는 데 지연이 발생하며, 이는 역사적 데이터에 의존하므로 사용자 상호작용 중 즉각적인 통찰력을 제공하지 않습니다.",
            "활동 로그를 기반으로 예측을 트리거하기 위해 Lambda 함수를 설정하면 지연이 발생합니다. 함수가 사용자 쿼리에 즉시 반응하지 않으며, 실시간 추론보다는 비동기 처리에 더 적합합니다."
        ]
    },
    {
        "Question Number": "4",
        "Situation": "금융 서비스 회사는 실시간으로 사기 거래를 감지하기 위해 기계 학습 모델을 구축해야 합니다. 이 회사는 Amazon S3에 저장된 대규모의 과거 거래 기록 데이터셋을 보유하고 있습니다. 데이터에는 거래 금액, 상인 세부정보 및 사용자 행동 지표와 같은 다양한 특성이 포함되어 있습니다. 모델 훈련 중 최적의 성능을 보장하기 위해 회사는 전송 시간과 비용을 최소화하면서 이 데이터를 효율적으로 추출해야 합니다.",
        "Question": "회사가 기계 학습 모델 훈련을 위해 Amazon S3에서 데이터를 가장 낮은 지연 시간과 비용으로 추출하기 위해 어떤 AWS 서비스 옵션을 사용해야 합니까?",
        "Options": {
            "1": "Amazon Athena를 활용하여 S3에서 직접 데이터를 쿼리합니다.",
            "2": "Amazon S3 Transfer Acceleration을 사용하여 데이터 검색 속도를 높입니다.",
            "3": "Amazon S3 Select를 구현하여 데이터의 일부만 검색합니다.",
            "4": "Amazon Data Pipeline을 활용하여 데이터를 Amazon RDS 인스턴스로 이동합니다."
        },
        "Correct Answer": "Amazon S3 Transfer Acceleration을 사용하여 데이터 검색 속도를 높입니다.",
        "Explanation": "Amazon S3 Transfer Acceleration을 사용하면 회사는 최적화된 네트워크 경로를 통해 S3로 데이터를 전송할 수 있어 지연 시간과 전송 비용을 크게 줄일 수 있습니다. 이는 실시간 사기 감지 애플리케이션에 매우 중요합니다.",
        "Other Options": [
            "Amazon S3 Select를 구현하는 것은 대형 객체에서 특정 데이터 필드를 검색하는 데 유용하지만, Transfer Acceleration만큼 전체 검색 속도를 최적화하지는 못합니다, 특히 대규모 데이터셋의 경우.",
            "Amazon Athena를 활용하면 데이터를 직접 쿼리할 수 있지만, 쿼리 실행 시간과 비용 측면에서 추가적인 오버헤드를 초래할 수 있어 실시간 데이터 추출에 최적이 아닙니다.",
            "Amazon Data Pipeline을 활용하여 데이터를 Amazon RDS 인스턴스로 이동하는 것은 과정에 불필요한 복잡성과 지연을 추가하여 실시간 기계 학습 모델 훈련에 적합하지 않습니다."
        ]
    },
    {
        "Question Number": "5",
        "Situation": "기계 학습 엔지니어는 Amazon SageMaker 엔드포인트에 대한 모든 API 호출이 준수 및 보안 목적으로 기록되고 모니터링되도록 해야 합니다. 이를 달성하기 위해 엔지니어는 필요한 이벤트를 캡처하는 AWS CloudTrail 트레일을 생성해야 합니다. 이 목적을 위해 CloudTrail 트레일을 구성하는 가장 좋은 방법은 무엇입니까?",
        "Question": "모든 SageMaker API 호출이 CloudTrail 트레일에 기록되도록 하려면 어떤 설정을 사용해야 합니까?",
        "Options": {
            "1": "특정 리전의 로깅을 활성화하고 트레일을 데이터 이벤트만 기록하도록 설정합니다.",
            "2": "모든 리전의 로깅을 활성화하고 트레일을 관리 이벤트만 기록하도록 설정합니다.",
            "3": "특정 리전의 로깅을 활성화하고 트레일을 관리 이벤트만 기록하도록 설정합니다.",
            "4": "모든 리전의 로깅을 활성화하고 트레일을 관리 이벤트와 데이터 이벤트 모두 기록하도록 설정합니다."
        },
        "Correct Answer": "모든 리전의 로깅을 활성화하고 트레일을 관리 이벤트와 데이터 이벤트 모두 기록하도록 설정합니다.",
        "Explanation": "모든 SageMaker API 호출을 캡처하려면 모든 리전의 로깅을 활성화하고 CloudTrail 트레일을 관리 이벤트와 데이터 이벤트 모두 기록하도록 구성하는 것이 필수적입니다. 이를 통해 SageMaker 서비스와의 API 상호작용을 포괄적으로 모니터링할 수 있으며, 운영 및 데이터 접근 활동을 모두 포함합니다.",
        "Other Options": [
            "이 옵션은 SageMaker API 호출과 관련된 데이터 이벤트를 캡처하지 않으므로 트레일의 효과성을 제한합니다.",
            "특정 리전으로 로깅을 제한하면 SageMaker 리소스가 사용되는 다른 리전의 로그가 누락될 수 있어 가시성이 감소합니다.",
            "이 옵션 또한 데이터 이벤트를 캡처하지 못하므로 API 호출의 완전한 감사에 필수적인 요소로, 특히 준수 및 보안 모니터링에 중요합니다."
        ]
    },
    {
        "Question Number": "6",
        "Situation": "데이터 과학 팀은 고객 이탈 예측을 위한 새로운 기계 학습 모델을 개발하고 있습니다. 그들은 향후 개선 사항을 효과적으로 평가하기 위해 성능 기준선을 설정해야 합니다. 이 기준선을 만드는 가장 좋은 방법은 무엇입니까?",
        "Question": "기계 학습 모델의 성능 기준선을 설정하는 데 가장 효과적인 방법은 무엇입니까?",
        "Options": {
            "1": "k-겹 교차 검증을 수행하고 성능 지표를 평균합니다.",
            "2": "단일 훈련-테스트 분할을 사용하고 모델을 테스트 세트에서만 평가합니다.",
            "3": "간단한 모델을 사용하여 더 복잡한 모델과 비교합니다.",
            "4": "전체 데이터셋에서 모델을 훈련하고 정확도를 보고합니다."
        },
        "Correct Answer": "k-겹 교차 검증을 수행하고 성능 지표를 평균합니다.",
        "Explanation": "k-겹 교차 검증은 데이터를 여러 하위 집합으로 분할하여 모델 성능을 평가하는 강력한 방법을 제공합니다. 이러한 겹을 통해 성능 지표를 평균화함으로써 팀은 기준선이 단일 훈련-테스트 분할의 특이성에 영향을 받지 않도록 하여 모델의 능력을 보다 신뢰성 있게 평가할 수 있습니다.",
        "Other Options": [
            "전체 데이터셋에서 훈련하고 정확도를 보고하는 것은 과적합을 고려하지 않으며, 보지 못한 데이터에서 모델의 실제 성능을 나타내지 않을 수 있습니다.",
            "간단한 모델을 사용하여 벤치마킹하는 것은 유용하지만, 다양한 데이터 분할에서 성능 변동성을 포괄적으로 이해하는 데는 도움이 되지 않습니다.",
            "단일 훈련-테스트 분할은 데이터 선택의 무작위성으로 인해 모델 성능을 정확하게 반영하지 못할 수 있어 기준선으로서 신뢰성이 떨어집니다."
        ]
    },
    {
        "Question Number": "7",
        "Situation": "데이터 과학 팀이 Amazon SageMaker를 사용하여 머신러닝 모델을 배포하고 있으며, 성능과 비용 효율성을 위해 사용하는 리소스의 최적 크기를 보장하고자 합니다. 그들은 특히 추론 엔드포인트에 사용할 적절한 인스턴스 패밀리와 크기에 대한 추천에 관심이 있습니다.",
        "Question": "SageMaker에서 머신러닝 모델 배포를 위한 인스턴스 패밀리와 크기를 적절하게 조정하는 추천을 제공할 수 있는 AWS 서비스는 무엇인가요?",
        "Options": {
            "1": "AWS Elastic Beanstalk",
            "2": "Amazon SageMaker Inference Recommender",
            "3": "AWS Lambda",
            "4": "Amazon EC2 Auto Scaling"
        },
        "Correct Answer": "Amazon SageMaker Inference Recommender",
        "Explanation": "Amazon SageMaker Inference Recommender는 추론 엔드포인트의 작업 부하를 분석하고 가장 적합한 인스턴스 패밀리와 크기에 대한 추천을 제공하도록 특별히 설계되어 있어 성능과 비용을 최적화하는 데 도움을 줍니다.",
        "Other Options": [
            "AWS Lambda는 주로 서버리스 컴퓨팅에 사용되며 SageMaker 배포를 위한 인스턴스 크기 조정에 대한 추천을 제공하도록 설계되지 않았습니다.",
            "Amazon EC2 Auto Scaling은 로드에 따라 EC2 인스턴스 수를 자동으로 조정하는 데 중점을 두고 있으며, 인스턴스 유형이나 크기에 대한 특정 추천을 제공하지 않습니다.",
            "AWS Elastic Beanstalk는 애플리케이션 배포를 간소화하는 플랫폼 서비스(PaaS)지만 SageMaker의 머신러닝 모델에 대한 추론 추천을 제공하는 데 전문화되어 있지 않습니다."
        ]
    },
    {
        "Question Number": "8",
        "Situation": "데이터 과학 팀이 머신러닝 모델을 위한 데이터셋을 준비하고 있습니다. 그들은 데이터가 정확하게 레이블이 지정되고 검증되도록 해야 합니다. 이 과정에서 다양한 AWS 서비스를 고려하며, 수작업을 최소화하면서 훈련 데이터의 품질을 향상시키는 솔루션을 목표로 하고 있습니다.",
        "Question": "고품질 레이블 데이터 확보를 위해 인간 검토와 함께 데이터 레이블링 프로세스를 자동화하는 데 가장 적합한 AWS 서비스는 무엇인가요?",
        "Options": {
            "1": "Amazon SageMaker Ground Truth를 활용하여 인간 검토 옵션과 함께 데이터 레이블링을 자동화합니다.",
            "2": "Amazon Rekognition을 활용하여 인간 개입 없이 이미지를 자동으로 레이블링합니다.",
            "3": "Amazon Mechanical Turk를 사용하여 수작업 데이터 주석을 위한 레이블링 인력을 만듭니다.",
            "4": "AWS Glue를 구현하여 데이터를 전처리하고 머신러닝을 위한 준비를 합니다."
        },
        "Correct Answer": "Amazon SageMaker Ground Truth를 활용하여 인간 검토 옵션과 함께 데이터 레이블링을 자동화합니다.",
        "Explanation": "Amazon SageMaker Ground Truth는 머신러닝을 위한 레이블 데이터셋을 생성하고 관리하도록 특별히 설계되었습니다. 이 서비스는 레이블링 프로세스를 자동화하면서도 인간 검토를 허용하여 레이블 데이터의 품질을 보장하는 효율적인 방법을 제공합니다.",
        "Other Options": [
            "Amazon Mechanical Turk는 수작업 주석에 유용하지만 자동화 기능을 제공하지 않으며 인력의 직접 관리 필요성으로 인해 운영 비용이 증가할 수 있습니다.",
            "Amazon Rekognition은 이미지 분석에 뛰어나지만 인간의 감독이 필요한 맞춤형 데이터 레이블링 작업을 위해 설계되지 않아 고품질 레이블 데이터의 특정 요구에 덜 적합합니다.",
            "AWS Glue는 주로 데이터 통합 서비스로 분석을 위한 데이터를 준비합니다. 데이터 변환에 도움을 주지만 머신러닝 모델 훈련에 필요한 레이블링 기능은 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "9",
        "Situation": "한 의료 제공자가 환자 재입원율을 예측하기 위해 머신러닝 모델을 배포했습니다. 모델은 처음에는 잘 작동하지만 시간이 지나면서 의료 제공자는 환자 인구 통계와 치료 프로토콜의 변화를 감지합니다. 모델이 계속 효과적으로 작동하도록 보장하기 위해 ML 엔지니어는 모델 정확도에 영향을 미칠 수 있는 데이터 분포의 변화를 모니터링해야 합니다.",
        "Question": "ML 엔지니어가 모델 성능에 영향을 미칠 수 있는 데이터 분포의 변화를 감지하기 위해 어떤 방법을 사용해야 하나요? (두 가지 선택)",
        "Options": {
            "1": "데이터 드리프트 감지",
            "2": "하이퍼파라미터 튜닝",
            "3": "모델 평가 메트릭",
            "4": "특징 중요도 분석",
            "5": "SageMaker Clarify"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "SageMaker Clarify",
            "데이터 드리프트 감지"
        ],
        "Explanation": "SageMaker Clarify는 데이터 드리프트를 감지하고 이해하는 도구를 제공하여 모델 성능에 영향을 미칠 수 있는 데이터 분포의 변화를 모니터링하는 데 필수적입니다. 데이터 드리프트 감지는 모델 저하를 초래할 수 있는 데이터의 변화를 식별하도록 특별히 설계된 방법으로, 모델이 시간이 지나도 정확성을 유지하도록 보장합니다.",
        "Other Options": [
            "모델 평가 메트릭은 모델 성능을 평가하는 데 중요하지만 데이터 분포의 변화를 직접 측정하지는 않습니다.",
            "하이퍼파라미터 튜닝은 모델 매개변수를 최적화하는 데 중점을 두며 데이터 분포 변화 모니터링과는 관련이 없습니다.",
            "특징 중요도 분석은 예측에 가장 많이 기여하는 특징을 식별하는 데 도움을 주지만 전체 데이터 분포의 변화에 대한 통찰력을 제공하지는 않습니다."
        ]
    },
    {
        "Question Number": "10",
        "Situation": "금융 서비스 회사가 실시간으로 사기 거래를 감지하기 위해 머신 러닝 모델을 배포했습니다. 이 모델은 거래 처리 파이프라인에 통합되어 있습니다. ML 엔지니어는 모델 추론 및 데이터 처리에서 이상을 식별하기 위한 모니터링 솔루션을 구현하는 임무를 맡고 있습니다. 그들은 모델이 지속적으로 잘 작동하고 모든 문제가 신속하게 감지되도록 해야 합니다.",
        "Question": "ML 엔지니어가 모델의 성능을 효과적으로 모니터링하고 실시간으로 이상을 감지하기 위해 어떤 접근 방식을 취해야 합니까?",
        "Options": {
            "1": "모든 거래와 모델 출력을 기록하는 로깅 시스템을 구현한 후, 배치 처리를 사용하여 주기적으로 로그를 분석하여 이상을 감지합니다.",
            "2": "모델 성능 지표와 거래 데이터를 시각화하는 대시보드를 생성하고, 매일 끝에 대시보드를 수동으로 검토합니다.",
            "3": "사기 감지 모델의 출력을 분석하고 추가 조사를 위해 플래그를 올리는 별도의 이상 감지 모델을 배포합니다.",
            "4": "거래가 과거 데이터에 기반하여 예상 패턴에서 크게 벗어날 때 알림을 트리거하는 자동 경고 시스템을 설정합니다."
        },
        "Correct Answer": "거래가 과거 데이터에 기반하여 예상 패턴에서 크게 벗어날 때 알림을 트리거하는 자동 경고 시스템을 설정합니다.",
        "Explanation": "자동 경고 시스템은 모델의 예측을 실시간으로 모니터링할 수 있게 하여 이상이 발생할 때 즉각적인 조치를 취할 수 있도록 합니다. 이러한 능동적인 접근 방식은 문제를 신속하게 식별하고 해결하는 데 도움이 되어 모델이 사기를 감지하는 데 효과적으로 유지되도록 합니다.",
        "Other Options": [
            "주기적으로 로그를 분석하는 로깅 시스템은 반응적이며, 즉각적인 주의가 필요한 문제나 이상을 식별하는 데 지연이 발생할 수 있습니다.",
            "별도의 이상 감지 모델을 배포하는 것은 유용할 수 있지만 복잡성을 추가하며, 실시간 성능을 모니터링하는 경고 시스템만큼 신속한 통찰력을 제공하지 않을 수 있습니다.",
            "수동 검토를 위한 대시보드를 만드는 것은 비효율적이며, 인간의 개입에 의존하므로 즉시 검토되지 않으면 이상을 놓칠 수 있습니다."
        ]
    },
    {
        "Question Number": "11",
        "Situation": "머신 러닝 엔지니어가 고객의 탐색 행동에 따라 제품 구매 여부를 예측하는 이진 분류 모델을 평가하는 임무를 맡고 있습니다. 엔지니어는 혼동 행렬, 정밀도, 재현율 및 F1 점수 지표에 접근할 수 있습니다. 그들은 이 특정 사용 사례에 대해 정밀도와 재현율의 균형을 맞출 수 있는 최상의 지표를 선택하고자 합니다.",
        "Question": "엔지니어가 정밀도와 재현율 간의 균형을 이루기 위해 어떤 지표를 우선시해야 합니까?",
        "Options": {
            "1": "정확도",
            "2": "정밀도",
            "3": "수신자 조작 특성(ROC)",
            "4": "F1 점수"
        },
        "Correct Answer": "F1 점수",
        "Explanation": "F1 점수는 정밀도와 재현율의 조화 평균으로, 두 지표의 균형을 맞추는 것이 목표일 때 이상적인 지표입니다. 이는 잘못된 긍정과 잘못된 부정을 모두 포착하는 단일 점수를 제공하며, 한 유형의 오류가 다른 유형보다 더 비용이 많이 드는 시나리오에서 중요합니다.",
        "Other Options": [
            "정확도는 특히 불균형 데이터 세트에서 오해를 불러일으킬 수 있으며, 높은 정확도가 반드시 두 클래스 모두에서 좋은 모델 성능을 나타내는 것은 아닙니다.",
            "정밀도는 긍정적인 예측의 정확성만 측정하며, 실제 긍정 사례가 얼마나 놓쳤는지를 고려하지 않기 때문에 재현율이 중요한 경우에는 적합하지 않습니다.",
            "수신자 조작 특성(ROC) 곡선은 진짜 긍정 비율과 잘못된 긍정 비율 간의 균형을 시각화하는 데 유용하지만, F1 점수처럼 정밀도와 재현율을 균형 있게 나타내는 단일 점수를 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "12",
        "Situation": "소매 회사가 Amazon SageMaker를 사용하여 제품 수요를 예측하는 머신 러닝 모델을 개발하고 있습니다. 팀은 내장 알고리즘을 활용하여 개발 프로세스를 간소화하고 높은 성능을 보장하고자 합니다.",
        "Question": "이 시나리오에서 시계열 예측 작업에 가장 적합한 SageMaker 내장 알고리즘은 무엇입니까?",
        "Options": {
            "1": "Linear Learner",
            "2": "K-Means",
            "3": "DeepAR",
            "4": "XGBoost"
        },
        "Correct Answer": "DeepAR",
        "Explanation": "DeepAR 알고리즘은 시계열 예측을 위해 특별히 설계되었으며, 다양한 시간 의존 데이터 패턴을 처리할 수 있어 이 시나리오에서 제품 수요 예측에 이상적인 선택입니다.",
        "Other Options": [
            "Linear Learner는 주로 회귀 및 이진 분류 작업에 사용되며, 시계열 데이터에 특별히 맞춰져 있지 않습니다.",
            "XGBoost는 회귀 및 분류 문제에 강력한 알고리즘이지만, 시계열 예측에 최적화되어 있지 않습니다.",
            "K-Means는 유사한 데이터 포인트를 그룹화하는 클러스터링 알고리즘으로, 예측 작업에 적합하지 않습니다."
        ]
    },
    {
        "Question Number": "13",
        "Situation": "데이터 과학자는 제조 공정의 장비 고장을 예측하기 위한 머신러닝 모델 개발을 맡고 있습니다. 과학자는 다양한 모델 아키텍처와 그에 따른 자원 요구 사항, 훈련 시간 및 비용 영향을 평가하고 있습니다.",
        "Question": "데이터 과학자는 모델 성능, 훈련 시간 및 비용 간의 균형을 이루기 위해 어떤 접근 방식을 취해야 합니까?",
        "Options": {
            "1": "모델 정확도가 저하되더라도 가장 빠른 알고리즘을 사용하여 훈련 시간을 줄이는 데만 집중합니다.",
            "2": "정확도를 높이기 위해 대규모 앙상블 모델을 사용하되, 추가적인 훈련 시간과 자원 비용은 고려하지 않습니다.",
            "3": "예측 정확도를 극대화하기 위해 광범위한 하이퍼파라미터 튜닝이 포함된 복잡한 딥러닝 모델을 활용합니다.",
            "4": "매개변수가 적은 간단한 모델을 선택하고 자동화된 특성 엔지니어링을 활용하여 성능을 향상시키면서 훈련 비용을 줄입니다."
        },
        "Correct Answer": "매개변수가 적은 간단한 모델을 선택하고 자동화된 특성 엔지니어링을 활용하여 성능을 향상시키면서 훈련 비용을 줄입니다.",
        "Explanation": "간단한 모델을 선택하면 훈련 시간을 단축하고 비용을 낮추면서도 만족스러운 성능을 달성할 수 있습니다. 자동화된 특성 엔지니어링은 복잡한 아키텍처 없이 모델의 예측 능력을 향상시키는 데 도움이 됩니다.",
        "Other Options": [
            "복잡한 딥러닝 모델을 활용하면 종종 더 긴 훈련 시간과 높은 비용이 발생하며, 이는 정확도의 유의미한 개선으로 이어지지 않을 수 있어 이 시나리오에 비효율적인 선택이 됩니다.",
            "대규모 앙상블을 사용하는 것은 정확도를 높일 수 있지만, 일반적으로 더 많은 계산 자원과 훈련 시간이 필요하며, 성능과 비용의 균형을 맞추는 것이 목표라면 정당화되지 않을 수 있습니다.",
            "가장 빠른 알고리즘을 사용하여 훈련 시간을 줄이는 데만 집중하면, 이러한 알고리즘이 데이터의 기본 복잡성을 효과적으로 포착하지 못할 수 있어 최적의 모델 성능을 이끌어내지 못할 수 있습니다."
        ]
    },
    {
        "Question Number": "14",
        "Situation": "머신러닝 엔지니어는 Amazon SageMaker를 사용하여 고객 이탈 예측 모델을 개발하는 임무를 맡고 있습니다. 엔지니어는 기존 자원을 활용하고 높은 정확도를 보장하면서 신속하게 솔루션을 프로토타입하고자 합니다. 그들은 모델 개발 프로세스를 가속화하기 위해 SageMaker에서 다양한 옵션을 고려하고 있습니다.",
        "Question": "머신러닝 엔지니어는 고객 이탈에 대한 높은 정확도의 예측 모델을 신속하게 개발하기 위해 어떤 접근 방식을 선택해야 합니까?",
        "Options": {
            "1": "고객 유지를 위해 특별히 맞춤화된 기초 모델을 구축하기 위해 Amazon Bedrock을 통합합니다.",
            "2": "고객 이탈 예측을 위한 사전 구축된 솔루션 템플릿에 접근하기 위해 Amazon SageMaker JumpStart를 활용합니다.",
            "3": "최고의 정확도를 달성하기 위해 처음부터 맞춤형 딥러닝 모델을 사용합니다.",
            "4": "기존 데이터셋에서 모델을 훈련하기 위해 SageMaker 내장 알고리즘을 활용합니다."
        },
        "Correct Answer": "고객 이탈 예측을 위한 사전 구축된 솔루션 템플릿에 접근하기 위해 Amazon SageMaker JumpStart를 활용합니다.",
        "Explanation": "Amazon SageMaker JumpStart를 사용하면 머신러닝 엔지니어가 고객 이탈 예측과 같은 특정 작업에 최적화된 사전 구축된 솔루션 템플릿을 활용할 수 있습니다. 이는 프로토타입 프로세스를 크게 가속화하고 처음부터 시작하기보다는 미세 조정에 집중할 수 있게 합니다.",
        "Other Options": [
            "SageMaker 내장 알고리즘을 활용하는 것은 유효한 접근 방식이지만, 이탈 예측을 위해 특별히 설계된 사전 구축된 템플릿에 비해 모델 튜닝 및 최적화에 더 많은 시간이 소요될 수 있습니다.",
            "처음부터 맞춤형 딥러닝 모델을 사용하는 것은 높은 정확도를 낼 수 있지만, 시간 소모가 크고 모델 설계 및 훈련에 상당한 전문 지식이 필요하므로 신속한 프로토타입에는 실용적이지 않을 수 있습니다.",
            "Amazon Bedrock을 통합하여 기초 모델을 구축하는 것은 강력할 수 있지만, 고객 이탈 예측과 같은 특정 작업보다는 일반적인 용도에 더 적합하여 이 시나리오에서는 비효율적일 수 있습니다."
        ]
    },
    {
        "Question Number": "15",
        "Situation": "소매 회사는 머신러닝을 사용하여 전자상거래 플랫폼에서 고객 참여를 향상시키기 위한 새로운 추천 엔진을 출시할 준비를 하고 있습니다. 데이터 과학 팀은 고객 행동, 제품 세부 사항 및 판매 이력을 포함한 다양한 데이터셋을 수집했습니다. 그러나 ML 모델을 훈련하기 전에 데이터셋을 효율적으로 정리하고 변환하며 시각화할 방법이 필요합니다.",
        "Question": "팀은 머신러닝을 위해 데이터셋을 효율적으로 준비하기 위해 어떤 AWS 서비스를 사용해야 합니까?",
        "Options": {
            "1": "서버리스 데이터 처리 및 정리를 위한 AWS Lambda.",
            "2": "데이터 시각화 및 보고를 위한 Amazon QuickSight.",
            "3": "시각적 데이터 준비 및 변환을 위한 AWS Glue DataBrew.",
            "4": "머신러닝 모델 훈련을 위한 Amazon SageMaker."
        },
        "Correct Answer": "시각적 데이터 준비 및 변환을 위한 AWS Glue DataBrew.",
        "Explanation": "AWS Glue DataBrew는 데이터 준비 작업을 위해 특별히 설계되어 사용자가 코드를 작성하지 않고도 데이터를 정리하고 변환하며 시각화할 수 있도록 합니다. 이는 추천 엔진을 위한 데이터셋을 준비하는 팀의 요구에 이상적입니다.",
        "Other Options": [
            "Amazon QuickSight는 보고서 및 대시보드 생성을 중심으로 한 데이터 시각화 도구이지만, 머신러닝을 위한 데이터셋 준비에 필수적인 데이터 정리 및 변환 기능을 제공하지 않습니다.",
            "AWS Lambda는 데이터를 처리하는 데 사용할 수 있는 서버리스 컴퓨팅 서비스이지만, 모델 훈련 전에 데이터셋을 효율적으로 정리하고 변환하는 데 필요한 내장 데이터 준비 및 시각화 기능이 부족합니다.",
            "Amazon SageMaker는 머신러닝 모델을 구축, 훈련 및 배포하기 위한 종합 서비스이지만, 데이터 준비 단계에 특별히 초점을 맞추고 있지 않으며, 이는 AWS Glue DataBrew와 같은 도구가 가장 잘 처리할 수 있습니다."
        ]
    },
    {
        "Question Number": "16",
        "Situation": "소매 회사가 과거 구매 데이터를 기반으로 고객 통찰력을 개선하기 위한 머신 러닝 모델을 개발하고 있습니다. 그들은 모델 훈련을 위해 고품질의 레이블이 있는 데이터 세트를 만들고, 제품 카테고리와 고객 인구 통계의 정확한 주석을 보장하고자 합니다. 이 작업을 지원하기 위해 다양한 데이터 주석 서비스들을 고려하고 있습니다.",
        "Question": "회사가 수동 개입의 필요성을 최소화하면서 데이터 세트를 효율적으로 고정밀로 레이블링하기 위해 사용할 수 있는 AWS 서비스는 무엇입니까?",
        "Options": {
            "1": "Amazon Comprehend",
            "2": "Amazon SageMaker Ground Truth",
            "3": "Amazon Rekognition",
            "4": "AWS Glue"
        },
        "Correct Answer": "Amazon SageMaker Ground Truth",
        "Explanation": "Amazon SageMaker Ground Truth는 머신 러닝을 위한 고품질 레이블이 있는 데이터 세트를 생성하기 위해 특별히 설계되었습니다. 자동 데이터 레이블링을 위한 도구를 제공하고, 인간 레이블러와 통합되며, 다양한 데이터 유형을 지원하여 회사의 요구에 적합합니다.",
        "Other Options": [
            "Amazon Rekognition은 객체 및 장면 감지를 포함한 이미지 및 비디오 분석에 주로 사용되지만, 일반 데이터 주석 및 레이블링 작업을 위해 설계되지 않았습니다.",
            "AWS Glue는 분석을 위한 데이터를 준비하는 데이터 통합 서비스이지만, 머신 러닝 데이터 세트를 위한 데이터 주석 기능을 제공하지 않습니다.",
            "Amazon Comprehend는 텍스트 이해를 돕는 자연어 처리(NLP) 서비스이지만, 머신 러닝 목적의 데이터 세트 주석을 촉진하지 않습니다."
        ]
    },
    {
        "Question Number": "17",
        "Situation": "데이터 과학 팀이 머신 러닝 모델을 프로덕션에 배포할 준비를 하고 있습니다. 그들은 예상치 못한 문제가 발생할 경우 모델의 이전 버전으로 신속하게 되돌릴 수 있도록 하고 싶어합니다. 팀이 이를 용이하게 하기 위해 구현해야 할 배포 전략은 무엇입니까?",
        "Question": "머신 러닝 모델의 이전 버전으로 쉽게 롤백할 수 있도록 하면서 최소한의 다운타임을 보장하는 배포 전략은 무엇입니까?",
        "Options": {
            "1": "버전 관리가 있는 블루/그린 배포",
            "2": "버전 관리가 있는 카나리 배포",
            "3": "모니터링이 있는 섀도우 배포",
            "4": "A/B 테스트가 있는 롤링 업데이트"
        },
        "Correct Answer": "버전 관리가 있는 블루/그린 배포",
        "Explanation": "버전 관리가 있는 블루/그린 배포는 팀이 현재 프로덕션 버전과 새로운 버전을 위한 두 개의 별도 환경을 유지할 수 있게 합니다. 이 설정은 버전 간 즉각적인 전환을 가능하게 하여 문제가 발생할 경우 쉽게 롤백할 수 있습니다.",
        "Other Options": [
            "버전 관리가 있는 카나리 배포는 새로운 버전으로의 점진적인 트래픽 이동을 촉진할 수 있지만, 블루/그린 배포처럼 간단한 롤백 메커니즘을 본질적으로 제공하지는 않습니다.",
            "A/B 테스트가 있는 롤링 업데이트는 서로 다른 버전을 동시에 테스트할 수 있지만, 여러 버전이 동시에 활성화되어 있기 때문에 롤백 프로세스를 복잡하게 만듭니다.",
            "모니터링이 있는 섀도우 배포는 사용자 경험에 영향을 주지 않으면서 새로운 모델을 이전 모델과 함께 실행하지만, 버전 간 트래픽을 전환하지 않기 때문에 직접적인 롤백 전략을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "18",
        "Situation": "소매 회사가 고객의 탐색 기록과 구매 행동을 기반으로 제품을 추천하는 추천 시스템을 구축하고 있습니다. 기능에는 제품 카테고리 및 고객 인구 통계와 같은 범주형 속성이 포함됩니다. 데이터 과학자는 머신 러닝 모델을 위해 데이터를 준비하기 위해 다양한 인코딩 기술을 사용할 계획입니다.",
        "Question": "이 시나리오에서 높은 카디널리티를 가진 범주형 특성을 처리하는 데 가장 적합한 인코딩 기술은 무엇입니까?",
        "Options": {
            "1": "토큰화",
            "2": "원-핫 인코딩",
            "3": "레이블 인코딩",
            "4": "이진 인코딩"
        },
        "Correct Answer": "이진 인코딩",
        "Explanation": "이진 인코딩은 높은 카디널리티 범주형 특성에 특히 효과적이며, 원-핫 인코딩에 비해 데이터의 차원을 줄이면서도 정보를 보존합니다. 카테고리를 이진 숫자로 변환하여 컴팩트하고 머신 러닝 알고리즘에 적합하게 만듭니다.",
        "Other Options": [
            "원-핫 인코딩은 각 카테고리 수준에 대해 새로운 이진 열을 생성하여 카디널리티가 높을 경우 차원이 크게 증가할 수 있어 모델 훈련의 비효율성을 초래합니다.",
            "레이블 인코딩은 각 카테고리에 고유한 정수 값을 할당하지만, 존재하지 않는 서열 관계를 도입할 수 있어 특정 알고리즘이 값을 순서대로 처리하도록 오도할 수 있습니다.",
            "토큰화는 주로 텍스트 데이터를 단어를 토큰으로 변환하는 데 사용되며, 추천 시스템의 범주형 특성을 인코딩하는 맥락에서는 관련이 없습니다."
        ]
    },
    {
        "Question Number": "19",
        "Situation": "ML 엔지니어가 Amazon SageMaker를 사용하여 맞춤형 머신 러닝 모델을 배포하고 있습니다. 엔지니어는 모델 엔드포인트 관리를 위한 SageMaker의 기능을 활용하고 싶어하며, 배포 프로세스가 효율적이고 업데이트를 원활하게 처리할 수 있도록 하고자 합니다.",
        "Question": "엔지니어가 다운타임을 최소화하면서 모델 엔드포인트에 원활한 업데이트를 허용하기 위해 어떤 전략을 구현해야 합니까?",
        "Options": {
            "1": "추론을 위해 배치 변환 작업을 활용합니다.",
            "2": "블루/그린 배포 전략을 사용합니다.",
            "3": "모델을 다중 모델 엔드포인트로 배포합니다.",
            "4": "모델 버전의 A/B 테스트를 구현합니다."
        },
        "Correct Answer": "블루/그린 배포 전략을 사용합니다.",
        "Explanation": "블루/그린 배포 전략은 두 개의 별도 환경(블루와 그린)을 유지함으로써 모델 엔드포인트에 원활한 업데이트를 허용합니다. 엔지니어는 그린 환경에서 모델의 새 버전을 배포하여 블루 환경에서 트래픽을 전환하기 전에 테스트할 수 있으므로 다운타임을 최소화할 수 있습니다.",
        "Other Options": [
            "모델을 다중 모델 엔드포인트로 배포하면 여러 모델을 단일 엔드포인트에서 호스팅할 수 있지만, 원활한 업데이트의 필요성을 직접적으로 해결하지 않으며 업데이트 중 트래픽 관리가 복잡해질 수 있습니다.",
            "배치 변환 작업을 활용하는 것은 대규모 데이터셋을 배치로 처리하는 데 적합하지만, 엔드포인트에서 실시간 추론 업데이트에 적용되지 않으며, 이는 다운타임을 최소화하는 데 필요합니다.",
            "모델 버전의 A/B 테스트를 구현하면 다양한 모델 성능을 평가하는 데 도움이 될 수 있지만, 업데이트 중 원활한 전환을 보장하거나 다운타임을 최소화하지 않으며 추가 관리가 필요할 수 있습니다."
        ]
    },
    {
        "Question Number": "20",
        "Situation": "머신 러닝 엔지니어가 성능을 개선하고 훈련 시간을 단축하기 위해 딥 러닝 모델의 훈련 프로세스를 최적화하고 있습니다. 그들은 에포크, 스텝 및 배치 크기와 같은 훈련 프로세스에 영향을 미치는 다양한 요소를 고려하고 있습니다. 이러한 구성 요소를 이해하는 것은 효과적인 모델 훈련에 매우 중요합니다.",
        "Question": "다음 중 머신 러닝 모델의 훈련 프로세스에서 배치 크기의 역할을 올바르게 설명하는 것은 무엇입니까?",
        "Options": {
            "1": "배치 크기는 모델의 내부 매개변수가 업데이트되기 전에 처리되는 훈련 예제의 수를 결정합니다.",
            "2": "배치 크기는 훈련 중인 모델 아키텍처의 크기를 나타냅니다.",
            "3": "배치 크기는 훈련 중 모델이 실행해야 하는 에포크 수를 정의합니다.",
            "4": "배치 크기는 훈련 프로세스가 거치는 총 반복 횟수입니다."
        },
        "Correct Answer": "배치 크기는 모델의 내부 매개변수가 업데이트되기 전에 처리되는 훈련 예제의 수를 결정합니다.",
        "Explanation": "배치 크기는 가중치 업데이트를 수행하기 전에 모델에 공급되는 샘플 수를 결정하는 데 중요한 역할을 합니다. 더 큰 배치 크기는 더 안정적인 그래디언트 추정을 초래할 수 있지만 더 많은 메모리를 요구하며, 더 작은 배치 크기는 더 빠른 수렴을 초래할 수 있지만 최적화 과정에서 노이즈를 유발할 수 있습니다.",
        "Other Options": [
            "이 옵션은 배치 크기가 에포크 수를 결정하지 않기 때문에 잘못되었습니다. 에포크는 학습 알고리즘이 전체 훈련 데이터셋을 몇 번 작업할지를 나타냅니다.",
            "이 옵션은 배치 크기가 총 반복 횟수가 아니기 때문에 잘못되었습니다. 반복 횟수는 에포크당 처리되는 배치 수에 의해 결정됩니다.",
            "이 옵션은 배치 크기가 모델 아키텍처 크기를 나타내지 않기 때문에 잘못되었습니다. 배치 크기는 한 반복에서 처리되는 훈련 예제의 수를 구체적으로 나타냅니다."
        ]
    },
    {
        "Question Number": "21",
        "Situation": "ML 엔지니어가 이미지를 분류하기 위해 딥 러닝 모델을 구축하고 있습니다. 모델은 훈련 데이터셋에서 잘 작동하지만 검증 데이터셋에서 평가할 때 과적합의 징후를 보입니다. 엔지니어는 모델의 일반화를 개선하기 위해 다양한 정규화 기법을 고려하고 있습니다.",
        "Question": "훈련 중에 유닛을 무작위로 드롭하여 모델의 과적합을 줄이는 데 도움이 되는 정규화 기법은 무엇입니까?",
        "Options": {
            "1": "L2 정규화, 이는 손실 함수에 제곱 패널티를 추가합니다.",
            "2": "L1 정규화, 이는 손실 함수에 절대값 패널티를 추가합니다.",
            "3": "가중치 감소, 이는 모델의 큰 가중치에 패널티를 부여합니다.",
            "4": "드롭아웃, 이는 훈련 중 입력 유닛의 일부를 무작위로 0으로 설정합니다."
        },
        "Correct Answer": "드롭아웃, 이는 훈련 중 입력 유닛의 일부를 무작위로 0으로 설정합니다.",
        "Explanation": "드롭아웃은 훈련 단계에서 지정된 비율의 뉴런을 무작위로 드롭하여 과적합을 방지하도록 설계된 정규화 기법입니다. 이는 네트워크가 훈련 중에 어떤 하나의 특징에 의존할 수 없도록 하여 더 강력한 특징을 학습하도록 강요합니다.",
        "Other Options": [
            "가중치 감소는 큰 가중치를 억제하여 과적합을 제어하는 데 도움이 되지만, 훈련 중에 유닛을 무작위로 드롭하는 것과는 관련이 없으며, 이는 질문의 핵심입니다.",
            "L1 정규화는 가중치의 절대값에 기반한 패널티를 추가하여 희소성을 촉진하지만, 훈련 중에 유닛을 드롭하는 것과는 관련이 없습니다.",
            "L2 정규화는 가중치에 제곱 패널티를 추가하여 과적합에 도움이 될 수 있지만, 가중치 감소와 마찬가지로 유닛을 무작위로 드롭하는 것과는 관련이 없습니다."
        ]
    },
    {
        "Question Number": "22",
        "Situation": "머신 러닝 엔지니어가 AWS에서 ML 배포의 인프라 비용을 최적화하는 임무를 맡았습니다. 엔지니어는 비용과 성능 요구를 균형 있게 맞추기 위해 Amazon EC2 인스턴스에 대한 다양한 구매 옵션을 고려하고 있습니다. 그들은 작업 부하에 충분한 용량을 유지하면서 비용 효율성을 보장하고자 합니다.",
        "Question": "전용 용량이 필요하지 않은 가변 작업 부하에 대한 비용을 최소화하기 위해 엔지니어가 선택해야 할 구매 옵션은 무엇입니까?",
        "Options": {
            "1": "가변 작업 부하에 대해 Spot Instances를 선택하세요. 이는 On-Demand Instances에 비해 상당한 비용 절감 효과를 제공합니다.",
            "2": "유연성을 유지하고 중단을 피하기 위해 On-Demand Instances를 선택하세요. 그러나 Spot Instances에 비해 비용이 더 높습니다.",
            "3": "SageMaker Savings Plans를 구현하여 비용을 효과적으로 관리하면서 컴퓨팅 자원의 유연성을 보장하세요.",
            "4": "작업 부하의 변동성과 관계없이 장기적이고 일관된 작업 부하에 대해 더 낮은 비용을 보장하기 위해 Reserved Instances를 선택하세요."
        },
        "Correct Answer": "가변 작업 부하에 대해 Spot Instances를 선택하세요. 이는 On-Demand Instances에 비해 상당한 비용 절감 효과를 제공합니다.",
        "Explanation": "Spot Instances는 On-Demand Instances보다 훨씬 낮은 가격으로 사용되지 않는 EC2 용량을 활용할 수 있게 해줍니다. 이는 중단을 견딜 수 있는 가변 작업 부하에 특히 유리하여 성능을 희생하지 않고 비용을 최적화합니다.",
        "Other Options": [
            "Reserved Instances는 안정적인 사용을 위해 설계되었으며 장기 계약에 대한 절감 효과를 제공하지만, 전체 용량을 일관되게 활용하지 않을 수 있는 가변 작업 부하에는 비용 효율적이지 않습니다.",
            "On-Demand Instances는 유연성과 즉각적인 가용성을 제공하지만, 가장 비싼 옵션이며 비용 절감이 우선인 가변 작업 부하에는 적합하지 않습니다.",
            "SageMaker Savings Plans는 SageMaker 환경에서 비용을 관리하는 데 유용하지만, EC2 인스턴스에서 가변 작업 부하에 대한 필요를 Spot Instances만큼 효과적으로 해결하지 못할 수 있습니다."
        ]
    },
    {
        "Question Number": "23",
        "Situation": "소매 회사가 판매 예측을 위한 머신 러닝 모델을 구축할 준비를 하고 있습니다. 데이터 세트에는 날짜, 판매 금액, 제품 카테고리 및 매장 위치와 같은 다양한 속성이 포함되어 있습니다. 데이터 엔지니어링 팀은 Amazon S3에서 데이터 세트를 저장하고 처리하기 위한 가장 적합한 데이터 형식을 결정해야 하며, 효율적인 쿼리 및 저장의 필요성을 고려해야 합니다.",
        "Question": "대규모 분석을 위한 저장 효율성과 쿼리 성능을 최적화하기 위해 데이터 엔지니어링 팀이 선택해야 할 데이터 형식은 무엇입니까?",
        "Options": {
            "1": "XML",
            "2": "CSV",
            "3": "JSON",
            "4": "Parquet"
        },
        "Correct Answer": "Parquet",
        "Explanation": "Parquet는 효율적인 데이터 검색 및 저장을 위해 최적화된 열 기반 저장 파일 형식입니다. 이는 대규모 데이터 세트와 분석 작업에 특히 적합하며, 상당한 압축을 제공하고 관련 열만 읽어 더 빠른 쿼리를 가능하게 합니다.",
        "Other Options": [
            "JSON은 읽고 쓰기 쉬운 유연한 데이터 형식이지만, Parquet와 같은 열 기반 형식에 비해 대규모 데이터 세트에서 저장 및 쿼리 효율성이 떨어집니다.",
            "CSV는 간단하고 널리 사용되는 형식이지만, 열 기반 형식의 압축 및 쿼리 최적화 이점이 부족하여 대규모 분석에 덜 적합합니다.",
            "XML은 저장이나 성능에 최적화되지 않은 장황한 마크업 언어입니다. 일반적으로 다른 형식에 비해 더 많은 저장 공간을 요구하며, 구문 분석 속도가 느려 대규모 데이터 세트에 덜 적합합니다."
        ]
    },
    {
        "Question Number": "24",
        "Situation": "ML 엔지니어가 머신 러닝 프로젝트를 위한 대규모 데이터 세트에 적합한 저장 솔루션을 선택하는 임무를 맡았습니다. 데이터 세트는 향후 몇 년 동안 크게 성장할 것으로 예상되며, 엔지니어는 저장 솔루션을 결정하는 데 있어 비용과 접근 속도를 모두 고려해야 합니다. 팀은 모델 훈련 및 검증을 위해 데이터에 자주 접근해야 합니다.",
        "Question": "비용, 성능 및 확장성을 고려할 때 이 시나리오에 가장 적합한 저장 옵션은 무엇입니까?",
        "Options": {
            "1": "장기 저장을 위한 Amazon Glacier",
            "2": "지능형 티어링이 적용된 Amazon S3",
            "3": "프로비저닝된 처리량이 있는 Amazon EFS",
            "4": "표준 저장 클래스가 적용된 Amazon S3"
        },
        "Correct Answer": "표준 저장 클래스가 적용된 Amazon S3",
        "Explanation": "표준 저장 클래스가 적용된 Amazon S3는 높은 가용성과 낮은 대기 시간 접근을 위해 설계되어 자주 접근하는 데이터에 적합하며, 대규모 데이터 세트에 대한 비용 효율성을 제공합니다. 데이터 세트의 예상 성장에 따라 확장성을 지원합니다.",
        "Other Options": [
            "지능형 티어링이 적용된 Amazon S3는 예측할 수 없는 접근 패턴을 가진 데이터 세트에 좋은 옵션이지만, 모니터링 및 자동 티어링으로 인해 추가 비용이 발생할 수 있습니다. 이 경우 데이터 세트는 자주 접근해야 하므로 표준 저장 클래스가 더 효율적입니다.",
            "프로비저닝된 처리량이 있는 Amazon EFS는 높은 성능을 제공하지만, EFS가 제공하는 지속적이고 고속 접근이 필요하지 않은 대규모 데이터 세트에는 비용이 많이 들 수 있습니다. 이 사용 사례에서는 S3가 성능 요구를 충족하면서도 비용 효율적입니다.",
            "Amazon Glacier는 드물게 접근하는 장기 아카이브 저장을 위해 설계되었습니다. 프로젝트가 훈련 및 검증을 위해 자주 접근해야 하므로, Glacier는 이 시나리오에 필요한 성능 요구를 충족하지 못합니다."
        ]
    },
    {
        "Question Number": "25",
        "Situation": "머신러닝 엔지니어가 대규모 데이터셋을 사용하여 딥러닝 모델을 훈련할 준비를 하고 있습니다. 그들은 에포크, 스텝, 배치 크기와 같은 모델 성능에 영향을 미치는 주요 요소를 이해하여 훈련 과정을 최적화해야 합니다. 엔지니어는 각 훈련 반복이 효율적이고 효과적으로 수렴되도록 하고 싶어합니다.",
        "Question": "'배치 크기'가 ML 모델의 훈련 과정에서 수행하는 역할을 올바르게 정의하는 다음 중 어떤 진술이 맞습니까?",
        "Options": {
            "1": "배치 크기는 훈련 과정의 한 반복에서 사용되는 훈련 예제의 수입니다.",
            "2": "배치 크기는 모델 아키텍처의 숨겨진 레이어 수를 나타냅니다.",
            "3": "배치 크기는 모델이 훈련 과정에서 훈련할 총 에포크 수를 나타냅니다.",
            "4": "배치 크기는 모델 훈련을 완료하기 위해 수행된 총 스텝 수를 나타냅니다."
        },
        "Correct Answer": "배치 크기는 훈련 과정의 한 반복에서 사용되는 훈련 예제의 수입니다.",
        "Explanation": "배치 크기는 모델의 내부 매개변수가 업데이트되기 전에 처리될 샘플 수를 결정하므로 중요합니다. 더 큰 배치 크기는 더 빠른 훈련을 가능하게 하지만 더 많은 메모리를 요구할 수 있습니다.",
        "Other Options": [
            "이 옵션은 잘못되었습니다. 에포크는 전체 훈련 데이터셋을 완전히 통과한 횟수를 나타내며, 배치 크기와는 관련이 없습니다.",
            "이 옵션은 잘못되었습니다. 스텝은 훈련 중 완료된 반복 횟수를 나타내며, 이는 배치 크기와 전체 데이터셋 크기에 의해 영향을 받지만 배치 크기를 정의하지 않습니다.",
            "이 옵션은 잘못되었습니다. 배치 크기는 모델의 숨겨진 레이어 수와는 관련이 없으며, 훈련 반복 중 데이터 처리와 관련이 있습니다."
        ]
    },
    {
        "Question Number": "26",
        "Situation": "머신러닝 엔지니어가 고객 이탈 예측 모델을 최적화하는 임무를 맡았습니다. 모델의 성능을 효율적으로 하이퍼파라미터를 조정하여 개선해야 합니다. 팀은 작업 흐름에 자동화된 하이퍼파라미터 최적화 기능을 통합하기로 결정했습니다. 그들은 최적화 과정이 효과적일 뿐만 아니라 비용 효율적이기를 원합니다.",
        "Question": "다음 중 머신러닝 모델에 대한 자동화된 하이퍼파라미터 최적화를 제공하는 AWS 서비스는 무엇입니까?",
        "Options": {
            "1": "Amazon SageMaker",
            "2": "AWS Glue",
            "3": "AWS Lambda",
            "4": "Amazon EC2"
        },
        "Correct Answer": "Amazon SageMaker",
        "Explanation": "Amazon SageMaker는 하이퍼파라미터 최적화를 위한 내장 기능을 포함하고 있어 사용자가 조정 과정을 자동화하고 최적의 모델 매개변수를 효율적으로 찾을 수 있도록 합니다.",
        "Other Options": [
            "AWS Lambda는 이벤트에 응답하여 코드를 실행하는 서버리스 컴퓨팅 서비스이지만, 하이퍼파라미터 최적화를 위한 전문 기능을 제공하지 않습니다.",
            "AWS Glue는 주로 분석을 위한 데이터 준비를 위한 데이터 통합 서비스이며, 머신러닝 모델 조정에 중점을 두지 않습니다.",
            "Amazon EC2는 확장 가능한 컴퓨팅 리소스를 제공하지만, 머신러닝 작업 흐름에서 자동화된 하이퍼파라미터 최적화를 위한 특정 기능이 부족합니다."
        ]
    },
    {
        "Question Number": "27",
        "Situation": "데이터 과학 팀이 Amazon SageMaker 외부에서 TensorFlow 및 PyTorch와 같은 다양한 프레임워크를 사용하여 머신러닝 모델을 개발했습니다. 그들은 이러한 모델을 SageMaker에 통합하여 배포 및 관리를 용이하게 하기를 원합니다. 팀은 이 통합을 효과적으로 달성할 방법을 찾고 있습니다.",
        "Question": "팀이 SageMaker 외부에서 구축된 모델을 SageMaker에 배포하기 위해 통합하는 데 사용할 방법은 무엇입니까?",
        "Options": {
            "1": "모델을 ONNX 형식으로 변환한 다음 SageMaker 내장 추론 컨테이너를 사용하여 ONNX 모델을 배포합니다.",
            "2": "SageMaker의 내장 알고리즘을 사용하여 모델 코드를 수동으로 다시 작성하고 SageMaker 훈련 작업을 통해 배포합니다.",
            "3": "모델을 PMML 파일로 내보내고 Amazon SageMaker의 PMML 지원을 활용하여 배포합니다.",
            "4": "모델을 Docker 컨테이너로 패키징하고 이를 사용자 정의 모델로 Amazon SageMaker에 직접 배포합니다."
        },
        "Correct Answer": "모델을 Docker 컨테이너로 패키징하고 이를 사용자 정의 모델로 Amazon SageMaker에 직접 배포합니다.",
        "Explanation": "모델을 Docker 컨테이너로 패키징하면 완전한 사용자 정의가 가능하고 추론에 필요한 모든 라이브러리나 프레임워크를 활용할 수 있어 SageMaker 외부에서 개발된 모델을 통합하는 데 이상적인 방법입니다.",
        "Other Options": [
            "모델을 ONNX 형식으로 변환하는 것은 유효한 접근 방식이지만, 모든 프레임워크가 이 형식을 원활하게 지원하지 않으며 불필요한 복잡성을 초래할 수 있습니다.",
            "모델을 PMML 파일로 내보내는 것은 특정 유형의 모델에 제한되며 모든 프레임워크와 호환되지 않을 수 있어 컨테이너화보다 덜 다재다능합니다.",
            "SageMaker의 내장 알고리즘을 사용하여 모델 코드를 수동으로 다시 작성하는 것은 비효율적이며, 기존 작업을 활용하는 대신 처음부터 시작해야 하므로 모델 성능 손실로 이어질 수 있습니다."
        ]
    },
    {
        "Question Number": "28",
        "Situation": "금융 서비스 회사가 신용 위험을 평가하기 위해 머신 러닝 모델을 개발하고 있습니다. 데이터 과학 팀은 규제 요구 사항으로 인해 해석 가능성에 중점을 두고 다양한 알고리즘을 평가하고 있습니다.",
        "Question": "모델의 해석 가능성을 보장하기 위해 알고리즘을 선택할 때 팀이 우선시해야 할 옵션은 무엇입니까?",
        "Options": {
            "1": "모델 성능을 향상시키기 위해 앙상블 방법만 사용하는 것.",
            "2": "유연성을 위해 광범위한 하이퍼파라미터 조정이 필요한 알고리즘을 선호하는 것.",
            "3": "더 나은 정확성을 위해 딥 러닝과 같은 복잡한 알고리즘을 선택하는 것.",
            "4": "결정 트리나 선형 회귀와 같은 더 간단하고 해석 가능한 모델을 선택하는 것."
        },
        "Correct Answer": "결정 트리나 선형 회귀와 같은 더 간단하고 해석 가능한 모델을 선택하는 것.",
        "Explanation": "머신 러닝 모델을 개발할 때, 특히 금융과 같은 규제 산업에서는 해석 가능성이 매우 중요합니다. 결정 트리나 선형 회귀와 같은 간단한 모델은 일반적으로 더 복잡한 알고리즘에 비해 이해하고 설명하며 검증하기가 더 쉽습니다. 이는 규제 요구 사항을 충족하고 모델의 예측에 대한 신뢰를 높이는 데 도움이 됩니다.",
        "Other Options": [
            "딥 러닝과 같은 복잡한 알고리즘은 종종 정확성을 위해 해석 가능성을 희생하므로 모델 결정 이해가 중요한 시나리오에는 덜 적합합니다.",
            "앙상블 방법은 강력하지만 여러 모델을 결합하므로 의사 결정 과정을 해독하기 어렵게 만들어 해석 가능성을 줄일 수 있습니다.",
            "광범위한 하이퍼파라미터 조정이 필요한 알고리즘은 조정 과정이 입력 특성이 예측에 미치는 영향을 모호하게 만들 수 있으므로 모델 해석을 복잡하게 만들 수 있습니다."
        ]
    },
    {
        "Question Number": "29",
        "Situation": "머신 러닝 엔지니어가 구독 기반 서비스의 고객 이탈을 예측하는 모델의 성능을 개선하는 임무를 맡고 있습니다. 엔지니어는 대규모 데이터 세트에 접근할 수 있으며, 광범위한 수동 조정 없이 모델의 하이퍼파라미터를 효과적으로 최적화하고자 합니다.",
        "Question": "엔지니어가 모델 개발 프로세스에 자동 하이퍼파라미터 최적화 기능을 통합하기 위해 어떤 접근 방식을 사용해야 합니까?",
        "Options": {
            "1": "하이퍼파라미터에 대한 그리드 검색을 수동으로 생성하고 EC2 인스턴스에서 배치 처리하여 다양한 구성을 평가하는 것.",
            "2": "SageMaker의 로컬 모드를 사용하여 서로 다른 하이퍼파라미터 설정으로 여러 모델을 병렬로 훈련하여 최적 구성을 찾는 것.",
            "3": "타사 라이브러리를 사용하여 사용자 정의 최적화 알고리즘을 구현한 다음 엔지니어의 머신에서 로컬로 실행하여 하이퍼파라미터 조정하는 것.",
            "4": "Amazon SageMaker의 내장 하이퍼파라미터 조정 기능을 활용하여 지정된 범위에 따라 최상의 하이퍼파라미터 값을 자동으로 검색하는 것."
        },
        "Correct Answer": "Amazon SageMaker의 내장 하이퍼파라미터 조정 기능을 활용하여 지정된 범위에 따라 최상의 하이퍼파라미터 값을 자동으로 검색하는 것.",
        "Explanation": "Amazon SageMaker의 내장 하이퍼파라미터 조정 기능을 사용하면 머신 러닝 엔지니어가 최적의 하이퍼파라미터 값을 효율적으로 검색하는 프로세스를 자동화할 수 있습니다. 이 서비스는 베이지안 최적화와 같은 기술을 활용하여 하이퍼파라미터 공간을 지능적으로 탐색하여 시간을 절약하고 모델 성능을 향상시킵니다.",
        "Other Options": [
            "그리드 검색을 수동으로 생성하는 것은 자동 조정에 비해 효율성이 떨어지며, 지능적인 검색 방법을 고려하지 않기 때문에 최적의 성능을 이끌어내지 못할 수 있습니다.",
            "사용자 정의 최적화를 위해 타사 라이브러리를 사용하는 것은 유연해 보일 수 있지만 추가 설정 및 유지 관리가 필요하며 SageMaker의 내장 기능이 제공하는 통합 및 확장성이 부족합니다.",
            "SageMaker의 로컬 모드를 사용하여 여러 모델을 병렬로 훈련하는 것은 다양한 설정을 평가하는 데 도움이 될 수 있지만 자동 최적화 기술을 활용하지 않으므로 효율성이 떨어지고 자원 집약적일 수 있습니다."
        ]
    },
    {
        "Question Number": "30",
        "Situation": "머신 러닝 팀이 여러 모델을 개발하고 배포하는 프로젝트에 협력할 준비를 하고 있습니다. 팀은 코드 변경을 관리하고 팀원들의 기여를 추적하며 모든 수정의 이력을 유지하는 버전 관리 시스템을 구축해야 합니다. 팀은 이 목표를 달성하기 위해 다양한 도구를 고려하고 있습니다.",
        "Question": "협업 환경에서 머신 러닝 모델의 코드베이스를 관리하는 데 가장 적합한 버전 관리 시스템은 무엇입니까?",
        "Options": {
            "1": "Subversion (SVN)",
            "2": "Perforce",
            "3": "Git",
            "4": "Mercurial"
        },
        "Correct Answer": "Git",
        "Explanation": "Git은 유연성, 브랜칭 기능 및 변경 사항 병합에 대한 강력한 지원 덕분에 협업 환경에서 널리 사용되는 분산 버전 관리 시스템입니다. 여러 기여자가 동시에 다양한 기능에서 작업하고 변경 사항을 효과적으로 관리할 수 있게 해주어 코드가 빠르게 발전하는 머신 러닝 프로젝트에 이상적입니다.",
        "Other Options": [
            "Subversion (SVN)은 중앙 집중식 버전 관리 시스템으로, 특히 대규모 프로젝트에서 여러 팀원 간의 협업 및 변경 사항 병합에 어려움을 초래할 수 있습니다. 이는 빈번한 업데이트와 팀워크가 필요한 머신 러닝 워크플로우에 덜 적합합니다.",
            "Mercurial은 분산 버전 관리 시스템이지만 Git에 비해 덜 일반적으로 사용됩니다. 유사한 기능을 제공하지만 Git 주변의 더 넓은 커뮤니티 지원과 생태계는 머신 러닝 팀에 더 유리합니다.",
            "Perforce는 대규모 코드베이스 관리를 위해 대기업에서 자주 사용되는 버전 관리 시스템입니다. 그러나 Git처럼 빈번한 브랜칭 및 병합이 필요한 머신 러닝 프로젝트의 전형적인 민첩한 워크플로우에는 잘 맞지 않습니다."
        ]
    },
    {
        "Question Number": "31",
        "Situation": "ML 엔지니어가 Amazon SageMaker를 사용하여 실시간 추론 모델을 배포하는 임무를 맡았습니다. 이 모델은 기업 VPC 내에서 안전하게 접근할 수 있어야 하며, 모든 통신은 내부 네트워크로 제한되고 모델이 공개적으로 접근할 수 없어야 합니다. 엔지니어는 VPC 내에서 SageMaker 엔드포인트를 올바르게 구성해야 합니다.",
        "Question": "VPC 내에서 SageMaker 엔드포인트를 배포하기 위해 필요한 구성은 무엇입니까?",
        "Options": {
            "1": "엔드포인트에 대한 공개 접근을 활성화하여 외부 클라이언트가 접근할 수 있도록 합니다.",
            "2": "엔드포인트를 생성할 때 VPC 서브넷과 보안 그룹을 지정합니다.",
            "3": "모델 훈련과 별도의 AWS 리전에서 엔드포인트를 배포합니다.",
            "4": "엔드포인트에 대해 AmazonSageMakerFullAccess가 포함된 IAM 역할을 사용합니다."
        },
        "Correct Answer": "엔드포인트를 생성할 때 VPC 서브넷과 보안 그룹을 지정합니다.",
        "Explanation": "VPC 내에서 SageMaker 엔드포인트를 안전하게 배포하려면 엔드포인트 생성 과정에서 올바른 VPC 서브넷과 보안 그룹을 지정하는 것이 필수적입니다. 이렇게 하면 엔드포인트가 VPC 내의 다른 리소스와 통신할 수 있으면서도 공용 인터넷 접근으로부터 격리될 수 있습니다.",
        "Other Options": [
            "IAM 역할을 사용하는 것은 권한을 위한 필수 요소이지만, 이 역할은 VPC 내에서 엔드포인트를 배포하기 위한 요구 사항을 구체적으로 다루지 않으므로 이 옵션만으로는 충분하지 않습니다.",
            "공개 접근을 활성화하는 것은 VPC 내에서 엔드포인트를 안전하게 유지해야 한다는 요구 사항과 모순됩니다. 공개 접근은 엔드포인트를 인터넷에 노출시켜 이 시나리오에서는 원하지 않는 결과입니다.",
            "엔드포인트를 별도의 AWS 리전에서 배포하면 의도된 VPC 내의 리소스와 효과적으로 통신할 수 없습니다. 엔드포인트는 VPC와 동일한 리전 내에 있어야 합니다."
        ]
    },
    {
        "Question Number": "32",
        "Situation": "한 소매 회사가 공정성을 보장하고 예측에서 잠재적인 편향을 감지하기 위해 기계 학습 모델을 평가하고자 합니다. 이 회사는 이를 위해 Amazon SageMaker Clarify를 사용하고 있습니다. 모델은 고객 데이터를 기반으로 훈련되며, 회사는 특히 다양한 인구 통계 그룹이 예측에서 어떻게 대우받는지에 대해 우려하고 있습니다.",
        "Question": "회사가 다양한 인구 통계 그룹에서 기계 학습 모델의 잠재적 편향을 측정하기 위해 SageMaker Clarify에서 제공하는 어떤 지표를 사용할 수 있습니까?",
        "Options": {
            "1": "다양한 인구 통계 그룹의 대우를 측정하기 위한 불균형 영향 비율.",
            "2": "모델 훈련 중의 훈련 손실로 수렴 및 안정성을 평가합니다.",
            "3": "모델 행동을 분석하기 위한 각 인구 통계 그룹의 특성 중요도 점수.",
            "4": "예측 성능을 평가하기 위한 다양한 인구 통계 그룹의 모델 정확도."
        },
        "Correct Answer": "다양한 인구 통계 그룹의 대우를 측정하기 위한 불균형 영향 비율.",
        "Explanation": "불균형 영향 비율은 모델의 예측이 한 인구 통계 그룹에 비해 다른 그룹에 불균형적으로 영향을 미치는지를 평가하는 데 도움이 되는 특정 지표로, 기계 학습 모델의 편향을 평가하고 공정성을 보장하는 데 중요한 도구입니다.",
        "Other Options": [
            "특성 중요도 점수는 모델의 예측에 영향을 미치는 특성을 파악하는 데 통찰력을 제공할 수 있지만, 인구 통계 그룹 간의 편향을 구체적으로 측정하지는 않습니다.",
            "모델 정확도는 전반적인 성능 지표를 제공하지만, 다양한 인구 통계 그룹 간의 모델 성능을 나타내지 않으므로 편향 문제를 해결하지 못합니다.",
            "훈련 손실은 모델이 훈련 중 얼마나 잘 학습하고 있는지를 나타내는 지표이지만, 모델의 예측에서 편향이나 공정성에 대한 통찰력을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "33",
        "Situation": "한 조직이 고객 이탈을 예측하는 기계 학습 모델을 개발하고 있습니다. 이들은 이 모델을 효과적으로 배포하는 방법을 결정해야 하며, 특히 다양한 예측 작업에 대한 리소스 관리에 중점을 두고 있습니다.",
        "Question": "기계 학습 워크플로우를 배포하기 위한 온디맨드 리소스와 프로비저닝된 리소스 간의 차이를 가장 잘 설명하는 것은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "온디맨드 리소스는 사용될 때만 비용이 발생합니다.",
            "2": "프로비저닝된 리소스는 부하 변화에 대해 수동 조정이 필요합니다.",
            "3": "프로비저닝된 리소스는 수요와 관계없이 일관된 성능을 제공합니다.",
            "4": "온디맨드 리소스는 항상 가용성을 보장합니다.",
            "5": "온디맨드 리소스는 트래픽에 따라 자동으로 확장됩니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "온디맨드 리소스는 사용될 때만 비용이 발생합니다.",
            "프로비저닝된 리소스는 수요와 관계없이 일관된 성능을 제공합니다."
        ],
        "Explanation": "온디맨드 리소스는 실제로 사용될 때만 요금이 부과되므로 예측할 수 없는 작업에 비용 효율적입니다. 반면, 프로비저닝된 리소스는 피크 사용 중 일관된 성능을 보장하기 위해 미리 예약되어 있으며, 실제 수요와 관계없이 설정됩니다.",
        "Other Options": [
            "온디맨드 리소스는 실제로 트래픽에 따라 자동으로 확장되지만, 이 특성만으로는 프로비저닝된 리소스와 비교했을 때의 비용 구조의 본질을 포착하지 않습니다.",
            "프로비저닝된 리소스는 부하 변화에 대해 수동 조정이 필요하지 않으며, 대신 미리 정해진 용량을 처리하도록 설정되어 있어 실시간 트래픽에 반응하지 않습니다.",
            "온디맨드 리소스는 필요할 때 사용할 수 있도록 설계되었지만, 항상 가용성을 보장하지는 않으며, 이는 잠재적으로 중단될 수 있는 기본 인프라에 의존하기 때문입니다."
        ]
    },
    {
        "Question Number": "34",
        "Situation": "금융 기관이 역사적인 고객 데이터를 사용하여 대출 채무 불이행 위험을 예측하려고 합니다. 데이터에는 신용 점수, 소득, 고용 상태 및 이전 대출 이력과 같은 다양한 특성이 포함되어 있습니다. 기관은 이해관계자들이 대출 결정에 영향을 미치는 요인을 이해할 수 있도록 모델의 해석 가능성을 보장하고자 합니다. ML 엔지니어는 이 예측 모델링 작업에 적합한 알고리즘을 선택해야 합니다.",
        "Question": "모델의 해석 가능성을 보장하면서 대출 채무 불이행 위험을 예측하는 데 가장 적합한 머신 러닝 알고리즘은 무엇입니까?",
        "Options": {
            "1": "선형 커널을 가진 서포트 벡터 머신",
            "2": "거리 가중치를 가진 K-최근접 이웃",
            "3": "여러 개의 은닉층을 가진 딥 러닝 신경망",
            "4": "특성 중요도 분석을 가진 랜덤 포레스트"
        },
        "Correct Answer": "특성 중요도 분석을 가진 랜덤 포레스트",
        "Explanation": "랜덤 포레스트는 높은 정확도를 제공할 뿐만 아니라 특성 중요도 분석을 가능하게 하는 트리 기반 앙상블 방법으로, 이해관계자들에게 해석 가능성을 제공합니다. 이는 대출 채무 불이행을 예측하는 데 가장 영향력 있는 특성이 무엇인지 이해하는 데 도움이 됩니다.",
        "Other Options": [
            "선형 커널을 가진 서포트 벡터 머신은 해석 가능성을 제공할 수 있지만, 랜덤 포레스트와 같은 앙상블 방법만큼 데이터의 복잡한 관계를 효과적으로 포착하지 못할 수 있습니다.",
            "여러 개의 은닉층을 가진 딥 러닝 신경망은 높은 정확도를 제공하지만 해석하기 어려워 모델 투명성이 중요한 상황에서는 덜 적합합니다.",
            "거리 가중치를 가진 K-최근접 이웃은 간단하고 직관적이지만 데이터의 고차원성에 어려움을 겪을 수 있으며, 명시적인 특성 중요도를 제공하지 않아 이 맥락에서 해석 가능성이 떨어집니다."
        ]
    },
    {
        "Question Number": "35",
        "Situation": "금융 기관이 대출 신청자의 신용 위험을 예측하기 위한 머신 러닝 모델을 개발하고 있습니다. 이해관계자들은 규제 요구 사항 준수를 보장하기 위해 모델의 해석 가능성이 필요하다고 강조합니다. ML 엔지니어는 성능과 해석 가능성을 균형 있게 유지하는 모델을 선택해야 합니다.",
        "Question": "ML 엔지니어가 예측 성능을 유지하면서 해석 가능성을 보장하기 위해 고려해야 할 알고리즘은 무엇입니까?",
        "Options": {
            "1": "그래디언트 부스팅 머신",
            "2": "랜덤 포레스트",
            "3": "선형 회귀",
            "4": "딥 신경망"
        },
        "Correct Answer": "선형 회귀",
        "Explanation": "선형 회귀는 간단한 수학적 공식 덕분에 본질적으로 해석 가능하여 이해관계자들이 입력 특성과 예측 결과 간의 관계를 쉽게 이해할 수 있습니다. 이는 신용 위험 평가와 같은 고위험 결정에서 해석 가능성 요구 사항과 잘 맞습니다.",
        "Other Options": [
            "랜덤 포레스트는 많은 예측 작업에 효과적이지만 블랙 박스 모델로 간주되어 개별 특성이 예측에 어떻게 기여하는지 해석하기 어렵습니다.",
            "그래디언트 부스팅 머신은 좋은 성능을 제공할 수 있지만, 선형 모델보다 복잡하고 덜 해석 가능하여 이해관계자들의 명확성 요구를 충족하지 못할 수 있습니다.",
            "딥 신경망은 복잡한 작업에 강력하지만 해석 가능성이 부족하다는 비판을 받는 경우가 많아 의사 결정 과정을 이해해야 하는 상황에서는 적합하지 않습니다."
        ]
    },
    {
        "Question Number": "36",
        "Situation": "데이터 과학 팀이 고객 이탈에 대한 기존 예측 모델의 성능을 개선하기 위해 작업하고 있습니다. 그들은 다양한 알고리즘을 실험했으며 더 나은 정확도를 달성하기 위해 여러 모델을 결합하고자 합니다. 팀은 앙상블 학습을 위한 다양한 접근 방식을 고려하고 있습니다.",
        "Question": "여러 모델을 결합하여 예측 성능을 개선하는 데 가장 효과적인 방법은 무엇입니까?",
        "Options": {
            "1": "최고의 개별 모델을 찾기 위해 서로 다른 하이퍼파라미터로 단일 알고리즘을 여러 번 적용합니다.",
            "2": "기본 모델의 예측을 메타 모델의 입력으로 사용하는 스태킹 접근 방식을 사용합니다.",
            "3": "모델의 예측을 평균하여 추가 처리 없이 결합합니다.",
            "4": "검증 정확도에 따라 최고의 성능을 보이는 모델을 선택하고 배포합니다."
        },
        "Correct Answer": "기본 모델의 예측을 메타 모델의 입력으로 사용하는 스태킹 접근 방식을 사용합니다.",
        "Explanation": "스태킹은 기본 모델의 예측을 기반으로 메타 모델을 훈련시키는 효과적인 앙상블 학습 방법입니다. 이 접근 방식은 다양한 모델의 강점을 포착할 수 있으며 일반적으로 개별 모델보다 향상된 예측 성능을 제공합니다.",
        "Other Options": [
            "서로 다른 하이퍼파라미터로 단일 알고리즘을 적용하면 해당 모델을 최적화하지만, 앙상블 학습에 필수적인 여러 모델의 강점을 활용하지 못합니다.",
            "검증 정확도를 기준으로 최고의 성능을 보이는 모델을 선택하면 여러 모델을 결합하여 얻을 수 있는 잠재적 이익을 무시하게 되어 전체 성능이 저하될 수 있습니다.",
            "예측을 평균하는 것은 성능을 개선할 수 있지만, 추가 처리(예: 메타 모델 사용)가 없으면 각 개별 모델의 강점을 완전히 활용하지 못해 전체 정확도가 제한될 수 있습니다."
        ]
    },
    {
        "Question Number": "37",
        "Situation": "머신 러닝 엔지니어가 Amazon SageMaker를 사용하여 모델을 구축하고 배포하는 임무를 맡았습니다. 엔지니어는 SageMaker의 내장 알고리즘과 인기 있는 ML 라이브러리를 사용하는 것을 고려하고 있습니다. 성능을 최적화하면서 비용을 최소화해야 합니다.",
        "Question": "머신 러닝 엔지니어가 고려해야 할 두 가지 접근 방식은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "기존 기능을 활용하기 위해 TensorFlow를 사용하여 사용자 정의 훈련 스크립트를 구현합니다.",
            "2": "비용을 줄이기 위해 동일한 인스턴스에서 여러 모델을 병렬로 훈련합니다.",
            "3": "모델 훈련 프로세스를 자동화하고 간소화하기 위해 SageMaker Pipelines를 활용합니다.",
            "4": "더 빠른 모델 훈련 및 배포를 위해 SageMaker의 내장 알고리즘을 사용합니다.",
            "5": "훈련 중 최적의 성능을 보장하기 위해 더 큰 인스턴스 유형을 선택합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "더 빠른 모델 훈련 및 배포를 위해 SageMaker의 내장 알고리즘을 사용합니다.",
            "모델 훈련 프로세스를 자동화하고 간소화하기 위해 SageMaker Pipelines를 활용합니다."
        ],
        "Explanation": "SageMaker의 내장 알고리즘을 사용하면 모델 훈련 프로세스가 크게 빨라질 수 있습니다. 이러한 알고리즘은 SageMaker 환경 내에서 성능을 최적화하도록 설계되었습니다. 또한 SageMaker Pipelines를 활용하면 전체 머신 러닝 워크플로우를 자동화하여 모델 생애 주기를 관리하기 쉽게 하고 효율성을 향상시킵니다.",
        "Other Options": [
            "TensorFlow를 사용하여 사용자 정의 훈련 스크립트를 구현하는 것은 개발 및 디버깅에 더 오랜 시간이 걸릴 수 있으며, 이는 전체 프로세스를 지연시킬 수 있습니다. 특히 SageMaker에 최적화된 내장 알고리즘이 이미 있는 경우 더욱 그렇습니다.",
            "더 큰 인스턴스 유형을 선택하면 비용이 증가할 수 있으며, 성능이 반드시 향상되는 것은 아닙니다. 인스턴스 유형은 크기만이 아니라 작업 부하의 특정 요구 사항에 따라 선택해야 합니다.",
            "동일한 인스턴스에서 여러 모델을 병렬로 훈련하는 것은 비용을 효과적으로 줄이지 않습니다. 이는 자원 경쟁과 성능 저하를 초래할 수 있으며, 궁극적으로 훈련을 느리게 하고 비효율적으로 만들 수 있습니다."
        ]
    },
    {
        "Question Number": "38",
        "Situation": "머신 러닝 엔지니어가 온라인 소매 플랫폼의 고객 수요를 예측하는 모델을 유지 관리하는 책임이 있습니다. 이 모델은 몇 달 동안 배포되었으며, 엔지니어는 정확도가 감소하고 있음을 발견했습니다. 이 감소의 원인을 파악하기 위해 엔지니어는 데이터 품질 및 모델 성능을 위한 강력한 모니터링 프레임워크를 구축해야 합니다.",
        "Question": "시간이 지남에 따라 데이터 품질과 모델 성능을 모니터링하는 가장 효과적인 방법은 무엇입니까?",
        "Options": {
            "1": "Amazon CloudWatch를 사용하여 모델 성능 지표에 대한 경고를 설정하고 훈련 파이프라인에 데이터 품질 검사를 통합합니다.",
            "2": "주간 단위로 데이터를 수동으로 검토하고 모델 출력을 확인하여 이상 징후를 식별합니다.",
            "3": "모델 예측을 주기적으로 기록하고 실제 결과와 비교하는 예약 작업을 구현합니다.",
            "4": "훈련 데이터셋에 버전 관리를 적용하고 데이터셋이 크게 변경될 때만 모델을 재훈련합니다."
        },
        "Correct Answer": "Amazon CloudWatch를 사용하여 모델 성능 지표에 대한 경고를 설정하고 훈련 파이프라인에 데이터 품질 검사를 통합합니다.",
        "Explanation": "Amazon CloudWatch를 사용하여 성능 지표에 대한 경고를 설정하면 실시간 모니터링이 가능하여 성능 저하 시 즉각적인 조치를 취할 수 있습니다. 데이터 품질 검사를 통합하면 입력 데이터의 문제를 신속하게 해결하여 모델 신뢰성을 높일 수 있습니다.",
        "Other Options": [
            "예측을 기록하기 위한 예약 작업을 구현하는 것은 일부 통찰력을 제공할 수 있지만, 능동적인 모니터링에 필요한 즉각성과 자동화가 부족하여 실시간 솔루션보다 효과적이지 않습니다.",
            "훈련 데이터셋에 버전 관리를 적용하는 것은 유익하지만, 성능이나 데이터 품질에 대한 지속적인 모니터링을 제공하지 않아 문제 해결에 지연이 발생할 수 있습니다.",
            "데이터와 모델 출력을 주간 단위로 수동으로 검토하는 것은 시간 소모적이며 반응적입니다. 이 접근 방식은 즉각적인 주의가 필요한 중요한 문제를 놓칠 수 있습니다."
        ]
    },
    {
        "Question Number": "39",
        "Situation": "소매 회사가 고객 이탈을 예측하는 머신 러닝 모델을 위해 고객 거래 데이터를 준비하고 있습니다. 데이터는 Amazon S3에 저장되어 있으며, 회사는 모델에 데이터를 공급하기 전에 높은 데이터 품질을 보장하고자 합니다. 그들은 데이터 유효성을 검사하기 위해 AWS Glue DataBrew와 AWS Glue Data Quality를 사용하려고 합니다.",
        "Question": "ML 엔지니어가 데이터 품질을 효과적으로 검증하기 위해 어떤 조치를 취해야 합니까? (두 가지 선택)",
        "Options": {
            "1": "검증 전에 데이터를 변환하기 위해 Amazon EMR에서 배치 처리 작업을 구현합니다.",
            "2": "시간이 지남에 따라 데이터 신선도를 모니터링하기 위해 AWS Glue Data Quality에서 정기적인 데이터 검증 작업을 예약합니다.",
            "3": "AWS Glue Data Quality에서 중요한 필드의 null 값을 확인하기 위한 데이터 품질 규칙을 생성합니다.",
            "4": "AWS Glue DataBrew를 사용하여 데이터 분포를 시각화하고 데이터셋의 이상치를 식별합니다.",
            "5": "AWS Glue DataBrew를 활용하여 서로 다른 데이터셋 간의 데이터 형식을 정리하고 표준화합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "AWS Glue Data Quality에서 중요한 필드의 null 값을 확인하기 위한 데이터 품질 규칙을 생성합니다.",
            "AWS Glue Data Quality에서 정기적인 데이터 검증 작업을 예약하여 시간에 따라 데이터 신선도를 모니터링합니다."
        ],
        "Explanation": "AWS Glue Data Quality에서 null 값을 확인하기 위한 데이터 품질 규칙을 생성하면 중요한 필드가 채워져 있는지 확인할 수 있으며, 이는 신뢰할 수 있는 모델 예측에 필수적입니다. 정기적인 데이터 검증 작업을 예약하면 지속적인 데이터 품질을 유지하고 데이터 신선도와 관련된 문제를 신속하게 해결할 수 있습니다.",
        "Other Options": [
            "AWS Glue DataBrew를 사용하여 데이터 분포를 시각화하는 것은 이상치를 식별하는 데 도움이 될 수 있지만, 전체 데이터 품질을 직접적으로 검증하지는 않습니다. 시각화는 유용하지만 데이터 품질 규칙과 같은 데이터 무결성을 보장하는 구조적 접근 방식을 제공하지 않습니다.",
            "Amazon EMR에서 배치 처리 작업을 구현하는 것은 대량의 데이터셋을 처리하는 데 도움이 될 수 있지만, 데이터 품질 검증을 구체적으로 다루지 않으므로 이 맥락에서는 덜 관련성이 있습니다.",
            "AWS Glue DataBrew를 사용하여 데이터 형식을 정리하고 표준화하는 것은 중요하지만, 특정 검증 규칙이 없으면 이 단계만으로는 전체 데이터 품질을 보장할 수 없습니다."
        ]
    },
    {
        "Question Number": "40",
        "Situation": "한 헬스케어 스타트업이 과거 의료 기록을 기반으로 환자 결과를 예측하기 위한 머신 러닝 모델을 개발하고 있습니다. 모델의 성능을 보장하기 위해 스타트업은 고품질의 레이블이 있는 데이터셋이 필요합니다. 그들은 데이터를 효율적으로 주석 달고 레이블을 붙이기 위해 다양한 서비스를 고려하고 있습니다.",
        "Question": "어떤 AWS 서비스가 머신 러닝을 위한 고품질 레이블이 있는 데이터셋을 생성하는 데 도움이 되는 데이터 레이블링 기능을 제공합니까?",
        "Options": {
            "1": "Amazon Comprehend",
            "2": "Amazon SageMaker Ground Truth",
            "3": "Amazon Rekognition Custom Labels",
            "4": "AWS Glue DataBrew"
        },
        "Correct Answer": "Amazon SageMaker Ground Truth",
        "Explanation": "Amazon SageMaker Ground Truth는 사용자가 머신 러닝을 위한 고품질 훈련 데이터셋을 구축하고 관리하는 데 도움을 주는 완전 관리형 데이터 레이블링 서비스입니다. 이 서비스는 능동 학습 및 크라우드 소싱 레이블링과 같은 기능을 제공하여 스타트업의 요구에 적합한 선택입니다.",
        "Other Options": [
            "AWS Glue DataBrew는 주로 데이터를 정리하고 정규화하는 데이터 준비 도구로, 머신 러닝 데이터셋을 위한 특정 데이터 레이블링 서비스를 제공하지 않습니다.",
            "Amazon Comprehend는 텍스트에서 인사이트를 추출하는 자연어 처리(NLP) 서비스로, 머신 러닝 작업을 위한 데이터 레이블링에 중점을 두지 않습니다.",
            "Amazon Rekognition Custom Labels는 이미지 분석을 위해 설계되었으며 사용자가 맞춤형 이미지 분류 모델을 생성할 수 있도록 하지만, 다양한 유형의 데이터셋에 대한 일반 데이터 레이블링 서비스를 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "41",
        "Situation": "한 소매 회사가 고객 구매 행동을 예측하기 위한 머신 러닝 모델을 개발하고 있습니다. 데이터 과학 팀은 배포 전에 모델 성능을 최적화하기 위해 다양한 하이퍼파라미터 조정 기술을 탐색하고 있습니다. 그들은 하이퍼파라미터 공간 탐색과 계산 효율성을 균형 있게 조정할 수 있는 기술을 선택하고자 합니다.",
        "Question": "팀이 더 적은 평가로 최적의 하이퍼파라미터를 효율적으로 찾기 위해 우선시해야 할 하이퍼파라미터 조정 기술은 무엇입니까?",
        "Options": {
            "1": "과거 평가 결과를 사용하여 향후 검색을 안내하는 베이지안 최적화.",
            "2": "미리 정의된 그리드에서 하이퍼파라미터를 무작위로 검색하는 랜덤 서치.",
            "3": "전문 지식과 경험에 기반한 수동 하이퍼파라미터 조정.",
            "4": "지정된 하이퍼파라미터의 하위 집합을 철저히 검색하는 그리드 서치."
        },
        "Correct Answer": "과거 평가 결과를 사용하여 향후 검색을 안내하는 베이지안 최적화.",
        "Explanation": "베이지안 최적화는 이전 결과를 기반으로 평가할 하이퍼파라미터를 지능적으로 선택하는 확률적 모델 기반 최적화 기술로, 다른 방법에 비해 더 적은 평가로 최적 값으로의 효율적인 수렴을 이끌어냅니다.",
        "Other Options": [
            "랜덤 서치는 과거 평가를 활용하지 않고 하이퍼파라미터를 무작위로 샘플링하므로 베이지안 최적화보다 효율성이 떨어지며, 최적 값을 찾기 위해 더 많은 반복이 필요할 수 있습니다.",
            "그리드 서치는 지정된 그리드의 모든 하이퍼파라미터 조합을 철저히 평가하므로 높은 계산 비용과 비효율성을 초래할 수 있으며, 하이퍼파라미터 공간의 가장 유망한 영역을 우선시하지 않습니다.",
            "수동 하이퍼파라미터 조정은 인간의 전문성과 직관에 크게 의존하므로 시간이 많이 소요될 수 있으며, 하이퍼파라미터 공간을 체계적으로 탐색하지 않아 종종 최적의 모델 성능을 이끌어내지 못할 수 있습니다."
        ]
    },
    {
        "Question Number": "42",
        "Situation": "한 데이터 과학 팀이 머신 러닝 프로젝트를 위한 데이터셋을 준비하고 있습니다. 그들은 모델의 공정성과 정확성에 영향을 미칠 수 있는 데이터의 잠재적 편향에 대해 우려하고 있습니다. 팀은 모델 훈련 전에 AWS 도구를 사용하여 이러한 편향을 식별하고 완화하고자 합니다. 그들은 특히 선택 편향과 측정 편향을 해결하고 싶어합니다.",
        "Question": "팀이 데이터 준비 단계에서 데이터셋의 편향을 감지하고 완화하기 위해 사용할 수 있는 AWS 서비스는 무엇입니까?",
        "Options": {
            "1": "AWS Glue DataBrew",
            "2": "AWS Lake Formation",
            "3": "Amazon SageMaker Data Wrangler",
            "4": "AWS SageMaker Clarify"
        },
        "Correct Answer": "AWS SageMaker Clarify",
        "Explanation": "AWS SageMaker Clarify는 머신 러닝 데이터와 모델에서 편향을 감지하고 완화하기 위해 특별히 설계되었습니다. 이 서비스는 데이터의 잠재적 편향을 분석하고 시각화하는 기능을 제공하여 팀의 요구에 가장 적합한 선택입니다.",
        "Other Options": [
            "AWS Glue DataBrew는 편향 감지 및 완화보다는 데이터 준비 및 변환에 주로 초점을 맞추고 있습니다.",
            "Amazon SageMaker Data Wrangler는 데이터 준비 및 특성 엔지니어링을 지원하지만 데이터의 편향을 특별히 다루지 않습니다.",
            "AWS Lake Formation은 안전한 데이터 레이크를 설정하고 관리하기 위한 서비스로, 편향 분석 도구를 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "43",
        "Situation": "금융 서비스 회사가 사기 탐지를 위한 머신 러닝 모델을 배포하고 있으며, 각 모델 버전이 추적되고 감사에 쉽게 접근할 수 있도록 해야 합니다. 그들은 규제 요구 사항을 준수하면서 모델의 생애 주기 전반에 걸쳐 모델을 카탈로그화하고 버전 관리하며 모니터링할 수 있는 시스템을 구현하고자 합니다.",
        "Question": "회사가 반복성과 감사를 효과적으로 관리하기 위해 어떤 AWS 서비스를 사용해야 합니까?",
        "Options": {
            "1": "AWS CodeCommit",
            "2": "Amazon SageMaker Model Registry",
            "3": "Amazon SageMaker Pipelines",
            "4": "AWS Lambda"
        },
        "Correct Answer": "Amazon SageMaker Model Registry",
        "Explanation": "Amazon SageMaker Model Registry는 머신 러닝 모델을 카탈로그화하고 버전 관리할 수 있는 완전 관리형 방법을 제공하여 팀이 모델 버전을 생애 주기 전반에 걸쳐 추적하고 감사할 수 있도록 합니다. 이는 규제 감사 및 준수에 필수적인 모델 계보 및 메타데이터 기능을 포함합니다.",
        "Other Options": [
            "Amazon SageMaker Pipelines는 엔드 투 엔드 머신 러닝 워크플로우 자동화에 중점을 두지만, 모델 버전을 관리하거나 감사 목적을 위한 레지스트리를 제공하지 않습니다.",
            "AWS CodeCommit은 코드 리포지토리를 관리하기 위한 소스 제어 서비스이지만, 머신 러닝 모델 버전을 추적하거나 ML 모델 생애 주기 관리를 위한 특정 기능을 제공하도록 설계되지 않았습니다.",
            "AWS Lambda는 이벤트에 응답하여 코드를 실행하는 서버리스 컴퓨팅 서비스이지만, 머신 러닝 모델 버전을 관리하거나 감사하는 기능을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "44",
        "Situation": "머신 러닝 엔지니어가 전자 상거래 플랫폼을 위한 추천 시스템을 개발하는 임무를 맡았습니다. 이 플랫폼은 클릭, 구매 및 리뷰를 포함한 방대한 양의 사용자 행동 데이터를 수집합니다. 엔지니어는 비용, 성능 및 다양한 데이터 구조를 효율적으로 처리할 수 있는 저장 솔루션을 선택해야 합니다.",
        "Question": "비용 효율성과 성능 요구 사항을 가장 잘 충족하기 위해 엔지니어가 선택해야 할 저장 솔루션은 무엇입니까?",
        "Options": {
            "1": "Amazon DynamoDB와 NoSQL 데이터베이스 구조",
            "2": "Amazon Redshift와 데이터 웨어하우스 아키텍처",
            "3": "Amazon S3와 데이터 레이크 아키텍처",
            "4": "Amazon RDS와 SQL 데이터베이스 구조"
        },
        "Correct Answer": "Amazon S3와 데이터 레이크 아키텍처",
        "Explanation": "Amazon S3와 데이터 레이크 아키텍처는 다양한 데이터 유형의 대량 저장을 비용 효율적으로 가능하게 하여, 사전 스키마 설계 없이 분석 및 머신 러닝 작업을 용이하게 하여 추천 시스템에 이상적입니다.",
        "Other Options": [
            "Amazon RDS와 SQL 데이터베이스 구조는 구조화된 데이터에 더 적합하며, 대규모 데이터 처리 시 더 높은 비용이 발생할 수 있어 다양한 데이터 처리에 단점이 될 수 있습니다.",
            "Amazon DynamoDB는 확장 가능한 NoSQL 데이터베이스에 좋은 옵션이지만, 높은 읽기/쓰기 처리량 요구 사항으로 인해 비용이 증가할 수 있으며, 머신 러닝에 필요한 복잡한 분석 쿼리에는 효율적이지 않을 수 있습니다.",
            "Amazon Redshift는 데이터 웨어하우징 및 분석을 위해 설계되어 대규모 쿼리에 적합하지만, 일반적으로 더 높은 비용이 수반되며 원시 및 다양한 데이터 유형 저장에 유연성이 떨어집니다."
        ]
    },
    {
        "Question Number": "45",
        "Situation": "머신 러닝 엔지니어링 팀이 AWS 서비스를 사용하여 예측 유지보수 모델을 위한 자동화된 배포 파이프라인을 설정하고 있습니다. 그들은 AWS CloudFormation을 활용하여 인프라를 코드로 관리하고, 모든 리소스가 다양한 환경에서 효율적이고 일관되게 프로비저닝되도록 하기를 원합니다. 팀은 모델이 중단 없이 원활하게 업데이트될 수 있도록 해야 합니다. AWS 서비스를 사용하여 이를 달성하기 위한 가장 적절한 접근 방식은 무엇입니까?",
        "Question": "모델 배포를 자동화하면서 지속적인 통합 및 지속적인 배포(CI/CD) 원칙을 유지하기 위해 어떤 AWS 서비스를 사용할 수 있습니까?",
        "Options": {
            "1": "AWS Lambda",
            "2": "AWS CodeDeploy",
            "3": "AWS Step Functions",
            "4": "AWS CodePipeline"
        },
        "Correct Answer": "AWS CodePipeline",
        "Explanation": "AWS CodePipeline은 CI/CD를 위해 설계되어 배포 프로세스를 자동화할 수 있으며, 다양한 AWS 서비스의 통합을 포함합니다. 이는 코드 변경을 관리하고 모델 배포를 자동화할 수 있는 파이프라인을 생성하여 중단 없이 지속적인 배포 및 통합을 보장합니다.",
        "Other Options": [
            "AWS Lambda는 주로 이벤트에 응답하여 코드를 실행하는 데 사용되며, 모델 배포를 위한 CI/CD 파이프라인 관리에 특별히 설계되지 않았습니다.",
            "AWS CodeDeploy는 인스턴스에 대한 코드 배포 자동화에 중점을 두고 있으며, 전체 파이프라인을 소스에서 배포까지 관리하는 완전한 CI/CD 솔루션이 아닙니다.",
            "AWS Step Functions는 워크플로우를 조정하는 데 사용되지만, 머신 러닝 모델의 지속적인 통합 및 배포를 위해 특별히 맞춤화되어 있지 않습니다."
        ]
    },
    {
        "Question Number": "46",
        "Situation": "소매 회사가 고객 이탈 예측을 위한 머신 러닝 모델을 배포했습니다. 모델은 운영 중이며, 시간이 지남에 따라 성능과 보안을 보장하는 것이 중요합니다. 회사는 예측의 이상을 감지하고 데이터 보안 표준을 준수하기 위해 모델 모니터링을 위한 모범 사례를 구현하고자 합니다.",
        "Question": "데이터 보안을 유지하고 수동 개입을 최소화하면서 머신 러닝 모델을 모니터링하기 위한 가장 효과적인 접근 방식은 무엇입니까?",
        "Options": {
            "1": "Amazon CloudWatch를 구현하여 모델의 예측 지연 시간과 오류를 추적하고, AWS IAM 역할을 활용하여 예측 데이터에 대한 접근을 제어합니다.",
            "2": "Amazon Kinesis Data Streams를 설정하여 예측 데이터를 실시간으로 캡처하고, 모델 성능의 불일치를 분석하기 위해 사용자 정의 스크립트를 사용합니다.",
            "3": "Amazon SageMaker Model Monitor를 사용하여 데이터 품질 문제와 모델 예측의 드리프트를 자동으로 확인하고, 이상에 대한 경고를 구성합니다.",
            "4": "AWS Config를 사용하여 모든 모델 구성이 보안 정책을 준수하도록 하고, 모델 환경의 변경 사항을 기록합니다."
        },
        "Correct Answer": "Amazon SageMaker Model Monitor를 사용하여 데이터 품질 문제와 모델 예측의 드리프트를 자동으로 확인하고, 이상에 대한 경고를 구성합니다.",
        "Explanation": "Amazon SageMaker Model Monitor를 사용하면 데이터 드리프트 및 품질 문제에 대한 지속적인 모니터링이 가능하여 모델 성능과 준수를 유지하는 데 필수적입니다. 또한 경고를 생성하는 기능이 내장되어 있어 모델 관리를 위한 선제적 접근을 용이하게 합니다.",
        "Other Options": [
            "Amazon CloudWatch를 구현하면 지연 시간과 오류를 추적하는 데 도움이 되지만, 모델 성능에 중요한 데이터 품질이나 예측 드리프트를 구체적으로 다루지는 않습니다.",
            "Amazon Kinesis Data Streams를 설정하는 것은 실시간 데이터 캡처를 위한 유효한 접근 방식이지만, 분석을 위해 수동 개입이 필요하며 모델 성능의 자동 모니터링을 제공하지 않습니다.",
            "AWS Config를 사용하는 것은 준수 및 구성 관리에 중점을 두고 있으며, 모델 성능이나 데이터 품질을 직접 모니터링하는 것과는 관련이 없습니다."
        ]
    },
    {
        "Question Number": "47",
        "Situation": "ML 엔지니어가 고객 이탈을 예측하는 머신 러닝 모델을 제공하는 임무를 맡았습니다. 이 모델은 즉각적인 예측을 위한 실시간 상호작용이 필요하지만, 훈련 및 검증을 위해 대량의 과거 데이터를 처리해야 합니다. 엔지니어는 이러한 요구를 효율적으로 충족하기 위한 최상의 배포 전략을 평가하고 있습니다.",
        "Question": "데이터의 배치 처리를 허용하면서 ML 모델을 실시간으로 제공하기에 가장 적합한 배포 방법은 무엇입니까?",
        "Options": {
            "1": "예측을 위해 Amazon SageMaker 실시간 엔드포인트를 활용하고, 배치 처리를 위해 SageMaker 배치 변환을 사용합니다.",
            "2": "실시간 예측을 위해 SageMaker 서버리스 엔드포인트를 구현하고, 배치 처리를 위해 AWS Batch를 사용합니다.",
            "3": "실시간 예측을 위해 SageMaker 비동기 엔드포인트를 설정하고, 배치 처리를 위해 AWS Glue를 사용합니다.",
            "4": "실시간 예측을 위해 AWS Lambda를 사용하고, 배치 처리를 위해 Amazon EMR을 배포합니다."
        },
        "Correct Answer": "예측을 위해 Amazon SageMaker 실시간 엔드포인트를 활용하고, 배치 처리를 위해 SageMaker 배치 변환을 사용합니다.",
        "Explanation": "Amazon SageMaker 실시간 엔드포인트를 활용하면 사용자 입력에 기반한 즉각적인 예측이 가능하며, SageMaker 배치 변환은 대량의 데이터 세트를 배치로 처리하기 위해 특별히 설계되었습니다. 이 조합은 실시간 및 배치 처리의 요구를 효과적으로 충족합니다.",
        "Other Options": [
            "AWS Lambda는 상당한 컴퓨팅 자원이나 대량의 페이로드가 필요한 ML 모델 예측을 처리하는 데 적합하지 않으며, Amazon EMR은 일반적으로 직접 모델 예측보다 빅 데이터 처리에 더 적합합니다.",
            "SageMaker 비동기 엔드포인트는 약간의 지연을 감내할 수 있는 요청을 위해 설계되었으며, 즉각적인 예측의 필요성과 일치하지 않습니다. AWS Glue는 주로 ETL 작업을 위한 것이며 모델 제공에 중점을 두지 않습니다.",
            "SageMaker 서버리스 엔드포인트는 배포 및 확장을 단순화하지만, 높은 부하에서 실시간 예측을 위한 최상의 성능을 제공하지 않을 수 있으며, AWS Batch는 실시간 추론에 적합하지 않습니다."
        ]
    },
    {
        "Question Number": "48",
        "Situation": "ML 엔지니어가 AWS에 배포된 ML 모델을 모니터링하고 유지 관리하는 임무를 맡았습니다. 모델이 효과적이고 비즈니스 목표에 부합하도록 보장하기 위해, 엔지니어는 특정 이벤트에 따라 재훈련 활동을 기록하고 트리거하기 위해 AWS CloudTrail을 활용하는 솔루션을 구현해야 합니다.",
        "Question": "ML 모델의 로깅, 모니터링 및 재훈련 호출을 위해 AWS CloudTrail을 사용하는 가장 좋은 접근 방식은 무엇입니까?",
        "Options": {
            "1": "Amazon CloudWatch Events를 사용하여 SageMaker 로그를 모니터링하고 필요할 때마다 수동으로 재훈련 프로세스를 호출합니다.",
            "2": "AWS CloudTrail을 설정하여 Amazon SageMaker와 관련된 API 호출을 기록하고, 특정 로그 이벤트에 따라 재훈련을 트리거하는 AWS Lambda 함수를 생성합니다.",
            "3": "AWS CloudTrail을 구성하여 S3 이벤트만 기록하고, 시간 간격에 따라 모델 재훈련 일정을 설정합니다.",
            "4": "AWS CloudTrail을 활용하여 SageMaker 인스턴스와의 모든 네트워크 트래픽을 기록하고, 재훈련 트리거를 분석합니다."
        },
        "Correct Answer": "AWS CloudTrail을 설정하여 Amazon SageMaker와 관련된 API 호출을 기록하고, 특정 로그 이벤트에 따라 재훈련을 트리거하는 AWS Lambda 함수를 생성합니다.",
        "Explanation": "이 접근 방식은 특정 이벤트에 따라 재훈련 프로세스를 자동화하기 위해 AWS CloudTrail과 AWS Lambda를 효과적으로 통합합니다. API 호출을 기록함으로써 엔지니어는 관련 활동을 모니터링하고 필요할 때 자동으로 재훈련을 호출할 수 있습니다.",
        "Other Options": [
            "Amazon CloudWatch Events를 사용하여 SageMaker 로그를 모니터링하는 것은 모니터링 전략의 일부가 될 수 있지만, 수동 호출에 의존하는 것은 모델 성능을 유지하는 데 효율적이지 않습니다.",
            "S3 이벤트만 기록하는 것은 모델의 성능이나 배포 변경 사항에 대한 포괄적인 관점을 제공하지 않습니다. 시간 기반 일정은 데이터나 모델 성능의 실시간 변화를 고려하지 않을 수 있습니다.",
            "모든 네트워크 트래픽을 기록하는 것은 과도하며, 모델 성능이나 재훈련 필요성과 직접적으로 연관되지 않아 재훈련 활동을 트리거하는 비현실적인 접근 방식입니다."
        ]
    },
    {
        "Question Number": "49",
        "Situation": "한 의료 기관이 Amazon SageMaker를 사용하여 기계 학습 모델을 훈련하기 위해 민감한 환자 데이터를 준비하고 있습니다. 데이터 프라이버시 규정을 준수하기 위해, 데이터가 기밀성을 유지하면서도 모델 훈련에 사용될 수 있도록 하는 기술을 구현해야 합니다.",
        "Question": "기계 학습 준비 단계에서 민감한 데이터를 보호하기 위해 기관이 구현해야 할 암호화 기술은 무엇입니까?",
        "Options": {
            "1": "데이터 세트의 민감한 필드를 모호하게 만들기 위해 데이터 마스킹 기술을 적용합니다.",
            "2": "Amazon S3에 업로드하기 전에 클라이언트 측 암호화를 사용하여 데이터를 암호화합니다.",
            "3": "모델 훈련 중 Amazon SageMaker의 내장 데이터 암호화 기능을 활용합니다.",
            "4": "Amazon S3와 함께 서버 측 암호화를 활용하여 데이터가 정지 상태에서 안전하게 보호됩니다."
        },
        "Correct Answer": "Amazon S3에 업로드하기 전에 클라이언트 측 암호화를 사용하여 데이터를 암호화합니다.",
        "Explanation": "클라이언트 측 암호화는 기관이 민감한 환자 데이터를 Amazon S3에 업로드하기 전에 암호화할 수 있게 하여 데이터가 기밀성을 유지하고 데이터 프라이버시 규정을 준수하도록 보장합니다. 이 방법은 암호화 키에 대한 완전한 제어를 제공하고 저장 및 전송 중에 데이터가 무단 접근으로부터 보호되도록 합니다.",
        "Other Options": [
            "Amazon SageMaker는 데이터에 대한 특정 내장 암호화 기능이 없으며, 데이터 보안을 위해 Amazon S3와 같은 기본 서비스에 의존하므로 이 옵션은 잘못되었습니다.",
            "데이터 마스킹 기술은 데이터를 모호하게 만드는 데 유용하지만, 원본 데이터에 여전히 접근할 수 있기 때문에 훈련 단계에서 데이터를 완전히 보호하지는 못합니다. 따라서 이 옵션은 민감한 환자 정보에 필요한 데이터 기밀성 수준을 제공하지 않습니다.",
            "Amazon S3와 함께 서버 측 암호화는 데이터가 정지 상태에서 안전하게 보호되지만, 업로드 과정에서 데이터를 보호하지 않으며 엄격한 데이터 프라이버시 요구 사항을 충족하지 못할 수 있습니다. 이 옵션은 데이터가 저장 서비스에 도달하기 전에 데이터 기밀성의 필요성을 해결하지 못합니다."
        ]
    },
    {
        "Question Number": "50",
        "Situation": "한 소매 회사가 고객 이탈을 예측하기 위해 기계 학습 모델을 개발했습니다. 이들은 모바일 앱 사용자에게 실시간으로 예측을 제공하기 위해 이 모델을 배포하고자 하며, 엔드포인트가 가변 트래픽 부하를 효율적으로 처리할 수 있도록 보장하고자 합니다.",
        "Question": "회사가 수신 요청 트래픽에 따라 자동으로 확장할 수 있는 실시간 추론 엔드포인트로 모델을 배포하기 위해 어떤 AWS 서비스 또는 기능을 사용해야 합니까?",
        "Options": {
            "1": "Amazon SageMaker Batch Transform",
            "2": "Amazon SageMaker Multi-Model Endpoints",
            "3": "Amazon SageMaker Real-Time Inference with Auto Scaling",
            "4": "Amazon SageMaker Asynchronous Inference"
        },
        "Correct Answer": "Amazon SageMaker Real-Time Inference with Auto Scaling",
        "Explanation": "Amazon SageMaker Real-Time Inference with Auto Scaling은 수요에 따라 모델을 제공하는 인스턴스 수를 자동으로 조정하여 가변 트래픽을 처리할 수 있는 모델 배포를 가능하게 합니다. 이를 통해 모델이 요청에 신속하게 응답하면서 비용을 최적화할 수 있습니다.",
        "Other Options": [
            "Amazon SageMaker Batch Transform은 배치 처리를 위해 설계되었으며, 여러 요청을 동시에 처리하기 때문에 실시간 추론에는 적합하지 않습니다.",
            "Amazon SageMaker Asynchronous Inference는 낮은 대기 시간이 중요하지 않은 시나리오에 사용되며, 요청을 백그라운드에서 처리하고 나중에 결과를 반환하므로 실시간 예측 요구 사항을 충족하지 않습니다.",
            "Amazon SageMaker Multi-Model Endpoints는 비용 절감을 위해 동일한 엔드포인트에서 여러 모델을 배포할 수 있게 하지만, 가변 트래픽을 효율적으로 처리하는 데 중요한 자동 확장 기능을 본질적으로 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "51",
        "Situation": "한 ML 엔지니어가 실시간 추론과 배치 처리 기능이 모두 필요한 기계 학습 모델을 배포하는 임무를 맡았습니다. 엔지니어는 리소스 사용을 최적화하고 비용을 효과적으로 관리하면서 두 가지 유형의 요청을 원활하게 처리할 수 있는 솔루션이 필요합니다. 이 솔루션은 또한 엔지니어가 수요에 따라 인프라를 자동으로 확장할 수 있도록 해야 합니다.",
        "Question": "실시간 추론과 배치 처리 요구 사항을 충족하면서 자동 확장을 허용하는 모델 배포에 가장 적합한 AWS 서비스는 무엇입니까?",
        "Options": {
            "1": "AWS Lambda",
            "2": "Amazon ECS with Fargate",
            "3": "Amazon SageMaker Batch Transform",
            "4": "Amazon SageMaker Endpoints"
        },
        "Correct Answer": "Amazon SageMaker Endpoints",
        "Explanation": "Amazon SageMaker Endpoints는 실시간 추론을 위한 기계 학습 모델 배포를 위한 완전 관리형 서비스를 제공합니다. 요청량에 따라 자동으로 확장할 수 있어 낮은 대기 시간 예측과 효율적인 리소스 활용이 필요한 애플리케이션에 적합합니다. 또한 SageMaker는 대규모 데이터 세트를 처리하기 위한 배치 변환을 지원하여 실시간 및 배치 처리 기능을 모두 제공합니다.",
        "Other Options": [
            "Amazon SageMaker Batch Transform은 데이터의 배치 처리를 위해 특별히 설계되었으며, 실시간 추론을 직접 지원하지 않습니다. 대규모 데이터 세트를 처리하는 데 유용하지만, 실시간 요청 요구 사항을 충족할 수 없습니다.",
            "AWS Lambda는 서버리스 컴퓨팅에 적합하며 실시간 추론에 사용할 수 있지만, 실행 시간과 메모리에 제한이 있어 더 큰 모델이나 복잡한 추론 프로세스에는 이상적이지 않을 수 있습니다.",
            "Amazon ECS with Fargate는 컨테이너화된 애플리케이션을 실행할 수 있으며 배치 및 실시간 작업을 모두 처리할 수 있지만, 기계 학습 배포를 위한 Amazon SageMaker의 완전 통합 기능에 비해 더 많은 관리 및 설정이 필요합니다."
        ]
    },
    {
        "Question Number": "52",
        "Situation": "ML 엔지니어가 AWS에 기계 학습 모델을 배포하는 임무를 맡았습니다. 이 배포는 인프라의 버전 관리 및 재현성을 지원해야 합니다. 팀은 배포 프로세스를 자동화하기 위해 다양한 코드로서의 인프라(IaC) 옵션을 고려하고 있습니다. 그들은 프로그래밍 언어의 유연성을 허용하고 기존 CI/CD 파이프라인과 잘 통합되는 솔루션을 원합니다.",
        "Question": "어떤 IaC 옵션이 팀의 유연성과 CI/CD 파이프라인 통합 요구 사항을 가장 잘 충족할까요?",
        "Options": {
            "1": "AWS Cloud Development Kit (AWS CDK)",
            "2": "Terraform",
            "3": "AWS CloudFormation",
            "4": "AWS SAM"
        },
        "Correct Answer": "AWS Cloud Development Kit (AWS CDK)",
        "Explanation": "AWS Cloud Development Kit (AWS CDK)는 친숙한 프로그래밍 언어를 사용하여 클라우드 인프라를 정의할 수 있게 해주며, 유연성을 제공하고 CI/CD 파이프라인과의 통합을 가능하게 합니다. 이는 배포 자동화를 원하면서 코드 품질과 버전 관리를 유지하려는 팀에게 강력한 선택이 됩니다.",
        "Other Options": [
            "AWS CloudFormation은 IaC를 위한 강력한 도구이지만 JSON 또는 YAML 템플릿에 제한되어 있어 AWS CDK에 비해 유연성이 떨어지고 CI/CD 파이프라인과 통합하기 어려울 수 있습니다.",
            "Terraform은 인기 있는 오픈 소스 IaC 도구이지만, AWS 서비스를 광범위하게 사용하는 팀에게는 AWS CDK만큼 AWS 서비스와 원활하게 통합되지 않을 수 있습니다.",
            "AWS SAM은 서버리스 애플리케이션을 위해 특별히 설계되었으므로, 팀이 더 전통적인 기계 학습 모델 배포를 진행하고 있다면 적합하지 않을 수 있습니다."
        ]
    },
    {
        "Question Number": "53",
        "Situation": "데이터 과학자가 역사적 데이터로 훈련된 기계 학습 모델의 성능을 평가하고 있습니다. 모델은 훈련 데이터셋에서 높은 정확도를 보이지만, 검증 데이터셋에서의 성능은 상당히 낮습니다. 데이터 과학자는 모델의 과적합 및 과소적합 문제를 이해하여 더 나은 모델 최적화를 원합니다.",
        "Question": "데이터 과학자가 모델이 과적합인지 과소적합인지 판단하기 위해 사용할 수 있는 방법은 무엇인가요?",
        "Options": {
            "1": "에포크에 따른 훈련 및 검증 손실의 학습 곡선을 분석합니다.",
            "2": "하이퍼파라미터 조정을 사용하여 모델 복잡성을 조정합니다.",
            "3": "교차 검증을 구현하여 다양한 하위 집합에서 모델의 안정성을 평가합니다.",
            "4": "특징 중요성 분석을 수행하여 관련 없는 특징을 확인합니다."
        },
        "Correct Answer": "에포크에 따른 훈련 및 검증 손실의 학습 곡선을 분석합니다.",
        "Explanation": "에포크에 따른 훈련 및 검증 손실의 학습 곡선을 분석하면 데이터 과학자가 모델이 과적합인지 과소적합인지 시각적으로 식별하는 데 도움이 됩니다. 훈련 손실이 계속 감소하는 반면 검증 손실이 증가하기 시작하면 과적합을 나타냅니다. 반대로 두 손실 모두 높다면 과소적합을 나타냅니다.",
        "Other Options": [
            "특징 중요성 분석을 수행하는 것은 모델의 예측에 기여하는 특징을 이해하는 데 도움이 되지만, 모델이 과적합인지 과소적합인지 직접적으로 나타내지는 않습니다.",
            "교차 검증을 구현하는 것은 일반적으로 모델 성능을 평가하는 좋은 방법이지만, 손실 곡선 측면에서 과적합이나 과소적합에 대한 직접적인 통찰을 제공하지는 않습니다.",
            "하이퍼파라미터 조정을 사용하는 것은 모델 성능을 최적화하는 데 도움이 될 수 있지만, 과적합이나 과소적합을 식별하는 직접적인 방법은 아닙니다. 문제를 식별한 후 성능 개선에 도움이 될 수 있습니다."
        ]
    },
    {
        "Question Number": "54",
        "Situation": "기계 학습 엔지니어가 협업 환경에서 다양한 기계 학습 모델과 관련 코드를 위한 버전 관리를 설정하는 임무를 맡았습니다. 팀은 코드 변경을 효율적으로 관리하고, 모델 버전을 추적하며, 팀원 간의 협업을 촉진할 필요가 있습니다.",
        "Question": "기계 학습 엔지니어가 ML 모델과 코드를 효과적으로 관리하기 위해 구현해야 할 도구 조합은 무엇인가요? (두 가지 선택)",
        "Options": {
            "1": "AWS CodeCommit",
            "2": "Jupyter Notebooks",
            "3": "GitHub",
            "4": "Apache Airflow",
            "5": "Amazon S3"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "GitHub",
            "AWS CodeCommit"
        ],
        "Explanation": "GitHub와 AWS CodeCommit은 모두 팀이 코드 변경을 추적하고 효과적으로 협업할 수 있도록 해주는 버전 관리 시스템입니다. GitHub는 오픈 소스 프로젝트에서 널리 사용되며 버전 관리를 위한 종합적인 플랫폼을 제공하는 반면, AWS CodeCommit은 다른 AWS 서비스와 잘 통합되는 완전 관리형 소스 제어 서비스로 기업 환경에 적합합니다.",
        "Other Options": [
            "Amazon S3는 주로 객체 저장 서비스이며 코드 리포지토리에 대한 버전 관리 기능을 제공하지 않습니다.",
            "Apache Airflow는 워크플로우를 위한 오케스트레이션 도구이며 코드나 모델의 버전 관리를 위해 설계되지 않았습니다.",
            "Jupyter Notebooks는 데이터 분석 및 시각화를 촉진하는 대화형 컴퓨팅 환경이지만 내장된 버전 관리 기능이 부족합니다."
        ]
    },
    {
        "Question Number": "55",
        "Situation": "금융 서비스 회사는 실시간 거래를 분석하여 사기 활동을 탐지하고자 합니다. 이들은 기계 학습 모델에 분류를 위해 데이터를 공급하기 전에 이 스트리밍 데이터를 효율적으로 변환하고 처리하기 위해 AWS 서비스를 사용하는 것을 고려하고 있습니다.",
        "Question": "최소한의 지연으로 스트리밍 거래 데이터를 변환하면서 확장성을 보장하는 데 가장 적합한 AWS 서비스 조합은 무엇입니까?",
        "Options": {
            "1": "데이터 저장을 위해 Amazon S3를 활용하고 분석 전에 AWS Glue를 사용하여 배치 변환을 수행합니다.",
            "2": "스트리밍 데이터를 처리하고 변환 및 분석을 위한 SQL 쿼리를 실행하기 위해 Amazon Redshift를 배포합니다.",
            "3": "거래 데이터를 저장하기 위해 Amazon RDS를 구현하고, 거의 실시간으로 데이터를 처리하기 위해 Amazon EMR과 Spark를 사용합니다.",
            "4": "데이터를 수집하기 위해 Amazon Kinesis Data Stream을 설정하고, 실시간 처리를 위해 AWS Lambda를 사용하며, 결과를 Amazon SageMaker로 전송하여 모델 추론을 수행합니다."
        },
        "Correct Answer": "데이터를 수집하기 위해 Amazon Kinesis Data Stream을 설정하고, 실시간 처리를 위해 AWS Lambda를 사용하며, 결과를 Amazon SageMaker로 전송하여 모델 추론을 수행합니다.",
        "Explanation": "이 옵션은 Amazon Kinesis를 활용하여 실시간으로 데이터를 수집하고 스트리밍하는 것으로, 저지연 처리에 필수적입니다. AWS Lambda는 이러한 스트림을 즉시 처리할 수 있어, Amazon SageMaker와의 통합을 통해 실시간 기계 학습 추론을 가능하게 하여 가장 효율적이고 확장 가능한 솔루션입니다.",
        "Other Options": [
            "Amazon S3와 AWS Glue를 사용하는 것은 배치 처리에 더 적합하며, 이는 실시간 사기 탐지에 이상적이지 않은 지연을 초래합니다.",
            "Amazon Redshift는 데이터 웨어하우징 및 분석에 최적화되어 있지만, 실시간 스트리밍 데이터 처리를 위해 설계되지 않아 즉각적인 거래 분석에 덜 적합합니다.",
            "Amazon RDS는 데이터를 저장할 수 있지만, 실시간 스트리밍 수집에 최적이 아니며, EMR과 Spark를 사용하는 것은 이 사용 사례에 불필요한 복잡성과 지연을 추가합니다."
        ]
    },
    {
        "Question Number": "56",
        "Situation": "한 의료 기관은 역사적인 환자 데이터를 기반으로 환자 재입원을 예측하는 기계 학습 모델을 개발하는 것을 고려하고 있습니다. 이 기관은 전자 건강 기록, 실험실 결과 및 인구 통계 정보 등 다양한 데이터 소스에 접근할 수 있습니다. 그러나 데이터의 품질과 완전성에 대한 몇 가지 문제를 확인했습니다.",
        "Question": "환자 재입원 예측을 위한 ML 모델 개발 가능성을 평가하기 위해 기관이 가장 먼저 취해야 할 행동은 무엇입니까?",
        "Options": {
            "1": "기존 데이터를 보완하기 위해 환자들로부터 추가 정보를 수집하는 설문 조사를 실시합니다.",
            "2": "사용 가능한 데이터의 품질과 완전성을 평가하여 잠재적인 격차를 식별합니다.",
            "3": "기존 데이터를 사용하여 ML 모델 개발을 시작하여 유용한 예측을 생성하는지 확인합니다.",
            "4": "환자 재입원 예측에 관한 관련 연구를 검토하여 문제의 복잡성을 분석합니다."
        },
        "Correct Answer": "사용 가능한 데이터의 품질과 완전성을 평가하여 잠재적인 격차를 식별합니다.",
        "Explanation": "사용 가능한 데이터의 품질과 완전성을 평가하는 것은 기계 학습 솔루션의 가능성을 결정하는 데 중요한 첫 단계입니다. 데이터 격차와 문제를 식별하면 기관이 모델 개발을 진행할 수 있는지, 아니면 추가 데이터 수집이나 전처리가 필요한지를 이해하는 데 도움이 됩니다.",
        "Other Options": [
            "데이터 품질을 이해하지 않고 ML 모델 개발을 시작하면 모델 성능이 저하되고 자원이 낭비될 수 있습니다. 모델이 학습할 충분하거나 정확한 데이터가 없을 수 있기 때문입니다.",
            "설문 조사를 실시하면 추가 데이터를 제공할 수 있지만, 첫 번째 단계로는 적합하지 않습니다. 기관은 먼저 기존 데이터가 사용 가능한지 확인해야 합니다.",
            "관련 연구를 분석하는 것은 문제의 복잡성에 대한 통찰력을 제공할 수 있지만, 프로젝트의 가능성을 직접적으로 다루지는 않습니다. 문제의 복잡성을 탐색하기 전에 먼저 데이터를 이해하는 것이 필수적입니다."
        ]
    },
    {
        "Question Number": "57",
        "Situation": "금융 서비스 회사는 고객 데이터를 기반으로 신용 점수를 예측하는 기계 학습 모델을 구축할 준비를 하고 있습니다. 이들은 CSV, JSON 및 Apache Parquet 등 다양한 데이터 형식을 보유하고 있습니다. 데이터 수집 과정은 모델 학습 파이프라인과의 높은 성능 및 호환성을 보장해야 합니다.",
        "Question": "최적의 수집 및 처리 효율성을 위해 ML 엔지니어가 선택해야 할 두 가지 데이터 형식은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "Apache Avro",
            "2": "RecordIO",
            "3": "JSON",
            "4": "CSV",
            "5": "Apache Parquet"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Apache Parquet",
            "Apache Avro"
        ],
        "Explanation": "Apache Parquet와 Apache Avro는 모두 대규모 데이터 처리 성능을 최적화하는 열 기반 저장 형식으로, Apache Spark와 같은 데이터 처리 프레임워크와 잘 어울립니다. 이들은 복잡한 데이터 유형과 스키마 진화를 지원하여 효율적인 데이터 수집 및 처리가 필요한 기계 학습 워크플로우에 이상적입니다.",
        "Other Options": [
            "JSON은 API에 자주 사용되는 유연한 형식이지만, Parquet나 Avro와 같은 열 기반 형식에 비해 성능이나 저장 효율성이 최적화되어 있지 않습니다, 특히 대규모 데이터셋에서.",
            "CSV는 널리 사용되는 데이터 형식이지만, 복잡한 데이터 유형에 대한 지원이 부족하고, 행 기반 저장 방식으로 인해 대량의 데이터를 처리할 때 성능 문제를 초래할 수 있습니다.",
            "RecordIO는 주로 Apache MXNet에서 스트리밍 데이터에 사용되는 형식으로, Parquet 및 Avro에 비해 일반적인 데이터 수집에 덜 일반적으로 사용됩니다."
        ]
    },
    {
        "Question Number": "58",
        "Situation": "한 소매 회사가 실시간 재고 관리를 위해 머신 러닝 모델을 배포했습니다. 최근 이들은 모델이 피크 시간대에 지연이 발생하여 비용이 증가하고 성능이 저하되는 것을 발견했습니다.",
        "Question": "이 머신 러닝 솔루션과 관련된 용량 문제를 해결하고 문제를 해결하기 위한 가장 효과적인 접근 방식은 무엇입니까?",
        "Options": {
            "1": "피크 시간대에 실시간 제약을 완화하기 위해 배치 처리 방식으로 전환합니다.",
            "2": "자동 스케일링을 고려하지 않고 피크 부하를 처리하기 위해 인스턴스 유형 크기를 늘립니다.",
            "3": "서비스 쿼터를 모니터링하지 않고 부하를 분산하기 위해 추가 모델 복제본을 배포합니다.",
            "4": "제공된 동시성 설정을 분석하고 사용 패턴에 따라 조정하여 성능과 비용을 최적화합니다."
        },
        "Correct Answer": "제공된 동시성 설정을 분석하고 사용 패턴에 따라 조정하여 성능과 비용을 최적화합니다.",
        "Explanation": "제공된 동시성 설정을 조정하면 컴퓨팅 리소스를 더 잘 관리할 수 있어 모델이 다양한 부하를 효율적으로 처리하면서 비용을 제어할 수 있습니다.",
        "Other Options": [
            "인스턴스 유형 크기를 단순히 늘리는 것은 피크 시간대의 부하 관리 및 성능과 관련된 근본적인 문제를 해결하지 않고 비용만 증가시킬 수 있습니다.",
            "추가 모델 복제본을 배포하면 부하를 분산하는 데 도움이 될 수 있지만, 서비스 쿼터를 모니터링하지 않으면 한계를 초과하고 예상치 못한 비용이 발생할 수 있습니다.",
            "배치 처리 방식으로 전환하는 것은 재고 관리에 중요한 실시간 처리의 즉각적인 필요를 해결하지 못할 수 있으며, 의사 결정의 지연을 초래할 수 있습니다."
        ]
    },
    {
        "Question Number": "59",
        "Situation": "한 금융 서비스 회사가 사기 탐지를 위해 Amazon SageMaker를 사용하여 머신 러닝 모델을 배포하고 있습니다. 모델의 추론 결과는 성능 지표를 실시간으로 추적하는 모니터링 대시보드로 전송됩니다. 최근 팀은 잘못된 긍정의 급증을 발견하여 모델이 잘못된 예측을 하고 있을 수 있음을 나타냅니다. 모델의 정확성을 보장하고 운영 위험을 줄이기 위해 ML 엔지니어는 추론 결과를 효과적으로 모니터링하는 솔루션을 구현해야 합니다.",
        "Question": "ML 엔지니어는 모델의 성능을 모니터링하고 추론 결과의 이상을 감지하기 위해 어떤 접근 방식을 취해야 합니까?",
        "Options": {
            "1": "추론 결과를 주기적으로 수동으로 검토하기 위해 별도의 SageMaker 노트북 인스턴스를 생성합니다.",
            "2": "모델 추론 요청 및 응답을 분석하기 위해 모든 요청과 응답을 캡처하는 로깅 메커니즘을 구현합니다.",
            "3": "예측을 비교하고 불일치를 식별하기 위해 추가 모델 버전을 배포합니다.",
            "4": "AWS CloudWatch를 사용하여 모델의 예측 출력을 기반으로 사용자 정의 메트릭 및 경고를 설정합니다."
        },
        "Correct Answer": "AWS CloudWatch를 사용하여 모델의 예측 출력을 기반으로 사용자 정의 메트릭 및 경고를 설정합니다.",
        "Explanation": "AWS CloudWatch를 사용하면 모델 성능과 관련된 사용자 정의 메트릭을 실시간으로 모니터링할 수 있습니다. 잘못된 긍정 또는 기타 주요 성과 지표에 대한 임계값을 기반으로 경고를 설정함으로써 ML 엔지니어는 이상을 신속하게 감지하고 필요한 경우 수정 조치를 취할 수 있습니다.",
        "Other Options": [
            "로깅 메커니즘을 구현하는 것은 데이터를 캡처하는 데 유용하지만 실시간 모니터링이나 경고 기능을 제공하지 않습니다. 이는 이상 감지의 지연을 초래할 수 있습니다.",
            "별도의 SageMaker 노트북 인스턴스를 생성하여 수동 검토하는 것은 비효율적이고 시간이 많이 소요됩니다. 이 접근 방식은 문제의 적시 감지를 보장하지 않으며 인간의 개입에 의존합니다.",
            "비교를 위해 추가 모델 버전을 배포하는 것은 리소스를 많이 소모할 수 있으며 배포 프로세스를 복잡하게 만듭니다. 이는 기존 모델의 성능에 대한 즉각적인 통찰력을 제공하지 않을 수 있습니다."
        ]
    },
    {
        "Question Number": "60",
        "Situation": "한 금융 서비스 회사가 고객 이탈을 예측하기 위해 다양한 머신 러닝 알고리즘을 평가하고 있습니다. 이들은 인프라 비용에 대한 예산이 제한되어 있으며 성능과 운영 비용의 균형을 맞출 수 있는 모델을 선택해야 합니다. 이 회사는 모델 훈련 및 배포를 위해 AWS 서비스를 사용하는 것을 고려하고 있습니다.",
        "Question": "회사가 머신 러닝 모델을 선택하면서 비용을 최적화하기 위해 고려해야 할 두 가지 전략은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "AWS Lambda를 활용하여 수요에 따라 확장할 수 있는 경량 모델을 배포하여 유휴 리소스와 관련된 비용을 줄입니다.",
            "2": "특정 사용 사례에 맞게 비용과 성능이 최적화된 Amazon SageMaker에서 제공하는 사전 구축된 모델을 선택합니다.",
            "3": "모델 앙상블 기법을 구현합니다. 이는 종종 우수한 성능을 제공하지만 운영 비용이 증가할 수 있습니다.",
            "4": "비용과 관계없이 복잡한 모델(예: 딥 러닝)의 하이퍼파라미터를 최적화하기 위해 Amazon SageMaker 자동 모델 튜닝을 사용합니다.",
            "5": "단순성과 비용 효율성을 위해 선형 회귀 또는 결정 트리와 같은 낮은 계산 요구 사항을 가진 알고리즘을 우선시합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "단순성과 비용 효율성을 위해 선형 회귀 또는 결정 트리와 같은 낮은 계산 요구 사항을 가진 알고리즘을 우선시합니다.",
            "특정 사용 사례에 맞게 비용과 성능이 최적화된 Amazon SageMaker에서 제공하는 사전 구축된 모델을 선택합니다."
        ],
        "Explanation": "선형 회귀 또는 결정 트리와 같은 낮은 계산 요구 사항을 가진 알고리즘을 선택하면 회사가 인프라 비용을 최소화하면서도 만족스러운 예측 성능을 달성할 수 있습니다. 또한 특정 사용 사례에 맞게 최적화된 Amazon SageMaker의 사전 구축된 모델을 사용하면 개발 시간과 비용을 크게 줄일 수 있습니다.",
        "Other Options": [
            "복잡한 모델을 최적화하기 위해 Amazon SageMaker 자동 모델 튜닝을 사용하는 것은 필요한 계산 리소스 증가로 인해 비용이 더 높아질 수 있으며, 이는 회사의 예산 제약과 일치하지 않습니다.",
            "AWS Lambda를 통해 경량 모델을 배포하면 비용을 줄일 수 있지만, 모델이 Lambda가 효율적으로 처리할 수 없는 더 복잡한 계산을 요구하는 경우 모든 사용 사례에 적합하지 않을 수 있습니다.",
            "모델 앙상블 기법은 성능을 향상시킬 수 있지만, 일반적으로 훈련 및 리소스 사용에 대한 추가 비용이 발생하여 비용 최적화 목표와 모순됩니다."
        ]
    },
    {
        "Question Number": "61",
        "Situation": "클라우드 기반 머신 러닝 팀은 배포된 ML 모델의 비용을 모니터링하는 임무를 맡고 있습니다. 그들은 인프라가 잘 조직되어 있고 비용을 효과적으로 추적할 수 있기를 원합니다. 팀은 AWS 리소스 전반에 걸쳐 태깅 전략을 구현하기로 결정했습니다.",
        "Question": "효과적인 비용 모니터링을 준비하기 위해 팀이 구현해야 할 태깅 전략은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "프로덕션 또는 개발과 같은 환경을 나타내는 태그 적용.",
            "2": "액세스 제어 목적으로만 태그 사용.",
            "3": "더 나은 가시성을 위해 프로젝트 이름으로 리소스 태깅.",
            "4": "모든 리소스에 대해 표준화되지 않은 태그 생성.",
            "5": "각 리소스와 관련된 비용 센터를 나타내는 태그 구현."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "더 나은 가시성을 위해 프로젝트 이름으로 리소스 태깅.",
            "각 리소스와 관련된 비용 센터를 나타내는 태그 구현."
        ],
        "Explanation": "프로젝트 이름으로 리소스를 태깅하면 특정 프로젝트와 관련된 비용을 식별하고 분류하는 데 도움이 되어 비용 추적 및 관리가 용이해집니다. 마찬가지로, 비용 센터 정보를 태깅하는 것은 조직 내 재무 책임 및 예산 추적에 매우 중요합니다.",
        "Other Options": [
            "환경 태그를 적용하면 리소스의 사용 유형을 식별하는 데 도움이 될 수 있지만, 올바른 옵션만큼 효과적으로 비용 모니터링에 기여하지는 않습니다.",
            "액세스 제어를 위해서만 사용되는 태그는 비용 모니터링에 기여하지 않으며 리소스 추적의 잘못된 관리로 이어질 수 있습니다.",
            "비표준화된 태그를 생성하면 혼란과 비효율성을 초래할 수 있으며, 데이터 집계 및 의미 있는 통찰력을 생성하기 어려워집니다."
        ]
    },
    {
        "Question Number": "62",
        "Situation": "한 ML 엔지니어가 머신 러닝 모델을 프로덕션에 배포하는 임무를 맡고 있으며, 코드 변경 사항이 프로덕션 환경에 원활하게 반영되도록 배포 프로세스를 자동화하고자 합니다. 엔지니어는 ML 워크플로우의 CI/CD 파이프라인을 관리하기 위해 다양한 AWS 서비스를 고려하고 있습니다. 그들은 높은 통합성을 가지며 ML 모델의 버전 관리, 빌드 및 배포를 효율적으로 지원할 수 있는 도구를 선택해야 합니다.",
        "Question": "이 시나리오에서 ML 모델 배포 프로세스의 자동화를 가장 잘 촉진할 수 있는 AWS 서비스 조합은 무엇입니까?",
        "Options": {
            "1": "배포를 위해 AWS Lambda 활용, 버전 관리를 위해 AWS Elastic Beanstalk, 오케스트레이션을 위해 AWS CloudFormation 사용.",
            "2": "오케스트레이션을 위해 AWS CodePipeline, 아티팩트 빌드를 위해 AWS CodeBuild, 모델 배포를 위해 AWS CodeDeploy 사용.",
            "3": "모델 호스팅을 위해 Amazon SageMaker, 데이터 준비를 위해 AWS Glue, 워크플로우 오케스트레이션을 위해 AWS Step Functions 활용.",
            "4": "모델 서빙을 위해 Amazon EC2, 작업 스케줄링을 위해 AWS Batch, 구성 관리를 위해 AWS OpsWorks 활용."
        },
        "Correct Answer": "오케스트레이션을 위해 AWS CodePipeline, 아티팩트 빌드를 위해 AWS CodeBuild, 모델 배포를 위해 AWS CodeDeploy 사용.",
        "Explanation": "AWS CodePipeline, AWS CodeBuild 및 AWS CodeDeploy는 함께 작동하도록 특별히 설계되어 강력한 CI/CD 파이프라인을 생성합니다. CodePipeline은 워크플로를 오케스트레이션하고, CodeBuild는 코드를 컴파일하고 테스트를 실행하며, CodeDeploy는 다양한 컴퓨팅 서비스에 대한 배포 프로세스를 자동화하여 ML 모델 배포를 자동화하는 데 이상적인 조합입니다.",
        "Other Options": [
            "AWS Lambda는 일반적으로 모델 배포에 사용되지 않고 이벤트에 대한 응답으로 코드를 실행하는 데 사용됩니다. AWS Elastic Beanstalk는 서비스로서의 플랫폼이며 버전 관리를 제공하지 않습니다. AWS CloudFormation은 인프라를 코드로 관리하는 데 사용되므로 이 조합은 배포 자동화를 효과적으로 해결하지 않습니다.",
            "Amazon SageMaker는 모델 호스팅에 탁월하지만 전체 CI/CD 파이프라인을 포괄하지 않습니다. AWS Glue는 데이터 준비 도구이며 배포를 위한 것이 아니며, AWS Step Functions는 워크플로를 관리하지만 모델을 직접 배포하지 않습니다.",
            "Amazon EC2는 모델 서빙에 사용될 수 있지만 CodeDeploy의 자동화 이점 없이 수동 배포 프로세스를 요구합니다. AWS Batch는 배치 처리에 설계되었으며 실시간 모델 배포에는 적합하지 않으며, AWS OpsWorks는 ML 모델의 배포보다는 구성 관리에 더 중점을 둡니다."
        ]
    },
    {
        "Question Number": "63",
        "Situation": "한 금융 서비스 회사가 실시간 사기 탐지 시스템을 구현하고자 합니다. 그들은 다양한 출처에서 스트리밍 거래 데이터를 수집하고 즉각적인 분석을 위해 처리하고자 합니다. 팀은 이러한 스트리밍 소스에서 데이터 수집을 용이하게 하기 위해 여러 AWS 서비스를 고려하고 있습니다.",
        "Question": "팀이 실시간 머신 러닝 애플리케이션을 위해 스트리밍 데이터를 효율적으로 수집하고 처리하기 위해 사용해야 할 AWS 서비스는 무엇입니까?",
        "Options": {
            "1": "Amazon Kinesis Data Streams",
            "2": "AWS Lambda와 API Gateway",
            "3": "ETL을 위한 AWS Glue",
            "4": "배치 처리를 위한 Amazon S3"
        },
        "Correct Answer": "Amazon Kinesis Data Streams",
        "Explanation": "Amazon Kinesis Data Streams는 실시간 데이터 수집 및 처리를 위해 특별히 설계되어 스트리밍 데이터에 대한 저지연 액세스를 가능하게 하여, 들어오는 데이터에서 즉각적인 통찰력이 필요한 사기 탐지와 같은 애플리케이션에 이상적입니다.",
        "Other Options": [
            "배치 처리를 위한 Amazon S3는 데이터를 저장하고 배치로 처리하기 위해 설계되었으므로 실시간 데이터 수집에 적합하지 않으며, 이는 더 높은 지연을 초래합니다.",
            "AWS Lambda와 API Gateway는 주로 이벤트에 대한 응답으로 코드를 실행하는 데 사용되지만, 실시간 처리를 위해 중요한 효율적인 스트리밍 데이터 수집에 중점을 두지 않습니다.",
            "ETL을 위한 AWS Glue는 주로 분석을 위한 데이터 변환 및 준비에 사용되지만, 즉각적인 사기 탐지를 위해 필요한 실시간 스트리밍 수집에 최적화되어 있지 않습니다."
        ]
    },
    {
        "Question Number": "64",
        "Situation": "ML 엔지니어가 머신 러닝 모델 훈련을 위한 데이터셋을 준비하고 있습니다. 데이터셋에는 여러 개의 결측값과 결과를 왜곡할 수 있는 몇 가지 이상치가 포함되어 있습니다.",
        "Question": "엔지니어가 데이터셋의 품질을 향상시키기 위해 어떤 기법을 사용해야 합니까? (두 가지 선택)",
        "Options": {
            "1": "범주형 변수 인코딩",
            "2": "이상치 탐지 및 처리",
            "3": "결측값 대체",
            "4": "데이터 범위 정규화",
            "5": "중복 항목 제거"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "결측값 대체",
            "이상치 탐지 및 처리"
        ],
        "Explanation": "결측값 대체는 모델이 모든 사용 가능한 데이터를 활용할 수 있도록 하여 귀중한 정보를 잃지 않도록 도와줍니다. 이상치 탐지 및 처리는 결과 왜곡을 피하기 위해 중요하며, 이상치는 모델 성능과 예측에 상당한 영향을 미칠 수 있습니다.",
        "Other Options": [
            "중복 항목 제거는 데이터 무결성을 위해 중요하지만, 결측값이나 이상치 문제를 해결하지 않으므로 품질 예측에 중요한 요소는 아닙니다.",
            "데이터 범위 정규화는 모델 훈련을 개선할 수 있지만, 결측값이나 이상치 문제를 직접적으로 해결하지 않으며, 이는 먼저 해결해야 할 문제입니다.",
            "범주형 변수 인코딩은 머신 러닝 모델을 위한 데이터 준비에 필요한 단계이지만, 결측 데이터나 이상치를 처리하지 않으므로 이 시나리오에서 주요 관심사는 아닙니다."
        ]
    },
    {
        "Question Number": "65",
        "Situation": "데이터 과학자는 구독 기반 서비스의 고객 이탈을 예측하는 모델을 개발하는 임무를 맡고 있습니다. 과학자는 높은 예측 정확도를 제공할 뿐만 아니라 고객 이탈에 기여하는 요인을 이해할 수 있도록 모델의 해석 가능성을 허용하는 알고리즘을 선택해야 합니다.",
        "Question": "이 시나리오에 가장 적합한 머신 러닝 알고리즘은 무엇입니까?",
        "Options": {
            "1": "Random Forest",
            "2": "Support Vector Machine",
            "3": "K-Means Clustering",
            "4": "Linear Regression"
        },
        "Correct Answer": "Random Forest",
        "Explanation": "Random Forest는 높은 정확도를 제공하는 앙상블 학습 방법으로, 특성 중요도 지표를 통해 해석 가능성을 제공하여 고객 이탈에 기여하는 요인을 이해하는 데 적합합니다.",
        "Other Options": [
            "Support Vector Machine은 일반적으로 분류 작업에 효과적이지만 Random Forest에 비해 해석 가능성이 부족하여 이 시나리오에서 기여 요인을 이해하는 데 덜 적합합니다.",
            "K-Means Clustering은 클러스터링을 위한 비지도 학습 알고리즘으로, 예측보다는 클러스터링에 사용됩니다. 이 경우 고객 이탈을 예측하는 기능을 제공하지 않습니다.",
            "Linear Regression은 결과 예측에 사용할 수 있지만, 고객 이탈 데이터에 존재할 수 있는 비선형 패턴을 효과적으로 포착하지 못할 수 있으며, Random Forest만큼 복잡한 관계를 잘 포착하지 못할 수 있습니다."
        ]
    }
]