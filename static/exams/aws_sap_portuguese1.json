[
    {
        "Question Number": "1",
        "Situation": "Uma empresa está executando um aplicativo web em uma frota de instâncias Amazon EC2 em um grupo de Auto Scaling. O aplicativo apresenta padrões de tráfego variáveis ao longo do dia, com picos de carga ocorrendo durante o horário comercial. A empresa precisa garantir que o aplicativo possa escalar adequadamente para lidar com a carga aumentada, minimizando os custos durante as horas de menor movimento. O arquiteto de soluções precisa implementar uma política de Auto Scaling que responda efetivamente às mudanças na demanda.",
        "Question": "Qual política de Auto Scaling o arquiteto de soluções deve implementar para otimizar a escalabilidade das instâncias EC2 com base na carga do aplicativo, garantindo eficiência de custos?",
        "Options": {
            "1": "Implementar uma política de escalonamento de rastreamento de metas que ajusta o número de instâncias com base na média de utilização da CPU.",
            "2": "Configurar uma política de escalonamento programado que adiciona instâncias em um horário específico a cada dia, sem considerar a demanda real.",
            "3": "Usar uma política de escalonamento em etapas que aumenta o número de instâncias com base em limites específicos de métricas de tráfego de rede.",
            "4": "Configurar uma política de escalonamento simples que escala apenas quando a utilização da CPU cai abaixo de um nível base."
        },
        "Correct Answer": "Implementar uma política de escalonamento de rastreamento de metas que ajusta o número de instâncias com base na média de utilização da CPU.",
        "Explanation": "Uma política de escalonamento de rastreamento de metas ajusta automaticamente o número de instâncias EC2 para manter um nível especificado de utilização da CPU, permitindo escalonamento dinâmico em resposta à carga real. Essa abordagem otimiza o desempenho enquanto controla os custos, escalando para baixo durante períodos de baixa demanda.",
        "Other Options": [
            "Uma política de escalonamento programado não leva em conta as flutuações reais da demanda e pode levar a superprovisionamento ou subprovisionamento de recursos, resultando em custos desnecessários ou problemas de desempenho.",
            "Embora uma política de escalonamento em etapas baseada em tráfego de rede possa funcionar, pode não correlacionar diretamente com o desempenho do aplicativo e pode levar a atrasos nas ações de escalonamento, especialmente se os padrões de tráfego forem imprevisíveis.",
            "Uma política de escalonamento simples que escala apenas com base na utilização da CPU não permite escalonamento proativo durante a demanda máxima, o que pode resultar em desempenho degradado e uma experiência do usuário insatisfatória."
        ]
    },
    {
        "Question Number": "2",
        "Situation": "Uma empresa de varejo deseja melhorar a experiência do cliente usando Amazon Rekognition para analisar feeds de vídeo de suas lojas. O objetivo é identificar a demografia dos clientes, rastrear o fluxo de pessoas e detectar qualquer conteúdo inadequado em tempo real. A empresa precisa garantir que a solução seja eficiente e econômica.",
        "Question": "Qual das seguintes abordagens a empresa deve adotar para implementar a análise de vídeo em tempo real usando Amazon Rekognition, enquanto adere às melhores práticas?",
        "Options": {
            "1": "A empresa deve usar Amazon Rekognition Video para analisar segmentos de vídeo armazenados no S3 e consultar periodicamente os resultados para avaliar a demografia dos clientes e o fluxo de pessoas.",
            "2": "A empresa deve configurar um Amazon Kinesis Data Stream para ingerir feeds de vídeo em tempo real e acionar o Amazon Rekognition Video para analisar os streams em busca de insights e conteúdo inadequado.",
            "3": "A empresa deve implementar um aplicativo de processamento de vídeo personalizado que use FFmpeg para analisar os feeds de vídeo e extrair insights antes de enviar os dados para o Amazon Rekognition para validação.",
            "4": "A empresa deve executar o Amazon Rekognition localmente usando o dispositivo AWS Snowball Edge para analisar feeds de vídeo localmente e, em seguida, enviar os resultados para a AWS para processamento adicional."
        },
        "Correct Answer": "A empresa deve configurar um Amazon Kinesis Data Stream para ingerir feeds de vídeo em tempo real e acionar o Amazon Rekognition Video para analisar os streams em busca de insights e conteúdo inadequado.",
        "Explanation": "Usar Amazon Kinesis Data Streams permite que a empresa processe feeds de vídeo em tempo real de forma eficiente. Ao integrar Kinesis com Amazon Rekognition Video, a empresa pode analisar o conteúdo do vídeo imediatamente à medida que é ingerido, fornecendo insights oportunos e garantindo a detecção de conteúdo inadequado em tempo real.",
        "Other Options": [
            "Analisar segmentos de vídeo armazenados no S3 não fornece insights em tempo real, pois haveria um atraso entre a gravação e a análise, tornando-o inadequado para melhorias imediatas na experiência do cliente.",
            "Usar uma solução local com AWS Snowball Edge pode não aproveitar todas as capacidades do Amazon Rekognition e também complica a arquitetura ao introduzir etapas adicionais para processamento e upload de resultados.",
            "Implementar um aplicativo de processamento de vídeo personalizado pode levar a uma complexidade e sobrecarga de manutenção aumentadas, além de não utilizar as capacidades especializadas do Amazon Rekognition, que é projetado especificamente para análise de imagens e vídeos."
        ]
    },
    {
        "Question Number": "3",
        "Situation": "Uma empresa de streaming de mídia está utilizando Amazon CloudFront para entregar conteúdo armazenado no Amazon S3. Eles têm usado Origin Access Identity (OAI) para proteger seu bucket S3, mas estão enfrentando desafios com configurações de políticas e métodos HTTP. Para melhorar sua segurança e expandir a funcionalidade, eles decidem explorar o Origin Access Control (OAC) para suas distribuições CloudFront. O arquiteto de soluções precisa determinar as principais vantagens de fazer a transição para OAC em vez de OAI para seu caso de uso.",
        "Question": "Qual das seguintes opções descreve um benefício principal de usar Origin Access Control (OAC) em vez de Origin Access Identity (OAI) no Amazon CloudFront?",
        "Options": {
            "1": "OAI fornece melhores práticas de segurança com credenciais de curto prazo e rotações frequentes de credenciais em comparação com OAC.",
            "2": "OAC restringe o acesso a origens S3 permitindo que apenas distribuições CloudFront designadas acessem o conteúdo.",
            "3": "OAC suporta apenas objetos S3 que não estão criptografados, garantindo compatibilidade com todas as regiões da AWS.",
            "4": "OAC permite configurações de políticas granulares e suporta todos os métodos HTTP, incluindo PUT e DELETE."
        },
        "Correct Answer": "OAC restringe o acesso a origens S3 permitindo que apenas distribuições CloudFront designadas acessem o conteúdo.",
        "Explanation": "Origin Access Control (OAC) melhora a segurança ao permitir acesso a origens S3 exclusivamente para distribuições CloudFront especificadas, limitando assim a exposição e melhorando o modelo de segurança em comparação com OAI.",
        "Other Options": [
            "Embora OAC permita suporte a todos os métodos HTTP, incluindo PUT e DELETE, ele não fornece especificamente configurações de políticas granulares, tornando essa afirmação enganosa.",
            "OAC suporta objetos S3 que estão criptografados e permite acesso a todas as regiões da AWS, portanto, essa opção está incorreta, pois distorce as capacidades do OAC.",
            "OAC é projetado para incorporar melhores práticas de segurança do que OAI, incluindo credenciais de curto prazo, portanto, essa opção afirma incorretamente o oposto."
        ]
    },
    {
        "Question Number": "4",
        "Situation": "Um aplicativo de saúde implantado na AWS Cloud precisa garantir que os dados sensíveis dos pacientes estejam seguros, permitindo ao mesmo tempo que usuários autorizados acessem o sistema. O aplicativo utiliza uma Virtual Private Cloud (VPC) com várias sub-redes em diferentes Zonas de Disponibilidade. Como Arquiteto de Soluções, você é responsável por configurar a rede para atender aos requisitos de conformidade e segurança de forma eficaz.",
        "Question": "Quais configurações de rede você deve implementar para garantir acesso seguro ao aplicativo enquanto protege os dados sensíveis? (Selecione Dois)",
        "Options": {
            "1": "Configurar um grupo de segurança para permitir tráfego de entrada apenas de endereços IP específicos usados por usuários autorizados.",
            "2": "Criar uma tabela de rotas que permita apenas tráfego das sub-redes privadas para as sub-redes públicas.",
            "3": "Usar um ACL de rede para permitir tráfego de entrada de faixas CIDR específicas para as sub-redes do aplicativo.",
            "4": "Implementar um ACL de rede que nega todo o tráfego de entrada, bloqueando assim todo o acesso.",
            "5": "Configurar grupos de segurança que permitam tráfego para o aplicativo de todos os endereços IP na porta 80."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Configurar um grupo de segurança para permitir tráfego de entrada apenas de endereços IP específicos usados por usuários autorizados.",
            "Usar um ACL de rede para permitir tráfego de entrada de faixas CIDR específicas para as sub-redes do aplicativo."
        ],
        "Explanation": "Usar um grupo de segurança para permitir tráfego de entrada apenas de endereços IP específicos garante que apenas usuários autorizados possam acessar o aplicativo de saúde, aumentando assim a segurança. Além disso, implementar um ACL de rede para permitir tráfego de faixas CIDR específicas fornece uma camada extra de segurança no nível da sub-rede, permitindo que apenas fontes confiáveis acessem os recursos.",
        "Other Options": [
            "Criar uma tabela de rotas que permita apenas tráfego de sub-redes privadas para sub-redes públicas não fornece segurança para dados sensíveis, pois não controla quem pode acessar o aplicativo.",
            "Implementar um ACL de rede que nega todo o tráfego de entrada bloquearia todo o acesso, incluindo de usuários autorizados, tornando o aplicativo inacessível.",
            "Configurar grupos de segurança que permitam tráfego de todos os endereços IP na porta 80 exporia o aplicativo a potenciais ataques, pois permitiria acesso irrestrito a qualquer pessoa na internet."
        ]
    },
    {
        "Question Number": "5",
        "Situation": "Uma empresa de tecnologia em saúde está desenvolvendo um aplicativo móvel que permite aos usuários rastrear suas atividades de fitness e métricas de saúde. O aplicativo requer atualizações em tempo real sobre os dados do usuário e deve fornecer capacidades offline para garantir uma experiência contínua. A equipe de desenvolvimento está considerando usar AWS AppSync para facilitar a gestão de dados de várias fontes, incluindo um banco de dados NoSQL para perfis de usuários e funções AWS Lambda para processamento de dados personalizado. Eles querem garantir que, quando os usuários ficarem offline, seus dados ainda sejam acessíveis e quaisquer alterações feitas enquanto estiverem offline sejam sincronizadas assim que se reconectarem. A equipe também está preocupada em lidar com conflitos que podem surgir durante a sincronização de dados.",
        "Question": "Qual é a maneira mais eficaz de implementar o AWS AppSync para atender aos requisitos do aplicativo para acesso a dados em tempo real, capacidades offline e resolução de conflitos?",
        "Options": {
            "1": "Integrar o AWS AppSync com um banco de dados Amazon RDS e implementar uma API personalizada para gerenciar atualizações em tempo real, acesso offline e resolução de conflitos manualmente.",
            "2": "Configurar o AWS AppSync com um modelo de assinatura para fornecer atualizações em tempo real e habilitar a resolução de conflitos usando os mecanismos integrados do AppSync, garantindo acesso local aos dados para uso offline.",
            "3": "Usar o AWS AppSync com um mecanismo de polling para buscar atualizações em intervalos regulares e implementar uma solução personalizada para armazenamento offline e sincronização sem resolução de conflitos integrada.",
            "4": "Implantar o AWS AppSync em conjunto com o Amazon S3 para armazenar todos os dados dos usuários e contar com o Amazon CloudFront para entregar dados aos usuários, o que não suporta atualizações em tempo real ou acesso offline."
        },
        "Correct Answer": "Configurar o AWS AppSync com um modelo de assinatura para fornecer atualizações em tempo real e habilitar a resolução de conflitos usando os mecanismos integrados do AppSync, garantindo acesso local aos dados para uso offline.",
        "Explanation": "Usar o AWS AppSync com um modelo de assinatura permite que atualizações em tempo real sejam enviadas para os clientes, garantindo que os usuários tenham sempre acesso aos dados mais recentes. Além disso, o suporte integrado do AppSync para capacidades offline e resolução de conflitos simplifica a implementação, permitindo que o aplicativo lide com alterações de dados de forma contínua quando a conectividade for restaurada.",
        "Other Options": [
            "Usar um mecanismo de polling não forneceria atualizações em tempo real, que é um requisito crítico para o aplicativo. Além disso, soluções personalizadas para armazenamento offline e sincronização podem ser complexas e propensas a erros em comparação com o aproveitamento dos recursos integrados do AppSync.",
            "Implantar o AWS AppSync apenas com o Amazon S3 não se alinha à necessidade de atualizações em tempo real, pois o S3 não é projetado para interações dinâmicas de dados. Além disso, o CloudFront serve principalmente conteúdo estático e não facilita a comunicação em tempo real.",
            "Integrar o AWS AppSync com um banco de dados Amazon RDS enquanto gerencia manualmente atualizações e resolução de conflitos adiciona complexidade desnecessária e pode levar a problemas potenciais. Essa abordagem não aproveita todas as capacidades do AppSync, que é projetado para simplificar essas tarefas."
        ]
    },
    {
        "Question Number": "6",
        "Situation": "Uma empresa de serviços financeiros opera um aplicativo crítico que processa transações em tempo real. Para garantir alta disponibilidade e minimizar o tempo de inatividade, a empresa implementa monitoramento centralizado usando AWS CloudWatch e AWS CloudTrail. O aplicativo é projetado para se recuperar automaticamente de falhas usando serviços da AWS. (Selecione Dois)",
        "Question": "Quais das seguintes estratégias a empresa deve implementar para se recuperar proativamente de falhas no sistema?",
        "Options": {
            "1": "Implementar regras do AWS Config para monitorar conformidade e acionar remediação.",
            "2": "Configurar Eventos do CloudWatch para detectar mudanças no estado do sistema e invocar processos de recuperação.",
            "3": "Habilitar Alarmes do CloudWatch para acionar funções Lambda para ações de auto-cura.",
            "4": "Integrar Logs do CloudWatch com o Amazon SNS para enviar notificações de erros críticos.",
            "5": "Usar o AWS CloudTrail para registrar todas as chamadas de API apenas para fins de auditoria."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Habilitar Alarmes do CloudWatch para acionar funções Lambda para ações de auto-cura.",
            "Configurar Eventos do CloudWatch para detectar mudanças no estado do sistema e invocar processos de recuperação."
        ],
        "Explanation": "Habilitar Alarmes do CloudWatch para acionar funções Lambda permite ações de auto-cura automatizadas quando limites específicos são ultrapassados, garantindo recuperação proativa. Configurar Eventos do CloudWatch para detectar mudanças no estado do sistema também pode invocar processos de recuperação, permitindo que o sistema reaja a falhas à medida que ocorrem.",
        "Other Options": [
            "Usar o AWS CloudTrail apenas para auditoria não contribui para a recuperação proativa, pois é focado principalmente em registrar chamadas de API e não aciona nenhuma ação.",
            "Integrar Logs do CloudWatch com o Amazon SNS para notificações é útil para alertas, mas não contribui diretamente para processos de recuperação automatizados.",
            "Implementar regras do AWS Config ajuda a manter a conformidade, mas não aciona automaticamente ações de recuperação em resposta a falhas."
        ]
    },
    {
        "Question Number": "7",
        "Situation": "Uma empresa de serviços financeiros está enfrentando problemas de desempenho com sua solução de banco de dados atual, que é usada principalmente para processamento transacional. Eles estão buscando melhorar o desempenho de seu aplicativo enquanto garantem conformidade com os padrões da indústria. A empresa possui padrões de acesso a dados diversos, incluindo análises em tempo real, processamento de transações e armazenamento de documentos. Eles querem identificar oportunidades para aproveitar bancos de dados projetados especificamente para suas cargas de trabalho.",
        "Question": "Qual das seguintes estratégias a empresa deve implementar para otimizar sua arquitetura de banco de dados para as cargas de trabalho específicas mencionadas?",
        "Options": {
            "1": "Implantar um único cluster Amazon ElastiCache para lidar com todos os padrões de acesso a dados para melhorar o desempenho.",
            "2": "Utilizar Amazon Aurora para processamento transacional, Amazon DynamoDB para análises em tempo real e Amazon DocumentDB para armazenamento de documentos.",
            "3": "Migrar todos os dados existentes para uma única instância Amazon RDS para simplificar a gestão e a manutenção.",
            "4": "Implementar Amazon S3 com Athena para todas as necessidades de armazenamento e consulta de dados para reduzir custos."
        },
        "Correct Answer": "Utilizar Amazon Aurora para processamento transacional, Amazon DynamoDB para análises em tempo real e Amazon DocumentDB para armazenamento de documentos.",
        "Explanation": "Essa abordagem aproveita bancos de dados projetados especificamente para os casos de uso, garantindo desempenho e escalabilidade ideais. Amazon Aurora oferece alta capacidade para cargas de trabalho transacionais, DynamoDB oferece acesso de baixa latência para análises em tempo real, e DocumentDB é projetado para gerenciar dados baseados em documentos, atendendo assim aos diversos requisitos da empresa de forma eficiente.",
        "Other Options": [
            "Migrar todos os dados para uma única instância Amazon RDS pode simplificar a gestão, mas pode levar a gargalos de desempenho, pois não atende aos diferentes padrões de acesso e requisitos das cargas de trabalho.",
            "Implantar um único cluster Amazon ElastiCache não é adequado, pois é usado principalmente para cache e não fornece um armazenamento de dados persistente necessário para processamento transacional e armazenamento de documentos.",
            "Implementar Amazon S3 com Athena não é ideal para cargas de trabalho transacionais, pois S3 é um serviço de armazenamento e Athena é um serviço de consulta. Essa combinação carece das capacidades transacionais necessárias e do desempenho exigido para os casos de uso específicos da empresa."
        ]
    },
    {
        "Question Number": "8",
        "Situation": "Uma organização de saúde precisa garantir a disponibilidade contínua de seu aplicativo de gerenciamento de pacientes hospedado na AWS. O aplicativo é crítico para as operações diárias e deve permanecer funcional durante interrupções ou falhas regionais. A organização está buscando projetar uma arquitetura que forneça alta disponibilidade e tolerância a falhas.",
        "Question": "Qual das seguintes estratégias de design ajudaria a alcançar a disponibilidade do aplicativo e da infraestrutura durante uma interrupção? (Selecione Dois)",
        "Options": {
            "1": "Aproveitar Amazon RDS com uma implantação Multi-AZ para a camada de banco de dados para aumentar a disponibilidade.",
            "2": "Implantar o aplicativo em várias regiões da AWS com o Route 53 para failover de DNS.",
            "3": "Implementar um único Elastic Load Balancer (ELB) em uma única Zona de Disponibilidade para gerenciar o tráfego.",
            "4": "Utilizar funções AWS Lambda com um bucket S3 para armazenar dados do aplicativo e gerenciar o armazenamento.",
            "5": "Usar instâncias Amazon EC2 em um grupo de Auto Scaling em várias Zonas de Disponibilidade dentro de uma única região."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Implantar o aplicativo em várias regiões da AWS com o Route 53 para failover de DNS.",
            "Aproveitar Amazon RDS com uma implantação Multi-AZ para a camada de banco de dados para aumentar a disponibilidade."
        ],
        "Explanation": "Implantar o aplicativo em várias regiões da AWS com o Route 53 para failover de DNS permite redundância geográfica, garantindo que, se uma região falhar, o tráfego possa ser redirecionado automaticamente para outra região. Além disso, usar Amazon RDS com uma implantação Multi-AZ fornece failover automático para uma instância de espera em outra Zona de Disponibilidade, aumentando a disponibilidade e resiliência do banco de dados a falhas de infraestrutura.",
        "Other Options": [
            "Usar instâncias EC2 em um grupo de Auto Scaling em várias Zonas de Disponibilidade dentro de uma única região oferece algum nível de disponibilidade, mas não protege contra interrupções regionais. Uma falha em toda a região ainda pode levar a tempo de inatividade do aplicativo.",
            "Implementar um único Elastic Load Balancer em uma única Zona de Disponibilidade limita a redundância. Se essa Zona de Disponibilidade sofrer uma interrupção, o aplicativo se tornará indisponível, contradizendo os objetivos de alta disponibilidade e tolerância a falhas.",
            "Utilizar funções AWS Lambda com um bucket S3 para gerenciamento de dados do aplicativo não aborda a disponibilidade do aplicativo de forma abrangente. Embora essa abordagem possa ser parte de uma solução, não melhora especificamente a disponibilidade do aplicativo em si durante interrupções."
        ]
    },
    {
        "Question Number": "9",
        "Situation": "Uma startup está desenvolvendo um aplicativo baseado em microserviços que será executado em contêineres. A equipe de desenvolvimento está procurando uma solução que permita implantar, gerenciar e escalar seus aplicativos em contêineres com mínima sobrecarga operacional. Eles querem se concentrar no desenvolvimento de seu aplicativo sem se preocupar com a infraestrutura subjacente.",
        "Question": "Qual das seguintes opções é a melhor escolha para gerenciar as necessidades de orquestração de contêineres da startup?",
        "Options": {
            "1": "Utilizar Amazon EKS com instâncias spot para economizar custos enquanto executa um serviço Kubernetes gerenciado.",
            "2": "Configurar um cluster Docker Swarm autogerenciado em instâncias EC2 para orquestrar os contêineres.",
            "3": "Implantar Kubernetes em instâncias Amazon EC2 e gerenciar o cluster manualmente para orquestração de contêineres.",
            "4": "Usar Amazon ECS com Fargate para executar contêineres sem gerenciar as instâncias EC2 subjacentes."
        },
        "Correct Answer": "Usar Amazon ECS com Fargate para executar contêineres sem gerenciar as instâncias EC2 subjacentes.",
        "Explanation": "Amazon ECS com Fargate permite que a startup execute contêineres sem precisar gerenciar a infraestrutura subjacente. Essa abordagem sem servidor oferece à equipe a flexibilidade de se concentrar no desenvolvimento de seu aplicativo enquanto a AWS cuida da escalabilidade e gerenciamento do ambiente de contêineres.",
        "Other Options": [
            "Implantar Kubernetes em instâncias Amazon EC2 requer uma sobrecarga operacional significativa para gerenciar o cluster, incluindo atualizações, escalonamento e configuração, o que contradiz a exigência da startup de minimizar a gestão operacional.",
            "Usar Amazon EKS com instâncias spot pode economizar custos, mas ainda requer que a equipe gerencie a configuração e a configuração do Kubernetes, o que adiciona complexidade desnecessária, dada sua vontade de ter uma sobrecarga operacional mínima.",
            "Configurar um cluster Docker Swarm autogerenciado em instâncias EC2 envolve consideráveis responsabilidades de gerenciamento e manutenção, o que vai contra o objetivo da startup de se concentrar no desenvolvimento de aplicativos sem o fardo da gestão da infraestrutura."
        ]
    },
    {
        "Question Number": "10",
        "Situation": "Uma equipe de desenvolvimento de software está trabalhando em uma aplicação de microserviços hospedada na AWS. A equipe usa o AWS CodeCommit para gerenciar seu código-fonte e o AWS CodeBuild para automatizar o processo de construção e teste. A aplicação requer acesso a um banco de dados hospedado dentro de uma Nuvem Privada Virtual (VPC), e o projeto do CodeBuild precisa ser configurado para esse acesso. A equipe identificou o ID da VPC, os IDs das sub-redes e os IDs dos grupos de segurança necessários para a configuração do projeto do CodeBuild. No entanto, eles não têm certeza sobre as opções de configuração necessárias para permitir que o CodeBuild acesse os recursos da VPC com sucesso.",
        "Question": "O que a equipe deve fazer para garantir que o AWS CodeBuild possa acessar os recursos na VPC especificada?",
        "Options": {
            "1": "Adicionar uma variável de ambiente no projeto do CodeBuild para especificar as configurações da VPC.",
            "2": "Configurar o projeto do CodeBuild para usar o ID da VPC, os IDs das sub-redes e os IDs dos grupos de segurança nas configurações do ambiente de construção.",
            "3": "Criar um novo papel IAM para o CodeBuild que conceda acesso aos recursos da VPC e anexá-lo ao projeto do CodeBuild.",
            "4": "Garantir que o projeto do CodeBuild seja executado na mesma região que os recursos da VPC para permitir o acesso."
        },
        "Correct Answer": "Configurar o projeto do CodeBuild para usar o ID da VPC, os IDs das sub-redes e os IDs dos grupos de segurança nas configurações do ambiente de construção.",
        "Explanation": "Para permitir que o AWS CodeBuild acesse recursos dentro de uma VPC, você deve fornecer o ID da VPC, os IDs das sub-redes e os IDs dos grupos de segurança na configuração do projeto do CodeBuild. Essa configuração permite que o CodeBuild configure um ambiente de construção habilitado para VPC, que pode então interagir com recursos dentro da VPC.",
        "Other Options": [
            "Criar um novo papel IAM não é necessário porque o CodeBuild requer configurações específicas da VPC em vez de apenas um papel IAM para acessar os recursos da VPC.",
            "Embora executar na mesma região que a VPC seja um requisito, isso não garante acesso; configurações específicas da VPC ainda devem ser definidas no projeto do CodeBuild.",
            "Variáveis de ambiente não configuram o acesso à VPC; as configurações da VPC devem ser explicitamente definidas nas configurações do ambiente de construção."
        ]
    },
    {
        "Question Number": "11",
        "Situation": "Uma empresa de serviços financeiros está planejando migrar sua aplicação legada de gerenciamento de relacionamento com o cliente (CRM) para a AWS. A aplicação é crítica para interações em tempo real com os clientes e deve manter alta disponibilidade e desempenho durante o processo de migração. A empresa quer garantir o mínimo de tempo de inatividade e uma transição tranquila para seus usuários. Para melhorar as capacidades da aplicação após a migração, eles também consideram modernizar a aplicação usando uma arquitetura de microserviços. Qual das seguintes abordagens deve ser adotada para acelerar a migração da carga de trabalho e a modernização, garantindo desempenho e disponibilidade?",
        "Question": "Qual estratégia de migração a empresa deve adotar para garantir uma transição bem-sucedida de sua aplicação CRM para a AWS com mínima interrupção e com foco na modernização futura?",
        "Options": {
            "1": "Lift and shift de toda a aplicação para instâncias EC2 em uma VPC dedicada, mantendo a arquitetura existente. Usar o Amazon Route 53 para gerenciamento de DNS e roteamento de tráfego.",
            "2": "Rearquitetar a aplicação para computação sem servidor usando AWS Lambda e Amazon API Gateway para reduzir a sobrecarga operacional e melhorar a escalabilidade após a migração.",
            "3": "Utilizar o AWS Database Migration Service para replicar o banco de dados CRM para uma instância Amazon RDS. Migrar a aplicação em fases usando funções AWS Lambda para lidar com microserviços específicos.",
            "4": "Refatorar a aplicação em microserviços antes de migrar para a AWS, implantando cada microserviço como um contêiner no Amazon ECS. Usar o AWS App Mesh para descoberta e comunicação de serviços."
        },
        "Correct Answer": "Refatorar a aplicação em microserviços antes de migrar para a AWS, implantando cada microserviço como um contêiner no Amazon ECS. Usar o AWS App Mesh para descoberta e comunicação de serviços.",
        "Explanation": "Refatorar a aplicação em microserviços antes da migração permite que a empresa aproveite ao máximo os recursos da AWS e melhore a escalabilidade e o desempenho após a migração. Implantar cada microserviço como um contêiner no Amazon ECS facilita melhor gerenciamento de recursos e flexibilidade de implantação, enquanto o AWS App Mesh simplifica a descoberta de serviços e a comunicação entre microserviços.",
        "Other Options": [
            "Usar o AWS Database Migration Service é útil para transições de banco de dados, mas migrar toda a aplicação em fases pode não abordar efetivamente a necessidade de modernização e pode levar a um tempo de inatividade prolongado.",
            "Uma abordagem lift and shift não aproveita as capacidades da AWS para modernização e pode resultar em custos operacionais mais altos e escalabilidade limitada, o que não está alinhado com os objetivos futuros da empresa.",
            "Rearquitetar a aplicação para computação sem servidor usando AWS Lambda e API Gateway é uma abordagem válida, mas pode introduzir complexidade e pode exigir mudanças significativas na arquitetura existente da aplicação antes da migração."
        ]
    },
    {
        "Question Number": "12",
        "Situation": "Uma empresa de serviços financeiros está processando dados de transações ao vivo para detectar atividades fraudulentas em tempo real. Eles estão usando o Amazon Kinesis Data Streams (KDS) para coletar e analisar esses dados. No entanto, eles notaram que durante períodos de transações de pico, alguns registros estão sendo limitados devido a limitações de shard. A administração deseja aumentar a capacidade de processamento do seu setup KDS para lidar com a carga de dados aumentada sem perder nenhum registro.",
        "Question": "Qual das seguintes opções é a solução mais eficaz para aumentar a capacidade de ingestão de dados para o Kinesis Data Stream enquanto garante alta disponibilidade?",
        "Options": {
            "1": "Implementar a Kinesis Producer Library (KPL) para agrupar os registros antes de enviá-los para o Kinesis Data Stream, maximizando assim a utilização dos shards existentes.",
            "2": "Aumentar o número de shards no Kinesis Data Stream existente para acomodar uma maior taxa de gravação e prevenir a limitação durante períodos de pico.",
            "3": "Utilizar o Amazon S3 para armazenar temporariamente os dados de transações e configurar uma função AWS Lambda para carregar periodicamente os dados no Kinesis Data Stream para lidar com cargas de pico.",
            "4": "Criar um novo Kinesis Data Stream e configurar a aplicação para dividir os dados de transação uniformemente entre os streams original e novo para equilibrar a carga."
        },
        "Correct Answer": "Aumentar o número de shards no Kinesis Data Stream existente para acomodar uma maior taxa de gravação e prevenir a limitação durante períodos de pico.",
        "Explanation": "Aumentar o número de shards no Kinesis Data Stream melhora diretamente a capacidade de ingestão de dados. Cada shard pode lidar com uma quantidade específica de dados, portanto, adicionar mais shards permite que o stream gerencie volumes maiores de dados de entrada, reduzindo assim o risco de limitação e perda de dados durante períodos de pico.",
        "Other Options": [
            "Implementar a Kinesis Producer Library (KPL) é benéfico para agrupar registros, mas não aumenta inerentemente a taxa máxima de processamento do stream em si. Se o stream já está sendo limitado devido a limitações de shard, apenas agrupar não resolverá o problema.",
            "Usar o Amazon S3 para armazenamento temporário introduz latência e complexidade adicionais ao fluxo de trabalho. Isso pode não atender à necessidade imediata de aumentar a capacidade de ingestão, pois requer processamento adicional para mover dados do S3 para o Kinesis.",
            "Criar um novo Kinesis Data Stream e equilibrar a carga pode funcionar, mas essa abordagem adiciona complexidade na gestão de múltiplos streams e não resolve o problema da limitação existente no stream original."
        ]
    },
    {
        "Question Number": "13",
        "Situation": "Uma empresa está enfrentando problemas de latência com sua aplicação web que depende fortemente de um banco de dados backend. A aplicação atende a um grande número de usuários simultaneamente, e o acesso direto ao banco de dados está diminuindo o desempenho. O arquiteto de soluções tem a tarefa de melhorar o desempenho enquanto garante a consistência dos dados.",
        "Question": "Qual padrão de design o arquiteto de soluções deve implementar para melhorar o desempenho por meio de cache e reduzir a carga no banco de dados?",
        "Options": {
            "1": "Implantar réplicas de leitura do banco de dados para lidar com o aumento do tráfego de leitura.",
            "2": "Incorporar Amazon SQS para enfileirar solicitações para o banco de dados.",
            "3": "Implementar uma camada de cache usando Amazon ElastiCache para dados acessados com frequência.",
            "4": "Usar AWS Lambda para processar solicitações de maneira serverless."
        },
        "Correct Answer": "Implementar uma camada de cache usando Amazon ElastiCache para dados acessados com frequência.",
        "Explanation": "Implementar uma camada de cache usando Amazon ElastiCache permite que dados acessados com frequência sejam armazenados na memória, reduzindo significativamente a latência experimentada pelos usuários e diminuindo a carga no banco de dados. Este padrão é eficaz para melhorar o desempenho da aplicação.",
        "Other Options": [
            "Implantar réplicas de leitura do banco de dados pode ajudar a distribuir o tráfego de leitura, mas não resolve a latência causada pela alta carga no banco de dados principal. É mais uma solução de escalabilidade do que uma estratégia de cache.",
            "Usar AWS Lambda para processar solicitações pode melhorar a escalabilidade, mas não aborda especificamente os problemas de desempenho diretos associados ao acesso ao banco de dados. As funções Lambda ainda requerem acesso ao banco de dados, que pode continuar sendo um gargalo.",
            "Incorporar Amazon SQS pode ajudar a gerenciar o fluxo de solicitações e melhorar a confiabilidade, mas não melhora diretamente o desempenho por meio de cache. É mais adequado para desacoplar componentes do que para reduzir a latência das consultas ao banco de dados."
        ]
    },
    {
        "Question Number": "14",
        "Situation": "Uma empresa de mídia está migrando seu serviço de streaming de vídeo para a AWS. O serviço apresenta padrões de tráfego flutuantes, levando a custos de transferência de dados imprevisíveis. O arquiteto de soluções precisa projetar uma maneira econômica de transferir dados do armazenamento local para a AWS, minimizando as taxas de saída.",
        "Question": "Qual das seguintes estratégias o arquiteto de soluções deve implementar para otimizar os custos de transferência de dados para o serviço de streaming de vídeo?",
        "Options": {
            "1": "Usar Amazon S3 Transfer Acceleration para fazer upload rápido de vídeos para o S3 e reduzir a latência, incorrendo em custos adicionais de transferência.",
            "2": "Implementar AWS Snowball para transferir grandes volumes de dados de vídeo para a AWS, beneficiando-se de custos de envio reduzidos e sem taxas de saída durante a transferência inicial de dados.",
            "3": "Utilizar Amazon CloudFront para armazenar em cache o conteúdo de vídeo mais próximo dos usuários e reduzir os custos de transferência de dados minimizando as buscas de origem do S3.",
            "4": "Aproveitar o AWS Direct Connect para estabelecer uma conexão de rede dedicada, reduzindo assim os custos de transferência de dados para grandes arquivos de vídeo."
        },
        "Correct Answer": "Implementar AWS Snowball para transferir grandes volumes de dados de vídeo para a AWS, beneficiando-se de custos de envio reduzidos e sem taxas de saída durante a transferência inicial de dados.",
        "Explanation": "AWS Snowball é projetado para transferir grandes quantidades de dados para a AWS de forma eficiente. Ele elimina as cobranças de saída durante o processo de transferência inicial, tornando-se uma solução econômica para as necessidades da empresa de mídia.",
        "Other Options": [
            "Amazon S3 Transfer Acceleration aumenta a velocidade de transferência, mas incorrendo em custos adicionais pelo uso do serviço, o que pode não ser ideal para otimização de custos.",
            "Embora o AWS Direct Connect forneça uma conexão confiável e de baixa latência com a AWS, é mais benéfico para transferências de dados contínuas do que para transferências iniciais em massa e pode não reduzir significativamente os custos para tráfego esporádico.",
            "Amazon CloudFront melhora a entrega de conteúdo, mas não aborda a transferência inicial de grandes arquivos de vídeo para a AWS, e ainda pode incorrer em taxas de saída do S3."
        ]
    },
    {
        "Question Number": "15",
        "Situation": "Uma empresa global de e-commerce implantou sua aplicação em várias regiões da AWS para garantir alta disponibilidade e baixa latência para seus clientes. A arquitetura da aplicação utiliza Amazon RDS para suas necessidades de banco de dados, com instâncias localizadas em cada região. No entanto, durante um incidente recente, a empresa enfrentou uma interrupção regional que causou a interrupção do serviço. Para aumentar a resiliência e minimizar o tempo de inatividade, o Arquiteto de Soluções tem a tarefa de projetar uma arquitetura mais robusta que aproveite implantações Multi-AZ e multi-Região.",
        "Question": "Qual das seguintes soluções melhora melhor a disponibilidade e resiliência da aplicação enquanto minimiza o tempo de inatividade durante interrupções regionais?",
        "Options": {
            "1": "Implantar instâncias do Amazon RDS em configuração Multi-AZ dentro de cada região e habilitar réplicas de leitura entre regiões para atender ao tráfego de leitura.",
            "2": "Implantar instâncias do Amazon RDS em uma única região com configuração Multi-AZ e usar Amazon ElastiCache para cache para reduzir a carga do banco de dados.",
            "3": "Implantar instâncias do Amazon RDS em configuração Multi-AZ em todas as regiões e usar DynamoDB Global Tables para sincronização de dados entre regiões.",
            "4": "Implantar instâncias do Amazon RDS em uma única região apenas com configuração Multi-AZ e implementar políticas de roteamento de failover do Route 53 para direcionar o tráfego para uma região de espera."
        },
        "Correct Answer": "Implantar instâncias do Amazon RDS em configuração Multi-AZ dentro de cada região e habilitar réplicas de leitura entre regiões para atender ao tráfego de leitura.",
        "Explanation": "Esta opção fornece tanto alta disponibilidade quanto a capacidade de atender ao tráfego de leitura de outra região durante uma interrupção, melhorando assim a resiliência e minimizando efetivamente o tempo de inatividade.",
        "Other Options": [
            "Esta opção fornece apenas alta disponibilidade dentro de uma única região. Falta a replicação entre regiões necessária, que é crucial para minimizar o tempo de inatividade durante uma falha regional.",
            "Esta opção não aproveita totalmente as configurações Multi-AZ entre regiões, e embora use o Route 53 para failover, pode resultar em inconsistência de dados devido à falta de replicação em tempo real entre regiões.",
            "Embora o uso de Multi-AZ entre regiões melhore a disponibilidade, confiar exclusivamente nas DynamoDB Global Tables para sincronização pode introduzir complexidade e potenciais problemas de latência que podem afetar o desempenho da aplicação."
        ]
    },
    {
        "Question Number": "16",
        "Situation": "Uma empresa está planejando implantar uma aplicação global que requer acesso de baixa latência para usuários em todo o mundo. A aplicação consiste em múltiplos microserviços que devem ser implantados em várias Regiões da AWS, garantindo a consistência dos dados e alta disponibilidade. A empresa deseja usar um serviço da AWS que forneça uma camada de cache global para melhorar o desempenho e reduzir a latência para os usuários finais. Qual das seguintes soluções é a MAIS adequada para esse requisito?",
        "Question": "Qual serviço da AWS a empresa deve usar para fornecer uma camada de cache global para sua aplicação?",
        "Options": {
            "1": "Amazon CloudFront com failover de origem para um bucket S3 em cada região que hospeda os ativos da aplicação.",
            "2": "Amazon CloudFront com Lambda@Edge para personalizar a entrega de conteúdo e reduzir a latência globalmente.",
            "3": "Amazon ElastiCache com grupos de replicação para manter a consistência do cache em diferentes Regiões da AWS.",
            "4": "AWS Global Accelerator para direcionar o tráfego para o endpoint da aplicação mais próximo, utilizando o Amazon Route 53 para gerenciamento de DNS."
        },
        "Correct Answer": "Amazon CloudFront com Lambda@Edge para personalizar a entrega de conteúdo e reduzir a latência globalmente.",
        "Explanation": "Amazon CloudFront é uma rede de entrega de conteúdo (CDN) que armazena em cache o conteúdo em locais de borda ao redor do mundo, proporcionando acesso de baixa latência aos usuários. Lambda@Edge permite a personalização da entrega de conteúdo, permitindo que a aplicação ajuste dinamicamente o conteúdo com base nas solicitações dos usuários, otimizando ainda mais o desempenho.",
        "Other Options": [
            "Amazon CloudFront com failover de origem para um bucket S3 não fornece uma camada de cache para conteúdo dinâmico e não é otimizado para microserviços que requerem baixa latência.",
            "Amazon ElastiCache é projetado para cache dentro de uma única região e não suporta cache global por padrão, o que é crucial para uma aplicação global.",
            "AWS Global Accelerator melhora a disponibilidade e o desempenho da aplicação ao direcionar o tráfego para o endpoint mais próximo, mas não fornece capacidades de cache, que são necessárias para reduzir a latência."
        ]
    },
    {
        "Question Number": "17",
        "Situation": "Uma empresa de serviços financeiros está planejando migrar sua aplicação local para a AWS. A aplicação é crítica e requer alta disponibilidade e baixa latência. A empresa precisa avaliar a aplicação para entender sua arquitetura, dependências e os melhores serviços da AWS a serem utilizados. Eles querem garantir que a migração não interrompa as operações existentes e que o novo ambiente atenda aos requisitos de conformidade. A equipe está buscando reunir informações sobre a arquitetura da aplicação, requisitos de rede e métricas de desempenho. Eles também precisam identificar quaisquer dependências de banco de dados e potenciais gargalos.",
        "Question": "Qual das seguintes abordagens a empresa deve adotar para completar uma avaliação abrangente de migração para sua aplicação?",
        "Options": {
            "1": "Utilizar o AWS Application Discovery Service para coletar informações detalhadas sobre a aplicação local, incluindo sua arquitetura, métricas de desempenho e dependências de rede.",
            "2": "Contratar uma empresa de consultoria terceirizada para analisar a aplicação e recomendar serviços da AWS com base em sua experiência em migrações para a nuvem.",
            "3": "Realizar uma revisão manual do código da aplicação e da documentação da arquitetura para identificar dependências e gargalos de desempenho antes de migrar para a AWS.",
            "4": "Implementar um projeto piloto na AWS com um subconjunto limitado da aplicação para testar o desempenho e identificar potenciais desafios de migração antes de uma migração completa."
        },
        "Correct Answer": "Utilizar o AWS Application Discovery Service para coletar informações detalhadas sobre a aplicação local, incluindo sua arquitetura, métricas de desempenho e dependências de rede.",
        "Explanation": "O AWS Application Discovery Service é projetado especificamente para ajudar as organizações a reunir informações sobre suas aplicações locais, incluindo arquitetura, dependências e métricas de desempenho. Esses dados são cruciais para planejar uma migração para a AWS e garantir que todos os aspectos da aplicação sejam considerados, o que ajuda a minimizar interrupções e atender aos requisitos de conformidade.",
        "Other Options": [
            "Embora a realização de uma revisão manual possa fornecer algumas percepções, ela é suscetível a erros humanos e pode perder dependências críticas ou métricas de desempenho que ferramentas automatizadas podem capturar facilmente.",
            "Implementar um projeto piloto pode ajudar a identificar desafios, mas não fornece uma visão completa da arquitetura e das dependências da aplicação, que são essenciais para uma avaliação abrangente de migração.",
            "Contratar uma empresa de consultoria terceirizada pode fornecer insights valiosos, mas confiar apenas na experiência externa pode negligenciar detalhes específicos que a equipe interna poderia avaliar usando ferramentas da AWS personalizadas."
        ]
    },
    {
        "Question Number": "18",
        "Situation": "Uma empresa de serviços financeiros está expandindo sua infraestrutura para suportar um novo aplicativo de banco móvel. Eles precisam garantir que podem monitorar o tráfego da rede de forma eficaz para detectar qualquer atividade suspeita e manter a conformidade com os padrões regulatórios. A empresa está atualmente usando Amazon VPC e AWS CloudTrail, mas deseja aprimorar suas capacidades de monitoramento.",
        "Question": "Qual das seguintes soluções ajudaria melhor a empresa a monitorar o tráfego da rede de forma eficaz e garantir a conformidade com os padrões regulatórios?",
        "Options": {
            "1": "Usar o Amazon Inspector para realizar avaliações de segurança na aplicação e gerar relatórios de conformidade.",
            "2": "Implantar um AWS WAF para filtrar solicitações de entrada e bloquear tráfego malicioso antes que ele chegue à aplicação.",
            "3": "Configurar o AWS CloudTrail para registrar todas as chamadas de API feitas na conta e revisar os logs periodicamente em busca de atividade suspeita.",
            "4": "Implementar AWS VPC Flow Logs para capturar e analisar o tráfego dentro da VPC e configurar alertas para padrões incomuns."
        },
        "Correct Answer": "Implementar AWS VPC Flow Logs para capturar e analisar o tráfego dentro da VPC e configurar alertas para padrões incomuns.",
        "Explanation": "AWS VPC Flow Logs fornecem visibilidade detalhada sobre o tráfego da rede que flui para e de interfaces de rede em sua VPC. Isso permite que a empresa analise padrões de tráfego, detecte anomalias e garanta a conformidade com os padrões regulatórios de forma eficaz.",
        "Other Options": [
            "Embora o AWS CloudTrail seja útil para registrar chamadas de API, ele não fornece visibilidade detalhada sobre o tráfego real da rede, que é essencial para monitorar atividades suspeitas.",
            "Amazon Inspector é focado principalmente na avaliação da segurança da aplicação, em vez de monitoramento em tempo real do tráfego da rede, tornando-o menos adequado para as necessidades da empresa.",
            "AWS WAF é usado para proteger aplicações contra explorações comuns da web, mas não fornece capacidades abrangentes de monitoramento de tráfego necessárias para analisar e detectar padrões de rede suspeitos."
        ]
    },
    {
        "Question Number": "19",
        "Situation": "Uma empresa está implantando um novo aplicativo web que requer proteção contra vulnerabilidades comuns da web, como injeção de SQL e script entre sites. Eles querem usar o AWS WAF para filtrar o tráfego antes que ele chegue à sua distribuição do CloudFront. A equipe está considerando usar as Regras Gerenciadas da AWS para simplificar a configuração e a manutenção do WAF. Eles também querem implementar limitação de taxa para prevenir abusos de endereços IP específicos. (Selecione Dois)",
        "Question": "Quais das seguintes ações devem ser tomadas para implementar efetivamente o AWS WAF para este cenário?",
        "Options": {
            "1": "Selecione um ou mais grupos de Regras Gerenciadas da AWS para adicionar ao seu WebACL que fornecem proteção contra vulnerabilidades comuns.",
            "2": "Implemente uma regra baseada em taxa no seu WebACL para bloquear endereços IP que excedem um limite de solicitações especificado.",
            "3": "Crie uma regra personalizada que permita todo o tráfego para a distribuição do CloudFront, independentemente das condições.",
            "4": "Configure seu WebACL para permitir tráfego apenas de uma localização geográfica específica para aumentar a segurança.",
            "5": "Modifique a ação padrão do WebACL para contar solicitações em vez de bloqueá-las."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Selecione um ou mais grupos de Regras Gerenciadas da AWS para adicionar ao seu WebACL que fornecem proteção contra vulnerabilidades comuns.",
            "Implemente uma regra baseada em taxa no seu WebACL para bloquear endereços IP que excedem um limite de solicitações especificado."
        ],
        "Explanation": "Ao selecionar grupos de Regras Gerenciadas da AWS, você pode aproveitar regras pré-definidas que automaticamente protegem seu aplicativo contra vulnerabilidades comuns sem precisar de uma configuração extensa. Implementar uma regra baseada em taxa permite limitar o número de solicitações de endereços IP individuais, prevenindo efetivamente abusos e garantindo o uso justo dos recursos.",
        "Other Options": [
            "Criar uma regra personalizada que permita todo o tráfego anula o propósito de implementar um WAF, pois exporia o aplicativo a todos os tipos de ataques sem filtragem.",
            "Configurar o WebACL para permitir tráfego apenas de uma localização geográfica específica poderia bloquear inadvertidamente usuários legítimos de outras regiões, reduzindo a acessibilidade.",
            "Modificar a ação padrão para contar solicitações não forneceria nenhuma medida de proteção; simplesmente registra o tráfego sem impor políticas de segurança."
        ]
    },
    {
        "Question Number": "20",
        "Situation": "Uma organização está implementando um ambiente AWS de múltiplas contas onde diferentes equipes precisam acessar recursos compartilhados de maneira segura. A equipe de segurança aconselhou o uso de funções IAM com IDs externos para mitigar o risco de acesso não autorizado. A organização quer garantir que partes externas possam assumir funções de forma segura sem expor permissões sensíveis.",
        "Question": "Qual abordagem a organização deve adotar para permitir que partes externas assumam funções em suas contas AWS de forma segura?",
        "Options": {
            "1": "Defina uma função vinculada a serviços que permita que serviços externos acessem recursos em sua conta sem usar um ID externo.",
            "2": "Configure uma função com uma política de confiança que exija que a parte externa forneça um ID externo ao assumir a função.",
            "3": "Configure uma política IAM que conceda acesso à parte externa e a anexe diretamente aos recursos que eles precisam.",
            "4": "Crie um novo usuário IAM para cada parte externa com chaves de acesso de longo prazo e forneça a eles as permissões necessárias."
        },
        "Correct Answer": "Configure uma função com uma política de confiança que exija que a parte externa forneça um ID externo ao assumir a função.",
        "Explanation": "Usar uma política de confiança que exige um ID externo aumenta a segurança, garantindo que a parte externa só possa assumir a função quando fornecer o ID externo correto. Isso mitiga o risco de a função ser assumida por usuários não autorizados.",
        "Other Options": [
            "Criar usuários IAM com chaves de acesso de longo prazo aumenta o risco de vazamento de credenciais e não segue as melhores práticas para acesso temporário.",
            "Funções vinculadas a serviços são pré-definidas pelos serviços da AWS e não são adequadas para conceder acesso a partes externas, pois não permitem IDs externos ou permissões personalizadas.",
            "Anexar uma política IAM diretamente aos recursos para partes externas não fornece os controles de segurança necessários que os IDs externos oferecem e pode expor permissões sensíveis sem verificar a identidade da parte externa."
        ]
    },
    {
        "Question Number": "21",
        "Situation": "Uma empresa de serviços financeiros está implementando um aplicativo que processa transações em tempo real. Dada a natureza crítica dessas transações, a empresa precisa garantir a adesão a rigorosos Acordos de Nível de Serviço (SLAs) e estabelecer Indicadores-Chave de Desempenho (KPIs) relevantes para monitorar efetivamente o desempenho do aplicativo.",
        "Question": "Qual das seguintes abordagens garante melhor que o aplicativo atenda seus SLAs e KPIs enquanto mantém alta confiabilidade e desempenho?",
        "Options": {
            "1": "Defina SLAs que especifiquem tempos máximos de resposta e tempo de inatividade máximo, e implemente uma arquitetura altamente disponível em várias regiões.",
            "2": "Estabeleça uma equipe dedicada para verificar manualmente o desempenho do aplicativo semanalmente para garantir conformidade com os SLAs.",
            "3": "Utilize uma única instância EC2 para hospedar o aplicativo enquanto implementa backups diários para recuperar de quaisquer falhas.",
            "4": "Implemente uma solução de monitoramento que rastreie métricas de desempenho do aplicativo e alerte a equipe de operações quando os KPIs não forem atendidos."
        },
        "Correct Answer": "Defina SLAs que especifiquem tempos máximos de resposta e tempo de inatividade máximo, e implemente uma arquitetura altamente disponível em várias regiões.",
        "Explanation": "Essa abordagem garante que o aplicativo seja projetado com SLAs em mente, estabelecendo expectativas claras de desempenho enquanto também fornece redundância por meio de uma arquitetura de múltiplas regiões. Essa configuração melhora significativamente a disponibilidade e a resiliência, alinhando-se à natureza crítica dos serviços prestados.",
        "Other Options": [
            "Embora monitorar métricas de desempenho do aplicativo seja essencial, confiar apenas em alertas não garante proativamente que os SLAs e KPIs sejam atendidos. Falta as garantias estruturais necessárias para alta confiabilidade.",
            "Utilizar uma única instância EC2 introduz um ponto único de falha e não atende aos requisitos de alta disponibilidade necessários para processar transações críticas. Backups diários não substituem a disponibilidade em tempo real.",
            "Um processo de verificação manual não é uma maneira escalável ou eficaz de monitorar o desempenho do aplicativo. Esse método é propenso a atrasos e erros humanos, falhando em fornecer insights em tempo real sobre a conformidade com os SLAs."
        ]
    },
    {
        "Question Number": "22",
        "Situation": "Uma empresa utiliza um bucket do Amazon S3 para armazenar documentos importantes. Recentemente, eles ativaram o versionamento para garantir que as alterações nesses documentos sejam rastreadas. Após ativar o versionamento, eles estão preocupados com como os documentos existentes e os uploads futuros serão afetados, e se poderão reverter para versões anteriores, se necessário.",
        "Question": "Quais são as implicações de ativar o versionamento em um bucket S3? (Selecione Dois)",
        "Options": {
            "1": "Uma vez que o versionamento é ativado, não pode ser desativado sem excluir o bucket.",
            "2": "Os objetos existentes no bucket manterão seu ID de versão nulo e não serão impactados.",
            "3": "Objetos que são excluídos ainda manterão suas versões anteriores no bucket.",
            "4": "Todos os novos objetos enviados para o bucket receberão um ID de versão exclusivo.",
            "5": "Ativar o versionamento atribui retroativamente um ID de versão exclusivo a todos os objetos existentes."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Os objetos existentes no bucket manterão seu ID de versão nulo e não serão impactados.",
            "Todos os novos objetos enviados para o bucket receberão um ID de versão exclusivo."
        ],
        "Explanation": "Quando o versionamento é ativado em um bucket S3, os objetos existentes permanecem inalterados com seu ID de versão definido como nulo. No entanto, quaisquer novos objetos enviados para o bucket receberão um ID de versão exclusivo, permitindo um melhor rastreamento e gerenciamento das versões dos objetos.",
        "Other Options": [
            "Esta opção está incorreta porque ativar o versionamento não atribui retroativamente IDs de versão exclusivos a objetos existentes; eles manterão seu ID de versão nulo.",
            "Esta opção está incorreta porque o versionamento pode ser suspenso, mas o bucket em si não precisa ser excluído para parar o versionamento.",
            "Esta opção está incorreta porque objetos excluídos não são removidos permanentemente; em vez disso, são marcados como excluídos, e suas versões anteriores ainda podem ser acessadas."
        ]
    },
    {
        "Question Number": "23",
        "Situation": "Uma empresa está buscando implementar uma solução que permita que seus dispositivos de borda processem dados localmente e se comuniquem com os serviços AWS IoT para gerenciamento e análise. A arquitetura deve garantir que os dispositivos possam operar de forma independente, mesmo durante a conectividade intermitente. O Arquiteto de Soluções precisa escolher a abordagem mais adequada usando os serviços da AWS.",
        "Question": "Qual das seguintes configurações que utilizam serviços da AWS fornece a melhor solução para estender as capacidades da nuvem para dispositivos de borda, garantindo que eles possam agir sobre os dados que geram localmente?",
        "Options": {
            "1": "Usar AWS Lambda@Edge para executar funções que modificam solicitações e respostas no CloudFront, permitindo o processamento de dados mais próximo dos usuários, mas dependendo de uma conectividade de internet consistente.",
            "2": "Implantar AWS IoT Greengrass nos dispositivos de borda para permitir a execução local de funções AWS Lambda e comunicação segura com os serviços AWS, mesmo sem conectividade à internet.",
            "3": "Implementar uma instância do Amazon EC2 na borda para executar aplicativos que processam dados localmente, garantindo conectividade com a AWS para gerenciamento e análise.",
            "4": "Utilizar AWS IoT Core para conectar dispositivos diretamente à nuvem, realizando todo o processamento de dados na nuvem sem execução local."
        },
        "Correct Answer": "Implantar AWS IoT Greengrass nos dispositivos de borda para permitir a execução local de funções AWS Lambda e comunicação segura com os serviços AWS, mesmo sem conectividade à internet.",
        "Explanation": "AWS IoT Greengrass permite que dispositivos de borda executem funções AWS Lambda e realizem ações locais com base nos dados que geram. Essa capacidade garante que os dispositivos possam funcionar de forma independente durante interrupções, mantendo comunicação segura com os serviços AWS quando a conectividade estiver disponível.",
        "Other Options": [
            "AWS Lambda@Edge é projetado para executar funções na borda da rede AWS, principalmente para modificar solicitações e respostas em conjunto com o CloudFront. Esta solução depende fortemente da conectividade com a internet e não permite a execução local de funções nos próprios dispositivos.",
            "Usar uma instância do Amazon EC2 na borda pode fornecer capacidades de processamento local, mas não atende especificamente à gestão de dispositivos de borda ou comunicação segura com os serviços AWS em um estado desconectado. Também introduz sobrecarga e complexidade que podem não ser necessárias.",
            "Embora o AWS IoT Core permita comunicação direta com serviços em nuvem, não fornece capacidades de processamento local para dispositivos de borda. Esta opção exigiria uma conexão constante com a internet, tornando-a inadequada para cenários onde ações locais são necessárias durante problemas de conectividade."
        ]
    },
    {
        "Question Number": "24",
        "Situation": "Uma equipe de desenvolvimento de software está implementando um pipeline de CI/CD usando serviços da AWS para automatizar a implantação de suas aplicações. Eles querem garantir que as alterações de código sejam automaticamente construídas, testadas e implantadas em múltiplos ambientes sem intervenção manual. A equipe está considerando várias ferramentas da AWS para alcançar esse objetivo.",
        "Question": "Qual das seguintes opções é a maneira MAIS eficaz de implementar um pipeline de CI/CD na AWS para este cenário?",
        "Options": {
            "1": "Configurar um servidor Jenkins em uma instância EC2 para gerenciar o processo de construção e implantação da aplicação.",
            "2": "Implementar um processo de implantação manual usando AWS Elastic Beanstalk para implantar a aplicação no ambiente de staging.",
            "3": "Utilizar funções AWS Lambda para gerenciar gatilhos de implantação e gerenciar o processo de CI/CD sem um pipeline dedicado.",
            "4": "Usar AWS CodePipeline para orquestrar o fluxo de trabalho de CI/CD e integrá-lo com AWS CodeBuild e AWS CodeDeploy."
        },
        "Correct Answer": "Usar AWS CodePipeline para orquestrar o fluxo de trabalho de CI/CD e integrá-lo com AWS CodeBuild e AWS CodeDeploy.",
        "Explanation": "Usar o AWS CodePipeline fornece um serviço totalmente gerenciado que permite definir facilmente as etapas do seu pipeline de CI/CD, integrar-se com outros serviços da AWS como CodeBuild para construção de código e CodeDeploy para implantação, e automatizar todo o processo desde o commit do código até a implantação. Essa abordagem minimiza a intervenção manual e maximiza a eficiência.",
        "Other Options": [
            "Implementar um processo de implantação manual usando AWS Elastic Beanstalk não fornece a automação e as funcionalidades de integração contínua que um pipeline de CI/CD adequado oferece, o que levaria a um aumento do risco de erro humano e ciclos de lançamento mais lentos.",
            "Utilizar funções AWS Lambda para gatilhos de implantação carece das funcionalidades abrangentes de um pipeline de CI/CD, como gerenciamento de construção e orquestração de implantação, tornando-a uma solução menos eficaz para automatizar todo o ciclo de vida de desenvolvimento.",
            "Configurar um servidor Jenkins em uma instância EC2 adiciona complexidade desnecessária e sobrecarga de manutenção em comparação com o uso de serviços gerenciados da AWS como o CodePipeline, que são projetados especificamente para fluxos de trabalho de CI/CD."
        ]
    },
    {
        "Question Number": "25",
        "Situation": "Uma startup está buscando otimizar seus custos na AWS enquanto garante que tenha capacidade suficiente para seu crescente aplicativo web. Eles estão considerando diferentes opções de compra oferecidas pela AWS. A carga de trabalho da empresa é previsível, com padrões de uso consistentes durante o horário comercial e uso mínimo durante as horas de menor movimento. Qual é a opção de compra mais econômica para este cenário?",
        "Question": "Qual opção de compra da AWS o Arquiteto de Soluções deve recomendar para otimizar os custos da carga de trabalho previsível da startup?",
        "Options": {
            "1": "Comprar Instâncias Reservadas com um prazo de um ano para cobrir a carga de trabalho consistente durante o horário comercial.",
            "2": "Implementar Savings Plans para fornecer flexibilidade enquanto também reduz os custos com base nos padrões de uso.",
            "3": "Utilizar Instâncias Spot para toda a carga de trabalho para aproveitar os preços mais baixos.",
            "4": "Aproveitar Instâncias Sob Demanda para manter a flexibilidade sem qualquer compromisso inicial."
        },
        "Correct Answer": "Comprar Instâncias Reservadas com um prazo de um ano para cobrir a carga de trabalho consistente durante o horário comercial.",
        "Explanation": "Comprar Instâncias Reservadas com um prazo de um ano é a opção mais econômica para cargas de trabalho previsíveis, pois oferece economias significativas em comparação com os preços Sob Demanda, garantindo que a capacidade esteja reservada para o uso consistente durante o horário comercial.",
        "Other Options": [
            "Usar Instâncias Spot pode levar a interrupções e não é adequado para cargas de trabalho previsíveis que requerem tempo de atividade consistente, pois essas instâncias podem ser retomadas pela AWS a qualquer momento.",
            "Implementar Savings Plans proporcionaria alguma flexibilidade, mas para uma carga de trabalho altamente previsível, as Instâncias Reservadas geralmente oferecem maiores economias, dado o compromisso com o uso.",
            "Aproveitar Instâncias Sob Demanda permite flexibilidade e sem custos iniciais, mas é a opção mais cara para cargas de trabalho previsíveis em comparação com as Instâncias Reservadas."
        ]
    },
    {
        "Question Number": "26",
        "Situation": "Uma empresa de serviços financeiros depende de um conjunto de instâncias EC2 e de um banco de dados Amazon RDS para PostgreSQL para gerenciar dados sensíveis de transações de clientes. Eles exigem uma estratégia robusta de backup e restauração para garantir a integridade dos dados e conformidade com os requisitos regulatórios. A empresa determina que os backups devem ser realizados sem impactar o desempenho da aplicação, e o RTO deve ser inferior a 2 horas, enquanto o RPO não deve exceder 10 minutos. Além disso, dados sensíveis devem ser criptografados tanto em trânsito quanto em repouso.",
        "Question": "Como Arquiteto de Soluções, qual estratégia de backup e restauração atenderia melhor aos requisitos de RTO, RPO e criptografia de dados, minimizando o impacto no desempenho da aplicação?",
        "Options": {
            "1": "Ativar backups automatizados do RDS com um intervalo de snapshot de 15 minutos. Usar o Amazon S3 para armazenar backups e configurar criptografia do lado do servidor com chaves gerenciadas pelo S3, garantindo que os dados sejam criptografados em trânsito com TLS.",
            "2": "Agendar backups manuais da instância RDS a cada 30 minutos e armazenar logs de transações em um bucket S3 a cada 5 minutos. Usar o AWS Secrets Manager para gerenciar chaves de criptografia e garantir que os dados sejam criptografados em trânsito com HTTPS.",
            "3": "Implementar o AWS Backup para criar backups diários da instância RDS e habilitar backups automatizados com uma frequência de snapshot de 5 minutos. Usar o AWS Key Management Service (KMS) para gerenciar chaves de criptografia para dados em repouso e garantir que o SSL esteja habilitado para dados em trânsito.",
            "4": "Usar o AWS Data Pipeline para agendar backups da instância RDS a cada hora e transferi-los para o Amazon S3. Configurar criptografia para os backups usando o AWS CloudHSM e garantir que os dados sejam criptografados em trânsito usando IPsec."
        },
        "Correct Answer": "Implementar o AWS Backup para criar backups diários da instância RDS e habilitar backups automatizados com uma frequência de snapshot de 5 minutos. Usar o AWS Key Management Service (KMS) para gerenciar chaves de criptografia para dados em repouso e garantir que o SSL esteja habilitado para dados em trânsito.",
        "Explanation": "Esta opção garante que backups automatizados sejam criados com impacto mínimo no desempenho e fornece um RPO de 5 minutos, que atende ao requisito. Também aproveita o AWS KMS para criptografia em repouso e SSL para criptografia em trânsito, garantindo conformidade com as políticas de segurança da empresa.",
        "Other Options": [
            "Esta opção não atende ao requisito de RPO de 10 minutos, pois os backups manuais a cada 30 minutos podem levar à perda de dados. Além disso, o AWS Secrets Manager não é projetado principalmente para gerenciar chaves de criptografia para dados em repouso.",
            "Embora os backups automatizados do RDS sejam um bom recurso, um intervalo de snapshot de 15 minutos não atende ao requisito de RPO de 10 minutos. Além disso, usar chaves gerenciadas pelo S3 não fornece o mesmo nível de controle que o AWS KMS para gerenciamento de chaves de criptografia.",
            "Usar o AWS Data Pipeline para agendar backups pode introduzir complexidade desnecessária, e backups horários não atendem ao requisito de RPO de 10 minutos. Embora o CloudHSM forneça um gerenciamento de chaves forte, sua integração com o RDS para criptografia de backup pode não ser direta."
        ]
    },
    {
        "Question Number": "27",
        "Situation": "Uma empresa está planejando migrar um grande aplicativo local para a AWS. O aplicativo será hospedado em várias Zonas de Disponibilidade dentro de uma única região. Como parte da estratégia de migração, a empresa deseja garantir que minimize os custos de transferência de dados enquanto mantém alta disponibilidade e desempenho. Eles estão particularmente preocupados com os custos associados à transferência de dados entre os serviços da AWS e o data center local.",
        "Question": "Qual das seguintes estratégias ajudaria melhor a empresa a minimizar os custos de transferência de dados enquanto garante alta disponibilidade e desempenho para seu aplicativo migrado?",
        "Options": {
            "1": "Implementar peering de VPC entre várias Nuvens Privadas Virtuais (VPCs) para facilitar a transferência de dados sem custo dentro das regiões da AWS.",
            "2": "Usar o AWS Direct Connect para estabelecer uma conexão dedicada do data center local para a AWS, garantindo baixa latência e redução dos custos de transferência de dados.",
            "3": "Utilizar o Amazon CloudFront como uma rede de entrega de conteúdo para armazenar dados em locais de borda, reduzindo a quantidade de dados transferidos da origem na AWS.",
            "4": "Aproveitar o AWS Global Accelerator para otimizar o caminho para a região da AWS a partir do data center local, reduzindo a latência e melhorando o desempenho."
        },
        "Correct Answer": "Usar o AWS Direct Connect para estabelecer uma conexão dedicada do data center local para a AWS, garantindo baixa latência e redução dos custos de transferência de dados.",
        "Explanation": "Usar o AWS Direct Connect fornece uma conexão dedicada de alta largura de banda do data center local para a AWS, o que reduz significativamente os custos de transferência de dados em comparação com o uso da internet. Este método também garante baixa latência e alta confiabilidade, tornando-o ideal para aplicativos de alto desempenho.",
        "Other Options": [
            "Utilizar o Amazon CloudFront ajuda principalmente a reduzir a latência e fornece benefícios de cache para distribuição de conteúdo, mas não aborda diretamente os custos de transferência de dados associados à movimentação de grandes volumes de dados entre o local e a AWS.",
            "Implementar peering de VPC permite transferência gratuita de dados entre VPCs na mesma região, mas não se aplica a transferências de dados entre o local e a AWS, portanto, não ajuda a minimizar custos neste cenário específico.",
            "Aproveitar o AWS Global Accelerator otimiza o roteamento do tráfego para os serviços da AWS, mas não impacta diretamente o custo da transferência de dados entre o data center local e os serviços da AWS."
        ]
    },
    {
        "Question Number": "28",
        "Situation": "Uma organização de serviços financeiros está buscando aprimorar sua postura de segurança implementando um sistema robusto de gerenciamento de credenciais na AWS. O Arquiteto de Soluções precisa identificar serviços eficazes que possam gerenciar, armazenar e recuperar informações sensíveis, como chaves de API, senhas e credenciais de banco de dados, de forma segura. A organização requer uma solução que possa ser facilmente integrada aos seus serviços existentes da AWS e que forneça controle de acesso detalhado para seus usuários. (Selecione Dois)",
        "Question": "Qual combinação de serviços da AWS o Arquiteto de Soluções deve recomendar para gerenciamento de credenciais?",
        "Options": {
            "1": "Implementar o AWS Systems Manager Parameter Store para gerenciar dados de configuração e segredos com criptografia embutida.",
            "2": "Usar o AWS Secrets Manager para armazenar e recuperar credenciais sensíveis e rotacioná-las automaticamente.",
            "3": "Aproveitar o AWS Lambda para criar uma solução personalizada de gerenciamento de credenciais usando variáveis de ambiente.",
            "4": "Adotar o Amazon Cognito para gerenciar a autenticação de usuários e o controle de acesso para o armazenamento de credenciais.",
            "5": "Utilizar funções do AWS Identity and Access Management (IAM) para armazenar diretamente senhas de usuários de forma segura."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Usar o AWS Secrets Manager para armazenar e recuperar credenciais sensíveis e rotacioná-las automaticamente.",
            "Implementar o AWS Systems Manager Parameter Store para gerenciar dados de configuração e segredos com criptografia embutida."
        ],
        "Explanation": "O AWS Secrets Manager é projetado especificamente para gerenciar informações sensíveis, como credenciais, fornecendo rotação automática e controle de acesso detalhado. O AWS Systems Manager Parameter Store também oferece uma maneira segura de armazenar dados de configuração, incluindo segredos, com criptografia, tornando-o adequado para gerenciamento de credenciais.",
        "Other Options": [
            "As funções do AWS Identity and Access Management (IAM) são usadas para gerenciar permissões e acesso a recursos da AWS, mas não fornecem um mecanismo para armazenar senhas de usuários de forma segura, tornando essa opção inadequada para gerenciamento de credenciais.",
            "Usar o AWS Lambda para uma solução personalizada de gerenciamento de credenciais aumenta a complexidade e pode introduzir riscos de segurança, pois requer o gerenciamento de toda a solução em vez de aproveitar os serviços existentes da AWS projetados para gerenciamento de credenciais.",
            "O Amazon Cognito é focado principalmente na autenticação de usuários e controle de acesso, e embora possa gerenciar credenciais de usuários, não é especificamente projetado para armazenar e recuperar de forma segura credenciais sensíveis de aplicativos, como chaves de API ou senhas de banco de dados."
        ]
    },
    {
        "Question Number": "29",
        "Situation": "Uma empresa global de varejo online está buscando aprimorar sua estratégia de recuperação de desastres para garantir o mínimo de tempo de inatividade e perda de dados. A empresa utiliza extensivamente os serviços da AWS, mas ainda não implementou um plano formal de recuperação de desastres. O arquiteto de soluções é encarregado de identificar metodologias e ferramentas de recuperação de desastres apropriadas para atender efetivamente aos requisitos da empresa. (Selecione Dois)",
        "Question": "Qual dos seguintes métodos e ferramentas de recuperação de desastres o arquiteto de soluções deve recomendar?",
        "Options": {
            "1": "Utilizar o Amazon S3 para backup e restauração apenas durante o horário comercial.",
            "2": "Adotar uma abordagem de standby quente com instâncias do Amazon EC2 em uma região diferente.",
            "3": "Aproveitar o AWS Backup para automatizar processos de backup entre serviços.",
            "4": "Implementar o AWS Elastic Disaster Recovery para replicação contínua.",
            "5": "Confiar apenas em backups em fita locais para restauração de dados."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Implementar o AWS Elastic Disaster Recovery para replicação contínua.",
            "Aproveitar o AWS Backup para automatizar processos de backup entre serviços."
        ],
        "Explanation": "O AWS Elastic Disaster Recovery permite a replicação contínua de recursos da AWS, possibilitando uma recuperação rápida em caso de desastre. O AWS Backup automatiza e centraliza tarefas de backup entre vários serviços da AWS, garantindo que os dados sejam regularmente copiados e prontamente disponíveis para recuperação. Ambas as opções atendem à necessidade de soluções eficazes de recuperação de desastres adaptadas à infraestrutura em nuvem da empresa.",
        "Other Options": [
            "Utilizar o Amazon S3 para backup e restauração apenas durante o horário comercial não é ideal, pois não garante proteção contínua de dados e pode levar à perda de dados se um desastre ocorrer fora desse horário.",
            "Adotar uma abordagem de standby quente com instâncias do Amazon EC2 em uma região diferente pode ser eficaz, mas pode não fornecer o mesmo nível de automação e facilidade de gerenciamento que o AWS Elastic Disaster Recovery e o AWS Backup oferecem.",
            "Confiar apenas em backups em fita locais para restauração de dados é inadequado, pois não aproveita as vantagens das soluções baseadas em nuvem e pode levar a tempos de recuperação mais longos e potencial perda de dados."
        ]
    },
    {
        "Question Number": "30",
        "Situation": "Uma empresa de serviços financeiros está realizando uma auditoria de seu ambiente AWS para garantir que os usuários tenham apenas as permissões necessárias para desempenhar suas funções, de acordo com o princípio do menor privilégio. A empresa possui várias equipes com diferentes responsabilidades e necessidades de acesso. Eles estão usando o AWS Identity and Access Management (IAM) para gerenciamento de permissões de usuários.",
        "Question": "Qual é a estratégia mais eficaz para auditar o ambiente AWS e garantir acesso de menor privilégio para todos os usuários?",
        "Options": {
            "1": "Implementar uma solução de registro centralizado que rastreie todas as chamadas de API feitas pelos usuários para identificar permissões excessivas e padrões de uso.",
            "2": "Configurar um script automatizado que remova regularmente quaisquer permissões que não tenham sido usadas nos últimos 30 dias para todos os usuários.",
            "3": "Usar o AWS IAM Access Analyzer para identificar permissões que não estão sendo usadas e ajustar funções e políticas do IAM de acordo.",
            "4": "Realizar uma revisão manual de todas as políticas e funções do IAM para garantir que os usuários tenham as permissões mínimas necessárias para suas tarefas."
        },
        "Correct Answer": "Usar o AWS IAM Access Analyzer para identificar permissões que não estão sendo usadas e ajustar funções e políticas do IAM de acordo.",
        "Explanation": "Usar o AWS IAM Access Analyzer é a maneira mais eficaz de auditar permissões de usuários, pois analisa automaticamente as políticas e identifica acessos excessivamente permissivos, permitindo ajustes sistemáticos para manter o acesso de menor privilégio em todo o ambiente.",
        "Other Options": [
            "Realizar uma revisão manual é demorado e propenso a erros, tornando-se menos eficaz em comparação com ferramentas automatizadas como o IAM Access Analyzer.",
            "Embora o registro centralizado possa fornecer insights sobre padrões de chamadas de API, não identifica diretamente permissões que são excessivas ou desnecessárias, o que é essencial para impor o menor privilégio.",
            "Um script automatizado que remove permissões não utilizadas pode inadvertidamente revogar acessos necessários para os usuários, levando a potenciais interrupções em sua capacidade de realizar tarefas exigidas."
        ]
    },
    {
        "Question Number": "31",
        "Situation": "Uma empresa de serviços financeiros precisa processar regularmente dados de transações armazenados no Amazon S3 e, em seguida, carregar os dados transformados em um banco de dados Amazon RDS para fins de relatórios. A empresa requer uma solução que possa automatizar esse processo e garantir a integridade dos dados, minimizando os custos.",
        "Question": "Qual serviço da AWS a empresa deve usar para orquestrar o movimento e a transformação de dados do Amazon S3 para o Amazon RDS?",
        "Options": {
            "1": "AWS Step Functions para gerenciar o fluxo de trabalho e AWS Lambda para transformação de dados.",
            "2": "Amazon Kinesis Data Firehose para transmitir dados do S3 para o RDS.",
            "3": "AWS Batch para processar dados no S3 e carregá-los no RDS.",
            "4": "AWS Glue para criar trabalhos de ETL e automatizar a transferência e transformação de dados."
        },
        "Correct Answer": "AWS Glue para criar trabalhos de ETL e automatizar a transferência e transformação de dados.",
        "Explanation": "O AWS Glue é projetado especificamente para processos de ETL (Extrair, Transformar, Carregar), tornando-o ideal para mover e transformar dados do Amazon S3 para o Amazon RDS. Ele fornece uma arquitetura sem servidor que automatiza o agendamento e a execução de fluxos de trabalho de dados, garantindo a integridade dos dados e minimizando a sobrecarga operacional.",
        "Other Options": [
            "O AWS Step Functions é usado para gerenciar fluxos de trabalho complexos, mas não fornece capacidades nativas de ETL, exigindo serviços adicionais para a transformação de dados.",
            "O Amazon Kinesis Data Firehose é usado principalmente para transmissão de dados e pode não ser adequado para processamento em lote e transformação dos dados existentes no S3 antes de carregá-los no RDS.",
            "O AWS Batch é projetado para trabalhos de processamento em lote, mas não fornece uma maneira direta de orquestrar processos de ETL ou gerenciar o fluxo de dados entre S3 e RDS."
        ]
    },
    {
        "Question Number": "32",
        "Situation": "Uma empresa de streaming de mídia está enfrentando problemas de desempenho com seu serviço de entrega de vídeo, que está hospedado na AWS. Os usuários relataram buffering e atraso durante a reprodução de vídeo, especialmente durante horários de pico. Como Arquiteto de Soluções, você precisa melhorar o desempenho do serviço de streaming de vídeo para garantir uma experiência de usuário suave. (Selecione Dois)",
        "Question": "Quais das seguintes estratégias você deve implementar para otimizar o desempenho do serviço de entrega de vídeo?",
        "Options": {
            "1": "Configurar o Amazon Simple Storage Service (S3) para hospedar seus arquivos de vídeo sem nenhum mecanismo de cache à sua frente.",
            "2": "Implementar o Amazon CloudFront como uma rede de entrega de conteúdo (CDN) para armazenar em cache o conteúdo de vídeo mais próximo dos usuários e reduzir a latência.",
            "3": "Usar o AWS Global Accelerator para melhorar a disponibilidade e o desempenho de suas aplicações com usuários em várias regiões geográficas.",
            "4": "Implantar uma configuração multi-região para sua aplicação de processamento de mídia para garantir alta disponibilidade e baixa latência globalmente.",
            "5": "Habilitar o Amazon Elastic Transcoder para converter automaticamente arquivos de vídeo em vários formatos e resoluções para entrega otimizada."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Implementar o Amazon CloudFront como uma rede de entrega de conteúdo (CDN) para armazenar em cache o conteúdo de vídeo mais próximo dos usuários e reduzir a latência.",
            "Usar o AWS Global Accelerator para melhorar a disponibilidade e o desempenho de suas aplicações com usuários em várias regiões geográficas."
        ],
        "Explanation": "Implementar o Amazon CloudFront armazenará em cache o conteúdo de vídeo em locais de borda, reduzindo significativamente a latência para os usuários. Além disso, usar o AWS Global Accelerator otimiza a rota para sua aplicação, melhorando o desempenho para usuários espalhados por diferentes regiões.",
        "Other Options": [
            "Habilitar o Amazon Elastic Transcoder é benéfico para o processamento de mídia, mas não aborda diretamente os problemas de desempenho relacionados à entrega. Ele se concentra no formato e na qualidade do conteúdo, em vez de reduzir a latência.",
            "Implantar uma configuração multi-região pode melhorar a disponibilidade, mas pode não abordar diretamente os problemas de desempenho, a menos que combinado com uma CDN. Isso adiciona complexidade e custo sem garantir melhoria de desempenho por si só.",
            "Configurar o S3 sem mecanismos de cache provavelmente agravará os problemas de desempenho, pois os usuários teriam que recuperar o conteúdo de vídeo diretamente do S3 sem os benefícios do cache de borda, levando a um aumento da latência."
        ]
    },
    {
        "Question Number": "33",
        "Situation": "Um arquiteto de nuvem está projetando uma solução que requer a implantação de várias instâncias do Amazon EC2 em várias regiões para garantir alta disponibilidade e tolerância a falhas. O arquiteto precisa garantir que o número máximo de instâncias do EC2 possa ser provisionado sem atingir os limites de serviço.",
        "Question": "Quais combinações de ações o arquiteto deve tomar para gerenciar efetivamente as cotas de serviço do EC2? (Selecione Dois)",
        "Options": {
            "1": "Solicitar um aumento de limite para instâncias do EC2 através do AWS Support Center se os limites forem atingidos.",
            "2": "Configurar o Amazon EC2 Auto Scaling para ajustar dinamicamente o número de instâncias com base no tráfego.",
            "3": "Usar o AWS CloudFormation para automatizar a implantação de instâncias do EC2 sem considerar as cotas.",
            "4": "Implementar uma função do AWS Lambda para monitorar o uso de instâncias do EC2 e alertar quando os limites estiverem próximos.",
            "5": "Revisar os limites padrão de instâncias do EC2 para cada região no AWS Management Console."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Revisar os limites padrão de instâncias do EC2 para cada região no AWS Management Console.",
            "Solicitar um aumento de limite para instâncias do EC2 através do AWS Support Center se os limites forem atingidos."
        ],
        "Explanation": "Para gerenciar efetivamente as cotas de serviço do EC2, o arquiteto deve primeiro revisar os limites padrão para entender a capacidade disponível em cada região. Se as demandas do projeto excederem esses limites, solicitar um aumento de limite através do AWS Support Center é essencial para provisionar recursos adicionais.",
        "Other Options": [
            "Usar o AWS CloudFormation não considera as cotas de serviço e pode levar a implantações com falha se os limites forem excedidos, tornando essa uma ação ineficaz para gerenciar cotas.",
            "Embora monitorar o uso do EC2 seja benéfico, simplesmente implementar uma função Lambda para alertar quando os limites estiverem próximos não aborda diretamente a gestão das cotas de serviço e não garante capacidade de provisionamento.",
            "Configurar o EC2 Auto Scaling é útil para gerenciar a capacidade das instâncias com base na demanda, mas não aborda inherentemente a necessidade de entender ou solicitar aumentos nas cotas de serviço."
        ]
    },
    {
        "Question Number": "34",
        "Situation": "Uma empresa de e-commerce de médio porte deseja melhorar suas práticas de gerenciamento de custos na AWS. A empresa atualmente utiliza vários serviços da AWS, incluindo EC2, S3 e RDS. Eles querem configurar um sistema de alerta automatizado para notificar a equipe financeira quando seus gastos mensais excederem um limite pré-definido. Além disso, a equipe financeira requer um relatório mensal detalhado que forneça insights sobre o uso dos serviços e os custos associados. Qual é a maneira mais eficaz de atender a esses requisitos?",
        "Question": "Qual das seguintes opções atende melhor às necessidades da empresa em termos de gerenciamento de custos, alertas e relatórios na AWS?",
        "Options": {
            "1": "Utilizar AWS CloudTrail para registro e configurar alarmes do Amazon CloudWatch para monitorar gastos em todos os serviços.",
            "2": "Configurar AWS Budgets para enviar alertas quando o limite de custo for alcançado e usar AWS Cost Explorer para relatórios detalhados.",
            "3": "Implementar AWS Trusted Advisor para revisar o uso dos serviços e configurar scripts personalizados para relatórios de custo.",
            "4": "Habilitar AWS Config para rastrear mudanças de recursos e utilizar Amazon SNS para alertas sobre limites de custo."
        },
        "Correct Answer": "Configurar AWS Budgets para enviar alertas quando o limite de custo for alcançado e usar AWS Cost Explorer para relatórios detalhados.",
        "Explanation": "AWS Budgets é projetado especificamente para definir orçamentos de custo e uso, com a capacidade de enviar alertas quando os limites são ultrapassados. AWS Cost Explorer fornece insights detalhados sobre o uso dos serviços e custos, tornando esta opção a mais eficaz para os requisitos da empresa.",
        "Other Options": [
            "AWS CloudTrail é usado principalmente para auditoria de chamadas de API e não fornece diretamente monitoramento de custos ou capacidades de alerta, tornando-o insuficiente para as necessidades da empresa.",
            "AWS Trusted Advisor oferece recomendações para otimização de recursos da AWS, mas não fornece um mecanismo dedicado para alertas sobre limites de custo ou relatórios detalhados.",
            "AWS Config é usado para rastrear configurações de recursos e conformidade; não fornece monitoramento de custos e carece das capacidades de alerta necessárias para limites de gastos."
        ]
    },
    {
        "Question Number": "35",
        "Situation": "Uma grande empresa de mídia precisa transferir terabytes de dados de vídeo para o Amazon S3 para arquivamento e processamento. A empresa tem uma largura de banda de internet limitada e está preocupada com o tempo necessário para fazer o upload de um volume tão grande de dados. Eles estão avaliando qual aparelho AWS Snowball usar para a migração, considerando as várias opções disponíveis com base em suas necessidades de armazenamento e computação.",
        "Question": "Qual opção do AWS Snowball a empresa deve escolher para transferir eficientemente seus dados de vídeo, permitindo também algum pré-processamento no dispositivo?",
        "Options": {
            "1": "Selecionar a opção Standard Snowball com 50 TB de armazenamento para transferir os dados diretamente para o S3 sem quaisquer capacidades de computação.",
            "2": "Escolher a opção Snowball Edge Storage Optimized para utilizar a capacidade de armazenamento de 100 TB e 24 vCPUs para pré-processar os dados de vídeo antes de transferi-los para o S3.",
            "3": "Optar pelo serviço Snowmobile, que fornece 100 PB de armazenamento, para transferir todos os dados de vídeo para o S3 em uma única viagem.",
            "4": "Selecionar a opção Snowball Edge Compute Optimized para executar algoritmos avançados de aprendizado de máquina nos dados de vídeo antes de transferi-los para o S3."
        },
        "Correct Answer": "Escolher a opção Snowball Edge Storage Optimized para utilizar a capacidade de armazenamento de 100 TB e 24 vCPUs para pré-processar os dados de vídeo antes de transferi-los para o S3.",
        "Explanation": "A opção Snowball Edge Storage Optimized fornece a capacidade de armazenamento necessária e recursos de computação para realizar o pré-processamento dos dados de vídeo, tornando-a ideal para as necessidades da empresa de transferir grandes volumes de dados enquanto também utiliza capacidades de computação.",
        "Other Options": [
            "A opção Standard Snowball não possui capacidades de computação e não permitiria qualquer pré-processamento dos dados de vídeo, tornando-a inadequada para os requisitos da empresa.",
            "O serviço Snowmobile é projetado para migrações de dados extremamente grandes, mas seria excessivo para terabytes de dados de vídeo e não oferece capacidades de pré-processamento.",
            "A opção Snowball Edge Compute Optimized é mais adequada para executar cargas de trabalho avançadas de aprendizado de máquina e pode não fornecer capacidade de armazenamento suficiente para as necessidades da empresa em comparação com a opção Storage Optimized."
        ]
    },
    {
        "Question Number": "36",
        "Situation": "Uma grande empresa está migrando para a AWS e precisa de uma solução centralizada para gerenciar identidades de usuários e acesso em várias contas e aplicativos da AWS. A empresa atualmente utiliza o Microsoft Active Directory para seu gerenciamento de identidade e deseja implementar uma solução de autenticação para a força de trabalho que suporte capacidades de login único.",
        "Question": "Qual das seguintes soluções a empresa deve implementar para atender melhor aos seus requisitos de gerenciamento centralizado de identidade e acesso de login único?",
        "Options": {
            "1": "Configurar várias contas da AWS com usuários IAM individuais em cada conta para gerenciar o controle de acesso e gerenciamento de usuários.",
            "2": "Implantar o AWS Directory Service para criar um repositório de identidade separado e gerenciar o acesso dos usuários diretamente dentro de cada conta da AWS.",
            "3": "Implementar o AWS IAM Identity Center para conectar ao Microsoft Active Directory existente e gerenciar o acesso dos usuários em contas da AWS.",
            "4": "Usar o Amazon Cognito para criar identidades de usuários e gerenciar a autenticação em todos os serviços e aplicativos da AWS."
        },
        "Correct Answer": "Implementar o AWS IAM Identity Center para conectar ao Microsoft Active Directory existente e gerenciar o acesso dos usuários em contas da AWS.",
        "Explanation": "O AWS IAM Identity Center é projetado para gerenciamento centralizado de identidade, permitindo que as organizações conectem suas fontes de identidade existentes, como o Microsoft Active Directory. Ele fornece capacidades de login único em várias contas e aplicativos da AWS, o que se alinha perfeitamente com os requisitos da empresa.",
        "Other Options": [
            "O AWS Directory Service exigiria um repositório de identidade separado e não forneceria o gerenciamento centralizado necessário em várias contas, o que não se alinha com o objetivo da empresa.",
            "O Amazon Cognito é mais focado na autenticação de usuários em nível de aplicativo e não é ideal para gerenciar o acesso em várias contas da AWS em um ambiente corporativo.",
            "Configurar usuários IAM individuais em cada conta levaria a um gerenciamento de identidade fragmentado, dificultando o gerenciamento de acesso e a criação de uma experiência de login único contínua."
        ]
    },
    {
        "Question Number": "37",
        "Situation": "Uma plataforma global de e-commerce está planejando aprimorar sua estratégia de recuperação de desastres. A empresa opera em várias regiões e precisa garantir que seu aplicativo possa se recuperar rapidamente de interrupções, minimizando o tempo de inatividade e a perda de dados. O arquiteto de soluções foi encarregado de identificar as estratégias de recuperação de desastres apropriadas que equilibrem custo e objetivos de tempo de recuperação.",
        "Question": "Qual das seguintes estratégias de recuperação de desastres o arquiteto de soluções deve considerar implementar? (Selecione duas)",
        "Options": {
            "1": "Estratégia de espera fria sem componentes ativos durante as operações normais",
            "2": "Estratégia de Pilot Light com componentes essenciais funcionando em modo de espera",
            "3": "Estratégia de backup e restauração com dados armazenados em uma única região",
            "4": "Estratégia de espera morna com uma versão reduzida de um ambiente totalmente funcional",
            "5": "Estratégia multi-site com implantações ativas-ativas em várias regiões"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Estratégia de Pilot Light com componentes essenciais funcionando em modo de espera",
            "Estratégia de espera morna com uma versão reduzida de um ambiente totalmente funcional"
        ],
        "Explanation": "A estratégia de Pilot Light permite que componentes críticos estejam prontos para escalar rapidamente quando necessário, enquanto a estratégia de espera morna mantém um ambiente parcialmente em funcionamento que pode ser rapidamente levado à plena capacidade em caso de falha. Ambas as estratégias proporcionam um equilíbrio eficaz entre custo e velocidade de recuperação para cenários de recuperação de desastres.",
        "Other Options": [
            "A estratégia de backup e restauração geralmente envolve tempos de recuperação mais longos e pode levar à perda de dados se não for gerenciada cuidadosamente, pois depende de backups sendo restaurados de um único local.",
            "A estratégia multi-site, embora forneça os tempos de recuperação mais rápidos, pode ser significativamente mais cara devido à manutenção de ambientes totalmente operacionais em várias regiões, o que pode não ser justificado para todos os aplicativos.",
            "A estratégia de espera fria não é ideal para recuperação rápida, pois envolve trazer recursos de um estado inativo, levando a tempos de inatividade mais longos e potencial perda de dados."
        ]
    },
    {
        "Question Number": "38",
        "Situation": "Uma empresa hospeda um aplicativo crítico que processa dados em tempo real em uma instância do Amazon EC2. O aplicativo está enfrentando interrupções ocasionais devido a falhas na instância, o que impacta as operações comerciais. O arquiteto de soluções precisa implementar uma arquitetura altamente disponível e resiliente que possa lidar com falhas na instância com mínima interrupção ao aplicativo e garantir que os dados sejam processados continuamente.",
        "Question": "Qual das seguintes soluções atende aos requisitos de alta disponibilidade e resiliência enquanto minimiza a interrupção ao aplicativo?",
        "Options": {
            "1": "Criar um snapshot da instância do EC2 e agendá-lo para ser executado a cada hora. Em caso de falha da instância, iniciar manualmente uma nova instância do EC2 usando o snapshot mais recente para restaurar o aplicativo.",
            "2": "Usar o Amazon ECS com Fargate para executar o aplicativo de forma serverless. Configurar um serviço com várias tarefas distribuídas em várias Zonas de Disponibilidade. Implementar um Application Load Balancer para direcionar o tráfego para as tarefas.",
            "3": "Implantar o aplicativo em uma única instância do EC2 com um volume do Amazon Elastic Block Store (EBS) anexado para armazenamento de dados. Criar um backup do volume EBS usando o Amazon Data Lifecycle Manager para restaurar em caso de falha.",
            "4": "Criar um grupo de Auto Scaling com várias instâncias do EC2 em várias Zonas de Disponibilidade. Usar um Application Load Balancer (ALB) para distribuir o tráfego de entrada para as instâncias no grupo de Auto Scaling. Configurar verificações de saúde para o ALB para garantir que o tráfego seja enviado apenas para instâncias saudáveis."
        },
        "Correct Answer": "Criar um grupo de Auto Scaling com várias instâncias do EC2 em várias Zonas de Disponibilidade. Usar um Application Load Balancer (ALB) para distribuir o tráfego de entrada para as instâncias no grupo de Auto Scaling. Configurar verificações de saúde para o ALB para garantir que o tráfego seja enviado apenas para instâncias saudáveis.",
        "Explanation": "Esta solução fornece alta disponibilidade e resiliência ao utilizar um grupo de Auto Scaling com instâncias espalhadas por várias Zonas de Disponibilidade. O Application Load Balancer garante que o tráfego seja enviado apenas para instâncias saudáveis, minimizando o tempo de inatividade e a interrupção para os usuários.",
        "Other Options": [
            "Implantar o aplicativo em uma única instância do EC2 não fornece alta disponibilidade, pois a falha dessa instância resultaria em tempo de inatividade. Embora os backups sejam úteis, eles não garantem operação contínua durante falhas.",
            "Usar o Amazon ECS com Fargate oferece uma abordagem serverless, mas se não for configurado corretamente, pode não fornecer alta disponibilidade. No entanto, é uma opção válida para resiliência; falta a menção explícita de verificações de saúde e distribuição equilibrada de tráfego em comparação com a resposta correta.",
            "Criar um snapshot da instância do EC2 não fornece capacidades imediatas de failover. Esta abordagem depende de intervenção manual e não garante operação contínua, tornando-a menos adequada para requisitos de alta disponibilidade."
        ]
    },
    {
        "Question Number": "39",
        "Situation": "Uma empresa de serviços financeiros tem a tarefa de garantir que os dados de transação de seus clientes estejam protegidos contra perda de dados e interrupções de serviço. Eles exigem um Objetivo de Tempo de Recuperação (RTO) de 30 minutos e um Objetivo de Ponto de Recuperação (RPO) de 15 minutos. A arquitetura deve permanecer operacional mesmo no caso de uma falha completa da Região da AWS.",
        "Question": "Qual das seguintes soluções atende melhor aos requisitos de RTO e RPO para este cenário?",
        "Options": {
            "1": "Configurar uma arquitetura ativa-passiva com replicação de dados a cada 15 minutos para uma região secundária, e um processo de failover que pode ser executado em até 30 minutos.",
            "2": "Implementar uma configuração de espera morna que realiza backups a cada hora para outra região, permitindo uma intervenção manual para restaurar os serviços.",
            "3": "Usar o Amazon S3 para armazenamento de dados e configurar políticas de ciclo de vida para replicar dados para outra região a cada hora, fornecendo um processo de failover manual.",
            "4": "Implementar uma arquitetura ativa-ativa em várias Regiões da AWS com replicação de dados síncrona para garantir que não haja perda de dados."
        },
        "Correct Answer": "Configurar uma arquitetura ativa-passiva com replicação de dados a cada 15 minutos para uma região secundária, e um processo de failover que pode ser executado em até 30 minutos.",
        "Explanation": "Esta opção fornece o RPO exigido de 15 minutos através da replicação frequente de dados e atende ao RTO de 30 minutos com um processo de failover automático, garantindo mínima inatividade e perda de dados.",
        "Other Options": [
            "Embora uma arquitetura ativa-ativa forneça baixa latência e alta disponibilidade, pode introduzir complexidade e potencialmente custos mais altos sem garantir o RTO e RPO exigidos para este cenário específico.",
            "Usar o Amazon S3 com replicação horária não atende ao RPO de 15 minutos, pois permite uma perda máxima de dados de uma hora, o que excede o requisito.",
            "Uma configuração de espera morna com backups a cada hora não satisfaz o RTO de 30 minutos porque exigiria mais tempo para colocar os serviços online em comparação com os requisitos especificados."
        ]
    },
    {
        "Question Number": "40",
        "Situation": "Uma empresa de serviços financeiros está expandindo suas operações para várias contas da AWS para melhorar a gestão de recursos e a conformidade. Eles querem implementar uma estrutura de governança que permita a gestão centralizada de políticas e controles de segurança em todas as suas contas da AWS. Eles estão considerando usar AWS Control Tower e AWS Organizations como parte de sua estratégia de governança.",
        "Question": "Qual das seguintes configurações proporcionará a gestão de governança e conformidade MAIS eficaz para a configuração de múltiplas contas da empresa?",
        "Options": {
            "1": "Configurar o AWS Control Tower para criar contas com guardrails pré-configurados. Usar o AWS Organizations para gerenciar as contas, mas não aplicar SCPs, confiando apenas em funções IAM para gerenciar permissões e conformidade.",
            "2": "Criar uma conta central da AWS e vincular todas as outras contas usando o AWS Organizations. Implementar regras do AWS Config para verificações de conformidade, mas não usar o AWS Control Tower ou qualquer guardrail para simplificar a gestão.",
            "3": "Usar o AWS Organizations para criar uma estrutura de múltiplas contas e aplicar manualmente políticas IAM entre as contas. Configurar logs individuais do CloudTrail para cada conta para monitorar atividades e garantir conformidade com políticas internas.",
            "4": "Implementar o AWS Control Tower para configurar um novo ambiente de múltiplas contas e aplicar os guardrails fornecidos. Usar o AWS Organizations para gerenciar a criação de contas e aplicar SCPs para controles de conformidade adicionais. Auditar regularmente as contas usando o AWS Config."
        },
        "Correct Answer": "Implementar o AWS Control Tower para configurar um novo ambiente de múltiplas contas e aplicar os guardrails fornecidos. Usar o AWS Organizations para gerenciar a criação de contas e aplicar SCPs para controles de conformidade adicionais. Auditar regularmente as contas usando o AWS Config.",
        "Explanation": "Usar o AWS Control Tower permite que a empresa configure rapidamente um ambiente seguro de múltiplas contas com guardrails de conformidade integrados. Acoplar isso com o AWS Organizations possibilita a gestão centralizada e a aplicação de Políticas de Controle de Serviço (SCPs) para uma governança aprimorada. Auditorias regulares com o AWS Config garantem conformidade contínua.",
        "Other Options": [
            "Usar apenas o AWS Organizations para políticas IAM pode levar a inconsistências e aumentar o esforço manual. Sem a automação e os guardrails do AWS Control Tower, a conformidade pode ser mais desafiadora e menos eficaz.",
            "Configurar o AWS Control Tower sem aplicar SCPs limita as capacidades de governança. Confiar apenas em funções IAM para permissões pode expor as contas a riscos devido à falta de controle e supervisão centralizados.",
            "Criar uma conta central e confiar em regras do AWS Config sem usar o AWS Control Tower ou guardrails deixa o ambiente vulnerável a configurações incorretas e não aproveita todas as capacidades das ferramentas de governança da AWS."
        ]
    },
    {
        "Question Number": "41",
        "Situation": "Uma empresa de serviços financeiros opera um aplicativo crítico que processa transações em tempo real. O aplicativo está hospedado em instâncias do Amazon EC2 dentro de um grupo de Auto Scaling em várias Zonas de Disponibilidade. O arquiteto é encarregado de garantir que o aplicativo possa suportar falhas e se recuperar sem problemas, sem perda de dados. O aplicativo grava dados de transação em um banco de dados Amazon RDS. A empresa requer uma solução que minimize o tempo de inatividade e garanta a integridade dos dados.",
        "Question": "Qual das seguintes estratégias o arquiteto de soluções deve implementar para projetar para falhas e garantir uma recuperação sem interrupções?",
        "Options": {
            "1": "Implementar snapshots do Amazon RDS para criar backups antes de cada transação. Usar AWS Lambda para automatizar procedimentos de failover e recuperação.",
            "2": "Implantar uma réplica de leitura da instância do Amazon RDS em outra região. Usar o Amazon Route 53 para failover de DNS para redirecionar o tráfego em caso de falha.",
            "3": "Implementar implantações Multi-AZ do Amazon RDS para garantir alta disponibilidade e failover automático para o banco de dados. Usar um bucket do Amazon S3 para backups e habilitar recuperação ponto-a-ponto.",
            "4": "Implantar o aplicativo no Amazon ECS com uma configuração de service mesh. Armazenar logs de transação em uma tabela do Amazon DynamoDB para recuperação rápida."
        },
        "Correct Answer": "Implementar implantações Multi-AZ do Amazon RDS para garantir alta disponibilidade e failover automático para o banco de dados. Usar um bucket do Amazon S3 para backups e habilitar recuperação ponto-a-ponto.",
        "Explanation": "Implementar implantações Multi-AZ do Amazon RDS fornece alta disponibilidade e failover automático para o banco de dados, o que é essencial para um aplicativo crítico que lida com transações em tempo real. Usar o Amazon S3 para backups e habilitar a recuperação ponto-a-ponto garante a integridade dos dados e a recuperabilidade em caso de falhas.",
        "Other Options": [
            "Implantar uma réplica de leitura em outra região não fornece failover automático para o banco de dados primário e pode introduzir latência adicional para operações de gravação. Esta opção não é adequada para um aplicativo crítico que requer recuperação imediata.",
            "Usar snapshots do RDS antes de cada transação não é uma estratégia viável para garantir zero perda de dados, pois os snapshots levam tempo para serem criados e podem não capturar dados em tempo real, arriscando a perda de transações recentes em caso de falha.",
            "Implantar o aplicativo no Amazon ECS com um service mesh não aborda diretamente a alta disponibilidade e recuperabilidade do banco de dados. Armazenar logs de transação no DynamoDB pode não garantir a integridade dos dados transacionais necessários para o aplicativo."
        ]
    },
    {
        "Question Number": "42",
        "Situation": "Uma empresa de serviços financeiros implementou recentemente uma ferramenta de varredura de vulnerabilidades que roda à noite em seu ambiente AWS. A ferramenta identifica várias vulnerabilidades, mas a equipe tem dificuldade em responder rapidamente e de forma eficaz a essas descobertas. Eles querem priorizar respostas automatizadas para melhorar sua postura de segurança e reduzir a intervenção manual. (Selecione Dois)",
        "Question": "Quais das seguintes respostas automatizadas devem ser priorizadas para abordar as vulnerabilidades detectadas?",
        "Options": {
            "1": "Agendar revisões manuais regulares das descobertas de vulnerabilidades para discutir com a equipe de segurança.",
            "2": "Configurar alarmes do CloudWatch para notificar a equipe sempre que uma vulnerabilidade for detectada sem remediação automatizada.",
            "3": "Utilizar regras do AWS Config para garantir conformidade com as melhores práticas de segurança e remediar automaticamente recursos não conformes.",
            "4": "Implementar funções do AWS Lambda para remediar automaticamente vulnerabilidades comuns com base na gravidade.",
            "5": "Integrar documentos de Automação do AWS Systems Manager para executar ações de remediação predefinidas para vulnerabilidades."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Implementar funções do AWS Lambda para remediar automaticamente vulnerabilidades comuns com base na gravidade.",
            "Integrar documentos de Automação do AWS Systems Manager para executar ações de remediação predefinidas para vulnerabilidades."
        ],
        "Explanation": "Implementar funções do AWS Lambda para remediação automática permite uma resposta imediata a vulnerabilidades com base em sua gravidade, minimizando a janela de exposição. Além disso, integrar documentos de Automação do AWS Systems Manager permite que ações predefinidas sejam executadas, agilizando o processo de remediação e garantindo consistência no tratamento de vulnerabilidades.",
        "Other Options": [
            "Agendar revisões manuais regulares não fornece uma resposta automatizada e pode atrasar o processo de remediação, deixando vulnerabilidades sem tratamento por períodos mais longos.",
            "Configurar alarmes do CloudWatch para notificações sem remediação automatizada não resolve as vulnerabilidades; apenas alerta a equipe, o que pode levar a tempos de resposta mais lentos.",
            "Usar regras do AWS Config foca na conformidade em vez da remediação direta de vulnerabilidades, e embora ajude a manter a postura de segurança geral, não aborda a necessidade imediata de respostas automatizadas para vulnerabilidades detectadas."
        ]
    },
    {
        "Question Number": "43",
        "Situation": "Uma empresa de serviços financeiros está migrando seu armazenamento de dados para a AWS. Eles precisam de uma solução que possa fornecer alta taxa de transferência e baixa latência para suas aplicações de processamento de dados. A empresa também precisa de uma solução que possa escalar facilmente para acomodar cargas de trabalho flutuantes e oferece recursos para replicação automática de dados entre regiões para recuperação de desastres. Além disso, eles querem garantir que os dados sejam acessíveis a partir de várias máquinas virtuais de forma contínua.",
        "Question": "Qual combinação de serviço de armazenamento da AWS atenderia melhor aos requisitos da empresa para alta taxa de transferência, baixa latência, escalabilidade e replicação entre regiões?",
        "Options": {
            "1": "Amazon EFS com taxa de transferência provisionada e replicação entre regiões habilitada.",
            "2": "Amazon S3 com políticas de ciclo de vida para gerenciamento de dados e versionamento habilitados.",
            "3": "Amazon FSx for Lustre com replicação de dados entre várias Zonas de Disponibilidade.",
            "4": "Amazon S3 com S3 Transfer Acceleration e replicação entre regiões habilitada."
        },
        "Correct Answer": "Amazon FSx for Lustre com replicação de dados entre várias Zonas de Disponibilidade.",
        "Explanation": "Amazon FSx for Lustre é otimizado para alta taxa de transferência e baixa latência, tornando-o adequado para aplicações de processamento de dados. Ele suporta replicação de dados, o que melhora a durabilidade e a disponibilidade entre várias Zonas de Disponibilidade.",
        "Other Options": [
            "Amazon S3 com S3 Transfer Acceleration e replicação entre regiões habilitada não é a melhor opção, pois é principalmente armazenamento de objetos e pode não fornecer a baixa latência necessária para aplicações de processamento de dados.",
            "Amazon EFS com taxa de transferência provisionada e replicação entre regiões habilitada é mais adequado para armazenamento de arquivos, mas pode não entregar a alta taxa de transferência necessária para cargas de trabalho intensivas de processamento de dados.",
            "Amazon S3 com políticas de ciclo de vida para gerenciamento de dados e versionamento habilitados não atende aos requisitos de desempenho de alta taxa de transferência e baixa latência para aplicações de processamento de dados."
        ]
    },
    {
        "Question Number": "44",
        "Situation": "Uma empresa possui uma aplicação de processamento de dados em tempo real que ingere e processa dados de eventos de vários dispositivos IoT. A arquitetura atual consiste em várias instâncias do Amazon EC2 executando um framework de processamento de dados, mas a empresa deseja reduzir custos e simplificar operações migrando para uma arquitetura sem servidor.",
        "Question": "Qual é a abordagem mais eficaz para transitar esta aplicação para uma arquitetura sem servidor, mantendo as capacidades de processamento em tempo real?",
        "Options": {
            "1": "Migrar o processamento de dados para o AWS Batch com Instâncias Spot do EC2 para lidar com os eventos de dados que chegam. Usar o Amazon SNS para notificar os trabalhos do Batch sobre novos eventos.",
            "2": "Implementar um cluster do Amazon Elastic MapReduce (EMR) com capacidades sem servidor para lidar com o processamento de dados de eventos. Usar o Amazon DynamoDB para armazenar os resultados.",
            "3": "Usar funções do AWS Lambda com Amazon Kinesis Data Streams para processar os dados de eventos em tempo real. Configurar o stream do Kinesis para acionar as funções Lambda para cada evento de dados.",
            "4": "Utilizar o Amazon SQS para armazenar em buffer os dados de eventos e configurar uma frota de instâncias do AWS EC2 para consultar a fila do SQS para processamento. Usar Auto Scaling para gerenciar as instâncias do EC2."
        },
        "Correct Answer": "Usar funções do AWS Lambda com Amazon Kinesis Data Streams para processar os dados de eventos em tempo real. Configurar o stream do Kinesis para acionar as funções Lambda para cada evento de dados.",
        "Explanation": "Usar AWS Lambda com Amazon Kinesis Data Streams fornece uma arquitetura sem servidor totalmente gerenciada que pode escalar facilmente para lidar com o processamento de dados em tempo real. Essa abordagem minimiza a sobrecarga operacional enquanto garante baixa latência e resposta imediata a eventos que chegam.",
        "Other Options": [
            "Migrar para o AWS Batch com Instâncias Spot do EC2 ainda exigiria gerenciar instâncias do EC2, o que não cumpre o objetivo de adotar uma arquitetura sem servidor.",
            "Usar o Amazon SQS com uma frota de instâncias do EC2 requer gerenciamento contínuo dessas instâncias e não aproveita os benefícios de uma abordagem verdadeiramente sem servidor, levando a custos mais altos e complexidade operacional.",
            "Implementar um cluster do Amazon EMR, embora possa processar grandes conjuntos de dados, não é inerentemente sem servidor e exigiria gerenciamento e configuração adicionais, o que vai contra o objetivo de simplificar operações."
        ]
    },
    {
        "Question Number": "45",
        "Situation": "Uma empresa de serviços financeiros está desenvolvendo uma aplicação sem servidor para processar transações em tempo real. O arquiteto de soluções decidiu usar o AWS Serverless Application Model (AWS SAM) para implantação. A aplicação requer várias funções do AWS Lambda, um API Gateway e permissões do IAM para acessar recursos da AWS. O arquiteto quer garantir que o processo de implantação seja eficiente e gerenciável.",
        "Question": "Qual das seguintes abordagens permitirá que o arquiteto defina e implante a aplicação sem servidor usando o AWS SAM, mantendo uma estrutura limpa e compreensível no template?",
        "Options": {
            "1": "Definir cada função do AWS Lambda e seus recursos associados em templates separados do AWS SAM e, em seguida, implantar manualmente cada template para criar a aplicação.",
            "2": "Usar o AWS SAM para criar um único stack do AWS CloudFormation que inclua todos os recursos necessários para a aplicação, definindo cada recurso no mesmo arquivo de template.",
            "3": "Utilizar o AWS SAM para criar um stack separado do CloudFormation para cada função Lambda e seus recursos, vinculando-os juntos com saídas e importações.",
            "4": "Aproveitar as capacidades integradas do AWS SAM para definir a aplicação sem servidor em um único template usando a seção 'Resources' para funções Lambda, API Gateway e funções IAM necessárias."
        },
        "Correct Answer": "Aproveitar as capacidades integradas do AWS SAM para definir a aplicação sem servidor em um único template usando a seção 'Resources' para funções Lambda, API Gateway e funções IAM necessárias.",
        "Explanation": "Essa abordagem utiliza efetivamente o AWS SAM para gerenciar toda a aplicação sem servidor dentro de um único template, proporcionando uma estrutura clara e simplificando o processo de implantação por meio do uso de recursos do SAM, como funções Lambda e integração com o API Gateway.",
        "Other Options": [
            "Essa opção pode levar a um processo de implantação convoluto e dificultar o gerenciamento de dependências e configurações entre vários recursos, negando os benefícios de usar o AWS SAM.",
            "Implantar templates separados para cada função pode complicar o processo de implantação e aumentar a sobrecarga, o que não é ideal para uma arquitetura sem servidor que o AWS SAM visa simplificar.",
            "Embora criar stacks separados possa ser útil em alguns cenários, isso adiciona complexidade no gerenciamento das interações entre diferentes recursos e pode levar a uma experiência de implantação mais fragmentada."
        ]
    },
    {
        "Question Number": "46",
        "Situation": "Uma empresa global de comércio eletrônico implantou seu aplicativo web em várias Regiões da AWS para garantir alta disponibilidade e baixa latência para usuários em todo o mundo. Eles implementaram o AWS Global Accelerator para direcionar o tráfego de entrada para seus Application Load Balancers em cada Região. No entanto, eles notam um desempenho inconsistente durante os horários de pico de tráfego e buscam soluções para otimizar sua configuração. (Selecione Dois)",
        "Question": "Qual das seguintes configurações ajudará a melhorar o desempenho e a disponibilidade do aplicativo? (Selecione Dois)",
        "Options": {
            "1": "Implemente o AWS Shield Advanced para fornecer proteção DDoS aprimorada para seus endpoints do Global Accelerator.",
            "2": "Configure o Global Accelerator com dois endereços IP estáticos e habilite o recurso Anycast para direcionar o tráfego para a Região mais próxima.",
            "3": "Utilize o Amazon CloudFront como uma camada de cache na frente do aplicativo para reduzir a latência para usuários globais.",
            "4": "Configure verificações de saúde no Global Accelerator para garantir que o tráfego seja enviado apenas para endpoints saudáveis em todas as Regiões.",
            "5": "Implante Load Balancers adicionais em cada Região para lidar com o aumento do tráfego durante os horários de pico."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Configure o Global Accelerator com dois endereços IP estáticos e habilite o recurso Anycast para direcionar o tráfego para a Região mais próxima.",
            "Configure verificações de saúde no Global Accelerator para garantir que o tráfego seja enviado apenas para endpoints saudáveis em todas as Regiões."
        ],
        "Explanation": "Configurar o Global Accelerator com Anycast permite que o tráfego seja direcionado para o endpoint saudável mais próximo, melhorando o desempenho e a disponibilidade. Além disso, configurar verificações de saúde garante que os usuários não sejam direcionados para endpoints não saudáveis, aumentando ainda mais a confiabilidade do aplicativo.",
        "Other Options": [
            "Embora implantar Load Balancers adicionais possa ajudar a lidar com o aumento do tráfego, isso não aborda diretamente os benefícios de roteamento e desempenho fornecidos pelo Global Accelerator.",
            "Implementar o AWS Shield Advanced fornece proteção DDoS, mas não otimiza o roteamento de tráfego ou o desempenho diretamente através do Global Accelerator.",
            "Utilizar o Amazon CloudFront pode reduzir a latência, mas é um serviço separado e não aproveita os benefícios das capacidades de roteamento do Global Accelerator."
        ]
    },
    {
        "Question Number": "47",
        "Situation": "Uma empresa de serviços financeiros opera várias VPCs em diferentes regiões para gerenciar dados sensíveis de clientes. A empresa precisa estabelecer conectividade segura e eficiente entre essas VPCs para comunicação de aplicativos, minimizando a latência e o custo. O arquiteto de soluções é encarregado de avaliar as melhores opções de conectividade para atender a esses requisitos.",
        "Question": "Qual das seguintes soluções melhor atende às necessidades de conectividade entre várias VPCs, garantindo segurança e baixa latência?",
        "Options": {
            "1": "Configure conexões VPN entre cada par de VPCs, garantindo comunicação criptografada, mas resultando em gerenciamento complexo e potenciais problemas de desempenho.",
            "2": "Utilize o AWS Direct Connect para estabelecer uma conexão dedicada a cada VPC, proporcionando baixa latência, mas exigindo um investimento significativo em infraestrutura e gerenciamento.",
            "3": "Crie conexões de peering entre todas as VPCs, configurando manualmente as tabelas de roteamento para cada conexão para garantir o fluxo de tráfego adequado, mantendo a segurança.",
            "4": "Use o AWS Transit Gateway para interconectar as VPCs, permitindo gerenciamento centralizado das conexões e permitindo comunicação escalável e segura entre todas as VPCs."
        },
        "Correct Answer": "Use o AWS Transit Gateway para interconectar as VPCs, permitindo gerenciamento centralizado das conexões e permitindo comunicação escalável e segura entre todas as VPCs.",
        "Explanation": "O AWS Transit Gateway simplifica o processo de interconexão de várias VPCs, fornecendo um hub central que permite roteamento e gerenciamento eficientes. Ele suporta milhares de VPCs e permite comunicação escalável e segura, tornando-se a melhor escolha para este cenário.",
        "Other Options": [
            "Criar conexões de peering entre VPCs pode se tornar complexo e trabalhoso à medida que o número de VPCs aumenta, levando a uma sobrecarga de gerenciamento e potenciais problemas de roteamento.",
            "Configurar conexões VPN entre cada par de VPCs adiciona complexidade significativa e potenciais gargalos de desempenho, já que cada conexão deve ser gerenciada individualmente.",
            "Utilizar o AWS Direct Connect requer um investimento substancial em infraestrutura e gerenciamento contínuo, tornando-o menos adequado para cenários onde flexibilidade e custos mais baixos são prioridades."
        ]
    },
    {
        "Question Number": "48",
        "Situation": "Uma empresa global está migrando seus aplicativos para a AWS e deseja implementar uma estratégia de múltiplas contas usando o AWS Organizations. O objetivo é aumentar a segurança, simplificar a cobrança e gerenciar recursos de forma eficaz entre várias equipes e departamentos.",
        "Question": "Qual das seguintes estratégias o arquiteto de soluções deve recomendar para criar um ambiente AWS de múltiplas contas seguro e eficiente que atenda às necessidades da organização?",
        "Options": {
            "1": "Crie uma conta separada para cada equipe de aplicativo e aplique tags de recursos para gerenciamento de custos.",
            "2": "Consolide todas as contas em uma única conta para simplificar a cobrança e o gerenciamento de recursos.",
            "3": "Use um único papel IAM para todas as contas para gerenciar permissões de forma uniforme em toda a organização.",
            "4": "Implemente Políticas de Controle de Serviço (SCPs) no AWS Organizations para impor governança entre as contas."
        },
        "Correct Answer": "Implemente Políticas de Controle de Serviço (SCPs) no AWS Organizations para impor governança entre as contas.",
        "Explanation": "Implementar Políticas de Controle de Serviço (SCPs) permite que a organização defina limites de permissão entre várias contas, garantindo que as contas possam acessar apenas os serviços da AWS que são necessários para suas funções específicas. Isso aumenta a segurança e a conformidade, permitindo ao mesmo tempo um gerenciamento centralizado.",
        "Other Options": [
            "Consolidar todas as contas em uma única conta elimina os benefícios de isolamento e segurança que vêm de uma estratégia de múltiplas contas, como limitar o raio de explosão e controles de acesso mais granulares.",
            "Usar um único papel IAM para todas as contas não é uma boa prática, pois pode levar a um acesso excessivamente permissivo e não aproveita os benefícios da separação de contas e políticas IAM distintas adaptadas a funções ou equipes específicas.",
            "Criar uma conta separada para cada equipe de aplicativo e aplicar tags de recursos sozinhas não impõe políticas de governança ou segurança de forma eficaz. Embora a tagueação seja útil para gerenciamento de custos, não fornece os controles necessários que as SCPs oferecem."
        ]
    },
    {
        "Question Number": "49",
        "Situation": "Uma empresa de serviços financeiros implantou um aplicativo crítico na AWS que está enfrentando interrupções intermitentes. O arquiteto de soluções foi encarregado de melhorar a confiabilidade do aplicativo para garantir desempenho e disponibilidade consistentes. A arquitetura atual inclui instâncias EC2 em um Grupo de Auto Scaling em várias Zonas de Disponibilidade. O arquiteto precisa recomendar estratégias para aumentar a confiabilidade.",
        "Question": "Quais das seguintes estratégias o arquiteto deve implementar para melhorar a confiabilidade? (Selecione Duas)",
        "Options": {
            "1": "Usar funções AWS Lambda para lidar com tarefas assíncronas e reduzir a carga no aplicativo principal.",
            "2": "Implantar o Amazon RDS em uma configuração Multi-AZ para fornecer alta disponibilidade para a camada de banco de dados.",
            "3": "Implementar o AWS Global Accelerator para direcionar o tráfego e melhorar a disponibilidade entre regiões.",
            "4": "Configurar uma verificação de saúde do Amazon Route 53 para monitorar os endpoints do aplicativo e acionar a troca em caso de falha.",
            "5": "Configurar o Amazon CloudFront para armazenar em cache conteúdo estático e reduzir a carga nos servidores de origem."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Implantar o Amazon RDS em uma configuração Multi-AZ para fornecer alta disponibilidade para a camada de banco de dados.",
            "Configurar uma verificação de saúde do Amazon Route 53 para monitorar os endpoints do aplicativo e acionar a troca em caso de falha."
        ],
        "Explanation": "Implantar o Amazon RDS em uma configuração Multi-AZ garante que haja uma instância de espera disponível em caso de falha da instância primária, aumentando assim a confiabilidade do banco de dados. Além disso, configurar uma verificação de saúde do Amazon Route 53 permite o monitoramento automatizado dos endpoints do aplicativo e pode facilitar a troca para instâncias saudáveis em caso de interrupções, melhorando ainda mais a confiabilidade.",
        "Other Options": [
            "Implementar o AWS Global Accelerator pode melhorar o desempenho e reduzir a latência, mas não melhora diretamente a confiabilidade do aplicativo em si.",
            "Configurar o Amazon CloudFront é benéfico para o cache e pode melhorar o desempenho, mas não aborda as preocupações centrais de confiabilidade relacionadas ao aplicativo e ao banco de dados.",
            "Usar funções AWS Lambda pode ajudar a descarregar tarefas, mas não melhora inerentemente a confiabilidade do aplicativo principal, pois é um serviço separado."
        ]
    },
    {
        "Question Number": "50",
        "Situation": "Uma empresa de serviços financeiros está migrando seus aplicativos para a AWS e precisa de uma maneira confiável de gerenciar informações sensíveis, como credenciais de banco de dados, chaves de API e outros segredos. A empresa requer uma solução que se integre perfeitamente com seus serviços AWS existentes, forneça controle de acesso e garanta armazenamento e recuperação seguros de segredos sem codificá-los diretamente no código do aplicativo. (Selecione Duas)",
        "Question": "Qual das seguintes soluções o arquiteto de soluções deve implementar para atender aos requisitos da empresa para gerenciamento de segredos?",
        "Options": {
            "1": "Implementar o AWS Systems Manager Parameter Store com criptografia para armazenar segredos e parâmetros.",
            "2": "Armazenar informações sensíveis no Amazon S3 com criptografia do lado do servidor ativada.",
            "3": "Usar o AWS Secrets Manager para armazenar e gerenciar todas as informações sensíveis de forma segura.",
            "4": "Usar funções IAM para embutir credenciais diretamente no código do aplicativo para facilitar o acesso.",
            "5": "Implantar uma solução de cofre auto-hospedada em instâncias EC2 para gerenciamento de segredos."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Usar o AWS Secrets Manager para armazenar e gerenciar todas as informações sensíveis de forma segura.",
            "Implementar o AWS Systems Manager Parameter Store com criptografia para armazenar segredos e parâmetros."
        ],
        "Explanation": "O AWS Secrets Manager permite o armazenamento e gerenciamento seguros de informações sensíveis com integração embutida para vários serviços AWS, enquanto o AWS Systems Manager Parameter Store fornece uma solução escalável para armazenar dados de configuração e segredos, com a opção de criptografia. Ambos os serviços atendem aos requisitos da empresa para acesso seguro e gerenciamento de informações sensíveis.",
        "Other Options": [
            "Armazenar informações sensíveis no Amazon S3, mesmo com criptografia, não fornece o mesmo nível de controle de acesso e recursos de gerenciamento que o Secrets Manager ou o Parameter Store, tornando-o menos adequado para gerenciamento de segredos.",
            "Embutir credenciais diretamente no código do aplicativo compromete a segurança e não permite fácil rotação ou gerenciamento de segredos, o que vai contra as melhores práticas.",
            "Uma solução de cofre auto-hospedada adiciona sobrecarga operacional e complexidade, o que pode não ser necessário quando serviços gerenciados da AWS oferecem robustas capacidades de gerenciamento de segredos."
        ]
    },
    {
        "Question Number": "51",
        "Situation": "Uma empresa de serviços financeiros depende de um aplicativo legado hospedado localmente que lida com transações de clientes. O aplicativo é crítico para as operações diárias, mas carece de escalabilidade e agilidade. A administração decidiu migrar o aplicativo para a AWS para melhorar o desempenho e reduzir custos operacionais. Eles buscam uma solução que permita a modernização do aplicativo enquanto minimiza a interrupção dos serviços existentes.",
        "Question": "Qual das seguintes estratégias o Arquiteto de Soluções deve recomendar para modernizar o aplicativo de forma eficaz, garantindo uma transição suave?",
        "Options": {
            "1": "Levantar e transferir todo o aplicativo para instâncias Amazon EC2 e gradualmente refatorar o aplicativo conforme necessário para aproveitar os serviços da AWS.",
            "2": "Reconstruir todo o aplicativo usando AWS Lambda e arquitetura de microsserviços para utilizar totalmente as capacidades serverless desde o início.",
            "3": "Migrar o banco de dados para o Amazon RDS e manter o aplicativo legado localmente enquanto transita gradualmente para uma solução nativa da nuvem.",
            "4": "Containerizar o aplicativo e implantá-lo no Amazon ECS, depois refatorar o aplicativo em microsserviços ao longo do tempo para melhorar a escalabilidade."
        },
        "Correct Answer": "Containerizar o aplicativo e implantá-lo no Amazon ECS, depois refatorar o aplicativo em microsserviços ao longo do tempo para melhorar a escalabilidade.",
        "Explanation": "Containerizar o aplicativo permite uma melhor utilização de recursos e uma gestão mais fácil das dependências. Usar o Amazon ECS permite que a empresa orquestre contêineres de forma eficaz, e a refatoração gradual em microsserviços permite uma modernização incremental sem uma reformulação completa, minimizando a interrupção.",
        "Other Options": [
            "Levantar e transferir pode não fornecer os melhores benefícios das características nativas da nuvem e muitas vezes leva a continuar ineficiências existentes sem modernizar o aplicativo.",
            "Reconstruir todo o aplicativo do zero é uma abordagem arriscada e intensiva em recursos que pode levar a longos períodos de inatividade e custos mais altos sem garantir benefícios imediatos.",
            "Manter o aplicativo legado localmente enquanto migra o banco de dados não aproveita efetivamente as capacidades da nuvem e pode complicar o processo de modernização ao manter dependências legadas."
        ]
    },
    {
        "Question Number": "52",
        "Situation": "Uma empresa de serviços financeiros está projetando uma arquitetura de microserviços na AWS. O arquiteto de soluções precisa garantir que os vários serviços possam se comunicar de forma segura e eficiente usando endpoints de serviço. A empresa possui requisitos de conformidade rigorosos que ditam o uso de conectividade privada para serviços internos.",
        "Question": "Qual das seguintes configurações o arquiteto de soluções deve implementar para permitir integrações de serviço seguras enquanto atende aos requisitos de conformidade? (Selecione Dois)",
        "Options": {
            "1": "Configurar VPC Peering entre seus serviços para permitir conectividade direta dentro de suas VPCs, mantendo a conformidade.",
            "2": "Configurar AWS Transit Gateway para conectar várias VPCs e redes locais, facilitando a comunicação segura para seus microserviços.",
            "3": "Usar AWS PrivateLink para criar endpoints privados para seus serviços, garantindo que o tráfego não atravesse a internet pública.",
            "4": "Utilizar Amazon API Gateway com uma interface web para expor seus serviços publicamente, permitindo fácil acesso por clientes externos.",
            "5": "Implementar AWS Direct Connect para estabelecer uma conexão de rede dedicada do seu data center local para a AWS."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Usar AWS PrivateLink para criar endpoints privados para seus serviços, garantindo que o tráfego não atravesse a internet pública.",
            "Configurar AWS Transit Gateway para conectar várias VPCs e redes locais, facilitando a comunicação segura para seus microserviços."
        ],
        "Explanation": "AWS PrivateLink fornece conectividade privada entre VPCs e serviços, garantindo que os dados não deixem a rede AWS, atendendo assim aos requisitos de conformidade. AWS Transit Gateway simplifica o processo de conectar várias VPCs e redes locais de forma segura, facilitando a gestão das comunicações entre serviços em uma arquitetura de microserviços.",
        "Other Options": [
            "VPC Peering é uma opção válida para conectividade direta; no entanto, pode se tornar complexo de gerenciar à medida que o número de VPCs aumenta e não aborda a conformidade tão bem quanto o PrivateLink.",
            "Amazon API Gateway é projetado para acesso público a serviços, o que contradiz o requisito de conectividade privada e conformidade neste cenário.",
            "AWS Direct Connect é útil para conexões dedicadas, mas não aborda integrações de serviço a serviço dentro de uma arquitetura VPC tão efetivamente quanto o PrivateLink e o Transit Gateway."
        ]
    },
    {
        "Question Number": "53",
        "Situation": "Uma empresa de serviços financeiros usa Amazon RDS para PostgreSQL para gerenciar seu banco de dados transacional. O banco de dados contém informações sensíveis de clientes e é crítico para as operações diárias. A empresa precisa garantir que os dados sejam replicados em várias regiões para recuperação de desastres e conformidade. Eles requerem um RTO de 1 hora e um RPO de 10 minutos.",
        "Question": "Qual das seguintes opções o Arquiteto de Soluções deve implementar para atender efetivamente aos requisitos da empresa? (Selecione Dois)",
        "Options": {
            "1": "Criar uma réplica de leitura da instância RDS na mesma região para permitir uma recuperação rápida.",
            "2": "Agendar backups automatizados da instância RDS para um bucket S3 em outra região a cada 10 minutos.",
            "3": "Implementar o AWS Database Migration Service (DMS) para replicar continuamente dados para um banco de dados de destino em outra região.",
            "4": "Usar snapshots do Amazon RDS para fazer backups manuais e copiá-los para outra região uma vez por hora.",
            "5": "Habilitar a replicação entre regiões do Amazon RDS para replicar alterações no banco de dados para outra região."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Habilitar a replicação entre regiões do Amazon RDS para replicar alterações no banco de dados para outra região.",
            "Implementar o AWS Database Migration Service (DMS) para replicar continuamente dados para um banco de dados de destino em outra região."
        ],
        "Explanation": "Habilitar a replicação entre regiões do Amazon RDS permite a replicação quase em tempo real de alterações para outra região, atendendo ao requisito de RPO de 10 minutos. Além disso, usar o AWS DMS para replicação contínua fornece uma maneira eficaz de garantir que os dados estejam sempre atualizados na região de destino, o que é essencial para o planejamento de recuperação de desastres.",
        "Other Options": [
            "Criar uma réplica de leitura na mesma região não fornece recuperação de desastres entre regiões e não atende ao requisito de replicação de dados para outra região.",
            "Backups automatizados para S3 a cada 10 minutos poderiam atender ao RPO, mas não permitem failover imediato, pois requerem um processo de restauração manual que não atenderia ao requisito de RTO.",
            "Usar snapshots do Amazon RDS para backups manuais uma vez por hora não atenderia ao requisito de RPO de 10 minutos, pois alterações nos dados poderiam ser perdidas entre os snapshots."
        ]
    },
    {
        "Question Number": "54",
        "Situation": "Uma empresa está executando um aplicativo crítico na AWS que requer alta disponibilidade. Atualmente, eles têm um banco de dados primário em uma região da AWS e desejam implementar uma estratégia para failover automático para um banco de dados secundário em outra região em caso de falha.",
        "Question": "Qual abordagem fornecerá o failover automático mais confiável para o banco de dados, minimizando o tempo de inatividade?",
        "Options": {
            "1": "Utilizar Amazon Aurora Global Database para capacidades de failover entre regiões.",
            "2": "Usar Amazon RDS com implantações Multi-AZ para failover automático.",
            "3": "Implementar uma réplica de leitura em outra região e promovê-la durante uma falha.",
            "4": "Configurar um serviço de migração de banco de dados para replicar continuamente dados para outra região."
        },
        "Correct Answer": "Utilizar Amazon Aurora Global Database para capacidades de failover entre regiões.",
        "Explanation": "Amazon Aurora Global Database é projetado para replicação entre regiões e fornece leituras de baixa latência e capacidades de failover automático. Isso o torna a opção mais confiável para minimizar o tempo de inatividade e garantir alta disponibilidade entre regiões.",
        "Other Options": [
            "Amazon RDS com implantações Multi-AZ fornece failover automático dentro de uma única região, mas não suporta failover para outra região, tornando-o inadequado para alta disponibilidade entre regiões.",
            "Implementar uma réplica de leitura em outra região requer intervenção manual para promovê-la a primária, o que pode resultar em tempo de inatividade adicional durante o processo de failover.",
            "Configurar um serviço de migração de banco de dados para replicação contínua é uma opção viável, mas introduz complexidade e potenciais atrasos no failover, o que pode não atender aos requisitos de alta disponibilidade."
        ]
    },
    {
        "Question Number": "55",
        "Situation": "Uma empresa de serviços financeiros executa várias aplicações críticas na AWS. Eles precisam garantir que suas aplicações estejam funcionando de forma otimizada e que quaisquer problemas potenciais sejam detectados e resolvidos rapidamente. A empresa possui requisitos de conformidade rigorosos, necessitando de mecanismos detalhados de registro e alerta para todas as operações. A equipe de TI deseja implementar uma estratégia de monitoramento que minimize a intervenção manual enquanto garante visibilidade abrangente sobre o desempenho e a saúde do sistema.",
        "Question": "Qual das seguintes soluções fornece o sistema de monitoramento e alerta mais eficaz para as aplicações da empresa com a menor supervisão manual?",
        "Options": {
            "1": "Usar o AWS CloudTrail para rastrear chamadas de API e registrá-las no Amazon S3. Configurar funções do AWS Lambda para analisar os logs e enviar alertas com base em critérios predefinidos.",
            "2": "Aproveitar o Amazon CloudWatch Service Lens para monitorar o desempenho da aplicação, detectar automaticamente anomalias e integrar com o AWS Config para garantir conformidade e alertar sobre mudanças de configuração.",
            "3": "Implementar o AWS X-Ray para rastrear solicitações nas aplicações para visualizar gargalos de desempenho e configurar o Amazon SNS para enviar notificações com base nas anomalias do X-Ray.",
            "4": "Configurar o Amazon CloudWatch para rastrear métricas personalizadas e criar alarmes para limites de desempenho. Usar o CloudWatch Logs para agregar logs da aplicação e configurar alertas para padrões de log específicos."
        },
        "Correct Answer": "Aproveitar o Amazon CloudWatch Service Lens para monitorar o desempenho da aplicação, detectar automaticamente anomalias e integrar com o AWS Config para garantir conformidade e alertar sobre mudanças de configuração.",
        "Explanation": "O Amazon CloudWatch Service Lens fornece uma solução de monitoramento abrangente que monitora o desempenho da aplicação, detecta anomalias automaticamente e integra-se ao AWS Config para gerenciamento de conformidade, tornando-se a escolha mais eficiente para minimizar a supervisão manual.",
        "Other Options": [
            "Configurar o Amazon CloudWatch para métricas personalizadas e alarmes requer alguma configuração e manutenção manual, tornando-se menos eficiente do que uma solução totalmente integrada como o Service Lens.",
            "O AWS X-Ray é excelente para rastrear problemas de desempenho, mas não fornece monitoramento e alerta abrangentes para requisitos de conformidade, que a empresa precisa.",
            "Usar o AWS CloudTrail foca principalmente no rastreamento de chamadas de API em vez do desempenho da aplicação, e embora o Lambda possa processar logs, requer configuração adicional e não oferece capacidades de monitoramento direto."
        ]
    },
    {
        "Question Number": "56",
        "Situation": "Uma organização de serviços financeiros usa o AWS IAM para gerenciar o acesso de seus funcionários e fornecedores terceirizados. A organização requer estrita adesão às políticas de segurança e precisa garantir que os usuários tenham acesso apenas aos recursos que necessitam para suas funções específicas. Além disso, a organização deseja implementar acesso temporário para contratados que expirará automaticamente após a conclusão de seu projeto.",
        "Question": "Qual das seguintes soluções IAM o Arquiteto de Soluções deve implementar para atender aos requisitos da organização?",
        "Options": {
            "1": "Utilizar grupos IAM para gerenciar permissões de usuários agrupando funcionários e contratados com base em suas necessidades de acesso. Criar chaves de acesso para contratados que permitam acesso a recursos apenas durante o horário comercial.",
            "2": "Criar contas de usuário IAM para cada funcionário e contratado, atribuindo a cada usuário uma senha única e anexando políticas para permitir acesso a recursos específicos. Usar uma função Lambda agendada para desativar contas de contratados após a conclusão do projeto.",
            "3": "Criar funções IAM para cada função de trabalho específica com políticas correspondentes. Atribuir usuários a essas funções com base em suas necessidades de trabalho. Para contratados, criar uma função com um relacionamento de confiança que permita que eles assumam a função temporariamente, garantindo que a função tenha uma duração máxima de sessão que se alinhe ao cronograma do projeto.",
            "4": "Implementar políticas IAM que estão anexadas a um grupo central de usuários para funcionários e contratados. Definir permissões com base em tags atribuídas aos recursos, garantindo que os contratados possam acessar apenas recursos com as tags apropriadas."
        },
        "Correct Answer": "Criar funções IAM para cada função de trabalho específica com políticas correspondentes. Atribuir usuários a essas funções com base em suas necessidades de trabalho. Para contratados, criar uma função com um relacionamento de confiança que permita que eles assumam a função temporariamente, garantindo que a função tenha uma duração máxima de sessão que se alinhe ao cronograma do projeto.",
        "Explanation": "Criar funções IAM para cada função de trabalho permite um controle preciso sobre as permissões. Ao permitir que contratados assumam uma função temporariamente, você pode garantir que o acesso seja adaptado às suas necessidades, enquanto adere às melhores práticas de segurança. Além disso, definir uma duração máxima de sessão para funções de contratados garante que seu acesso seja automaticamente limitado ao cronograma do projeto.",
        "Other Options": [
            "Esta opção está incorreta porque usar contas de usuário IAM para contratados sem um processo de desativação automatizado pode levar a riscos de segurança se as contas não forem gerenciadas adequadamente. Uma função Lambda agendada adiciona complexidade e pode ainda deixar lacunas na segurança.",
            "Esta opção está incorreta, pois usar grupos IAM não fornece o controle detalhado necessário para acesso temporário. Chaves de acesso para contratados também são menos seguras do que o acesso baseado em funções, pois podem não expirar automaticamente ou podem ser mal utilizadas.",
            "Esta opção está incorreta porque usar políticas IAM baseadas em tags não restringe inherentemente o acesso de maneira sensível ao tempo. Não fornece o mecanismo necessário para garantir que o acesso de contratados seja temporário."
        ]
    },
    {
        "Question Number": "57",
        "Situation": "Uma aplicação de saúde está hospedada na AWS que armazena dados sensíveis de pacientes no Amazon S3 e usa um API Gateway para acessar serviços de backend. A aplicação deve estar em conformidade com as regulamentações HIPAA, que incluem acesso seguro aos serviços da AWS enquanto mantém os dados privados. A equipe deseja minimizar a exposição ao acesso à internet pública e garantir que todas as comunicações com os serviços da AWS sejam seguras e privadas. A arquitetura já inclui uma Virtual Private Cloud (VPC) com várias sub-redes configuradas para alta disponibilidade.",
        "Question": "Qual configuração de serviço da AWS seria a maneira mais eficaz de garantir conectividade privada ao Amazon S3 enquanto adere à conformidade HIPAA para esta aplicação de saúde?",
        "Options": {
            "1": "Configurar uma conexão VPN entre a VPC e uma rede local, roteando todo o tráfego do S3 através da VPN para maior segurança.",
            "2": "Implantar um NAT Gateway em uma sub-rede pública e rotear todo o tráfego do S3 através dele para manter a arquitetura da aplicação privada.",
            "3": "Criar um endpoint de gateway para o Amazon S3 e atualizar a tabela de rotas associada às sub-redes privadas para direcionar o tráfego destinado ao S3 através do endpoint.",
            "4": "Configurar um endpoint de interface para o Amazon S3 e vinculá-lo ao grupo de segurança que controla o acesso às instâncias da aplicação nas sub-redes privadas."
        },
        "Correct Answer": "Criar um endpoint de gateway para o Amazon S3 e atualizar a tabela de rotas associada às sub-redes privadas para direcionar o tráfego destinado ao S3 através do endpoint.",
        "Explanation": "Criar um endpoint de gateway para o Amazon S3 permite conectividade privada ao S3 a partir da VPC sem atravessar a internet pública, o que é crítico para a conformidade HIPAA. Esta configuração também simplifica o roteamento e aumenta a segurança ao eliminar a necessidade de acesso público ao S3.",
        "Other Options": [
            "Implantar um NAT Gateway em uma sub-rede pública não forneceria a conectividade privada necessária ao Amazon S3 e ainda exporia o tráfego à internet pública, o que não está em conformidade com as regulamentações HIPAA.",
            "Configurar um endpoint de interface para o Amazon S3 não é válido, pois o S3 suporta apenas endpoints de gateway, que são especificamente projetados para este serviço e fornecem a conectividade privada necessária.",
            "Configurar uma conexão VPN não é a melhor solução para acessar o S3, pois introduz complexidade e latência desnecessárias. Um endpoint de gateway é um método mais eficiente e em conformidade para conectar-se ao S3 a partir da VPC."
        ]
    },
    {
        "Question Number": "58",
        "Situation": "Uma equipe de segurança é responsável por garantir a segurança de suas cargas de trabalho na AWS. Eles querem aproveitar o Amazon Inspector para monitorar continuamente seus recursos em busca de vulnerabilidades e exposições não intencionais. A equipe está particularmente focada em instâncias do Amazon EC2 e funções do AWS Lambda.",
        "Question": "Quais configurações a equipe de segurança deve implementar para maximizar a eficácia do Amazon Inspector? (Selecione Dois)",
        "Options": {
            "1": "Desativar a varredura automática para funções do AWS Lambda para reduzir a sobrecarga.",
            "2": "Instalar o agente do Amazon Inspector em todas as instâncias do Amazon EC2 em execução.",
            "3": "Vincular o Amazon Inspector ao AWS CloudTrail para obter logs detalhados de todas as descobertas.",
            "4": "Agendar avaliações regulares das instâncias do Amazon EC2 usando o Amazon Inspector.",
            "5": "Configurar o Amazon Inspector para enviar automaticamente as descobertas ao AWS Security Hub."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Instalar o agente do Amazon Inspector em todas as instâncias do Amazon EC2 em execução.",
            "Agendar avaliações regulares das instâncias do Amazon EC2 usando o Amazon Inspector."
        ],
        "Explanation": "Para avaliar completamente a segurança das instâncias do Amazon EC2, a instalação do agente do Amazon Inspector é essencial. Isso permite uma análise abrangente de potenciais vulnerabilidades. Além disso, agendar avaliações regulares garante que a equipe permaneça atenta à postura de segurança de seus recursos e possa abordar prontamente quaisquer problemas identificados.",
        "Other Options": [
            "Desativar a varredura automática para funções do AWS Lambda reduziria a eficácia da detecção de vulnerabilidades, o que é contrário ao objetivo de manter um ambiente seguro.",
            "Embora vincular o Amazon Inspector ao AWS CloudTrail possa fornecer alguns benefícios de registro, isso não melhora diretamente o processo de varredura ou a eficácia da gestão de vulnerabilidades.",
            "Configurar o Amazon Inspector para enviar descobertas ao AWS Security Hub é benéfico, mas não contribui diretamente para a avaliação inicial e monitoramento de vulnerabilidades nas funções EC2 e Lambda."
        ]
    },
    {
        "Question Number": "59",
        "Situation": "Uma empresa de serviços financeiros está enfrentando uma demanda crescente por seu aplicativo web que processa transações. O aplicativo está atualmente implantado em uma única instância do Amazon EC2 e está lutando para lidar com a carga durante os horários de pico de transações. A empresa quer garantir alta disponibilidade e desempenho com mudanças mínimas na arquitetura existente.",
        "Question": "Qual das seguintes estratégias um Arquiteto de Soluções deve implementar para melhorar a escalabilidade e confiabilidade do aplicativo?",
        "Options": {
            "1": "Migrar o aplicativo para o AWS Lambda para lidar com o processamento de transações e usar o Amazon API Gateway para roteamento de solicitações.",
            "2": "Atualizar a instância do EC2 para um tipo de instância maior e configurar uma Réplica de Leitura do Amazon RDS para descarregar consultas de leitura do banco de dados principal.",
            "3": "Implantar uma única instância adicional do EC2 para compartilhar a carga e configurar o Route 53 para distribuição de tráfego baseada em DNS.",
            "4": "Implementar um grupo de Auto Scaling para as instâncias do EC2 e usar um Elastic Load Balancer para distribuir o tráfego de entrada uniformemente entre as instâncias."
        },
        "Correct Answer": "Implementar um grupo de Auto Scaling para as instâncias do EC2 e usar um Elastic Load Balancer para distribuir o tráfego de entrada uniformemente entre as instâncias.",
        "Explanation": "Usar um grupo de Auto Scaling combinado com um Elastic Load Balancer permite que o aplicativo ajuste automaticamente a capacidade de acordo com a demanda, garantindo tanto escalabilidade quanto alta disponibilidade. Essa configuração garante que o aplicativo possa lidar com cargas variáveis de forma eficiente.",
        "Other Options": [
            "Migrar para o AWS Lambda exigiria mudanças significativas na arquitetura do aplicativo e pode não ser adequado para todos os cenários de processamento de transações, especialmente se o aplicativo for stateful ou exigir conexões persistentes.",
            "Atualizar para uma instância do EC2 maior pode fornecer alívio temporário, mas não resolve a preocupação com a escalabilidade durante os horários de pico, já que uma única instância ainda pode se tornar um gargalo e não fornece redundância.",
            "Implantar uma única instância adicional do EC2 melhoraria a distribuição da carga até certo ponto, mas carece das capacidades de escalonamento dinâmico de um grupo de Auto Scaling e não garante alta disponibilidade, já que ambas as instâncias ainda poderiam falhar."
        ]
    },
    {
        "Question Number": "60",
        "Situation": "Uma empresa possui um grupo de Auto Scaling gerenciando várias instâncias do EC2 para lidar com cargas de trabalho variadas. Eles querem desanexar uma instância do grupo de Auto Scaling para manutenção, garantindo que as instâncias restantes continuem a atender a capacidade desejada. Eles também querem garantir que a instância seja removida corretamente de quaisquer balanceadores de carga associados.",
        "Question": "Qual é a abordagem correta para desanexar uma instância do grupo de Auto Scaling enquanto garante que ela seja desregistrada de seus balanceadores de carga?",
        "Options": {
            "1": "Usar a API DetachInstances para remover a instância do grupo de Auto Scaling e garantir que o balanceador de carga também seja desanexado.",
            "2": "Desanexar a instância do grupo de Auto Scaling usando a API DetachLoadBalancers para garantir que ela seja removida do balanceador de carga.",
            "3": "Suspender os processos de escalonamento, desanexar manualmente a instância do grupo de Auto Scaling e, em seguida, desregistrá-la do balanceador de carga.",
            "4": "Desanexar a instância usando a API DetachInstances, que lidará automaticamente com a desregistração do balanceador de carga."
        },
        "Correct Answer": "Desanexar a instância usando a API DetachInstances, que lidará automaticamente com a desregistração do balanceador de carga.",
        "Explanation": "Ao usar a API DetachInstances, a instância é removida do grupo de Auto Scaling e será desregistrada de quaisquer balanceadores de carga associados, garantindo que o grupo de escalonamento mantenha sua capacidade desejada.",
        "Other Options": [
            "Esta opção sugere incorretamente usar a API DetachInstances enquanto menciona a necessidade de garantir que o balanceador de carga seja desanexado, o que já é tratado automaticamente pela API.",
            "Embora suspender os processos de escalonamento possa evitar a substituição da instância, isso não aborda a desregistração automática dos balanceadores de carga, tornando essa abordagem menos eficiente.",
            "A API DetachLoadBalancers apenas desanexa Classic Load Balancers e não aborda a desanexação de instâncias do grupo de Auto Scaling, tornando essa opção inválida."
        ]
    },
    {
        "Question Number": "61",
        "Situation": "Uma empresa de serviços financeiros está usando Amazon Redshift para suas necessidades de armazenamento de dados. Eles enfrentam problemas de desempenho durante os horários de pico, quando vários usuários executam consultas analíticas complexas. Os analistas de dados da empresa frequentemente reclamam sobre longos tempos de espera para a execução de suas consultas. A equipe de arquitetura está explorando opções para otimizar o desempenho das consultas, garantindo que consultas curtas possam ser executadas sem atrasos significativos.",
        "Question": "Qual é a maneira mais eficaz de otimizar o desempenho das consultas no Amazon Redshift enquanto gerencia a concorrência?",
        "Options": {
            "1": "Desativar a gestão de carga de trabalho no Amazon Redshift para permitir que todas as consultas sejam executadas sem restrições.",
            "2": "Aumentar o wlm_query_slot_count para permitir mais consultas concorrentes e definir classes de serviço apropriadas para diferentes tipos de consultas.",
            "3": "Implementar um sistema de agendamento de consultas para garantir que consultas de longa duração não afetem a execução de consultas curtas durante os horários de pico.",
            "4": "Reduzir o número de nós no cluster Redshift para diminuir a contenção de recursos entre consultas concorrentes."
        },
        "Correct Answer": "Aumentar o wlm_query_slot_count para permitir mais consultas concorrentes e definir classes de serviço apropriadas para diferentes tipos de consultas.",
        "Explanation": "Aumentar o wlm_query_slot_count permite que mais consultas sejam executadas simultaneamente, melhorando assim o desempenho geral durante os horários de pico. Definir corretamente as classes de serviço pode otimizar ainda mais as prioridades de execução, garantindo que consultas curtas sejam priorizadas em relação às de longa duração.",
        "Other Options": [
            "Reduzir o número de nós no cluster Redshift limitaria os recursos disponíveis, potencialmente agravando os problemas de desempenho em vez de melhorá-los.",
            "Implementar um sistema de agendamento de consultas não é um recurso direto do Amazon Redshift e pode introduzir complexidade desnecessária sem abordar a causa raiz dos problemas de concorrência.",
            "Desativar a gestão de carga de trabalho significaria que não haveria controles para gerenciar a execução das consultas, resultando provavelmente em tempos de espera mais longos para todas as consultas, especialmente durante o uso intenso."
        ]
    },
    {
        "Question Number": "62",
        "Situation": "Uma equipe de análise de dados está atualmente processando grandes conjuntos de dados usando Amazon EMR com Apache Spark. Eles querem otimizar seus fluxos de trabalho de processamento para reduzir custos enquanto mantêm alto desempenho. A equipe frequentemente recupera dados do Amazon S3 e também precisa armazenar resultados intermediários para análise posterior. Eles estão explorando opções para melhorar a eficiência de seu cluster EMR enquanto gerenciam custos.",
        "Question": "Qual das seguintes estratégias o arquiteto de soluções deve recomendar para otimizar os custos de processamento de dados para a equipe que usa Amazon EMR?",
        "Options": {
            "1": "Lançar o cluster EMR apenas com instâncias sob demanda para garantir disponibilidade e confiabilidade, independentemente das flutuações de custo, e usar uma instância reservada para o nó mestre.",
            "2": "Utilizar o Amazon S3 para todas as necessidades de armazenamento intermediário e configurar o trabalho EMR para processar dados em uma única etapa sem qualquer embaralhamento de dados para minimizar os custos de transferência de dados.",
            "3": "Agendar clusters EMR para serem executados apenas durante horários fora de pico, aproveitando instâncias reservadas para gerenciar custos de forma eficaz enquanto garante que os dados estejam disponíveis para processamento.",
            "4": "Usar instâncias spot para o cluster EMR para aproveitar preços mais baixos para cargas de trabalho não críticas e configurar o cluster para escalar automaticamente para cima e para baixo com base na demanda de carga de trabalho."
        },
        "Correct Answer": "Usar instâncias spot para o cluster EMR para aproveitar preços mais baixos para cargas de trabalho não críticas e configurar o cluster para escalar automaticamente para cima e para baixo com base na demanda de carga de trabalho.",
        "Explanation": "Usar instâncias spot permite que a equipe reduza significativamente os custos associados ao cluster EMR enquanto mantém a capacidade de escalar de acordo com os requisitos de carga de trabalho. Essa abordagem é ideal para cargas de trabalho não críticas, onde interrupções podem ser toleradas. Escalar automaticamente o cluster com base na demanda otimiza ainda mais os custos.",
        "Other Options": [
            "Lançar o cluster EMR apenas com instâncias sob demanda garantirá confiabilidade, mas não otimizará os custos de forma eficaz, já que as instâncias sob demanda são mais caras do que as instâncias spot.",
            "Utilizar o Amazon S3 para todo o armazenamento intermediário é uma boa prática; no entanto, processar dados em uma única etapa sem embaralhamento pode não ser sempre viável para fluxos de trabalho complexos e pode levar a uma utilização ineficiente de recursos.",
            "Agendar clusters EMR para serem executados durante horários fora de pico pode ajudar a gerenciar custos, mas pode não ser prático para todas as cargas de trabalho, especialmente se o processamento de dados precisar ocorrer em tempo real ou quase em tempo real."
        ]
    },
    {
        "Question Number": "63",
        "Situation": "Uma empresa de serviços financeiros está migrando seu armazenamento de dados para a AWS para melhorar a escalabilidade e reduzir custos. Eles precisam de uma solução que permita armazenar grandes volumes de dados não estruturados, garantindo durabilidade e facilidade de acesso. Além disso, eles planejam implementar uma estratégia de backup que se integre perfeitamente ao seu fluxo de trabalho existente. O arquiteto de soluções foi solicitado a recomendar serviços de armazenamento da AWS que atendam a esses requisitos. (Selecione Dois)",
        "Question": "Quais das seguintes soluções de armazenamento da AWS o arquiteto de soluções deve recomendar para as necessidades da empresa?",
        "Options": {
            "1": "Amazon S3 para armazenamento de objetos duráveis e soluções de backup, com políticas de ciclo de vida para gerenciar dados.",
            "2": "Amazon FSx for Windows File Server para hospedar aplicativos baseados em Windows que requerem suporte ao protocolo SMB.",
            "3": "Amazon EBS para armazenamento em bloco para fornecer armazenamento de alto desempenho para instâncias EC2.",
            "4": "Amazon Elastic File System (EFS) para armazenamento de arquivos compartilhados, permitindo que várias instâncias acessem arquivos simultaneamente.",
            "5": "AWS Storage Gateway para integrar ambientes locais com armazenamento em nuvem para backup."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon S3 para armazenamento de objetos duráveis e soluções de backup, com políticas de ciclo de vida para gerenciar dados.",
            "AWS Storage Gateway para integrar ambientes locais com armazenamento em nuvem para backup."
        ],
        "Explanation": "O Amazon S3 oferece alta durabilidade, escalabilidade e gerenciamento de ciclo de vida para dados não estruturados, tornando-o ideal para as necessidades de armazenamento da empresa. O AWS Storage Gateway permite a integração perfeita de ambientes locais com armazenamento em nuvem, fornecendo uma solução de backup que se alinha aos fluxos de trabalho existentes da empresa.",
        "Other Options": [
            "O Amazon Elastic File System (EFS) é mais adequado para armazenamento de arquivos compartilhados e pode não ser ideal para grandes volumes de dados não estruturados que requerem durabilidade extensiva.",
            "O Amazon FSx for Windows File Server é voltado para aplicativos Windows que precisam do protocolo SMB, o que pode não ser necessário para os requisitos da empresa para armazenamento de dados não estruturados.",
            "O Amazon EBS é eficaz para armazenamento em bloco, mas não é projetado para armazenamento de dados não estruturados em grande escala, como necessário pela empresa."
        ]
    },
    {
        "Question Number": "64",
        "Situation": "Uma empresa de serviços financeiros está mudando sua estratégia de arquivamento de dados para a AWS. A empresa lida com dados financeiros sensíveis e precisa de uma solução para armazenamento a longo prazo que minimize custos, garantindo conformidade e acesso rápido aos dados quando necessário. O arquiteto de soluções é encarregado de selecionar uma classe de armazenamento apropriada do Amazon S3 para arquivamento. Os dados serão acessados com pouca frequência, mas devem ser recuperáveis em minutos, se necessário.",
        "Question": "Qual das seguintes opções é a solução mais adequada que atende aos requisitos da empresa?",
        "Options": {
            "1": "Utilizar S3 Glacier Flexible Retrieval para otimizar a economia de custos, permitindo tempos de recuperação de várias horas para dados menos críticos.",
            "2": "Armazenar os dados no S3 Standard para acesso frequente e, em seguida, transferir para o S3 Glacier quando se tornarem menos relevantes.",
            "3": "Usar S3 Glacier Instant Retrieval para acesso imediato, minimizando os custos de armazenamento devido à necessidade de acesso pouco frequente.",
            "4": "Implementar S3 Standard-IA para acesso pouco frequente e confiar em processos manuais para a recuperação de dados."
        },
        "Correct Answer": "Usar S3 Glacier Instant Retrieval para acesso imediato, minimizando os custos de armazenamento devido à necessidade de acesso pouco frequente.",
        "Explanation": "O S3 Glacier Instant Retrieval é projetado para dados que são acessados com pouca frequência, mas requerem recuperação imediata. Isso se alinha perfeitamente com a necessidade da empresa de acesso rápido aos dados, mantendo os custos de armazenamento baixos, tornando-o a escolha ideal para sua estratégia de arquivamento.",
        "Other Options": [
            "O S3 Standard não é econômico para arquivamento a longo prazo de dados acessados com pouca frequência, pois incorreria em custos de armazenamento mais altos do que as opções Glacier.",
            "O S3 Glacier Flexible Retrieval é adequado para economia de custos, mas não atende ao requisito de acesso imediato, pois pode levar horas para recuperar os dados.",
            "O S3 Standard-IA é destinado a acesso pouco frequente, mas não oferece o mesmo nível de economia de custos que as opções Glacier para necessidades de armazenamento a longo prazo."
        ]
    },
    {
        "Question Number": "65",
        "Situation": "Uma empresa está usando AWS Lambda para processar registros de um fluxo do Amazon Kinesis. O arquiteto de soluções precisa otimizar o processamento de dados para garantir que a função Lambda seja invocada com a configuração de agrupamento mais eficiente. A empresa requer que a função Lambda possa lidar com o número máximo de registros em um lote sem exceder os limites de tamanho de carga útil.",
        "Question": "Qual é o número máximo de registros que podem ser processados em um único lote por uma função AWS Lambda ao ler de um fluxo do Amazon Kinesis?",
        "Options": {
            "1": "1.000 registros por lote",
            "2": "10.000 registros por lote",
            "3": "6 MB de tamanho de carga útil",
            "4": "2.000 registros por lote"
        },
        "Correct Answer": "1.000 registros por lote",
        "Explanation": "O tamanho máximo do lote para funções Lambda que processam registros de um fluxo do Amazon Kinesis é de 1.000 registros. Esse limite garante que a função não exceda o tamanho máximo de carga útil de 6 MB.",
        "Other Options": [
            "10.000 registros por lote está incorreto porque o tamanho máximo do lote para Kinesis é limitado a 1.000 registros, independentemente do tamanho da carga útil.",
            "6 MB de tamanho de carga útil está incorreto, pois se refere ao limite total de tamanho para a carga útil, mas não especifica o número máximo de registros processados em um lote.",
            "2.000 registros por lote está incorreto porque o tamanho máximo do lote para Kinesis é limitado a 1.000 registros, não 2.000."
        ]
    },
    {
        "Question Number": "66",
        "Situation": "Uma empresa de serviços financeiros está migrando suas aplicações para a AWS. Eles implantaram uma mistura de instâncias EC2 para diferentes cargas de trabalho, incluindo servidores web, servidores de aplicativos e bancos de dados. Após monitorar o desempenho e os custos de suas instâncias EC2 atuais, eles percebem que algumas instâncias estão subutilizadas enquanto outras estão sobrecarregadas. A empresa deseja otimizar seus recursos da AWS redimensionando suas instâncias EC2 para melhor corresponder às suas cargas de trabalho. (Selecione Dois)",
        "Question": "Quais das seguintes ações ajudarão a empresa a alcançar um melhor redimensionamento de suas instâncias EC2?",
        "Options": {
            "1": "Implementar o AWS Compute Optimizer para receber recomendações de redimensionamento de instâncias com base em padrões de utilização.",
            "2": "Realizar uma análise de custos de cada tipo de instância e selecionar a instância mais barata para todas as cargas de trabalho, independentemente dos requisitos de desempenho.",
            "3": "Usar uma função AWS Lambda para encerrar automaticamente instâncias que estão operando abaixo de um limite especificado de utilização da CPU.",
            "4": "Revisar os tipos de instâncias EC2 usados para a camada de banco de dados e migrar para um único tipo de instância para simplificar a gestão.",
            "5": "Analisar métricas do CloudWatch para identificar instâncias EC2 subutilizadas e redimensioná-las para tipos de instância menores."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Analisar métricas do CloudWatch para identificar instâncias EC2 subutilizadas e redimensioná-las para tipos de instância menores.",
            "Implementar o AWS Compute Optimizer para receber recomendações de redimensionamento de instâncias com base em padrões de utilização."
        ],
        "Explanation": "Analisar métricas do CloudWatch permite que a empresa tome decisões baseadas em dados para identificar instâncias subutilizadas, que podem ser redimensionadas para economizar custos. Além disso, o AWS Compute Optimizer fornece recomendações automatizadas com base em padrões de uso históricos, facilitando a identificação de oportunidades de redimensionamento.",
        "Other Options": [
            "Embora revisar os tipos de instâncias possa ajudar, migrar para um único tipo de instância não aborda necessariamente a eficiência de desempenho ou custo para cargas de trabalho diversas, tornando-se uma abordagem ineficaz para redimensionamento.",
            "Usar uma função Lambda para encerrar instâncias com base apenas na utilização da CPU pode levar a interrupções não intencionais para aplicações críticas, pois não considera o desempenho geral ou a natureza das cargas de trabalho.",
            "Selecionar o tipo de instância mais barato sem considerar requisitos específicos de desempenho pode resultar em desempenho degradado da aplicação, levando à insatisfação do usuário e potencial perda de negócios."
        ]
    },
    {
        "Question Number": "67",
        "Situation": "Uma empresa de serviços financeiros implantou várias aplicações na AWS que lidam com dados sensíveis de clientes. Para melhorar a segurança e a conformidade, a empresa decidiu implementar ferramentas de segurança da AWS que podem ajudar a monitorar e avaliar seus ambientes na AWS. O arquiteto de soluções é responsável por selecionar as ferramentas apropriadas que podem fornecer insights sobre vulnerabilidades de segurança, status de conformidade e configurações de controle de acesso. Eles precisam de uma visão consolidada de alertas de segurança e descobertas em várias contas da AWS.",
        "Question": "Qual combinação de serviços da AWS atenderia melhor aos requisitos da empresa para monitoramento de segurança e conformidade?",
        "Options": {
            "1": "AWS Security Hub, AWS CloudTrail, Amazon Inspector, AWS IAM Access Analyzer",
            "2": "Amazon CloudWatch, AWS Config, AWS Shield, AWS Firewall Manager",
            "3": "AWS Lambda, AWS Budgets, Amazon S3, AWS CloudFormation",
            "4": "AWS Trusted Advisor, Amazon GuardDuty, AWS WAF, AWS Systems Manager"
        },
        "Correct Answer": "AWS Security Hub, AWS CloudTrail, Amazon Inspector, AWS IAM Access Analyzer",
        "Explanation": "A combinação de AWS Security Hub, AWS CloudTrail, Amazon Inspector e AWS IAM Access Analyzer fornece uma abordagem abrangente para monitoramento de segurança e conformidade. O AWS Security Hub agrega e prioriza alertas de segurança, enquanto o AWS CloudTrail permite visibilidade sobre a atividade da conta. O Amazon Inspector avalia aplicações em busca de vulnerabilidades, e o AWS IAM Access Analyzer ajuda a identificar acessos não intencionais a recursos, garantindo conformidade com as políticas de segurança.",
        "Other Options": [
            "Esta opção inclui serviços que se concentram principalmente no monitoramento e gerenciamento de recursos, mas carece de ferramentas dedicadas para avaliações de segurança e monitoramento de conformidade.",
            "Esta opção apresenta serviços que oferecem proteção contra ataques DDoS e gerenciam regras de segurança, mas não oferece uma visão abrangente de alertas de segurança ou verificações de conformidade.",
            "Esta opção inclui serviços que oferecem otimização de custos e monitoramento de desempenho, mas não aborda vulnerabilidades de segurança ou requisitos de conformidade."
        ]
    },
    {
        "Question Number": "68",
        "Situation": "Uma empresa está planejando migrar sua aplicação existente local para a AWS. Eles querem aproveitar novos serviços e recursos da AWS para melhorar o desempenho e a confiabilidade. O arquiteto de soluções precisa desenvolver uma estratégia de migração que inclua a modernização da arquitetura da aplicação, minimizando o tempo de inatividade durante a transição. A arquitetura também deve suportar escalabilidade e manutenibilidade futuras.",
        "Question": "Qual das seguintes opções é a abordagem mais adequada para a empresa adotar neste cenário?",
        "Options": {
            "1": "Migrar a aplicação para uma instância do Amazon RDS e refatorá-la para utilizar os recursos do banco de dados, mantendo a aplicação hospedada localmente.",
            "2": "Containerizar a aplicação usando o Amazon ECS e implantá-la em instâncias do Amazon EC2, permitindo uma gestão e implantação mais fáceis de microsserviços.",
            "3": "Reestruturar a aplicação para usar AWS Lambda e Amazon API Gateway, garantindo uma arquitetura serverless que escala automaticamente e minimiza a sobrecarga operacional.",
            "4": "Lift and shift a aplicação para instâncias do Amazon EC2 sem alterações e planejar a modernização após a migração ser concluída."
        },
        "Correct Answer": "Reestruturar a aplicação para usar AWS Lambda e Amazon API Gateway, garantindo uma arquitetura serverless que escala automaticamente e minimiza a sobrecarga operacional.",
        "Explanation": "Esta opção fornece a melhor abordagem para modernizar a aplicação utilizando arquitetura serverless. AWS Lambda e API Gateway permitem escalabilidade automática, reduzindo a necessidade de gerenciamento de servidores e melhorando o desempenho e a confiabilidade geral.",
        "Other Options": [
            "Esta abordagem não aproveita os serviços da AWS para modernizar a aplicação. Pode levar a custos operacionais mais altos e não suporta melhorias de escalabilidade ou desempenho.",
            "Embora a containerização possa melhorar a gestão e a implantação, esta opção ainda depende do EC2, que requer gerenciamento da infraestrutura subjacente e não aproveita totalmente os benefícios de uma arquitetura serverless.",
            "Esta opção foca exclusivamente na migração do banco de dados e não aborda a camada da aplicação. Mantém a aplicação local, o que limita a escalabilidade e não aproveita as capacidades completas dos serviços da AWS."
        ]
    },
    {
        "Question Number": "69",
        "Situation": "Uma empresa global de jogos online atende milhões de jogadores ao redor do mundo e precisa otimizar sua experiência de jogo reduzindo a latência e melhorando a entrega de conteúdo. A empresa implantou seus servidores de jogos em várias regiões da AWS e está em busca de uma solução que possa fornecer entrega de conteúdo rápida e experiências de jogador contínuas em diferentes geografias. Além disso, a empresa deseja garantir alta disponibilidade e failover automático em caso de interrupções regionais.",
        "Question": "Qual das seguintes soluções atenderia melhor aos requisitos da empresa para entrega de conteúdo de baixa latência e alta disponibilidade?",
        "Options": {
            "1": "Implementar AWS Lambda@Edge com Amazon CloudFront para armazenar em cache os dados do jogo mais próximos dos jogadores, enquanto usa o Amazon Route 53 para gerenciar o failover de DNS para alta disponibilidade.",
            "2": "Implantar o Amazon S3 para armazenamento de conteúdo de jogos e usar o AWS Direct Connect para fornecer uma linha dedicada para transferência de dados para os servidores de jogos. Isso melhorará a latência e o desempenho.",
            "3": "Usar o Amazon CloudFront para distribuir conteúdo de jogos globalmente. Implementar o AWS Global Accelerator para direcionar os jogadores ao servidor de jogos mais próximo e melhorar a disponibilidade com failover automático.",
            "4": "Utilizar o Amazon Elastic Load Balancing em várias regiões para distribuir o tráfego uniformemente entre os servidores de jogos, enquanto também configura o Amazon RDS com Multi-AZ para redundância de banco de dados."
        },
        "Correct Answer": "Usar o Amazon CloudFront para distribuir conteúdo de jogos globalmente. Implementar o AWS Global Accelerator para direcionar os jogadores ao servidor de jogos mais próximo e melhorar a disponibilidade com failover automático.",
        "Explanation": "Usar o Amazon CloudFront permite uma distribuição eficiente do conteúdo do jogo com latência reduzida, pois armazena em cache o conteúdo em locais de borda próximos aos jogadores. O AWS Global Accelerator melhora ainda mais a disponibilidade, direcionando o tráfego de forma inteligente para o servidor de jogos ideal, garantindo que os jogadores tenham o mínimo de atraso e uma experiência contínua.",
        "Other Options": [
            "Implantar o Amazon S3 para armazenamento de conteúdo de jogos e usar o AWS Direct Connect melhora o desempenho da transferência de dados, mas não aborda diretamente a entrega de conteúdo de baixa latência ou mecanismos de failover automático para servidores de jogos.",
            "Implementar AWS Lambda@Edge com Amazon CloudFront para cache e usar o Amazon Route 53 para failover de DNS oferece alguns benefícios, mas pode não fornecer o mesmo nível de failover automático e otimização de roteamento que o AWS Global Accelerator.",
            "Utilizar o Amazon Elastic Load Balancing para distribuição de tráfego e o Amazon RDS com Multi-AZ para redundância de banco de dados é uma boa estratégia de alta disponibilidade, mas não aborda especificamente a entrega global de conteúdo e a redução da latência para uma base de jogadores mundial."
        ]
    },
    {
        "Question Number": "70",
        "Situation": "Uma empresa de serviços financeiros está migrando suas aplicações web para a AWS. A empresa precisa proteger suas APIs e serviços internos com certificados SSL/TLS. A equipe de segurança prefere usar certificados que sejam automaticamente confiáveis por aplicações clientes e navegadores sem configuração adicional. Eles estão considerando usar o AWS Certificate Manager para esse propósito.",
        "Question": "Qual tipo de certificado a empresa deve provisionar usando o AWS Certificate Manager para garantir confiança contínua com aplicações clientes e navegadores?",
        "Options": {
            "1": "Usar uma autoridade certificadora de terceiros para certificados públicos.",
            "2": "Usar certificados autoassinados para todas as aplicações internas.",
            "3": "Provisionar um certificado SSL/TLS privado para serviços internos.",
            "4": "Provisionar um certificado SSL/TLS público para serviços externos."
        },
        "Correct Answer": "Provisionar um certificado SSL/TLS público para serviços externos.",
        "Explanation": "Provisionar um certificado SSL/TLS público através do AWS Certificate Manager garante que o certificado seja automaticamente confiável por navegadores e aplicações clientes, atendendo à necessidade da empresa de confiança contínua sem configuração adicional.",
        "Other Options": [
            "Provisionar um certificado SSL/TLS privado exigiria configuração explícita nas aplicações clientes para confiar no certificado, o que não atende à exigência de confiança contínua.",
            "Usar certificados autoassinados não é recomendado para ambientes de produção, pois não são confiáveis por padrão, exigindo configuração adicional para cada cliente, o que contradiz a exigência.",
            "Usar uma autoridade certificadora de terceiros pode introduzir complexidade e custo desnecessários, já que o AWS Certificate Manager fornece certificados públicos gratuitos que são automaticamente confiáveis."
        ]
    },
    {
        "Question Number": "71",
        "Situation": "Uma empresa multinacional está implantando uma aplicação globalmente distribuída na AWS que precisa direcionar o tráfego de usuários de forma eficiente e fornecer alta disponibilidade. A aplicação será acessada de várias localizações geográficas, e a empresa visa minimizar a latência enquanto garante que os usuários sejam direcionados para os recursos disponíveis mais próximos. Eles estão considerando várias políticas de roteamento fornecidas pelo AWS Route 53 para alcançar esse objetivo.",
        "Question": "Qual das seguintes políticas de roteamento no AWS Route 53 seria a MAIS eficaz para direcionar os usuários ao ponto de extremidade da aplicação mais próximo com base em sua localização geográfica?",
        "Options": {
            "1": "Política de roteamento ponderado",
            "2": "Política de roteamento por geolocalização",
            "3": "Política de roteamento de failover",
            "4": "Política de roteamento por latência"
        },
        "Correct Answer": "Política de roteamento por geolocalização",
        "Explanation": "A política de roteamento por geolocalização permite que o Route 53 direcione o tráfego com base na localização geográfica do usuário. Isso significa que os usuários serão direcionados para o ponto de extremidade da aplicação mais próximo, reduzindo a latência e melhorando o desempenho. É especificamente projetada para cenários onde a proximidade geográfica é crucial para otimizar a experiência do usuário.",
        "Other Options": [
            "A política de roteamento por latência direciona os usuários para o ponto de extremidade que fornece a menor latência com base em verificações de saúde, mas não considera especificamente a localização geográfica do usuário. Isso pode não resultar sempre em direcionar os usuários para o recurso mais próximo, que é o requisito principal neste cenário.",
            "A política de roteamento ponderado permite distribuir o tráfego entre vários pontos de extremidade com base em pesos atribuídos, mas não leva em conta a localização geográfica. Isso pode levar a um roteamento ineficiente em termos de latência, já que os usuários podem não ser direcionados para o recurso mais próximo.",
            "A política de roteamento de failover é usada para direcionar o tráfego para um ponto de extremidade primário e mudar para um ponto de extremidade secundário em caso de falha. Essa política é destinada à alta disponibilidade, em vez de otimizar a proximidade do usuário ou a latência, tornando-a inadequada para o requisito de direcionar os usuários ao ponto de extremidade da aplicação mais próximo."
        ]
    },
    {
        "Question Number": "72",
        "Situation": "Uma empresa está migrando sua arquitetura de on-premises para a AWS. Eles requerem uma solução que permita que instâncias em uma sub-rede privada acessem a internet para atualizações e patches, garantindo que as instâncias não estejam expostas diretamente ao tráfego de internet de entrada. A equipe está avaliando o melhor uso do NAT para alcançar esse requisito.",
        "Question": "Qual afirmação descreve corretamente o comportamento das instâncias NAT e dos gateways NAT no contexto de timeouts de conexão?",
        "Options": {
            "1": "As instâncias NAT enviam um pacote FIN para fechar conexões em timeouts, enquanto os gateways NAT enviam um pacote RST para terminá-las.",
            "2": "Tanto as instâncias NAT quanto os gateways enviam pacotes RST para terminar conexões em timeouts.",
            "3": "Tanto as instâncias NAT quanto os gateways enviam pacotes FIN para terminar conexões em timeouts.",
            "4": "Os gateways NAT enviam um pacote FIN para fechar conexões em timeouts, enquanto as instâncias NAT enviam um pacote RST para terminá-las."
        },
        "Correct Answer": "As instâncias NAT enviam um pacote FIN para fechar conexões em timeouts, enquanto os gateways NAT enviam um pacote RST para terminá-las.",
        "Explanation": "As instâncias NAT e os gateways NAT lidam com timeouts de conexão de maneira diferente. As instâncias NAT enviarão um pacote FIN para os recursos privados para fechar a conexão de forma adequada, enquanto os gateways NAT enviarão um pacote RST, que termina a conexão de forma forçada sem uma sequência de desligamento adequada.",
        "Other Options": [
            "Os gateways NAT enviando um pacote FIN está incorreto; na verdade, eles enviam um pacote RST em timeouts de conexão.",
            "Isso está incorreto porque apenas as instâncias NAT enviam pacotes FIN, enquanto os gateways NAT enviam pacotes RST.",
            "Isso está incorreto; as instâncias NAT e os gateways não enviam ambos pacotes FIN em timeouts, pois utilizam mecanismos diferentes para a terminação de conexões."
        ]
    },
    {
        "Question Number": "73",
        "Situation": "Uma empresa de serviços financeiros está migrando suas aplicações para a AWS e precisa escolher uma plataforma de hospedagem de contêineres. A empresa requer uma solução que permita fácil escalabilidade, alta disponibilidade e integração com pipelines de CI/CD existentes. As aplicações são baseadas em microserviços e devem suportar capacidades rápidas de implantação e reversão, garantindo que os requisitos de segurança e conformidade sejam atendidos.",
        "Question": "Qual das seguintes plataformas de hospedagem de contêineres seria a escolha mais adequada para os requisitos da empresa?",
        "Options": {
            "1": "Amazon EC2 com Docker instalado para executar contêineres diretamente em máquinas virtuais, oferecendo controle total, mas complicando a escalabilidade e a gestão.",
            "2": "Amazon ECS com AWS Fargate para gerenciar os contêineres e permitir computação serverless, simplificando a escalabilidade e a implantação.",
            "3": "AWS Lambda para executar aplicações em contêineres de forma serverless, eliminando a necessidade de gerenciamento de contêineres, mas limitando o controle.",
            "4": "Amazon EKS com Kubernetes para gerenciar os contêineres, fornecendo recursos avançados de orquestração, mas exigindo mais sobrecarga operacional."
        },
        "Correct Answer": "Amazon ECS com AWS Fargate para gerenciar os contêineres e permitir computação serverless, simplificando a escalabilidade e a implantação.",
        "Explanation": "Amazon ECS com AWS Fargate fornece uma opção de hospedagem de contêineres serverless que abstrai a infraestrutura subjacente, permitindo que a empresa se concentre na implantação e gerenciamento de aplicações sem se preocupar com a manutenção de servidores. Ele suporta fácil escalabilidade e se integra bem com pipelines de CI/CD, atendendo aos requisitos da empresa.",
        "Other Options": [
            "Amazon EKS com Kubernetes exige o gerenciamento do plano de controle do Kubernetes, o que adiciona complexidade e sobrecarga operacional, tornando-o menos adequado para uma equipe que busca simplicidade e facilidade de uso.",
            "AWS Lambda é projetado para executar código em uma arquitetura serverless, mas não fornece o mesmo nível de controle sobre aplicações em contêineres como ECS ou EKS, limitando a capacidade da empresa de gerenciar microserviços de forma eficaz.",
            "Amazon EC2 com Docker instalado oferece controle total sobre o ambiente, mas complica a escalabilidade e a gestão, o que vai contra a necessidade da empresa por uma solução simplificada e gerenciável."
        ]
    },
    {
        "Question Number": "74",
        "Situation": "Uma empresa está projetando uma nova aplicação serverless usando Amazon DynamoDB como seu banco de dados principal. A aplicação lidará com cargas de trabalho variadas, e a equipe de desenvolvimento está focada em otimizar os padrões de acesso a dados e minimizar custos. Eles precisam decidir sobre o uso apropriado de chaves primárias para garantir a recuperação e armazenamento eficientes de dados. (Selecione Dois)",
        "Question": "Quais duas configurações garantirão desempenho ideal e eficiência de custos no DynamoDB? (Selecione Dois)",
        "Options": {
            "1": "Configurar capacidade adaptativa para ajustar automaticamente a taxa de transferência para partições que estão experimentando alto tráfego sem exceder a capacidade total provisionada.",
            "2": "Usar uma chave primária simples com apenas uma chave de partição para garantir que os itens sejam distribuídos uniformemente entre as partições.",
            "3": "Usar índices secundários globais para permitir consultas com base em atributos diferentes da chave primária.",
            "4": "Usar uma chave primária composta com uma chave de partição e uma chave de ordenação para permitir consultas eficientes de itens relacionados.",
            "5": "Implementar um design de tabela única para consolidar todos os dados relacionados em uma única tabela DynamoDB para melhor desempenho."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Usar uma chave primária composta com uma chave de partição e uma chave de ordenação para permitir consultas eficientes de itens relacionados.",
            "Configurar capacidade adaptativa para ajustar automaticamente a taxa de transferência para partições que estão experimentando alto tráfego sem exceder a capacidade total provisionada."
        ],
        "Explanation": "Usar uma chave primária composta permite consultas e recuperação eficientes de itens relacionados, o que é crucial para aplicações com padrões de acesso complexos. Além disso, configurar capacidade adaptativa garante que a aplicação possa lidar com cargas de trabalho variadas sem incorrer em custos desnecessários devido a limitação ou superprovisionamento.",
        "Other Options": [
            "Usar uma chave primária simples pode não fornecer a flexibilidade necessária para recuperação eficiente de dados ao lidar com itens relacionados, o que pode levar a consultas ineficientes e potenciais problemas de desempenho.",
            "Embora índices secundários globais possam ser úteis, eles não abordam diretamente o design da chave primária para desempenho ideal; eles servem como um padrão de acesso secundário e podem incorrer em custos adicionais.",
            "Implementar um design de tabela única pode ser benéfico em alguns cenários, mas não aborda diretamente a necessidade de configuração ideal da chave primária e pode complicar os padrões de acesso a dados."
        ]
    },
    {
        "Question Number": "75",
        "Situation": "Uma empresa de serviços financeiros está desenvolvendo uma nova aplicação serverless usando AWS Lambda para lidar com transações em tempo real. Espera-se que a aplicação tenha níveis variados de tráfego ao longo do dia, com pico de uso durante o horário comercial. O arquiteto de soluções é responsável por garantir que a aplicação possa lidar com picos súbitos de tráfego enquanto minimiza custos.",
        "Question": "Qual método de controle de concorrência o arquiteto de soluções deve implementar para garantir que a aplicação possa lidar com picos súbitos de tráfego de forma eficiente?",
        "Options": {
            "1": "Usar uma combinação de concorrência provisionada e reservada para gerenciar o tráfego de forma eficaz e otimizar custos.",
            "2": "Definir concorrência reservada para limitar o número máximo de execuções simultâneas em todas as funções Lambda para evitar limitação.",
            "3": "Aumentar o limite total de concorrência para a conta AWS para permitir mais execuções simultâneas em todas as funções.",
            "4": "Configurar concorrência provisionada para pré-aquecer um número específico de instâncias Lambda para disponibilidade imediata durante picos de tráfego."
        },
        "Correct Answer": "Configurar concorrência provisionada para pré-aquecer um número específico de instâncias Lambda para disponibilidade imediata durante picos de tráfego.",
        "Explanation": "A concorrência provisionada permite que o arquiteto pré-inicialize um número definido de instâncias Lambda, garantindo que elas estejam prontas para lidar com solicitações imediatamente, o que é crucial para aplicações que experimentam picos súbitos de tráfego.",
        "Other Options": [
            "Definir concorrência reservada apenas limita as execuções simultâneas máximas sem garantir tempos de resposta imediatos, o que pode levar a atrasos durante cargas máximas.",
            "Embora uma combinação de concorrência provisionada e reservada possa fornecer alguns benefícios, isso complica a arquitetura e pode não ser necessário para gerenciar picos súbitos de forma eficaz.",
            "Aumentar o limite total de concorrência para a conta AWS pode não abordar a necessidade de disponibilidade imediata das instâncias Lambda durante picos de tráfego e pode levar a custos adicionais."
        ]
    }
]