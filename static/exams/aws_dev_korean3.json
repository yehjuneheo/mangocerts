[
    {
        "Question Number": "1",
        "Situation": "개발자가 강력하게 일관된 읽기를 위해 DynamoDB 테이블을 구성해야 합니다. 애플리케이션은 초당 50회의 읽기를 수행하며, 각 항목의 크기는 16 KB입니다.",
        "Question": "애플리케이션에 필요한 RCU의 수는 얼마입니까?",
        "Options": {
            "1": "100",
            "2": "200",
            "3": "400",
            "4": "800"
        },
        "Correct Answer": "200",
        "Explanation": "DynamoDB에서 강력하게 일관된 읽기를 위해 4 KB보다 큰 항목을 읽을 때마다 2 RCU가 필요합니다. 각 항목이 16 KB이므로, 읽기당 4 RCU가 필요합니다 (16 KB / 4 KB = 4). 따라서 초당 50회의 읽기를 위해 필요한 총 RCU는 50회의 읽기 * 4 RCU = 200 RCU입니다.",
        "Other Options": [
            "이 옵션은 잘못되었습니다. 100 RCU는 16 KB 항목에 대해 초당 25회의 읽기만 허용합니다 (100 RCU / 읽기당 4 RCU).",
            "이 옵션은 잘못되었습니다. 400 RCU는 요구 사항을 초과하여 초당 100회의 읽기를 허용합니다 (400 RCU / 읽기당 4 RCU), 이는 필요 이상입니다.",
            "이 옵션은 잘못되었습니다. 800 RCU는 초당 200회의 읽기를 허용합니다 (800 RCU / 읽기당 4 RCU), 이는 주어진 애플리케이션에 필요하지 않습니다."
        ]
    },
    {
        "Question Number": "2",
        "Situation": "개발 팀은 AWS Serverless Application Model (AWS SAM)을 사용하여 서버리스 애플리케이션의 새 버전을 배포할 준비를 하고 있습니다. 그들은 개발, 스테이징 및 프로덕션과 같은 다양한 환경에서 일관성을 보장하기 위해 배포 프로세스를 자동화하고자 합니다.",
        "Question": "팀이 이러한 환경에서 자동화된 애플리케이션 배포를 수행하기 위해 어떤 AWS 서비스 기능을 활용해야 합니까?",
        "Options": {
            "1": "수동 승인 단계를 포함한 AWS CodeCommit, 이는 배포 프로세스에 지연을 초래합니다.",
            "2": "AWS CodeDeploy와 AWS CodePipeline 통합, 이는 환경 간의 자동화되고 지속적인 배포 워크플로를 촉진합니다.",
            "3": "전통적인 애플리케이션에 더 적합한 AWS Elastic Beanstalk 환경 구성.",
            "4": "변경 사항 검토에 유용하지만 배포에 대한 완전한 자동화 솔루션을 제공하지 않는 AWS CloudFormation Change Sets."
        },
        "Correct Answer": "AWS CodeDeploy와 AWS CodePipeline 통합, 이는 환경 간의 자동화되고 지속적인 배포 워크플로를 촉진합니다.",
        "Explanation": "AWS CodeDeploy와 AWS CodePipeline 통합은 팀이 서버리스 애플리케이션을 위한 완전 자동화된 CI/CD 파이프라인을 생성할 수 있도록 합니다. 이 통합은 배포 프로세스가 원활하게 진행되고 개발, 스테이징 및 프로덕션과 같은 다양한 환경에서 일관되게 실행될 수 있도록 하여 팀의 자동화 및 일관성 목표를 지원합니다.",
        "Other Options": [
            "수동 승인 단계를 포함한 AWS CodeCommit은 인간의 개입이 필요하여 배포 프로세스를 지연시키고 자동화를 방해하여 지속적인 배포 요구에 덜 효과적입니다.",
            "AWS Elastic Beanstalk 환경 구성은 서버리스 애플리케이션보다 전통적인 웹 애플리케이션 배포를 위해 특별히 설계되어 현재 프로젝트에 적합하지 않습니다.",
            "AWS CloudFormation Change Sets는 변경 사항을 적용하기 전에 미리 볼 수 있는 방법을 제공하지만, 여러 환경에서 배포 프로세스를 본질적으로 자동화하지 않으며, 이는 팀의 주요 요구 사항입니다."
        ]
    },
    {
        "Question Number": "3",
        "Situation": "한 회사는 Amazon S3, Lambda 및 Amazon RDS와 같은 다양한 서비스를 사용하는 AWS에 호스팅된 마이크로서비스 기반 애플리케이션을 보유하고 있습니다. 각 마이크로서비스의 구성 데이터는 환경(예: 개발, 스테이징, 프로덕션)에 따라 다릅니다. 회사는 모든 서비스의 구성 데이터를 관리하고 안전하게 저장하며 배포 중에 올바른 구성을 자동으로 적용할 수 있는 솔루션이 필요합니다.",
        "Question": "회사가 환경 간 애플리케이션 구성 데이터를 관리하고 안전하게 저장하기 위해 어떤 AWS 서비스를 사용해야 합니까?",
        "Options": {
            "1": "AWS AppConfig를 사용하여 구성 데이터를 관리하고 실시간으로 다양한 환경에 구성을 적용합니다.",
            "2": "AWS Secrets Manager를 사용하여 민감한 애플리케이션 구성을 안전하게 저장하고 자동으로 회전합니다.",
            "3": "버전 관리 및 접근 제어 기능을 갖춘 AWS Systems Manager Parameter Store를 사용하여 애플리케이션 구성 데이터를 관리합니다.",
            "4": "모든 환경의 구성 파일을 저장하고 배포 중에 읽기 위해 Amazon S3를 사용합니다."
        },
        "Correct Answer": "AWS AppConfig를 사용하여 구성 데이터를 관리하고 실시간으로 다양한 환경에 구성을 적용합니다.",
        "Explanation": "AWS AppConfig는 애플리케이션 구성을 관리하도록 특별히 설계되었으며 실시간 업데이트를 허용합니다. 이는 마이크로서비스 아키텍처에 이상적이며, 환경에 따라 동적으로 구성을 적용할 수 있어 설명된 시나리오에 가장 적합한 선택입니다.",
        "Other Options": [
            "AWS Secrets Manager는 API 키 및 비밀번호와 같은 민감한 정보를 관리하는 데 중점을 두고 있으며, 일반 애플리케이션 구성 데이터에 대한 동일한 수준의 관리를 제공하지 않습니다. 보안을 강화하지만 환경 간 구성 데이터 관리를 제공하지 않습니다.",
            "AWS Systems Manager Parameter Store는 버전 관리 및 접근 제어와 같은 기능으로 구성 데이터를 관리하는 데 강력한 후보입니다. 그러나 AWS AppConfig가 제공하는 실시간 업데이트 기능이 부족하여 즉각적인 배포 요구에 덜 적합합니다.",
            "Amazon S3는 주로 저장 서비스이며 구성 데이터의 동적 관리 및 배포에 필요한 기능을 제공하지 않습니다. 배포 중에 구성 파일을 읽고 적용하는 데 추가 노력이 필요하며, 이는 AWS AppConfig를 사용하는 것만큼 효율적이지 않습니다."
        ]
    },
    {
        "Question Number": "4",
        "Situation": "개발자가 API Gateway를 사용하여 API를 설계하고 있으며, 들어오는 API 요청을 인증하고 권한 부여하기 위해 Lambda 함수를 사용하려고 합니다. 권한 부여 프로세스에는 각 요청의 Authorization 헤더에 포함된 JSON Web Token (JWT)에 대한 검사가 포함되어야 합니다.",
        "Question": "개발자가 Authorization 헤더에서 JSON Web Token (JWT)을 효과적으로 검증하기 위해 어떤 유형의 Lambda 권한 부여자를 사용해야 합니까?",
        "Options": {
            "1": "쿼리 문자열 매개변수 또는 헤더를 검증하는 데 적합한 요청 매개변수 기반 권한 부여자.",
            "2": "JSON Web Tokens (JWT)와 같은 지정된 토큰 형식을 검증하도록 설계된 토큰 기반 권한 부여자.",
            "3": "사용자 역할에 따라 액세스를 제어하기 위해 AWS Identity and Access Management를 활용하는 IAM 기반 권한 부여자.",
            "4": "요청 및 응답 형식을 변환하는 데 사용되는 Velocity Template Language (VTL) 매핑 템플릿."
        },
        "Correct Answer": "JSON Web Tokens (JWT)와 같은 지정된 토큰 형식을 검증하도록 설계된 토큰 기반 권한 부여자.",
        "Explanation": "개발자는 토큰 형식에 따라 권한 부여를 처리하도록 특별히 설계된 토큰 기반 권한 부여자를 사용해야 합니다. 이 권한 부여자는 Authorization 헤더에서 토큰을 추출하고 지정된 인증 논리에 따라 검증하여 JWT 인증이 포함된 시나리오에 적합합니다.",
        "Other Options": [
            "요청 매개변수 기반 권한 부여자는 요청에서 전달된 매개변수를 검증하는 데 중점을 두기 때문에 이 경우 적합하지 않습니다. JWT와 같은 토큰 기반 인증을 직접 처리하지 않습니다.",
            "IAM 기반 권한 부여자는 AWS Identity and Access Management 정책 및 역할에 의존하여 액세스를 권한 부여하기 때문에 여기서는 잘못된 선택입니다. JWT와 같은 토큰을 직접 검증하지 않습니다.",
            "Velocity Template Language (VTL) 매핑 템플릿은 권한 부여자가 아니라 요청 및 응답 페이로드를 변환하는 데 사용되는 도구이며, 인증 또는 권한 부여 기능을 수행하지 않습니다."
        ]
    },
    {
        "Question Number": "5",
        "Situation": "개발자가 Amazon DynamoDB 테이블에 저장된 데이터를 처리하기 위해 AWS Lambda 함수를 사용하는 애플리케이션을 작업하고 있습니다. 이 애플리케이션은 높은 읽기 및 쓰기 처리량을 처리하면서 지연 시간을 최소화해야 합니다. 개발자는 성능을 향상시키기 위해 캐싱을 구현하고 싶어합니다.",
        "Question": "개발자가 애플리케이션에 캐싱을 제공하기 위해 DynamoDB와 통합해야 하는 AWS 서비스는 무엇입니까?",
        "Options": {
            "1": "Amazon ElastiCache for Redis",
            "2": "Amazon S3",
            "3": "Amazon CloudFront",
            "4": "AWS Global Accelerator"
        },
        "Correct Answer": "Amazon ElastiCache for Redis",
        "Explanation": "Amazon ElastiCache for Redis는 자주 액세스되는 데이터를 메모리에 저장하여 애플리케이션의 성능을 크게 향상시킬 수 있는 캐싱 서비스입니다. 이는 DynamoDB를 사용하는 애플리케이션에 특히 유용하며, 데이터 검색 속도를 높여 지연 시간을 줄이고 높은 부하 조건에서 처리량을 개선합니다.",
        "Other Options": [
            "Amazon S3는 주로 객체 저장소로 사용되며, DynamoDB 통합에 직접적으로 이익을 줄 수 있는 캐싱 기능을 제공하지 않습니다.",
            "Amazon CloudFront는 정적 콘텐츠를 캐시하는 콘텐츠 전송 네트워크이지만 데이터베이스 쿼리나 애플리케이션 데이터를 캐시하는 데 설계되지 않았습니다.",
            "AWS Global Accelerator는 최적의 엔드포인트로 트래픽을 유도하여 애플리케이션의 가용성과 성능을 개선하지만 캐싱 기능을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "6",
        "Situation": "개발자가 게임 애플리케이션을 위한 캐싱 솔루션을 설계하고 있습니다. 이 애플리케이션은 자동 장애 조치, 복잡한 데이터 구조 및 지리 공간 쿼리에 대한 지원과 같은 기능이 필요합니다.",
        "Question": "개발자가 어떤 캐싱 엔진을 사용해야 합니까?",
        "Options": {
            "1": "Memcached",
            "2": "Redis",
            "3": "DynamoDB Accelerator (DAX)",
            "4": "Amazon S3"
        },
        "Correct Answer": "Redis",
        "Explanation": "Redis는 다양한 복잡한 데이터 유형을 지원하고 Redis Sentinel을 통한 자동 장애 조치 및 지리 공간 인덱싱을 지원하는 인메모리 데이터 구조 저장소로, 게임 애플리케이션의 캐싱 요구에 적합한 선택입니다.",
        "Other Options": [
            "Memcached는 복잡한 데이터 구조나 지리 공간 쿼리를 지원하지 않는 간단한 캐싱 솔루션이며, 자동 장애 조치에 대한 내장 지원이 없습니다.",
            "DynamoDB Accelerator (DAX)는 DynamoDB 성능을 향상시키기 위해 특별히 설계되었으며, 지리 공간 쿼리를 지원하는 범용 캐싱 엔진으로 기능하지 않습니다.",
            "Amazon S3는 캐싱 엔진이 아닌 저장 서비스이며, 게임 애플리케이션에서 캐싱에 필요한 인메모리 기능이나 요구 사항을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "7",
        "Situation": "ECS 클러스터에 있는 인스턴스가 간헐적으로 헬스 체크에 실패하여 애플리케이션의 안정성에 문제가 발생하고 있습니다. 이 애플리케이션은 사용자 만족도와 운영 효율성을 유지하기 위해 일관된 성능에 크게 의존하고 있습니다.",
        "Question": "이 문제를 해결하기 위한 가장 효과적인 솔루션은 무엇입니까?",
        "Options": {
            "1": "인스턴스 부하를 효과적으로 관리하기 위해 자동 스케일링 정책을 구현합니다.",
            "2": "허위 긍정 반응을 줄이기 위해 헬스 체크 주기를 늘립니다.",
            "3": "부하를 고르게 분산시키기 위해 더 많은 ECS 인스턴스를 추가합니다.",
            "4": "자원 소비를 줄이기 위해 애플리케이션 코드를 최적화합니다."
        },
        "Correct Answer": "인스턴스 부하를 효과적으로 관리하기 위해 자동 스케일링 정책을 구현합니다.",
        "Explanation": "자동 스케일링 정책을 구현하면 ECS 클러스터가 실시간 부하에 따라 인스턴스 수를 동적으로 조정할 수 있어 자원 제약과 관련된 문제를 완화하고 애플리케이션의 전반적인 안정성과 성능을 향상시킬 수 있습니다. 이 선제적 접근 방식은 헬스 체크 실패의 근본 원인을 해결하며, 단순히 매개변수를 조정하거나 부하 관리를 고려하지 않고 인스턴스를 추가하는 것이 아닙니다.",
        "Other Options": [
            "헬스 체크 주기를 늘리면 헬스 체크의 빈도를 줄일 수 있지만, 인스턴스가 실패하는 근본적인 문제를 해결하지는 않습니다. 실패가 발생할 경우 애플리케이션의 다운타임이 길어질 수 있습니다.",
            "더 많은 ECS 인스턴스를 추가하면 일시적으로 부하 문제를 완화할 수 있지만, 헬스 체크 실패의 근본 원인이 해결되지 않으면 새로운 인스턴스도 실패할 수 있습니다. 이는 반응적 접근 방식이지 선제적 해결책이 아닙니다.",
            "자원 소비를 줄이기 위해 애플리케이션 코드를 최적화하는 것은 중요하지만, 전체 부하 관리를 해결하지 않으면 간헐적인 헬스 체크 실패 문제가 지속될 수 있습니다. 이 옵션은 애플리케이션에 초점을 맞추지만 인프라의 확장성을 고려하지 않습니다."
        ]
    },
    {
        "Question Number": "8",
        "Situation": "개발자가 AWS Lambda와 Amazon Kinesis Data Streams를 사용하여 실시간 데이터 스트림을 처리하는 애플리케이션을 구축하고 있습니다. 이 애플리케이션은 정확한 처리를 보장하기 위해 순서가 뒤바뀐 레코드를 재정렬할 수 있는 기능이 필요합니다.",
        "Question": "개발자가 Kinesis에서 순서가 뒤바뀐 레코드를 처리하기 위해 구현해야 할 기능은 무엇입니까?",
        "Options": {
            "1": "배치 윈도우를 사용하여 Lambda 이벤트 소스 매핑을 활성화합니다.",
            "2": "변경 사항을 캡처하고 레코드를 재정렬하기 위해 DynamoDB Streams를 사용합니다.",
            "3": "Lambda 함수 내에서 레코드 순서 번호 매기기 및 재정렬 로직을 구현합니다.",
            "4": "Kinesis Data Firehose를 활용하여 Lambda 처리 전에 레코드를 전처리하고 재정렬합니다."
        },
        "Correct Answer": "Lambda 함수 내에서 레코드 순서 번호 매기기 및 재정렬 로직을 구현합니다.",
        "Explanation": "Lambda 함수 내에서 레코드 순서 번호 매기기 및 재정렬 로직을 구현하면 애플리케이션이 레코드의 순서 번호에 따라 레코드의 순서를 관리할 수 있습니다. 이 접근 방식은 레코드가 순서가 뒤바뀌어 도착하더라도 올바른 순서로 처리되도록 보장합니다.",
        "Other Options": [
            "배치 윈도우를 사용하여 Lambda 이벤트 소스 매핑을 활성화하는 것은 레코드의 순서 처리를 보장하지 않으며, 레코드를 재정렬하기보다는 배치 처리에 중점을 둡니다.",
            "변경 사항을 캡처하고 레코드를 재정렬하기 위해 DynamoDB Streams를 사용하는 것은 직접적으로 적용되지 않으며, DynamoDB Streams는 Kinesis Data Streams에서 레코드를 재정렬하기 위한 내장 메커니즘을 제공하지 않습니다.",
            "Kinesis Data Firehose를 활용하여 레코드를 전처리하고 재정렬하는 것은 적합하지 않으며, Data Firehose는 데이터 전달을 위해 설계되었지 실시간 레코드 재정렬 및 처리를 위해 설계된 것이 아닙니다."
        ]
    },
    {
        "Question Number": "9",
        "Situation": "개발자가 AWS에 호스팅된 애플리케이션의 암호화 설정을 적극적으로 구성하고 있습니다. 이 과정의 일환으로 개발자는 AWS 공유 책임 모델에 명시된 책임의 구분을 이해하고자 합니다. 이 모델은 AWS의 관할 하에 있는 보안 의무와 개발자의 책임이 무엇인지 명확하게 정의합니다. 이러한 이해는 애플리케이션과 데이터가 적절히 보호되도록 보장하는 데 매우 중요합니다.",
        "Question": "AWS 공유 책임 모델의 맥락에서 AWS가 보안 및 규정 준수를 관리하는 데 있어 책임지는 특정 측면은 무엇입니까?",
        "Options": {
            "1": "S3에 저장된 데이터를 기본적으로 암호화합니다.",
            "2": "물리적 인프라 및 관리형 서비스를 보호합니다.",
            "3": "보안 그룹 및 IAM 역할을 구성합니다.",
            "4": "고객 특정 데이터 규정 준수를 보장합니다."
        },
        "Correct Answer": "물리적 인프라 및 관리형 서비스를 보호합니다.",
        "Explanation": "AWS 공유 책임 모델에 따라 AWS는 클라우드 인프라 자체의 보안에 책임이 있으며, 여기에는 AWS 서비스가 실행되는 물리적 시설, 하드웨어 및 소프트웨어의 보안이 포함됩니다. 이는 AWS가 제공하는 관리형 서비스도 포함되며, 고객은 자신의 애플리케이션 및 데이터 보안을 구성할 책임이 있습니다.",
        "Other Options": [
            "AWS는 S3에 저장된 데이터를 기본적으로 암호화하지 않으며, 고객이 데이터를 보호하려면 암호화를 활성화해야 합니다.",
            "보안 그룹 및 IAM 역할을 구성하는 것은 고객의 책임이며, 이는 접근 제어 및 권한과 관련된 요소입니다.",
            "AWS는 많은 규정 준수 서비스와 인증을 제공하지만, 특정 고객 데이터 규정 준수를 보장하는 것은 주로 고객의 책임이며, 고객은 필요한 통제를 이해하고 구현해야 합니다."
        ]
    },
    {
        "Question Number": "10",
        "Situation": "한 회사가 관계형 데이터베이스 관리를 위해 Amazon RDS를 사용하고, 자주 접근되는 데이터를 캐시하기 위해 Amazon ElastiCache for Redis를 사용하고 있습니다. 개발 팀은 캐시된 데이터가 데이터베이스와 일관성을 유지하고 캐시 미스를 최소화하도록 보장하고자 합니다.",
        "Question": "팀이 데이터 캐시를 효과적으로 관리하기 위해 어떤 전략을 구현해야 합니까?",
        "Options": {
            "1": "데이터가 캐시와 데이터베이스에 동시에 기록되는 쓰기-통과 캐시를 구현합니다.",
            "2": "애플리케이션에서 요청할 때만 데이터를 캐시에 로드하는 지연 로딩 캐시를 사용합니다.",
            "3": "캐시된 데이터의 TTL(유효 기간)을 짧게 설정하여 자주 새로 고침되도록 합니다.",
            "4": "애플리케이션이 캐시 채우기 및 무효화를 관리하는 캐시-옆 패턴을 사용합니다."
        },
        "Correct Answer": "데이터가 캐시와 데이터베이스에 동시에 기록되는 쓰기-통과 캐시를 구현합니다.",
        "Explanation": "쓰기-통과 캐시는 데이터가 기록될 때마다 캐시와 데이터베이스 모두에서 동시에 업데이트되도록 보장합니다. 이 접근 방식은 캐시와 데이터베이스 간의 일관성을 유지하는 데 도움이 되며, 캐시 미스를 최소화하고 캐시의 데이터가 항상 기본 데이터베이스와 최신 상태를 유지하도록 합니다.",
        "Other Options": [
            "지연 로딩 캐시는 데이터가 요청될 때만 캐시를 채우므로, 데이터가 미리 로드되지 않으면 캐시 미스가 발생할 수 있어 일관성을 보장하지 않습니다.",
            "짧은 TTL을 설정하면 데이터 신선도를 개선할 수 있지만, 데이터가 자주 새로 로드되면서 캐시 미스가 증가하고 데이터베이스에 추가 부하가 발생할 수 있습니다.",
            "캐시-옆 패턴은 애플리케이션이 캐시 채우기 및 무효화에 대한 책임을 져야 하므로, 일관성 관리가 복잡해지고 잘못 처리될 경우 오래된 데이터가 발생할 수 있습니다."
        ]
    },
    {
        "Question Number": "11",
        "Situation": "개발자가 Amazon API Gateway와 AWS Lambda를 사용하여 RESTful API를 설계하고 있습니다. API는 제3자 신원 제공자가 발급한 JSON 웹 토큰(JWT)을 사용하여 사용자를 인증해야 합니다. 개발자는 Lambda 함수를 호출하기 전에 JWT를 검증하여 안전한 접근을 보장하고자 합니다.",
        "Question": "개발자가 Lambda 함수에 대한 접근을 허용하기 전에 JWT를 효과적으로 검증하기 위해 어떤 API Gateway 기능을 사용해야 합니까?",
        "Options": {
            "1": "API 키는 호출 애플리케이션을 식별하여 API에 대한 접근을 제어하는 데 사용되지만 JWT를 검증하지는 않습니다.",
            "2": "AWS Identity and Access Management (IAM) 역할은 AWS 리소스에 대한 권한을 관리하지만 API Gateway의 JWT 검증을 직접 처리하지는 않습니다.",
            "3": "사용자 정의 인증자(Lambda 인증자)는 JWT 검증을 포함한 사용자 정의 인증 논리를 구현할 수 있게 하여 API 엔드포인트를 보호합니다.",
            "4": "Amazon Cognito 사용자 풀은 사용자 인증 및 관리를 제공하지만 Cognito 외부에서 발급된 제3자 JWT를 검증하는 데는 필요하지 않습니다."
        },
        "Correct Answer": "사용자 정의 인증자(Lambda 인증자)는 JWT 검증을 포함한 사용자 정의 인증 논리를 구현할 수 있게 하여 API 엔드포인트를 보호합니다.",
        "Explanation": "사용자 정의 인증자(Lambda 인증자)는 사용자 정의 인증 논리를 위한 유연성을 제공하도록 설계되어 있어 JSON 웹 토큰(JWT) 검증에 이상적입니다. 개발자는 API Gateway가 요청을 백엔드 Lambda 함수로 라우팅하기 전에 JWT를 검증하는 Lambda 함수를 작성할 수 있어, 인증된 사용자만 보호된 리소스에 접근할 수 있도록 보장합니다.",
        "Other Options": [
            "API 키는 요청을 하는 애플리케이션을 식별하여 API에 대한 접근을 추적하고 제어하는 데 주로 사용되지만 JWT를 검증하는 메커니즘을 제공하지 않습니다.",
            "AWS Identity and Access Management (IAM) 역할은 AWS 리소스에 대한 권한 및 접근을 관리하는 데 필수적이지만, 외부 신원 제공자가 발급한 JWT의 직접 검증을 촉진하지는 않습니다.",
            "Amazon Cognito 사용자 풀은 AWS 내에서 사용자 인증 및 권한 관리를 위한 서비스입니다. JWT를 처리할 수 있지만, JWT가 제3자 신원 제공자에 의해 발급된 경우에는 필요하지 않으므로 이 특정 검증 작업에 적합하지 않습니다."
        ]
    },
    {
        "Question Number": "12",
        "Situation": "개발자가 다른 AWS 계정의 팀과 협업해야 하는 프로젝트를 진행하고 있습니다. 이 협업을 촉진하기 위해 개발자는 특정 작업을 위해 다른 AWS 계정의 특정 AWS 리소스에 대한 임시 접근 권한을 부여해야 하며, 이 접근 권한이 범위와 기간 모두에서 제한되도록 해야 합니다. 이는 관련 리소스에 대한 보안과 통제를 유지하는 데 중요합니다.",
        "Question": "이 시나리오에서 개발자가 다른 AWS 계정의 필요한 리소스에 대해 지정된 작업을 수행하기 위해 임시 접근 권한을 효과적으로 부여하기 위해 어떤 AWS 서비스 또는 기능을 활용해야 합니까?",
        "Options": {
            "1": "AWS IAM 역할과 AssumeRole",
            "2": "AWS 리소스 접근 관리자(RAM)",
            "3": "AWS Secrets Manager",
            "4": "AWS Single Sign-On (SSO)"
        },
        "Correct Answer": "AWS IAM 역할과 AssumeRole",
        "Explanation": "AWS IAM 역할과 AssumeRole 기능은 한 AWS 계정의 사용자가 다른 계정에 정의된 역할을 맡을 수 있도록 합니다. 이는 역할에 연결된 권한을 필요한 작업에 맞게 조정할 수 있어 임시 접근 권한을 부여하는 안전한 방법을 제공합니다. 또한 역할을 맡을 때 설정된 세션 기간에 따라 접근이 시간 제한됩니다.",
        "Other Options": [
            "AWS 리소스 접근 관리자(RAM)는 계정 간 리소스를 공유하도록 설계되었지만, 다른 계정의 사용자에게 특별히 맞춘 임시 접근 관리 메커니즘을 제공하지 않습니다.",
            "AWS Secrets Manager는 비밀번호, API 키 및 기타 비밀과 같은 민감한 정보를 관리하는 데 주로 사용되며, 계정 간 AWS 리소스에 대한 접근을 부여하는 데 사용되지 않습니다.",
            "AWS Single Sign-On (SSO)은 사용자가 단일 자격 증명을 사용하여 여러 AWS 계정 및 애플리케이션에 로그인할 수 있도록 하지만, 다른 계정의 리소스에 대한 임시 접근 권한 부여를 구체적으로 다루지는 않습니다."
        ]
    },
    {
        "Question Number": "13",
        "Situation": "개발 팀이 애플리케이션 개발 생애 주기를 개선하기 위한 종합 솔루션을 찾고 있습니다. 필수 기능으로는 버전 관리, 효율적인 빌드 및 배포 기능, 프로젝트 진행 상황을 모니터링하고 개발 작업을 관리할 수 있는 중앙 대시보드가 포함됩니다. 또한, Atlassian JIRA와 같은 타사 프로젝트 관리 도구와의 원활한 통합을 원합니다.",
        "Question": "팀이 모든 요구 사항을 효과적으로 충족하기 위해 어떤 AWS 서비스를 사용해야 합니까?",
        "Options": {
            "1": "AWS CodePipeline은 지속적인 통합 및 배포 워크플로를 가능하게 하지만 중앙 대시보드가 없습니다.",
            "2": "AWS CodeStar는 개발 작업, 버전 관리 및 JIRA와 같은 프로젝트 관리 도구와의 통합을 관리하기 위한 통합 인터페이스를 제공합니다.",
            "3": "AWS CodeCommit은 버전 관리 서비스이지만 빌드 및 배포 기능이나 프로젝트 대시보드를 포함하지 않습니다.",
            "4": "AWS CodeDeploy는 배포 자동화에 중점을 두지만 버전 관리나 프로젝트 관리 인터페이스를 제공하지 않습니다."
        },
        "Correct Answer": "AWS CodeStar는 개발 작업, 버전 관리 및 JIRA와 같은 프로젝트 관리 도구와의 통합을 관리하기 위한 통합 인터페이스를 제공합니다.",
        "Explanation": "AWS CodeStar는 버전 관리, 빌드 및 배포 기능, 중앙 프로젝트 대시보드를 포함하는 완벽한 솔루션을 제공하므로 개발 팀에 가장 적합한 선택입니다. 또한 Atlassian JIRA와 원활하게 통합되어 팀의 요구 사항에 완벽하게 부합합니다.",
        "Other Options": [
            "AWS CodePipeline은 주로 지속적인 통합 및 배포를 촉진하지만 중앙 대시보드나 광범위한 프로젝트 관리 기능을 제공하지 않아 팀의 필요에 덜 적합합니다.",
            "AWS CodeCommit은 팀이 소스 코드를 관리할 수 있도록 하는 버전 관리 서비스이지만, 팀의 워크플로에 중요한 배포 기능이나 프로젝트 관리 인터페이스가 부족합니다.",
            "AWS CodeDeploy는 배포 프로세스를 자동화하여 애플리케이션이 일관되게 업데이트되도록 하지만, 버전 관리나 프로젝트 관리 대시보드를 제공하지 않아 팀의 모든 요구 사항을 충족하지 못합니다."
        ]
    },
    {
        "Question Number": "14",
        "Situation": "개발자가 실시간 데이터 처리 애플리케이션을 위해 Kinesis 스트림을 관리하고 있으며, 스트림 내 특정 샤드가 불균형한 양의 데이터로 과부하되고 있음을 관찰합니다. 데이터 분포의 이러한 불균형은 병목 현상을 초래하여 데이터 처리 파이프라인의 전반적인 성능과 효율성을 크게 저해할 수 있습니다. 시스템을 최적화하고 모든 샤드가 일관된 속도로 데이터를 처리할 수 있도록 하기 위해 개발자는 이 상황을 수정하기 위한 적절한 조치를 식별해야 합니다.",
        "Question": "개발자가 Kinesis 스트림 내 샤드 간의 불균형한 데이터 분포 문제를 효과적으로 해결하기 위해 어떤 조치를 취해야 합니까?",
        "Options": {
            "1": "샤드를 병합하여 용량을 줄입니다.",
            "2": "Kinesis에서 핫 샤드 억제를 활성화합니다.",
            "3": "핫 샤드를 분할하여 용량을 증가시킵니다.",
            "4": "스트림의 보존 기간을 늘립니다."
        },
        "Correct Answer": "핫 샤드를 분할하여 용량을 증가시킵니다.",
        "Explanation": "개발자가 취해야 할 올바른 조치는 핫 샤드를 분할하여 용량을 증가시키는 것입니다. 높은 데이터 속도를 경험하고 있는 샤드를 분할함으로써, 개발자는 데이터 부하를 여러 샤드에 더 고르게 분산시킬 수 있어 처리 병목 현상을 완화하고 Kinesis 스트림의 전반적인 성능을 향상시킬 수 있습니다.",
        "Other Options": [
            "샤드를 병합하면 용량이 결합되지만 불균형한 데이터 분포 문제를 해결하지 못하고 스트림의 성능을 악화시킬 수 있습니다.",
            "핫 샤드 억제를 활성화하는 것은 Kinesis의 표준 기능이 아니며 샤드 간의 불균형한 데이터 분포 문제를 직접 해결하지 않습니다.",
            "스트림의 보존 기간을 늘리는 것은 데이터 저장 기간에만 영향을 미치며, 샤드 간의 수신 데이터 분포에는 영향을 미치지 않습니다."
        ]
    },
    {
        "Question Number": "15",
        "Situation": "한 회사가 데이터베이스에 대한 뛰어난 가용성과 내결함성을 요구하는 중요한 애플리케이션을 운영하고 있습니다. 이를 달성하기 위해 데이터베이스는 여러 가용 영역에 걸쳐 데이터를 자동으로 복제할 수 있어야 하며, 이를 통해 장애나 중단 발생 시 다운타임의 위험을 최소화해야 합니다. 이 요구 사항은 클라우드 환경에서 데이터베이스 시스템의 복원력과 안정성을 향상시키는 올바른 기능을 선택하는 것의 중요성을 강조합니다.",
        "Question": "Amazon Aurora의 어떤 특정 기능이 여러 가용 영역에 걸쳐 데이터를 자동으로 복제하여 중요한 애플리케이션에 필요한 내결함성을 제공하도록 설계되었습니까?",
        "Options": {
            "1": "Aurora Read Replicas",
            "2": "Multi-AZ Deployments",
            "3": "Aurora Global Database",
            "4": "Continuous Backup"
        },
        "Correct Answer": "Multi-AZ Deployments",
        "Explanation": "Amazon Aurora의 Multi-AZ Deployments는 데이터베이스를 여러 가용 영역에 걸쳐 자동으로 복제하여 높은 가용성을 제공합니다. 이로 인해 하나의 가용 영역에서 중단이 발생하더라도 데이터베이스는 다른 영역에서 접근 가능하게 되어 다운타임을 최소화하고 중요한 애플리케이션에 대한 내결함성을 제공합니다.",
        "Other Options": [
            "Aurora Read Replicas는 주로 읽기 확장성과 성능을 향상시키기 위해 사용되지만, 여러 가용 영역에 걸쳐 자동 장애 조치 기능을 제공하지 않습니다.",
            "Aurora Global Database는 글로벌 애플리케이션을 위해 설계되었으며, 다양한 AWS 리전에서 저지연 읽기를 가능하게 하지만, 단일 리전 내에서 내결함성을 보장하는 데는 특별히 초점을 맞추고 있지 않습니다.",
            "Continuous Backup은 데이터베이스의 자동 백업을 가능하게 하여 데이터 보호에 유용하지만, 여러 가용 영역에 걸친 실시간 복제 및 높은 가용성 문제를 해결하지 않습니다."
        ]
    },
    {
        "Question Number": "16",
        "Situation": "당신은 AWS에서 고가용성과 비용 효율성을 갖춘 데이터 처리 솔루션을 만드는 임무를 맡았습니다. 처리해야 할 데이터는 방대하며 배치로 처리됩니다. 또한, 효율성을 최적화하기 위해 변경된 항목만 처리되는 것이 중요합니다.",
        "Question": "이 시나리오에서 변경된 항목만 효율적으로 처리하기 위해 사용할 수 있는 최상의 서비스 조합은 무엇입니까?",
        "Options": {
            "1": "Amazon S3와 CloudFront를 함께 활용하여 데이터를 Lambda 함수로 효율적으로 전달하고 처리 및 분석합니다.",
            "2": "Amazon Kinesis Data Streams를 활용하여 데이터를 지속적으로 수집하고 Lambda 함수를 사용하여 항목 변경 여부와 관계없이 실시간으로 처리합니다.",
            "3": "Amazon SQS와 Lambda 함수를 사용하여 도착하는 메시지를 배치로 처리하여 데이터를 효과적으로 관리합니다.",
            "4": "Amazon DynamoDB Streams를 구현하여 데이터에 변경 사항이 있을 때마다 Lambda 함수를 자동으로 트리거하여 수정된 항목만 처리되도록 합니다."
        },
        "Correct Answer": "Amazon DynamoDB Streams를 구현하여 데이터에 변경 사항이 있을 때마다 Lambda 함수를 자동으로 트리거하여 수정된 항목만 처리되도록 합니다.",
        "Explanation": "Amazon DynamoDB Streams를 사용하면 DynamoDB 테이블의 변경 사항을 감지하고 해당 변경 사항에 대해 Lambda 함수를 트리거할 수 있습니다. 이는 변경된 항목만 처리하게 되어 불필요한 변경되지 않은 데이터의 처리를 피함으로써 솔루션의 효율성과 비용 효율성을 높입니다.",
        "Other Options": [
            "Amazon S3와 CloudFront를 사용하는 것은 변경 감지보다는 콘텐츠 전달에 중점을 두어 변경된 항목만 처리해야 한다는 요구 사항을 충족하지 않습니다.",
            "Amazon Kinesis Data Streams를 사용하는 것은 배치 처리보다는 실시간 데이터 처리에 더 적합하며, 변경 사항을 본질적으로 필터링하지 않아 수집된 모든 데이터를 처리하게 됩니다.",
            "Amazon SQS와 Lambda 함수를 활용하면 효율적인 메시지 처리가 가능하지만 데이터 항목의 변경 사항을 구체적으로 추적하지 않아 변경되지 않은 항목을 처리할 수 있습니다."
        ]
    },
    {
        "Question Number": "17",
        "Situation": "개발자는 여러 장치에서 데이터가 고가용성과 일관성을 유지하도록 하는 모바일 애플리케이션을 설계하고 있습니다. 이 애플리케이션은 사용자 선호도 및 설정을 저장하기 위해 Amazon DynamoDB를 사용합니다.",
        "Question": "개발자가 사용자가 항상 최신 데이터를 볼 수 있도록 보장하기 위해 어떤 DynamoDB 일관성 모델을 사용해야 합니까?",
        "Options": {
            "1": "최종 일관성 읽기",
            "2": "강력한 일관성 읽기",
            "3": "트랜잭션 읽기",
            "4": "일관된 해싱"
        },
        "Correct Answer": "강력한 일관성 읽기",
        "Explanation": "강력한 일관성 읽기는 사용자가 데이터를 검색할 때 항상 해당 데이터의 가장 최근 쓰기를 볼 수 있도록 보장합니다. 이는 모바일 앱에서 사용자 선호도 및 설정과 같이 최신 정보가 필요한 애플리케이션에 매우 중요합니다.",
        "Other Options": [
            "최종 일관성 읽기는 미래의 어느 시점에서 가장 최근 쓰기를 반영하는 결과를 제공하므로 오래된 데이터를 반환할 수 있으며, 최신 데이터를 보장하지 않습니다.",
            "트랜잭션 읽기는 여러 항목에 대한 원자적 작업에 사용되지만 단일 읽기 작업의 일관성을 구체적으로 다루지 않으므로 가장 최근 데이터를 단순히 검색하는 데 덜 관련이 있습니다.",
            "일관된 해싱은 클러스터에 데이터를 분산하는 데 사용되는 기술이며 DynamoDB에서 읽기의 일관성 모델과 관련이 없습니다."
        ]
    },
    {
        "Question Number": "18",
        "Situation": "개발자는 Amazon RDS 인스턴스의 데이터베이스 자격 증명이 가장 높은 수준의 보안으로 관리되도록 하는 임무를 맡았습니다. 이러한 자격 증명의 민감한 특성을 고려할 때, 자격 증명이 안전하게 유지될 뿐만 아니라 지정된 간격으로 자동으로 회전되어 무단 접근의 위험을 최소화하는 것이 필수적입니다.",
        "Question": "개발자가 RDS 인스턴스의 데이터베이스 자격 증명의 자동 회전 및 안전한 관리를 구현하기 위해 가장 적합한 AWS 서비스는 무엇입니까?",
        "Options": {
            "1": "AWS Cloud9은 주로 코드 개발 및 협업을 위한 클라우드 기반 통합 개발 환경으로, 안전한 자격 증명 관리 기능을 제공하지 않습니다.",
            "2": "AWS Secrets Manager는 API 키 및 데이터베이스 자격 증명과 같은 민감한 정보를 관리하기 위해 특별히 설계되었으며, 보안을 강화하기 위해 비밀의 자동 회전 기능을 포함하고 있습니다.",
            "3": "AWS Systems Manager Parameter Store는 구성 데이터 및 비밀을 위한 안전한 저장소를 제공하지만 자격 증명의 자동 회전을 다른 서비스만큼 효과적으로 지원하지 않습니다.",
            "4": "AWS SWF(단순 워크플로 서비스)는 분산 애플리케이션에서 워크플로를 조정하고 관리하는 데 중점을 두며, 데이터베이스 자격 증명의 안전한 관리와는 관련이 없습니다."
        },
        "Correct Answer": "AWS Secrets Manager는 API 키 및 데이터베이스 자격 증명과 같은 민감한 정보를 관리하기 위해 특별히 설계되었으며, 보안을 강화하기 위해 비밀의 자동 회전 기능을 포함하고 있습니다.",
        "Explanation": "AWS Secrets Manager는 비밀을 안전하게 관리하기 위해 명시적으로 설계되었으며, 자격 증명의 자동 회전 기능을 포함하고 있어 데이터베이스 관리에서 보안을 유지하는 데 매우 중요합니다. 이 서비스는 개발자가 비밀을 쉽게 저장하고 관리할 수 있도록 하며, 수동 개입 없이 정기적으로 회전되도록 보장합니다.",
        "Other Options": [
            "AWS Cloud9은 개발 환경으로 기능하며 데이터베이스 자격 증명이나 비밀 관리 기능을 제공하지 않기 때문에 잘못된 선택입니다.",
            "AWS Systems Manager Parameter Store는 구성 데이터 및 비밀을 위한 안전한 저장소를 제공하지만 AWS Secrets Manager의 자동 회전 기능이 부족하여 데이터베이스 자격 증명을 안전하고 효율적으로 관리하는 데 덜 적합합니다.",
            "AWS SWF는 자격 증명 관리에 적합하지 않으며, 분산 애플리케이션에서 워크플로를 관리하는 데 중점을 두고 있어 데이터베이스 자격 증명의 안전한 처리와는 관련이 없습니다."
        ]
    },
    {
        "Question Number": "19",
        "Situation": "개발자가 AWS 서비스를 사용하고 있으며, 다른 AWS 계정에 위치한 S3 버킷에 접근할 수 있는 권한을 EC2 인스턴스에서 실행 중인 서비스에 제공해야 합니다. 보안과 모범 사례의 중요성을 이해한 개발자는 EC2 인스턴스가 이 크로스 계정 접근을 용이하게 할 수 있도록 IAM 역할을 사용하기로 결정합니다.",
        "Question": "개발자가 이 솔루션을 안전하게 구현하기 위해 어떤 조치를 취해야 하며, EC2 인스턴스가 보안을 해치지 않고 S3 버킷에 접근할 수 있는 적절한 권한을 갖도록 해야 합니까?",
        "Options": {
            "1": "EC2 인스턴스가 역할을 맡을 수 있도록 신뢰 정책을 가진 IAM 역할을 생성합니다. 다른 AWS 계정의 S3 버킷에 대한 접근을 허용하는 정책을 역할에 첨부합니다.",
            "2": "S3 계정에 버킷에 접근할 수 있는 권한을 가진 IAM 사용자를 생성하고 EC2 인스턴스에 IAM 사용자의 자격 증명을 제공합니다.",
            "3": "EC2 인스턴스에 IAM 정책을 직접 첨부하여 S3 버킷에 접근할 수 있도록 하며, 역할 기반 인증을 우회합니다.",
            "4": "필요한 권한을 가진 새로운 IAM 그룹을 생성하고 EC2 인스턴스를 해당 그룹에 할당하여 S3 버킷에 접근합니다."
        },
        "Correct Answer": "EC2 인스턴스가 역할을 맡을 수 있도록 신뢰 정책을 가진 IAM 역할을 생성합니다. 다른 AWS 계정의 S3 버킷에 대한 접근을 허용하는 정책을 역할에 첨부합니다.",
        "Explanation": "신뢰 정책을 가진 IAM 역할을 생성하면 EC2 인스턴스가 안전하게 역할을 맡을 수 있으며 최소 권한 원칙을 유지할 수 있습니다. 이 역할에 다른 AWS 계정의 S3 버킷에 대한 접근을 허용하는 정책을 첨부함으로써, 개발자는 권한이 중앙에서 안전하게 관리되도록 보장하며 IAM 사용자 자격 증명을 노출하거나 역할 기반 접근 제어를 우회하지 않도록 합니다.",
        "Other Options": [
            "S3 계정에 IAM 사용자를 생성하고 EC2 인스턴스에 사용자의 자격 증명을 제공하는 것은 보안을 해칩니다. 자격 증명이 노출되거나 잘못 관리되면 무단 접근으로 이어질 수 있어, IAM 역할을 사용하는 것보다 덜 안전한 접근 방식입니다.",
            "EC2 인스턴스에 IAM 정책을 직접 첨부하는 것은 역할 기반 인증의 이점을 우회하며 보안 위험을 초래할 수 있습니다. 이 방법은 중앙 집중식 권한 관리가 불가능하며 부적절한 접근 권한 부여의 위험을 증가시킵니다.",
            "새로운 IAM 그룹을 생성하고 EC2 인스턴스를 해당 그룹에 할당하는 것은 다른 AWS 계정의 S3 버킷에 접근을 허용하는 유효한 방법이 아닙니다. IAM 그룹은 IAM 사용자에 대한 권한 관리를 위해 설계되었으며, EC2 인스턴스에 직접 권한을 할당하는 데 사용되지 않습니다."
        ]
    },
    {
        "Question Number": "20",
        "Situation": "개발 팀이 AWS에서 실행되는 애플리케이션에 대한 접근 제어를 구현하고 있습니다. 그들은 사용자가 조직 내에서 자신의 직무 역할에 맞는 리소스에만 접근할 수 있도록 해야 합니다.",
        "Question": "팀이 이 요구 사항을 구현하기 위해 어떤 접근 제어 모델을 사용해야 합니까?",
        "Options": {
            "1": "속성 기반 접근 제어 (ABAC)",
            "2": "역할 기반 접근 제어 (RBAC)",
            "3": "재량적 접근 제어 (DAC)",
            "4": "강제적 접근 제어 (MAC)"
        },
        "Correct Answer": "역할 기반 접근 제어 (RBAC)",
        "Explanation": "역할 기반 접근 제어 (RBAC)는 조직 내 사용자 역할에 따라 권한을 할당하도록 설계되어 있어 팀의 요구 사항에 가장 적합한 옵션입니다.",
        "Other Options": [
            "속성 기반 접근 제어 (ABAC)는 역할 대신 속성을 사용하므로 직무 기반 권한 구현을 복잡하게 만들 수 있습니다.",
            "재량적 접근 제어 (DAC)는 사용자가 자신의 리소스에 대한 접근을 제어할 수 있도록 하며, 이는 역할 기반 권한과 일치하지 않습니다.",
            "강제적 접근 제어 (MAC)는 사용자 역할에 기반하지 않은 엄격한 정책을 시행하므로 직무 관련 접근 요구에 덜 유연합니다."
        ]
    },
    {
        "Question Number": "21",
        "Situation": "조직은 여러 계정과 지역에 걸쳐 S3 버킷을 생성하기 위해 CloudFormation 스택을 배포해야 합니다.",
        "Question": "조직이 이를 달성하기 위해 AWS CloudFormation의 어떤 기능을 사용해야 합니까?",
        "Options": {
            "1": "크로스 스택 참조",
            "2": "내장 함수",
            "3": "스택 세트",
            "4": "매개변수"
        },
        "Correct Answer": "스택 세트",
        "Explanation": "AWS CloudFormation 스택 세트를 사용하면 사용자가 여러 계정과 지역에 걸쳐 스택을 생성, 업데이트 또는 삭제할 수 있습니다. 이는 환경 전반에 걸쳐 리소스를 일관되게 관리해야 하는 조직에 특히 유용합니다.",
        "Other Options": [
            "크로스 스택 참조는 한 스택의 리소스를 다른 스택에서 참조하는 데 사용되지만, 여러 계정과 지역에 걸쳐 배포를 용이하게 하지는 않습니다.",
            "내장 함수는 리소스 속성에 대한 작업을 수행하는 데 도움이 되는 CloudFormation 템플릿 내의 내장 함수이지만, 크로스 계정 또는 크로스 지역 배포를 위한 메커니즘을 제공하지 않습니다.",
            "매개변수는 런타임에 CloudFormation 템플릿에 동적 값을 전달하는 데 사용되지만, 여러 계정이나 지역에 걸쳐 스택을 배포하는 것을 가능하게 하지는 않습니다."
        ]
    },
    {
        "Question Number": "22",
        "Situation": "기술 중심의 회사가 서비스 배포를 효율적으로 관리하기 위해 Amazon ECS와 CodeDeploy를 채택했습니다. 새로운 서비스 업데이트가 고객 경험을 방해하지 않도록 보장하기 위한 노력의 일환으로, 그들은 전체 전환을 하기 전에 업데이트된 서비스로 향하는 트래픽의 작은 비율을 테스트할 수 있는 전략을 구현하고자 합니다. 이 접근 방식은 위험을 최소화하고 새로운 서비스 버전의 성능에 대한 귀중한 통찰을 제공하는 것을 목표로 합니다.",
        "Question": "업데이트된 서비스 테스트를 위해 트래픽을 점진적으로 전환하려는 목표를 고려할 때, 어떤 특정 ECS 배포 전략이 그들의 필요에 가장 적합할까요?",
        "Options": {
            "1": "구형 버전을 새로운 버전으로 점진적으로 교체하면서 전환 중 서비스 가용성을 유지하는 롤링 업데이트.",
            "2": "대부분의 트래픽을 안정적인 버전으로 유지하면서 새로운 버전으로 소량의 트래픽을 라우팅할 수 있는 블루/그린 배포와 카나리.",
            "3": "모든 서버에 동시에 새로운 버전을 배포하지만 점진적인 트래픽 테스트를 허용하지 않는 블루/그린 배포와 올-앳-원스.",
            "4": "ECS 프레임워크 외부에 서비스를 배포하는 외부 배포로, 현재 설정에 덜 적합합니다."
        },
        "Correct Answer": "대부분의 트래픽을 안정적인 버전으로 유지하면서 새로운 버전으로 소량의 트래픽을 라우팅할 수 있는 블루/그린 배포와 카나리.",
        "Explanation": "블루/그린 배포와 카나리 전략은 회사에 이상적입니다. 이 전략은 업데이트된 서비스 버전으로 소량의 트래픽을 유도하면서 대부분의 사용자가 안정적인 버전을 계속 사용할 수 있게 합니다. 이 방법은 새로운 버전의 성능을 모니터링하고 전체 서비스 안정성을 위험에 빠뜨리지 않고 실제 사용자 피드백에 기반하여 정보에 입각한 결정을 내릴 수 있게 합니다.",
        "Other Options": [
            "롤링 업데이트는 점진적인 배포를 허용하지만, 전체 전환 전에 새로운 버전에서 소량의 트래픽을 테스트할 수 있는 능력을 제공하지 않으므로 그들의 전략에 필수적입니다.",
            "블루/그린 배포와 올-앳-원스는 새로운 버전을 모든 인스턴스에 동시에 배포하므로, 전체 롤아웃 전에 소량의 트래픽을 테스트하려는 그들의 욕구와 일치하지 않아 서비스 중단의 위험을 증가시킵니다.",
            "외부 배포는 ECS 환경 외부에 애플리케이션을 배포하는 것을 제안하므로, 서비스 배포 관리를 위해 ECS와 CodeDeploy를 현재 사용하고 있는 그들의 상황과 모순됩니다."
        ]
    },
    {
        "Question Number": "23",
        "Situation": "AWS 개발자가 Lambda 함수를 테스트하고 있으며, 피크 트래픽 중에 스로틀링 오류를 만났습니다.",
        "Question": "AWS Lambda 함수가 HTTP 상태 코드 429로 스로틀링 오류를 경험할 때 어떤 일이 발생하며, AWS는 재시도를 어떻게 처리합니까?",
        "Options": {
            "1": "동기 호출에 대한 요청 처리량 한도를 초과하며, 요청은 추가 처리 없이 즉시 재시도됩니다.",
            "2": "비동기 호출에 대한 요청 처리량 한도를 초과하며, 요청을 재시도하고 재시도가 소진된 후에는 데드 레터 큐(DLQ)로 전송됩니다.",
            "3": "요청이 비동기 호출에 대한 허용된 동시성을 초과하며, 자동으로 재시도되지만 로깅은 없습니다.",
            "4": "동기 호출에 대한 요청 처리량 한도를 초과하며, AWS는 사전 구성된 설정에 따라 요청을 재시도합니다."
        },
        "Correct Answer": "비동기 호출에 대한 요청 처리량 한도를 초과하며, 요청을 재시도하고 재시도가 소진된 후에는 데드 레터 큐(DLQ)로 전송됩니다.",
        "Explanation": "AWS Lambda 함수가 비동기 호출에 대한 요청 처리량 한도를 초과하여 스로틀링될 경우, AWS는 미리 정의된 횟수만큼 요청을 자동으로 재시도합니다. 재시도가 소진되면 실패한 이벤트는 추가 조사 또는 처리를 위해 데드 레터 큐(DLQ)로 전송될 수 있습니다.",
        "Other Options": [
            "이 옵션은 동기 호출을 설명하며, 스로틀링 시 자동으로 재시도되지 않으며 비동기 호출과 동일한 방식으로 처리되지 않습니다.",
            "이 옵션은 요청 처리 방식을 잘못 설명하고 있습니다. DLQ를 언급하지만 동기 호출과 관련이 있습니다.",
            "이 옵션은 동시성 한도에 잘못 초점을 맞추고 있으며, 비동기 호출의 스로틀링 동작을 정확하게 나타내지 않으며, 재시도 및 잠재적인 DLQ 처리를 포함합니다."
        ]
    },
    {
        "Question Number": "24",
        "Situation": "개발자가 DNS 호환 이름을 가진 S3 버킷으로 대량의 데이터를 전송해야 합니다. 다양한 지리적 위치에 분산된 사용자들의 전송 속도를 개선하기 위해, 개발자는 지연 시간을 줄이는 솔루션을 구현해야 합니다.",
        "Question": "개발자가 데이터 전송 속도를 향상시키기 위해 어떤 기능을 사용해야 합니까?",
        "Options": {
            "1": "S3 멀티 업로드를 사용하여 데이터를 더 작은 청크로 나눕니다.",
            "2": "버킷에 대해 S3 전송 가속을 활성화합니다.",
            "3": "CloudFront를 사용하여 데이터를 엣지 위치로 배포합니다.",
            "4": "더 빠른 업로드를 허용하기 위해 S3 버킷 정책을 구성합니다."
        },
        "Correct Answer": "버킷에 대해 S3 전송 가속을 활성화합니다.",
        "Explanation": "S3 전송 가속은 Amazon S3로 파일을 전송할 때 Amazon CloudFront 엣지 네트워크를 사용하여 전송 속도를 높이도록 특별히 설계되었습니다. 이는 지연 시간을 최소화하고 업로드 속도를 증가시켜, 다양한 지리적 위치에 있는 사용자들의 전송 속도를 개선하려는 개발자의 요구에 가장 적합한 선택입니다.",
        "Other Options": [
            "S3 멀티 업로드는 대용량 파일을 더 작은 부분으로 나누어 병렬 업로드를 돕지만, 본질적으로 지연 시간을 줄이지 않으므로 이 특정 시나리오에는 덜 효과적입니다.",
            "CloudFront를 사용하는 것은 데이터를 사용자에게 효율적으로 배포하는 데 유용하지만, S3로의 업로드 프로세스를 직접 가속화하지 않으므로 이 상황에서의 주요 요구를 충족하지 않습니다.",
            "S3 버킷 정책을 구성하는 것은 권한 및 접근 제어에 영향을 미치지만, 전송 속도에는 영향을 미치지 않으므로 개발자의 더 빠른 업로드 요구를 해결하지 않습니다."
        ]
    },
    {
        "Question Number": "25",
        "Situation": "개발자가 Amazon Simple Queue Service (SQS)를 활용하는 메시징 시스템의 성능 최적화 작업을 진행하고 있습니다. 처리 효율성을 향상시키고 API 호출 수를 줄이기 위해, 개발자는 단일 API 작업으로 SQS 큐에서 여러 메시지를 검색하는 방법을 찾고 있으며, 이를 통해 지연 시간을 최소화하고 처리량을 개선하고자 합니다. 이 목표를 달성하기 위해서는 올바른 API와 그 매개변수를 이해하는 것이 필수적입니다.",
        "Question": "개발자가 SQS 큐에서 단일 API 호출로 여러 메시지를 효율적으로 검색하기 위해 어떤 특정 API와 매개변수를 사용해야 합니까?",
        "Options": {
            "1": "send_message_batch with MaxNumberOfMessages",
            "2": "receive_message with MaxNumberOfMessages",
            "3": "list_queues with ReceiveMessage",
            "4": "change_message_visibility with VisibilityTimeout"
        },
        "Correct Answer": "receive_message with MaxNumberOfMessages",
        "Explanation": "'receive_message with MaxNumberOfMessages'가 정답입니다. `receive_message` API 호출은 SQS 큐에서 메시지를 검색하기 위해 특별히 설계되었습니다. 'MaxNumberOfMessages' 매개변수를 사용하면 개발자가 단일 호출에서 반환될 최대 메시지 수를 지정할 수 있어 처리 효율성을 개선하는 데 중요합니다.",
        "Other Options": [
            "'send_message_batch with MaxNumberOfMessages' 옵션은 잘못된 것입니다. 'send_message_batch'는 SQS에 여러 메시지를 보내는 데 사용되며, 검색하는 데 사용되지 않습니다.",
            "'list_queues with ReceiveMessage' 옵션은 잘못된 것입니다. 'list_queues'는 기존 큐를 나열하는 데 사용되며 특정 큐에서 메시지를 검색하는 데 사용되지 않습니다.",
            "'change_message_visibility with VisibilityTimeout' 옵션은 잘못된 것입니다. 이 API는 이미 처리 중인 메시지의 가시성 타임아웃을 변경하는 데 사용되며, 큐에서 메시지를 검색하는 데 사용되지 않습니다."
        ]
    },
    {
        "Question Number": "26",
        "Situation": "개발자가 AWS Lambda 함수를 배포하기 위해 열심히 준비하고 있으며, 효율적이고 원활한 배포 프로세스를 목표로 하고 있습니다. 이 함수는 Python으로 작성된 여러 서드파티 라이브러리에 의존하고 있어, 패키징 방법을 신중하게 선택해야 합니다. 개발자는 성능을 최적화하면서 모든 종속성을 효과적으로 관리하는 데 집중하고 있습니다. 필요한 라이브러리를 지원할 뿐만 아니라 배포 패키지의 전체 크기를 최소화하여 함수 호출 시 더 빠른 실행과 낮은 지연 시간을 보장하는 옵션을 선택하는 것이 중요합니다.",
        "Question": "개발자가 AWS Lambda 함수의 성능을 최적화하고 종속성을 효과적으로 관리하면서 배포 패키지의 크기를 최소화하기 위해 어떤 배포 패키징 옵션을 선택해야 합니까?",
        "Options": {
            "1": "함수 코드와 모든 필수 서드파티 종속성을 포함하는 압축 ZIP 파일을 AWS Lambda 서비스에 직접 업로드합니다.",
            "2": "Lambda 레이어를 활용하여 필요한 서드파티 라이브러리를 별도로 패키징하고 포함시키며, 최적의 종속성 관리를 위해 Lambda 함수의 구성 설정에서 이를 참조합니다.",
            "3": "함수 코드와 모든 종속성을 하나의 통합된 Docker 컨테이너 이미지로 패키징하여 AWS Lambda에 배포하여 원활한 실행을 합니다.",
            "4": "필요한 서드파티 라이브러리를 Amazon S3 버킷에 저장하고 Lambda 함수가 실행 시 런타임에 다운로드하도록 합니다."
        },
        "Correct Answer": "Lambda 레이어를 활용하여 필요한 서드파티 라이브러리를 별도로 패키징하고 포함시키며, 최적의 종속성 관리를 위해 Lambda 함수의 구성 설정에서 이를 참조합니다.",
        "Explanation": "Lambda 레이어를 사용하면 개발자가 함수 코드와 종속성을 분리할 수 있어 서드파티 라이브러리를 보다 효과적으로 관리할 수 있으며, 전체 배포 패키지 크기를 줄일 수 있습니다. 이 옵션은 여러 Lambda 함수 간의 라이브러리 재사용을 촉진하고, 종속성 업데이트를 함수 자체와 독립적으로 처리할 수 있도록 하여 성능을 최적화하고 배포 프로세스를 간소화합니다.",
        "Other Options": [
            "모든 종속성을 포함한 ZIP 파일을 업로드하면 패키지 크기가 커지고 버전 관리 문제를 초래할 수 있어 서드파티 라이브러리 관리에 비효율적입니다. 특히 여러 함수가 동일한 라이브러리를 사용하는 경우 더욱 그렇습니다.",
            "모든 것을 단일 Docker 컨테이너 이미지로 패키징하는 것은 번거로울 수 있으며, Lambda 함수의 경량 및 확장 가능한 특성을 활용하지 못할 수 있어 Lambda 레이어를 사용하는 것보다 콜드 스타트 시간이 길어질 수 있습니다.",
            "Amazon S3 버킷에 종속성을 저장하고 런타임에 다운로드하는 것은 실행 중 지연을 초래할 수 있으며, 함수가 라이브러리를 다운로드할 때까지 기다려야 하므로 성능과 응답성에 부정적인 영향을 미칠 수 있습니다."
        ]
    },
    {
        "Question Number": "27",
        "Situation": "개발자가 Elastic Beanstalk에 배포할 소스 번들을 준비하고 있습니다. 소스 코드와 종속성이 ZIP 파일로 패키징되어 배포 프로세스와의 호환성을 보장합니다.",
        "Question": "Elastic Beanstalk에서 성공적인 배포를 위해 소스 번들이 충족해야 하는 요구 사항은 무엇입니까?",
        "Options": {
            "1": "파일 크기가 1GB를 초과해서는 안 되며, 더 큰 파일은 제한으로 인해 배포 실패를 초래할 수 있습니다.",
            "2": "번들에는 여러 개의 ZIP 파일을 포함할 수 있어 구성 요소와 종속성의 보다 조직적인 구조를 허용합니다.",
            "3": "번들에는 상위 폴더나 최상위 디렉토리를 포함해서는 안 되며, 이는 Elastic Beanstalk가 애플리케이션에 직접 접근할 수 있도록 보장합니다.",
            "4": "번들에는 애플리케이션의 예약 작업을 정의하기 위한 cron.yaml 파일이 포함되어야 하며, 이는 모든 배포에 대한 요구 사항은 아닙니다."
        },
        "Correct Answer": "번들에는 상위 폴더나 최상위 디렉토리를 포함해서는 안 되며, 이는 Elastic Beanstalk가 애플리케이션에 직접 접근할 수 있도록 보장합니다.",
        "Explanation": "정확한 요구 사항은 소스 번들에 상위 폴더나 최상위 디렉토리를 포함해서는 안 된다는 것입니다. 이는 Elastic Beanstalk가 ZIP 파일을 풀 때 애플리케이션 파일에 직접 접근할 수 있도록 하여 배포 프로세스를 원활하게 합니다.",
        "Other Options": [
            "파일 크기가 1GB를 초과해서는 안 된다는 것은 잘못된 것입니다. 실제로 Elastic Beanstalk의 소스 번들에 대한 크기 제한은 512MB이며, 1GB가 아닙니다.",
            "번들에는 여러 개의 ZIP 파일을 포함할 수 있다는 것은 잘못된 것입니다. Elastic Beanstalk는 필요한 모든 파일을 포함하는 단일 ZIP 파일을 기대하며, 번들 내에 여러 개의 ZIP 파일을 포함하는 것을 허용하지 않습니다.",
            "번들에는 cron.yaml 파일이 포함되어야 한다는 것은 잘못된 것입니다. 이 파일은 Elastic Beanstalk에 배포된 모든 애플리케이션에 필수적이지 않으며, 애플리케이션이 예약 작업이 필요한 경우에만 필요합니다."
        ]
    },
    {
        "Question Number": "28",
        "Situation": "개발자가 AWS Lambda 함수를 모니터링하고 동기 호출 중에 HTTP 상태 코드 429 오류가 자주 발생하는 패턴을 발견했습니다. 이는 요청이 제한되고 있음을 나타냅니다.",
        "Question": "이 429 오류의 가장 가능성이 높은 원인은 무엇이며, 개발자가 이를 효과적으로 해결할 수 있는 방법은 무엇입니까?",
        "Options": {
            "1": "Lambda 함수가 동시 실행 제한을 초과했습니다. 이를 해결하기 위해 개발자는 함수의 예약된 동시 실행 설정을 늘려 더 많은 동시 실행을 허용해야 합니다.",
            "2": "Lambda 함수의 타임아웃 값이 너무 낮습니다. 개발자는 함수 구성에서 타임아웃 값을 늘려 함수의 조기 종료를 방지해야 합니다.",
            "3": "Lambda 함수에 할당된 IAM 역할이 충분한 권한을 가지고 있지 않습니다. 개발자는 필요한 권한을 부여하기 위해 IAM 정책을 업데이트해야 합니다.",
            "4": "Lambda 함수가 VPC에 접근할 수 없습니다. 개발자는 VPC에 대한 적절한 접근을 보장하기 위해 AWSLambdaVPCAccessExecutionRole 정책을 할당해야 합니다."
        },
        "Correct Answer": "Lambda 함수가 동시 실행 제한을 초과했습니다. 이를 해결하기 위해 개발자는 함수의 예약된 동시 실행 설정을 늘려 더 많은 동시 실행을 허용해야 합니다.",
        "Explanation": "HTTP 상태 코드 429는 클라이언스가 제한되고 있음을 나타내며, 이는 일반적으로 Lambda 함수에 설정된 동시 실행 제한을 초과했기 때문입니다. 예약된 동시 실행 설정을 늘리면 더 많은 동시 실행이 가능해져 이 오류가 발생할 가능성을 줄일 수 있습니다.",
        "Other Options": [
            "이 옵션은 잘못된 것입니다. 타임아웃 값이 낮으면 타임아웃 오류(HTTP 504)가 발생할 것이며, 이는 제한 오류(HTTP 429)가 아닙니다. 타임아웃을 늘리는 것은 동시 실행 문제의 근본 원인을 해결하지 않습니다.",
            "이 옵션은 잘못된 것입니다. IAM 권한이 부족하면 일반적으로 권한 오류가 발생하며, 제한 오류가 발생하지 않습니다. 429 오류는 권한이 아니라 동시 실행 설정에 의해 함수가 제한되고 있음을 나타냅니다.",
            "이 옵션은 잘못된 것입니다. 함수가 VPC에 접근할 수 없다면 429 오류가 발생하지 않습니다. 대신 연결 오류나 타임아웃이 발생할 수 있습니다. 429 오류는 실행 한계를 초과하는 것과 관련이 있습니다."
        ]
    },
    {
        "Question Number": "29",
        "Situation": "Dev 계정에서 작업하는 개발자가 Prod 계정에 위치한 S3 버킷에 접근해야 합니다. 보안을 유지하면서 이 접근을 용이하게 하기 위해 Prod 계정에 Dev 계정을 신뢰할 수 있는 엔티티로 지정하는 IAM 역할이 이미 생성되었습니다. 이 설정은 교차 계정 접근을 허용하지만, 개발자는 역할을 맡고 필요한 권한을 얻기 위해 특정 단계를 수행해야 합니다.",
        "Question": "Dev 계정의 개발자가 Prod 계정에 설정된 IAM 역할을 성공적으로 맡기 위해 수행해야 하는 작업은 무엇입니까? 이를 통해 S3 버킷과 상호작용하는 데 필요한 접근을 얻을 수 있습니다.",
        "Options": {
            "1": "S3 권한이 있는 IAM 사용자를 Dev에 생성합니다.",
            "2": "aws sts assume-role 명령을 사용하여 Prod의 역할을 맡습니다.",
            "3": "Prod의 역할에 S3 버킷에 대한 전체 접근을 부여하는 정책을 첨부합니다.",
            "4": "aws s3 sync 명령을 사용하여 버킷에 직접 접근합니다."
        },
        "Correct Answer": "aws sts assume-role 명령을 사용하여 Prod의 역할을 맡습니다.",
        "Explanation": "다른 AWS 계정의 역할을 맡으려면 개발자는 `aws sts assume-role` 명령을 사용해야 합니다. 이 명령은 개발자가 인증하고 Prod 계정의 역할에 대한 임시 보안 자격 증명을 얻을 수 있게 해주며, 이는 S3 버킷과 같은 리소스에 접근하는 데 필요합니다.",
        "Other Options": [
            "S3 권한이 있는 IAM 사용자를 Dev에 생성하는 것은 Prod의 S3 버킷에 대한 교차 계정 접근을 용이하게 하지 않습니다. 사용자는 역할을 맡지 않고는 다른 계정의 리소스에 접근할 수 있는 권한이 없습니다.",
            "Prod의 역할에 S3 버킷에 대한 전체 접근을 부여하는 정책을 첨부하는 것만으로는 충분하지 않습니다. 개발자는 먼저 적절한 명령을 사용하여 역할을 맡아야 해당 정책에 의해 부여된 권한을 얻을 수 있습니다.",
            "aws s3 sync 명령을 사용하여 버킷에 직접 접근하는 것은 잘못된 것입니다. 이 명령은 로컬과 S3 저장소 간의 파일을 동기화하는 데 사용되지만, 개발자는 먼저 Prod에서 역할을 맡아야 접근을 인증할 수 있습니다."
        ]
    },
    {
        "Question Number": "30",
        "Situation": "한 회사가 사용자 세션 상태를 저장하기 위해 DynamoDB 또는 ElastiCache를 사용할지 결정하고 있습니다. 애플리케이션은 세션 데이터를 검색하고 업데이트하는 데 초저지연이 필요합니다.",
        "Question": "회사는 어떤 옵션을 선택해야 합니까?",
        "Options": {
            "1": "DynamoDB, 세션 상태를 높은 내구성으로 저장할 수 있기 때문에",
            "2": "DynamoDB, ElastiCache보다 높은 지연 시간을 제공하기 때문에",
            "3": "ElastiCache, DynamoDB보다 낮은 지연 시간을 제공하기 때문에",
            "4": "ElastiCache, 세션 데이터에 대한 복합 기본 키를 지원하기 때문에"
        },
        "Correct Answer": "ElastiCache, DynamoDB보다 낮은 지연 시간을 제공하기 때문에",
        "Explanation": "ElastiCache는 인메모리 데이터 저장소로, DynamoDB에 비해 데이터 검색 및 업데이트 속도가 훨씬 빠릅니다. 따라서 세션 데이터에 대해 초저지연이 필요한 애플리케이션에 더 적합한 선택입니다.",
        "Other Options": [
            "DynamoDB는 높은 내구성을 제공하지만, 이는 이 상황에서의 주요 요구 사항이 아니며, 초저지연에 초점을 맞추고 있습니다.",
            "이 옵션은 잘못된 것입니다. DynamoDB는 실제로 ElastiCache보다 높은 지연 시간을 가지고 있어 애플리케이션의 요구에 적합하지 않습니다.",
            "ElastiCache는 일부 고급 기능을 지원하지만, 복합 기본 키에 대한 언급은 이 경우 낮은 지연 시간 요구 사항과는 관련이 없습니다."
        ]
    },
    {
        "Question Number": "31",
        "Situation": "당신은 AWS에서 호스팅되는 웹 애플리케이션을 개발하고 있으며, DDoS 공격을 포함한 잠재적 위협에 대한 보안을 보장하고자 합니다.",
        "Question": "어떤 AWS 서비스가 애플리케이션에 대한 능동적인 DDoS 공격 탐지 및 자동 완화를 제공합니까?",
        "Options": {
            "1": "AWS Shield",
            "2": "AWS GuardDuty",
            "3": "AWS WAF",
            "4": "AWS Config"
        },
        "Correct Answer": "AWS Shield",
        "Explanation": "AWS Shield는 AWS에서 실행되는 애플리케이션을 보호하는 관리형 DDoS 보호 서비스입니다. DDoS 공격에 대한 자동 탐지 및 완화를 제공하여 웹 애플리케이션의 보안을 강화합니다.",
        "Other Options": [
            "AWS GuardDuty는 악의적인 활동과 무단 행동을 지속적으로 모니터링하는 위협 탐지 서비스이지만, DDoS 완화를 특별히 제공하지는 않습니다.",
            "AWS WAF (웹 애플리케이션 방화벽)는 HTTP 트래픽을 필터링하고 모니터링하여 웹 애플리케이션을 보호하도록 설계되었지만, DDoS 보호에 특별히 초점을 맞추고 있지는 않습니다.",
            "AWS Config는 사용자가 AWS 리소스의 구성을 평가, 감사 및 평가할 수 있도록 하는 서비스이지만, DDoS 보호 또는 완화 기능을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "32",
        "Situation": "한 회사가 고객 주문을 저장하기 위해 Amazon DynamoDB를 사용하는 글로벌 전자상거래 플랫폼을 구축하고 있습니다. 이 플랫폼은 주문 데이터에 대한 빠른 접근을 보장해야 하지만, 고객이 최근에 주문한 최신 주문을 검색할 때 강력한 일관성도 제공해야 합니다.",
        "Question": "회사가 이 요구 사항을 충족하기 위해 어떤 일관성 모델을 사용해야 합니까?",
        "Options": {
            "1": "최소 대기 시간과 더 빠른 주문 데이터 접근을 보장하기 위해 결국 일관된 읽기를 사용합니다.",
            "2": "최신 주문 데이터가 항상 검색되도록 보장하기 위해 강력하게 일관된 읽기를 사용합니다.",
            "3": "대기 시간을 줄이고 읽기 성능을 향상시키기 위해 로컬 캐시와 함께 일관된 읽기를 사용합니다.",
            "4": "전자상거래 애플리케이션에 대한 일관성과 성능을 모두 제공하기 위해 트랜잭션 읽기를 사용합니다."
        },
        "Correct Answer": "최신 주문 데이터가 항상 검색되도록 보장하기 위해 강력하게 일관된 읽기를 사용합니다.",
        "Explanation": "강력하게 일관된 읽기는 읽기 작업이 수행될 때 해당 데이터에 대한 가장 최근의 쓰기가 반환되도록 보장합니다. 이는 최신 주문 데이터를 검색하는 것이 정확한 주문 처리와 고객 경험에 중요하기 때문에 전자상거래 플랫폼에 필수적입니다.",
        "Other Options": [
            "결국 일관된 읽기는 오래된 데이터가 반환될 수 있으며, 이는 최신 주문 데이터를 실시간으로 검색해야 하는 요구 사항에 적합하지 않습니다.",
            "로컬 캐시와 함께 일관된 읽기는 성능을 향상시킬 수 있지만, 가장 최근의 데이터가 검색될 것이라는 보장을 제공하지 않으며, 이는 주문 관리에 필수적입니다.",
            "트랜잭션 읽기는 강력한 일관성을 제공하지만, 일반적으로 여러 항목을 포함하는 복잡한 작업을 위해 설계되어 있어 단순한 주문 검색 시나리오에는 덜 적합합니다."
        ]
    },
    {
        "Question Number": "33",
        "Situation": "한 소프트웨어 개발자가 여러 외부 API와 인터페이스하는 복잡한 애플리케이션에 대한 통합 테스트를 작성하는 과정에 있습니다. 이러한 테스트가 일관되게 실행될 수 있도록 하고 실제 외부 서비스의 실시간 가용성이나 성능에 의존하지 않도록 하기 위해 개발자는 모의 엔드포인트를 구현하기로 결정했습니다. 이 접근 방식은 실제 API 상호작용의 예측 불가능성 없이 다양한 시나리오를 테스트할 수 있게 해줍니다.",
        "Question": "이 맥락에서 통합 테스트를 위한 효과적인 모의 엔드포인트를 생성하기 위해 개발자가 활용할 수 있는 AWS 서비스의 특정 기능은 무엇입니까?",
        "Options": {
            "1": "Amazon API Gateway의 모의 통합 기능을 활용하여 실시간 백엔드 서비스 없이 API 응답을 시뮬레이션합니다.",
            "2": "예상되는 API 호출의 동작을 모방하여 미리 정의된 응답을 반환하도록 구성된 AWS Lambda 함수를 구현합니다.",
            "3": "실제 구독자가 없이 메시지 전달을 허용하는 모의 엔드포인트로 작동하도록 구성된 Amazon SNS 주제를 설정합니다.",
            "4": "실제 API 호출 없이 작업 실행을 시뮬레이션하는 모의 작업 상태를 포함하는 워크플로를 정의하기 위해 AWS Step Functions를 사용합니다."
        },
        "Correct Answer": "Amazon API Gateway의 모의 통합 기능을 활용하여 실시간 백엔드 서비스 없이 API 응답을 시뮬레이션합니다.",
        "Explanation": "정답은 Amazon API Gateway의 모의 통합 기능을 활용하는 것입니다. 이 기능은 개발자가 정적 응답을 반환하는 엔드포인트를 생성할 수 있게 해줍니다. 이는 통합 테스트에 특히 유용하며, 개발자가 실제 외부 서비스에 의존하지 않고 예상 응답을 정의할 수 있게 하여 테스트를 더 빠르고 신뢰할 수 있게 만듭니다.",
        "Other Options": [
            "미리 정의된 응답을 가진 AWS Lambda 함수를 구현하는 것은 일부 API 동작을 시뮬레이션할 수 있지만, API Gateway의 모의 통합 기능만큼의 엔드포인트 관리 및 요청/응답 시뮬레이션 수준을 제공하지 않습니다.",
            "Amazon SNS 주제를 모의 엔드포인트로 설정하는 것은 이 경우 통합 테스트에 적합하지 않으며, SNS는 주로 메시지 알림을 위한 것이며 API 엔드포인트처럼 직접적인 요청/응답 상호작용을 촉진하지 않습니다.",
            "모의 작업 상태를 가진 AWS Step Functions를 사용하는 것은 워크플로를 시뮬레이션하는 데 도움이 될 수 있지만, 외부 서비스와의 상호작용을 테스트하기 위한 모의 API 엔드포인트를 특별히 생성하지는 않으며, 이는 이 시나리오에서의 주요 요구 사항입니다."
        ]
    },
    {
        "Question Number": "34",
        "Situation": "한 회사가 AWS CodePipeline을 사용하여 지속적 통합 및 지속적 배포(CI/CD) 파이프라인을 구현하는 과정에 있습니다. 이 파이프라인은 소프트웨어 개발 생명 주기의 다양한 단계를 자동화하여 애플리케이션을 효율적으로 빌드, 테스트 및 배포하도록 설계되었습니다. 팀은 특히 리포지토리의 'feature' 브랜치에 푸시된 변경 사항이 파이프라인 내에서 특정 작업 세트를 트리거하도록 보장하는 데 집중하고 있으며, 'main' 브랜치에 대한 수정은 프로덕션 준비 배포에 맞춘 다른 작업 시퀀스를 시작합니다.",
        "Question": "팀이 각 브랜치에 대해 실행해야 하는 다양한 작업을 효과적으로 관리하기 위해 AWS CodePipeline 내 CI/CD 워크플로우의 어떤 특정 구성 요소를 설정해야 합니까?",
        "Options": {
            "1": "CI/CD 프로세스 동안 수행되는 작업의 순서를 정의하는 CodePipeline 내의 단계입니다.",
            "2": "애플리케이션의 소스 코드를 저장하고 다양한 브랜치 간의 버전 관리를 용이하게 하는 CodeCommit 리포지토리입니다.",
            "3": "소스 코드를 컴파일하고 코드 품질을 보장하기 위해 테스트를 실행하는 CodeBuild 프로젝트입니다.",
            "4": "특정 기준에 따라 다양한 환경에 애플리케이션을 배포하는 CodeDeploy 배포 그룹입니다."
        },
        "Correct Answer": "CI/CD 프로세스 동안 수행되는 작업의 순서를 정의하는 CodePipeline 내의 단계입니다.",
        "Explanation": "정답은 CodePipeline 내의 단계입니다. 이 단계는 팀이 리포지토리의 각 브랜치에 대해 다양한 작업을 구성할 수 있게 해줍니다. 'feature' 브랜치와 'main' 브랜치에 대해 별도의 단계를 설정함으로써, 팀은 CI/CD 프로세스의 흐름을 제어하고 변경 사항이 푸시된 브랜치에 따라 적절한 작업이 실행되도록 보장할 수 있습니다.",
        "Other Options": [
            "CodeCommit 리포지토리는 버전 관리 및 코드 변경 관리를 위해 중요하지만, CI/CD 파이프라인 내에서 브랜치 변경에 따라 수행되는 작업을 직접적으로 제어하지는 않습니다.",
            "CodeBuild 프로젝트는 애플리케이션 코드를 빌드하고 테스트하는 데 중점을 두지만, 파이프라인 내에서 브랜치 컨텍스트에 따라 다양한 작업을 관리하지는 않습니다.",
            "CodeDeploy 배포 그룹은 특정 환경에 애플리케이션을 배포하는 데 사용되지만, 서로 다른 브랜치에 의해 트리거되는 작업의 구성을 처리하지는 않습니다."
        ]
    },
    {
        "Question Number": "35",
        "Situation": "한 회사가 API 키와 데이터베이스 자격 증명을 안전하게 저장해야 하는 애플리케이션을 개발하고 있습니다. 개발 팀은 이러한 비밀을 애플리케이션 코드에 하드코딩하는 것을 피하고 안전하게 관리하며 쉽게 회전할 수 있도록 하기를 원합니다.",
        "Question": "개발자가 이러한 민감한 자격 증명을 관리하고 보호하기 위해 어떤 AWS 서비스를 사용해야 합니까?",
        "Options": {
            "1": "AWS Certificate Manager",
            "2": "서버 측 암호화가 적용된 Amazon S3",
            "3": "AWS Secrets Manager",
            "4": "AWS Identity and Access Management (IAM)"
        },
        "Correct Answer": "AWS Secrets Manager",
        "Explanation": "AWS Secrets Manager는 API 키 및 데이터베이스 자격 증명과 같은 민감한 정보를 안전하게 저장, 관리 및 검색하도록 특별히 설계되었습니다. 자격 증명의 손쉬운 회전, 접근 제어 및 감사 로그 기능을 제공하여 이 시나리오에 가장 적합한 선택입니다.",
        "Other Options": [
            "AWS Certificate Manager는 SSL/TLS 인증서를 관리하는 데 사용되며, API 키와 같은 민감한 자격 증명을 저장하는 데 사용되지 않습니다.",
            "서버 측 암호화가 적용된 Amazon S3는 파일을 안전하게 저장할 수 있지만, 민감한 자격 증명을 관리하거나 쉽게 회전할 수 있도록 설계되지 않았습니다.",
            "AWS Identity and Access Management (IAM)는 사용자 접근 및 권한 관리를 위해 사용되며, 민감한 정보를 안전하게 저장하는 데 사용되지 않습니다."
        ]
    },
    {
        "Question Number": "36",
        "Situation": "개발 팀은 ECS 작업이 애플리케이션 코드에 자격 증명을 포함하지 않고 Amazon S3 버킷에 안전하게 접근할 수 있도록 해야 합니다.",
        "Question": "팀이 이를 달성하기 위해 무엇을 해야 합니까?",
        "Options": {
            "1": "S3 버킷에 대한 접근을 허용하는 IAM 정책을 ECS 작업 정의에 연결합니다.",
            "2": "ECS 서비스에 S3 권한이 있는 IAM 역할을 할당합니다.",
            "3": "필요한 S3 권한이 있는 IAM 역할을 생성하고 이를 ECS 작업 정의에 할당합니다.",
            "4": "S3 버킷 권한을 구성하여 무제한 접근을 허용합니다."
        },
        "Correct Answer": "필요한 S3 권한이 있는 IAM 역할을 생성하고 이를 ECS 작업 정의에 할당합니다.",
        "Explanation": "필요한 S3 권한이 있는 IAM 역할을 생성하고 이를 ECS 작업 정의에 할당하면 작업이 자격 증명을 하드코딩하지 않고도 S3 버킷에 안전하게 접근할 수 있습니다. 이 방법은 AWS에서 관리하는 임시 자격 증명을 사용하여 보안 모범 사례를 따릅니다.",
        "Other Options": [
            "ECS 작업 정의에 IAM 정책을 직접 연결하는 것은 자격 증명의 동적 할당을 허용하지 않으며, IAM 역할을 사용하는 것만큼 최소 권한 원칙을 효과적으로 따르지 않을 수 있습니다.",
            "S3 권한이 있는 IAM 역할을 ECS 서비스에 할당하는 것은 개별 작업에 S3 버킷에 대한 접근을 직접적으로 부여하지 않으며, 이는 안전한 작업을 위해 필요합니다.",
            "S3 버킷 권한을 구성하여 무제한 접근을 허용하는 것은 심각한 보안 위험을 초래하며, 이는 버킷을 모든 엔티티의 무단 접근에 노출시킵니다."
        ]
    },
    {
        "Question Number": "37",
        "Situation": "개발자가 세션 동안 임시 사용자 데이터를 처리하는 웹 애플리케이션을 설계하고 있습니다. 애플리케이션은 세션이 종료된 후 이 데이터를 유지할 필요가 없으며, 개발자는 데이터 저장 솔루션의 효율성과 효과성을 고려하고 있습니다.",
        "Question": "이 맥락에서 일시적 데이터 저장 패턴과 지속적 데이터 저장 패턴의 주요 차이점은 무엇인가요?",
        "Options": {
            "1": "일시적 저장은 데이터를 임시로 보관하도록 설계되어 있으며, 세션이 종료된 후 데이터를 지웁니다. 반면, 지속적 저장은 세션 기간을 넘어 데이터를 유지하도록 설계되어 있습니다.",
            "2": "일시적 저장은 접근 속도가 더 빠를 수 있지만, 시간이 지남에 따라 데이터를 유지하는 지속적 저장 솔루션과 일반적으로 관련된 보안 조치가 부족할 수 있습니다.",
            "3": "일시적 저장은 빠른 데이터 접근을 위해 인메모리 데이터베이스를 포함하고, 지속적 저장은 장기 데이터 보존을 위해 디스크 기반 데이터베이스에 의존합니다.",
            "4": "일시적 저장은 향후 세션을 위해 데이터를 영구적으로 보존하며, 지속적 저장은 더 이상 사용되지 않을 때 자동으로 데이터를 삭제합니다."
        },
        "Correct Answer": "일시적 저장은 데이터를 임시로 보관하도록 설계되어 있으며, 세션이 종료된 후 데이터를 지웁니다. 반면, 지속적 저장은 세션 기간을 넘어 데이터를 유지하도록 설계되어 있습니다.",
        "Explanation": "일시적 저장과 지속적 저장의 주요 차이는 데이터의 의도된 수명에 있습니다. 일시적 저장은 세션이 종료되면 지워지는 임시 데이터를 위해 사용되며, 데이터 보존이 필요 없는 애플리케이션에 적합합니다. 반면, 지속적 저장은 세션을 넘어 보존해야 하는 데이터를 위해 설계되어 장기적인 접근 및 검색을 가능하게 합니다.",
        "Other Options": [
            "이 옵션은 일시적 저장이 데이터를 영구적으로 보존한다고 잘못 설명하고 있으며, 이는 임시 저장의 정의와 모순됩니다. 반면, 지속적 저장은 사용 후 데이터를 삭제하지 않습니다.",
            "이 옵션은 속도와 보안에 대해 언급하지만, 각 저장 패턴에서 데이터의 수명과 관련된 근본적인 차이를 정확하게 설명하지 않으며, 이는 질문의 본질입니다.",
            "이 옵션은 일시적 저장을 인메모리 데이터베이스에만 의존한다고 부정확하게 설명하고 있으며, 이는 일반적이지만 정의적인 특성이 아니며, 데이터 보존의 더 넓은 맥락을 간과하고 있습니다."
        ]
    },
    {
        "Question Number": "38",
        "Situation": "개발자가 Amazon S3 버킷에서 데이터를 처리하는 AWS Lambda 함수를 구현하고 있습니다. 이 함수는 메모리 부족 문제 없이 대용량 파일을 효율적으로 처리해야 합니다. 개발자는 메모리 사용량을 최소화하기 위해 S3에서 직접 데이터를 스트리밍하고자 합니다.",
        "Question": "개발자가 Lambda 함수에서 대용량 파일을 효율적으로 처리하기 위해 어떤 프로그래밍 기법을 사용해야 하나요?",
        "Options": {
            "1": "처리하기 전에 전체 파일을 메모리에 읽어들이는 것으로, 이는 메모리 오버플로우 문제를 일으킬 수 있습니다.",
            "2": "비동기 I/O를 사용하여 파일 읽기를 관리하고, 데이터 대기 중 다른 작업이 진행될 수 있도록 합니다.",
            "3": "S3 Object Lambda를 활용하여 데이터 검색 중에 수정하지만, 이는 대용량 파일 처리에 맞춰져 있지 않습니다.",
            "4": "입력 스트림이나 반복자를 사용하여 스트리밍을 구현하여 과도한 메모리 사용 없이 대용량 파일을 효율적으로 처리할 수 있도록 합니다."
        },
        "Correct Answer": "입력 스트림이나 반복자를 사용하여 스트리밍을 구현하여 과도한 메모리 사용 없이 대용량 파일을 효율적으로 처리할 수 있도록 합니다.",
        "Explanation": "입력 스트림이나 반복자를 사용하여 스트리밍을 구현하는 것은 AWS Lambda에서 대용량 파일을 처리하는 가장 효율적인 방법입니다. 이 방법은 전체 파일을 메모리에 로드하는 대신 데이터를 청크 단위로 처리할 수 있게 하여 메모리 사용량을 크게 줄이고 오버플로우 문제를 방지합니다. 따라서 대용량 파일 처리에 이상적입니다.",
        "Other Options": [
            "처리하기 전에 전체 파일을 메모리에 읽어들이는 것은 대용량 파일에 대해 매우 비효율적이며 메모리 오버플로우 위험을 증가시켜 이 시나리오에 적합하지 않습니다.",
            "비동기 I/O를 사용하면 다른 작업이 동시에 실행될 수 있어 성능을 개선할 수 있지만, 대용량 파일 처리와 관련된 메모리 관리 문제를 구체적으로 해결하지는 않습니다.",
            "S3 Object Lambda를 활용하면 검색 중에 일부 데이터 수정 기능을 제공할 수 있지만, 본질적으로 메모리 사용을 최적화하거나 대용량 파일을 효과적으로 처리하지는 않습니다."
        ]
    },
    {
        "Question Number": "39",
        "Situation": "한 회사가 사용자가 기존의 기업 자격 증명을 사용하여 로그인해야 하는 웹 애플리케이션을 개발하고 있습니다. 개발 팀은 사용자가 별도의 AWS IAM 사용자를 생성하지 않고 회사의 아이덴티티 공급자를 통해 인증할 수 있도록 하기를 원합니다.",
        "Question": "이 목표를 달성하기 위해 팀이 구현해야 할 솔루션은 무엇인가요?",
        "Options": {
            "1": "각 직원에 대해 IAM 사용자를 생성하고 적절한 권한을 부여합니다.",
            "2": "사용자 인증을 관리하기 위해 Amazon Cognito User Pools를 사용합니다.",
            "3": "Security Assertion Markup Language (SAML)를 사용하여 아이덴티티 연합을 구현합니다.",
            "4": "AWS Single Sign-On (AWS SSO)을 활용하여 접근을 관리합니다."
        },
        "Correct Answer": "Security Assertion Markup Language (SAML)를 사용하여 아이덴티티 연합을 구현합니다.",
        "Explanation": "SAML을 사용하여 아이덴티티 연합을 구현하면 애플리케이션이 기존의 기업 아이덴티티 공급자를 통해 사용자를 인증할 수 있게 되어 별도의 AWS IAM 사용자 없이도 원활한 접근이 가능합니다. 이 접근 방식은 애플리케이션과 아이덴티티 공급자 간의 인증 요청 및 응답을 전달하기 위해 SAML을 활용하여, 설명된 시나리오에 대한 효율적인 솔루션이 됩니다.",
        "Other Options": [
            "각 직원에 대해 IAM 사용자를 생성하는 것은 개별 사용자 관리를 요구하므로 실현 가능하지 않으며, 기존 기업 자격 증명을 활용하지 않습니다.",
            "Amazon Cognito User Pools를 사용하는 것은 사용자 가입 및 인증 관리를 위해 더 적합하지만, 추가 구성 없이 기업 아이덴티티 공급자와의 연합을 직접 지원하지 않습니다.",
            "AWS Single Sign-On (AWS SSO)을 활용하는 것은 유효한 접근 방식이지만, 선택된 정답인 SAML 연합 구현과는 직접적으로 일치하지 않습니다."
        ]
    },
    {
        "Question Number": "40",
        "Situation": "개발자는 Python으로 정교하게 작성된 AWS Lambda 함수를 패키징하는 과정에 있습니다. 이 함수는 핵심 기능을 위해 여러 서드파티 라이브러리에 의존할 뿐만 아니라, 여러 Lambda 함수에서 중요한 공유 유틸리티 코드를 활용합니다. 배포 프로세스를 간소화하고 코드 재사용성을 높이기 위해 개발자는 공유 코드를 더 잘 조직하고 관리할 수 있도록 Lambda 레이어를 활용하기로 결정했습니다. 이러한 맥락에서 개발자는 이제 Lambda 레이어를 사용하여 공유 유틸리티 코드를 효과적으로 포함하는 최선의 접근 방식을 고려하고 있습니다.",
        "Question": "개발자가 Lambda 레이어를 사용하여 공유 유틸리티 코드를 포함하기 위해 취해야 할 가장 효과적인 접근 방식은 무엇인가요? 유지 관리 용이성과 모범 사례 준수를 보장해야 합니다.",
        "Options": {
            "1": "각 Lambda 함수의 배포 패키지에 공유 유틸리티 코드를 직접 번들로 묶습니다.",
            "2": "공유 유틸리티 코드를 포함하는 별도의 Lambda 레이어를 생성하고 이 레이어를 각 Lambda 함수의 구성에서 참조합니다.",
            "3": "공유 유틸리티 코드를 Amazon S3 버킷에 저장하고 Lambda 함수 내에서 런타임에 다운로드합니다.",
            "4": "AWS Systems Manager Parameter Store를 사용하여 공유 유틸리티 코드를 저장하고 함수 실행 중에 이를 검색합니다."
        },
        "Correct Answer": "공유 유틸리티 코드를 포함하는 별도의 Lambda 레이어를 생성하고 이 레이어를 각 Lambda 함수의 구성에서 참조합니다.",
        "Explanation": "가장 효과적인 접근 방식은 공유 유틸리티 코드를 포함하는 별도의 Lambda 레이어를 생성하고 이 레이어를 각 Lambda 함수의 구성에서 참조하는 것입니다. 이 방법은 코드 재사용을 촉진하고 업데이트를 간소화하며(레이어에 대한 변경 사항이 이를 사용하는 모든 함수에 자동으로 반영됨), Lambda 함수 배포 패키지를 경량으로 유지합니다. 이는 여러 Lambda 함수에서 공유 코드를 관리하기 위한 AWS 모범 사례와 일치합니다.",
        "Other Options": [
            "각 Lambda 함수의 배포 패키지에 공유 유틸리티 코드를 직접 번들로 묶는 것은 비효율적이며 코드 중복을 초래하고 유지 관리를 어렵게 만듭니다. 유틸리티 코드에 대한 변경 사항은 모든 개별 함수에 업데이트를 요구하므로 불일치의 위험이 증가합니다.",
            "공유 유틸리티 코드를 Amazon S3 버킷에 저장하고 Lambda 함수 내에서 런타임에 다운로드하는 것은 불필요한 복잡성과 지연을 추가합니다. 이 접근 방식은 코드를 다운로드하기 위한 추가 처리가 필요하며, 이는 실행 속도를 저하시킬 수 있고 함수의 배포를 복잡하게 만듭니다.",
            "AWS Systems Manager Parameter Store를 사용하여 공유 유틸리티 코드를 저장하는 것은 적합하지 않습니다. Parameter Store는 코드 저장이 아닌 구성 데이터, 비밀 및 매개변수를 위한 것이기 때문입니다. 이 방법은 코드 재사용을 효과적으로 촉진하지 않으며 Lambda 함수의 논리를 복잡하게 만들 것입니다."
        ]
    },
    {
        "Question Number": "41",
        "Situation": "개발자는 사용자 요청에 간헐적으로 응답하지 않는 배포된 웹 애플리케이션을 문제 해결하고 있습니다. 근본 원인을 파악하기 위해 개발자는 실패와 관련된 이상 징후 및 패턴을 감지하기 위해 포괄적인 로깅 및 모니터링 데이터를 검토해야 합니다.",
        "Question": "개발자가 애플리케이션의 로깅 및 모니터링을 위해 주로 사용해야 할 AWS 서비스는 무엇인가요?",
        "Options": {
            "1": "Amazon CloudWatch Logs 및 Amazon CloudWatch Metrics",
            "2": "AWS X-Ray 및 AWS CloudTrail",
            "3": "AWS Config 및 Amazon GuardDuty",
            "4": "Amazon S3 및 Amazon Athena"
        },
        "Correct Answer": "Amazon CloudWatch Logs 및 Amazon CloudWatch Metrics",
        "Explanation": "Amazon CloudWatch는 AWS 리소스 및 애플리케이션의 로깅 및 모니터링을 위해 특별히 설계되었습니다. CloudWatch Logs는 개발자가 로그 데이터를 수집하고 분석할 수 있게 해주며, CloudWatch Metrics는 성능 및 운영 건강에 대한 통찰력을 제공하여 애플리케이션 문제 해결에 가장 적합한 선택입니다.",
        "Other Options": [
            "AWS X-Ray는 요청을 추적하고 서비스 성능을 분석하는 데 유용하지만, CloudWatch Logs와 같은 포괄적인 로깅 기능을 제공하지 않습니다.",
            "AWS Config는 AWS 리소스의 구성을 모니터링하고 GuardDuty는 보안 위협에 중점을 두므로, 둘 다 애플리케이션 로깅 및 모니터링에 전념하지 않습니다.",
            "Amazon S3는 저장 서비스이며, Amazon Athena는 S3의 데이터를 쿼리하는 데 사용됩니다. 이들은 애플리케이션을 위한 전문적인 로깅 및 모니터링 기능을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "42",
        "Situation": "개발자는 사용자 세션 동안 임시 데이터 저장이 필요한 애플리케이션을 구축하고 있습니다. 애플리케이션은 리소스 사용을 최적화하고 개인 정보를 유지하기 위해 세션이 끝난 후 데이터를 유지하지 않아야 합니다.",
        "Question": "개발자가 이 요구 사항을 효과적으로 처리하기 위해 구현해야 할 데이터 저장 패턴은 무엇인가요?",
        "Options": {
            "1": "애플리케이션 내에서 인메모리 데이터 구조를 사용하는 임시 저장.",
            "2": "/tmp 디렉토리를 사용하는 Lambda 실행 환경 내의 임시 저장.",
            "3": "세션 관리를 사용하는 Amazon RDS를 통한 지속적 저장.",
            "4": "데이터 삭제를 위한 라이프사이클 정책을 사용하는 Amazon S3를 통한 지속적 저장."
        },
        "Correct Answer": "애플리케이션 내에서 인메모리 데이터 구조를 사용하는 임시 저장.",
        "Explanation": "인메모리 데이터 구조는 사용자 세션 동안 데이터를 빠르게 접근하고 조작할 수 있게 해주며, 세션이 끝난 후에는 해당 데이터를 지속하지 않아 리소스 사용을 최적화하고 사용자 개인 정보를 유지합니다.",
        "Other Options": [
            "/tmp 디렉토리를 사용하는 Lambda 실행 환경은 임시 저장을 제공하지만, 인메모리 옵션에 비해 세션 기반 데이터 관리에 최적화되어 있지 않으므로 이상적이지 않습니다.",
            "세션 관리를 사용하는 Amazon RDS를 통한 지속적 저장은 세션을 넘어 데이터를 유지하므로 세션이 끝난 후 데이터를 유지하지 않겠다는 요구 사항과 모순됩니다.",
            "라이프사이클 정책을 사용하는 Amazon S3를 통한 지속적 저장은 저장 및 검색을 위해 설계되었으므로 임시 세션 데이터에 적합하지 않으며, 필요 이상으로 데이터를 더 오래 유지합니다."
        ]
    },
    {
        "Question Number": "43",
        "Situation": "개발자가 읽기 및 쓰기 작업 중에 스로틀링이 발생하는 DynamoDB 테이블을 관리하고 있습니다. 이 스로틀링은 애플리케이션 성능과 사용자 경험에 부정적인 영향을 미치고 있습니다. 개발자는 스로틀링을 유발하는 특정 작업을 신속하게 식별하고, 근본적인 문제를 이해하며, 애플리케이션의 최적 성능을 복원하기 위해 필요한 수정 조치를 구현해야 합니다.",
        "Question": "DynamoDB 테이블의 스로틀링 문제를 효과적으로 조사하고 책임이 있는 정확한 작업을 파악하기 위해 개발자가 어떤 AWS 서비스를 활용하여 관련 메트릭과 로그를 수집해야 합니까?",
        "Options": {
            "1": "Amazon CloudWatch",
            "2": "AWS X-Ray",
            "3": "AWS Config",
            "4": "Amazon GuardDuty"
        },
        "Correct Answer": "Amazon CloudWatch",
        "Explanation": "Amazon CloudWatch는 AWS 리소스와 애플리케이션 모니터링에 가장 적합한 서비스입니다. 읽기 및 쓰기 작업 메트릭을 보여줌으로써 개발자가 DynamoDB 테이블의 스로틀링 문제를 식별하는 데 도움이 되는 상세한 메트릭과 로그를 제공합니다. 이를 통해 효과적인 문제 해결 및 성능 조정이 가능합니다.",
        "Other Options": [
            "AWS X-Ray는 주로 애플리케이션의 성능 병목 현상과 오류를 식별하기 위해 추적 및 분석하는 데 사용되지만, DynamoDB 스로틀링 메트릭을 모니터링하기 위해 특별히 설계된 것은 아닙니다.",
            "AWS Config는 AWS 리소스 인벤토리, 구성 이력 및 구성 변경 알림을 제공하는 서비스이지만, DynamoDB의 스로틀링과 같은 실시간 성능 메트릭에 중점을 두지 않습니다.",
            "Amazon GuardDuty는 악의적인 활동 및 무단 행동을 모니터링하는 위협 탐지 서비스로, DynamoDB의 스로틀링 문제를 진단하는 데 필요한 운영 메트릭을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "44",
        "Situation": "한 회사가 AWS에서 마이크로서비스 기반 애플리케이션을 운영하고 있으며, 다양한 서비스 간의 상호작용 및 성능을 이해하고자 합니다. 이를 위해 서비스 종속성의 시각적 표현과 상세한 성능 메트릭을 제공하는 강력한 솔루션을 찾고 있습니다. 이러한 통찰력은 복잡한 분산 환경에서 병목 현상을 식별하고 문제를 효율적으로 해결하는 데 중요합니다.",
        "Question": "회사가 최적의 성능과 신뢰성을 보장하기 위해 마이크로서비스 애플리케이션에서 상세한 서비스 맵을 생성하고 요청을 추적하기 위해 어떤 AWS 서비스를 활용해야 합니까?",
        "Options": {
            "1": "Amazon CloudWatch",
            "2": "AWS X-Ray",
            "3": "AWS Config",
            "4": "AWS CloudTrail"
        },
        "Correct Answer": "AWS X-Ray",
        "Explanation": "AWS X-Ray는 분산 애플리케이션을 모니터링하고 디버깅하기 위해 특별히 설계되어 있어, 마이크로서비스 아키텍처 내에서 서비스 맵을 생성하고 요청을 추적하는 데 이상적입니다. 성능 병목 현상에 대한 통찰력을 제공하고 서비스 종속성을 시각화하는 데 도움을 주어, 회사의 문제 해결 및 성능 분석 요구에 완벽하게 부합합니다.",
        "Other Options": [
            "Amazon CloudWatch는 주로 메트릭 수집 및 추적, 로그 파일 모니터링 및 알람 설정에 중점을 둡니다. 유용한 성능 데이터를 제공하지만, AWS X-Ray와 같은 포괄적인 방식으로 서비스 맵을 생성하거나 요청을 추적하지는 않습니다.",
            "AWS Config는 AWS 리소스의 구성을 평가, 감사 및 평가하는 데 도움을 주는 서비스입니다. 성능 모니터링이나 애플리케이션 간 요청 추적을 위해 설계되지 않았으므로, 서비스 맵 및 요청 추적 요구에 적합하지 않습니다.",
            "AWS CloudTrail은 AWS 인프라 전반에 걸쳐 계정 활동을 기록하고 모니터링하는 데 사용되며, AWS API 호출의 이력을 제공합니다. 그러나 애플리케이션 성능이나 서비스 종속성에 중점을 두지 않으므로 회사의 목표에 필수적인 요소가 아닙니다."
        ]
    },
    {
        "Question Number": "45",
        "Situation": "한 회사가 문서, 이미지 및 사용자 정보를 위한 관계형 데이터를 포함한 다양한 유형의 데이터를 저장해야 하는 콘텐츠 관리 시스템(CMS)을 구축하고 있습니다. 개발 팀은 효율적인 접근 및 관리를 보장하기 위해 다양한 데이터 유형에 적합한 저장 옵션을 선택해야 합니다.",
        "Question": "팀이 파일, 객체 및 관계형 데이터베이스를 효과적으로 저장하기 위해 어떤 AWS 클라우드 저장 옵션 조합을 사용해야 합니까?",
        "Options": {
            "1": "파일에 Amazon Elastic Block Store (EBS), 객체에 Amazon Simple Storage Service (S3), 관계형 데이터베이스에 Amazon Relational Database Service (RDS).",
            "2": "객체에 Amazon Simple Storage Service (S3), NoSQL 데이터 저장을 위한 Amazon DynamoDB, 관계형 데이터베이스에 Amazon Aurora.",
            "3": "파일에 Amazon Elastic File System (EFS), 객체에 Amazon Simple Storage Service (S3), 관계형 데이터베이스 관리에 Amazon Relational Database Service (RDS).",
            "4": "아카이브 저장에 Amazon Glacier, 객체에 Amazon Simple Storage Service (S3), 빅 데이터 분석에 Amazon Redshift."
        },
        "Correct Answer": "Amazon Elastic File System (EFS) for files, Amazon Simple Storage Service (S3) for objects, and Amazon Relational Database Service (RDS) for managing relational databases.",
        "Explanation": "이 옵션은 여러 인스턴스를 위한 공유 파일 시스템을 제공할 수 있는 Amazon EFS를 올바르게 활용합니다. Amazon S3는 이미지 및 문서와 같은 객체를 저장하는 데 적합하며, 확장성과 내구성을 제공합니다. 마지막으로, Amazon RDS는 관계형 데이터베이스 관리를 위해 특별히 설계되어 사용자 정보 저장에 가장 적합한 선택입니다.",
        "Other Options": [
            "이 옵션은 파일에 Amazon EBS를 사용하는 것을 잘못 제안하고 있으며, EBS는 주로 블록 저장소에 사용되며 공유 파일 접근에 적합하지 않습니다. 또한, 관계형 데이터베이스 옵션 대신 NoSQL 데이터베이스인 Amazon DynamoDB를 사용하는 것은 이 CMS 요구에 적합하지 않습니다.",
            "이 옵션은 활성 파일 접근을 위한 것이 아니라 장기 아카이브 저장을 위해 설계된 Amazon Glacier를 사용하는 것을 잘못 제안하고 있습니다. Amazon S3는 객체 저장에 적합하지만, 사용자 정보를 위한 관계형 데이터베이스 서비스 대신 데이터 웨어하우징 및 분석에 맞춰진 Amazon Redshift를 제안하는 것은 적합하지 않습니다."
        ]
    },
    {
        "Question Number": "46",
        "Situation": "개발자가 사용자 등록을 처리하고 이메일 주소 및 전화번호를 포함한 사용자 정보를 저장하는 애플리케이션을 작업하고 있습니다. 이 애플리케이션은 데이터 보호 규정을 준수하기 위해 처리되는 데이터 유형을 분류해야 합니다.",
        "Question": "개발자가 규정에 따라 적절하게 처리하기 위해 사용자 이메일 주소와 전화번호를 저장할 때 어떤 데이터 분류를 사용해야 합니까?",
        "Options": {
            "1": "공개 데이터(Public Data), 이는 누구나 제한 없이 자유롭게 접근하고 사용할 수 있는 정보를 의미합니다.",
            "2": "민감 데이터(Sensitive Data), 이는 기밀성 때문에 특별한 보호가 필요한 정보로, 공개될 경우 해를 끼칠 수 있는 정보를 포함합니다.",
            "3": "개인 식별 정보(PII), 이는 이름, 이메일 주소 및 전화번호를 포함하여 개인을 식별할 수 있는 모든 데이터를 포함합니다.",
            "4": "기밀 데이터(Confidential Data), 이는 비밀로 유지되어야 하며 권한이 있는 개인과만 공유되어야 하는 정보를 의미합니다."
        },
        "Correct Answer": "개인 식별 정보(PII), 이는 이름, 이메일 주소 및 전화번호를 포함하여 개인을 식별할 수 있는 모든 데이터를 포함합니다.",
        "Explanation": "사용자 이메일 주소와 전화번호를 저장하기 위한 올바른 분류는 '개인 식별 정보(PII)'입니다. 이 정보는 개인을 직접 식별할 수 있기 때문에, 개발자는 이러한 데이터를 주의 깊게 처리하여 개인정보 보호 규정을 준수해야 합니다.",
        "Other Options": [
            "공개 데이터는 민감하지 않고 누구나 접근할 수 있는 정보를 의미하므로 이메일 주소와 전화번호와 같은 보호가 필요한 정보에는 해당되지 않기 때문에 잘못된 선택입니다.",
            "민감 데이터는 보호의 필요성을 암시하지만, 일반적으로 건강 정보나 재무 기록과 같이 유출 시 더 높은 위험을 초래하는 데이터를 의미하므로 최선의 답변이 아닙니다.",
            "기밀 데이터는 정보가 제한되어야 한다고 제안하지만, 이메일 주소와 전화번호와 같은 식별 측면을 명시적으로 다루지 않기 때문에 이 맥락에서는 오해의 소지가 있습니다."
        ]
    },
    {
        "Question Number": "47",
        "Situation": "개발자가 Amazon SQS (Simple Queue Service) 큐에서 메시지를 관리하는 프로젝트를 작업하고 있습니다. 성능을 최적화하고 AWS에 대한 API 호출 수를 줄이기 위해, 개발자는 큐에서 여러 메시지를 효율적으로 단일 요청으로 삭제해야 합니다. 이는 애플리케이션의 응답성을 유지하고 자원 관리의 모범 사례를 준수하는 데 필수적입니다.",
        "Question": "개발자가 Amazon SQS 큐에서 단일 API 호출로 여러 메시지를 삭제하여 프로세스의 효율성을 개선하기 위해 어떤 API 메서드를 사용해야 합니까?",
        "Options": {
            "1": "delete_message",
            "2": "purge_queue",
            "3": "delete_message_batch",
            "4": "receive_message"
        },
        "Correct Answer": "delete_message_batch",
        "Explanation": "Amazon SQS 큐에서 단일 API 호출로 여러 메시지를 삭제하기 위한 올바른 API 메서드는 'delete_message_batch'입니다. 이 메서드는 개발자가 한 번에 최대 10개의 메시지를 삭제하도록 지정할 수 있게 하여, 메시지를 하나씩 삭제하는 것보다 더 효율적인 접근 방식을 제공합니다.",
        "Other Options": [
            "'delete_message' API 메서드는 한 번에 단일 메시지를 삭제하도록 설계되었으므로 여러 메시지를 한 번에 삭제해야 하는 요구 사항과 일치하지 않습니다.",
            "'purge_queue' API 메서드는 큐의 모든 메시지를 한 번에 삭제하지만, 특정 메시지를 선택적으로 삭제할 수 없으므로 요구 사항을 충족하지 않습니다.",
            "'receive_message' API 메서드는 큐에서 메시지를 검색하는 데 사용되며, 삭제하는 것과는 관련이 없습니다. 따라서 메시지를 삭제하는 작업과는 관련이 없습니다."
        ]
    },
    {
        "Question Number": "48",
        "Situation": "한 회사가 여러 클라이언트(테넌트)를 위한 다중 테넌트 애플리케이션을 개발 중입니다. 이 애플리케이션의 중요한 요구 사항은 각 테넌트가 자신의 데이터에만 접근할 수 있도록 하여 다른 테넌트의 데이터에 대한 무단 접근을 방지하는 것입니다. 이러한 보안 수준을 달성하기 위해, 애플리케이션은 Access Control Lists (ACLs)를 사용하여 권한을 효과적으로 관리하고 자원에 대한 접근을 제어하고 있습니다.",
        "Question": "다중 테넌트 애플리케이션 내에서 강력한 권한 부여를 구현하기 위해 각 테넌트가 자신의 특정 데이터에만 접근할 수 있도록 하면서 안전한 환경을 유지하기 위한 최선의 접근 방식은 무엇입니까?",
        "Options": {
            "1": "각 테넌트의 고유한 요구 사항과 데이터 접근 필요에 맞춘 리소스 기반 정책을 가진 IAM 역할을 활용합니다.",
            "2": "각 테넌트에게 자신의 데이터에만 접근할 수 있는 신중하게 제한된 접근 권한을 가진 고유한 API 키를 할당하여 테넌트 간 데이터 가시성을 방지합니다.",
            "3": "각 개별 테넌트와 관련된 데이터에 대한 읽기 및 쓰기 권한을 정확하게 정의하는 Access Control Lists (ACLs)를 구현하여 데이터 격리를 보장합니다.",
            "4": "Amazon Cognito 사용자 풀을 활용하여 테넌트 접근을 효과적으로 관리하고, 테넌트 특정 자원에 대한 접근을 제어하는 안전한 인증 계층을 제공합니다."
        },
        "Correct Answer": "각 개별 테넌트와 관련된 데이터에 대한 읽기 및 쓰기 권한을 정확하게 정의하는 Access Control Lists (ACLs)를 구현하여 데이터 격리를 보장합니다.",
        "Explanation": "올바른 답변은 각 테넌트의 데이터에 맞춰 설계된 Access Control Lists (ACLs)를 구현하는 것입니다. ACLs는 누가 어떤 데이터에 접근할 수 있는지를 세밀하게 제어할 수 있게 하여, 각 테넌트가 자신의 데이터에만 읽기 또는 쓰기 권한을 가질 수 있도록 보장합니다. 이 방법은 데이터 격리가 중요한 다중 테넌트 아키텍처에서 특히 효과적이며, 각 테넌트의 요구에 맞춘 권한 정의를 명확하게 할 수 있습니다.",
        "Other Options": [
            "IAM 역할과 리소스 기반 정책을 사용하는 것은 접근 제어 수준을 제공할 수 있지만, 다중 테넌트 환경에서 권한을 관리하는 데 ACLs만큼 간단하지 않을 수 있으며, 테넌트별로 접근을 세밀하게 조정하는 것이 중요합니다.",
            "각 테넌트에게 고유한 API 키를 할당하는 것은 어느 정도 보안을 강화할 수 있지만, API가 데이터 접근에 대한 검사를 시행하지 않으면 접근 제어 문제를 본질적으로 방지하지 못할 수 있으며, 테넌트가 접근해서는 안 되는 데이터에 접근할 수 있게 될 수 있습니다.",
            "Amazon Cognito 사용자 풀을 활용하는 것은 강력한 인증 메커니즘을 제공하지만, 데이터 접근에 대한 권한 관리를 직접적으로 수행하지 않습니다. ACLs와 같은 추가 조치가 없으면, 테넌트가 서로의 데이터에 접근하지 못하도록 보장하는 데 필요한 세밀함을 제공하지 않을 수 있습니다."
        ]
    },
    {
        "Question Number": "49",
        "Situation": "개발자가 AWS 리소스를 효율적으로 관리해야 하는 프로젝트에서 작업하고 있습니다. 특히, 현재 실행 중인 모든 EC2 인스턴스의 포괄적인 목록을 검색해야 합니다. 이 데이터를 스크립트에서 처리하기 쉽게 하기 위해 출력 형식을 JSON으로 선호합니다. 또한, 데이터 검색을 간소화하기 위해 출력이 페이지로 나뉘지 않도록 하여 결과 파싱을 복잡하게 만들지 않기를 원합니다.",
        "Question": "이를 달성하기 위해 개발자가 모든 실행 중인 EC2 인스턴스를 단일 JSON 출력으로 페이지 없이 받기 위해 어떤 특정 명령줄 인터페이스(CLI) 옵션을 사용해야 합니까?",
        "Options": {
            "1": "--output text와 --max-items를 사용하여 단일 명령 실행에서 반환되는 인스턴스 수를 제한합니다.",
            "2": "--output json과 --dry-run을 사용하여 인스턴스를 실제로 검색하지 않고 명령을 시뮬레이션합니다.",
            "3": "--output json과 --no-paginate를 사용하여 페이지 없이 단일 JSON 출력으로 모든 인스턴스의 전체 목록을 받습니다.",
            "4": "--output yaml과 --page-size를 사용하여 출력의 각 페이지에 표시되는 인스턴스 수를 제어합니다."
        },
        "Correct Answer": "--output json과 --no-paginate를 사용하여 페이지 없이 단일 JSON 출력으로 모든 인스턴스의 전체 목록을 받습니다.",
        "Explanation": "정확한 CLI 옵션 조합은 '--output json과 --no-paginate'입니다. 이는 모든 실행 중인 EC2 인스턴스가 JSON 형식으로 단일 출력으로 반환되도록 하여 스크립트 파싱에 적합합니다. '--no-paginate' 옵션은 출력이 여러 페이지로 나뉘지 않도록 하여 개발자가 인스턴스의 전체 보기를 한 번에 제공받을 수 있도록 합니다.",
        "Other Options": [
            "'--output text와 --max-items' 옵션은 '--output text'가 출력을 일반 텍스트로 형식화하지만 JSON 형식 요구 사항을 충족하지 않으며, '--max-items'는 반환되는 인스턴스 수를 제한하기 때문에 잘못된 옵션입니다.",
            "'--output json과 --dry-run' 옵션은 원하는 JSON 형식을 지정하지만 '--dry-run' 플래그는 인스턴스를 나열하는 명령을 실제로 실행하지 않기 때문에 출력이 생성되지 않습니다.",
            "'--output yaml과 --page-size' 옵션은 출력을 JSON 대신 YAML 형식으로 요청하며, '--page-size'는 여전히 출력을 페이지로 나누기 때문에 개발자의 단일 연속 출력 요구 사항에 반합니다."
        ]
    },
    {
        "Question Number": "50",
        "Situation": "개발 팀이 애플리케이션의 새 버전을 배포하고 있으며, 다운타임을 최소화하고 배포 실패의 위험을 줄이기를 원합니다. 그들은 성능을 모니터링하면서 새로운 버전으로 트래픽을 점진적으로 전환하는 배포 전략을 사용하기로 결정했습니다.",
        "Question": "이 목표를 달성하기 위해 팀이 사용해야 하는 배포 전략은 무엇입니까?",
        "Options": {
            "1": "AWS CodeDeploy를 사용한 Blue/Green 배포로 별도의 환경을 유지합니다.",
            "2": "AWS CodeDeploy를 사용하여 인스턴스를 배치로 업데이트하는 Rolling 배포입니다.",
            "3": "AWS CodeDeploy를 사용하여 새로운 버전으로 트래픽을 점진적으로 전환하는 Canary 배포입니다.",
            "4": "업데이트된 애플리케이션을 위해 새로운 인스턴스를 생성하는 Immutable 배포입니다."
        },
        "Correct Answer": "AWS CodeDeploy를 사용하여 새로운 버전으로 트래픽을 점진적으로 전환하는 Canary 배포입니다.",
        "Explanation": "Canary 배포는 애플리케이션의 새로운 버전으로 트래픽을 점진적으로 전환하면서 성능을 모니터링하도록 설계되었습니다. 이 접근 방식은 팀이 새로운 버전의 문제를 통제된 방식으로 감지할 수 있게 하여 다운타임을 최소화하고 광범위한 배포 실패의 위험을 줄입니다.",
        "Other Options": [
            "Blue/Green 배포는 두 개의 별도 환경을 유지하는 것으로, 전환 중에 더 많은 다운타임을 초래할 수 있어 점진적인 트래픽 전환에는 덜 적합합니다.",
            "Rolling 배포는 인스턴스를 배치로 업데이트하지만, 위험을 최소화하는 데 중요한 트래픽 제어 및 모니터링 수준을 제공하지 않습니다.",
            "Immutable 배포는 업데이트된 애플리케이션을 위해 새로운 인스턴스를 생성하지만, 점진적인 트래픽 조정이 불가능하여 성능 모니터링에 덜 이상적입니다."
        ]
    },
    {
        "Question Number": "51",
        "Situation": "개발자가 디버깅을 돕기 위해 Node.js 기반 AWS Lambda 함수에 여러 console.log 문을 통합했습니다. 함수를 성공적으로 실행한 후, 개발자는 예상된 로그 항목이 Amazon CloudWatch Logs에 표시되지 않는 것을 발견하여 함수의 로깅 구성 및 권한에 대한 우려를 불러일으킵니다.",
        "Question": "Lambda 함수가 성공적으로 실행되었음에도 불구하고 Amazon CloudWatch Logs에 로그 항목이 없는 근본적인 원인은 무엇일 수 있습니까?",
        "Options": {
            "1": "개발자가 Lambda 함수를 Amazon S3에 로그를 전송하도록 구성하지 않았을 수 있으며, 이는 이 경우 표준 로깅의 의도된 목적지가 아닙니다.",
            "2": "Lambda 함수에 할당된 IAM 역할이 CloudWatch Logs에 로그 데이터를 기록하는 데 필요한 권한이 부족할 수 있으며, 이로 인해 로그 항목이 기록되지 않을 수 있습니다.",
            "3": "AWS Lambda 구성 내에서 로깅이 명시적으로 활성화되지 않았을 가능성이 있으며, 이는 로그가 캡처되고 적절한 서비스로 전송되도록 보장하는 데 필요합니다.",
            "4": "Lambda 함수의 stdout 스트림이 CloudWatch Logs로 제대로 리디렉션되지 않는 문제가 있을 수 있으며, 이로 인해 로그 출력이 완전히 없을 수 있습니다."
        },
        "Correct Answer": "Lambda 함수에 할당된 IAM 역할이 CloudWatch Logs에 로그 데이터를 기록하는 데 필요한 권한이 부족할 수 있으며, 이로 인해 로그 항목이 기록되지 않을 수 있습니다.",
        "Explanation": "정확한 답변은 Lambda 함수에 할당된 IAM 역할이 CloudWatch Logs에 로그를 기록할 적절한 권한이 없다는 것입니다. Lambda 함수가 출력을 기록하려면 IAM 역할에 CloudWatch Logs에서 로그 그룹 및 로그 스트림을 생성하고 해당 스트림에 로그를 기록할 수 있는 권한이 포함되어야 합니다. 이러한 권한이 없으면 함수가 성공적으로 실행되더라도 로그가 나타나지 않습니다.",
        "Other Options": [
            "이 옵션은 AWS Lambda가 기본적으로 로그를 Amazon S3로 전송하지 않기 때문에 잘못된 것입니다. 대신, 로그는 일반적으로 명시적으로 다르게 코딩되지 않는 한 CloudWatch Logs로 전송됩니다.",
            "이 옵션은 AWS Lambda에서 로깅이 명시적으로 활성화될 필요가 없기 때문에 잘못된 것입니다. 올바른 IAM 권한이 할당되면 로깅은 자동으로 활성화됩니다. 로그가 없는 것은 명시적 활성화의 필요성보다 권한 부족 때문일 가능성이 높습니다.",
            "이 옵션은 Lambda 함수의 stdout 스트림이 올바른 권한이 있는 경우 CloudWatch Logs로 본질적으로 리디렉션되기 때문에 잘못된 것입니다. 따라서 로그가 나타나지 않는 경우 이는 stdout 리디렉션 문제보다 권한 문제를 나타냅니다."
        ]
    },
    {
        "Question Number": "52",
        "Situation": "개발자는 EC2 인스턴스가 역할을 맡고 S3 버킷에 접근할 수 있도록 허용하는 IAM 역할을 생성해야 합니다. 신뢰 정책은 example-role-trust-policy.json이라는 JSON 파일에 정의되어 있습니다.",
        "Question": "개발자가 EC2 인스턴스가 역할을 맡을 수 있도록 하는 역할을 생성하기 위해 어떤 AWS CLI 명령어를 사용해야 합니까?",
        "Options": {
            "1": "aws iam create-role --role-name example-role --policy-document file://example-role-trust-policy.json",
            "2": "aws iam create-role --role-name example-role --assume-role-policy-document file://example-role-trust-policy.json",
            "3": "aws iam create-role --role-name example-role --policy file://example-role-trust-policy.json",
            "4": "aws iam create-role --role-name example-role --assume-policy-document file://example-role-trust-policy.json"
        },
        "Correct Answer": "aws iam create-role --role-name example-role --assume-role-policy-document file://example-role-trust-policy.json",
        "Explanation": "EC2 인스턴스가 역할을 맡을 수 있도록 하는 IAM 역할을 생성하기 위한 올바른 명령어는 '--assume-role-policy-document' 옵션을 사용하는 것입니다. 이 옵션은 지정된 엔티티(이 경우 EC2 인스턴스)가 역할을 맡을 수 있도록 권한을 부여하는 신뢰 정책을 지정합니다.",
        "Other Options": [
            "이 옵션은 '--policy-document'를 사용하므로 잘못된 것입니다. 이는 IAM 역할을 생성할 때 신뢰 정책을 지정하는 올바른 매개변수가 아닙니다.",
            "이 옵션은 '--policy'를 사용하므로 잘못된 것입니다. 이는 역할에 권한 정책을 첨부하기 위한 것이지 신뢰 정책을 정의하기 위한 것이 아닙니다.",
            "이 옵션은 '--assume-policy-document'를 잘못 사용하므로 잘못된 것입니다. 올바른 매개변수는 '--assume-role-policy-document'입니다."
        ]
    },
    {
        "Question Number": "53",
        "Situation": "개발자는 AWS에서 실시간으로 들어오는 이벤트를 처리해야 하는 서버리스 애플리케이션을 구축하고 있습니다. 이 애플리케이션은 고가용성, 내결함성 및 낮은 지연 시간으로 대량의 이벤트를 처리할 수 있어야 합니다. 개발자는 AWS Lambda를 사용하여 이벤트를 처리하고 Amazon SQS를 사용하여 큐에 넣는 것을 고려하고 있습니다.",
        "Question": "이벤트가 올바른 순서로 처리되면서 내결함성과 확장성을 유지하기 위해 개발자가 어떤 아키텍처 패턴을 사용해야 합니까?",
        "Options": {
            "1": "팬아웃 패턴과 배달되지 않은 메시지를 위한 데드레터 큐가 있는 이벤트 기반 아키텍처.",
            "2": "단일 서비스가 이벤트를 순차적으로 처리하는 모놀리식 패턴.",
            "3": "이벤트를 직접 처리하기 위한 AWS Lambda 및 API Gateway를 사용하는 동기 API 호출.",
            "4": "이벤트당 단일 Lambda 함수를 호출하는 오케스트레이션 패턴의 이벤트 기반 아키텍처."
        },
        "Correct Answer": "팬아웃 패턴과 배달되지 않은 메시지를 위한 데드레터 큐가 있는 이벤트 기반 아키텍처.",
        "Explanation": "팬아웃 패턴은 여러 소비자가 이벤트를 동시에 처리할 수 있도록 하여 확장성을 보장합니다. 데드레터 큐를 사용하면 배달되지 않은 메시지를 캡처하여 나중에 분석하거나 재시도할 수 있어 내결함성을 제공합니다. 이 접근 방식은 높은 볼륨의 이벤트를 효과적으로 관리하면서 처리 순서를 유지하는 데 도움이 될 수 있습니다.",
        "Other Options": [
            "모놀리식 패턴은 이벤트를 순차적으로 처리하므로 효과적으로 확장성과 내결함성을 지원하지 않으며, 높은 부하에서 병목 현상이 발생할 수 있습니다.",
            "동기 API 호출은 지연 시간을 초래할 수 있으며, 실시간으로 대량의 이벤트를 처리하는 데 이상적이지 않아 성능 문제와 비용 증가를 초래할 수 있습니다.",
            "이벤트당 단일 Lambda 함수를 호출하는 오케스트레이션 패턴은 애플리케이션 요구 사항에 중요한 순서 처리 보장을 본질적으로 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "54",
        "Situation": "한 회사는 전 세계 여러 지역에서 운영되며 데이터베이스에 접근할 때 지연 시간을 최소화하여 사용자에게 최상의 경험을 제공하는 것을 목표로 하고 있습니다. 이 회사는 또한 잠재적인 재해로부터 신속하게 복구할 수 있도록 원활한 전환을 허용하는 강력한 장애 조치 기능을 보장하는 데 집중하고 있습니다. 낮은 지연 시간과 높은 가용성에 대한 이중 요구는 회사의 운영과 사용자 만족도에 매우 중요합니다.",
        "Question": "글로벌 사용자에 대한 지연 시간을 최소화하고 신속한 재해 복구를 보장하기 위한 회사의 요구 사항을 고려할 때, 이러한 목표를 효과적으로 달성하기 위해 Amazon Aurora의 어떤 특정 기능을 구현해야 합니까?",
        "Options": {
            "1": "Multi-AZ 배포",
            "2": "Aurora Global Database",
            "3": "Aurora Serverless",
            "4": "Aurora Read Replicas"
        },
        "Correct Answer": "Aurora Global Database",
        "Explanation": "Aurora Global Database는 여러 지역에서 읽기 및 쓰기 작업을 수행할 수 있도록 설계되어 글로벌 애플리케이션의 지연 시간을 최소화합니다. 빠른 로컬 읽기를 제공하며 거의 즉시 다른 지역으로 장애 조치할 수 있어 회사의 낮은 지연 시간 및 재해 복구 기능 요구에 이상적입니다.",
        "Other Options": [
            "Multi-AZ 배포는 주로 단일 지역 내에서 높은 가용성과 장애 조치를 제공하므로 여러 지역에서 지연 시간을 줄이려는 회사의 요구를 충족하지 않습니다.",
            "Aurora Serverless는 가변 작업 부하와 자동 확장을 위해 설계되었지만, 지역 간 재해 복구 및 지연 시간 감소에 필요한 글로벌 범위나 신속한 장애 조치 기능을 본질적으로 제공하지 않습니다.",
            "Aurora Read Replicas는 읽기 작업의 확장을 허용하지만, 여러 지역에서 지연 시간을 최소화하고 재해 복구를 보장하는 데 필요한 글로벌 분산 및 신속한 장애 조치 기능을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "55",
        "Situation": "소프트웨어 서비스(SaaS) 회사가 사용자로부터 상당한 양의 트래픽을 처리하도록 설계된 정교한 웹 애플리케이션을 Amazon Web Services(AWS)에 배포하는 과정에 있습니다. 애플리케이션이 인기를 얻으면서 회사는 개선이 필요한 중요한 영역을 확인했습니다: 자주 접근되는 데이터가 검색되는 속도입니다. 현재 애플리케이션은 Amazon DynamoDB를 주요 데이터베이스로 사용하고 있지만, 팀은 동일한 데이터 조각에 대해 데이터베이스에서 반복적으로 읽는 것 때문에 애플리케이션이 눈에 띄는 지연을 경험하고 있다는 것을 알게 되었습니다. 그들은 이 지연을 최소화하고 애플리케이션의 전반적인 성능을 향상시키는 데 도움이 되는 캐싱 전략을 구현해야 합니다.",
        "Question": "회사가 현재 아키텍처의 맥락에서 지연을 효과적으로 줄이고 애플리케이션 성능을 크게 개선하기 위해 어떤 캐싱 전략을 구현해야 합니까?",
        "Options": {
            "1": "Amazon ElastiCache를 사용하여 자주 쿼리되는 DynamoDB 데이터를 캐시하고 읽기 성능을 개선하기 위해 쓰기 통과 전략을 사용합니다.",
            "2": "데이터를 Amazon S3에 저장하고 CloudFront를 사용하여 엣지에서 데이터를 캐시하여 더 빠른 검색을 가능하게 합니다.",
            "3": "애플리케이션 서버 내에서 인메모리 캐싱을 구현하여 데이터를 로컬 메모리에 저장합니다.",
            "4": "DynamoDB Accelerator(DAX)를 사용하여 DynamoDB 데이터를 직접 인메모리에 캐시하여 읽기 지연을 줄입니다."
        },
        "Correct Answer": "DynamoDB Accelerator(DAX)를 사용하여 DynamoDB 데이터를 직접 인메모리에 캐시하여 읽기 지연을 줄입니다.",
        "Explanation": "DynamoDB Accelerator(DAX)는 DynamoDB를 위한 인메모리 캐싱을 제공하도록 특별히 설계되었습니다. DAX는 자주 읽는 요청을 캐시하여 데이터베이스에서 데이터를 검색할 때의 지연을 최소화하며, 이는 회사가 애플리케이션 성능을 개선하는 데 필요한 것입니다. DAX는 DynamoDB와 원활하게 통합되어 복잡한 캐싱 논리나 추가 관리 오버헤드 없이 더 빠른 읽기를 가능하게 합니다.",
        "Other Options": [
            "Amazon ElastiCache를 쓰기 통과 전략으로 사용하는 것은 읽기 성능을 개선할 수 있지만, 추가적인 복잡성을 도입하고 캐싱 레이어에 대한 추가 관리가 필요합니다. 이는 회사가 현재 DynamoDB에 의존하고 있는 점을 고려할 때 가장 효율적인 솔루션이 아닐 수 있습니다.",
            "데이터를 Amazon S3에 저장하고 CloudFront를 활용하면 정적 자산의 검색 속도를 높일 수 있지만, 이는 웹 애플리케이션 맥락에서 일반적으로 쿼리되는 자주 변경되거나 동적인 데이터에는 적합하지 않으며, 이는 회사의 주요 우려 사항입니다.",
            "애플리케이션 서버 내에서 인메모리 캐싱을 구현하면 지연을 줄일 수 있지만, 이 접근 방식은 서버의 메모리 용량에 의해 제한되며, DynamoDB에 대한 DAX와 같은 수준의 통합 및 성능 최적화를 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "56",
        "Situation": "개발자가 사용자 업로드를 처리하고 처리 중에 데이터를 임시로 저장하는 웹 애플리케이션을 구축하고 있습니다. 애플리케이션은 AWS Lambda 함수에서 실행되며, 임시 데이터는 처리가 완료된 후 지속될 필요가 없습니다.",
        "Question": "개발자가 이 임시 데이터를 처리하기 위해 어떤 데이터 저장 패턴을 사용해야 합니까?",
        "Options": {
            "1": "Lambda 함수에 연결된 Amazon EBS 볼륨을 사용하는 일시적 저장소.",
            "2": "임시 데이터를 저장하기 위해 Amazon RDS를 사용하는 지속적 저장소.",
            "3": "Lambda 실행 환경의 /tmp 디렉토리를 사용하는 일시적 저장소.",
            "4": "임시 데이터를 저장하기 위해 Amazon S3를 사용하는 지속적 저장소."
        },
        "Correct Answer": "Lambda 실행 환경의 /tmp 디렉토리를 사용하는 일시적 저장소.",
        "Explanation": "/tmp 디렉토리는 AWS Lambda 실행 환경에서 임시 저장소를 제공하며, 함수 실행 중 임시 데이터에 사용할 수 있습니다. 이는 처리가 완료된 후 지속될 필요가 없는 데이터에 적합하여 이 시나리오에서 이상적인 선택입니다.",
        "Other Options": [
            "Amazon EBS 볼륨은 AWS Lambda에 적합하지 않으며, Lambda 함수는 EBS 볼륨을 직접 연결할 수 없고 대신 일시적 저장소에 의존합니다.",
            "Amazon RDS는 지속적인 데이터 저장을 위한 관계형 데이터베이스 서비스로, 지속될 필요가 없는 임시 데이터에는 불필요하고 비효율적입니다.",
            "Amazon S3는 지속적인 저장을 위해 설계되었으며, 임시 데이터에는 최적이 아니며 데이터 전송에 지연이 발생하고 장기 저장 솔루션을 위해 설계되었습니다."
        ]
    },
    {
        "Question Number": "57",
        "Situation": "개발자가 전자상거래 애플리케이션의 캐싱 레이어로 Memcached를 사용하고 있습니다. 그러나 대부분의 캐시된 데이터는 읽히지 않아 자원이 낭비되고 있습니다.",
        "Question": "개발자가 사용되지 않는 캐시 데이터로 인한 자원 낭비 문제를 해결하기 위해 어떤 전략을 구현해야 합니까?",
        "Options": {
            "1": "자주 접근되는 데이터만 캐시되도록 TTL(Time To Live) 설정과 함께 지연 로딩을 구현합니다.",
            "2": "TTL 설정 없이 쓰기 통과 캐싱을 채택하여 모든 데이터를 동기화하지만, 드물게 사용되는 항목으로 캐시가 채워질 위험이 있습니다.",
            "3": "더 많은 데이터를 수용하기 위해 캐시 크기를 크게 늘리지만, 사용되지 않는 캐시의 근본적인 문제를 해결하지 못할 수 있습니다.",
            "4": "캐시 데이터를 보호하기 위해 자동 백업 및 복원 기능을 활성화하지만, 캐시 활용 문제를 해결하지는 않습니다."
        },
        "Correct Answer": "자주 접근되는 데이터만 캐시되도록 TTL(Time To Live) 설정과 함께 지연 로딩을 구현합니다.",
        "Explanation": "TTL 설정과 함께 지연 로딩을 구현하면 캐싱 시스템이 접근될 가능성이 있는 데이터만 저장하게 되어, 읽히지 않는 데이터에 대한 자원 낭비를 줄일 수 있습니다. TTL은 지정된 시간 후에 오래된 데이터가 캐시에서 자동으로 제거되도록 하여 캐시 사용을 최적화합니다.",
        "Other Options": [
            "TTL 설정 없이 쓰기 통과 캐싱을 채택하면 캐시와 데이터베이스 간의 모든 데이터를 동기화할 수 있지만, 드물게 접근되는 불필요한 데이터로 캐시가 채워질 수 있어 문제를 악화시킬 수 있습니다.",
            "캐시 크기를 늘리는 것은 사용되지 않는 데이터로 인한 자원 낭비의 근본적인 문제를 해결하지 않으며, 단지 더 많은 데이터를 저장할 수 있게 할 뿐이고, 여전히 드물게 접근되는 정보가 포함될 수 있습니다.",
            "자동 백업 및 복원 기능을 활성화하면 캐시에 저장된 데이터를 보호할 수 있지만, 캐시 활용을 관리하거나 최적화하는 데 도움이 되지 않아 자원 낭비 문제는 해결되지 않습니다."
        ]
    },
    {
        "Question Number": "58",
        "Situation": "팀이 다양한 소스에서 데이터를 수집하고 처리하여 데이터베이스에 결과를 저장하는 데이터 처리 파이프라인을 AWS에서 설계하고 있습니다. 이 파이프라인은 데이터 수집을 차단하지 않으면서 높은 처리량의 데이터 수집을 처리해야 합니다. 팀은 아키텍처 내에서 관심사를 효과적으로 분리하기 위해 다양한 통신 패턴을 탐색하고 있습니다.",
        "Question": "팀이 이러한 관심사 분리를 달성하기 위해 구현해야 할 통신 패턴은 무엇입니까?",
        "Options": {
            "1": "데이터 수집과 처리 구성 요소 간의 직접 API 호출에 의존하는 동기식 통신 패턴으로, 즉각적인 응답을 보장합니다.",
            "2": "메시지 큐를 활용하여 데이터 수집 프로세스를 처리 작업과 효과적으로 분리하는 비동기식 통신 패턴으로, 원활한 운영을 가능하게 합니다.",
            "3": "수집 직후 즉각적인 데이터 저장을 포함하는 동기식 통신 패턴으로, 데이터가 지연 없이 저장되지만 처리 작업을 차단할 수 있습니다.",
            "4": "데이터 처리를 위한 폴링 메커니즘을 사용하는 비동기식 통신 패턴으로, 새로운 데이터의 주기적인 확인과 효율적인 처리를 가능하게 합니다."
        },
        "Correct Answer": "메시지 큐를 활용하여 데이터 수집 프로세스를 처리 작업과 효과적으로 분리하는 비동기식 통신 패턴으로, 원활한 운영을 가능하게 합니다.",
        "Explanation": "정답은 메시지 큐를 사용하는 비동기식 패턴입니다. 이 패턴은 데이터 수집 프로세스가 처리 작업과 독립적으로 운영될 수 있게 하여, 높은 처리량의 데이터를 지속적으로 수집할 수 있도록 하며, 처리 작업에 의해 차단되지 않도록 합니다. 따라서 파이프라인의 전체 성능을 최적화합니다.",
        "Other Options": [
            "직접 API 호출을 사용하는 동기식 통신 패턴은 수집과 처리 간의 의존성을 생성하므로 잘못된 것입니다. 처리에 시간이 걸리면 수집이 차단되어 데이터 손실이나 지연이 발생할 수 있습니다.",
            "수집 후 즉각적인 데이터 저장을 포함하는 동기식 패턴은 처리 작업과 데이터 수집을 분리하지 않으므로 잘못된 것입니다. 이는 특히 높은 처리량 조건에서 성능 문제를 초래할 수 있으며, 처리 작업이 수집 프로세스를 지연시킬 수 있습니다.",
            "데이터 처리를 위한 폴링 메커니즘을 사용하는 비동기식 통신 패턴은 잘못된 것입니다. 폴링은 새로운 데이터 처리에 지연과 비효율성을 초래할 수 있으며, 메시지 큐를 사용하는 것보다 효과적이지 않습니다."
        ]
    },
    {
        "Question Number": "59",
        "Situation": "개발자가 민감한 개인 및 재무 데이터를 처리하는 보안 애플리케이션을 설계하는 과정에 있습니다. 이 정보를 보호하는 것이 중요하므로, 개발자는 모든 데이터가 Amazon S3에 저장되기 전에 적절하게 암호화되어야 한다는 것을 이해하고 있습니다. 이는 애플리케이션이 필요할 때 민감한 데이터를 복호화할 수 있도록 다양한 암호화 전략을 신중하게 평가해야 함을 의미합니다. 따라서 기밀성과 무결성을 유지해야 합니다.",
        "Question": "이 맥락에서 민감한 데이터를 보호할 때 클라이언트 측 암호화와 서버 측 암호화의 주요 차이점은 무엇입니까?",
        "Options": {
            "1": "클라이언트 측 암호화는 데이터를 S3로 전송하기 전에 클라이언트 측에서 암호화하는 반면, 서버 측 암호화는 S3에 저장된 후 서버 측에서 데이터를 암호화합니다.",
            "2": "클라이언트 측 암호화는 일반적으로 클라이언트와 애플리케이션 간에 공유되는 대칭 암호화 키를 사용하는 반면, 서버 측 암호화는 종종 추가 보안을 위해 비대칭 암호화 키를 사용합니다.",
            "3": "서버 측 암호화는 애플리케이션이 데이터 복호화를 위한 암호화 키를 관리하고 유지해야 하는 반면, 클라이언트 측 암호화는 애플리케이션이 S3 서비스에 키 관리를 위임할 수 있습니다.",
            "4": "서버 측 암호화는 AWS 보안 기능 및 관리형 키 서비스와의 통합으로 인해 일반적으로 클라이언트 측 암호화에 비해 더 강력한 보안 보장을 제공하는 것으로 간주됩니다."
        },
        "Correct Answer": "클라이언트 측 암호화는 데이터를 S3로 전송하기 전에 클라이언트 측에서 암호화하는 반면, 서버 측 암호화는 S3에 저장된 후 서버 측에서 데이터를 암호화합니다.",
        "Explanation": "정답은 클라이언트 측 암호화와 서버 측 암호화 간의 근본적인 차이를 강조합니다. 클라이언트 측 암호화에서는 데이터가 Amazon S3로 전송되기 전에 암호화되므로 애플리케이션이 암호화 프로세스에 대한 완전한 제어를 유지합니다. 반면, 서버 측 암호화는 데이터가 S3에 저장된 후에 발생하며, AWS가 암호화 및 복호화 프로세스를 관리하므로 애플리케이션의 민감한 키에 대한 제어가 제한될 수 있습니다.",
        "Other Options": [
            "이 옵션은 클라이언트 측 암호화가 대칭 키를 사용하는 경우가 많지만, 서버 측 암호화도 대칭 키를 사용할 수 있기 때문에 잘못된 것입니다. 비대칭 키가 항상 사용된다는 의미는 아닙니다.",
            "이 옵션은 서버 측 암호화가 일반적으로 AWS가 키 관리를 처리하여 애플리케이션의 책임을 전가하는 것을 의미하므로 잘못된 것입니다. 이는 진술된 내용과 반대입니다.",
            "이 옵션은 서버 측 암호화가 강력한 보안 기능을 제공하지만, 클라이언트 측 암호화보다 본질적으로 더 강력한 보안을 보장하지 않기 때문에 잘못된 것입니다. 효과는 구현 및 사용 사례에 따라 다릅니다."
        ]
    },
    {
        "Question Number": "60",
        "Situation": "개발 팀이 코드 리포지토리를 효과적으로 관리하기 위해 완전 관리형 소스 제어 서비스를 탐색하고 있습니다. 그들은 버전 관리 기능, 데이터가 저장될 때 암호화되어야 하며, 지속적인 통합 및 배포 프로세스를 위해 CodeBuild 및 CodePipeline과 같은 다른 AWS 개발 도구와 원활하게 통합할 수 있는 특정 요구 사항이 있습니다. 이러한 요구 사항을 고려하여 팀은 목표에 부합하는 가장 적합한 AWS 서비스를 식별하고자 합니다.",
        "Question": "팀이 버전 관리, 데이터 저장 시 암호화 및 CodeBuild 및 CodePipeline과 같은 다른 AWS 개발 도구와의 원활한 통합 요구 사항을 충족하기 위해 선택해야 할 AWS 서비스는 무엇입니까?",
        "Options": {
            "1": "AWS CodeBuild",
            "2": "AWS CodePipeline",
            "3": "AWS CodeDeploy",
            "4": "AWS CodeCommit"
        },
        "Correct Answer": "AWS CodeCommit",
        "Explanation": "AWS CodeCommit은 팀이 안전하고 확장 가능한 Git 리포지토리를 호스팅할 수 있도록 하는 완전 관리형 소스 제어 서비스입니다. 이는 팀의 버전 관리 요구 사항을 충족하고, 데이터가 저장될 때 암호화되며, CodeBuild 및 CodePipeline과 같은 다른 AWS 서비스와 잘 통합되어 팀의 요구에 이상적인 선택입니다.",
        "Other Options": [
            "AWS CodeBuild는 주로 코드를 빌드하고 테스트하는 데 중점을 두며, 리포지토리 관리를 위한 소스 제어 서비스를 제공하지 않으므로 팀의 요구 사항에 적합하지 않습니다.",
            "AWS CodePipeline은 애플리케이션의 빌드, 테스트 및 릴리스 단계를 자동화하는 지속적인 통합 및 배포 서비스이지만, 코드 리포지토리를 위한 소스 제어 서비스로 기능하지 않습니다.",
            "AWS CodeDeploy는 다양한 컴퓨팅 서비스에 애플리케이션 배포를 자동화하기 위해 설계되었지만, 팀의 필요에 필수적인 소스 제어 솔루션으로 기능하지 않습니다."
        ]
    },
    {
        "Question Number": "61",
        "Situation": "한 회사가 AWS Key Management Service (AWS KMS)를 활용하여 Amazon S3에 저장된 민감한 데이터를 보호하는 암호화 키를 효과적으로 관리하고 있습니다. 보안 조치를 강화하기 위해, 이 회사는 암호화 키가 자동으로 회전되도록 하는 전략을 구현하기로 결정했습니다. 이 선제적 접근 방식은 키 손상 가능성을 최소화하고 전반적인 데이터 보안을 강화하는 것을 목표로 합니다.",
        "Question": "회사가 암호화 키를 정기적으로 회전하도록 자동 회전을 활성화하기 위해 어떤 구체적인 조치를 취해야 합니까?",
        "Options": {
            "1": "AWS KMS 콘솔을 통해 고객 관리 KMS 키에 대해 자동 키 회전 기능을 직접 활성화하여 의도한 대로 회전하도록 합니다.",
            "2": "키의 수동 회전을 처리할 사용자 지정 Lambda 함수를 구현하되, 이 옵션은 복잡성을 초래하고 정기적인 유지 관리가 필요할 수 있습니다.",
            "3": "AWS 관리 KMS 키를 선택하여 매년 자동 회전 기능이 내장된 키 관리의 번거로움 없는 솔루션을 제공합니다.",
            "4": "CloudWatch 이벤트를 예약하여 매달 키 회전 프로세스를 트리거하여 키가 정기적으로 변경되도록 하되, 추가 구성이 필요합니다."
        },
        "Correct Answer": "AWS KMS 콘솔을 통해 고객 관리 KMS 키에 대해 자동 키 회전 기능을 직접 활성화하여 의도한 대로 회전하도록 합니다.",
        "Explanation": "AWS KMS 콘솔에서 고객 관리 KMS 키에 대한 자동 키 회전을 활성화하는 것이 올바른 조치입니다. 이 기능은 회사가 회전 프로세스를 자동화할 수 있도록 하며, 암호화 키가 수동 노력 없이 지정된 간격으로 회전되도록 보장하여 잠재적인 키 손상 위험을 효과적으로 줄입니다.",
        "Other Options": [
            "사용자 지정 Lambda 함수를 구현하여 수동 키 회전을 처리하는 것은 불필요한 복잡성을 초래하고 지속적인 유지 관리가 필요하므로 자동 키 관리에는 이상적이지 않습니다.",
            "AWS 관리 KMS 키를 선택하는 것은 키가 매년 한 번만 자동으로 회전되므로 회사의 요구를 완전히 충족하지 못할 수 있습니다. 이는 보안 요구 사항에 비해 빈번하지 않을 수 있습니다.",
            "매달 키 회전을 위한 CloudWatch 이벤트를 예약하는 것은 추가 구성 및 운영 오버헤드를 수반하며, AWS KMS에서 제공하는 내장 자동 키 회전 기능을 활용하지 않습니다."
        ]
    },
    {
        "Question Number": "62",
        "Situation": "개발자가 DynamoDB를 사용하여 세션 관리 애플리케이션을 구축하고 있습니다. 이 애플리케이션은 만료된 세션 데이터를 데이터베이스에서 자동으로 제거해야 합니다.",
        "Question": "개발자가 이를 달성하기 위해 어떤 기능을 사용해야 합니까?",
        "Options": {
            "1": "DynamoDB Streams를 활성화합니다.",
            "2": "Time To Live (TTL)를 활성화합니다.",
            "3": "필터 표현식이 있는 Global Secondary Index (GSI)를 사용합니다.",
            "4": "주기적으로 오래된 레코드를 삭제하기 위해 스캔 작업을 사용합니다."
        },
        "Correct Answer": "Time To Live (TTL)를 활성화합니다.",
        "Explanation": "Time To Live (TTL)는 DynamoDB의 기능으로, 지정된 타임스탬프 이후에 항목을 자동으로 삭제할 수 있습니다. 세션 데이터에 TTL 속성을 설정하면 만료된 레코드가 수동 개입 없이 데이터베이스에서 제거되어 세션 데이터 만료 관리를 위한 효율적인 솔루션이 됩니다.",
        "Other Options": [
            "DynamoDB Streams는 항목의 변경 사항을 캡처하지만 만료된 데이터를 자동으로 삭제하는 메커니즘을 제공하지 않습니다.",
            "Global Secondary Index (GSI)는 데이터의 효율적인 쿼리를 가능하게 하지만 만료된 레코드의 자동 제거를 처리하지 않습니다.",
            "주기적으로 오래된 레코드를 삭제하기 위해 스캔 작업을 사용하는 것은 리소스를 많이 소모하고 비효율적일 수 있으며, 지속적인 폴링과 수동 삭제가 필요합니다."
        ]
    },
    {
        "Question Number": "63",
        "Situation": "소프트웨어 개발자가 Amazon SQS (Simple Queue Service)를 사용하여 메시지 큐를 관리하는 업무를 맡고 있습니다. 새로 추가된 메시지가 큐에 추가된 후 특정 기간 동안 소비자에게 일시적으로 숨겨지도록 보장하기 위해 개발자는 솔루션을 찾고 있습니다. 이 요구 사항은 시스템이 메시지를 처리하거나 검증할 시간이 필요한 시나리오에서 중요합니다. 특히, 개발자는 이러한 메시지가 처음 5분 동안 접근할 수 없도록 하기를 원합니다.",
        "Question": "개발자가 새로 추가된 메시지의 가시성을 정확히 5분 동안 지연시키기 위해 어떤 구체적인 기능을 구현해야 합니까?",
        "Options": {
            "1": "VisibilityTimeout을 5분으로 설정하여 메시지가 소비자에 의해 읽힌 후 얼마나 오랫동안 보이지 않는지를 제어합니다.",
            "2": "정의된 시간 프레임 내에서 콘텐츠를 기반으로 중복 처리를 방지하는 기능인 콘텐츠 기반 중복 제거를 활성화합니다.",
            "3": "5분의 지연이 있는 Delay Queue를 사용하여 메시지가 저장되고 지정된 지연 기간이 경과할 때까지 소비자에게 접근할 수 없도록 합니다.",
            "4": "SQS 큐의 보존 기간을 늘려 메시지가 자동으로 삭제되기 전에 큐에 얼마나 오랫동안 저장되는지를 결정합니다."
        },
        "Correct Answer": "5분의 지연이 있는 Delay Queue를 사용하여 메시지가 저장되고 지정된 지연 기간이 경과할 때까지 소비자에게 접근할 수 없도록 합니다.",
        "Explanation": "정확한 답변은 5분의 지연이 있는 Delay Queue를 사용하는 것입니다. 이 기능은 메시지를 큐에 추가하지만 지연 시간이 지나기 전까지 소비자에게 전달되지 않도록 합니다. 이 맥락에서 이는 큐에 추가된 후 처음 5분 동안 소비자의 접근을 방지하는 요구 사항을 완벽하게 충족합니다.",
        "Other Options": [
            "VisibilityTimeout을 5분으로 설정하는 것은 잘못된 답변입니다. 이는 메시지가 소비자에 의해 읽힌 후에만 적용되며, 큐에 추가될 때 즉시 모든 소비자로부터 메시지를 숨기는 것이 필요합니다.",
            "콘텐츠 기반 중복 제거를 활성화하는 것은 이 경우와 관련이 없습니다. 이는 메시지 콘텐츠를 기반으로 중복을 방지하는 데 중점을 두며, 메시지의 가시성이나 접근 타이밍을 제어하는 것과는 관련이 없습니다.",
            "SQS 큐의 보존 기간을 늘리는 것은 지연된 접근 요구 사항을 해결하지 않습니다. 이 기능은 메시지가 삭제되기 전에 큐에 얼마나 오랫동안 남아 있는지를 단순히 연장할 뿐이며, 새로운 메시지의 즉각적인 가시성에는 영향을 미치지 않습니다."
        ]
    },
    {
        "Question Number": "64",
        "Situation": "한 회사는 AWS Key Management Service(SSE-KMS)를 사용하여 업로드된 모든 객체가 암호화되도록 하여 S3 버킷에 저장된 데이터의 보안을 강화하는 데 집중하고 있습니다. 이들은 이 암호화 기준이 충족되도록 특정 버킷 정책 조건을 구현하려고 합니다.",
        "Question": "서버 측 암호화를 위한 이 요구 사항을 시행하기 위해 회사가 포함해야 할 버킷 정책 조건은 무엇입니까?",
        "Options": {
            "1": "aws:SecureTransport 조건을 true로 설정하여 데이터가 HTTPS를 통해 전송되도록 합니다.",
            "2": "s3:x-amz-server-side-encryption 조건을 AES256으로 설정하여 Amazon의 기본 암호화 방법을 사용함을 나타냅니다.",
            "3": "s3:x-amz-server-side-encryption 조건을 aws:kms로 설정하여 AWS Key Management Service를 암호화에 사용하도록 지정합니다.",
            "4": "s3:PutObject 조건을 aws:kms로 설정하여 객체가 업로드될 때 AWS Key Management Service를 사용하도록 강제합니다."
        },
        "Correct Answer": "s3:x-amz-server-side-encryption 조건을 aws:kms로 설정하여 AWS Key Management Service를 암호화에 사용하도록 지정합니다.",
        "Explanation": "정답은 서버 측 암호화를 위해 AWS Key Management Service(SSE-KMS)의 사용을 지정하는 옵션입니다. 's3:x-amz-server-side-encryption' 조건을 'aws:kms'로 설정함으로써, 버킷 정책은 업로드되는 모든 객체가 KMS를 사용하여 암호화되어야 함을 강제하여 암호화 요구 사항을 준수하도록 합니다.",
        "Other Options": [
            "이 옵션은 안전한 전송을 보장하는 것이 중요하지만 회사에서 요구하는 특정 암호화 기준을 시행하지 않기 때문에 잘못된 것입니다.",
            "이 옵션은 AES256을 사용하는 것이 KMS 사용을 강제하기에 충분하지 않기 때문에 잘못된 것입니다. 이는 기본 서버 측 암호화가 적용되고 있음을 나타내기만 하며, 회사의 KMS 암호화에 대한 특정 요구 사항을 충족하지 않습니다.",
            "이 옵션은 's3:PutObject' 조건을 잘못 언급하고 있으며, 업로드 중 서버 측 암호화를 시행하는 데 필요한 올바른 's3:x-amz-server-side-encryption'이 아닙니다."
        ]
    },
    {
        "Question Number": "65",
        "Situation": "한 개발자가 S3 버킷에 저장된 데이터를 처리하기 위해 AWS Lambda를 사용하는 프로젝트를 진행하고 있습니다. Lambda 함수가 필요한 데이터에 접근할 수 있도록 하기 위해, 개발자는 권한 부여의 다양한 방법을 탐색하고 있습니다. 보안 및 관리 가능성에 대한 모범 사례를 고려한 후, 개발자는 이 특정 작업에 IAM 사용자 대신 IAM 역할을 사용하기로 결정합니다.",
        "Question": "AWS Lambda 함수가 S3 버킷에 접근할 수 있도록 권한을 부여할 때 IAM 사용자 대신 IAM 역할을 사용하는 주요 장점은 무엇입니까?",
        "Options": {
            "1": "역할은 임시 자격 증명을 제공하며 Lambda와 같은 AWS 서비스에 의해 가정될 수 있습니다.",
            "2": "역할은 사용자보다 더 높은 보안 권한을 가지고 있습니다.",
            "3": "역할은 생성하기가 더 쉽고 신뢰 정책이 필요하지 않습니다.",
            "4": "역할은 모든 AWS 리소스에 대한 전체 액세스를 자동으로 부여합니다."
        },
        "Correct Answer": "역할은 임시 자격 증명을 제공하며 Lambda와 같은 AWS 서비스에 의해 가정될 수 있습니다.",
        "Explanation": "IAM 역할을 사용하는 주요 장점은 AWS 서비스, 예를 들어 Lambda가 가정할 수 있는 임시 보안 자격 증명을 제공한다는 것입니다. 이는 장기 자격 증명과 관련된 위험을 줄여 보안을 강화하고, Lambda 함수가 함수 코드에 민감한 정보를 직접 포함하지 않고도 S3 버킷에 접근할 수 있도록 권한을 동적으로 관리할 수 있게 합니다.",
        "Other Options": [
            "이 옵션은 역할이 사용자보다 본질적으로 더 높은 보안 권한을 가지지 않기 때문에 잘못된 것입니다. 권한은 역할이나 사용자에 첨부된 정책에 따라 달라집니다.",
            "이 옵션은 역할이 경우에 따라 관리하기 더 쉬울 수 있지만, 여전히 어떤 엔티티가 역할을 가정할 수 있는지를 정의하기 위해 신뢰 정책이 필요하기 때문에 잘못된 것입니다. 특히 AWS 서비스가 관련될 때 그렇습니다.",
            "이 옵션은 역할이 모든 AWS 리소스에 대한 전체 액세스를 자동으로 부여하지 않기 때문에 잘못된 것입니다. 액세스는 역할에 첨부된 특정 정책에 의해 결정되며, 필요에 따라 매우 제한적일 수 있습니다."
        ]
    }
]