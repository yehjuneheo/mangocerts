[
    {
        "Question Number": "1",
        "Situation": "Una firma de servicios financieros recopila datos de transacciones en varios formatos de múltiples fuentes. Antes de realizar análisis, los datos deben ser limpiados, normalizados y enriquecidos. La firma busca una solución sin servidor que pueda automatizar este proceso de ETL (Extraer, Transformar, Cargar).",
        "Question": "¿Qué servicio de AWS debería recomendar el arquitecto de soluciones para la transformación de datos?",
        "Options": {
            "1": "Amazon EMR",
            "2": "AWS Glue",
            "3": "AWS Lambda",
            "4": "Amazon Redshift Spectrum"
        },
        "Correct Answer": "AWS Glue",
        "Explanation": "AWS Glue es un servicio de ETL (Extraer, Transformar, Cargar) completamente administrado que está diseñado específicamente para la preparación y transformación de datos. Automatiza el proceso de descubrimiento, catalogación y transformación de datos, lo que lo hace ideal para la firma de servicios financieros que necesita limpiar, normalizar y enriquecer datos de transacciones de diversas fuentes. AWS Glue puede manejar operaciones sin servidor, lo que se alinea con el requisito de la firma de una solución sin servidor.",
        "Other Options": [
            "Amazon EMR es una plataforma de clúster administrada que simplifica la ejecución de marcos de big data como Apache Hadoop y Apache Spark. Aunque puede realizar tareas de ETL, no es una solución sin servidor y requiere más gestión y configuración en comparación con AWS Glue.",
            "AWS Lambda es un servicio de computación sin servidor que ejecuta código en respuesta a eventos. Aunque se puede usar para la transformación de datos, no está diseñado específicamente para procesos de ETL y carece de las capacidades integradas para la catalogación de datos y la inferencia de esquemas que proporciona AWS Glue.",
            "Amazon Redshift Spectrum permite ejecutar consultas contra datos almacenados en S3 sin cargarlos en Redshift. Sin embargo, es principalmente un servicio de consultas en lugar de un servicio de ETL, y no proporciona las capacidades de transformación de datos necesarias para limpiar y enriquecer datos antes del análisis."
        ]
    },
    {
        "Question Number": "2",
        "Situation": "Una empresa está utilizando Amazon CloudWatch para monitorear la seguridad de sus recursos de AWS. La empresa necesita establecer un sistema que pueda responder automáticamente a posibles amenazas de seguridad al activar acciones de remediación cuando se detecta un patrón inusual en el tráfico de red o intentos de acceso no autorizados.",
        "Question": "¿Cuál de las siguientes configuraciones debería implementar la empresa para garantizar que los incidentes de seguridad sean detectados y remediados en tiempo real?",
        "Options": {
            "1": "Usar CloudWatch Logs para recopilar registros de instancias de EC2 y configurar Alarmas de CloudWatch para activar funciones de Lambda para acciones de remediación cuando se detecten patrones específicos en los registros.",
            "2": "Usar CloudWatch Metrics para monitorear la salud de las instancias de EC2 y configurar escalado automático cuando se superen los umbrales de seguridad, sin integrar otros servicios de seguridad de AWS.",
            "3": "Configurar CloudWatch Events para reenviar datos de registro de CloudTrail a un sistema SIEM (Gestión de Información y Eventos de Seguridad) externo para análisis en tiempo real y remediación automatizada.",
            "4": "Habilitar Dashboards de CloudWatch para visualizar métricas de EC2 e inspeccionar manualmente los datos en busca de amenazas de seguridad, activando alertas a través de Amazon SNS cuando sea necesario."
        },
        "Correct Answer": "Usar CloudWatch Logs para recopilar registros de instancias de EC2 y configurar Alarmas de CloudWatch para activar funciones de Lambda para acciones de remediación cuando se detecten patrones específicos en los registros.",
        "Explanation": "Esta opción es correcta porque aborda directamente la necesidad de detección y remediación en tiempo real de incidentes de seguridad. Al usar CloudWatch Logs para recopilar registros de instancias de EC2, la empresa puede monitorear patrones específicos que indican posibles amenazas de seguridad. Configurar Alarmas de CloudWatch permite respuestas automatizadas a través de funciones de AWS Lambda, que pueden ejecutar acciones de remediación predefinidas inmediatamente cuando se detecta una amenaza. Esta configuración asegura que los incidentes de seguridad no solo sean detectados en tiempo real, sino que también se actúe automáticamente, mejorando la postura de seguridad general de los recursos de AWS.",
        "Other Options": [
            "Esta opción es incorrecta porque, aunque sugiere usar CloudWatch Logs y alarmas, no especifica el uso de funciones de Lambda para la remediación automatizada. Sin automatización, la respuesta a las amenazas detectadas no sería en tiempo real, lo cual es crítico para una gestión de seguridad efectiva.",
            "Esta opción es incorrecta porque se centra en monitorear la salud de las instancias de EC2 y el escalado automático, lo cual no está directamente relacionado con la detección y remediación de amenazas de seguridad. Aunque monitorear la salud de las instancias es importante, no aborda la necesidad específica de responder a incidentes de seguridad como tráfico de red inusual o intentos de acceso no autorizados.",
            "Esta opción es incorrecta porque, aunque reenviar datos de registro a un sistema SIEM externo puede ser beneficioso para el análisis, no proporciona un mecanismo directo para acciones de remediación en tiempo real. La dependencia de un sistema externo introduce latencia en el tiempo de respuesta, lo cual no es adecuado para la mitigación inmediata de amenazas."
        ]
    },
    {
        "Question Number": "3",
        "Situation": "Una empresa de servicios financieros debe asegurarse de que su aplicación crítica de trading pueda ser restaurada y estar operativa dentro de un tiempo muy corto en caso de un desastre. Para cumplir con sus requisitos operativos, la empresa ha establecido un Objetivo de Tiempo de Recuperación (RTO) de 15 minutos, lo que significa que la aplicación debe estar en línea nuevamente dentro de este tiempo si ocurre una interrupción.",
        "Question": "¿Qué estrategia de recuperación ante desastres cumpliría mejor con este requisito de RTO?",
        "Options": {
            "1": "Copia de seguridad y restauración, utilizando una copia de seguridad nocturna almacenada en Amazon S3, que puede ser restaurada para volver a poner la aplicación en línea cuando sea necesario",
            "2": "Pilot Light, manteniendo infraestructura preconfigurada que permanece apagada pero puede ser lanzada rápidamente para restaurar la aplicación cuando sea necesario",
            "3": "Warm Standby, con una versión mínima en funcionamiento de la aplicación que puede ser escalada a plena capacidad de producción dentro del RTO de 15 minutos",
            "4": "Configuración Multi-site Active-Active, donde se mantienen recursos completamente operativos en múltiples ubicaciones, asegurando conmutación por error instantánea y cero tiempo de inactividad"
        },
        "Correct Answer": "Configuración Multi-site Active-Active, donde se mantienen recursos completamente operativos en múltiples ubicaciones, asegurando conmutación por error instantánea y cero tiempo de inactividad",
        "Explanation": "La configuración Multi-site Active-Active es la mejor estrategia de recuperación ante desastres para cumplir con el Objetivo de Tiempo de Recuperación (RTO) de 15 minutos porque asegura que los recursos completamente operativos estén disponibles en todo momento en múltiples ubicaciones. En caso de un desastre, el sistema puede conmutar instantáneamente a otro sitio sin tiempo de inactividad, cumpliendo así con el estricto requisito de tener la aplicación en línea de inmediato. Esta configuración proporciona el más alto nivel de disponibilidad y resiliencia, lo que la hace ideal para aplicaciones críticas de trading que no pueden permitirse retrasos.",
        "Other Options": [
            "Copia de seguridad y restauración no cumpliría con el requisito de RTO de 15 minutos, ya que restaurar desde una copia de seguridad nocturna puede tardar significativamente más de 15 minutos, especialmente si la copia de seguridad es grande o si hay problemas durante el proceso de restauración.",
            "Pilot Light implica mantener una infraestructura mínima que puede ser lanzada rápidamente, pero aún requiere tiempo para activar los recursos necesarios y puede no garantizar que la aplicación pueda estar completamente operativa dentro del RTO de 15 minutos.",
            "Warm Standby mantiene una versión mínima de la aplicación que puede ser escalada, pero escalar a plena capacidad de producción puede tardar más de 15 minutos, especialmente si hay limitaciones de recursos o si la aplicación requiere un tiempo significativo de inicialización."
        ]
    },
    {
        "Question Number": "4",
        "Situation": "Una aplicación de computación de alto rendimiento (HPC) que se ejecuta en instancias de Amazon EC2 requiere una latencia ultra baja y el mayor IOPS posible para el almacenamiento temporal de datos. Los datos no necesitan ser retenidos si la instancia se detiene o falla, y el costo es una preocupación principal.",
        "Question": "¿Qué opción de almacenamiento debería recomendar el arquitecto de soluciones?",
        "Options": {
            "1": "Amazon EBS General Purpose SSD (gp3)",
            "2": "Amazon EBS Provisioned IOPS SSD (io2)",
            "3": "Instance Store",
            "4": "Amazon S3 con Transfer Acceleration"
        },
        "Correct Answer": "Instance Store",
        "Explanation": "Instance Store proporciona el mayor IOPS posible y una latencia ultra baja porque está físicamente conectado al servidor host. Esto lo hace ideal para aplicaciones de computación de alto rendimiento que requieren un almacenamiento temporal de datos rápido. Dado que los datos no necesitan ser retenidos si la instancia se detiene o falla, usar Instance Store es rentable ya que no incurre en cargos adicionales como lo hacen los volúmenes de EBS.",
        "Other Options": [
            "Amazon EBS General Purpose SSD (gp3) ofrece un buen rendimiento y es rentable, pero no proporciona el mismo nivel de IOPS y latencia que Instance Store, lo que lo hace menos adecuado para aplicaciones HPC que requieren latencia ultra baja.",
            "Amazon EBS Provisioned IOPS SSD (io2) proporciona un alto IOPS y está diseñado para aplicaciones que requieren un rendimiento sostenido, pero es más caro que Instance Store y no es necesario para el almacenamiento temporal de datos que no necesita ser retenido.",
            "Amazon S3 con Transfer Acceleration está diseñado para la transferencia de datos a alta velocidad a través de Internet y no es adecuado para requisitos de latencia ultra baja. Además, S3 es un servicio de almacenamiento de objetos, que no es apropiado para el almacenamiento temporal de datos en aplicaciones HPC que requieren acceso rápido."
        ]
    },
    {
        "Question Number": "5",
        "Situation": "Una empresa de comercio electrónico necesita una solución de recuperación ante desastres para recuperar rápidamente su base de datos en caso de una falla regional inesperada. Requieren un tiempo de inactividad y pérdida de datos mínimos.",
        "Question": "¿Qué servicio y estrategia de AWS debería considerar la empresa para cumplir con un objetivo de punto de recuperación (RPO) bajo y un objetivo de tiempo de recuperación (RTO) bajo?",
        "Options": {
            "1": "Amazon RDS con una implementación Multi-AZ y réplicas de lectura entre regiones, ya que proporciona conmutación por error automática y replicación entre regiones para una recuperación rápida con mínima pérdida de datos.",
            "2": "Amazon S3 con versionado habilitado, ya que garantiza la durabilidad de los datos al mantener múltiples versiones de cada objeto en las Zonas de Disponibilidad.",
            "3": "AWS Backup para instantáneas regulares de la base de datos, ya que proporciona recuperación en el tiempo de la base de datos a través de múltiples regiones.",
            "4": "Amazon EC2 Auto Scaling con copias de seguridad programadas, ya que permite escalado automatizado y recuperación de datos periódica."
        },
        "Correct Answer": "Amazon RDS con una implementación Multi-AZ y réplicas de lectura entre regiones, ya que proporciona conmutación por error automática y replicación entre regiones para una recuperación rápida con mínima pérdida de datos.",
        "Explanation": "Amazon RDS con una implementación Multi-AZ está diseñado para alta disponibilidad y durabilidad. En una configuración Multi-AZ, RDS replica automáticamente la base de datos a una instancia de reserva en una Zona de Disponibilidad diferente, lo que permite la conmutación por error automática en caso de una interrupción. Esta configuración minimiza el tiempo de inactividad (bajo RTO) y asegura que los datos se repliquen continuamente, logrando así un objetivo de punto de recuperación (RPO) bajo. Además, el uso de réplicas de lectura entre regiones permite una mayor redundancia de datos y una recuperación más rápida en caso de una falla regional, lo que lo convierte en una solución ideal para los requisitos de la empresa.",
        "Other Options": [
            "Amazon S3 con versionado habilitado es principalmente para almacenamiento de objetos y no proporciona las capacidades necesarias de recuperación de bases de datos. Si bien garantiza la durabilidad de los datos al mantener múltiples versiones de objetos, no aborda la necesidad de un RPO y RTO bajos para una base de datos.",
            "AWS Backup para instantáneas regulares de la base de datos puede proporcionar recuperación en el tiempo, pero puede no cumplir con los requisitos de RPO y RTO bajos tan efectivamente como una implementación Multi-AZ con réplicas de lectura entre regiones. Las instantáneas pueden tardar en restaurarse, lo que podría llevar a un mayor tiempo de inactividad.",
            "Amazon EC2 Auto Scaling con copias de seguridad programadas se centra en escalar instancias de EC2 y no proporciona inherentemente una solución de recuperación ante desastres para bases de datos. Las copias de seguridad programadas pueden no ofrecer la conmutación por error inmediata y el bajo RPO/RTO que la empresa requiere."
        ]
    },
    {
        "Question Number": "6",
        "Situation": "Una empresa está ejecutando una aplicación web en Amazon RDS y quiere mejorar el rendimiento de lectura de la aplicación descargando consultas de lectura de la base de datos principal. La empresa necesita asegurarse de que la base de datos principal no se vea abrumada durante las horas pico de tráfico. Están considerando usar réplicas de lectura para manejar la carga de lectura aumentada.",
        "Question": "¿Cuál de las siguientes describe mejor cuándo debería usar la empresa réplicas de lectura?",
        "Options": {
            "1": "Usar réplicas de lectura cuando la aplicación requiere un alto rendimiento de escritura y necesita distribuir las escrituras a través de múltiples regiones.",
            "2": "Usar réplicas de lectura cuando la aplicación tiene un alto número de consultas pesadas de lectura y necesita escalar la capacidad de lectura a través de múltiples réplicas.",
            "3": "Usar réplicas de lectura cuando la aplicación necesita almacenar datos no estructurados como imágenes o documentos y requiere alta disponibilidad.",
            "4": "Usar réplicas de lectura solo para fines de migración de datos, no para mejorar el rendimiento de la aplicación."
        },
        "Correct Answer": "Usar réplicas de lectura cuando la aplicación tiene un alto número de consultas pesadas de lectura y necesita escalar la capacidad de lectura a través de múltiples réplicas.",
        "Explanation": "Las réplicas de lectura están diseñadas específicamente para descargar el tráfico de lectura de la base de datos principal. Cuando una aplicación experimenta un alto volumen de consultas de lectura, usar réplicas de lectura permite a la aplicación distribuir estas consultas a través de múltiples instancias, mejorando así el rendimiento de lectura y asegurando que la base de datos principal no se vea abrumada durante las horas pico de tráfico. Esta configuración mejora la escalabilidad y la capacidad de respuesta para cargas de trabajo pesadas de lectura.",
        "Other Options": [
            "Usar réplicas de lectura cuando la aplicación requiere un alto rendimiento de escritura y necesita distribuir las escrituras a través de múltiples regiones. Esto es incorrecto porque las réplicas de lectura están destinadas a operaciones de lectura, no a distribuir operaciones de escritura. Las escrituras siempre se dirigen a la base de datos principal.",
            "Usar réplicas de lectura cuando la aplicación necesita almacenar datos no estructurados como imágenes o documentos y requiere alta disponibilidad. Esto es incorrecto porque las réplicas de lectura no se utilizan para almacenar datos no estructurados; se utilizan para mejorar el rendimiento de lectura de datos estructurados en bases de datos.",
            "Usar réplicas de lectura solo para fines de migración de datos, no para mejorar el rendimiento de la aplicación. Esto es incorrecto porque, si bien las réplicas de lectura pueden usarse durante la migración de datos, su propósito principal es mejorar el rendimiento de la aplicación al manejar consultas de lectura, no solo para migración."
        ]
    },
    {
        "Question Number": "7",
        "Situation": "Una empresa de producción de medios requiere almacenamiento de alto rendimiento para la edición de video, pero desea mantener bajos los costos. Tienen una mezcla de cargas de trabajo de alto y bajo rendimiento y necesitan elegir tipos de almacenamiento en bloque apropiados.",
        "Question": "¿Qué combinaciones de opciones de almacenamiento en bloque debería utilizar la empresa para optimizar costos mientras cumple con los requisitos de rendimiento? (Elija dos.)",
        "Options": {
            "1": "Provisioned IOPS SSD (io2) para todos los volúmenes",
            "2": "General Purpose SSD (gp3) para tareas de alto rendimiento y Throughput Optimized HDD (st1) para tareas de menor rendimiento",
            "3": "Cold HDD (sc1) para todos los volúmenes",
            "4": "Usar Amazon S3 en lugar de almacenamiento en bloque para todos los datos",
            "5": "General Purpose SSD (gp3) para la mayoría de las cargas de trabajo y Cold HDD (sc1) para necesidades de almacenamiento de archivo"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Provisioned IOPS SSD (io2) para todos los volúmenes",
            "General Purpose SSD (gp3) para tareas de alto rendimiento y Throughput Optimized HDD (st1) para tareas de menor rendimiento"
        ],
        "Explanation": "Provisioned IOPS SSD (io2) es una opción de almacenamiento de alto rendimiento que proporciona un rendimiento rápido, predecible y consistente, lo que la hace adecuada para cargas de trabajo de alto rendimiento como la edición de video. Sin embargo, es más costosa que otras opciones. Por otro lado, General Purpose SSD (gp3) ofrece un equilibrio entre precio y rendimiento, lo que la hace adecuada para una amplia gama de cargas de trabajo. Throughput Optimized HDD (st1) es una opción de bajo costo que proporciona un rendimiento moderado, lo que la hace adecuada para tareas menos exigentes.",
        "Other Options": [
            "Cold HDD (sc1) para todos los volúmenes no es una opción adecuada porque está diseñada para datos fríos o de archivo que se acceden con poca frecuencia y de forma secuencial. No proporciona el alto rendimiento requerido para la edición de video.",
            "Usar Amazon S3 en lugar de almacenamiento en bloque para todos los datos no es ideal porque S3 es un servicio de almacenamiento de objetos, no un servicio de almacenamiento en bloque. No está diseñado para cargas de trabajo de alto rendimiento como la edición de video, que requieren acceso a datos de baja latencia.",
            "General Purpose SSD (gp3) para la mayoría de las cargas de trabajo y Cold HDD (sc1) para necesidades de almacenamiento de archivo no es la mejor opción porque, aunque gp3 es adecuada para la mayoría de las cargas de trabajo, sc1 no es adecuada para tareas de alto rendimiento. Está diseñada para datos fríos o de archivo que se acceden con poca frecuencia y de forma secuencial."
        ]
    },
    {
        "Question Number": "8",
        "Situation": "En una gran arquitectura multi-VPC, estás experimentando desafíos para mantener numerosas conexiones punto a punto y aumentar la complejidad de la red.",
        "Question": "¿Qué solución simplificaría mejor tu arquitectura de red mientras mejora la escalabilidad y la resiliencia?",
        "Options": {
            "1": "Configurar una conexión VPN entre cada par de VPC para asegurar la comunicación directa y mejorar la seguridad.",
            "2": "Usar AWS Direct Connect para cada VPC, permitiendo que cada una se conecte de manera independiente a tu red local.",
            "3": "Implementar un Transit Gateway (TGW) para actuar como un hub centralizado, conectando todas las VPC y reduciendo la necesidad de conexiones individuales.",
            "4": "Configurar una conexión de emparejamiento entre cada VPC para mantener alta disponibilidad y asegurar una latencia mínima a través de las conexiones."
        },
        "Correct Answer": "Implementar un Transit Gateway (TGW) para actuar como un hub centralizado, conectando todas las VPC y reduciendo la necesidad de conexiones individuales.",
        "Explanation": "Un Transit Gateway (TGW) simplifica la arquitectura de red al actuar como un hub central para interconectar múltiples VPC y redes locales. Esto reduce la complejidad de gestionar numerosas conexiones punto a punto, ya que todas las VPC pueden comunicarse a través del TGW. Mejora la escalabilidad porque puedes agregar fácilmente más VPC sin necesidad de establecer nuevas conexiones para cada par. Además, mejora la resiliencia al proporcionar un único punto de gestión y monitoreo, lo que puede agilizar la solución de problemas y el mantenimiento.",
        "Other Options": [
            "Configurar una conexión VPN entre cada par de VPC crearía una malla compleja de conexiones, lo que llevaría a un aumento en la carga de gestión y posibles cuellos de botella en el rendimiento. Este enfoque no escala bien a medida que aumenta el número de VPC.",
            "Usar AWS Direct Connect para cada VPC permite conexiones independientes a redes locales, pero no aborda la complejidad de la comunicación entre VPC. Cada VPC aún requeriría su propia configuración y gestión, lo que puede llevar a una arquitectura de red fragmentada.",
            "Configurar una conexión de emparejamiento entre cada VPC también crearía una red de malla compleja. Si bien puede proporcionar conexiones de baja latencia, la gestión de numerosas conexiones de emparejamiento se vuelve engorrosa a medida que crece el número de VPC, lo que la hace menos escalable en comparación con un Transit Gateway."
        ]
    },
    {
        "Question Number": "9",
        "Situation": "Una empresa de atención médica necesita respaldar los datos de los pacientes en AWS para fines de recuperación ante desastres. Para reducir costos, requieren una solución que minimice los costos de almacenamiento mientras asegura la retención a largo plazo de las copias de seguridad. También desean la opción de recuperar datos dentro de unas pocas horas si es necesario.",
        "Question": "¿Qué estrategia de respaldo cumpliría mejor con estos requisitos?",
        "Options": {
            "1": "Almacenar copias de seguridad en Amazon S3 Standard",
            "2": "Usar Amazon S3 Glacier Flexible Retrieval para almacenamiento de archivo",
            "3": "Almacenar copias de seguridad en Amazon S3 Standard-IA",
            "4": "Usar Amazon EBS Snapshots almacenados en la misma región"
        },
        "Correct Answer": "Usar Amazon S3 Glacier Flexible Retrieval para almacenamiento de archivo",
        "Explanation": "Amazon S3 Glacier Flexible Retrieval está diseñado para la archivación de datos a largo plazo y ofrece una solución rentable para almacenar datos que se acceden con poca frecuencia. Permite la recuperación de datos dentro de unas pocas horas, lo que se alinea con el requisito de la empresa de atención médica de recuperar copias de seguridad de manera oportuna. Esta opción minimiza los costos de almacenamiento mientras asegura que los datos se retengan durante largos períodos, lo que la convierte en la mejor opción para fines de recuperación ante desastres.",
        "Other Options": [
            "Almacenar copias de seguridad en Amazon S3 Standard no es rentable para almacenamiento a largo plazo, ya que está diseñado para datos que se acceden con frecuencia. Esta opción incurriría en costos más altos en comparación con Glacier para la misma cantidad de datos a lo largo del tiempo.",
            "Usar Amazon S3 Glacier Flexible Retrieval para almacenamiento de archivo es la respuesta correcta, pero si consideramos la opción de S3 Glacier Deep Archive, sería aún más barata para almacenamiento a largo plazo. Sin embargo, no cumple con el requisito de recuperar datos dentro de unas pocas horas, ya que los tiempos de recuperación pueden tardar hasta 12 horas.",
            "Almacenar copias de seguridad en Amazon S3 Standard-IA (Acceso Infrecuente) es una mejor opción que Standard, pero aún no es tan rentable como Glacier para almacenamiento a largo plazo. Si bien es adecuada para datos que se acceden con menos frecuencia, no proporciona el mismo nivel de ahorro de costos para la retención a largo plazo como lo hace Glacier."
        ]
    },
    {
        "Question Number": "10",
        "Situation": "Una empresa de SaaS ofrece una aplicación web que se conecta a una base de datos central de Amazon RDS para MySQL. La aplicación experimenta picos de conexión intermitentes que ocasionalmente superan el número máximo de conexiones permitidas en la base de datos.",
        "Question": "¿Qué solución debería implementar el arquitecto de soluciones para gestionar las conexiones a la base de datos de manera efectiva y prevenir que se supere el límite de conexiones?",
        "Options": {
            "1": "Aumentar el número máximo de conexiones permitidas en la instancia de Amazon RDS.",
            "2": "Desplegar un clúster de Amazon ElastiCache para manejar las consultas a la base de datos y reducir las conexiones directas.",
            "3": "Implementar Amazon RDS Proxy para agrupar y compartir conexiones a la base de datos de manera eficiente.",
            "4": "Usar funciones de AWS Lambda para gestionar y distribuir las conexiones a la base de datos dinámicamente."
        },
        "Correct Answer": "Implementar Amazon RDS Proxy para agrupar y compartir conexiones a la base de datos de manera eficiente.",
        "Explanation": "Amazon RDS Proxy está diseñado para gestionar las conexiones a la base de datos de manera eficiente al agrupar y compartir conexiones entre múltiples instancias de la aplicación. Esto ayuda a reducir el número de conexiones concurrentes a la base de datos, lo cual es particularmente útil en escenarios donde la aplicación experimenta picos en las solicitudes de conexión. Al usar RDS Proxy, la aplicación puede mantener un menor número de conexiones activas a la base de datos, evitando así que se supere el límite de conexiones y mejorando el rendimiento y la confiabilidad general de la aplicación.",
        "Other Options": [
            "Aumentar el número máximo de conexiones permitidas en la instancia de Amazon RDS puede proporcionar una solución temporal, pero no aborda el problema subyacente de los picos de conexión. Este enfoque puede llevar a un mayor consumo de recursos y puede no ser sostenible si la aplicación continúa creciendo.",
            "Desplegar un clúster de Amazon ElastiCache puede ayudar a reducir la carga en la base de datos al almacenar en caché los datos de acceso frecuente, pero no gestiona directamente las conexiones a la base de datos. Si bien puede mejorar el rendimiento al reducir el número de consultas enviadas a la base de datos, no resuelve el problema de superar el límite máximo de conexiones.",
            "Usar funciones de AWS Lambda para gestionar y distribuir las conexiones a la base de datos dinámicamente no es una solución efectiva para este escenario. Las funciones Lambda son sin estado y están diseñadas para arquitecturas impulsadas por eventos, lo que puede no proporcionar las capacidades necesarias de agrupamiento y gestión de conexiones requeridas para manejar picos en las conexiones a la base de datos."
        ]
    },
    {
        "Question Number": "11",
        "Situation": "Una empresa está buscando desplegar una solución de base de datos en AWS y desea mantener flexibilidad para parches personalizados del sistema operativo e instalaciones de software, mientras también se beneficia de un servicio administrado para copias de seguridad y escalado. Están considerando Amazon RDS, RDS Custom y ejecutar la base de datos en EC2.",
        "Question": "¿Qué opción se alinea mejor con sus requisitos para un equilibrio entre control y servicios administrados?",
        "Options": {
            "1": "Amazon RDS, ya que proporciona gestión completa por parte de AWS con copias de seguridad automáticas y escalado, pero con personalización limitada del sistema operativo y software.",
            "2": "RDS Custom, que permite a la empresa manejar parches personalizados del sistema operativo e instalaciones de software mientras AWS gestiona las copias de seguridad y el escalado.",
            "3": "EC2 con una base de datos autogestionada, ofreciendo control total sobre el sistema operativo y software, pero requiriendo que la empresa maneje todas las tareas de gestión, incluidas las copias de seguridad.",
            "4": "Amazon RDS con Multi-AZ habilitado, ya que equilibra disponibilidad y copias de seguridad, pero no permite acceso a nivel de sistema operativo para personalización."
        },
        "Correct Answer": "RDS Custom, que permite a la empresa manejar parches personalizados del sistema operativo e instalaciones de software mientras AWS gestiona las copias de seguridad y el escalado.",
        "Explanation": "RDS Custom está diseñado específicamente para proporcionar la flexibilidad de parches personalizados del sistema operativo e instalaciones de software mientras se beneficia de los servicios administrados que AWS ofrece, como copias de seguridad automatizadas y escalado. Esta opción logra el equilibrio adecuado entre control y gestión, permitiendo a la empresa adaptar su entorno de base de datos a sus necesidades específicas sin sacrificar los beneficios de un servicio administrado.",
        "Other Options": [
            "Amazon RDS proporciona gestión completa por parte de AWS, incluidas copias de seguridad automáticas y escalado, pero no permite la personalización del sistema operativo o instalaciones de software, lo que no cumple con el requisito de flexibilidad de la empresa.",
            "EC2 con una base de datos autogestionada ofrece control total sobre el sistema operativo y software, pero requiere que la empresa gestione todos los aspectos de la base de datos, incluidas las copias de seguridad y el escalado, lo que contradice su deseo de un servicio administrado.",
            "Amazon RDS con Multi-AZ habilitado mejora la disponibilidad y proporciona copias de seguridad automatizadas, pero al igual que el RDS estándar, no permite el acceso a nivel de sistema operativo o personalización, lo que lo hace inadecuado para las necesidades de la empresa."
        ]
    },
    {
        "Question Number": "12",
        "Situation": "Una empresa con múltiples cuentas de AWS desea implementar un enfoque centralizado para gestionar la seguridad y los permisos en todas las cuentas. La empresa requiere que cada cuenta siga políticas de cumplimiento estrictas, mientras permite a los administradores de cuentas individuales gestionar usuarios dentro de sus cuentas.",
        "Question": "¿Qué servicio de AWS debería usar la empresa para lograr estos requisitos?",
        "Options": {
            "1": "AWS IAM Identity Center (AWS Single Sign-On)",
            "2": "AWS Organizations con Políticas de Control de Servicio (SCPs)",
            "3": "AWS IAM con roles entre cuentas",
            "4": "Amazon Cognito"
        },
        "Correct Answer": "AWS Organizations con Políticas de Control de Servicio (SCPs)",
        "Explanation": "AWS Organizations permite gestionar de manera centralizada múltiples cuentas de AWS y aplicar políticas a través de esas cuentas. Las Políticas de Control de Servicio (SCPs) son una característica de AWS Organizations que permiten establecer límites de permisos para sus cuentas, asegurando el cumplimiento de políticas estrictas mientras se permite a los administradores de cuentas individuales gestionar usuarios y permisos dentro de sus propias cuentas. Esta configuración cumple con el requisito de la empresa para una gestión centralizada y la aplicación de cumplimiento en múltiples cuentas.",
        "Other Options": [
            "AWS IAM Identity Center (AWS Single Sign-On) se utiliza principalmente para gestionar el acceso de usuarios y el inicio de sesión único a través de cuentas y aplicaciones de AWS. Si bien ayuda con la gestión de usuarios, no proporciona las capacidades de aplicación de políticas centralizadas que ofrece AWS Organizations con SCPs.",
            "AWS IAM con roles entre cuentas permite otorgar permisos entre diferentes cuentas de AWS, pero no proporciona una forma centralizada de hacer cumplir políticas de cumplimiento en múltiples cuentas. Cada cuenta aún necesitaría gestionar sus propias políticas de IAM sin el control general proporcionado por las SCPs.",
            "Amazon Cognito está diseñado para la autenticación y gestión de usuarios para aplicaciones web y móviles. No es adecuado para gestionar permisos y cumplimiento en múltiples cuentas de AWS, ya que se centra en la identidad del usuario en lugar de la aplicación de políticas a nivel de cuenta."
        ]
    },
    {
        "Question Number": "13",
        "Situation": "Una empresa de comercio electrónico, ABC Online, aloja su sitio web y APIs en AWS utilizando servicios como CloudFront, Application Load Balancer (ALB), AppSync y API Gateway. Para protegerse contra amenazas como inyección SQL, scripting de sitios cruzados (XSS) y ataques basados en IP, ABC Online desea implementar una solución de firewall que pueda bloquear dinámicamente el tráfico malicioso mientras permite a los usuarios legítimos acceder sin interrupciones. Están considerando usar AWS Web Application Firewall (WAF) junto con Listas de Control de Acceso Web (Web ACLs) para asegurar sus aplicaciones en múltiples servicios de AWS. El equipo de seguridad quiere configurar reglas personalizadas y controlar el flujo de tráfico basado en criterios específicos para prevenir ataques que podrían comprometer su aplicación y los datos de los clientes.",
        "Question": "¿Cuál de las siguientes afirmaciones describe mejor cómo funcionan AWS Web Application Firewall (WAF) y Web ACLs para proteger aplicaciones desplegadas en servicios de AWS como CloudFront, ALB, AppSync y API Gateway?",
        "Options": {
            "1": "AWS WAF aplica reglas predefinidas para permitir o denegar automáticamente todo el tráfico entrante sin ajustes o actualizaciones manuales, ofreciendo protección estática contra amenazas comunes.",
            "2": "Las Web ACLs en AWS WAF consisten en reglas y grupos de reglas que se pueden aplicar a recursos específicos, como CloudFront o servicios regionales, para controlar el acceso basado en criterios definidos como reputación de IP, inyección SQL y ataques de scripting de sitios cruzados (XSS).",
            "3": "AWS WAF opera utilizando Web ACLs, que solo bloquean el tráfico que proviene de direcciones IP específicas, haciéndolo efectivo únicamente para prevenir ataques basados en IP.",
            "4": "Las Web ACLs son compatibles solo con distribuciones de CloudFront y no se pueden usar con otros servicios de AWS como ALB, AppSync o API Gateway."
        },
        "Correct Answer": "Las Web ACLs en AWS WAF consisten en reglas y grupos de reglas que se pueden aplicar a recursos específicos, como CloudFront o servicios regionales, para controlar el acceso basado en criterios definidos como reputación de IP, inyección SQL y ataques de scripting de sitios cruzados (XSS).",
        "Explanation": "AWS WAF permite a los usuarios crear Listas de Control de Acceso Web (Web ACLs) que contienen reglas y grupos de reglas para filtrar el tráfico web. Estas reglas se pueden personalizar para dirigirse a amenazas específicas, como inyección SQL y XSS, y se pueden aplicar a varios servicios de AWS, incluidos CloudFront, ALB, AppSync y API Gateway. Esta flexibilidad permite a las organizaciones bloquear dinámicamente el tráfico malicioso mientras permiten a los usuarios legítimos acceder sin interrupciones, lo cual es esencial para mantener la seguridad de la aplicación.",
        "Other Options": [
            "AWS WAF no se basa únicamente en reglas predefinidas; permite la creación de reglas personalizadas y requiere ajustes manuales para adaptarse a amenazas en evolución. Proporciona protección dinámica en lugar de estática.",
            "AWS WAF no se limita a bloquear tráfico de direcciones IP específicas. Puede bloquear o permitir tráfico basado en una amplia gama de criterios, incluyendo inyección SQL y XSS, lo que lo convierte en una solución integral para la seguridad de aplicaciones web.",
            "Las Web ACLs son compatibles con múltiples servicios de AWS, no solo con CloudFront. También se pueden aplicar a Application Load Balancers, API Gateway y otros servicios regionales, proporcionando un enfoque unificado para la seguridad de aplicaciones web en varias plataformas."
        ]
    },
    {
        "Question Number": "14",
        "Situation": "Una empresa desea desplegar una base de datos relacional altamente disponible en AWS que pueda cambiar sin problemas en caso de una interrupción de la Zona de Disponibilidad. También están interesados en descargar el tráfico de lectura y mantener copias de seguridad para recuperación ante desastres.",
        "Question": "¿Qué configuración de AWS RDS deberían usar para lograr estos requisitos?",
        "Options": {
            "1": "Configurar Amazon RDS con implementaciones Multi-AZ para replicación sincrónica a una instancia en espera, y crear réplicas de lectura en diferentes regiones para escalabilidad de lectura.",
            "2": "Usar una única instancia de Amazon RDS con instantáneas regulares de EBS y configurar direccionamiento público para permitir acceso remoto para failover.",
            "3": "Configurar Amazon RDS con implementaciones Multi-AZ y replicación asincrónica para réplicas de lectura dentro de la misma Zona de Disponibilidad.",
            "4": "Desplegar Amazon RDS con replicación entre regiones, habilitando failover a una instancia primaria en otra región de AWS cuando la instancia principal falla."
        },
        "Correct Answer": "Configurar Amazon RDS con implementaciones Multi-AZ para replicación sincrónica a una instancia en espera, y crear réplicas de lectura en diferentes regiones para escalabilidad de lectura.",
        "Explanation": "Esta configuración cumple con todos los requisitos descritos en la situación. Las implementaciones Multi-AZ proporcionan alta disponibilidad al cambiar automáticamente a una instancia en espera en otra Zona de Disponibilidad en caso de una interrupción, asegurando un failover sin problemas. La replicación sincrónica asegura que los datos se repliquen de manera consistente a la instancia en espera. Además, crear réplicas de lectura en diferentes regiones permite a la empresa descargar el tráfico de lectura y escalar las operaciones de lectura, al tiempo que proporciona opciones para recuperación ante desastres a través de copias de seguridad.",
        "Other Options": [
            "Usar una única instancia de Amazon RDS con instantáneas regulares de EBS no proporciona alta disponibilidad ni failover sin problemas, ya que depende de intervención manual para la recuperación. El direccionamiento público no mejora la disponibilidad y puede exponer la base de datos a riesgos de seguridad.",
            "Configurar Amazon RDS con implementaciones Multi-AZ y replicación asincrónica para réplicas de lectura dentro de la misma Zona de Disponibilidad no proporciona la alta disponibilidad y capacidades de failover requeridas, ya que no utiliza los beneficios de Multi-AZ para failover y no permite descargar el tráfico de lectura de manera efectiva.",
            "Desplegar Amazon RDS con replicación entre regiones no es necesario para los requisitos establecidos, ya que complica la configuración y puede introducir latencia. El enfoque principal debe ser en implementaciones Multi-AZ para alta disponibilidad dentro de la misma región, con réplicas de lectura para escalabilidad."
        ]
    },
    {
        "Question Number": "15",
        "Situation": "Una empresa está configurando una distribución de CloudFront para servir contenido de manera segura utilizando SSL. Quieren usar un nombre de dominio alternativo y asegurar conexiones seguras desde los espectadores a CloudFront y luego desde CloudFront a sus orígenes, que incluyen un bucket de S3 y un Application Load Balancer (ALB).",
        "Question": "¿Qué pasos deben seguir para asegurar conexiones SSL seguras en todo momento?",
        "Options": {
            "1": "Configurar un certificado SSL en CloudFront usando ACM en la región donde se despliega CloudFront.",
            "2": "Configurar un certificado SSL en ACM para el bucket de S3, permitiendo que CloudFront use el bucket directamente con HTTPS.",
            "3": "Usar un certificado de ACM para el ALB y un certificado externo para cualquier origen personalizado; los certificados autofirmados son aceptables.",
            "4": "Configurar soporte SNI en CloudFront para manejar múltiples sitios HTTPS en una sola IP, y generar un certificado ACM en us-east-1 para el nombre de dominio alternativo."
        },
        "Correct Answer": "Configurar un certificado SSL en CloudFront usando ACM en la región donde se despliega CloudFront.",
        "Explanation": "Para asegurar conexiones SSL seguras en toda la configuración, la empresa debe configurar un certificado SSL en CloudFront utilizando AWS Certificate Manager (ACM). Este certificado se utilizará para cifrar la conexión entre los espectadores y CloudFront. Es importante notar que CloudFront requiere que el certificado SSL esté en la región de EE. UU. Este (N. Virginia) (us-east-1) para que se pueda usar con nombres de dominio alternativos. Este paso asegura que el contenido servido por CloudFront se entregue de manera segura a través de HTTPS.",
        "Other Options": [
            "Configurar un certificado SSL en ACM para el bucket de S3 no es necesario porque CloudFront puede servir contenido desde S3 a través de HTTPS sin necesidad de un certificado SSL separado para el bucket en sí. CloudFront maneja la terminación SSL.",
            "Usar un certificado de ACM para el ALB y un certificado externo para cualquier origen personalizado no es la mejor práctica. Todos los orígenes deberían usar idealmente certificados de ACM para consistencia y facilidad de gestión. Los certificados autofirmados generalmente no se recomiendan para entornos de producción debido a problemas de confianza.",
            "Configurar soporte SNI en CloudFront no es necesario para este escenario. Si bien SNI (Server Name Indication) permite servir múltiples certificados SSL desde una sola dirección IP, el requisito principal es tener el certificado SSL configurado correctamente en ACM para CloudFront, que maneja la terminación SSL para el nombre de dominio alternativo."
        ]
    },
    {
        "Question Number": "16",
        "Situation": "Una empresa necesita establecer una conexión segura y confiable entre su centro de datos local y su entorno de AWS para acceder a datos sensibles. La empresa requiere baja latencia, alto ancho de banda y cifrado para los datos en tránsito.",
        "Question": "¿Qué solución cumpliría mejor con estos requisitos?",
        "Options": {
            "1": "Configurar una conexión de AWS Direct Connect con una superposición de VPN para proporcionar cifrado y transmisión segura de datos entre el local y AWS.",
            "2": "Configurar una puerta de enlace de Internet estándar en la VPC y usar túneles VPN IPsec para cifrar los datos durante el tránsito.",
            "3": "Usar una puerta de enlace de Internet junto con AWS Shield para protección DDoS y confiar en HTTPS para cifrado.",
            "4": "Establecer una conexión de VPC Peering entre el centro de datos local y la VPC de AWS para asegurar una comunicación segura y de baja latencia."
        },
        "Correct Answer": "Configurar una conexión de AWS Direct Connect con una superposición de VPN para proporcionar cifrado y transmisión segura de datos entre el local y AWS.",
        "Explanation": "AWS Direct Connect proporciona una conexión de red dedicada desde el centro de datos local a AWS, lo que asegura baja latencia y alto ancho de banda. Al agregar una superposición de VPN, los datos en tránsito pueden ser cifrados, cumpliendo con el requisito de la empresa para la transmisión segura de datos sensibles. Esta combinación ofrece tanto los beneficios de rendimiento de Direct Connect como la seguridad de una VPN, lo que la convierte en la mejor solución para el escenario dado.",
        "Other Options": [
            "Configurar una puerta de enlace de Internet estándar en la VPC y usar túneles VPN IPsec proporcionaría cifrado, pero la puerta de enlace de Internet depende de la internet pública, lo que puede introducir mayor latencia y menos confiabilidad en comparación con una conexión dedicada como Direct Connect.",
            "Usar una puerta de enlace de Internet junto con AWS Shield para protección DDoS y confiar en HTTPS para cifrado no cumple con los requisitos de baja latencia y alto ancho de banda. HTTPS es adecuado para asegurar datos en tránsito, pero la dependencia de la internet pública puede llevar a un rendimiento variable, lo que no es ideal para acceder a datos sensibles.",
            "Establecer una conexión de VPC Peering no se aplica en este contexto, ya que VPC Peering se utiliza para conectar dos VPC dentro de AWS, no para conectar un centro de datos local a AWS. Además, VPC Peering no proporciona cifrado ni una conexión dedicada, que son críticos para las necesidades de la empresa."
        ]
    },
    {
        "Question Number": "17",
        "Situation": "Una empresa ha desplegado una aplicación en instancias de Amazon EC2 dentro de una subred privada de una VPC. La aplicación necesita acceder a internet para descargar actualizaciones y comunicarse con otros servicios públicos, pero no debe ser accesible directamente desde internet.",
        "Question": "¿Qué configuración debería usar la empresa para cumplir con estos requisitos?",
        "Options": {
            "1": "Adjuntar una puerta de enlace de Internet a la subred privada y configurar las instancias de EC2 con IPs públicas para acceso saliente.",
            "2": "Desplegar una puerta de enlace NAT en una subred pública, asociar una tabla de rutas con la subred privada para dirigir el tráfico 0.0.0.0/0 a la puerta de enlace NAT, y asegurarse de que la puerta de enlace NAT tenga una IP elástica.",
            "3": "Usar VPC Peering para conectar la subred privada a otra VPC que tenga acceso a internet y configurar el enrutamiento entre las dos VPC.",
            "4": "Configurar una conexión VPN entre la subred privada y una red local con acceso a internet, permitiendo que las instancias de EC2 enruten a través de la red local para el tráfico saliente."
        },
        "Correct Answer": "Desplegar una puerta de enlace NAT en una subred pública, asociar una tabla de rutas con la subred privada para dirigir el tráfico 0.0.0.0/0 a la puerta de enlace NAT, y asegurarse de que la puerta de enlace NAT tenga una IP elástica.",
        "Explanation": "Una puerta de enlace NAT permite que las instancias en una subred privada inicien tráfico saliente hacia internet mientras previene el tráfico entrante desde internet. Al desplegar una puerta de enlace NAT en una subred pública y asociar la tabla de rutas de la subred privada con una ruta que dirija el tráfico 0.0.0.0/0 a la puerta de enlace NAT, las instancias de EC2 pueden acceder a internet para actualizaciones y comunicaciones sin ser accesibles directamente desde internet. La IP elástica asignada a la puerta de enlace NAT proporciona una IP pública para el tráfico saliente, asegurando una conectividad adecuada a internet.",
        "Other Options": [
            "Adjuntar una puerta de enlace de Internet a la subred privada y configurar las instancias de EC2 con IPs públicas expondría las instancias directamente a internet, lo que contradice el requisito de no ser accesibles directamente desde internet.",
            "Usar VPC Peering para conectar la subred privada a otra VPC con acceso a internet no proporciona una ruta directa para que las instancias de la subred privada accedan a internet. VPC Peering no facilita el acceso a internet para subredes privadas sin configuraciones adicionales, como NAT.",
            "Configurar una conexión VPN entre la subred privada y una red local con acceso a internet complicaría la arquitectura e introduciría latencia. Además, no aborda directamente el requisito de que las instancias de EC2 accedan a internet sin estar expuestas, ya que depende de una red externa para el acceso a internet."
        ]
    },
    {
        "Question Number": "18",
        "Situation": "Una empresa de servicios financieros genera y almacena grandes volúmenes de datos de clientes en sus instalaciones todos los días. Debido a estrictos requisitos regulatorios y de cumplimiento, deben retener estos datos localmente, pero quieren descargar datos más antiguos y de acceso poco frecuente a AWS para ahorrar en costos de almacenamiento. Necesitan una solución que pueda extender sin problemas su infraestructura de almacenamiento actual a AWS, permitiendo el acceso a datos archivados sin interrumpir sus aplicaciones o flujos de trabajo existentes.",
        "Question": "¿Qué servicio de AWS cumpliría mejor con los requisitos de la empresa? (Elija dos.)",
        "Options": {
            "1": "Amazon S3 con políticas de ciclo de vida",
            "2": "AWS Direct Connect",
            "3": "AWS Storage Gateway",
            "4": "Exportación de instantáneas de Amazon EBS",
            "5": "Amazon Glacier Deep Archive con Vault Lock"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon S3 con políticas de ciclo de vida",
            "AWS Storage Gateway"
        ],
        "Explanation": "Amazon S3 con políticas de ciclo de vida es una respuesta correcta porque permite la migración automática de datos a diferentes clases de almacenamiento según reglas definidas, lo que puede ayudar a la empresa a ahorrar en costos de almacenamiento para datos de acceso poco frecuente. AWS Storage Gateway también es correcto ya que proporciona una forma sin problemas de conectar aplicaciones locales al almacenamiento de AWS. Soporta tipos de almacenamiento de archivos, volúmenes y cintas, y puede ser utilizado para almacenar datos en S3, Glacier y EBS, lo que lo convierte en una buena opción para los requisitos de la empresa.",
        "Other Options": [
            "AWS Direct Connect se utiliza principalmente para establecer una conexión de red dedicada desde sus instalaciones a AWS, no específicamente para propósitos de almacenamiento o archivo.",
            "La exportación de instantáneas de Amazon EBS permite exportar una instantánea de Amazon EBS a un bucket de Amazon S3, pero no proporciona una extensión sin problemas de la infraestructura de almacenamiento local a AWS.",
            "Amazon Glacier Deep Archive con Vault Lock es una clase de almacenamiento para archivo de datos y respaldo a largo plazo a costos muy bajos. Sin embargo, no proporciona una forma sin problemas de extender el almacenamiento local a AWS, y los tiempos de recuperación de datos pueden ser de hasta 12 horas, lo que puede no cumplir con las necesidades de la empresa para acceder a datos archivados."
        ]
    },
    {
        "Question Number": "19",
        "Situation": "Un servicio de transmisión de video experimenta picos impredecibles en el tráfico de espectadores, especialmente durante eventos en vivo. El servicio necesita asegurarse de que puede manejar aumentos repentinos en la carga sin intervención manual, mientras minimiza costos durante los períodos de baja demanda.",
        "Question": "¿Qué característica de AWS debería configurar el arquitecto de soluciones para ajustar automáticamente el número de instancias de EC2 según los patrones de tráfico?",
        "Options": {
            "1": "AWS Elastic Beanstalk scaling",
            "2": "Amazon CloudWatch Alarms",
            "3": "Amazon EC2 Auto Scaling",
            "4": "AWS Lambda auto-scaling"
        },
        "Correct Answer": "Amazon EC2 Auto Scaling",
        "Explanation": "Amazon EC2 Auto Scaling está diseñado para ajustar automáticamente el número de instancias de EC2 en respuesta a los patrones de tráfico cambiantes. Puede escalar hacia afuera (agregar instancias) durante los momentos pico y escalar hacia adentro (eliminar instancias) durante los períodos de baja demanda sin intervención manual. Esta característica es ideal para manejar picos impredecibles en el tráfico de espectadores, como durante eventos en vivo, mientras minimiza costos durante períodos de baja demanda.",
        "Other Options": [
            "AWS Elastic Beanstalk scaling es una característica que permite la gestión de aplicaciones y sus entornos, incluyendo el escalado, pero no está tan directamente enfocada en la gestión de instancias de EC2 como lo está EC2 Auto Scaling. Es más adecuada para aplicaciones que para el escalado de instancias en función de los patrones de tráfico.",
            "Amazon CloudWatch Alarms puede monitorear métricas y activar acciones basadas en umbrales, pero no escala directamente las instancias de EC2. Pueden usarse junto con EC2 Auto Scaling para activar acciones de escalado, pero no realizan el escalado por sí mismas.",
            "AWS Lambda auto-scaling está relacionado con la computación sin servidor y ajusta automáticamente el número de instancias de funciones Lambda en función del número de solicitudes entrantes. Sin embargo, no es aplicable para escalar instancias de EC2, que es el requisito en este escenario."
        ]
    },
    {
        "Question Number": "20",
        "Situation": "Una empresa ejecuta aplicaciones críticas en instancias de Amazon EC2 dentro de la región us-east-1 para garantizar disponibilidad continua y resiliencia. Para lograr una arquitectura altamente disponible, necesitan diseñar su implementación de EC2 para resistir posibles fallas en diferentes niveles, como hosts individuales, Zonas de Disponibilidad (AZ) o instancias.",
        "Question": "¿Cuál de los siguientes enfoques apoya mejor una arquitectura EC2 resiliente? (Elija dos.)",
        "Options": {
            "1": "Desplegar instancias de EC2 en múltiples Zonas de Disponibilidad dentro de la región para proporcionar aislamiento de fallas y redundancia en caso de una falla de AZ.",
            "2": "Desplegar instancias de EC2 en una sola Zona de Disponibilidad, pero utilizar EC2 Auto Scaling para reemplazar instancias fallidas de inmediato.",
            "3": "Colocar todas las instancias de EC2 en un host dedicado dentro de una Zona de Disponibilidad para maximizar la utilización de recursos y simplificar la gestión.",
            "4": "Configurar instancias de EC2 con volúmenes de almacenamiento de instancia solamente para asegurar un alto rendimiento, confiando en instantáneas para durabilidad.",
            "5": "Usar Elastic Load Balancing (ELB) junto con grupos de Auto Scaling distribuidos en múltiples Zonas de Disponibilidad para distribuir el tráfico y manejar fallas de instancias sin problemas."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Desplegar instancias de EC2 en múltiples Zonas de Disponibilidad dentro de la región para proporcionar aislamiento de fallas y redundancia en caso de una falla de AZ.",
            "Usar Elastic Load Balancing (ELB) junto con grupos de Auto Scaling distribuidos en múltiples Zonas de Disponibilidad para distribuir el tráfico y manejar fallas de instancias sin problemas."
        ],
        "Explanation": "Desplegar instancias de EC2 en múltiples Zonas de Disponibilidad dentro de la región proporciona aislamiento de fallas y redundancia en caso de una falla de AZ. Esto asegura que incluso si una AZ falla, la aplicación sigue disponible en las otras AZ. Usar Elastic Load Balancing (ELB) junto con grupos de Auto Scaling distribuidos en múltiples Zonas de Disponibilidad permite la distribución del tráfico y el manejo de fallas de instancias sin problemas. ELB asegura que el tráfico se distribuya uniformemente entre las instancias, y Auto Scaling asegura que el número de instancias se ajuste hacia arriba o hacia abajo según la demanda, proporcionando alta disponibilidad y tolerancia a fallas.",
        "Other Options": [
            "Desplegar instancias de EC2 en una sola Zona de Disponibilidad y utilizar EC2 Auto Scaling para reemplazar instancias fallidas de inmediato no proporciona tolerancia a fallas a nivel de AZ. Si la única AZ falla, toda la aplicación se vuelve no disponible.",
            "Colocar todas las instancias de EC2 en un host dedicado dentro de una Zona de Disponibilidad para maximizar la utilización de recursos y simplificar la gestión no proporciona tolerancia a fallas a nivel de AZ. Si la única AZ falla, toda la aplicación se vuelve no disponible.",
            "Configurar instancias de EC2 con volúmenes de almacenamiento de instancia solamente para asegurar un alto rendimiento, confiando en instantáneas para durabilidad, no proporciona tolerancia a fallas a nivel de AZ. Los volúmenes de almacenamiento de instancia son efímeros y los datos se pierden si la instancia se detiene o falla, haciendo que esta opción sea menos resiliente."
        ]
    },
    {
        "Question Number": "21",
        "Situation": "Una startup está construyendo un pipeline de procesamiento de datos en AWS que ingiere datos de varias fuentes, los procesa y almacena los resultados para análisis. El pipeline debe manejar cargas de trabajo variables y escalar automáticamente según el volumen de datos entrantes. La empresa quiere minimizar la carga operativa de gestionar servidores.",
        "Question": "¿Qué combinación de servicios de AWS debería recomendar el arquitecto de soluciones para este pipeline? (Elija DOS.)",
        "Options": {
            "1": "Instancias de Amazon EC2 con Auto Scaling",
            "2": "AWS Lambda",
            "3": "Amazon EMR",
            "4": "Amazon Kinesis Data Firehose",
            "5": "Amazon RDS"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "AWS Lambda",
            "Amazon Kinesis Data Firehose"
        ],
        "Explanation": "AWS Lambda es un servicio de computación sin servidor que ejecuta tu código en respuesta a eventos y gestiona automáticamente los recursos de computación subyacentes por ti, lo que se alinea con el requisito de la empresa de minimizar la carga operativa. También puede escalar automáticamente según el volumen de datos entrantes, lo que es ideal para manejar cargas de trabajo variables. Amazon Kinesis Data Firehose es la forma más fácil de cargar datos de transmisión de manera confiable en lagos de datos, almacenes de datos y servicios de análisis. Puede capturar, transformar y cargar datos de transmisión en servicios de AWS como Amazon S3, Amazon Redshift, Amazon Elasticsearch Service y Splunk, permitiendo análisis casi en tiempo real con herramientas de inteligencia empresarial y paneles existentes.",
        "Other Options": [
            "Instancias de Amazon EC2 con Auto Scaling: Aunque las instancias de EC2 con Auto Scaling pueden manejar cargas de trabajo variables y escalar según el volumen de datos entrantes, no minimizan la carga operativa de gestionar servidores, ya que la empresa aún necesitaría gestionar las instancias de EC2.",
            "Amazon EMR: Amazon EMR es una plataforma de big data nativa de la nube, que permite procesar grandes cantidades de datos de manera rápida y rentable a escala utilizando marcos distribuidos populares como Apache Spark y Hadoop. Sin embargo, requiere gestionar clústeres de servidores, lo que no se alinea con el requisito de la empresa de minimizar la carga operativa.",
            "Amazon RDS: Amazon RDS es un servicio de base de datos relacional, que no se alinea con los requisitos de un pipeline de procesamiento de datos que necesita manejar cargas de trabajo variables y escalar automáticamente según el volumen de datos entrantes."
        ]
    },
    {
        "Question Number": "22",
        "Situation": "Una plataforma de streaming de video experimenta picos de tráfico impredecibles, particularmente durante eventos en vivo que atraen a millones de espectadores. Para mantener el rendimiento y evitar interrupciones, la plataforma necesita escalar su capacidad de cómputo de manera rápida y eficiente. La aplicación de streaming actualmente se ejecuta en instancias de Amazon EC2 en múltiples Zonas de Disponibilidad, y el equipo quiere asegurarse de que estas instancias se aprovisionen automáticamente según la demanda, especialmente durante picos de tráfico inesperados, para prevenir la degradación del rendimiento.",
        "Question": "¿Qué configuración debería implementar el arquitecto de soluciones para cumplir con estos requisitos? (Elija dos.)",
        "Options": {
            "1": "Establecer un número fijo de instancias de EC2 en todas las Zonas de Disponibilidad para manejar cargas máximas",
            "2": "Usar un Grupo de Auto Scaling configurado con políticas de escalado dinámico basadas en métricas como la utilización de CPU para escalar automáticamente hacia arriba y hacia abajo a medida que fluctúa la demanda",
            "3": "Monitorear manualmente los patrones de tráfico y agregar instancias de EC2 según sea necesario durante eventos de alto tráfico",
            "4": "Alojar el contenido del sitio web en Amazon S3 y eliminar la necesidad de instancias de EC2 para manejar el tráfico del sitio web",
            "5": "Implementar escalado predictivo utilizando Amazon CloudWatch para anticipar picos de tráfico y ajustar la capacidad proactivamente"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Usar un Grupo de Auto Scaling configurado con políticas de escalado dinámico basadas en métricas como la utilización de CPU para escalar automáticamente hacia arriba y hacia abajo a medida que fluctúa la demanda",
            "Implementar escalado predictivo utilizando Amazon CloudWatch para anticipar picos de tráfico y ajustar la capacidad proactivamente"
        ],
        "Explanation": "Los Grupos de Auto Scaling en AWS permiten el escalado dinámico de instancias de EC2 según la demanda. Esto significa que a medida que aumenta la demanda, se pueden aprovisionar más instancias para manejar la carga, y a medida que disminuye la demanda, se pueden terminar instancias para ahorrar costos. Esto es ideal para manejar picos de tráfico impredecibles. El escalado predictivo en Amazon CloudWatch utiliza algoritmos de aprendizaje automático para predecir la demanda futura y ajustar la capacidad con anticipación. Esto es útil para anticipar picos de tráfico y escalar proactivamente para satisfacer la demanda.",
        "Other Options": [
            "Establecer un número fijo de instancias de EC2 en todas las Zonas de Disponibilidad para manejar cargas máximas no es una solución eficiente. No toma en cuenta las fluctuaciones en la demanda y puede llevar a un sobreaprovisionamiento (desperdicio de recursos cuando la demanda es baja) o subaprovisionamiento (no tener suficientes recursos cuando la demanda es alta).",
            "Monitorear manualmente los patrones de tráfico y agregar instancias de EC2 según sea necesario durante eventos de alto tráfico no es una solución escalable ni eficiente. Requiere monitoreo constante e intervención manual, y puede haber retrasos en el escalado que podrían afectar el rendimiento.",
            "Alojar el contenido del sitio web en Amazon S3 y eliminar la necesidad de instancias de EC2 para manejar el tráfico del sitio web no es una solución adecuada para una plataforma de streaming de video. Aunque S3 es excelente para el alojamiento de sitios web estáticos, una plataforma de streaming de video requiere entrega de contenido dinámico y capacidad de cómputo, que es mejor manejada por instancias de EC2."
        ]
    },
    {
        "Question Number": "23",
        "Situation": "Una empresa está considerando AWS Direct Connect para mejorar la consistencia y velocidad de la conectividad de red entre su centro de datos local y AWS.",
        "Question": "¿Cuál de las siguientes describe con precisión un beneficio y una limitación de usar AWS Direct Connect para este propósito?",
        "Options": {
            "1": "AWS Direct Connect proporciona transferencia de datos segura a través de una línea privada y dedicada con resiliencia incorporada; sin embargo, está limitado a 1 Gbps de ancho de banda por conexión.",
            "2": "AWS Direct Connect puede proporcionar conectividad de alta velocidad y baja latencia directamente a los servicios públicos y privados de AWS sin dependencia de internet; sin embargo, no proporciona resiliencia de forma inherente, ya que depende de cables físicos que pueden verse afectados por interrupciones.",
            "3": "AWS Direct Connect ofrece transferencia de datos de alta velocidad y resiliente entre AWS y entornos locales, con la opción de conmutación por error automática; sin embargo, solo está disponible en regiones seleccionadas de AWS en todo el mundo.",
            "4": "AWS Direct Connect proporciona una solución rentable para la transferencia de datos basada en internet, permitiendo que los datos sean enrutados a través de puntos finales públicos de AWS; sin embargo, puede enfrentar una latencia más alta que las soluciones basadas en VPN debido a la infraestructura compartida."
        },
        "Correct Answer": "AWS Direct Connect puede proporcionar conectividad de alta velocidad y baja latencia directamente a los servicios públicos y privados de AWS sin dependencia de internet; sin embargo, no proporciona resiliencia de forma inherente, ya que depende de cables físicos que pueden verse afectados por interrupciones.",
        "Explanation": "AWS Direct Connect está diseñado para ofrecer conexiones de alta velocidad y baja latencia a los servicios de AWS, evitando el internet público, lo que mejora el rendimiento y la fiabilidad. Sin embargo, aunque proporciona una conexión dedicada, no incluye automáticamente redundancia o resiliencia; si la conexión física se interrumpe, puede llevar a cortes. Por lo tanto, los usuarios deben implementar medidas adicionales, como usar múltiples conexiones o estrategias de conmutación por error, para garantizar la resiliencia.",
        "Other Options": [
            "Si bien AWS Direct Connect proporciona transferencia de datos segura a través de una línea privada, no tiene una limitación estricta de 1 Gbps de ancho de banda por conexión. AWS Direct Connect ofrece múltiples velocidades de conexión, incluyendo 10 Gbps y más, dependiendo de los requisitos.",
            "AWS Direct Connect ofrece opciones para la resiliencia, como la capacidad de crear conexiones redundantes en diferentes ubicaciones. Además, está disponible en muchas regiones de AWS, no solo en seleccionadas, lo que mejora su accesibilidad.",
            "AWS Direct Connect no es una solución basada en internet; proporciona una conexión dedicada que típicamente resulta en menor latencia en comparación con soluciones VPN. No enruta datos a través de puntos finales públicos, lo que es una ventaja clave de usar Direct Connect."
        ]
    },
    {
        "Question Number": "24",
        "Situation": "Una corporación multinacional está planeando desplegar una nueva aplicación orientada al cliente en AWS que servirá a usuarios en América del Norte, Europa y Asia. Para optimizar el rendimiento de la aplicación y cumplir con las regulaciones de residencia de datos en cada región, la corporación quiere asegurarse de que los datos de los usuarios sean procesados y almacenados cerca de las ubicaciones geográficas de los usuarios. Además, quieren minimizar la latencia sirviendo a la base de usuarios de cada región con la infraestructura más cercana.",
        "Question": "¿Cuál es la estrategia más apropiada para desplegar esta aplicación?",
        "Options": {
            "1": "Desplegar la aplicación en una sola Región de AWS con instancias de alta capacidad, aprovechando los recursos de la región para manejar a todos los usuarios globales desde una ubicación centralizada",
            "2": "Desplegar la aplicación en múltiples Regiones de AWS, asegurando que cada región tenga infraestructura local para servir a su base de usuarios y cumplir con los requisitos de residencia de datos",
            "3": "Desplegar la aplicación en una Región central de AWS, luego usar una Red de Entrega de Contenido (CDN) para almacenar en caché datos en otras regiones, mejorando las velocidades de acceso",
            "4": "Usar Zonas de Disponibilidad dentro de una sola Región de AWS para servir a usuarios globales, asegurando redundancia sin desplegar en múltiples regiones"
        },
        "Correct Answer": "Desplegar la aplicación en múltiples Regiones de AWS, asegurando que cada región tenga infraestructura local para servir a su base de usuarios y cumplir con los requisitos de residencia de datos",
        "Explanation": "Desplegar la aplicación en múltiples Regiones de AWS permite a la corporación colocar el procesamiento y almacenamiento de datos de los usuarios cerca de los usuarios en América del Norte, Europa y Asia. Esta estrategia no solo optimiza el rendimiento de la aplicación al reducir la latencia para los usuarios que acceden a la aplicación, sino que también asegura el cumplimiento de las regulaciones de residencia de datos que requieren que los datos sean almacenados dentro de ubicaciones geográficas específicas. Al tener infraestructura local en cada región, la corporación puede servir efectivamente a su base de usuarios mientras cumple con los requisitos legales.",
        "Other Options": [
            "Desplegar la aplicación en una sola Región de AWS con instancias de alta capacidad crearía un punto de falla centralizado y aumentaría la latencia para los usuarios ubicados lejos de esa región. Este enfoque no aborda las regulaciones de residencia de datos, que pueden requerir que los datos sean almacenados en ubicaciones geográficas específicas.",
            "Usar una Red de Entrega de Contenido (CDN) para almacenar en caché datos en otras regiones puede mejorar las velocidades de acceso para contenido estático, pero no resuelve el problema de residencia de datos y requisitos de procesamiento. El procesamiento y almacenamiento de datos dinámicos aún deben ocurrir en las regiones apropiadas para cumplir con las regulaciones.",
            "Usar Zonas de Disponibilidad dentro de una sola Región de AWS proporciona redundancia y alta disponibilidad, pero no aborda la necesidad de distribución geográfica. Esta opción aún resultaría en una mayor latencia para los usuarios ubicados lejos de esa única región y no cumpliría con los requisitos de residencia de datos."
        ]
    },
    {
        "Question Number": "25",
        "Situation": "Una organización de atención médica está buscando una solución de respaldo integral para datos sensibles de pacientes almacenados en múltiples servicios de AWS, incluidos instancias de Amazon EC2, bases de datos RDS y sistemas de archivos EFS. Requieren una solución que pueda gestionar respaldos a través de múltiples cuentas y regiones de AWS, asegurar la integridad de los datos con cumplimiento de escritura una vez, lectura muchas veces (WORM) para prevenir cambios accidentales, y ofrecer recuperación en un punto en el tiempo para satisfacer las necesidades regulatorias y operativas de protección de datos críticos.",
        "Question": "¿Qué configuración de servicio de AWS cumpliría mejor con estos requisitos?",
        "Options": {
            "1": "Configurar instantáneas manuales para cada recurso y habilitar la replicación entre regiones para mayor redundancia",
            "2": "Utilizar AWS Backup con Planes de Respaldo, Vault Lock para cumplimiento WORM, y Recuperación en un Punto en el Tiempo (PITR) para respaldos y recuperaciones confiables",
            "3": "Almacenar respaldos en Amazon S3 con versionado y replicación habilitados para asegurar la integridad de los datos y disponibilidad entre regiones",
            "4": "Habilitar AWS CloudTrail para registro y crear procedimientos de recuperación manual basados en datos de registro"
        },
        "Correct Answer": "Utilizar AWS Backup con Planes de Respaldo, Vault Lock para cumplimiento WORM, y Recuperación en un Punto en el Tiempo (PITR) para respaldos y recuperaciones confiables",
        "Explanation": "AWS Backup está diseñado específicamente para centralizar y automatizar el respaldo de recursos de AWS a través de múltiples cuentas y regiones. Permite a los usuarios crear planes de respaldo que definen la frecuencia de respaldo y las políticas de retención. Además, AWS Backup soporta Vault Lock, que proporciona cumplimiento WORM para prevenir cambios accidentales en los datos de respaldo, asegurando la integridad de los datos. La función de Recuperación en un Punto en el Tiempo (PITR) permite restaurar datos a un punto específico en el tiempo, lo cual es crucial para satisfacer las necesidades regulatorias y operativas de protección de datos críticos.",
        "Other Options": [
            "Configurar instantáneas manuales para cada recurso y habilitar la replicación entre regiones puede proporcionar cierto nivel de redundancia, pero carece de automatización y gestión centralizada. Este enfoque es laborioso y no asegura cumplimiento WORM ni recuperación en un punto en el tiempo, lo que lo hace menos adecuado para las necesidades de respaldo integral de la organización.",
            "Almacenar respaldos en Amazon S3 con versionado y replicación habilitados puede ayudar con la integridad de los datos y la disponibilidad, pero no proporciona las características de gestión necesarias para respaldos a través de múltiples servicios o cuentas de AWS. Además, no ofrece inherentemente cumplimiento WORM ni recuperación en un punto en el tiempo, que son críticos para datos sensibles de pacientes.",
            "Habilitar AWS CloudTrail para registro y crear procedimientos de recuperación manual basados en datos de registro no es una solución de respaldo. CloudTrail es principalmente para auditoría y monitoreo de llamadas a la API, y aunque puede ayudar a entender los cambios realizados en los recursos, no proporciona un mecanismo para respaldar o recuperar datos, ni cumple con los requisitos de cumplimiento WORM o recuperación en un punto en el tiempo."
        ]
    },
    {
        "Question Number": "26",
        "Situation": "Una empresa de tecnología está configurando un grupo de Auto Scaling para sus instancias de EC2. Su objetivo es implementar una configuración que permita actualizaciones sin necesidad de recrear toda la infraestructura cada vez que sea necesario un cambio.",
        "Question": "¿Qué opción debería seleccionar la empresa para facilitar las actualizaciones de configuración de manera eficiente, y cuál es la justificación para esta elección?",
        "Options": {
            "1": "Utilizar Configuraciones de Lanzamiento, ya que soportan versionado y permiten actualizaciones sin necesidad de recreación.",
            "2": "Emplear Plantillas de Lanzamiento, ya que ofrecen capacidades de versionado, permitiendo actualizaciones de configuración sin crear nuevas plantillas.",
            "3": "Elegir Configuraciones de Lanzamiento por su facilidad de gestión y características de versionado inherentes.",
            "4": "Optar por Plantillas de Lanzamiento, que permiten actualizaciones en vivo directamente dentro del grupo de Auto Scaling sin requerir control de versiones."
        },
        "Correct Answer": "Emplear Plantillas de Lanzamiento, ya que ofrecen capacidades de versionado, permitiendo actualizaciones de configuración sin crear nuevas plantillas.",
        "Explanation": "Las Plantillas de Lanzamiento son la opción preferida para configurar grupos de Auto Scaling porque soportan versionado, lo que permite a los usuarios crear múltiples versiones de una plantilla. Esto significa que cuando se necesitan cambios de configuración, la empresa puede simplemente crear una nueva versión de la plantilla existente sin tener que recrear toda la infraestructura. Esta característica agiliza el proceso de actualización de configuraciones y mejora la eficiencia de gestión, facilitando la reversión a versiones anteriores si es necesario.",
        "Other Options": [
            "Utilizar Configuraciones de Lanzamiento, ya que soportan versionado y permiten actualizaciones sin necesidad de recreación. (Incorrecto porque las Configuraciones de Lanzamiento no soportan versionado; son estáticas y no pueden ser actualizadas una vez creadas. Cualquier cambio requiere la creación de una nueva Configuración de Lanzamiento.)",
            "Elegir Configuraciones de Lanzamiento por su facilidad de gestión y características de versionado inherentes. (Incorrecto porque las Configuraciones de Lanzamiento carecen de capacidades de versionado, lo que las hace menos flexibles para actualizaciones de configuración en comparación con las Plantillas de Lanzamiento.)",
            "Optar por Plantillas de Lanzamiento, que permiten actualizaciones en vivo directamente dentro del grupo de Auto Scaling sin requerir control de versiones. (Incorrecto porque aunque las Plantillas de Lanzamiento permiten el versionado, no permiten actualizaciones en vivo directamente dentro del grupo de Auto Scaling; las actualizaciones aún requieren crear una nueva versión de la plantilla.)"
        ]
    },
    {
        "Question Number": "27",
        "Situation": "Un equipo de investigación está ejecutando simulaciones de modelado científico altamente complejas que requieren un poder de CPU extremadamente alto y velocidades de procesamiento rápidas para generar resultados precisos rápidamente. Estas simulaciones son intensivas en computación e incluyen tareas como codificación de medios, dinámica de fluidos computacional y entrenamiento de modelos de aprendizaje automático. El equipo no necesita un alto soporte de memoria o GPU, ya que estas tareas son principalmente dependientes de la CPU.",
        "Question": "¿Qué categoría de instancia de EC2 se adaptaría mejor a sus necesidades?",
        "Options": {
            "1": "Uso General",
            "2": "Optimizado para Memoria",
            "3": "Optimizado para Computación",
            "4": "Computación Acelerada"
        },
        "Correct Answer": "Optimizado para Computación",
        "Explanation": "La categoría de instancia de EC2 Optimizado para Computación está diseñada específicamente para tareas intensivas en computación que requieren un alto rendimiento de CPU. Dado que las simulaciones del equipo de investigación son dependientes de la CPU y no requieren un alto soporte de memoria o GPU, las instancias Optimizado para Computación proporcionarán la potencia de procesamiento y velocidad necesarias para manejar eficientemente tareas como codificación de medios, dinámica de fluidos computacional y entrenamiento de modelos de aprendizaje automático. Estas instancias son ideales para cargas de trabajo que exigen alta capacidad de cómputo y pueden reducir significativamente el tiempo necesario para generar resultados precisos.",
        "Other Options": [
            "Las instancias de Uso General proporcionan un equilibrio de recursos de computación, memoria y red, lo que las hace adecuadas para una variedad de cargas de trabajo, pero no están específicamente optimizadas para tareas intensivas en computación. Pueden no ofrecer el alto rendimiento de CPU requerido para las simulaciones descritas.",
            "Las instancias Optimizado para Memoria están diseñadas para cargas de trabajo que requieren alta capacidad de memoria y rendimiento, como bases de datos en memoria y análisis de grandes datos en tiempo real. Dado que el equipo de investigación no necesita un alto soporte de memoria, esta categoría no es adecuada para sus simulaciones intensivas en computación.",
            "Las instancias de Computación Acelerada están diseñadas para cargas de trabajo que se benefician de aceleradores de hardware, como GPUs o FPGAs. Estas instancias son ideales para tareas como inferencia de aprendizaje automático y procesamiento gráfico, pero no son necesarias para tareas dependientes de la CPU, lo que las hace menos apropiadas para las necesidades del equipo."
        ]
    },
    {
        "Question Number": "28",
        "Situation": "Una empresa de logística necesita procesar datos de vehículos de entrega en tiempo real para monitorear rutas y condiciones de tráfico. Quieren procesar los datos lo más cerca posible de la fuente para reducir la latencia y minimizar la cantidad de datos enviados a la nube.",
        "Question": "¿Qué estrategia de computación distribuida satisfaría mejor estas necesidades?",
        "Options": {
            "1": "Ejecutar todo el procesamiento de datos en instancias de Amazon EC2 en la región de AWS más cercana",
            "2": "Usar procesamiento en el borde para manejar datos localmente en los dispositivos",
            "3": "Enviar datos a AWS Lambda para procesamiento sin servidor",
            "4": "Usar un rack de AWS Outposts en el centro de datos de la empresa"
        },
        "Correct Answer": "Usar procesamiento en el borde para manejar datos localmente en los dispositivos",
        "Explanation": "El procesamiento en el borde permite que los datos se procesen lo más cerca posible de la fuente, lo cual es crucial para el monitoreo en tiempo real de los vehículos de entrega. Al manejar los datos localmente en los dispositivos, la empresa de logística puede reducir significativamente la latencia, ya que los datos no necesitan viajar a un servidor en la nube distante para su procesamiento. Este enfoque también minimiza la cantidad de datos enviados a la nube, alineándose perfectamente con las necesidades de eficiencia y velocidad en el procesamiento de datos de la empresa.",
        "Other Options": [
            "Ejecutar todo el procesamiento de datos en instancias de Amazon EC2 en la región de AWS más cercana introduciría latencia debido a la distancia que deben recorrer los datos para llegar a la nube. Esta opción no cumple con el requisito de procesamiento en tiempo real tan eficazmente como el procesamiento en el borde.",
            "Enviar datos a AWS Lambda para procesamiento sin servidor también implicaría latencia, ya que los datos deben ser transmitidos a la nube para su procesamiento. Aunque AWS Lambda es eficiente para muchos casos de uso, no es óptimo para el procesamiento en tiempo real de datos generados por vehículos de entrega que necesitan análisis inmediato.",
            "Usar un rack de AWS Outposts en el centro de datos de la empresa podría proporcionar algunos beneficios de procesamiento local, pero aún requiere una configuración física y puede no ser tan ágil o rentable como el verdadero procesamiento en el borde. Además, puede no estar tan cerca de la fuente de datos como los dispositivos de borde, lo que puede llevar a una mayor latencia en comparación con el procesamiento directamente en los dispositivos."
        ]
    },
    {
        "Question Number": "29",
        "Situation": "Una empresa está alojando dos aplicaciones web, cada una con un nombre de dominio HTTPS único. Necesitan reducir el número de balanceadores de carga que utilizan, mientras mantienen el soporte HTTPS para ambas aplicaciones.",
        "Question": "¿Qué tipo de balanceador de carga de AWS sería el más adecuado para este requisito, y por qué?",
        "Options": {
            "1": "Classic Load Balancer (CLB), porque permite la consolidación de múltiples dominios en un solo balanceador de carga.",
            "2": "Application Load Balancer (ALB), porque soporta el enrutamiento basado en host con Server Name Indication (SNI), permitiendo múltiples dominios HTTPS en un solo balanceador de carga.",
            "3": "Network Load Balancer (NLB), porque proporciona enrutamiento de capa 4 y puede manejar múltiples dominios HTTPS.",
            "4": "Elastic Load Balancer (ELB) con sesiones persistentes, ya que permite múltiples grupos de destino bajo el mismo balanceador de carga."
        },
        "Correct Answer": "Application Load Balancer (ALB), porque soporta el enrutamiento basado en host con Server Name Indication (SNI), permitiendo múltiples dominios HTTPS en un solo balanceador de carga.",
        "Explanation": "El Application Load Balancer (ALB) está diseñado específicamente para manejar tráfico HTTP y HTTPS y soporta características avanzadas de enrutamiento, incluyendo el enrutamiento basado en host. Esto significa que puede enrutar solicitudes a diferentes grupos de destino basándose en el nombre de host en la solicitud, lo cual es esencial para alojar múltiples aplicaciones web con nombres de dominio HTTPS únicos. Además, el ALB soporta Server Name Indication (SNI), lo que le permite servir múltiples certificados SSL en una sola dirección IP, habilitando conexiones seguras para cada dominio sin necesidad de balanceadores de carga separados.",
        "Other Options": [
            "Classic Load Balancer (CLB) no soporta enrutamiento basado en host ni SNI, lo que lo hace menos adecuado para manejar múltiples dominios HTTPS de manera eficiente. Está diseñado principalmente para balanceo de carga básico y carece de las características avanzadas necesarias para este escenario.",
            "Network Load Balancer (NLB) opera en la capa 4 y está optimizado para manejar tráfico TCP. Aunque puede manejar múltiples dominios, no proporciona las características necesarias para la terminación SSL o el enrutamiento basado en host, que son cruciales para gestionar el tráfico HTTPS de manera efectiva.",
            "Elastic Load Balancer (ELB) es un término general que abarca tanto ALB como NLB. Aunque se pueden configurar sesiones persistentes, no abordan el requisito de soportar múltiples dominios HTTPS en un solo balanceador de carga. El ALB es el tipo específico que satisface las necesidades de este escenario."
        ]
    },
    {
        "Question Number": "30",
        "Situation": "Una empresa está planeando migrar sus aplicaciones locales a AWS. Estas aplicaciones dependen en gran medida de Active Directory para la autenticación de usuarios y la gestión de grupos. El equipo de TI quiere una solución administrada en AWS que soporte hasta 3,000 usuarios, se integre con Amazon Workspaces y no requiera una integración compleja en las instalaciones. Además, necesitan una solución que pueda soportar entornos de Windows con el mismo nombre de usuario y contraseña para la gestión centralizada de recursos.",
        "Question": "¿Qué opción de AWS Directory Service cumpliría mejor con estos requisitos?",
        "Options": {
            "1": "Simple AD con una instancia pequeña para gestión de directorios independiente",
            "2": "AWS Managed Microsoft AD con implementación multi-AZ",
            "3": "AWS SSO (Single Sign-On) para acceso entre cuentas",
            "4": "Amazon Cognito para gestión de grupos de usuarios"
        },
        "Correct Answer": "AWS Managed Microsoft AD con implementación multi-AZ",
        "Explanation": "AWS Managed Microsoft AD está diseñado para proporcionar un Active Directory completamente administrado en la nube de AWS. Soporta entornos de Windows y permite una integración fluida con aplicaciones que dependen de Active Directory para la autenticación y gestión de grupos. Puede soportar hasta 50,000 usuarios, lo que excede el requisito de 3,000 usuarios. Además, se integra bien con Amazon Workspaces, permitiendo a los usuarios tener el mismo nombre de usuario y contraseña para la gestión centralizada, cumpliendo con las necesidades de la empresa sin requerir una integración compleja en las instalaciones. La implementación multi-AZ asegura alta disponibilidad y resiliencia.",
        "Other Options": [
            "Simple AD con una instancia pequeña es un servicio de directorio básico que solo soporta un conjunto limitado de características de Active Directory y no es adecuado para aplicaciones que requieren capacidades completas de Active Directory. También no soporta el mismo nivel de integración con Amazon Workspaces como AWS Managed Microsoft AD.",
            "AWS SSO (Single Sign-On) está diseñado principalmente para gestionar el acceso a múltiples cuentas y aplicaciones de AWS, pero no proporciona las características completas de Active Directory necesarias para la autenticación de usuarios y la gestión de grupos en un entorno de Windows. No es un reemplazo directo de Active Directory.",
            "Amazon Cognito se centra en la autenticación y gestión de usuarios para aplicaciones web y móviles, pero no proporciona las capacidades de Active Directory requeridas para las aplicaciones de la empresa. Es más adecuado para grupos de usuarios e identidades federadas en lugar de gestionar entornos de Windows con integración de Active Directory."
        ]
    },
    {
        "Question Number": "31",
        "Situation": "Una empresa está implementando una aplicación web en múltiples instancias de Amazon EC2 en diferentes Zonas de Disponibilidad. La aplicación necesita un sistema de archivos compartido para almacenar y acceder al contenido generado por los usuarios. La empresa también desea la flexibilidad de conectar su centro de datos local al almacenamiento compartido en AWS.",
        "Question": "¿Qué solución de AWS debería recomendar el arquitecto de soluciones para cumplir con estos requisitos?",
        "Options": {
            "1": "Amazon EBS con Multi-Attach entre Zonas de Disponibilidad",
            "2": "Amazon EFS con puntos de montaje en cada Zona de Disponibilidad y acceso a través de VPN o Direct Connect para conectividad local",
            "3": "Amazon S3 con Transfer Acceleration para acceso entre regiones",
            "4": "Amazon RDS con réplicas de lectura en cada Zona de Disponibilidad"
        },
        "Correct Answer": "Amazon EFS con puntos de montaje en cada Zona de Disponibilidad y acceso a través de VPN o Direct Connect para conectividad local",
        "Explanation": "Amazon EFS (Elastic File System) es un servicio de almacenamiento de archivos totalmente gestionado que se puede montar en múltiples instancias de EC2 en diferentes Zonas de Disponibilidad, proporcionando un sistema de archivos compartido para aplicaciones. Soporta protocolos NFS (Network File System), lo que lo hace adecuado para aplicaciones que requieren acceso compartido a archivos. Además, EFS se puede acceder desde centros de datos locales a través de una VPN o AWS Direct Connect, cumpliendo con el requisito de conectividad entre el almacenamiento local y AWS.",
        "Other Options": [
            "Amazon EBS (Elastic Block Store) con Multi-Attach permite que múltiples instancias de EC2 se conecten a un solo volumen de EBS, pero está limitado a una sola Zona de Disponibilidad. Esto no cumple con el requisito de un sistema de archivos compartido entre múltiples Zonas de Disponibilidad.",
            "Amazon S3 (Simple Storage Service) es un servicio de almacenamiento de objetos y, aunque puede almacenar contenido generado por usuarios, no proporciona una interfaz de sistema de archivos tradicional que las aplicaciones suelen requerir para el acceso compartido. Transfer Acceleration es para acelerar las cargas y descargas, pero no aborda la necesidad de un sistema de archivos compartido entre instancias de EC2.",
            "Amazon RDS (Relational Database Service) es un servicio de base de datos gestionado y, aunque puede tener réplicas de lectura en diferentes Zonas de Disponibilidad para alta disponibilidad, no es adecuado para almacenar contenido generado por usuarios en un formato de sistema de archivos compartido. RDS está diseñado para datos estructurados y casos de uso de bases de datos relacionales, no para almacenamiento de archivos."
        ]
    },
    {
        "Question Number": "32",
        "Situation": "Una empresa de medios está transmitiendo contenido de video a nivel global y necesita mejorar la velocidad de entrega y reducir la latencia para los usuarios en diferentes regiones geográficas. La empresa está viendo una alta demanda durante las horas pico, y el almacenamiento en búfer de contenido está afectando la experiencia del usuario. También necesitan reducir la carga en sus servidores de origen para prevenir el agotamiento de recursos.",
        "Question": "¿Qué servicio de AWS debería usar la empresa para lograr estos objetivos y qué beneficios ofrece?",
        "Options": {
            "1": "Usar Amazon CloudFront como un CDN para almacenar en caché contenido en ubicaciones de borde alrededor del mundo, reduciendo la latencia y descargando tráfico de los servidores de origen.",
            "2": "Usar Amazon Route 53 con enrutamiento por geolocalización para dirigir a los usuarios al bucket de S3 más cercano, donde se almacena el contenido de video.",
            "3": "Usar Amazon S3 para almacenamiento y dirigir a los usuarios a una sola instancia de EC2 en una región para servir todo el contenido de video.",
            "4": "Usar AWS Direct Connect para establecer conexiones de red dedicadas a todos los clientes a nivel global para una entrega de contenido más rápida."
        },
        "Correct Answer": "Usar Amazon CloudFront como un CDN para almacenar en caché contenido en ubicaciones de borde alrededor del mundo, reduciendo la latencia y descargando tráfico de los servidores de origen.",
        "Explanation": "Amazon CloudFront es una Red de Entrega de Contenido (CDN) que almacena en caché contenido en ubicaciones de borde a nivel global. Al usar CloudFront, la empresa de medios puede entregar contenido de video más cerca de los usuarios, reduciendo significativamente la latencia y mejorando la velocidad de entrega. Este mecanismo de almacenamiento en caché también descarga tráfico de los servidores de origen, lo que ayuda a prevenir el agotamiento de recursos durante los momentos de alta demanda. En general, CloudFront mejora la experiencia del usuario al minimizar el almacenamiento en búfer y asegurar un acceso más rápido al contenido.",
        "Other Options": [
            "Usar Amazon Route 53 con enrutamiento por geolocalización podría ayudar a dirigir a los usuarios a los recursos más cercanos, pero no almacena en caché contenido ni reduce la latencia de manera efectiva. Principalmente gestiona el enrutamiento DNS y no aborda los problemas de almacenamiento en búfer o la carga en los servidores de origen.",
            "Usar Amazon S3 para almacenamiento y dirigir a los usuarios a una sola instancia de EC2 en una región no sería efectivo para la entrega de contenido global. Este enfoque podría llevar a una alta latencia para los usuarios lejanos de la instancia de EC2 y no aliviaría la carga en los servidores de origen, resultando en posibles problemas de rendimiento durante las horas pico.",
            "AWS Direct Connect proporciona conexiones de red dedicadas, pero no está diseñado para la entrega de contenido. Es más adecuado para establecer conexiones privadas entre centros de datos locales y AWS, en lugar de mejorar la velocidad de entrega de contenido a los usuarios finales en todo el mundo."
        ]
    },
    {
        "Question Number": "33",
        "Situation": "Una organización desea establecer una conexión segura entre su centro de datos local y su entorno de AWS. La conexión debe soportar alta disponibilidad y un enlace de baja latencia para datos críticos de aplicaciones.",
        "Question": "¿Qué solución cumple mejor con estos requisitos?",
        "Options": {
            "1": "Configurar una conexión VPN a través de internet",
            "2": "Usar AWS Direct Connect con una conexión redundante",
            "3": "Configurar un Elastic Load Balancer para distribuir el tráfico",
            "4": "Usar una conexión de emparejamiento de VPC"
        },
        "Correct Answer": "Usar AWS Direct Connect con una conexión redundante",
        "Explanation": "AWS Direct Connect proporciona una conexión de red dedicada desde el centro de datos local a AWS, que es ideal para requisitos de alta disponibilidad y baja latencia. Al usar Direct Connect con una conexión redundante, la organización puede asegurarse de que haya un enlace de respaldo disponible en caso de que falle el enlace principal, manteniendo así la alta disponibilidad. Esta solución está específicamente diseñada para conectividad a nivel empresarial y puede manejar datos críticos de aplicaciones de manera eficiente.",
        "Other Options": [
            "Configurar una conexión VPN a través de internet puede proporcionar una conexión segura, pero típicamente no garantiza baja latencia o alta disponibilidad en comparación con una conexión dedicada como AWS Direct Connect. Las conexiones VPN pueden verse afectadas por el tráfico de internet y pueden introducir variabilidad en la latencia.",
            "Configurar un Elastic Load Balancer no es relevante para establecer una conexión directa entre el centro de datos local y AWS. Los balanceadores de carga se utilizan para distribuir el tráfico de aplicaciones entrantes entre múltiples objetivos, pero no facilitan la conexión segura necesaria en este escenario.",
            "Usar una conexión de emparejamiento de VPC es útil para conectar dos VPC dentro de AWS, pero no aborda el requisito de conectar un centro de datos local a AWS. El emparejamiento de VPC no proporciona una conexión dedicada y de baja latencia y no es adecuado para este escenario."
        ]
    },
    {
        "Question Number": "34",
        "Situation": "Una empresa necesita otorgar acceso temporal a un bucket de S3 a contratistas externos. El acceso debe expirar automáticamente después de un período específico y debe limitarse a acciones específicas.",
        "Question": "¿Qué soluciones debería implementar la empresa? (Elige dos.)",
        "Options": {
            "1": "Crear usuarios de IAM para cada contratista y adjuntar una política de acceso a S3",
            "2": "Usar AWS IAM Identity Center (AWS Single Sign-On) con un rol de acceso temporal",
            "3": "Generar URLs prefirmadas para los objetos de S3 a los que necesitan acceder los contratistas",
            "4": "Adjuntar una política de bucket con una condición basada en tiempo para restringir el acceso",
            "5": "Implementar credenciales de seguridad temporales usando AWS Security Token Service (STS)"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Generar URLs prefirmadas para los objetos de S3 a los que necesitan acceder los contratistas",
            "Implementar credenciales de seguridad temporales usando AWS Security Token Service (STS)"
        ],
        "Explanation": "Las URLs prefirmadas proporcionan una forma de otorgar acceso temporal a objetos específicos de S3. Se generan con un tiempo de expiración, después del cual ya no son válidas. Esto se alinea con el requisito de que el acceso expire automáticamente después de un período específico. AWS Security Token Service (STS) es un servicio web que permite solicitar credenciales temporales y de privilegios limitados para usuarios de AWS Identity and Access Management (IAM). Puedes especificar los permisos para estas credenciales de seguridad temporales, lo que hace posible limitar las acciones que pueden realizar los contratistas.",
        "Other Options": [
            "Crear usuarios de IAM para cada contratista y adjuntar una política de acceso a S3 no es una solución temporal y no expira automáticamente. Esto requeriría intervención manual para revocar el acceso.",
            "Usar AWS IAM Identity Center (AWS Single Sign-On) con un rol de acceso temporal podría usarse para otorgar acceso temporal, pero no limita inherentemente el acceso a acciones específicas u objetos de S3.",
            "Adjuntar una política de bucket con una condición basada en tiempo para restringir el acceso no es una solución viable, ya que AWS no admite condiciones basadas en tiempo en las políticas de bucket."
        ]
    },
    {
        "Question Number": "35",
        "Situation": "Una empresa está diseñando una aplicación web y quiere implementar una arquitectura de múltiples capas para separar preocupaciones y mejorar la escalabilidad. Esperan ver cargas de trabajo fluctuantes basadas en la demanda de los usuarios, y la arquitectura necesita escalar automáticamente según los patrones de tráfico. La empresa también busca mejorar la seguridad aislando capas para prevenir el acceso no autorizado.",
        "Question": "¿Cuál de las siguientes describe mejor la arquitectura que debería implementar la empresa? (Elige dos.)",
        "Options": {
            "1": "Usar una instancia de Amazon EC2 como la capa web, Amazon RDS como la capa de base de datos, y un Application Load Balancer (ALB) para distribuir el tráfico entre las instancias en la capa web.",
            "2": "Usar funciones de AWS Lambda para ambas capas, web y de base de datos, para reducir la gestión de infraestructura y permitir escalado automático.",
            "3": "Usar Amazon S3 para almacenamiento, instancias de Amazon EC2 para computación, y AWS Direct Connect para comunicación segura entre capas.",
            "4": "Implementar una VPC con subredes públicas para la capa web y subredes privadas para las capas de aplicación y base de datos, usar grupos de Auto Scaling para las capas web y de aplicación, y desplegar una instancia de RDS en la subred privada.",
            "5": "Usar una sola instancia de EC2 para ambas capas, web y de base de datos, y conectarlas a través de una Virtual Private Cloud (VPC) para aislamiento."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Usar una instancia de Amazon EC2 como la capa web, Amazon RDS como la capa de base de datos, y un Application Load Balancer (ALB) para distribuir el tráfico entre las instancias en la capa web.",
            "Implementar una VPC con subredes públicas para la capa web y subredes privadas para las capas de aplicación y base de datos, usar grupos de Auto Scaling para las capas web y de aplicación, y desplegar una instancia de RDS en la subred privada."
        ],
        "Explanation": "La primera respuesta correcta utiliza Amazon EC2 para la capa web, que puede manejar cargas de trabajo fluctuantes y puede escalar automáticamente. Amazon RDS se utiliza para la capa de base de datos, que proporciona una solución escalable y segura para la gestión de bases de datos. El Application Load Balancer distribuye el tráfico entre las instancias en la capa web, lo que ayuda a gestionar cargas de trabajo fluctuantes. La segunda respuesta correcta utiliza una VPC con subredes públicas para la capa web y subredes privadas para las capas de aplicación y base de datos, lo que proporciona aislamiento y mejora la seguridad. Se utilizan grupos de Auto Scaling para las capas web y de aplicación, que pueden manejar cargas de trabajo fluctuantes y pueden escalar automáticamente. Se despliega una instancia de RDS en la subred privada, lo que proporciona una solución escalable y segura para la gestión de bases de datos.",
        "Other Options": [
            "Usar funciones de AWS Lambda para ambas capas, web y de base de datos, puede reducir la gestión de infraestructura y permitir escalado automático. Sin embargo, puede que no proporcione el aislamiento necesario entre capas para mejorar la seguridad.",
            "Usar Amazon S3 para almacenamiento, instancias de Amazon EC2 para computación, y AWS Direct Connect para comunicación segura entre capas puede proporcionar una arquitectura de múltiples capas. Sin embargo, no menciona ningún mecanismo para manejar cargas de trabajo fluctuantes o para escalar automáticamente según los patrones de tráfico.",
            "Usar una sola instancia de EC2 para ambas capas, web y de base de datos, y conectarlas a través de una Virtual Private Cloud (VPC) para aislamiento no proporciona una arquitectura de múltiples capas. Tampoco menciona ningún mecanismo para manejar cargas de trabajo fluctuantes o para escalar automáticamente según los patrones de tráfico."
        ]
    },
    {
        "Question Number": "36",
        "Situation": "Una aplicación de salud necesita almacenar registros de pacientes de manera segura. Los registros deben ser accedidos frecuentemente para actualizaciones y necesitan mantener la jerarquía de archivos y metadatos. El equipo de la aplicación quiere optimizar los costos de almacenamiento, pero también requiere acceso consistente y de baja latencia.",
        "Question": "¿Qué tipo de almacenamiento cumpliría mejor con estos requisitos?",
        "Options": {
            "1": "Almacenamiento de objetos (Amazon S3)",
            "2": "Almacenamiento de archivos (Amazon EFS)",
            "3": "Almacenamiento en bloques (Amazon EBS)",
            "4": "Almacenamiento en frío (Amazon S3 Glacier)"
        },
        "Correct Answer": "Almacenamiento de archivos (Amazon EFS)",
        "Explanation": "El almacenamiento de archivos, como Amazon EFS (Elastic File System), está diseñado para casos de uso que requieren una jerarquía de archivos y metadatos, lo que lo hace ideal para almacenar registros de pacientes. EFS proporciona acceso de baja latencia y permite que múltiples instancias accedan a los mismos datos simultáneamente, lo cual es esencial para aplicaciones que necesitan actualizar frecuentemente los registros de pacientes. Además, EFS puede escalar automáticamente, optimizando los costos de almacenamiento mientras mantiene el rendimiento.",
        "Other Options": [
            "El almacenamiento de objetos (Amazon S3) no es adecuado para este escenario porque está diseñado para datos no estructurados y no mantiene una jerarquía de archivos ni admite semánticas de sistema de archivos tradicionales, que son necesarias para gestionar los registros de pacientes de manera efectiva.",
            "El almacenamiento en bloques (Amazon EBS) se utiliza típicamente para aplicaciones que requieren almacenamiento de alto rendimiento para bases de datos o máquinas virtuales. Aunque ofrece acceso de baja latencia, no proporciona una jerarquía de archivos ni fácil compartición de archivos entre múltiples instancias, lo cual es un requisito para la aplicación de salud.",
            "El almacenamiento en frío (Amazon S3 Glacier) está diseñado para datos que se acceden infrecuentemente y no es adecuado para aplicaciones que requieren actualizaciones frecuentes y acceso de baja latencia. Se utiliza principalmente para archivar datos en lugar de para la gestión activa de datos."
        ]
    },
    {
        "Question Number": "37",
        "Situation": "Una empresa tiene un bucket S3 que contiene datos sensibles que deben ser accedidos por roles IAM específicos en múltiples cuentas de AWS. La empresa quiere asegurarse de que solo estos roles tengan acceso, manteniendo la gestión simple y evitando la necesidad de configuraciones complejas de usuarios IAM.",
        "Question": "¿Cuáles son las formas más apropiadas de implementar este control de acceso? (Elige dos.)",
        "Options": {
            "1": "Crear una política IAM en cada cuenta que otorgue acceso al bucket S3 y adjuntarla a los roles requeridos.",
            "2": "Adjuntar una política de bucket al bucket S3 que otorgue explícitamente acceso a los roles IAM requeridos en cada cuenta.",
            "3": "Usar AWS Secrets Manager para almacenar y gestionar las credenciales de acceso para cada rol IAM que necesita acceso al bucket.",
            "4": "Configurar puntos finales de VPC en cada cuenta para controlar el acceso al bucket S3 basado en la configuración de la red VPC.",
            "5": "Usar Amazon S3 Access Points con políticas que especifiquen los roles IAM permitidos en múltiples cuentas."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Crear una política IAM en cada cuenta que otorgue acceso al bucket S3 y adjuntarla a los roles requeridos.",
            "Adjuntar una política de bucket al bucket S3 que otorgue explícitamente acceso a los roles IAM requeridos en cada cuenta."
        ],
        "Explanation": "Crear una política IAM en cada cuenta que otorgue acceso al bucket S3 y adjuntarla a los roles requeridos es una respuesta correcta porque las políticas IAM son una forma de gestionar permisos para múltiples cuentas de AWS. Este enfoque permite a la empresa especificar qué roles en cada cuenta tienen acceso al bucket S3. Adjuntar una política de bucket al bucket S3 que otorgue explícitamente acceso a los roles IAM requeridos en cada cuenta también es correcto. Una política de bucket se aplica a todos los objetos en ese bucket y puede usarse para otorgar acceso entre cuentas al bucket S3, que es lo que la empresa desea.",
        "Other Options": [
            "Usar AWS Secrets Manager para almacenar y gestionar las credenciales de acceso para cada rol IAM que necesita acceso al bucket no es la mejor opción porque añadiría complejidad innecesaria a la gestión de credenciales de acceso. La empresa quiere evitar configuraciones complejas de usuarios IAM, y usar Secrets Manager no simplificaría la gestión del acceso al bucket S3.",
            "Configurar puntos finales de VPC en cada cuenta para controlar el acceso al bucket S3 basado en la configuración de la red VPC no es la mejor opción porque no controlaría directamente qué roles IAM tienen acceso al bucket S3. Los puntos finales de VPC se utilizan para conectar de forma privada tu VPC a servicios de AWS compatibles, no para gestionar el acceso a buckets S3 a nivel de rol IAM.",
            "Usar Amazon S3 Access Points con políticas que especifiquen los roles IAM permitidos en múltiples cuentas no es la mejor opción porque los S3 Access Points se utilizan para simplificar la gestión del acceso a datos a gran escala para aplicaciones que utilizan conjuntos de datos compartidos. No proporcionan una forma de gestionar el acceso a buckets S3 a nivel de rol IAM en múltiples cuentas."
        ]
    },
    {
        "Question Number": "38",
        "Situation": "Una empresa quiere diseñar una aplicación web altamente disponible que pueda soportar fallos de infraestructura dentro de una región y proporcionar acceso de baja latencia a usuarios en múltiples ubicaciones.",
        "Question": "¿Qué servicio de AWS debería usar la empresa para gestionar la distribución del tráfico a través de múltiples Zonas de Disponibilidad, y qué beneficio proporciona?",
        "Options": {
            "1": "Amazon Route 53",
            "2": "AWS Direct Connect",
            "3": "Amazon S3",
            "4": "Amazon DynamoDB"
        },
        "Correct Answer": "Amazon Route 53",
        "Explanation": "Amazon Route 53 es un servicio web de Sistema de Nombres de Dominio (DNS) escalable que proporciona registro de nombres de dominio altamente confiable y rentable, enrutamiento DNS y verificación de estado de recursos. Puede gestionar la distribución del tráfico a través de múltiples Zonas de Disponibilidad al enrutar las solicitudes de los usuarios al punto final saludable más cercano, asegurando acceso de baja latencia y alta disponibilidad. Esto lo convierte en una opción ideal para aplicaciones que necesitan soportar fallos de infraestructura y mantener el rendimiento en diferentes ubicaciones geográficas.",
        "Other Options": [
            "AWS Direct Connect es un servicio en la nube que proporciona una conexión de red dedicada desde tus instalaciones a AWS. Aunque puede mejorar el rendimiento de la red, no gestiona la distribución del tráfico a través de Zonas de Disponibilidad.",
            "Amazon S3 (Servicio de Almacenamiento Simple) es un servicio de almacenamiento de objetos que proporciona almacenamiento altamente escalable para datos. No maneja la distribución del tráfico ni el enrutamiento para aplicaciones web.",
            "Amazon DynamoDB es un servicio de base de datos NoSQL completamente administrado que proporciona un rendimiento rápido y predecible con escalabilidad sin problemas. No está diseñado para la distribución del tráfico ni para gestionar solicitudes de usuarios a través de múltiples Zonas de Disponibilidad."
        ]
    },
    {
        "Question Number": "39",
        "Situation": "Una empresa quiere integrar de manera segura su función AWS Lambda con DynamoDB y S3. Necesitan asegurarse de que la función Lambda solo pueda realizar acciones específicas en estos servicios, mientras que también limitan qué otros servicios y cuentas de AWS pueden invocar la función.",
        "Question": "¿Cuál de los siguientes enfoques deberían tomar para lograr esto?",
        "Options": {
            "1": "Adjuntar una política en línea a la función Lambda que especifique las acciones permitidas en DynamoDB y S3, y aplicar una política de recursos que restrinja qué servicios y cuentas pueden invocar la función Lambda.",
            "2": "Usar un rol de ejecución de Lambda que otorgue permisos para las acciones necesarias en DynamoDB y S3, y agregar una política de recursos de Lambda para controlar los permisos de invocación.",
            "3": "Adjuntar una política IAM administrada a la función Lambda para acceder a DynamoDB y S3, y configurar un límite de permisos de Lambda para restringir la invocación.",
            "4": "Crear un rol vinculado al servicio para la función Lambda para acceder a DynamoDB y S3 y usar una política de bucket S3 para restringir la invocación."
        },
        "Correct Answer": "Usar un rol de ejecución de Lambda que otorgue permisos para las acciones necesarias en DynamoDB y S3, y agregar una política de recursos de Lambda para controlar los permisos de invocación.",
        "Explanation": "Usar un rol de ejecución de Lambda es la mejor práctica para otorgar permisos a funciones de AWS Lambda. Este rol permite que la función realice acciones específicas en DynamoDB y S3, asegurando que solo se otorguen los permisos necesarios. Además, se puede aplicar una política de recursos de Lambda para controlar qué servicios y cuentas de AWS pueden invocar la función Lambda, proporcionando una forma segura y flexible de gestionar el acceso.",
        "Other Options": [
            "Adjuntar una política en línea a la función Lambda no se recomienda porque las políticas en línea están vinculadas a un recurso específico y pueden volverse difíciles de gestionar. Un rol de ejecución de Lambda es un enfoque más escalable y manejable. Si bien una política de recursos es importante, el rol de ejecución es el método principal para otorgar permisos para acceder a otros servicios de AWS.",
            "Adjuntar una política IAM administrada a la función Lambda no es el mejor enfoque porque las políticas administradas son más amplias y pueden otorgar más permisos de los necesarios. Además, aunque un límite de permisos puede ayudar a restringir permisos, no es el método principal para controlar los permisos de invocación, que es mejor manejado por una política de recursos.",
            "Crear un rol vinculado al servicio para la función Lambda no es aplicable en este caso, ya que los roles vinculados al servicio son roles predefinidos que los servicios de AWS utilizan para realizar acciones en tu nombre. No proporcionan la granularidad necesaria para controlar el acceso a DynamoDB y S3. Una política de bucket S3 tampoco es adecuada para controlar los permisos de invocación de Lambda, ya que es específica de S3 y no se aplica a funciones Lambda."
        ]
    },
    {
        "Question Number": "40",
        "Situation": "Una plataforma global de comercio financiero necesita minimizar la latencia para usuarios en diferentes partes del mundo. La plataforma requiere una transferencia de datos consistente y de alta velocidad con saltos mínimos para reducir el riesgo de retrasos o pérdida de paquetes. Además, necesita soportar tráfico TCP y UDP para diversas aplicaciones en tiempo real.",
        "Question": "¿Qué servicio de AWS cumpliría mejor con estos requisitos?",
        "Options": {
            "1": "Amazon CloudFront con almacenamiento en caché en el borde",
            "2": "AWS Direct Connect para conexiones dedicadas",
            "3": "AWS Global Accelerator con direcciones IP Anycast",
            "4": "Amazon Route 53 con enrutamiento basado en latencia"
        },
        "Correct Answer": "AWS Global Accelerator con direcciones IP Anycast",
        "Explanation": "AWS Global Accelerator está diseñado específicamente para mejorar la disponibilidad y el rendimiento de las aplicaciones con usuarios distribuidos globalmente. Utiliza direcciones IP Anycast para enrutar el tráfico de los usuarios a la ubicación de borde de AWS más cercana, minimizando la latencia y proporcionando un camino consistente para la transferencia de datos. Este servicio soporta tanto tráfico TCP como UDP, lo que lo hace ideal para aplicaciones en tiempo real que requieren baja latencia y transferencia de datos de alta velocidad. Además, reduce el número de saltos entre el usuario y la aplicación, lo que ayuda a minimizar retrasos y pérdida de paquetes.",
        "Other Options": [
            "Amazon CloudFront con almacenamiento en caché en el borde es principalmente una red de entrega de contenido (CDN) que almacena contenido en caché en ubicaciones de borde para reducir la latencia en la entrega de contenido estático. Si bien puede mejorar el rendimiento para ciertos tipos de aplicaciones, no está optimizado para aplicaciones en tiempo real que requieren transferencia de datos consistente y de alta velocidad y soporte para tráfico TCP y UDP.",
            "AWS Direct Connect proporciona conexiones de red dedicadas desde sus instalaciones a AWS, lo que puede reducir la latencia en la transferencia de datos. Sin embargo, es más adecuado para arquitecturas de nube híbrida y no proporciona inherentemente enrutamiento global o soporte para tráfico TCP y UDP a través de múltiples regiones, lo que lo hace menos ideal para una plataforma global de comercio financiero.",
            "Amazon Route 53 con enrutamiento basado en latencia es un servicio DNS que dirige las solicitudes de los usuarios a la región de AWS más cercana según la latencia. Si bien puede ayudar a mejorar el rendimiento, no proporciona el mismo nivel de transferencia de datos consistente y de alta velocidad y saltos mínimos como AWS Global Accelerator, ni soporta directamente tráfico TCP y UDP de la misma manera."
        ]
    },
    {
        "Question Number": "41",
        "Situation": "Un administrador de IAM está configurando el acceso para un equipo de desarrolladores que necesita acceso a largo plazo a los recursos de AWS. Para reducir la sobrecarga de gestión, el administrador quiere aplicar los mismos permisos a múltiples miembros del equipo mientras asegura que las políticas sean reutilizables y se puedan actualizar fácilmente.",
        "Question": "¿Qué enfoque debería tomar el administrador para implementar estos requisitos?",
        "Options": {
            "1": "Adjuntar políticas en línea individuales a cada usuario de IAM con permisos específicos.",
            "2": "Crear una política administrada por el cliente y adjuntarla a un grupo de IAM, luego agregar a los usuarios al grupo.",
            "3": "Usar una política administrada por AWS y adjuntarla directamente a cada usuario de IAM.",
            "4": "Definir una política de recursos con los permisos necesarios y aplicarla directamente a los recursos."
        },
        "Correct Answer": "Crear una política administrada por el cliente y adjuntarla a un grupo de IAM, luego agregar a los usuarios al grupo.",
        "Explanation": "Crear una política administrada por el cliente permite al administrador de IAM definir un conjunto de permisos que pueden ser reutilizados entre múltiples usuarios. Al adjuntar esta política a un grupo de IAM, todos los usuarios en ese grupo heredan los permisos definidos en la política. Este enfoque reduce la sobrecarga de gestión porque si los permisos necesitan ser actualizados, el administrador puede simplemente modificar la política en un solo lugar en lugar de actualizar a cada usuario individualmente. Este método también asegura que los permisos sean consistentes entre todos los miembros del equipo.",
        "Other Options": [
            "Adjuntar políticas en línea individuales a cada usuario de IAM crea una política única para cada usuario, lo que aumenta la sobrecarga de gestión y dificulta mantener permisos consistentes en el equipo. Las políticas en línea no son reutilizables y deben ser actualizadas individualmente para cada usuario.",
            "Usar una política administrada por AWS y adjuntarla directamente a cada usuario de IAM puede llevar a desafíos en la gestión de permisos, ya que las políticas administradas por AWS son predefinidas y pueden no satisfacer las necesidades específicas del equipo de desarrolladores. Además, si se necesitan cambios, cada usuario tendría que ser actualizado individualmente, lo que aumenta la sobrecarga de gestión.",
            "Definir una política de recursos con los permisos necesarios y aplicarla directamente a los recursos no es adecuado para gestionar permisos de usuario. Las políticas de recursos están destinadas a controlar el acceso a recursos específicos de AWS en lugar de gestionar permisos de usuario entre múltiples usuarios. Este enfoque no aborda el requisito de permisos reutilizables y fácilmente actualizables para un equipo de usuarios."
        ]
    },
    {
        "Question Number": "42",
        "Situation": "Una empresa está almacenando datos críticos de negocio en AWS y necesita elegir una solución de almacenamiento que proporcione alta durabilidad y replicación a través de múltiples regiones para recuperación ante desastres.",
        "Question": "¿Qué opción de almacenamiento debería elegir la empresa para asegurar durabilidad y replicación de datos?",
        "Options": {
            "1": "Usar Amazon EBS (Elastic Block Store) con instantáneas para respaldo y replicación, asegurando que los datos se repliquen a otra Zona de Disponibilidad.",
            "2": "Usar Amazon S3 con versionado habilitado y replicación entre regiones para asegurar la durabilidad de los datos y la replicación global.",
            "3": "Usar Amazon EFS (Elastic File System) para acceso compartido, ya que proporciona replicación automática pero no garantiza la durabilidad de los datos entre regiones.",
            "4": "Usar Amazon Glacier para almacenamiento de archivo, ya que proporciona durabilidad a bajo costo pero no soporta replicación entre regiones."
        },
        "Correct Answer": "Usar Amazon S3 con versionado habilitado y replicación entre regiones para asegurar la durabilidad de los datos y la replicación global.",
        "Explanation": "Amazon S3 está diseñado para alta durabilidad y disponibilidad, con un SLA de 99.999999999% (11 nueves) de durabilidad. Al habilitar el versionado, la empresa puede mantener múltiples versiones de un objeto, lo que ayuda a recuperar de eliminaciones accidentales o sobrescrituras. La replicación entre regiones (CRR) permite a la empresa replicar automáticamente datos a través de diferentes regiones de AWS, proporcionando una capa adicional de recuperación ante desastres y asegurando que los datos críticos estén disponibles incluso si una región experimenta una interrupción. Esto hace que S3 sea la mejor opción para las necesidades de durabilidad y replicación de la empresa a través de múltiples regiones.",
        "Other Options": [
            "Usar Amazon EBS con instantáneas proporciona durabilidad y la capacidad de crear respaldos, pero principalmente replica datos dentro de la misma Zona de Disponibilidad o puede ser copiado a otra región manualmente. EBS no está diseñado para replicación automática entre regiones, lo que lo hace menos adecuado para recuperación ante desastres a través de múltiples regiones.",
            "Amazon EFS proporciona un sistema de archivos administrado que puede ser accedido por múltiples instancias, y ofrece cierto nivel de redundancia y disponibilidad. Sin embargo, no replica automáticamente datos entre regiones, lo cual es un requisito crítico para la recuperación ante desastres en este escenario.",
            "Amazon Glacier está diseñado principalmente para almacenamiento de archivo a largo plazo y proporciona durabilidad a bajo costo. Si bien es altamente durable, no soporta replicación automática entre regiones, lo que lo hace inadecuado para la necesidad de la empresa de acceso inmediato y capacidades de recuperación ante desastres."
        ]
    },
    {
        "Question Number": "43",
        "Situation": "Una empresa quiere asegurarse de tener una estrategia de respaldo resiliente para su base de datos de Amazon RDS para recuperar datos en caso de falla. Requieren que las copias de seguridad se creen automáticamente y se conserven durante hasta 35 días, con la capacidad de restaurar a un punto específico en el tiempo si es necesario.",
        "Question": "¿Qué configuración deberían usar para cumplir con estos requisitos, y cuáles son las características clave? (Elige dos.)",
        "Options": {
            "1": "Configurar copias de seguridad automatizadas para retener datos durante hasta 35 días, con copias de seguridad incrementales después de la instantánea completa inicial. Las copias de seguridad automatizadas permiten la recuperación a un punto en el tiempo a cualquier intervalo de 5 minutos dentro del período de retención.",
            "2": "Usar instantáneas manuales diariamente y conservar cada instantánea indefinidamente para asegurar la recuperación de datos, ya que las copias de seguridad automatizadas no soportan la recuperación a un punto en el tiempo.",
            "3": "Configurar replicación entre regiones para copias de seguridad para asegurar que sean resilientes en múltiples regiones, pero limitar la retención a 7 días para reducir costos.",
            "4": "Implementar una única copia de seguridad completa una vez y habilitar instantáneas automáticas de RDS cada 5 minutos para cumplir con el requisito de recuperación a un punto en el tiempo.",
            "5": "Habilitar copias de seguridad continuas a Amazon S3 con versionado habilitado, permitiendo la restauración a cualquier estado anterior dentro de 35 días."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Configurar copias de seguridad automatizadas para retener datos durante hasta 35 días, con copias de seguridad incrementales después de la instantánea completa inicial. Las copias de seguridad automatizadas permiten la recuperación a un punto en el tiempo a cualquier intervalo de 5 minutos dentro del período de retención.",
            "Habilitar copias de seguridad continuas a Amazon S3 con versionado habilitado, permitiendo la restauración a cualquier estado anterior dentro de 35 días."
        ],
        "Explanation": "Las copias de seguridad automatizadas en Amazon RDS son una característica que crea automáticamente una copia de seguridad de su base de datos, con la capacidad de conservar estas copias de seguridad durante hasta 35 días. También permiten la recuperación a un punto en el tiempo, lo que significa que puede restaurar su base de datos a cualquier momento específico dentro del período de retención. Esto cumple con el requisito de la empresa para la creación y retención automática de copias de seguridad, así como la capacidad de restaurar a un punto específico en el tiempo. La copia de seguridad continua a Amazon S3 con versionado habilitado también cumple con estos requisitos, ya que permite la restauración a cualquier estado anterior dentro del período de retención.",
        "Other Options": [
            "Las instantáneas manuales no cumplen con el requisito de creación automática de copias de seguridad. Además, aunque pueden conservarse indefinidamente, no soportan la recuperación a un punto en el tiempo, que es un requisito.",
            "La replicación entre regiones para copias de seguridad proporciona resiliencia, pero limitar la retención a 7 días no cumple con el requisito de retención de hasta 35 días.",
            "Implementar una única copia de seguridad completa y habilitar instantáneas automáticas de RDS cada 5 minutos no cumple con el requisito de retención de hasta 35 días, ya que no especifica cuánto tiempo se conservarían estas instantáneas."
        ]
    },
    {
        "Question Number": "44",
        "Situation": "Una empresa de comercio electrónico maneja un gran volumen de datos de transacciones y quiere asegurar la durabilidad y disponibilidad de los datos a través de regiones. Necesitan una estrategia de respaldo y replicación confiable que les permita restaurar datos rápidamente en caso de un desastre o corrupción de datos. Para cumplir con estos requisitos, la empresa necesita determinar los servicios y configuraciones de AWS más apropiados para implementar copias de seguridad y replicación entre regiones.",
        "Question": "¿Qué deberían considerar al establecer esta estrategia de respaldo y replicación?",
        "Options": {
            "1": "Usar Amazon S3 con replicación entre regiones habilitada para duplicar automáticamente datos en diferentes regiones y establecer políticas de ciclo de vida para gestionar copias de seguridad.",
            "2": "Confiar en instantáneas de Amazon EC2 y transferir manualmente archivos de respaldo entre regiones para cada instancia.",
            "3": "Habilitar AWS Shield Advanced para replicar y proteger datos en caso de un desastre.",
            "4": "Almacenar copias de seguridad solo en Amazon Glacier y recuperarlas durante una emergencia para reducir costos de almacenamiento."
        },
        "Correct Answer": "Usar Amazon S3 con replicación entre regiones habilitada para duplicar automáticamente datos en diferentes regiones y establecer políticas de ciclo de vida para gestionar copias de seguridad.",
        "Explanation": "Usar Amazon S3 con replicación entre regiones (CRR) es la estrategia más efectiva para asegurar la durabilidad y disponibilidad de los datos a través de regiones. CRR replica automáticamente objetos en los buckets de S3 a una región de AWS diferente, proporcionando redundancia y opciones de recuperación rápida en caso de pérdida o corrupción de datos. Además, establecer políticas de ciclo de vida permite a la empresa gestionar la retención de datos y transitar datos más antiguos a clases de almacenamiento de menor costo, optimizando costos mientras asegura que los datos estén respaldados adecuadamente.",
        "Other Options": [
            "Confiar en instantáneas de Amazon EC2 y transferir manualmente archivos de respaldo entre regiones no es ideal para un gran volumen de datos de transacciones. Las instantáneas están vinculadas a instancias individuales de EC2 y no proporcionan el mismo nivel de automatización y eficiencia que S3 con CRR. Este método también aumenta el riesgo de error humano y puede llevar a copias de seguridad inconsistentes.",
            "Habilitar AWS Shield Advanced se centra principalmente en la protección contra DDoS y no proporciona capacidades de respaldo o replicación. Aunque es importante para la seguridad, no aborda la necesidad de la empresa de durabilidad y disponibilidad de datos a través de regiones.",
            "Almacenar copias de seguridad solo en Amazon Glacier no es adecuado para necesidades de recuperación rápida. Glacier está diseñado para almacenamiento y archivo a largo plazo, y los tiempos de recuperación pueden ser de horas, lo que no es ideal para escenarios de recuperación ante desastres donde se requiere acceso inmediato a los datos. Esta opción tampoco proporciona replicación entre regiones."
        ]
    },
    {
        "Question Number": "45",
        "Situation": "Una empresa está configurando un Elastic Load Balancer (ELB) en AWS para distribuir el tráfico entrante entre múltiples instancias de EC2 en diferentes Zonas de Disponibilidad (AZ). Quieren que el balanceador de carga sea accesible a través de internet, pero también quieren controlar el acceso a instancias públicas y privadas dentro de su VPC.",
        "Question": "¿Qué configuración deberían elegir, y por qué es beneficiosa esta configuración para manejar el tráfico a gran escala?",
        "Options": {
            "1": "Configurar un ELB orientado a internet con IPs públicas asignadas a los nodos, permitiendo que dirija el tráfico tanto a instancias públicas como privadas de EC2 dentro de la VPC. Esta configuración soporta la escalabilidad a través de AZ y proporciona alta disponibilidad.",
            "2": "Usar un balanceador de carga interno con IPs privadas, restringiendo el acceso a la VPC y asegurando que solo el tráfico interno sea equilibrado entre las instancias.",
            "3": "Configurar un ELB orientado a internet con solo instancias privadas de EC2 para limitar el acceso público mientras se mantiene la escalabilidad.",
            "4": "Configurar el balanceador de carga como una configuración de un solo nodo en una AZ para optimizar la utilización de recursos y limitar la escalabilidad a través de múltiples AZ."
        },
        "Correct Answer": "Configurar un ELB orientado a internet con IPs públicas asignadas a los nodos, permitiendo que dirija el tráfico tanto a instancias públicas como privadas de EC2 dentro de la VPC. Esta configuración soporta la escalabilidad a través de AZ y proporciona alta disponibilidad.",
        "Explanation": "Un Elastic Load Balancer (ELB) orientado a internet está diseñado para manejar el tráfico entrante desde internet y puede dirigir solicitudes tanto a instancias públicas como privadas de EC2. Al asignar IPs públicas al ELB, puede recibir tráfico directamente de fuentes externas mientras gestiona el tráfico interno hacia instancias privadas. Esta configuración permite alta disponibilidad y tolerancia a fallos al distribuir el tráfico entre múltiples instancias de EC2 en diferentes Zonas de Disponibilidad (AZ), asegurando que si una AZ falla, las otras aún puedan manejar la carga. Esta configuración es beneficiosa para manejar el tráfico a gran escala porque permite la escalabilidad sin problemas de los recursos según la demanda mientras se mantiene el control sobre el acceso a las instancias.",
        "Other Options": [
            "Usar un balanceador de carga interno con IPs privadas restringe el acceso solo al tráfico interno dentro de la VPC, lo que no cumple con el requisito de ser accesible a través de internet. Esta opción no permitiría a los usuarios externos acceder a los servicios alojados en las instancias de EC2.",
            "Configurar un ELB orientado a internet con solo instancias privadas de EC2 no funcionaría porque las instancias privadas no pueden ser accedidas directamente desde internet. Esta configuración impediría que el ELB dirija el tráfico de manera efectiva, ya que no tendría instancias de cara al público para manejar las solicitudes entrantes.",
            "Configurar el balanceador de carga como una configuración de un solo nodo en una AZ limita los beneficios del balanceo de carga, como alta disponibilidad y tolerancia a fallos. Esta configuración no utiliza las ventajas de distribuir el tráfico entre múltiples AZ, lo cual es crucial para manejar el tráfico a gran escala."
        ]
    },
    {
        "Question Number": "46",
        "Situation": "Una startup quiere monitorear de cerca sus costos mensuales de red en AWS y recibir alertas si el gasto supera la cantidad presupuestada. También desean analizar los costos de transferencia de datos entre regiones a lo largo del tiempo.",
        "Question": "¿Qué herramientas de gestión de costos de AWS deberían utilizar para lograr estos objetivos?",
        "Options": {
            "1": "AWS Cost and Usage Report y AWS Trusted Advisor",
            "2": "AWS Budgets y AWS Cost Explorer",
            "3": "AWS Trusted Advisor y AWS Budgets",
            "4": "AWS Support y AWS Cost Explorer"
        },
        "Correct Answer": "AWS Budgets y AWS Cost Explorer",
        "Explanation": "AWS Budgets permite a los usuarios establecer presupuestos personalizados de costos y uso que pueden activar alertas cuando el gasto supera los umbrales definidos. Esto es esencial para que la startup monitoree sus costos mensuales de red y reciba alertas. AWS Cost Explorer proporciona información detallada sobre los patrones de costos y uso a lo largo del tiempo, lo que es útil para analizar los costos de transferencia de datos entre regiones. Juntas, estas herramientas satisfacen eficazmente los requisitos de la startup para el monitoreo del presupuesto y el análisis de costos.",
        "Other Options": [
            "AWS Cost and Usage Report proporciona información detallada de facturación, pero no ofrece capacidades de alerta. AWS Trusted Advisor ofrece recomendaciones de mejores prácticas, pero no está diseñado específicamente para el monitoreo del presupuesto o el análisis detallado de costos.",
            "Si bien AWS Budgets se identifica correctamente para el monitoreo del presupuesto, AWS Cost Explorer es la mejor opción para analizar costos a lo largo del tiempo en comparación con AWS Trusted Advisor, que se centra en la optimización de recursos en lugar de la gestión de costos.",
            "AWS Support es un servicio de asistencia técnica y no proporciona características de gestión de costos. AWS Cost Explorer es útil para analizar costos, pero sin AWS Budgets, la startup carecería de la funcionalidad de alerta necesaria para el monitoreo del presupuesto."
        ]
    },
    {
        "Question Number": "47",
        "Situation": "Una aplicación de comercio electrónico utiliza Amazon DynamoDB para almacenar datos del catálogo de productos y necesita manejar un alto volumen de solicitudes de lectura durante las ventas flash. El equipo de la aplicación quiere reducir la latencia para las solicitudes de lectura, asegurando que los usuarios puedan acceder a los detalles del producto casi al instante. Sin embargo, no requieren lecturas fuertemente consistentes.",
        "Question": "¿Qué solución cumpliría mejor con estos requisitos?",
        "Options": {
            "1": "Habilitar el Auto Scaling de DynamoDB para manejar la carga aumentada durante las ventas flash",
            "2": "Integrar DynamoDB con Amazon ElastiCache para Redis para un acceso de lectura más rápido",
            "3": "Habilitar DynamoDB Accelerator (DAX) para proporcionar una caché en memoria para cargas de trabajo con muchas lecturas",
            "4": "Usar tablas globales de DynamoDB para replicar el catálogo de productos en múltiples regiones"
        },
        "Correct Answer": "Habilitar DynamoDB Accelerator (DAX) para proporcionar una caché en memoria para cargas de trabajo con muchas lecturas",
        "Explanation": "DynamoDB Accelerator (DAX) está diseñado específicamente para proporcionar una caché en memoria rápida para DynamoDB, lo que reduce significativamente la latencia de lectura. Dado que la aplicación no requiere lecturas fuertemente consistentes, DAX puede servir lecturas de consistencia eventual con muy baja latencia, lo que lo hace ideal para manejar altos volúmenes de solicitudes de lectura durante las ventas flash. DAX puede manejar picos de tráfico y mejorar el rendimiento de cargas de trabajo con muchas lecturas, asegurando que los usuarios puedan acceder a los detalles del producto casi al instante.",
        "Other Options": [
            "Habilitar el Auto Scaling de DynamoDB ayudaría a gestionar la carga aumentada ajustando automáticamente la capacidad de lectura y escritura según los patrones de tráfico. Sin embargo, no aborda directamente el problema de latencia para las solicitudes de lectura, que es crítico durante las ventas flash.",
            "Integrar DynamoDB con Amazon ElastiCache para Redis podría mejorar el rendimiento de lectura al almacenar en caché los datos de acceso frecuente. Sin embargo, añade complejidad a la arquitectura y puede no estar tan integrado con DynamoDB como DAX, que está específicamente optimizado para este propósito.",
            "Usar tablas globales de DynamoDB permitiría la replicación del catálogo de productos en múltiples regiones, mejorando la disponibilidad y reduciendo la latencia para los usuarios en diferentes ubicaciones geográficas. Sin embargo, esta solución no aborda directamente la necesidad de reducir la latencia durante una alta demanda de lectura, ya que se centra más en la disponibilidad y redundancia de datos."
        ]
    },
    {
        "Question Number": "48",
        "Situation": "Una empresa de juegos en línea necesita almacenar datos de jugadores, incluidos perfiles, estados de juego y elementos de inventario. Los datos deben ser altamente disponibles y duraderos, con la capacidad de manejar millones de solicitudes de lectura y escritura por segundo. La empresa también anticipa un crecimiento rápido y requiere una solución de almacenamiento que pueda escalar sin problemas para satisfacer la creciente demanda sin comprometer el rendimiento.",
        "Question": "¿Qué solución de almacenamiento debería recomendar el arquitecto de soluciones para cumplir con estos requisitos?",
        "Options": {
            "1": "Amazon RDS para MySQL",
            "2": "Amazon DynamoDB",
            "3": "Amazon S3 Intelligent-Tiering",
            "4": "Amazon Redshift"
        },
        "Correct Answer": "Amazon DynamoDB",
        "Explanation": "Amazon DynamoDB es un servicio de base de datos NoSQL totalmente administrado que proporciona alta disponibilidad y durabilidad. Está diseñado para manejar millones de solicitudes de lectura y escritura por segundo, lo que lo hace ideal para aplicaciones con altos requisitos de rendimiento, como los juegos en línea. DynamoDB escala automáticamente para acomodar la demanda creciente sin comprometer el rendimiento, lo que se alinea perfectamente con la necesidad de la empresa de una solución de almacenamiento que pueda crecer rápidamente a medida que se expande la base de jugadores. Además, ofrece características como copias de seguridad automáticas y replicación global, asegurando la durabilidad y disponibilidad de los datos.",
        "Other Options": [
            "Amazon RDS para MySQL es un servicio de base de datos relacional que es adecuado para datos estructurados y admite consultas SQL. Sin embargo, puede no manejar el mismo nivel de rendimiento que DynamoDB y requiere más gestión para escalar, lo que lo hace menos ideal para las necesidades de alta disponibilidad y rápido crecimiento de una plataforma de juegos en línea.",
            "Amazon S3 Intelligent-Tiering es un servicio de almacenamiento de objetos diseñado para almacenar grandes cantidades de datos no estructurados. Si bien ofrece durabilidad y disponibilidad, no está optimizado para operaciones de lectura y escritura de alta frecuencia como las requeridas para los datos de jugadores en un contexto de juegos en línea, lo que lo hace inadecuado para este escenario.",
            "Amazon Redshift es un servicio de almacenamiento de datos optimizado para consultas analíticas e informes. No está diseñado para cargas de trabajo transaccionales de alta velocidad como las necesarias para la gestión de datos de jugadores en tiempo real en los juegos, lo que lo convierte en una opción inapropiada para los requisitos descritos."
        ]
    },
    {
        "Question Number": "49",
        "Situation": "Una empresa está diseñando una arquitectura de VPC segura para sus aplicaciones en AWS. Necesitan controlar tanto el tráfico entrante como el saliente hacia instancias específicas dentro de una subred y aplicar controles de seguridad adicionales a nivel de subred.",
        "Question": "¿Cuál de las siguientes explica correctamente el uso y las diferencias entre NACLs y Grupos de Seguridad para este propósito? (Elija dos.)",
        "Options": {
            "1": "Los NACLs operan a nivel de instancia y proporcionan filtrado de tráfico con estado, mientras que los Grupos de Seguridad operan a nivel de subred y ofrecen controles sin estado para cada solicitud.",
            "2": "Los Grupos de Seguridad se aplican a nivel de instancia y proporcionan controles con estado, permitiendo o denegando direcciones IP específicas, mientras que los NACLs se aplican a nivel de subred y pueden configurarse para permitir o denegar rangos de IP específicos de manera sin estado.",
            "3": "Los NACLs solo se aplican al tráfico entrante a nivel de subred, mientras que los Grupos de Seguridad controlan tanto el tráfico entrante como el saliente y son con estado por defecto.",
            "4": "Los Grupos de Seguridad y los NACLs operan ambos a nivel de instancia, pero los NACLs son con estado, permitiendo el filtrado dinámico de paquetes a través de múltiples instancias.",
            "5": "Los NACLs proporcionan una capa adicional de seguridad actuando como un firewall para controlar el tráfico dentro y fuera de una o más subredes, independientemente de los Grupos de Seguridad."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Los Grupos de Seguridad se aplican a nivel de instancia y proporcionan controles con estado, permitiendo o denegando direcciones IP específicas, mientras que los NACLs se aplican a nivel de subred y pueden configurarse para permitir o denegar rangos de IP específicos de manera sin estado.",
            "Los NACLs proporcionan una capa adicional de seguridad actuando como un firewall para controlar el tráfico dentro y fuera de una o más subredes, independientemente de los Grupos de Seguridad."
        ],
        "Explanation": "Los Grupos de Seguridad en AWS se aplican a nivel de instancia y proporcionan controles con estado, lo que significa que realizan un seguimiento del estado de las conexiones de red y permiten automáticamente el tráfico de retorno para las conexiones salientes permitidas. Pueden configurarse para permitir o denegar direcciones IP específicas. Por otro lado, las Listas de Control de Acceso de Red (NACLs) se aplican a nivel de subred y proporcionan controles sin estado, lo que significa que evalúan cada paquete individualmente sin considerar conexiones existentes. Pueden configurarse para permitir o denegar rangos de IP específicos. Los NACLs también proporcionan una capa adicional de seguridad actuando como un firewall para controlar el tráfico dentro y fuera de una o más subredes, independientemente de los Grupos de Seguridad.",
        "Other Options": [
            "Los NACLs operan a nivel de subred y proporcionan filtrado de tráfico sin estado, no a nivel de instancia. Además, los Grupos de Seguridad operan a nivel de instancia y ofrecen controles con estado, no a nivel de subred.",
            "Los NACLs se aplican tanto al tráfico entrante como al saliente a nivel de subred, no solo al tráfico entrante.",
            "Los Grupos de Seguridad y los NACLs no operan ambos a nivel de instancia. Los Grupos de Seguridad operan a nivel de instancia, mientras que los NACLs operan a nivel de subred. Además, los NACLs son sin estado, no con estado."
        ]
    },
    {
        "Question Number": "50",
        "Situation": "Una empresa de medios está configurando una arquitectura sin servidor para manejar el aumento de cargas de video durante las vacaciones de sus usuarios. Quieren que la configuración sea completamente administrada, que escale automáticamente para manejar tráfico impredecible y que permita a los usuarios autenticarse sin problemas. El flujo de trabajo ideal debería involucrar cargas de video, procesamiento para múltiples formatos y almacenamiento, todo con una sobrecarga mínima.",
        "Question": "Dado este escenario, ¿qué combinación de servicios de AWS apoyaría mejor esta arquitectura y qué la hace la opción óptima?",
        "Options": {
            "1": "Aprovechar Amazon Cognito para la autenticación de usuarios para intercambiar de manera segura los tokens del proveedor de identidad por credenciales temporales de AWS, permitiendo cargas directas a un bucket de S3. Activar una función de AWS Lambda con cada carga para iniciar el pipeline de procesamiento de video.",
            "2": "Utilizar una flota de instancias de Amazon EC2 para la autenticación de usuarios, cargas de video y transcodificación, almacenando archivos de video en volúmenes EBS adjuntos. Escalar manualmente las instancias para satisfacer los picos de demanda.",
            "3": "Configurar Amazon S3 para almacenamiento de video, iniciar una función de AWS Lambda por cada carga de video para procesamiento, y registrar los detalles del trabajo de procesamiento en una base de datos de Amazon RDS para resiliencia.",
            "4": "Autenticar a los usuarios utilizando roles de IAM, almacenar videos en DynamoDB y usar instancias de EC2 para manejar tareas de procesamiento, con los videos procesados finales almacenados nuevamente en S3 para su recuperación."
        },
        "Correct Answer": "Aprovechar Amazon Cognito para la autenticación de usuarios para intercambiar de manera segura los tokens del proveedor de identidad por credenciales temporales de AWS, permitiendo cargas directas a un bucket de S3. Activar una función de AWS Lambda con cada carga para iniciar el pipeline de procesamiento de video.",
        "Explanation": "Esta opción es óptima porque utiliza servicios completamente administrados que escalan automáticamente y requieren una sobrecarga operativa mínima. Amazon Cognito proporciona autenticación de usuarios sin problemas, permitiendo a los usuarios cargar videos directamente a un bucket de S3, que está diseñado para alta disponibilidad y durabilidad. El uso de AWS Lambda para activar el procesamiento de video al cargar asegura que el procesamiento pueda escalar automáticamente con el número de cargas, manejando tráfico impredecible de manera eficiente. Esta arquitectura se alinea perfectamente con los requisitos de ser sin servidor y completamente administrada.",
        "Other Options": [
            "Utilizar una flota de instancias de Amazon EC2 para la autenticación de usuarios, cargas de video y transcodificación introduce una sobrecarga de gestión significativa y no proporciona escalado automático. Las instancias de EC2 requieren intervención manual para escalar, lo que no es ideal para patrones de tráfico impredecibles, haciendo que esta opción sea menos adecuada.",
            "Configurar Amazon S3 para almacenamiento de video e iniciar una función de AWS Lambda por cada carga de video para procesamiento es un buen enfoque, pero registrar los detalles del trabajo de procesamiento en una base de datos de Amazon RDS añade complejidad innecesaria y sobrecarga de gestión. El enfoque debería estar en minimizar la sobrecarga, y usar una base de datos para este propósito puede no ser necesario en una arquitectura sin servidor completamente administrada.",
            "Autenticar a los usuarios utilizando roles de IAM no es adecuado para la autenticación de usuarios en este contexto, ya que los roles de IAM se utilizan típicamente para permisos de servicios de AWS en lugar de autenticación de usuarios. Almacenar videos en DynamoDB tampoco es ideal para archivos de video grandes, ya que S3 está específicamente diseñado para tales casos de uso. Además, usar instancias de EC2 para tareas de procesamiento contradice el requisito de una arquitectura sin servidor."
        ]
    },
    {
        "Question Number": "51",
        "Situation": "Una empresa está utilizando Amazon Elastic Block Store (EBS) para almacenar datos adjuntos a sus instancias de EC2 dentro de una única Zona de Disponibilidad (AZ) en la región us-east-1. Para mejorar la durabilidad y resiliencia de los datos, la empresa quiere asegurarse de que sus datos estén seguros incluso en caso de una falla de AZ.",
        "Question": "¿Qué estrategia proporcionaría la mejor resiliencia para sus datos de EBS?",
        "Options": {
            "1": "Usar instantáneas de EBS almacenadas en Amazon S3 y copiarlas a una región diferente para habilitar la recuperación ante desastres entre regiones.",
            "2": "Adjuntar volúmenes de EBS a múltiples instancias de EC2 en diferentes AZs dentro de la misma región para redundancia.",
            "3": "Configurar volúmenes de EBS para replicarse automáticamente a través de todas las Zonas de Disponibilidad dentro de la región.",
            "4": "Usar S3 para almacenamiento directo de datos en lugar de EBS, ya que proporciona mayor durabilidad y disponibilidad a través de AZs."
        },
        "Correct Answer": "Usar instantáneas de EBS almacenadas en Amazon S3 y copiarlas a una región diferente para habilitar la recuperación ante desastres entre regiones.",
        "Explanation": "Usar instantáneas de EBS almacenadas en Amazon S3 y copiarlas a una región diferente proporciona la mejor resiliencia para los datos de EBS porque asegura que los datos no solo estén respaldados, sino también almacenados en una ubicación geográfica diferente. Esto protege contra la pérdida de datos debido a una falla completa de una Zona de Disponibilidad, ya que las instantáneas pueden restaurarse en otra región. Esta estrategia aprovecha la durabilidad de Amazon S3 y las capacidades entre regiones para mejorar las opciones de recuperación ante desastres.",
        "Other Options": [
            "Adjuntar volúmenes de EBS a múltiples instancias de EC2 en diferentes AZs dentro de la misma región no proporciona resiliencia contra una falla de AZ porque los volúmenes de EBS solo pueden adjuntarse a una instancia a la vez. Si bien puede proporcionar cierto nivel de redundancia, no protege contra la pérdida de toda la AZ.",
            "Configurar volúmenes de EBS para replicarse automáticamente a través de todas las Zonas de Disponibilidad dentro de la región no es una característica ofrecida por EBS. Los volúmenes de EBS están vinculados a una AZ específica, y aunque se pueden crear instantáneas, no hay replicación automática entre AZs. Por lo tanto, esta opción no mejora la resiliencia contra fallas de AZ.",
            "Usar S3 para almacenamiento directo de datos en lugar de EBS proporciona mayor durabilidad y disponibilidad a través de AZs, pero puede no ser adecuado para todos los casos de uso, especialmente aquellos que requieren almacenamiento en bloque. Además, no aborda directamente la necesidad de resiliencia de datos de EBS en el contexto de instancias de EC2, ya que implica un paradigma de almacenamiento diferente."
        ]
    },
    {
        "Question Number": "52",
        "Situation": "Una empresa de servicios financieros está migrando su almacén de datos local a AWS. El almacén de datos procesa grandes volúmenes de datos transaccionales y requiere un alto rendimiento para las operaciones de ETL. La empresa busca minimizar costos mientras asegura escalabilidad y rendimiento.",
        "Question": "¿Qué servicio de AWS debería recomendar el arquitecto de soluciones para el almacenamiento del almacén de datos?",
        "Options": {
            "1": "Amazon RDS for PostgreSQL",
            "2": "Amazon Redshift",
            "3": "Amazon DynamoDB",
            "4": "Amazon Aurora"
        },
        "Correct Answer": "Amazon Redshift",
        "Explanation": "Amazon Redshift es un servicio de almacén de datos totalmente administrado y a escala de petabytes, diseñado específicamente para cargas de trabajo analíticas. Está optimizado para un alto rendimiento y puede manejar eficientemente grandes volúmenes de datos transaccionales, lo que lo hace ideal para operaciones de ETL. Las capacidades de almacenamiento columnar y procesamiento paralelo de Redshift permiten un rendimiento rápido de consultas y escalabilidad, lo que se alinea con los requisitos de rendimiento y rentabilidad de la empresa durante la migración de su almacén de datos a AWS.",
        "Other Options": [
            "Amazon RDS for PostgreSQL es un servicio de base de datos relacional que es adecuado para cargas de trabajo transaccionales, pero no está optimizado para el almacenamiento de datos a gran escala y análisis como Redshift. Puede que no proporcione el mismo nivel de rendimiento y escalabilidad para operaciones de ETL en grandes conjuntos de datos.",
            "Amazon DynamoDB es un servicio de base de datos NoSQL diseñado para alta disponibilidad y acceso de baja latencia a datos clave-valor y documentos. Aunque es excelente para ciertos tipos de aplicaciones, no es adecuado para las necesidades tradicionales de almacenamiento de datos, especialmente para consultas complejas y análisis en grandes conjuntos de datos.",
            "Amazon Aurora es un servicio de base de datos relacional que ofrece alto rendimiento y disponibilidad. Sin embargo, al igual que RDS, no está diseñado específicamente para el almacenamiento de datos y puede no proporcionar el mismo nivel de rendimiento para consultas analíticas y operaciones de ETL como Amazon Redshift."
        ]
    },
    {
        "Question Number": "53",
        "Situation": "Una empresa de producción de medios requiere almacenamiento de alto rendimiento para la edición de video, pero quiere mantener bajos los costos. Tienen una mezcla de cargas de trabajo de alto y bajo rendimiento y necesitan elegir tipos de almacenamiento en bloque apropiados.",
        "Question": "¿Qué combinación de opciones de almacenamiento en bloque debería usar la empresa para optimizar costos mientras cumple con los requisitos de rendimiento?",
        "Options": {
            "1": "Provisioned IOPS SSD (io2) para todos los volúmenes",
            "2": "General Purpose SSD (gp3) para tareas de alto rendimiento y Throughput Optimized HDD (st1) para tareas de menor rendimiento",
            "3": "Cold HDD (sc1) para todos los volúmenes",
            "4": "Usar Amazon S3 en lugar de almacenamiento en bloque para todos los datos"
        },
        "Correct Answer": "General Purpose SSD (gp3) para tareas de alto rendimiento y Throughput Optimized HDD (st1) para tareas de menor rendimiento",
        "Explanation": "Esta combinación permite a la empresa de producción de medios equilibrar rendimiento y costo de manera efectiva. General Purpose SSD (gp3) proporciona un buen equilibrio entre precio y rendimiento para cargas de trabajo de alto rendimiento, como la edición de video, donde la baja latencia y el alto rendimiento son esenciales. Por otro lado, Throughput Optimized HDD (st1) es más rentable para tareas de menor rendimiento, como almacenar archivos de video de acceso menos frecuente o copias de seguridad. Este enfoque híbrido optimiza costos mientras cumple con los requisitos de rendimiento para ambos tipos de cargas de trabajo.",
        "Other Options": [
            "Provisioned IOPS SSD (io2) para todos los volúmenes sería innecesariamente caro para tareas de menor rendimiento, ya que está diseñado para cargas de trabajo de alto IOPS y no proporcionaría eficiencia de costos para tareas que no requieren tal rendimiento.",
            "Cold HDD (sc1) para todos los volúmenes no cumpliría con los requisitos de rendimiento para tareas de alto rendimiento como la edición de video, ya que sc1 está diseñado para acceso poco frecuente y tiene un rendimiento mucho más bajo en comparación con las opciones SSD.",
            "Usar Amazon S3 en lugar de almacenamiento en bloque para todos los datos puede no ser adecuado para cargas de trabajo de edición de video que requieren baja latencia y alto rendimiento, ya que S3 es almacenamiento de objetos y no está optimizado para el acceso a nivel de bloque necesario para aplicaciones de alto rendimiento."
        ]
    },
    {
        "Question Number": "54",
        "Situation": "Una empresa quiere establecer acceso seguro para un equipo de desarrolladores que trabaja en un proyecto en una cuenta compartida de AWS. El equipo requiere acceso flexible a recursos específicos de AWS dentro de la cuenta, y el acceso debe ser revocable por usuario.",
        "Question": "¿Cuál de las siguientes es la forma MÁS segura y flexible de otorgar acceso a estos recursos?",
        "Options": {
            "1": "Crear usuarios de IAM para cada desarrollador con permisos y políticas específicas",
            "2": "Crear un solo usuario de IAM con claves de acceso compartidas entre los desarrolladores",
            "3": "Usar AWS IAM Identity Center (AWS Single Sign-On) para asignar roles a cada desarrollador",
            "4": "Asignar un rol de IAM a los recursos compartidos y otorgar permisos a un grupo de IAM que contenga a los desarrolladores"
        },
        "Correct Answer": "Usar AWS IAM Identity Center (AWS Single Sign-On) para asignar roles a cada desarrollador",
        "Explanation": "Usar AWS IAM Identity Center (AWS Single Sign-On) permite una gestión centralizada del acceso de usuarios a través de cuentas y aplicaciones de AWS. Proporciona una forma flexible y segura de asignar roles a desarrolladores individuales, permitiéndoles acceder solo a los recursos que necesitan. Este enfoque también permite la revocación fácil de acceso por usuario, lo cual es esencial para mantener la seguridad en un entorno compartido. Además, IAM Identity Center admite la integración con proveedores de identidad existentes, mejorando la seguridad y la gestión de usuarios.",
        "Other Options": [
            "Crear usuarios de IAM para cada desarrollador con permisos y políticas específicas es un enfoque válido, pero puede volverse engorroso de gestionar a medida que el equipo crece. Cada usuario necesitaría ser gestionado individualmente, y revocar el acceso requeriría modificar los permisos de cada usuario, lo que es menos eficiente que usar IAM Identity Center.",
            "Crear un solo usuario de IAM con claves de acceso compartidas entre los desarrolladores es altamente inseguro. Este enfoque viola el principio de menor privilegio y dificulta el seguimiento de las acciones individuales de los usuarios. Si las claves de acceso se ven comprometidas, el acceso de todos los desarrolladores está en riesgo, y revocar el acceso para un usuario requeriría cambiar las claves para todos.",
            "Asignar un rol de IAM a los recursos compartidos y otorgar permisos a un grupo de IAM que contenga a los desarrolladores es un enfoque razonable, pero carece de la flexibilidad y facilidad de gestión que proporciona AWS IAM Identity Center. Aunque permite cierto nivel de control de acceso, no proporciona el mismo nivel de gestión de usuarios individuales y capacidades de revocación que IAM Identity Center."
        ]
    },
    {
        "Question Number": "55",
        "Situation": "Una empresa multinacional de comercio electrónico tiene usuarios en todo el mundo que necesitan acceso rápido a la información de sus pedidos. La aplicación requiere replicación de datos en múltiples regiones para garantizar alta disponibilidad y baja latencia para los usuarios en diferentes continentes. Además, el sistema debe manejar posibles conflictos de manera elegante cuando se producen actualizaciones en diferentes regiones simultáneamente.",
        "Question": "¿Qué característica de DynamoDB Global Tables satisface mejor estos requisitos?",
        "Options": {
            "1": "Replicación multi-maestro con resolución de conflictos de \"el último escritor gana\"",
            "2": "Replicación de un solo maestro para garantizar la consistencia de los datos",
            "3": "Consistencia fuerte global para todas las lecturas y escrituras a través de regiones",
            "4": "Resolución de conflictos FIFO (Primero en entrar, primero en salir) estricta a través de regiones"
        },
        "Correct Answer": "Replicación multi-maestro con resolución de conflictos de 'el último escritor gana'",
        "Explanation": "DynamoDB Global Tables utiliza replicación multi-maestro, lo que permite que las actualizaciones se realicen en múltiples regiones simultáneamente. Esto es crucial para una empresa multinacional de comercio electrónico que necesita proporcionar acceso rápido a la información de pedidos en diferentes continentes. La estrategia de resolución de conflictos de 'el último escritor gana' asegura que cuando se producen actualizaciones en diferentes regiones al mismo tiempo, la actualización más reciente (basada en una marca de tiempo) es la que se conserva, permitiendo un manejo elegante de posibles conflictos. Esta característica apoya la alta disponibilidad y baja latencia, satisfaciendo efectivamente los requisitos de la aplicación.",
        "Other Options": [
            "La replicación de un solo maestro no cumpliría con el requisito de alta disponibilidad y baja latencia en múltiples regiones, ya que restringe las actualizaciones a una sola región, lo que podría llevar a retrasos para los usuarios en otras regiones.",
            "La consistencia fuerte global para todas las lecturas y escrituras a través de regiones no es compatible con DynamoDB Global Tables, ya que requeriría coordinación que podría introducir latencia y reducir la disponibilidad, lo que contradice la necesidad de acceso rápido y baja latencia.",
            "La resolución de conflictos FIFO (Primero en entrar, primero en salir) estricta no es una característica de DynamoDB Global Tables. Este enfoque no sería adecuado para una configuración de múltiples regiones donde las actualizaciones pueden ocurrir simultáneamente, ya que podría llevar a retrasos e inconsistencias en la disponibilidad de datos."
        ]
    },
    {
        "Question Number": "56",
        "Situation": "Una empresa está configurando un nuevo entorno de AWS y necesita una red privada e aislada dentro de una región específica de AWS. Quieren controlar el rango de direcciones IP para esta red y tener múltiples subredes, cada una dentro de una zona de disponibilidad (AZ) diferente para alta disponibilidad. La empresa también quiere saber si pueden tener múltiples VPCs en la misma región y qué configuraciones predeterminadas se aplican si utilizan la VPC predeterminada.",
        "Question": "¿Qué enfoque debe tomar la empresa para configurar su red de acuerdo con estos requisitos?",
        "Options": {
            "1": "Crear una VPC predeterminada, que proporciona automáticamente subredes en cada zona de disponibilidad dentro de la región. La VPC predeterminada tiene un rango CIDR fijo de 172.31.0.0/16, y no se pueden crear VPCs personalizadas adicionales en la misma región.",
            "2": "Crear una VPC personalizada, que permite a la empresa especificar su propio rango CIDR y crear múltiples subredes en cada zona de disponibilidad. La VPC predeterminada también estará disponible por defecto, y pueden eliminarla o recrearla si es necesario.",
            "3": "Usar la VPC predeterminada proporcionada por AWS, que permite rangos CIDR personalizados y ofrece control total sobre las asignaciones de direcciones IP de las subredes. La VPC predeterminada permite solo una subred por zona de disponibilidad.",
            "4": "Configurar una única VPC en múltiples regiones, ya que las VPCs son globales por defecto. Esta configuración permite a la empresa tener múltiples zonas de disponibilidad en una sola VPC a través de diferentes regiones, proporcionando redundancia y alta disponibilidad."
        },
        "Correct Answer": "Crear una VPC personalizada, que permite a la empresa especificar su propio rango CIDR y crear múltiples subredes en cada zona de disponibilidad. La VPC predeterminada también estará disponible por defecto, y pueden eliminarla o recrearla si es necesario.",
        "Explanation": "Crear una VPC personalizada permite a la empresa definir su propio rango de direcciones IP (bloque CIDR) y crear múltiples subredes en diferentes zonas de disponibilidad (AZs) para alta disponibilidad. Esta configuración cumple con su requisito de una red privada y aislada con control sobre el rango de direcciones IP. Además, AWS permite crear múltiples VPCs dentro de la misma región, y la VPC predeterminada está disponible por defecto, la cual puede ser eliminada o recreada si es necesario.",
        "Other Options": [
            "Crear una VPC predeterminada no permite a la empresa especificar su propio rango CIDR, ya que tiene un rango CIDR fijo de 172.31.0.0/16. Además, efectivamente se pueden crear múltiples VPCs personalizadas en la misma región, por lo que esta opción es incorrecta.",
            "La VPC predeterminada no permite rangos CIDR personalizados; tiene un rango CIDR fijo. Además, aunque la VPC predeterminada proporciona subredes en cada AZ, no permite control total sobre las asignaciones de direcciones IP de las subredes como lo haría una VPC personalizada. Por lo tanto, esta opción es incorrecta.",
            "Las VPCs no son globales; son regionales. Cada VPC está confinada a una sola región, y aunque una VPC puede abarcar múltiples AZs dentro de esa región, no puede abarcar múltiples regiones. Esta opción es incorrecta ya que malinterpreta cómo operan las VPCs en AWS."
        ]
    },
    {
        "Question Number": "57",
        "Situation": "Estás configurando un sistema de entrega de contenido con Amazon CloudFront para servir contenido seguro desde un bucket de S3 y un Application Load Balancer (ALB). Para garantizar una comunicación encriptada, decides configurar certificados SSL.",
        "Question": "Considerando los requisitos de SSL, ¿cuál de los siguientes es crucial para habilitar conexiones HTTPS seguras entre el espectador y tu distribución de CloudFront?",
        "Options": {
            "1": "Generar o importar un certificado público válido en ACM (Amazon Certificate Manager) en la región us-east-1, asegurando que coincida con el nombre DNS de tu dominio.",
            "2": "Usar certificados autofirmados en los orígenes (S3 y ALB) para ahorrar costos, ya que CloudFront manejará la terminación SSL.",
            "3": "Asignar una IP dedicada para soporte SSL en cada ubicación de Edge de CloudFront, ya que esto es obligatorio para que los navegadores modernos establezcan conexiones HTTPS.",
            "4": "Habilitar SSL solo en la distribución de CloudFront y no en los servidores de origen, ya que CloudFront encripta automáticamente todo el tráfico con los espectadores."
        },
        "Correct Answer": "Generar o importar un certificado público válido en ACM (Amazon Certificate Manager) en la región us-east-1, asegurando que coincida con el nombre DNS de tu dominio.",
        "Explanation": "Para habilitar conexiones HTTPS seguras entre el espectador y tu distribución de CloudFront, es crucial tener un certificado SSL válido. Amazon Certificate Manager (ACM) te permite generar o importar certificados SSL que son necesarios para establecer conexiones seguras. El certificado debe estar en la región us-east-1 porque CloudFront requiere que el certificado SSL sea emitido desde esta región para que pueda ser utilizado con las distribuciones. Además, el certificado debe coincidir con el nombre de dominio utilizado en la distribución de CloudFront para asegurar una validación adecuada durante el apretón de manos SSL.",
        "Other Options": [
            "Usar certificados autofirmados en los orígenes (S3 y ALB) no se recomienda para entornos de producción, ya que no son confiables para los clientes y pueden generar advertencias de seguridad. CloudFront no maneja la terminación SSL para certificados autofirmados, y los clientes no establecerán conexiones seguras sin un certificado confiable.",
            "Asignar una IP dedicada para soporte SSL en cada ubicación de Edge de CloudFront no es necesario. CloudFront utiliza una infraestructura compartida para la terminación SSL, y los navegadores modernos no requieren IPs dedicadas para conexiones HTTPS. En su lugar, dependen de los certificados SSL para establecer conexiones seguras.",
            "Habilitar SSL solo en la distribución de CloudFront y no en los servidores de origen no es recomendable. Si bien CloudFront puede encriptar el tráfico entre sí y los espectadores, es esencial también asegurar la conexión entre CloudFront y los servidores de origen (S3 y ALB) para garantizar la encriptación de extremo a extremo. Esto previene posibles vulnerabilidades durante la transferencia de datos de CloudFront al origen."
        ]
    },
    {
        "Question Number": "58",
        "Situation": "Una empresa de aprendizaje automático está ejecutando simulaciones de computación de alto rendimiento (HPC) que requieren una latencia de red extremadamente baja y un alto rendimiento de paquetes por segundo (PPS) entre instancias. Las simulaciones son intensivas en cómputo y necesitan que las instancias se comuniquen directamente entre sí con un retraso mínimo.",
        "Question": "¿Qué configuración de Grupo de Colocación de EC2 debería elegir el arquitecto de soluciones para cumplir con estos requisitos?",
        "Options": {
            "1": "Grupo de Colocación Disperso a través de múltiples Zonas de Disponibilidad",
            "2": "Grupo de Colocación en Clúster dentro de una sola Zona de Disponibilidad",
            "3": "Grupo de Colocación por Partición a través de múltiples estantes",
            "4": "Host Dedicado"
        },
        "Correct Answer": "Grupo de Colocación en Clúster dentro de una sola Zona de Disponibilidad",
        "Explanation": "Un Grupo de Colocación en Clúster está diseñado para proporcionar baja latencia y alto rendimiento entre instancias al colocarlas físicamente cerca unas de otras en la misma Zona de Disponibilidad. Esta configuración es ideal para aplicaciones intensivas en cómputo que requieren una comunicación rápida entre instancias, ya que minimiza la latencia de red y maximiza el rendimiento de paquetes por segundo. Dado que las simulaciones son intensivas en cómputo y requieren comunicación directa con un retraso mínimo, el Grupo de Colocación en Clúster es la mejor opción.",
        "Other Options": [
            "El Grupo de Colocación Disperso a través de múltiples Zonas de Disponibilidad está diseñado para distribuir instancias a través de diferentes hardware físico para reducir el riesgo de fallos simultáneos. Si bien ofrece alta disponibilidad, no proporciona la baja latencia y el alto rendimiento de PPS requeridos para simulaciones intensivas en cómputo, ya que las instancias no están ubicadas cerca unas de otras.",
            "El Grupo de Colocación por Partición a través de múltiples estantes es útil para aplicaciones que requieren alta disponibilidad y tolerancia a fallos, ya que distribuye instancias a través de diferentes estantes. Sin embargo, no garantiza la baja latencia y el alto rendimiento necesarios para la comunicación directa entre instancias, lo que lo hace menos adecuado para el escenario dado.",
            "El Host Dedicado es un servidor físico dedicado a su uso, lo que permite más control sobre la colocación de instancias y la licencia. Sin embargo, no proporciona inherentemente la baja latencia y el alto rendimiento de paquetes por segundo que son críticos para las simulaciones HPC descritas, ya que se centra más en el cumplimiento y el control que en el rendimiento de la red."
        ]
    },
    {
        "Question Number": "59",
        "Situation": "Una organización de atención médica necesita establecer una conexión segura y confiable entre su centro de datos local y su entorno de AWS para cumplir con los requisitos regulatorios. La conexión debe soportar un alto ancho de banda y proporcionar baja latencia para el procesamiento de datos en tiempo real.",
        "Question": "¿Qué opción de conexión de red debería recomendar el arquitecto de soluciones?",
        "Options": {
            "1": "AWS Site-to-Site VPN con enrutamiento dinámico",
            "2": "AWS Direct Connect con una conexión dedicada",
            "3": "AWS Transit Gateway con emparejamiento de VPC",
            "4": "AWS PrivateLink para acceder a servicios de AWS de forma privada"
        },
        "Correct Answer": "AWS Direct Connect con una conexión dedicada",
        "Explanation": "AWS Direct Connect proporciona una conexión dedicada, de alto ancho de banda y baja latencia entre un centro de datos local y AWS. Esta opción es ideal para organizaciones que requieren una conexión segura y confiable para cumplir con la normativa, especialmente para el procesamiento de datos en tiempo real. Direct Connect evita el internet público, reduciendo la latencia y mejorando el rendimiento, lo que lo hace adecuado para aplicaciones de alto rendimiento.",
        "Other Options": [
            "AWS Site-to-Site VPN con enrutamiento dinámico utiliza el internet público para establecer una conexión segura, lo que puede introducir variabilidad en la latencia y el ancho de banda. Si bien es una opción segura, puede no cumplir con los altos requisitos de ancho de banda y baja latencia necesarios para el procesamiento de datos en tiempo real.",
            "AWS Transit Gateway con emparejamiento de VPC se utiliza principalmente para conectar múltiples VPC y redes locales. Si bien puede facilitar la comunicación entre varias redes, no proporciona una conexión dedicada y puede no cumplir con los altos requisitos de ancho de banda y baja latencia tan efectivamente como Direct Connect.",
            "AWS PrivateLink está diseñado para acceder a servicios de AWS de forma privada sin exponer el tráfico al internet público. Sin embargo, no establece una conexión directa entre un centro de datos local y AWS, lo que lo hace inadecuado para el requisito específico de una conexión segura y confiable para alto ancho de banda y baja latencia."
        ]
    },
    {
        "Question Number": "60",
        "Situation": "Una empresa de servicios financieros quiere rastrear costos a través de diferentes departamentos utilizando una sola cuenta de AWS. Necesitan un método para categorizar recursos por departamento y generar informes de costos detallados.",
        "Question": "¿Qué característica de gestión de costos de AWS les ayudaría mejor a lograr esto?",
        "Options": {
            "1": "Habilitar facturación de múltiples cuentas",
            "2": "Usar etiquetas de asignación de costos",
            "3": "Configurar presupuestos de AWS para cada departamento",
            "4": "Habilitar S3 Requester Pays para almacenamiento específico de departamentos"
        },
        "Correct Answer": "Usar etiquetas de asignación de costos",
        "Explanation": "Las etiquetas de asignación de costos permiten categorizar los recursos de AWS por departamento o cualquier otro criterio que elija. Al aplicar estas etiquetas a los recursos, la empresa de servicios financieros puede rastrear los costos asociados con cada departamento y generar informes de costos detallados basados en estas etiquetas. Esta característica está diseñada específicamente para rastrear e informar costos, lo que la convierte en la mejor opción para sus necesidades.",
        "Other Options": [
            "Habilitar facturación de múltiples cuentas no es adecuado porque implica usar múltiples cuentas de AWS para separar costos, lo que no es lo que la empresa desea, ya que busca rastrear costos dentro de una sola cuenta de AWS.",
            "Configurar presupuestos de AWS para cada departamento es útil para monitorear gastos y establecer alertas, pero no proporciona la categorización de recursos necesaria para informes de costos detallados. Los presupuestos se centran más en rastrear y controlar costos que en categorizarlos.",
            "Habilitar S3 Requester Pays para almacenamiento específico de departamentos no es relevante en este contexto. Esta característica permite a los usuarios cobrar al solicitante del acceso a datos de S3, pero no ayuda a categorizar costos entre departamentos o generar informes de costos detallados."
        ]
    },
    {
        "Question Number": "61",
        "Situation": "Una empresa de comercio electrónico opera múltiples cuentas de AWS a través de varias unidades de negocio, como marketing, ventas y desarrollo, y desea rastrear y monitorear con precisión los costos de AWS por departamento. Necesitan un método para asignar recursos compartidos como bases de datos y recursos de computación al presupuesto de cada departamento y asegurar un seguimiento de costos transparente para cada unidad de negocio.",
        "Question": "¿Qué característica de gestión de costos de AWS deberían usar para cumplir con estos requisitos?",
        "Options": {
            "1": "Usar facturación consolidada en todas las cuentas y aplicar etiquetas de asignación de costos para asignar costos a departamentos específicos",
            "2": "Crear una sola cuenta de AWS para todos los departamentos y usar prácticas de facturación internas para asignar costos",
            "3": "Habilitar S3 Requester Pays para los recursos de cada departamento para transferir costos a usuarios individuales dentro de cada departamento",
            "4": "Configurar alertas de facturación separadas para cada departamento para rastrear costos de manera independiente"
        },
        "Correct Answer": "Usar facturación consolidada en todas las cuentas y aplicar etiquetas de asignación de costos para asignar costos a departamentos específicos",
        "Explanation": "Usar facturación consolidada permite a la empresa de comercio electrónico gestionar múltiples cuentas de AWS bajo una sola cuenta de facturación, lo que simplifica el proceso de pago. Al aplicar etiquetas de asignación de costos, pueden categorizar y rastrear los costos asociados con recursos específicos utilizados por cada departamento. Este método proporciona transparencia en la asignación de costos y permite un seguimiento preciso del presupuesto para cada unidad de negocio, cumpliendo con el requisito de monitorear los costos de AWS de manera efectiva.",
        "Other Options": [
            "Crear una sola cuenta de AWS para todos los departamentos complicaría el seguimiento de costos, ya que todos los recursos se agregarían bajo una cuenta. Este enfoque carece de la granularidad necesaria para asignar costos con precisión a departamentos individuales, lo que dificultaría la gestión efectiva de los presupuestos.",
            "Habilitar S3 Requester Pays no es adecuado para rastrear costos entre departamentos, ya que solo se aplica a los recursos de Amazon S3. Esta característica permite que el solicitante de los datos pague los costos de transferencia de datos, pero no proporciona una solución integral para rastrear y asignar costos a través de varios servicios y departamentos de AWS.",
            "Configurar alertas de facturación separadas para cada departamento puede ayudar a monitorear costos, pero no proporciona un método para asignar recursos compartidos o rastrear costos con precisión contra los presupuestos departamentales. Las alertas son reactivas en lugar de proactivas y no facilitan la gestión o asignación detallada de costos."
        ]
    },
    {
        "Question Number": "62",
        "Situation": "Una empresa financiera quiere cifrar datos en tránsito entre su entorno local y AWS. Los datos deben ser cifrados utilizando un certificado TLS.",
        "Question": "¿Qué servicio de AWS debería usar la empresa para gestionar y desplegar el certificado TLS?",
        "Options": {
            "1": "AWS Key Management Service (AWS KMS)",
            "2": "AWS Secrets Manager",
            "3": "AWS Certificate Manager (ACM)",
            "4": "Amazon S3"
        },
        "Correct Answer": "AWS Certificate Manager (ACM)",
        "Explanation": "AWS Certificate Manager (ACM) está diseñado específicamente para gestionar y desplegar certificados TLS/SSL para su uso con servicios y aplicaciones de AWS. Simplifica el proceso de aprovisionamiento, gestión y despliegue de certificados, permitiendo a la empresa financiera cifrar fácilmente los datos en tránsito entre su entorno local y AWS. ACM también maneja la renovación de certificados automáticamente, asegurando que el cifrado permanezca válido sin intervención manual.",
        "Other Options": [
            "AWS Key Management Service (AWS KMS) se utiliza principalmente para gestionar claves criptográficas para sus aplicaciones y servicios. Si bien juega un papel crucial en los procesos de cifrado y descifrado, no gestiona certificados TLS directamente.",
            "AWS Secrets Manager se utiliza para gestionar secretos como credenciales de bases de datos, claves API y otra información sensible. No proporciona funcionalidad para gestionar certificados TLS, lo que lo hace inadecuado para este requisito específico.",
            "Amazon S3 es un servicio de almacenamiento que permite almacenar y recuperar cualquier cantidad de datos en cualquier momento. No tiene capacidades para gestionar o desplegar certificados TLS, y por lo tanto no es relevante para la tarea de cifrar datos en tránsito."
        ]
    },
    {
        "Question Number": "63",
        "Situation": "Una empresa está desarrollando una aplicación web en AWS que requiere autenticación segura de usuarios y protección contra amenazas externas, como ataques DDoS e inyecciones SQL. La aplicación también necesita asegurar que las credenciales de los usuarios se gestionen de manera segura y que los usuarios tengan acceso limitado según sus roles.",
        "Question": "¿Qué combinación de servicios de AWS debería usar la empresa para cumplir con estos requisitos de seguridad?",
        "Options": {
            "1": "Usar AWS Shield para protección DDoS, Amazon Cognito para autenticación de usuarios y AWS WAF para bloquear ataques de inyección SQL.",
            "2": "Usar Amazon GuardDuty para protección DDoS, roles de IAM para autenticación de usuarios y AWS CloudFront para protección contra inyecciones SQL.",
            "3": "Usar AWS Identity Center (AWS SSO) para autenticación de usuarios, AWS WAF para protección DDoS y Amazon Macie para prevención de inyecciones SQL.",
            "4": "Usar AWS Secrets Manager para autenticación de usuarios, AWS Shield para protección DDoS y AWS Lambda para protección contra inyecciones SQL."
        },
        "Correct Answer": "Usar AWS Shield para protección DDoS, Amazon Cognito para autenticación de usuarios y AWS WAF para bloquear ataques de inyección SQL.",
        "Explanation": "Esta combinación de servicios aborda efectivamente todos los requisitos de seguridad descritos en el escenario. AWS Shield proporciona una robusta protección DDoS, que es esencial para salvaguardar la aplicación web contra amenazas externas. Amazon Cognito está diseñado específicamente para la autenticación de usuarios, permitiendo la gestión segura de credenciales de usuarios y habilitando el control de acceso basado en roles. AWS WAF (Web Application Firewall) está específicamente adaptado para proteger aplicaciones web de exploits comunes, incluidas las inyecciones SQL, al permitir crear reglas que bloqueen tales solicitudes maliciosas.",
        "Other Options": [
            "Usar Amazon GuardDuty para protección DDoS es incorrecto porque GuardDuty es principalmente un servicio de detección de amenazas que monitorea actividad maliciosa y comportamiento no autorizado, en lugar de proporcionar protección DDoS directa. Los roles de IAM no son un servicio de autenticación de usuarios; se utilizan para otorgar permisos a recursos de AWS. AWS CloudFront es una red de entrega de contenido y no proporciona protección directa contra inyecciones SQL.",
            "AWS Identity Center (AWS SSO) es un servicio para inicio de sesión único y autenticación de usuarios, pero AWS WAF no está diseñado para protección DDoS; está destinado a la seguridad de aplicaciones web. Amazon Macie es un servicio de seguridad y privacidad de datos que ayuda a descubrir y proteger datos sensibles, pero no previene ataques de inyección SQL.",
            "AWS Secrets Manager se utiliza para gestionar secretos como claves API y credenciales de bases de datos, pero no es un servicio de autenticación. AWS Shield es apropiado para protección DDoS, pero AWS Lambda no proporciona inherentemente protección contra inyecciones SQL; es un servicio de computación que puede ejecutar código en respuesta a eventos y no aborda directamente la seguridad de aplicaciones web."
        ]
    },
    {
        "Question Number": "64",
        "Situation": "Una empresa está configurando una Nube Privada Virtual (VPC) y necesita diseñar múltiples subredes para una aplicación que se desplegará en múltiples Zonas de Disponibilidad (AZ). Quieren asegurarse de que las direcciones IP dentro de cada subred estén correctamente asignadas y reservadas para funciones específicas dentro de la red.",
        "Question": "¿Cuál de las siguientes afirmaciones describe mejor las reglas para configurar subredes de VPC y manejar direcciones IP reservadas?",
        "Options": {
            "1": "Una sola subred puede abarcar múltiples zonas de disponibilidad para maximizar la utilización de direcciones IP dentro del bloque CIDR de la VPC.",
            "2": "Cada subred tiene un rango de direcciones IP, con cinco direcciones IP específicas en cada subred reservadas automáticamente por AWS para funciones de red, incluyendo direcciones para DNS y enrutamiento de VPC.",
            "3": "Los bloques CIDR IPv4 asignados a las subredes pueden superponerse entre sí para optimizar el uso del espacio, especialmente cuando las subredes están en diferentes AZ.",
            "4": "Los conjuntos de opciones DHCP en AWS permiten editar y eliminar direcciones IP asignadas automáticamente dentro de cada subred."
        },
        "Correct Answer": "Cada subred tiene un rango de direcciones IP, con cinco direcciones IP específicas en cada subred reservadas automáticamente por AWS para funciones de red, incluyendo direcciones para DNS y enrutamiento de VPC.",
        "Explanation": "En AWS, a cada subred se le asigna un rango de direcciones IP del bloque CIDR de la VPC, y AWS reserva automáticamente cinco direcciones IP en cada subred para funciones específicas de red. Estas direcciones reservadas se utilizan para el enrutador de VPC, DNS y otros servicios esenciales, asegurando que no estén disponibles para asignación a instancias. Esta regla es crucial para mantener la funcionalidad de la VPC y sus subredes.",
        "Other Options": [
            "Una sola subred no puede abarcar múltiples zonas de disponibilidad; cada subred debe residir completamente dentro de una zona de disponibilidad. Este diseño asegura que los recursos en diferentes AZ estén aislados y puedan proporcionar alta disponibilidad y tolerancia a fallos.",
            "Los bloques CIDR IPv4 asignados a las subredes no pueden superponerse entre sí. Cada subred debe tener un rango único de direcciones IP para evitar conflictos y asegurar un enrutamiento adecuado dentro de la VPC. Los bloques CIDR superpuestos llevarían a problemas de enrutamiento y conectividad.",
            "Los conjuntos de opciones DHCP en AWS no permiten editar ni eliminar direcciones IP asignadas automáticamente dentro de cada subred. Los conjuntos de opciones DHCP se utilizan para configurar ajustes de DHCP para instancias, como servidores de nombres de dominio y servidores NTP, pero no afectan las direcciones IP reservadas dentro de la subred."
        ]
    },
    {
        "Question Number": "65",
        "Situation": "Una empresa está desplegando una aplicación web global y quiere asegurar alta disponibilidad y acceso de baja latencia para usuarios en todo el mundo. La empresa está utilizando Amazon Route 53 para la gestión de DNS y está considerando desplegar la aplicación en múltiples Zonas de Disponibilidad (AZ) dentro de múltiples Regiones de AWS para asegurar la tolerancia a fallos.",
        "Question": "¿Cuál de los siguientes enfoques cumpliría mejor con los requisitos de la empresa para alta disponibilidad y recuperación ante desastres?",
        "Options": {
            "1": "Usar Route 53 con enrutamiento por geolocalización para dirigir a los usuarios a la región más cercana, y desplegar la aplicación en múltiples Zonas de Disponibilidad en esas regiones para asegurar alta disponibilidad.",
            "2": "Usar Route 53 con una política de enrutamiento de conmutación por error para asegurar que el tráfico se dirija a una región de respaldo en caso de una falla en la región primaria.",
            "3": "Desplegar la aplicación en una sola Zona de Disponibilidad en una región para simplificar la gestión y reducir la complejidad operativa.",
            "4": "Usar Route 53 con enrutamiento ponderado para dirigir el tráfico de manera equitativa a todas las regiones, independientemente de la disponibilidad o latencia, para una distribución de tráfico más equilibrada."
        },
        "Correct Answer": "Usar Route 53 con enrutamiento por geolocalización para dirigir a los usuarios a la región más cercana, y desplegar la aplicación en múltiples Zonas de Disponibilidad en esas regiones para asegurar alta disponibilidad.",
        "Explanation": "Usar Route 53 con enrutamiento por geolocalización permite a la empresa dirigir a los usuarios a la región de AWS más cercana, lo que minimiza la latencia y mejora la experiencia del usuario. Al desplegar la aplicación en múltiples Zonas de Disponibilidad (AZ) dentro de esas regiones, la empresa puede asegurar alta disponibilidad, ya que el tráfico puede ser dirigido automáticamente a instancias saludables en diferentes AZ en caso de una falla. Este enfoque también proporciona capacidades de tolerancia a fallos y recuperación ante desastres, ya que aprovecha la redundancia de múltiples AZ y regiones.",
        "Other Options": [
            "Usar Route 53 con una política de enrutamiento de conmutación por error es beneficioso para la recuperación ante desastres, pero se centra principalmente en dirigir el tráfico a una región de respaldo solo cuando la región primaria falla. Esto no aborda la necesidad de acceso de baja latencia para usuarios en todo el mundo, ya que puede no dirigir a los usuarios a la región más cercana para un rendimiento óptimo.",
            "Desplegar la aplicación en una sola Zona de Disponibilidad en una región aumenta significativamente el riesgo de tiempo de inactividad y no proporciona alta disponibilidad ni tolerancia a fallos. Si esa única AZ experimenta una interrupción, toda la aplicación estaría indisponible, lo que contradice los requisitos de la empresa para alta disponibilidad.",
            "Usar Route 53 con enrutamiento ponderado para dirigir el tráfico de manera equitativa a todas las regiones ignora la disponibilidad y latencia de esas regiones. Esto podría llevar a un rendimiento subóptimo para los usuarios, ya que el tráfico puede ser enviado a una región que está más lejos o experimentando problemas, fallando así en cumplir con los objetivos de la empresa para acceso de baja latencia y alta disponibilidad."
        ]
    }
]