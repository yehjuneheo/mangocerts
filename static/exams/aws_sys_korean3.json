[
    {
        "Question Number": "1",
        "Situation": "글로벌 전자상거래 회사는 사용자의 지리적 위치에 따라 가장 가까운 데이터 센터로 사용자를 안내하여 웹사이트의 성능과 사용자 경험을 최적화하고자 합니다. 이를 위해 DNS 라우팅 정책을 구현하는 것을 고려하고 있습니다.",
        "Question": "회사가 사용자의 지리적 위치에 따라 가장 가까운 데이터 센터로 라우팅되도록 보장하기 위해 어떤 AWS Route 53 라우팅 정책을 사용해야 합니까?",
        "Options": {
            "1": "가중치 라우팅",
            "2": "지연 시간 기반 라우팅",
            "3": "지리적 위치 라우팅",
            "4": "페일오버 라우팅"
        },
        "Correct Answer": "지리적 위치 라우팅",
        "Explanation": "지리적 위치 라우팅은 사용자의 지리적 위치에 따라 트래픽을 라우팅할 수 있게 해줍니다. 이는 사용자를 가장 가까운 데이터 센터로 안내하여 지연 시간을 줄임으로써 경험을 향상시키는 가장 적합한 옵션입니다.",
        "Other Options": [
            "지연 시간 기반 라우팅은 가장 낮은 지연 시간이 있는 지역으로 트래픽을 라우팅하지만, 이 시나리오에서 필요한 사용자의 지리적 위치를 특별히 고려하지 않습니다.",
            "가중치 라우팅은 할당된 가중치에 따라 여러 리소스에 트래픽을 분산시키지만, 여기서의 주요 요구 사항인 사용자의 지리적 위치를 고려하지 않습니다.",
            "페일오버 라우팅은 기본 리소스가 실패할 경우 건강한 리소스로 트래픽을 라우팅하기 위해 설계되었으며, 사용자 위치에 기반한 솔루션을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "2",
        "Situation": "한 회사는 AWS에 호스팅된 웹 애플리케이션에 대한 업데이트를 자주 배포합니다. DevOps 팀은 다운타임과 오류를 최소화하기 위해 배포 프로세스를 자동화하는 것을 목표로 하고 있습니다. 이 목표를 달성하기 위해 AWS 서비스를 사용할 것을 고려하고 있습니다.",
        "Question": "DevOps 팀이 웹 애플리케이션 업데이트의 배포를 효율적으로 자동화하기 위해 어떤 AWS 서비스를 사용해야 합니까?",
        "Options": {
            "1": "AWS CodeDeploy",
            "2": "AWS Lambda",
            "3": "Amazon EC2 Auto Scaling",
            "4": "AWS Elastic Beanstalk"
        },
        "Correct Answer": "AWS CodeDeploy",
        "Explanation": "AWS CodeDeploy는 Amazon EC2 및 AWS Lambda와 같은 다양한 컴퓨팅 서비스에 애플리케이션 배포를 자동화하기 위해 특별히 설계되었습니다. 배포 프로세스를 관리하고 다운타임을 최소화하는 데 도움을 주어 DevOps 팀의 요구 사항에 가장 적합한 선택입니다.",
        "Other Options": [
            "AWS Elastic Beanstalk는 웹 애플리케이션을 관리할 수 있는 플랫폼 서비스(PaaS)지만, 추가 구성 없이 기존 애플리케이션의 배포 프로세스를 자동화하는 데만 집중하지 않습니다.",
            "AWS Lambda는 이벤트에 응답하여 코드를 실행하는 서버리스 컴퓨팅 서비스이지만, 전체 애플리케이션을 배포하거나 배포 생애 주기를 관리하는 데 주로 사용되지 않습니다.",
            "Amazon EC2 Auto Scaling은 수요에 따라 EC2 인스턴스의 수를 자동으로 조정하는 데 사용되지만, 애플리케이션 업데이트의 배포를 처리하지 않습니다."
        ]
    },
    {
        "Question Number": "3",
        "Situation": "한 회사는 최근에 애플리케이션을 AWS로 마이그레이션하였으며, VPC 흐름 로그를 사용하여 네트워크 트래픽을 모니터링하고 있습니다. 팀은 애플리케이션에 접근할 때 사용자가 경험하는 지연 시간 문제의 원인을 파악하기 위해 로그를 분석해야 합니다.",
        "Question": "팀이 지연 시간 문제를 해결하기 위해 VPC 흐름 로그를 효율적으로 해석하는 데 도움이 되는 다음 행동 중 어떤 것이 있습니까?",
        "Options": {
            "1": "흐름 로그에서 추가 메타데이터를 캡처하기 위해 VPC에 대한 상세 모니터링을 활성화합니다.",
            "2": "VPC 리소스와 관련된 API 호출을 캡처하기 위해 Amazon CloudTrail 트레일을 설정합니다.",
            "3": "Amazon Athena를 사용하여 S3에 저장된 흐름 로그를 쿼리하여 특정 트래픽 패턴을 분석합니다.",
            "4": "흐름 로그의 보존 기간을 늘려 더 많은 역사적 데이터를 수집합니다."
        },
        "Correct Answer": "Amazon Athena를 사용하여 S3에 저장된 흐름 로그를 쿼리하여 특정 트래픽 패턴을 분석합니다.",
        "Explanation": "Amazon Athena를 사용하면 팀이 S3에 저장된 흐름 로그에 대해 SQL 쿼리를 직접 실행할 수 있어, 지연 시간 문제와 관련된 특정 트래픽 패턴을 필터링하고 분석하는 것이 더 쉬워지며, 신속하게 실행 가능한 통찰력을 제공합니다.",
        "Other Options": [
            "상세 모니터링을 활성화하는 것은 VPC 흐름 로그에 직접적인 영향을 미치지 않습니다. 추가 메트릭을 제공하지만, 이미 관련 트래픽 데이터를 캡처하고 있는 흐름 로그의 내용을 향상시키지 않습니다.",
            "CloudTrail을 설정하면 VPC 작업과 관련된 API 호출을 기록하지만, VPC 흐름 로그가 캡처하는 실제 네트워크 트래픽 패턴에 대한 가시성을 제공하지 않으므로 지연 시간 문제를 진단하는 데 덜 유용합니다.",
            "흐름 로그의 보존 기간을 늘리면 더 많은 역사적 데이터 수집이 가능하지만, 현재의 지연 시간 문제를 효과적으로 해결하기 위한 즉각적인 분석에는 도움이 되지 않습니다."
        ]
    },
    {
        "Question Number": "4",
        "Situation": "Amazon S3에 호스팅된 애플리케이션이 AWS CloudFront의 오래된 캐시 콘텐츠로 인해 콘텐츠 전송 지연을 겪고 있습니다. SysOps 관리자는 사용자가 상당한 지연 없이 최신 콘텐츠를 받을 수 있도록 해야 합니다.",
        "Question": "SysOps 관리자가 CloudFront의 캐싱 문제를 해결하기 위해 어떤 조치를 취해야 합니까?",
        "Options": {
            "1": "업데이트된 설정으로 새로운 CloudFront 배포를 생성합니다.",
            "2": "CloudFront 배포 설정을 변경하여 캐싱을 비활성화합니다.",
            "3": "영향을 받는 객체에 대해 CloudFront 캐시를 무효화합니다.",
            "4": "S3 버킷 정책을 수정하여 공개 액세스를 허용합니다."
        },
        "Correct Answer": "영향을 받는 객체에 대해 CloudFront 캐시를 무효화합니다.",
        "Explanation": "영향을 받는 객체에 대해 CloudFront 캐시를 무효화하면 오래된 콘텐츠가 제거되고 원본에서 최신 버전이 사용자에게 제공됩니다. 이는 새로운 배포를 생성하거나 배포 설정을 변경하지 않고 콘텐츠를 새로 고치는 가장 효율적인 방법입니다.",
        "Other Options": [
            "CloudFront 배포 설정을 변경하여 캐싱을 비활성화하는 것은 비현실적이며, 이는 캐싱 및 성능 최적화를 위해 CloudFront를 사용하는 이점을 무효화합니다.",
            "S3 버킷 정책을 수정하여 공개 액세스를 허용하는 것은 캐싱 문제를 해결하지 않으며, 버킷의 내용을 공개적으로 노출하여 보안 위험을 초래할 수 있습니다.",
            "업데이트된 설정으로 새로운 CloudFront 배포를 생성하는 것은 불필요하며, 기존 배포에서 무효화를 수행할 수 있을 때 캐싱 문제를 해결하는 데 비효율적입니다."
        ]
    },
    {
        "Question Number": "5",
        "Situation": "SysOps 관리자는 조직 내 여러 계정에서 AWS 비용을 효과적으로 모니터링하고 제어하는 임무를 맡고 있습니다. 관리자는 조직이 정의된 예산 한도 내에 머물도록 하고, 비용이 해당 한도에 접근하거나 초과할 경우 알림을 받기를 원합니다. 관리자는 특정 서비스 사용량을 추적하는 데에도 관심이 있으며, 예산에 대한 사용자 정의 시작 및 종료 날짜를 정의할 수 있는 유연성을 원합니다.",
        "Question": "효과적인 예산 관리를 구현하기 위해 관리자가 취해야 할 조치는 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "AWS Budgets를 설정하여 Amazon RDS의 예약 활용도를 모니터링하고 활용도가 지정된 임계값 아래로 떨어질 때 알림을 보냅니다.",
            "2": "특정 AWS 서비스 및 연결된 계정과 관련된 비용을 추적하는 예산을 AWS Budgets에서 생성합니다.",
            "3": "어떠한 차원도 지정하지 않고 조직 내 모든 리소스를 추적하는 예산을 AWS Budgets에서 생성합니다.",
            "4": "사용자 정의 시작 및 종료 날짜로 월별, 분기별 또는 연간과 같은 여러 기간에 걸친 예산을 정의합니다.",
            "5": "예산 알림을 Amazon Simple Notification Service (SNS)를 통해서만 전송하도록 구성하고 이메일 알림은 사용하지 않습니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "특정 AWS 서비스 및 연결된 계정과 관련된 비용을 추적하는 예산을 AWS Budgets에서 생성합니다.",
            "사용자 정의 시작 및 종료 날짜로 월별, 분기별 또는 연간과 같은 여러 기간에 걸친 예산을 정의합니다."
        ],
        "Explanation": "특정 AWS 서비스 및 연결된 계정과 관련된 비용을 추적하는 예산을 AWS Budgets에서 생성하면 관리자가 비용에 대한 세부적인 제어를 할 수 있으며, 예산 임계값에 접근할 때 알림을 받을 수 있습니다. 또한, 사용자 정의 시작 및 종료 날짜로 여러 기간에 걸친 예산을 정의하면 예산 관리의 유연성을 제공하여 조직이 변화하는 재정적 요구에 적응할 수 있게 합니다.",
        "Other Options": [
            "이 옵션은 잘못되었습니다. 특정 AWS 서비스 및 연결된 계정과 관련된 비용을 추적하는 것이 중요하지만, 차원을 지정하지 않고 모든 리소스를 단순히 추적하는 것은 비용을 효과적으로 관리하는 데 필요한 세부 사항이 부족합니다.",
            "이 옵션은 최적이 아닙니다. 예산 알림을 SNS 알림으로만 제한하면, 이메일과 SNS를 모두 활용하는 것이 더 넓은 범위와 신뢰성을 보장합니다.",
            "이 옵션은 부분적으로 맞지만 구체성이 부족합니다. 예약 활용도를 모니터링하는 것이 중요하지만, 비용 추적과 결합되어야 예산 관리에 대한 포괄적인 관점을 제공할 수 있습니다."
        ]
    },
    {
        "Question Number": "6",
        "Situation": "한 회사가 AWS에 여러 애플리케이션을 배포하고 모든 AWS 서비스에 대한 API 호출이 감사 목적으로 기록되도록 하기를 원합니다. SysOps 관리자는 AWS 계정 전반에 걸쳐 모든 API 활동을 캡처하고 분석을 위한 상세 로그를 제공하는 솔루션을 구현해야 합니다. 이 솔루션은 또한 컴플라이언스 및 보안 검토를 위해 로그에 쉽게 접근할 수 있도록 해야 합니다.",
        "Question": "SysOps 관리자가 AWS 계정 전반에 걸쳐 모든 AWS API 호출을 포괄적으로 기록하기 위해 가장 좋은 접근 방식은 무엇입니까?",
        "Options": {
            "1": "Amazon CloudWatch Logs를 설정하여 계정에서 사용되는 모든 AWS 서비스의 로그를 수집하고 분석하여 API 호출이 캡처되도록 합니다.",
            "2": "AWS Lambda 함수를 활용하여 API 요청을 캡처하고 Amazon S3에 기록하여 향후 분석 및 감사에 사용합니다.",
            "3": "Amazon Inspector를 구현하여 AWS 서비스에 대한 모든 API 호출을 모니터링하고 기록하며 이 데이터를 기반으로 보고서를 생성합니다.",
            "4": "모든 리전에서 AWS CloudTrail을 활성화하고 AWS 계정의 모든 관리 이벤트 및 데이터 이벤트를 기록하도록 구성합니다."
        },
        "Correct Answer": "모든 리전에서 AWS CloudTrail을 활성화하고 AWS 계정의 모든 관리 이벤트 및 데이터 이벤트를 기록하도록 구성합니다.",
        "Explanation": "모든 리전에서 AWS CloudTrail을 활성화하면 AWS 서비스에 대한 모든 API 호출이 기록되며, 관리 이벤트 및 데이터 이벤트가 포함됩니다. 이는 보안 및 컴플라이언스 목적을 위한 포괄적인 감사 추적을 제공하므로 계정 전반에 걸쳐 API 활동을 기록하는 가장 좋은 접근 방식입니다.",
        "Other Options": [
            "Amazon CloudWatch Logs를 설정하는 것만으로는 AWS API 호출을 기록하기에 충분하지 않습니다. CloudWatch는 애플리케이션 메트릭 및 사용자 정의 로그 이벤트를 기록하는 데 더 중점을 두고 있으며, 모든 서비스의 API 활동을 캡처하는 데는 적합하지 않습니다.",
            "AWS Lambda 함수를 활용하여 API 요청을 캡처하는 것은 사용자 정의 개발이 필요하며, 추가 노력과 구성이 없이는 모든 AWS 서비스를 자동으로 포함하지 않기 때문에 포괄적인 솔루션이 아닙니다.",
            "Amazon Inspector를 구현하는 것은 애플리케이션 및 리소스의 보안 평가에 주로 초점을 맞추고 있으며, AWS 계정 전반에 걸쳐 API 호출을 기록하는 데는 적합하지 않은 선택입니다."
        ]
    },
    {
        "Question Number": "7",
        "Situation": "Amazon EBS 볼륨에서 실행되는 애플리케이션은 최적의 작동을 위해 높은 IOPS 성능이 필요합니다. SysOps 관리자는 AWS의 최대 IOPS 대 볼륨 크기 비율 가이드라인을 준수하면서 애플리케이션에 적절한 양의 IOPS를 프로비저닝해야 합니다.",
        "Question": "Amazon EBS 볼륨에 대해 구성할 수 있는 프로비저닝된 IOPS와 요청된 볼륨 크기(GiB)의 최대 비율은 얼마입니까?",
        "Options": {
            "1": "60:1",
            "2": "30:1",
            "3": "50:1",
            "4": "40:1"
        },
        "Correct Answer": "50:1",
        "Explanation": "Amazon EBS 볼륨에 대해 요청된 볼륨 크기(GiB)와 프로비저닝된 IOPS의 최대 비율은 50:1입니다. 이는 볼륨 크기 1GiB당 최대 50 IOPS를 프로비저닝할 수 있어, 높은 수요의 애플리케이션에 최적의 성능을 보장합니다.",
        "Other Options": [
            "60:1은 최대 허용 비율인 50:1을 초과하므로 잘못된 답변입니다. 이는 부적절한 프로비저닝 및 성능 문제를 초래할 수 있습니다.",
            "40:1은 최대 한도 아래에 있지만 AWS에서 IOPS 프로비저닝을 위해 허용된 전체 용량을 활용하지 않으므로 잘못된 답변입니다.",
            "30:1은 40:1과 같은 이유로 잘못된 답변입니다. 한도 내에 있지만 볼륨 크기에 따라 프로비저닝할 수 있는 IOPS를 최적화하지 않습니다."
        ]
    },
    {
        "Question Number": "8",
        "Situation": "한 회사가 여러 서브넷, 라우트 테이블 및 보안 그룹으로 구성된 Virtual Private Cloud (VPC)를 설정했습니다. 프라이빗 서브넷에서 실행되는 애플리케이션 인스턴스는 소프트웨어 업데이트를 위해 인터넷에 접근해야 하지만 공용 인터넷에서는 접근할 수 없어야 합니다. 이 요구 사항을 충족하기 위해 네트워크 설정을 구성하는 임무를 맡았습니다.",
        "Question": "다음 구성 중 프라이빗 서브넷의 인스턴스가 인터넷에 접근할 수 있도록 하면서 공용 인터넷에서 직접 접근할 수 없도록 하는 구성은 무엇입니까?",
        "Options": {
            "1": "VPC에 인터넷 게이트웨이를 연결하고 인스턴스의 보안 그룹을 수정하여 인터넷에서의 수신 트래픽을 허용합니다.",
            "2": "인터넷에 직접 접근할 수 있는 다른 VPC와 VPC 피어링을 활성화합니다.",
            "3": "퍼블릭 서브넷에 NAT 게이트웨이를 생성하고 프라이빗 서브넷의 라우트 테이블을 업데이트하여 인터넷 트래픽을 NAT 게이트웨이를 통해 라우팅합니다.",
            "4": "퍼블릭 서브넷에 Elastic Load Balancer (ELB)를 생성하고 프라이빗 서브넷의 인스턴스를 ELB에 등록합니다."
        },
        "Correct Answer": "퍼블릭 서브넷에 NAT 게이트웨이를 생성하고 프라이빗 서브넷의 라우트 테이블을 업데이트하여 인터넷 트래픽을 NAT 게이트웨이를 통해 라우팅합니다.",
        "Explanation": "퍼블릭 서브넷에 NAT 게이트웨이를 생성하면 프라이빗 서브넷의 인스턴스가 인터넷으로 아웃바운드 트래픽을 시작할 수 있지만 인터넷에서의 수신 트래픽은 차단되어, 공용 접근 없이 인터넷에 접근할 수 있는 요구 사항을 충족합니다.",
        "Other Options": [
            "VPC에 인터넷 게이트웨이를 연결하고 보안 그룹을 수정하면 인터넷에서 인스턴스에 직접 접근할 수 있게 되어 요구 사항과 모순됩니다.",
            "VPC 피어링을 활성화해도 피어링된 VPC에 NAT 또는 유사한 구성이 없는 한 프라이빗 인스턴스에 인터넷 접근을 제공하지 않으며, 요구 사항을 직접 충족하지 않습니다.",
            "Elastic Load Balancer를 생성하면 공용 인터넷에서 인스턴스에 접근할 수 있게 되어, 직접적인 공용 접근을 차단해야 하는 요구 사항을 충족하지 않습니다."
        ]
    },
    {
        "Question Number": "9",
        "Situation": "한 회사가 Classic Load Balancer를 사용하여 여러 가용 영역에 걸쳐 들어오는 트래픽을 분산하는 중요한 애플리케이션을 운영하고 있습니다. 그들은 인스턴스 가용성 문제를 겪고 있으며 애플리케이션의 복원력과 성능을 개선하고자 합니다.",
        "Question": "회사가 Classic Load Balancer를 사용하여 애플리케이션의 복원력과 성능을 개선할 수 있는 방법은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "크로스 존 로드 밸런싱을 활성화하여 모든 인스턴스에 트래픽을 고르게 분산합니다.",
            "2": "트래픽 패턴과 수요에 맞게 인스턴스 유형을 정기적으로 검토하고 조정합니다.",
            "3": "헬스 체크를 구성하여 비정상 인스턴스를 로드 밸런서에서 자동으로 제거합니다.",
            "4": "각 가용 영역에 동일한 수의 인스턴스를 수동으로 유지하여 균형 잡힌 트래픽을 보장합니다.",
            "5": "더 나은 성능을 위해 Classic Load Balancer 대신 Network Load Balancer를 사용합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "크로스 존 로드 밸런싱을 활성화하여 모든 인스턴스에 트래픽을 고르게 분산합니다.",
            "헬스 체크를 구성하여 비정상 인스턴스를 로드 밸런서에서 자동으로 제거합니다."
        ],
        "Explanation": "크로스 존 로드 밸런싱을 활성화하면 Classic Load Balancer가 모든 활성화된 가용 영역의 모든 등록된 인스턴스에 들어오는 트래픽을 분산할 수 있어, 인스턴스 실패 시 트래픽 처리 능력이 향상됩니다. 헬스 체크를 구성하면 건강한 인스턴스만 트래픽을 수신하게 되어 복원력과 성능이 향상됩니다.",
        "Other Options": [
            "각 가용 영역에 동일한 수의 인스턴스를 수동으로 유지하는 것은 비효율적인 자원 사용을 초래하고, 특히 트래픽 급증 시 스케일링을 복잡하게 만들 수 있습니다. 크로스 존 로드 밸런싱이 활성화되어 있다면 필요하지 않습니다.",
            "Network Load Balancer로 전환하는 것은 Classic Load Balancer의 복원력을 직접적으로 개선하지 않으며, 현재 인프라에 따라 완전한 마이그레이션이 필요하지 않을 수 있습니다.",
            "인스턴스 유형을 정기적으로 검토하고 조정하는 것은 최적화를 위한 좋은 관행이지만, 인스턴스 가용성 및 트래픽 분산의 즉각적인 문제를 직접적으로 해결하지는 않습니다."
        ]
    },
    {
        "Question Number": "10",
        "Situation": "한 회사가 Amazon EC2 인스턴스에서 여러 애플리케이션을 실행하고 있으며, 변동하는 작업 부하로 인해 성능 문제를 겪고 있습니다. SysOps 관리자는 비용을 관리하면서 효율적인 자원 활용을 보장하기 위해 성능 최적화 전략을 구현해야 합니다.",
        "Question": "SysOps 관리자가 EC2 인스턴스의 성능과 비용을 최적화하기 위해 어떤 접근 방식을 취해야 합니까?",
        "Options": {
            "1": "CPU 사용량을 모니터링하기 위해 CloudWatch 경고를 설정하고 사용량이 특정 임계값을 초과할 때 인스턴스를 종료합니다.",
            "2": "모든 작업 부하에 대해 EC2 예약 인스턴스를 사용하여 비용 예측 가능성을 보장하고 수요에 따라 확장하는 것을 피합니다.",
            "3": "Auto Scaling을 구현하여 수요에 따라 EC2 인스턴스 수를 조정하고 비핵심 작업 부하에 대해 Spot 인스턴스를 사용합니다.",
            "4": "성능 문제가 발생할 때마다 수동으로 인스턴스 유형을 더 큰 크기로 조정하여 부하를 처리합니다."
        },
        "Correct Answer": "Auto Scaling을 구현하여 수요에 따라 EC2 인스턴스 수를 조정하고 비핵심 작업 부하에 대해 Spot 인스턴스를 사용합니다.",
        "Explanation": "Auto Scaling을 구현하면 인프라가 작업 부하에 따라 자동으로 조정되어, 피크 시간 동안 성능이 최적화되고 수요가 낮을 때 비용이 최소화됩니다. 비핵심 작업 부하에 대해 Spot 인스턴스를 사용하면 추가로 비용을 절감할 수 있습니다.",
        "Other Options": [
            "인스턴스 유형을 수동으로 조정하는 것은 비효율적이고 반응적이며, 성능 문제 발생 시 잠재적인 다운타임과 높은 비용으로 이어질 수 있습니다. 이는 변동하는 작업 부하에 대한 선제적 해결책을 제공하지 않습니다.",
            "모든 작업 부하에 대해 EC2 예약 인스턴스를 사용하는 것은 과잉 프로비저닝과 비용 증가로 이어질 수 있습니다. 이는 작업 부하의 변동성을 고려하지 않으며 사용하지 않는 용량에 대해 비용을 지불하게 될 수 있습니다.",
            "CPU 사용량에 따라 인스턴스를 종료하기 위해 CloudWatch 경고를 설정하는 것은 성능을 최적화하지 않으며, 서비스 중단을 초래할 수 있고 수요에 따라 자원을 확장하는 문제를 해결하지 않습니다."
        ]
    },
    {
        "Question Number": "11",
        "Situation": "한 회사가 데이터 접근 빈도를 분석하여 저장 비용을 최적화하려고 합니다. 그들은 접근 패턴에 따라 어떤 객체를 저비용 저장 클래스으로 전환할 수 있는지 결정하고자 합니다. 시스템 관리자(Systems Administrator)로서, 시간에 따른 저장 접근 추세에 대한 통찰력을 제공할 수 있는 솔루션을 추천해야 합니다.",
        "Question": "S3 버킷 데이터의 접근 패턴을 분석하여 적절한 저장 클래스로 전환하는 데 도움을 줄 AWS 서비스는 무엇입니까?",
        "Options": {
            "1": "S3 Inventory를 사용하여 S3 버킷에 저장된 객체의 상태를 검토하고 평가합니다.",
            "2": "S3 Storage Lens를 사용하여 추가 비용 없이 사용 및 활동 메트릭을 분석합니다.",
            "3": "S3 Analytics를 사용하여 접근 패턴을 평가하고 데이터 전환에 대한 정보에 기반한 결정을 내립니다.",
            "4": "AWS Cost Explorer를 사용하여 지출을 추적하고 데이터 접근 패턴을 식별합니다."
        },
        "Correct Answer": "S3 Analytics를 사용하여 접근 패턴을 평가하고 데이터 전환에 대한 정보에 기반한 결정을 내립니다.",
        "Explanation": "S3 Analytics는 저장 접근 패턴을 분석하기 위해 특별히 설계되었으며, 데이터가 적절한 저장 클래스로 전환될 시기를 결정하는 데 도움을 줍니다. 이 서비스는 데이터 접근 빈도에 대한 통찰력을 제공하여 저장 비용을 최적화하는 데 용이합니다.",
        "Other Options": [
            "S3 Storage Lens는 사용 및 활동에 대한 메트릭을 제공하지만, 데이터 전환을 위한 접근 패턴에 특별히 초점을 맞추지 않습니다.",
            "S3 Inventory는 객체의 포괄적인 목록을 제공하지만 접근 패턴을 분석하지 않으므로 저장 클래스 전환을 최적화하는 특정 요구에 적합하지 않습니다.",
            "AWS Cost Explorer는 비용 및 사용 데이터를 분석하는 데 사용되지만, 데이터 전환 결정을 내리는 데 필요한 S3 데이터의 접근 패턴에 대한 통찰력을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "12",
        "Situation": "한 회사가 Amazon ElastiCache를 사용하여 웹 애플리케이션을 위한 캐싱 레이어를 배포하고 있습니다. 개발 팀은 특정 인스턴스 유형과 Memcached 또는 Redis 중 선택을 포함하여 새로운 캐시 클러스터를 생성해야 합니다. 그들은 캐시 클러스터가 효율적으로 배포되고 애플리케이션의 요구 사항을 충족하는 것을 보장하고자 합니다.",
        "Question": "SysOps 관리자가 지정된 노드 유형과 엔진 옵션으로 새로운 캐시 클러스터를 생성하기 위해 어떤 API 호출을 사용해야 합니까?",
        "Options": {
            "1": "CreateCacheCluster",
            "2": "ModifyCacheCluster",
            "3": "DescribeCacheClusters",
            "4": "CreateCacheSubnetGroup"
        },
        "Correct Answer": "CreateCacheCluster",
        "Explanation": "CreateCacheCluster API는 지정된 매개변수(인스턴스 유형 및 캐싱 엔진(Memcached 또는 Redis 포함))로 새로운 캐시 클러스터를 생성하기 위해 특별히 설계되었습니다. 이 방법은 애플리케이션을 위한 새로운 캐시 클러스터를 설정하는 요구 사항을 직접적으로 충족합니다.",
        "Other Options": [
            "CreateCacheSubnetGroup은 캐시 클러스터를 위한 서브넷 그룹을 생성하는 데 사용되지만 실제로 캐시 클러스터를 생성하지는 않습니다.",
            "ModifyCacheCluster는 기존 캐시 클러스터의 설정을 변경하는 데 사용되며, 새로운 클러스터를 생성하는 데 사용되지 않습니다.",
            "DescribeCacheClusters는 기존 캐시 클러스터에 대한 정보를 검색하는 읽기 전용 작업이며, 새로운 클러스터 생성을 촉진하지 않습니다."
        ]
    },
    {
        "Question Number": "13",
        "Situation": "한 금융 서비스 회사가 EC2 인스턴스에서 호스팅되는 애플리케이션의 트랜잭션 처리 중 지연 문제를 겪고 있습니다. 이 회사는 EC2 인스턴스의 성능을 최적화하고 네트워크 통신의 지연을 줄이기를 원합니다.",
        "Question": "회사가 EC2 인스턴스의 네트워크 성능을 향상시키기 위해 어떤 옵션을 구현해야 합니까?",
        "Options": {
            "1": "더 나은 중복성을 위해 배치 그룹을 사용하지 않고 여러 가용 영역에 인스턴스를 배포합니다.",
            "2": "비용을 줄이기 위해 CPU 옵션이 낮은 다른 인스턴스 유형으로 전환합니다.",
            "3": "애플리케이션에 사용할 수 있는 IOPS를 증가시키기 위해 인스턴스 스토어 볼륨이 있는 EC2 인스턴스를 사용합니다.",
            "4": "네트워크 처리량을 개선하고 지연을 줄이기 위해 인스턴스에서 Elastic Network Adapter (ENA)를 활성화합니다."
        },
        "Correct Answer": "네트워크 처리량을 개선하고 지연을 줄이기 위해 인스턴스에서 Elastic Network Adapter (ENA)를 활성화합니다.",
        "Explanation": "Elastic Network Adapter (ENA)를 활성화하면 향상된 네트워킹 기능이 제공되어 EC2 인스턴스의 네트워크 처리량을 크게 개선하고 지연을 줄일 수 있어 고성능 애플리케이션에 적합합니다.",
        "Other Options": [
            "인스턴스 스토어 볼륨을 사용하는 것은 네트워크 성능을 직접적으로 개선하지 않으며, 저장 성능을 향상시키지만 네트워크 통신의 지연 문제를 해결하지 않습니다.",
            "배치 그룹을 사용하지 않고 여러 가용 영역에 인스턴스를 배포하면 영역 간의 네트워크 홉으로 인해 지연이 증가할 수 있으며, 최적화가 이루어지지 않을 수 있습니다.",
            "CPU가 낮은 인스턴스 유형으로 전환하면 비용이 줄어들 수 있지만, 실제로 애플리케이션의 성능이 저하되고 지연이 증가할 수 있어 이 시나리오에서는 바람직하지 않습니다."
        ]
    },
    {
        "Question Number": "14",
        "Situation": "개발 팀이 여러 AWS 서비스의 신뢰할 수 있는 오케스트레이션을 요구하는 새로운 애플리케이션을 구현하려고 합니다. 그들은 애플리케이션이 실패를 우아하게 처리하고 상태를 잃지 않고 계속 처리할 수 있도록 하고 싶어합니다. 이를 위해 AWS Step Functions를 사용하는 것을 고려하고 있습니다.",
        "Question": "AWS Step Functions가 애플리케이션의 워크플로우 관리를 위해 제공하는 이점은 무엇입니까?",
        "Options": {
            "1": "애플리케이션 성능 메트릭의 실시간 모니터링을 허용합니다.",
            "2": "트래픽에 따라 기본 인프라를 자동으로 확장합니다.",
            "3": "데이터 분석을 위한 내장된 머신 러닝 기능을 제공합니다.",
            "4": "애플리케이션 상태 및 워크플로우 실행을 중앙에서 관리할 수 있는 방법을 제공합니다."
        },
        "Correct Answer": "애플리케이션 상태 및 워크플로우 실행을 중앙에서 관리할 수 있는 방법을 제공합니다.",
        "Explanation": "AWS Step Functions는 각 단계의 실행을 추적하여 애플리케이션 상태를 관리하고 워크플로우를 조정할 수 있게 해줍니다. 이러한 중앙 관리 방식은 비즈니스 논리에 영향을 주지 않고 워크플로우를 쉽게 업데이트하고 수정할 수 있게 합니다.",
        "Other Options": [
            "실시간 모니터링은 필수적이지만, AWS Step Functions는 성능 모니터링 메트릭을 직접 제공하지 않으며, 이는 일반적으로 CloudWatch와 같은 도구에서 처리됩니다.",
            "AWS Step Functions는 인프라를 확장하지 않으며, 기본 리소스보다는 워크플로우의 오케스트레이션에 중점을 둡니다.",
            "AWS Step Functions는 내장된 머신 러닝 기능을 포함하지 않으며, 주로 워크플로우 오케스트레이션 도구입니다."
        ]
    },
    {
        "Question Number": "15",
        "Situation": "한 회사가 AWS 계정에서 예상치 못한 요금을 경험하고 있으며, SysOps 관리자는 비용을 효과적으로 모니터링하기 위해 적절한 예산 및 청구 알람을 설정해야 합니다. 관리자는 회사가 예산 내에서 유지되고 잠재적인 과소비에 대해 알림을 받을 수 있도록 하고 싶어합니다.",
        "Question": "관리자가 AWS Budgets 및 청구 알람을 구성하기 위해 어떤 단계를 취할 수 있습니까? (두 개 선택)",
        "Options": {
            "1": "월별 비용을 요약하여 지출 패턴을 시각화하는 AWS Cost Explorer 보고서를 생성합니다.",
            "2": "계정 잔액이 미리 정의된 금액을 초과할 때 이해관계자에게 알림을 보내는 청구 알람을 구현합니다.",
            "3": "월별 지출을 추적하고 예산 한도의 80%에서 알림을 설정하는 비용 예산을 생성합니다.",
            "4": "리소스 할당을 자동으로 최적화하고 비용을 줄이기 위해 절약 계획을 구성합니다.",
            "5": "예상 데이터 전송을 기반으로 사용 예산을 설정하여 50% 및 100%에서 알림을 받습니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "월별 지출을 추적하고 예산 한도의 80%에서 알림을 설정하는 비용 예산을 생성합니다.",
            "예상 데이터 전송을 기반으로 사용 예산을 설정하여 50% 및 100%에서 알림을 받습니다."
        ],
        "Explanation": "비용 예산을 생성하면 관리자가 월별 비용을 모니터링하고 지출이 특정 한도에 도달할 때 알림을 설정할 수 있어 비용을 통제하는 데 도움이 됩니다. 예상 데이터 전송을 기반으로 한 사용 예산 설정은 리소스 활용도를 사전 모니터링하여 비용이 예상치 못하게 증가하지 않도록 보장합니다.",
        "Other Options": [
            "AWS Cost Explorer 보고서를 생성하면 지출을 시각화하는 데 도움이 되지만, 실시간 알림을 제공하거나 과소비를 방지하지 않으므로 예산 관리의 독립적인 솔루션으로는 효과적이지 않습니다.",
            "계정 잔액에만 기반한 청구 알람을 구현하는 것은 특정 서비스나 사용 패턴과 관련된 비용을 모니터링하기에는 충분히 구체적이지 않으며, 이는 효과적인 예산 관리를 위해 필수적입니다.",
            "절약 계획을 구성하면 시간이 지남에 따라 비용을 최적화하지만, 현재 지출이나 사용 패턴에 대해 관리자가 즉시 알림을 받지 않도록 하여 즉각적인 비용 통제에 필요합니다."
        ]
    },
    {
        "Question Number": "16",
        "Situation": "한 스타트업이 상당한 성장을 경험하고 있으며, AWS에 호스팅된 웹 애플리케이션이 높은 부하를 받고 있습니다. 현재 애플리케이션을 위해 단일 EC2 인스턴스를 사용하고 있지만, 피크 사용 시간 동안 성능 문제를 겪고 있습니다. DevOps 팀은 비용을 효과적으로 관리하면서 성능을 최적화할 수 있는 옵션을 고려하고 있습니다. 그들은 과도한 자원 할당 없이 성능 메트릭에 기반하여 컴퓨트 리소스를 추천해야 합니다.",
        "Question": "비용을 관리하면서 피크 시간 동안 성능을 최적화하기 위해 가장 적합한 컴퓨트 리소스 추천은 무엇입니까?",
        "Options": {
            "1": "CPU와 메모리 리소스가 더 많은 더 큰 EC2 인스턴스 유형으로 전환합니다.",
            "2": "피크 트래픽 동안 EC2 인스턴스 수를 늘리기 위해 Auto Scaling을 구현합니다.",
            "3": "AWS Lambda 함수를 활용하여 들어오는 요청의 서버리스 처리를 처리합니다.",
            "4": "프로비저닝된 IOPS 스토리지를 갖춘 전용 EC2 인스턴스로 애플리케이션을 마이그레이션합니다."
        },
        "Correct Answer": "피크 트래픽 동안 EC2 인스턴스 수를 늘리기 위해 Auto Scaling을 구현합니다.",
        "Explanation": "Auto Scaling을 구현하면 애플리케이션이 수요에 따라 EC2 인스턴스 수를 자동으로 조정할 수 있어, 피크 시간 동안 성능을 유지하면서 저조한 트래픽 기간 동안 비용을 관리할 수 있습니다.",
        "Other Options": [
            "더 큰 EC2 인스턴스 유형으로 전환하면 성능이 향상될 수 있지만, 비피크 시간 동안 증가된 용량이 필요하지 않을 경우 과도한 자원 할당과 높은 비용으로 이어질 수 있습니다.",
            "AWS Lambda 함수를 활용하면 특정 작업 부하를 효율적으로 처리할 수 있지만, 지속적인 연결이나 상태 유지 작업이 필요한 경우 애플리케이션의 모든 측면에 적합하지 않을 수 있습니다.",
            "프로비저닝된 IOPS 스토리지를 갖춘 전용 EC2 인스턴스로 마이그레이션하면 성능이 향상될 수 있지만, 더 높은 비용이 발생하며 다양한 트래픽 부하를 처리하는 데 필요한 유연성을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "17",
        "Situation": "한 회사가 기존 애플리케이션을 VPC로 마이그레이션하고 있으며, 더 나은 글로벌 도달성과 연결성을 위해 IPv6를 활용할 수 있도록 보장하고자 합니다.",
        "Question": "SysOps 관리자가 VPC 및 관련 서브넷에 대해 IPv6를 활성화하기 위해 어떤 단계를 수행해야 합니까?",
        "Options": {
            "1": "모든 인스턴스를 m3.large 인스턴스 유형으로 변경하여 IPv6를 지원합니다.",
            "2": "VPC에 IPv6 CIDR 블록을 연결하고, 라우트 테이블을 업데이트하며, 보안 그룹 규칙을 수정합니다.",
            "3": "IPv4만 있는 새 VPC를 생성한 다음, IPv6가 활성화된 인스턴스를 배포합니다.",
            "4": "인스턴스에 개인 IPv4 주소를 할당하고 NAT 게이트웨이를 사용하여 IPv6 연결을 제공합니다."
        },
        "Correct Answer": "VPC에 IPv6 CIDR 블록을 연결하고, 라우트 테이블을 업데이트하며, 보안 그룹 규칙을 수정합니다.",
        "Explanation": "VPC 및 서브넷에 대해 IPv6를 활성화하려면 관리자가 먼저 VPC 및 서브넷에 IPv6 CIDR 블록을 연결해야 합니다. 또한, IPv6 트래픽을 허용하도록 라우트 테이블을 업데이트하고 IPv6 트래픽을 허용하도록 보안 그룹 규칙을 수정하는 것이 구성 과정에서 필수적인 단계입니다.",
        "Other Options": [
            "IPv4만 있는 새 VPC를 생성하는 것은 IPv6 기능을 활성화하지 않으며, 기존 설정에서 IPv6를 활용하기 위한 유효한 접근 방식이 아닙니다.",
            "모든 인스턴스를 m3.large 인스턴스 유형으로 변경하는 것은 IPv6를 활성화하는 데 불필요하며, 모든 인스턴스 유형이 이 기능을 지원하지 않기 때문에 CIDR 블록 연결 및 라우팅에 집중해야 합니다.",
            "개인 IPv4 주소를 할당하고 NAT 게이트웨이를 사용하는 것은 IPv6 연결을 촉진하지 않으며, 실제로 VPC 및 그 리소스에 대해 IPv6를 활성화하는 목표와 모순됩니다."
        ]
    },
    {
        "Question Number": "18",
        "Situation": "한 전자상거래 플랫폼은 피크 트래픽 기간 동안 EC2 인스턴스를 관리하기 위해 Auto Scaling 그룹을 사용하고 있습니다. SysOps 관리자는 성능이 저조한 특정 인스턴스를 종료하는 임무를 맡고 있지만, Auto Scaling 그룹의 전체 용량이 변경되지 않도록 하여 향후 수요를 충족하고자 합니다. 관리자는 이 작업을 수행하기 위해 AWS CLI를 사용할 계획입니다.",
        "Question": "SysOps 관리자가 Auto Scaling 그룹의 원하는 용량을 조정하지 않고 지정된 인스턴스를 종료하기 위해 어떤 AWS CLI 명령을 사용해야 합니까?",
        "Options": {
            "1": "aws autoscaling terminate-instance-in-autoscaling-group --instance-id i-123456789 --desired-capacity 5",
            "2": "aws autoscaling terminate-instance-in-autoscaling-group --instance-id i-123456789 --adjust-capacity",
            "3": "aws autoscaling terminate-instance-in-autoscaling-group --instance-id i-123456789 --no-should-decrement-desired-capacity",
            "4": "aws autoscaling terminate-instance-in-autoscaling-group --instance-id i-123456789 --should-decrement-desired-capacity"
        },
        "Correct Answer": "aws autoscaling terminate-instance-in-autoscaling-group --instance-id i-123456789 --no-should-decrement-desired-capacity",
        "Explanation": "올바른 명령은 '--no-should-decrement-desired-capacity' 매개변수를 포함하여 인스턴스를 종료하더라도 Auto Scaling 그룹의 원하는 용량을 줄이지 않도록 하여 전체 용량이 변경되지 않도록 합니다.",
        "Other Options": [
            "이 옵션은 '--should-decrement-desired-capacity' 매개변수를 잘못 사용하여 인스턴스를 종료할 때 Auto Scaling 그룹의 원하는 용량을 줄이게 됩니다.",
            "이 옵션은 종료 인스턴스에 대해 적용되지 않는 '--desired-capacity' 매개변수를 잘못 지정하여 유효하지 않습니다.",
            "이 옵션은 '--adjust-capacity'가 terminate-instance-in-autoscaling-group 명령에 대해 인식되지 않는 매개변수이므로 오류가 발생합니다."
        ]
    },
    {
        "Question Number": "19",
        "Situation": "한 회사가 AWS에 웹 애플리케이션을 배포하고 잠재적인 웹 공격 및 DDoS 공격으로부터 보호하고자 합니다. 이 애플리케이션은 비즈니스에 매우 중요하며 다양한 수준의 트래픽을 처리할 것으로 예상됩니다. 회사는 애플리케이션 계층 보호와 DDoS 완화를 모두 제공하는 솔루션을 구현해야 합니다.",
        "Question": "SysOps 관리자가 웹 애플리케이션에 대한 포괄적인 보호를 보장하기 위해 어떤 AWS 서비스 조합을 구현해야 합니까?",
        "Options": {
            "1": "AWS Secrets Manager 및 AWS Key Management Service",
            "2": "AWS WAF 및 AWS Shield Advanced",
            "3": "AWS Firewall Manager 및 Amazon GuardDuty",
            "4": "AWS Config 및 AWS Inspector"
        },
        "Correct Answer": "AWS WAF 및 AWS Shield Advanced",
        "Explanation": "AWS WAF는 악의적인 웹 트래픽을 차단하기 위한 규칙을 생성할 수 있도록 하여 애플리케이션 계층에서 보호를 제공합니다. AWS Shield Advanced는 추가 DDoS 보호를 제공하여 공격 중에도 애플리케이션이 계속 사용 가능하도록 보장합니다. 이 두 가지는 애플리케이션 및 네트워크 계층 보안을 위한 포괄적인 솔루션을 제공합니다.",
        "Other Options": [
            "AWS Firewall Manager 및 Amazon GuardDuty는 직접적인 애플리케이션 계층 보호를 제공하지 않습니다. Firewall Manager는 계정 간 방화벽 규칙 관리를 위한 것이지만 웹 취약점에 대한 특정 보호를 제공하지 않으며, GuardDuty는 보호를 제공하기보다는 위협 감지에 중점을 둡니다.",
            "AWS Config 및 AWS Inspector는 각각 규정 준수 및 보안 평가 도구입니다. Config는 리소스 구성을 모니터링하고, Inspector는 애플리케이션 취약점을 평가하지만, 이 두 서비스는 웹 공격이나 DDoS 공격을 직접 완화하지 않습니다.",
            "AWS Secrets Manager 및 AWS Key Management Service는 비밀 및 암호화 키 관리를 중심으로 하며, 이는 보안에 중요하지만 웹 공격이나 DDoS 위협에 대한 보호를 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "20",
        "Situation": "귀사는 자주 접근되는 데이터에 대한 저지연 액세스가 필요한 실시간 분석 애플리케이션을 개발하고 있습니다. 기존 AWS 인프라와 쉽게 통합되고 확장 가능한 캐싱 솔루션을 선택해야 합니다.",
        "Question": "어떤 서비스를 선택하여 애플리케이션의 성능을 향상시키고 인메모리 캐싱 기능을 제공하시겠습니까?",
        "Options": {
            "1": "읽기 복제본이 있는 Amazon RDS",
            "2": "Amazon DynamoDB Accelerator (DAX)",
            "3": "Amazon ElastiCache for Redis",
            "4": "수명 주기 정책이 있는 Amazon S3"
        },
        "Correct Answer": "Amazon ElastiCache for Redis",
        "Explanation": "Amazon ElastiCache for Redis는 저지연 및 높은 처리량 성능이 필요한 애플리케이션에 적합한 완전 관리형 인메모리 데이터 저장소입니다. 문자열, 해시, 리스트, 집합 및 정렬된 집합과 같은 데이터 구조를 지원하여 캐싱 및 실시간 분석에 적합합니다.",
        "Other Options": [
            "읽기 복제본이 있는 Amazon RDS는 관계형 데이터베이스의 읽기 성능을 향상시키기 위해 주로 사용되지만, 실시간 애플리케이션에서 지연 시간을 줄이는 데 중요한 인메모리 캐싱 기능을 제공하지 않습니다.",
            "Amazon DynamoDB Accelerator (DAX)는 DynamoDB를 위해 설계되어 해당 서비스에 대해 인메모리 캐싱을 제공합니다. 저지연 액세스를 제공할 수 있지만, 다른 유형의 애플리케이션을 위한 독립적인 캐싱 솔루션은 아닙니다.",
            "수명 주기 정책이 있는 Amazon S3는 저장 관리 및 데이터 아카이빙에 사용되지만, 인메모리 캐싱 기능을 제공하지 않아 빠른 데이터 검색이 필요한 애플리케이션에는 적합하지 않습니다."
        ]
    },
    {
        "Question Number": "21",
        "Situation": "한 금융 서비스 회사가 애플리케이션을 AWS로 마이그레이션하고 있으며 데이터 보호 규정을 준수해야 합니다. 회사의 규정 준수 담당자는 모든 민감한 데이터는 저장 시 암호화되어야 하며, 이 데이터에 대한 접근은 엄격히 통제되어야 한다고 요구했습니다. SysOps 관리자는 이러한 요구 사항을 충족하는 솔루션을 구현해야 합니다.",
        "Question": "SysOps 관리자가 Amazon S3에 저장된 민감한 데이터가 저장 시 암호화되고 접근이 통제되도록 보장하는 가장 효과적인 방법은 무엇입니까?",
        "Options": {
            "1": "S3 버킷 수명 주기 규칙을 구현하여 객체를 Glacier로 전환하고 버킷에 대한 공개 액세스를 허용합니다.",
            "2": "S3 버킷 버전 관리를 활성화하고 버킷 정책을 설정하여 특정 IAM 사용자만 접근할 수 있도록 합니다.",
            "3": "AWS KMS와 함께 S3 서버 측 암호화를 사용하고 IAM 정책을 구성하여 S3 버킷에 대한 접근을 제한합니다.",
            "4": "CloudTrail 트레일을 설정하여 S3 버킷에 대한 모든 접근을 기록하고 보안 그룹을 사용하여 접근을 제한합니다."
        },
        "Correct Answer": "AWS KMS와 함께 S3 서버 측 암호화를 사용하고 IAM 정책을 구성하여 S3 버킷에 대한 접근을 제한합니다.",
        "Explanation": "AWS KMS와 함께 S3 서버 측 암호화를 사용하면 민감한 데이터가 AWS에서 관리하는 강력한 암호화 키를 사용하여 저장 시 암호화됩니다. 또한 IAM 정책을 구성하면 SysOps 관리자가 세밀한 접근 제어를 정의할 수 있어, 권한이 있는 사용자만 S3 버킷에 저장된 민감한 데이터에 접근할 수 있도록 보장합니다.",
        "Other Options": [
            "S3 버킷 버전 관리를 활성화하는 것은 저장 시 데이터 암호화를 제공하지 않습니다. 버전 관리를 유지하는 데 도움이 되지만, 데이터 보호 규정 준수에 기여하지 않습니다.",
            "CloudTrail 트레일을 설정하면 S3 버킷에 대한 접근을 기록하지만, 저장 시 데이터를 암호화하지 않습니다. 보안 그룹은 EC2 인스턴스에 대한 접근을 제어하므로 S3에는 적용되지 않습니다.",
            "객체를 Glacier로 전환하기 위한 수명 주기 규칙을 구현하는 것은 저장 시 데이터 암호화에 대한 솔루션이 아닙니다. 또한, 버킷에 대한 공개 액세스를 허용하는 것은 상당한 보안 위험을 초래하며 접근 통제 요구 사항에 반합니다."
        ]
    },
    {
        "Question Number": "22",
        "Situation": "한 회사가 Amazon Route 53을 사용하여 도메인을 관리하고 있으며 Elastic Load Balancer (ELB) 뒤에 여러 웹 서버를 설정했습니다. 고가용성을 보장하기 위해 SysOps 관리자는 이러한 웹 서버의 상태를 모니터링하고 건강한 서버 수가 특정 임계값 아래로 떨어질 경우 알림을 받기를 원합니다. 관리자는 또한 서버의 전반적인 건강이 손상될 때만 알림이 발생하도록 하고 싶어합니다.",
        "Question": "SysOps 관리자가 이 모니터링 및 알림 요구 사항을 달성하기 위해 구현해야 하는 구성은 무엇입니까?",
        "Options": {
            "1": "각 웹 서버에 대한 개별 건강 검사를 생성하고 각 서버에 대한 알림을 설정합니다.",
            "2": "ELB에 대한 CloudWatch 경고를 구현하고 경고 상태에 대한 알림을 구성합니다.",
            "3": "추가 구성 없이 Route 53 건강 검사를 사용하여 ELB를 직접 모니터링합니다.",
            "4": "웹 서버의 개별 건강 검사를 모니터링하는 계산된 건강 검사를 설정합니다."
        },
        "Correct Answer": "웹 서버의 개별 건강 검사를 모니터링하는 계산된 건강 검사를 설정합니다.",
        "Explanation": "계산된 건강 검사는 여러 웹 서버의 상태를 모니터링하고 건강한 서버 수가 지정된 임계값 아래로 떨어질 때만 알림을 제공하여 고가용성 요구 사항에 부합합니다.",
        "Other Options": [
            "각 웹 서버에 대한 개별 건강 검사를 생성하면 여러 알림이 발생하여 전반적인 건강이 손상될 때만 알림을 보내야 하는 요구 사항을 충족하지 않습니다.",
            "ELB에 대한 CloudWatch 경고를 구현하면 로드 밸런서의 상태를 모니터링할 수 있지만 개별 웹 서버의 상태를 판단하는 데 필요한 세부 사항을 제공하지 않습니다.",
            "Route 53 건강 검사를 사용하여 ELB를 직접 모니터링하면 개별 서버의 상태를 모니터링할 수 없으므로 전체 서버 가용성을 이해하는 데 필요합니다."
        ]
    },
    {
        "Question Number": "23",
        "Situation": "개발 팀은 애플리케이션 업데이트 중 다운타임을 최소화하는 배포 전략을 구현하려고 합니다. 그들은 새로운 버전의 애플리케이션이 점진적으로 배포되는 동안 이전 버전이 계속 사용 가능하도록 하기를 원합니다.",
        "Question": "이 목표를 달성하기 위해 사용할 수 있는 배포 전략은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "섀도우 배포",
            "2": "롤링 배포",
            "3": "포크리프트 배포",
            "4": "카나리 배포",
            "5": "블루/그린 배포"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "카나리 배포",
            "롤링 배포"
        ],
        "Explanation": "카나리 배포는 애플리케이션의 새로운 버전을 소수의 사용자에게 먼저 배포하여 위험을 최소화하고 새로운 버전에서 문제를 모니터링할 기회를 제공합니다. 롤링 배포는 이전 버전의 인스턴스를 새로운 버전으로 점진적으로 교체하여 업데이트 과정에서 일부 인스턴스가 계속 사용 가능하도록 하여 다운타임을 최소화합니다.",
        "Other Options": [
            "블루/그린 배포는 이전 환경(그린)이 여전히 실행 중인 동안 새로운 환경(블루)을 생성하는 것입니다. 다운타임을 줄일 수 있지만 두 환경을 유지하기 위한 추가 리소스가 필요합니다.",
            "섀도우 배포는 현재 버전과 함께 새로운 버전을 실행하되 사용자에게 트래픽을 제공하지 않는 것으로, 주로 테스트 목적으로 사용됩니다. 이는 사용자-facing 업데이트 중 다운타임을 최소화하는 요구 사항을 충족하지 않습니다.",
            "포크리프트 배포는 AWS에서 인정되는 배포 전략이 아닙니다. 이는 완전한 개편이나 마이그레이션을 의미하며 점진적인 롤아웃 전략과 일치하지 않습니다."
        ]
    },
    {
        "Question Number": "24",
        "Situation": "한 회사가 VPN 연결을 사용하여 온프레미스 데이터 센터를 AWS에 연결하는 하이브리드 클라우드 환경을 설정했습니다. 최근 사용자들은 온프레미스 애플리케이션과 AWS 리소스 간의 간헐적인 연결 문제를 보고했습니다. 네트워크 관리자는 라우팅 문제를 의심하고 문제의 원인을 파악해야 합니다.",
        "Question": "하이브리드 연결 문제를 해결하기 위해 네트워크 관리자가 가장 먼저 취해야 할 단계는 무엇입니까?",
        "Options": {
            "1": "AWS CloudTrail 로그에서 무단 접근 시도를 검사합니다.",
            "2": "온프레미스 네트워크 장치의 라우팅 테이블을 검토합니다.",
            "3": "AWS 리소스와 관련된 보안 그룹 규칙을 확인합니다.",
            "4": "VPN 연결이 활성화되어 있고 올바르게 구성되었는지 확인합니다."
        },
        "Correct Answer": "VPN 연결이 활성화되어 있고 올바르게 구성되었는지 확인합니다.",
        "Explanation": "하이브리드 연결 문제를 해결하는 첫 번째 단계는 VPN 연결 자체가 활성화되어 있고 올바르게 구성되었는지 확인하는 것입니다. 여기에는 터널 상태를 확인하고 올바른 암호화 설정이 적용되었는지 확인하며, 트래픽 흐름을 허용하기 위해 가상 프라이빗 게이트웨이와 고객 게이트웨이 구성이 올바른지 확인하는 것이 포함됩니다.",
        "Other Options": [
            "보안 그룹 규칙을 확인하는 것은 중요하지만 VPN 연결이 작동하는지 확인한 후에 수행해야 합니다. VPN이 다운되면 보안 그룹은 연결성에 영향을 미치지 않습니다.",
            "온프레미스 네트워크 장치의 라우팅 테이블을 검토하는 것은 유용하지만, 온프레미스 구성을 살펴보기 전에 AWS VPN이 제대로 작동하는지 확인하는 것이 중요합니다.",
            "무단 접근 시도를 위한 AWS CloudTrail 로그를 검사하는 것은 연결 문제와 관련이 없습니다. 이러한 로그는 보안 감사에 유용하지만 VPN 연결성에 대한 정보를 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "25",
        "Situation": "SysOps 관리자는 공용 DNS 호스트 이름을 통해 인스턴스에 접근할 수 있는 새로운 VPC를 구성하는 임무를 맡았습니다. 그러나 관리자는 VPC가 제대로 작동하기 위해 DNS 해상도가 올바르게 설정되어야 함을 보장해야 합니다. 관리자는 DNS 지원과 호스트 이름 구성 간의 의존성을 이해해야 합니다.",
        "Question": "SysOps 관리자가 VPC에서 시작된 인스턴스가 공용 DNS 호스트 이름을 받도록 하려면 무엇을 해야 합니까?",
        "Options": {
            "1": "enableDnsSupport를 false로 설정하고 enableDnsHostnames를 true로 설정합니다.",
            "2": "enableDnsSupport를 false로 설정하고 enableDnsHostnames를 false로 설정합니다.",
            "3": "enableDnsSupport를 true로 설정하고 enableDnsHostnames를 true로 설정합니다.",
            "4": "enableDnsSupport를 true로 설정하고 enableDnsHostnames를 false로 설정합니다."
        },
        "Correct Answer": "enableDnsSupport를 true로 설정하고 enableDnsHostnames를 true로 설정합니다.",
        "Explanation": "VPC에서 시작된 인스턴스가 공용 DNS 호스트 이름을 받도록 하려면 enableDnsSupport와 enableDnsHostnames를 모두 true로 설정해야 합니다. 이 구성은 인스턴스가 공용 DNS 호스트 이름을 올바르게 해석할 수 있도록 하며, 호스트 이름이 작동하기 위해서는 DNS 해상도가 활성화되어야 합니다.",
        "Other Options": [
            "enableDnsSupport를 false로 설정하면 VPC에서 DNS 해상도가 비활성화되어 인스턴스가 공용 DNS 호스트 이름을 받을 수 없습니다.",
            "enableDnsSupport가 true인 경우 enableDnsHostnames를 false로 설정하면 인스턴스가 공용 DNS 호스트 이름을 받을 수 없게 되어 공용 접근에 필요합니다.",
            "enableDnsSupport와 enableDnsHostnames를 모두 false로 설정하면 인스턴스에 대한 DNS 해상도와 공용 DNS 호스트 이름이 완전히 비활성화됩니다."
        ]
    },
    {
        "Question Number": "26",
        "Situation": "한 회사가 Elastic Load Balancer (ELB) 뒤에 EC2 인스턴스에서 웹 애플리케이션을 배포했습니다. 사용자는 애플리케이션에 접근할 때 간헐적인 연결 문제를 보고하고 있습니다. 네트워크 연결 문제를 해결하는 임무를 맡았습니다.",
        "Question": "연결 문제의 원인을 파악하기 위해 가장 먼저 어떤 단계를 수행해야 합니까?",
        "Options": {
            "1": "로드 밸런서에 등록된 대상의 상태를 확인합니다.",
            "2": "EC2 인스턴스와 관련된 보안 그룹 규칙을 확인합니다.",
            "3": "무단 접근 시도를 위한 CloudTrail 로그를 검토합니다.",
            "4": "VPC 라우트 테이블의 잘못된 구성을 검사합니다."
        },
        "Correct Answer": "로드 밸런서에 등록된 대상의 상태를 확인합니다.",
        "Explanation": "Elastic Load Balancer의 연결 문제를 해결하는 첫 번째 단계는 대상의 상태를 확인하는 것입니다. 대상이 비정상인 경우 ELB는 해당 대상에 트래픽을 라우팅하지 않으며, 이로 인해 사용자에게 연결 문제가 발생합니다.",
        "Other Options": [
            "보안 그룹 규칙을 확인하는 것은 중요하지만, 대상의 상태를 검증하는 것보다 우선순위가 낮습니다. 대상이 정상이라면 보안 그룹 설정을 검토할 수 있습니다.",
            "VPC 라우트 테이블을 검사하는 것은 일부 시나리오에서 도움이 될 수 있지만, ELB가 성공적으로 트래픽을 받고 있다면 라우팅은 올바를 가능성이 높습니다. 상태 검사를 우선시해야 합니다.",
            "무단 접근 시도를 위한 CloudTrail 로그를 검토하는 것은 연결 문제와 관련이 없습니다. 이 단계는 네트워크 성능보다는 보안에 더 중점을 둡니다."
        ]
    },
    {
        "Question Number": "27",
        "Situation": "한 미디어 회사가 Amazon S3를 사용하여 대량의 비디오 콘텐츠를 저장하고 있습니다. 그들은 규정 준수를 위해 이전 버전의 비디오를 보존해야 하며, 동시에 저장 비용을 효과적으로 관리해야 합니다. S3 버킷에 대한 버전 관리 및 수명 주기 규칙을 구현하는 임무를 맡았습니다.",
        "Question": "이 요구 사항을 달성하기 위해 어떤 조치를 취해야 합니까? (두 가지 선택)",
        "Options": {
            "1": "S3 버킷에서 버전 관리를 활성화하여 모든 비디오 버전을 유지합니다.",
            "2": "60일 후 이전 비디오 버전을 삭제하는 수명 주기 규칙을 설정합니다.",
            "3": "데이터 중복성을 보장하기 위해 S3 버킷에 대한 교차 리전 복제를 설정합니다.",
            "4": "30일 후 이전 비디오 버전을 S3 Glacier로 전환하는 수명 주기 규칙을 설정합니다.",
            "5": "규정 준수를 위해 AWS Backup을 사용하여 S3 버킷의 백업을 생성합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "S3 버킷에서 버전 관리를 활성화하여 모든 비디오 버전을 유지합니다.",
            "30일 후 이전 비디오 버전을 S3 Glacier로 전환하는 수명 주기 규칙을 설정합니다."
        ],
        "Explanation": "S3 버킷에서 버전 관리를 활성화하면 모든 비디오 버전이 보존되어 규정 준수에 필수적입니다. 이전 비디오 버전을 S3 Glacier로 전환하는 수명 주기 규칙을 설정하면 저장 비용을 효과적으로 관리하면서도 규정 준수를 위한 필요한 데이터를 유지할 수 있습니다.",
        "Other Options": [
            "AWS Backup을 사용하여 S3 버킷의 백업을 생성하는 것은 불필요합니다. 버전 관리가 이미 데이터 보존을 처리하며 이전 버전의 수명 주기 관리를 다루지 않기 때문입니다.",
            "교차 리전 복제를 활성화하는 것은 데이터 중복성과 재해 복구에 중점을 두고 있으며, 버전 관리 및 수명 주기 규칙을 관리하는 것과는 관련이 없습니다.",
            "60일 후 이전 비디오 버전을 삭제하는 수명 주기 규칙을 설정하면 규정 준수를 위해 이전 버전을 보존해야 하는 요구 사항과 충돌합니다."
        ]
    },
    {
        "Question Number": "28",
        "Situation": "금융 서비스 회사가 AWS에 애플리케이션을 배포할 계획입니다. 이 애플리케이션은 민감한 고객 데이터를 처리하며 PCI DSS 표준을 준수해야 합니다. 준수 담당자는 사용되는 모든 서비스가 PCI 요구 사항을 충족하는 AWS 리전이어야 한다고 명시했습니다.",
        "Question": "SysOps 관리자가 PCI DSS 요구 사항 준수를 보장하기 위해 선택해야 할 AWS 리전은 무엇입니까?",
        "Options": {
            "1": "eu-central-1 (프랑크푸르트)",
            "2": "us-east-1 (버지니아 북부)",
            "3": "sa-east-1 (상파울루)",
            "4": "ap-south-1 (뭄바이)"
        },
        "Correct Answer": "us-east-1 (버지니아 북부)",
        "Explanation": "us-east-1 (버지니아 북부) 리전은 PCI DSS를 준수하므로 민감한 결제 정보를 처리하는 애플리케이션 호스팅에 적합한 선택입니다. 준수 요구 사항을 충족하는 다양한 서비스를 제공합니다.",
        "Other Options": [
            "eu-central-1 (프랑크푸르트)는 GDPR을 준수하지만 특정 PCI DSS 준수 인증이 없을 수 있어 금융 서비스 회사의 민감한 고객 데이터 처리 요구 사항을 충족하지 못할 수 있습니다.",
            "ap-south-1 (뭄바이)는 일부 준수 인증이 있지만 PCI DSS 준수로 잘 알려져 있지 않아 신용 카드 정보를 처리하는 데 중요합니다.",
            "sa-east-1 (상파울루)는 포괄적인 PCI DSS 준수가 없으며, 이 리전을 사용하면 민감한 고객 데이터를 처리할 때 비준수 위험에 노출될 수 있습니다."
        ]
    },
    {
        "Question Number": "29",
        "Situation": "금융 서비스 회사가 애플리케이션을 AWS로 마이그레이션하고 있으며, 중요한 작업의 고가용성을 보장해야 합니다. 팀은 Amazon RDS 인스턴스에 대한 다양한 배포 전략을 고려하고 있습니다. 단일 가용 영역(AZ) 배포와 다중 AZ 배포의 의미를 이해하고자 합니다.",
        "Question": "다음 중 Amazon RDS에 대한 단일 가용 영역 배포와 다중 AZ 배포를 정확하게 구분하는 설명은 무엇입니까?",
        "Options": {
            "1": "단일 가용 영역 배포는 여러 리전 간에 데이터를 자동으로 복제할 수 있습니다.",
            "2": "다중 AZ 배포는 데이터베이스 인스턴스에 대한 자동 장애 조치 및 더 높은 가용성을 제공합니다.",
            "3": "단일 가용 영역 배포는 자동 백업을 허용하지만 다중 AZ는 그렇지 않습니다.",
            "4": "다중 AZ 배포는 단일 가용 영역 배포에 비해 비용이 더 낮습니다."
        },
        "Correct Answer": "다중 AZ 배포는 데이터베이스 인스턴스에 대한 자동 장애 조치 및 더 높은 가용성을 제공합니다.",
        "Explanation": "다중 AZ 배포는 데이터베이스 업데이트를 다른 가용 영역의 대기 인스턴스로 자동 복제하여 고가용성을 제공하도록 설계되었습니다. 장애가 발생할 경우 Amazon RDS는 자동으로 대기 인스턴스로 장애 조치하여 최소한의 다운타임을 보장합니다.",
        "Other Options": [
            "단일 가용 영역 배포는 다중 AZ 배포와 동일한 수준의 고가용성 및 장애 조치 기능을 제공하지 않습니다. 자동 백업은 두 구성 모두에서 사용할 수 있습니다.",
            "다중 AZ 배포는 추가 대기 인스턴스 및 관련 리소스 때문에 일반적으로 더 비쌉니다. 반면 단일 가용 영역 배포는 비용이 더 저렴합니다.",
            "단일 가용 영역 배포는 리전 간에 데이터를 복제하지 않으며, 단일 가용 영역에 한정됩니다. 다중 AZ 설정은 동일한 리전 내에서 서로 다른 가용 영역 간에 복제합니다."
        ]
    },
    {
        "Question Number": "30",
        "Situation": "조직은 모든 API 호출이 AWS 리소스에 대해 기록되고 모니터링되도록 하여 보안 태세를 강화하고자 합니다. 이들은 이러한 로그를 분석하여 비정상적인 활동을 감지하고 준수를 유지하고자 합니다. 조직은 로깅 및 분석 기능을 제공하는 AWS 서비스를 활용하고자 합니다.",
        "Question": "조직이 API 호출 로그를 수집하고 분석하기 위해 사용해야 할 AWS 서비스는 무엇입니까? (두 개 선택)",
        "Options": {
            "1": "AWS Config",
            "2": "AWS CloudTrail",
            "3": "Amazon CloudWatch Logs Insights",
            "4": "Amazon Kinesis Data Streams",
            "5": "Amazon CloudWatch Events"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon CloudWatch Logs Insights",
            "AWS CloudTrail"
        ],
        "Explanation": "AWS CloudTrail은 계정에서 이루어진 API 호출을 기록하여 모니터링 및 준수를 위한 필요한 로그를 제공합니다. Amazon CloudWatch Logs Insights는 이러한 로그에 대한 강력한 쿼리 및 분석을 가능하게 하여 조직이 비정상적인 활동을 효과적으로 감지할 수 있도록 합니다.",
        "Other Options": [
            "Amazon Kinesis Data Streams는 주로 실시간 데이터 처리 및 스트리밍 애플리케이션에 사용되며, API 호출 로깅이나 로그 분석에는 사용되지 않습니다.",
            "AWS Config는 AWS 리소스 인벤토리, 구성 이력 및 구성 변경 알림을 제공하는 서비스이지만 API 호출을 특별히 기록하지는 않습니다.",
            "Amazon CloudWatch Events는 AWS 환경에서 이벤트에 응답하는 데 유용하지만 API 호출 로그를 직접 기록하거나 분석하지는 않습니다."
        ]
    },
    {
        "Question Number": "31",
        "Situation": "SysOps 관리자는 Docker 컨테이너를 사용하여 Elastic Beanstalk에 새로운 웹 애플리케이션을 배포해야 합니다. 이 애플리케이션은 사용자 정의 소프트웨어 종속성과 구성 설정을 포함하여 런타임 환경에 대한 특정 요구 사항이 있습니다.",
        "Question": "배포 중 Docker 컨테이너가 모든 필요한 환경 변수에 접근할 수 있도록 관리자가 어떤 구성 단계를 수행해야 합니까?",
        "Options": {
            "1": "Dockerfile에 환경 변수를 직접 정의합니다.",
            "2": "EC2 인스턴스 메타데이터에 환경 변수를 설정합니다.",
            "3": "애플리케이션 소스 번들에 구성 파일을 포함하여 환경 변수를 설정합니다.",
            "4": "배포 전에 Elastic Beanstalk 콘솔에서 환경 변수를 지정합니다."
        },
        "Correct Answer": "배포 전에 Elastic Beanstalk 콘솔에서 환경 변수를 지정합니다.",
        "Explanation": "Elastic Beanstalk에서는 콘솔에서 지정한 환경 변수가 Docker 컨테이너가 시작될 때 자동으로 전달됩니다. 이를 통해 애플리케이션은 Dockerfile이나 다른 구성 파일을 수정할 필요 없이 필요한 구성 설정에 접근할 수 있습니다.",
        "Other Options": [
            "Dockerfile에 환경 변수를 직접 정의하는 것은 명시적으로 처리되지 않는 한 Elastic Beanstalk 환경에서 접근할 수 없으며, Elastic Beanstalk 콘솔에서 제공하는 유연성을 활용하지 않습니다.",
            "애플리케이션 소스 번들에 구성 파일을 포함하는 것은 특별히 설계되지 않는 한 제대로 처리되지 않을 수 있으며, 이로 인해 배포 중 환경 변수가 누락될 수 있습니다.",
            "EC2 인스턴스 메타데이터에 환경 변수를 설정하는 것은 Elastic Beanstalk의 Docker 컨테이너에 대해 지원되는 방법이 아니며, 컨테이너가 인스턴스에서 메타데이터를 자동으로 가져오지 않습니다."
        ]
    },
    {
        "Question Number": "32",
        "Situation": "한 회사는 여러 AWS 서비스를 활용하여 작업 부하를 관리하고 시스템 성능을 효과적으로 모니터링하며 서비스 중단이나 리소스 한계에 대한 알림을 받아야 합니다. SysOps 관리자는 사전 예방적인 모니터링 및 알림 시스템을 구현하는 임무를 맡고 있습니다.",
        "Question": "AWS 환경에 대한 효과적인 모니터링 및 알림을 보장하기 위해 SysOps 관리자가 어떤 단계의 조합을 수행해야 합니까? (두 가지 선택)",
        "Options": {
            "1": "CloudWatch 알람 트리거에 대한 알림을 보내기 위해 Amazon SNS를 설정합니다.",
            "2": "서비스 이벤트를 모니터링하기 위해 AWS Health Dashboard를 활용합니다.",
            "3": "리소스 구성의 변경 사항을 추적하기 위해 AWS Config를 구현합니다.",
            "4": "주요 성능 메트릭에 대한 CloudWatch 알람을 생성합니다.",
            "5": "리소스 관리 알림을 위해 AWS Service Quotas를 활성화합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "주요 성능 메트릭에 대한 CloudWatch 알람을 생성합니다.",
            "CloudWatch 알람 트리거에 대한 알림을 보내기 위해 Amazon SNS를 설정합니다."
        ],
        "Explanation": "CloudWatch 알람을 생성하면 관리자가 특정 메트릭에 대한 임계값을 설정할 수 있어 AWS 리소스를 사전 예방적으로 모니터링할 수 있습니다. 이러한 알람에 대한 알림을 보내기 위해 Amazon SNS를 설정하면 팀이 문제가 발생할 때 즉시 경고를 받을 수 있어 신속한 대응이 가능합니다.",
        "Other Options": [
            "AWS Config를 구현하는 것은 구성 변경 사항을 감사하고 추적하는 데 유용하지만 성능 메트릭이나 서비스 중단에 대한 알림을 직접 제공하지는 않습니다.",
            "AWS Health Dashboard를 활용하는 것은 계정 수준에서 서비스 문제를 이해하는 데 유용하지만 특정 리소스 성능 메트릭에 대한 실시간 알림을 제공하지는 않습니다.",
            "AWS Service Quotas를 활성화하면 리소스 한계를 모니터링하는 데 도움이 되지만 성능 모니터링이나 시스템 건강과 관련된 즉각적인 알림과는 직접적인 연관이 없습니다."
        ]
    },
    {
        "Question Number": "33",
        "Situation": "한 금융 서비스 회사는 AWS 환경 내에서 수행된 모든 작업을 추적하여 규제 요구 사항을 준수해야 합니다. 이들은 AWS 계정 전반에 걸쳐 API 호출 및 리소스 변경 사항에 대한 가시성을 제공하는 솔루션을 구현하고자 합니다.",
        "Question": "회사가 거버넌스 및 규정 준수를 위해 모든 계정 활동을 기록하고 모니터링하기 위해 어떤 AWS 서비스를 사용해야 합니까?",
        "Options": {
            "1": "Amazon CloudWatch",
            "2": "AWS Lambda",
            "3": "AWS Config",
            "4": "AWS CloudTrail"
        },
        "Correct Answer": "AWS CloudTrail",
        "Explanation": "AWS CloudTrail은 계정 활동을 기록하고 모니터링하는 데 적합한 서비스로, AWS 인프라 전반에 걸쳐 수행된 작업의 이벤트 기록을 제공합니다. 이는 거버넌스, 규정 준수, 운영 감사 및 위험 감사에 필수적이며, 규제 요구 사항을 충족하는 데 중요합니다.",
        "Other Options": [
            "AWS Config는 주로 AWS 리소스의 구성 변경 사항 및 규정 준수를 추적하는 데 사용되지만 API 호출을 기록하거나 CloudTrail이 제공하는 이벤트 기록을 제공하지 않습니다.",
            "Amazon CloudWatch는 리소스 및 애플리케이션을 실시간으로 모니터링하는 데 사용되지만 CloudTrail과 같은 API 호출이나 계정 활동에 대한 자세한 로그를 제공하지 않습니다.",
            "AWS Lambda는 이벤트에 응답하여 코드를 실행할 수 있는 컴퓨팅 서비스이지만 AWS 서비스 전반에 걸쳐 계정 활동을 기록하거나 모니터링하는 데 설계되지 않았습니다."
        ]
    },
    {
        "Question Number": "34",
        "Situation": "한 회사가 Amazon RDS를 사용하여 프로덕션 데이터베이스를 호스팅하고 있습니다. 비즈니스 연속성을 보장하기 위해 SysOps 관리자는 상당한 다운타임 없이 시점 복구를 허용하는 백업 전략을 구현해야 합니다.",
        "Question": "SysOps 관리자가 이 백업 전략을 구현하기 위한 최선의 접근 방식은 무엇입니까?",
        "Options": {
            "1": "모든 데이터베이스 트랜잭션에 대해 Amazon S3를 사용하여 지속적인 백업을 활성화합니다.",
            "2": "유지 관리 작업을 수행하기 전에 RDS 인스턴스의 수동 스냅샷을 생성합니다.",
            "3": "재해 복구를 위해 다른 지역에 읽기 복제본을 설정합니다.",
            "4": "RDS 인스턴스에서 자동 백업을 활성화하고 보존 기간을 7일로 설정합니다."
        },
        "Correct Answer": "RDS 인스턴스에서 자동 백업을 활성화하고 보존 기간을 7일로 설정합니다.",
        "Explanation": "RDS 인스턴스에서 자동 백업을 활성화하면 지정된 보존 기간 내에서 시점 복구가 가능해져 최소한의 다운타임을 보장하고 비즈니스 연속성을 위한 신뢰할 수 있는 백업 솔루션을 제공합니다.",
        "Other Options": [
            "유지 관리 전에 수동 스냅샷을 생성하면 백업을 제공할 수 있지만, 시점 복구를 허용하지 않으며 수동 개입이 필요하므로 지속적인 백업 요구에 덜 효과적입니다.",
            "Amazon S3를 사용한 지속적인 백업은 RDS에서 제공되는 기능이 아니며, RDS는 자체적으로 백업 및 복구 프로세스를 처리하므로 이 옵션은 잘못되었습니다.",
            "읽기 복제본을 설정하면 가용성이 향상되고 재해 복구를 제공할 수 있지만, 자동 백업과 같은 백업 전략의 필요성을 대체하지 않으며, 이는 시점 복구에 필수적입니다."
        ]
    },
    {
        "Question Number": "35",
        "Situation": "SysOps 관리자는 Amazon S3에 저장된 데이터가 규정 준수 및 재해 복구 목적으로 다른 AWS 지역에 복제되도록 해야 합니다. 관리자는 이러한 요구 사항을 충족하기 위해 Cross-Region Replication (CRR)을 구성해야 합니다.",
        "Question": "Amazon S3 Cross-Region Replication (CRR)을 구성하기 위해 관리자가 취해야 할 조치는 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "객체 복제를 위해 Lambda 함수를 트리거하는 소스 버킷에 S3 버킷 알림을 구성합니다.",
            "2": "소스 버킷의 복제 구성에서 대상 S3 버킷을 지정하고 복제를 위한 IAM 역할을 선택합니다.",
            "3": "객체 복제를 허용하기 위해 소스 및 대상 S3 버킷 모두에서 버전 관리를 활성화합니다.",
            "4": "대상 지역 내 S3 서비스 역할에 복제를 위한 필요한 권한을 부여하는 IAM 정책을 설정합니다.",
            "5": "복제가 작동하도록 소스 버킷의 버킷 정책을 수정하여 공개 액세스를 허용합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "객체 복제를 허용하기 위해 소스 및 대상 S3 버킷 모두에서 버전 관리를 활성화합니다.",
            "소스 버킷의 복제 구성에서 대상 S3 버킷을 지정하고 복제를 위한 IAM 역할을 선택합니다."
        ],
        "Explanation": "Amazon S3 Cross-Region Replication (CRR)을 구성하려면 소스 및 대상 버킷 모두에서 버전 관리를 활성화해야 합니다. 이는 CRR의 전제 조건으로, S3가 객체의 변경 사항을 추적할 수 있도록 합니다. 또한, 소스 버킷의 복제 구성에서 대상 버킷을 지정하고 S3가 객체를 복제하는 데 사용할 IAM 역할을 설정해야 합니다.",
        "Other Options": [
            "권한을 부여하는 IAM 정책을 설정하는 것은 중요하지만, 그것만으로는 충분하지 않습니다. 필요한 권한은 복제를 위해 사용되는 IAM 역할에 부여되어야 하며, 단순히 별도의 IAM 정책에만 의존해서는 안 됩니다.",
            "S3 버킷 알림을 구성하여 Lambda 함수를 트리거하는 것은 CRR 프로세스의 일부가 아니며, CRR은 Lambda나 다른 컴퓨팅 리소스 없이 S3에 의해 직접 관리됩니다.",
            "소스 버킷의 버킷 정책을 수정하여 공개 액세스를 허용하는 것은 필요하지 않으며 보안 위험을 초래합니다. CRR은 공개 액세스를 요구하지 않으며, 적절한 IAM 역할과 권한에 의존합니다."
        ]
    },
    {
        "Question Number": "36",
        "Situation": "시스템 관리자는 EC2 인스턴스에서 호스팅되는 애플리케이션의 가용성을 보장할 책임이 있습니다. 관리자는 CPU 사용률과 요청 대기 시간을 모니터링하기 위해 CloudWatch 경고를 설정했습니다. 최근에 애플리케이션이 피크 사용 시간 동안 대기 시간 급증을 경험하고 있음을 알게 되었습니다. 이 문제를 해결하기 위해 관리자는 이러한 메트릭을 기반으로 애플리케이션을 자동으로 확장하고자 합니다.",
        "Question": "관리자가 수동 개입 없이 애플리케이션이 증가하는 수요를 처리할 수 있도록 하기 위해 구현해야 할 솔루션은 무엇입니까?",
        "Options": {
            "1": "Amazon RDS 읽기 복제본",
            "2": "Amazon CloudFront",
            "3": "AWS Lambda 함수",
            "4": "Amazon EC2 Auto Scaling"
        },
        "Correct Answer": "Amazon EC2 Auto Scaling",
        "Explanation": "Amazon EC2 Auto Scaling은 관리자가 CPU 사용률 및 요청 대기 시간과 같은 정의된 CloudWatch 메트릭에 따라 수요 변화에 대응하여 EC2 인스턴스 수를 자동으로 조정할 수 있도록 합니다. 이를 통해 애플리케이션은 피크 시간 동안 확장하고 수요가 감소할 때 축소할 수 있어 비용 효율적인 솔루션을 제공합니다.",
        "Other Options": [
            "AWS Lambda 함수는 서버리스 컴퓨팅을 위해 설계되었으며, 모니터링된 메트릭을 기반으로 EC2 인스턴스를 자동으로 확장하는 데 적합하지 않습니다.",
            "Amazon CloudFront는 콘텐츠 전송 네트워크로 콘텐츠를 캐시할 수 있지만, 성능 메트릭에 따라 EC2 인스턴스의 자동 확장 기능을 제공하지 않습니다.",
            "Amazon RDS 읽기 복제본은 데이터베이스 인스턴스의 읽기 요청을 처리하는 데 사용되며, 애플리케이션 수요에 따라 EC2 인스턴스를 확장할 필요를 직접적으로 해결하지 않습니다."
        ]
    },
    {
        "Question Number": "37",
        "Situation": "한 회사가 데이터 저장소를 AWS로 마이그레이션하고 있으며, 자주 접근하지 않는 아카이브 데이터에 적합한 Elastic Block Store (EBS) 볼륨 유형을 선택해야 합니다. 그들은 비용 효율적인 솔루션을 찾고 있으며, 가끔 접근할 때 수용 가능한 성능을 유지하고자 합니다.",
        "Question": "회사가 아카이브 데이터 저장을 위해 선택해야 할 EBS 볼륨 유형은 무엇입니까?",
        "Options": {
            "1": "Throughput Optimized HDD (st1)",
            "2": "Cold HDD (sc1)",
            "3": "General Purpose SSD (gp2)",
            "4": "Provisioned IOPS SSD (io1)"
        },
        "Correct Answer": "Cold HDD (sc1)",
        "Explanation": "Cold HDD 볼륨(sc1)은 자주 접근하지 않는 작업 부하를 위해 특별히 설계되었으며, IOPS가 아닌 처리량 측면에서 성능을 정의하는 저비용 자기 저장소를 제공합니다. 따라서 접근이 드문 아카이브 데이터에 이상적입니다.",
        "Other Options": [
            "Provisioned IOPS SSD (io1)는 미션 크리티컬한 저지연 또는 고처리량 작업 부하에 대해 최고의 성능을 제공하지만, 자주 접근하지 않는 아카이브 데이터에는 필요하지 않습니다.",
            "Throughput Optimized HDD (st1)는 자주 접근하는 처리량 집약적인 작업 부하를 위해 설계되었으며, 회사의 비용 효율적인 아카이브 저장소 필요와 일치하지 않습니다.",
            "General Purpose SSD (gp2)는 다양한 작업 부하에 적합하지만, 자주 접근하지 않는 데이터에 대해 Cold HDD보다 더 비쌉니다. 따라서 아카이브 용도로는 덜 이상적입니다."
        ]
    },
    {
        "Question Number": "38",
        "Situation": "한 회사가 Amazon S3에 데이터 업로드가 느려서 전체 애플리케이션 성능에 영향을 받고 있습니다. 관리자는 S3에 대용량 파일의 업로드 속도를 개선하면서도 비용 효율적인 솔루션을 보장해야 합니다.",
        "Question": "관리자가 Amazon S3에 대용량 파일 업로드 성능을 향상시키기 위해 구현해야 할 기능은 무엇입니까?",
        "Options": {
            "1": "S3 이벤트 알림을 구성하여 업로드를 트리거합니다.",
            "2": "객체에 대해 서버 측 암호화를 구현합니다.",
            "3": "업로드 중에 파일을 변환하기 위해 S3 Object Lambda를 사용합니다.",
            "4": "버킷에 대해 S3 Transfer Acceleration을 활성화합니다."
        },
        "Correct Answer": "버킷에 대해 S3 Transfer Acceleration을 활성화합니다.",
        "Explanation": "S3 Transfer Acceleration은 Amazon CloudFront의 전 세계적으로 분산된 엣지 위치를 사용하여 S3에 대한 업로드 속도를 높이기 위해 특별히 설계되었습니다. 이 기능은 대용량 파일에 이상적이며, 지연 시간을 줄이고 업로드 성능을 크게 향상시킵니다.",
        "Other Options": [
            "S3 Object Lambda는 객체가 S3에서 검색될 때 데이터를 변환하는 데 주로 사용되며, 파일 업로드에는 도움이 되지 않습니다. 업로드 속도에 영향을 미치지 않습니다.",
            "S3 이벤트 알림은 S3에서 객체가 생성되거나 삭제될 때 작업을 트리거하는 데 사용되지만, 업로드 성능을 직접적으로 개선하지는 않습니다.",
            "서버 측 암호화는 데이터가 정지 상태에서 안전하게 보호되는 데 중점을 두며, S3에 대한 데이터 업로드 속도에는 영향을 미치지 않습니다."
        ]
    },
    {
        "Question Number": "39",
        "Situation": "한 회사가 Amazon S3에서 정적 웹사이트를 호스팅하고자 합니다. 그들은 HTML 파일을 S3 버킷에 업로드했지만 웹 브라우저를 통해 사이트에 접근할 수 없습니다. 팀은 버킷 정책이 공개 접근을 허용한다고 확인했습니다. 그들은 웹사이트를 접근 가능하게 만들기 위해 추가적으로 어떤 구성이 필요한지 확신하지 못하고 있습니다.",
        "Question": "팀이 S3 버킷에서 정적 웹사이트 호스팅을 활성화하기 위해 가장 필요할 것으로 보이는 단계는 무엇입니까?",
        "Options": {
            "1": "S3 버킷에서 정적 웹사이트 호스팅을 활성화하고 인덱스 문서를 지정합니다.",
            "2": "S3 버킷을 제공하기 위해 Amazon CloudFront 배포를 구성합니다.",
            "3": "S3 버킷에서 정적 파일을 제공하기 위해 새로운 EC2 인스턴스를 생성합니다.",
            "4": "Route 53을 설정하여 S3 버킷을 가리키는 도메인을 생성합니다."
        },
        "Correct Answer": "S3 버킷에서 정적 웹사이트 호스팅을 활성화하고 인덱스 문서를 지정합니다.",
        "Explanation": "Amazon S3에서 정적 웹사이트를 호스팅하려면 S3 버킷에서 정적 웹사이트 호스팅을 활성화하고 인덱스 문서를 지정해야 합니다. 이렇게 하면 S3가 정적 파일에 대한 요청을 올바르게 해석하고 HTTP를 통해 제공할 수 있습니다.",
        "Other Options": [
            "Amazon CloudFront 배포를 구성하면 성능을 향상시키고 추가 기능을 제공할 수 있지만, S3 버킷 자체에서 정적 웹사이트 호스팅을 활성화하는 데는 필요하지 않습니다.",
            "도메인을 위한 Route 53 설정은 S3 버킷으로 트래픽을 유도하는 데 유용하지만, 버킷 자체에서 정적 웹사이트 호스팅을 활성화하는 필요를 해결하지는 않습니다.",
            "S3 버킷에서 정적 파일을 제공하기 위해 새로운 EC2 인스턴스를 생성하는 것은 불필요합니다. S3는 EC2 인스턴스 없이도 정적 웹사이트를 직접 호스팅할 수 있습니다."
        ]
    },
    {
        "Question Number": "40",
        "Situation": "한 금융 서비스 회사가 Amazon S3를 사용하여 민감한 고객 데이터를 저장하고 있습니다. SysOps 관리자는 데이터가 Amazon S3 관리 키(SSE-S3)를 사용하여 서버 측 암호화로 안전하게 암호화되도록 해야 합니다. 또한 관리자는 사용되는 암호화 알고리즘이 조직의 기준에 부합하는지 확인해야 합니다.",
        "Question": "SysOps 관리자가 SSE-S3를 사용하여 적절한 암호화를 보장하고 필요한 암호화 알고리즘을 지정하기 위해 요청에 포함해야 하는 헤더의 조합은 무엇입니까?",
        "Options": {
            "1": "x-amz-server-side-encryption: AES256",
            "2": "x-amz-server-side-encryption: AES256, x-amz-server-side-encryption-customer-algorithm: AES256",
            "3": "x-amz-server-side-encryption: AES256, x-amz-server-side-encryption-customer-key-MD5: <base64-encoded MD5>",
            "4": "x-amz-server-side-encryption: AES256, x-amz-server-side-encryption-customer-key: <base64-encoded key>"
        },
        "Correct Answer": "x-amz-server-side-encryption: AES256",
        "Explanation": "SSE-S3를 사용하려면 'x-amz-server-side-encryption' 헤더와 값 'AES256'만 필요합니다. 이는 Amazon S3가 암호화를 위해 관리 키를 사용해야 함을 지정합니다. 다른 헤더는 SSE-S3에 필요하지 않습니다.",
        "Other Options": [
            "이 옵션은 SSE-S3를 사용할 때 적용되지 않는 고객 제공 암호화 키에 대한 불필요한 헤더를 잘못 포함하고 있습니다.",
            "이 옵션은 SSE-S3가 고객 제공 키를 요구하지 않는데 고객 키가 필요하다고 잘못 제안하고 있습니다.",
            "이 옵션은 SSE-S3를 사용할 때 관련이 없는 고객 키의 MD5 다이제스트가 필요하다고 잘못 제안하고 있습니다."
        ]
    },
    {
        "Question Number": "41",
        "Situation": "한 회사가 AWS CloudFormation을 사용하여 새로운 애플리케이션 스택을 배포하고 있습니다. 스택 생성 과정에서 'IAM 리소스를 생성할 수 있는 능력이 부족함' 오류로 인해 배포가 실패합니다. CloudFormation 템플릿은 IAM 역할을 포함하여 여러 리소스를 생성하도록 설계되었습니다. 회사는 이 문제를 해결하여 스택을 성공적으로 배포해야 합니다.",
        "Question": "회사가 CloudFormation 배포 실패를 해결하기 위해 취해야 할 가장 적절한 조치는 무엇입니까?",
        "Options": {
            "1": "CloudFormation 템플릿을 수정하여 IAM 리소스 생성을 제거합니다.",
            "2": "스택 업데이트 정책을 변경하여 IAM 리소스를 생성할 수 있는 더 많은 시간을 허용합니다.",
            "3": "AWS CloudFormation Designer를 사용하여 템플릿 문제를 시각화하고 문제를 해결합니다.",
            "4": "CloudFormation 스택을 실행하는 사용자 또는 역할의 IAM 정책을 업데이트하여 필요한 권한을 포함합니다."
        },
        "Correct Answer": "CloudFormation 스택을 실행하는 사용자 또는 역할의 IAM 정책을 업데이트하여 필요한 권한을 포함합니다.",
        "Explanation": "오류는 CloudFormation 스택을 실행하는 사용자 또는 역할이 IAM 리소스를 생성할 수 있는 충분한 권한이 없음을 나타냅니다. 필요한 권한을 포함하도록 IAM 정책을 업데이트하면 문제를 해결하고 스택을 성공적으로 생성할 수 있습니다.",
        "Other Options": [
            "템플릿에서 IAM 리소스 생성을 제거하는 것은 기본적인 권한 문제를 해결하지 못하며 애플리케이션 스택의 기능을 제한합니다.",
            "스택 업데이트 정책을 변경하는 것은 권한 문제를 해결하지 않으며, 단순히 기존 리소스가 업데이트되는 데 더 많은 시간을 허용할 뿐입니다.",
            "AWS CloudFormation Designer를 사용하는 것은 템플릿을 시각화하는 데 도움이 될 수 있지만, 스택 배포 중 권한 관련 오류를 직접적으로 해결하지는 않습니다."
        ]
    },
    {
        "Question Number": "42",
        "Situation": "한 회사가 사용자에게 높은 가용성과 낮은 대기 시간을 요구하는 다중 지역 애플리케이션을 운영하고 있습니다. SysOps 관리자는 사용자 위치와 상태 점검에 따라 신뢰성과 성능을 보장하기 위해 Amazon Route 53을 사용하여 라우팅 전략을 구현해야 합니다.",
        "Question": "이러한 요구 사항을 충족하기 위해 SysOps 관리자가 구현해야 할 Route 53 라우팅 정책은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "사용자를 가장 가까운 지역으로 안내하기 위해 지연 기반 라우팅을 구현합니다.",
            "2": "기본 리소스가 비정상 상태가 되면 트래픽을 리디렉션하기 위해 장애 조치 라우팅을 구성합니다.",
            "3": "복잡하지 않은 트래픽 관리 접근 방식을 위해 단순 라우팅을 구현합니다.",
            "4": "사용자의 지리적 위치에 따라 트래픽을 전송하기 위해 지리 위치 라우팅을 활성화합니다.",
            "5": "여러 리소스에 트래픽을 고르게 분배하기 위해 가중치 라우팅을 사용합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "사용자를 가장 가까운 지역으로 안내하기 위해 지연 기반 라우팅을 구현합니다.",
            "기본 리소스가 비정상 상태가 되면 트래픽을 리디렉션하기 위해 장애 조치 라우팅을 구성합니다."
        ],
        "Explanation": "지연 기반 라우팅은 애플리케이션이 가장 낮은 대기 시간을 가진 지역에서 사용자에게 서비스를 제공할 수 있도록 하여 성능을 향상시킵니다. 장애 조치 라우팅은 기본 리소스가 상태 점검에 실패할 경우 트래픽을 백업 리소스로 전환하여 신뢰성을 높입니다.",
        "Other Options": [
            "가중치 라우팅은 트래픽을 분배하는 데 적합하지만, 이 시나리오에서 요구되는 낮은 대기 시간이나 장애 조치 기능을 특별히 다루지 않습니다.",
            "지리 위치 라우팅은 사용자 위치에 따라 트래픽을 안내할 수 있지만, 장애 조치 기능을 보장하거나 낮은 대기 시간을 우선시하지 않으므로 요구 사항을 완전히 충족하지 않습니다.",
            "단순 라우팅은 상태 점검이나 대기 시간 고려와 같은 고급 라우팅 기능을 제공하지 않으므로 이 다중 지역 애플리케이션에 적합하지 않습니다."
        ]
    },
    {
        "Question Number": "43",
        "Situation": "SysOps 관리자는 Amazon EC2에서 실행되는 애플리케이션이 비용을 최소화하면서 다양한 부하를 처리할 수 있도록 자동으로 확장할 수 있도록 하는 임무를 맡고 있습니다. 현재 애플리케이션은 트래픽의 변동을 겪고 있습니다.",
        "Question": "SysOps 관리자가 애플리케이션의 확장성과 탄력성을 달성하기 위해 어떤 전략을 구현해야 합니까? (두 가지 선택)",
        "Options": {
            "1": "트래픽을 인스턴스에 분산시키기 위해 로드 밸런서를 배포합니다.",
            "2": "모든 인스턴스를 예약 용량에서 실행합니다.",
            "3": "트래픽 급증 시 인스턴스 크기를 수동으로 증가시킵니다.",
            "4": "확장 정책이 있는 Auto Scaling 그룹을 구현합니다.",
            "5": "콘텐츠 전송을 위해 Amazon CloudFront를 사용합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "확장 정책이 있는 Auto Scaling 그룹을 구현합니다.",
            "트래픽을 인스턴스에 분산시키기 위해 로드 밸런서를 배포합니다."
        ],
        "Explanation": "확장 정책이 있는 Auto Scaling 그룹을 구현하면 애플리케이션이 현재 수요에 따라 실행 중인 인스턴스 수를 자동으로 조정할 수 있어 자원을 효율적으로 사용할 수 있습니다. 또한, 로드 밸런서를 배포하면 들어오는 트래픽이 여러 인스턴스에 분산되어 트래픽 급증 시 가용성과 성능이 향상됩니다.",
        "Other Options": [
            "트래픽 급증 시 인스턴스 크기를 수동으로 증가시키는 것은 진정한 탄력성을 위한 자동화를 제공하지 않으며, 변화하는 부하 조건에 대한 응답 지연을 초래할 수 있습니다.",
            "콘텐츠 전송을 위해 Amazon CloudFront를 사용하는 것은 주로 정적 콘텐츠의 성능을 향상시키지만, 트래픽에 따라 애플리케이션이 동적으로 확장할 수 있는 능력에 직접적으로 대응하지 않습니다.",
            "모든 인스턴스를 예약 용량에서 실행하면 비용이 증가할 수 있으며, 수요에 따라 확장하거나 축소하는 데 필요한 유연성을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "44",
        "Situation": "한 회사가 온프레미스 서버와 Amazon EC2 인스턴스를 모두 포함하는 하이브리드 클라우드 전략을 위해 AWS를 활용하고 있습니다. 그들은 두 환경에서 시스템 수준의 메트릭을 효율적으로 모니터링하고 분석하고자 합니다. 팀은 이를 위해 통합 CloudWatch 에이전트를 사용하기로 결정했습니다.",
        "Question": "통합 CloudWatch 에이전트가 Amazon EC2 인스턴스와 온프레미스 서버를 모니터링하기 위해 제공하는 기능은 무엇입니까?",
        "Options": {
            "1": "EC2 인스턴스에서 메트릭을 수집하지만 온프레미스 서버에서는 수집하지 않습니다.",
            "2": "Windows 서버에서 collectd 프로토콜을 사용하여 애플리케이션의 사용자 정의 메트릭을 검색합니다.",
            "3": "EC2 인스턴스와 온프레미스 서버 모두에서 시스템 수준의 메트릭과 로그를 수집합니다.",
            "4": "온프레미스 서버에서만 인-게스트 메트릭을 수집합니다."
        },
        "Correct Answer": "EC2 인스턴스와 온프레미스 서버 모두에서 시스템 수준의 메트릭과 로그를 수집합니다.",
        "Explanation": "통합 CloudWatch 에이전트는 Amazon EC2 인스턴스와 온프레미스 서버 모두에서 시스템 수준의 메트릭을 수집하도록 설계되어 하이브리드 환경 전반에 걸쳐 포괄적인 모니터링을 가능하게 합니다. 또한 두 환경에서 로그를 수집하여 가시성을 향상시킵니다.",
        "Other Options": [
            "이 옵션은 통합 CloudWatch 에이전트가 Amazon EC2 인스턴스와 온프레미스 서버 모두에서 인-게스트 메트릭을 수집할 수 있으므로 잘못되었습니다.",
            "이 옵션은 collectd 프로토콜이 Linux 서버에서만 지원되기 때문에 잘못되었습니다. 통합 CloudWatch 에이전트는 Windows 서버에서 collectd를 사용하여 애플리케이션의 사용자 정의 메트릭을 검색하는 것을 지원하지 않습니다.",
            "이 옵션은 통합 CloudWatch 에이전트가 EC2 인스턴스와 온프레미스 서버 모두에서 메트릭을 수집할 수 있으므로 잘못되었습니다."
        ]
    },
    {
        "Question Number": "45",
        "Situation": "SysOps 관리자는 온프레미스 네트워크와 AWS VPC 간에 안전하고 비용 효율적인 연결을 설정하는 임무를 맡고 있습니다. 이 연결은 인터넷을 통해 데이터 무결성과 기밀성을 보장하는 프로토콜을 활용해야 합니다.",
        "Question": "관리자가 안전하고 경제적인 연결을 구현하기 위해 선택해야 할 옵션은 무엇입니까?",
        "Options": {
            "1": "저지연 및 높은 대역폭을 위해 Direct Connect 연결을 설정합니다.",
            "2": "안전한 통신을 위해 IPsec를 사용하여 AWS 관리 VPN 연결을 설정합니다.",
            "3": "VPC에 연결하기 위해 추가 보안 조치 없이 공용 인터넷 연결을 사용합니다.",
            "4": "IPsec를 사용하지 않는 타사 VPN 솔루션을 구현합니다."
        },
        "Correct Answer": "안전한 통신을 위해 IPsec를 사용하여 AWS 관리 VPN 연결을 설정합니다.",
        "Explanation": "AWS 관리 VPN 연결은 IPsec를 사용하여 온프레미스 네트워크와 AWS VPC 간에 안전한 연결을 제공하며, Direct Connect에 비해 비용 효율적인 솔루션이면서도 인터넷을 통한 데이터 무결성과 기밀성을 보장합니다.",
        "Other Options": [
            "Direct Connect는 VPN 연결보다 비용이 더 비쌉니다. 대부분의 안전한 연결이 필요한 사용 사례에는 필요하지 않습니다.",
            "추가 보안 조치 없이 공용 인터넷 연결을 사용하는 것은 민감한 데이터를 잠재적인 가로채기에 노출시켜 안전한 통신을 위한 모범 사례에 반합니다.",
            "IPsec를 사용하지 않는 타사 VPN 솔루션은 AWS 관리 VPN 연결과 같은 수준의 보안 및 규정을 제공하지 않을 수 있으며, 이는 산업 표준을 준수합니다."
        ]
    },
    {
        "Question Number": "46",
        "Situation": "한 회사가 온프레미스 네트워크와 AWS VPC 간에 안전하고 개인적인 연결을 설정해야 하며, 이를 통해 공용 인터넷을 거치지 않고 자원 간의 원활한 통신이 가능해야 합니다. IT 팀은 이 요구 사항을 효율적으로 구현할 수 있는 옵션을 고려하고 있습니다.",
        "Question": "다음 옵션 중에서 공용 인터넷을 거치지 않고 온프레미스 네트워크를 AWS VPC에 안전하게 연결할 수 있는 방법은 무엇입니까?",
        "Options": {
            "1": "VPC Endpoint",
            "2": "VPN Gateway",
            "3": "VPC Peering",
            "4": "AWS Direct Connect"
        },
        "Correct Answer": "AWS Direct Connect",
        "Explanation": "AWS Direct Connect는 온프레미스 네트워크와 AWS VPC 간에 전용, 개인 연결을 제공하여 낮은 지연 시간과 일관된 네트워크 성능을 가능하게 하며, 공용 인터넷을 피할 수 있습니다.",
        "Other Options": [
            "VPC Peering은 AWS 환경 내의 두 VPC를 연결하지만 온프레미스 네트워크에 대한 연결을 제공하지 않습니다.",
            "VPC Endpoint는 VPC 내에서 AWS 서비스에 대한 개인 연결을 허용하지만 온프레미스 네트워크에서 직접 개인 연결을 설정하지 않습니다.",
            "VPN Gateway는 인터넷을 통해 온프레미스 네트워크와 VPC를 연결하는 안전한 터널을 생성하지만 Direct Connect와 같은 전용 회선을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "47",
        "Situation": "여러 애플리케이션을 실행하는 EC2 인스턴스의 플릿을 관리하고 있습니다. 추가 비용을 발생시키지 않고 인스턴스 내에서 인스턴스별 정보를 프로그래밍적으로 액세스할 수 있는 방법이 필요합니다. 이 정보는 애플리케이션이 인스턴스 특성에 따라 동적으로 적응하는 데 도움이 될 것입니다.",
        "Question": "비용을 발생시키지 않고 EC2 인스턴스에 대한 메타데이터(예: 공용 IP 주소 및 인스턴스 ID)를 가장 효율적으로 검색하는 방법은 무엇입니까?",
        "Options": {
            "1": "AWS CLI를 사용하여 EC2 서비스를 쿼리합니다.",
            "2": "AWS Systems Manager를 사용하여 인스턴스 세부 정보를 가져옵니다.",
            "3": "애플리케이션에서 EC2 DescribeInstances API를 호출합니다.",
            "4": "http://169.254.169.254/latest/meta-data에서 인스턴스 메타데이터 서비스에 액세스합니다."
        },
        "Correct Answer": "http://169.254.169.254/latest/meta-data에서 인스턴스 메타데이터 서비스에 액세스합니다.",
        "Explanation": "지정된 URL에서 인스턴스 메타데이터 서비스에 액세스하면 인스턴스 자체에서 직접 인스턴스별 정보를 검색할 수 있으며, 비용이 발생하지 않습니다. 이 메타데이터 서비스는 이 목적을 위해 설계되었으며 인스턴스 내에서만 접근할 수 있습니다.",
        "Other Options": [
            "AWS CLI를 사용하여 EC2 서비스를 쿼리하는 것은 API 호출 비용이 발생하며 인스턴스 내에서 인스턴스별 메타데이터에 직접 접근하는 데 비효율적입니다.",
            "EC2 DescribeInstances API를 호출하는 것은 네트워크 호출이 필요하며 비용이 발생하므로 로컬에서 사용할 수 있는 메타데이터를 단순히 얻기 위해서는 불필요합니다.",
            "AWS Systems Manager를 사용하여 인스턴스 세부 정보를 가져오는 것은 불필요한 복잡성과 잠재적인 비용을 추가하며, 인스턴스 메타데이터는 추가 서비스 없이 로컬에서 쉽게 사용할 수 있습니다."
        ]
    },
    {
        "Question Number": "48",
        "Situation": "한 회사가 서로 다른 AWS 계정에 여러 VPC를 보유하고 있으며, 자원 간의 통신을 허용하기 위해 개인 네트워크 연결을 설정해야 합니다. 그들은 설정이 안전하고 효율적이기를 원합니다.",
        "Question": "다음 구성 중에서 회사가 서로 다른 AWS 계정의 두 VPC 간에 VPC 피어링 연결을 설정할 수 있도록 하는 것은 무엇입니까?",
        "Options": {
            "1": "두 VPC 간에 VPN 연결을 설정합니다. 이는 데이터 전송 중 암호화를 유지하면서 공용 인터넷을 통한 통신을 허용합니다.",
            "2": "AWS Direct Connect를 사용하여 두 계정의 데이터 센터 간에 개인 연결을 생성하여 두 VPC 간의 내부 라우팅을 허용합니다.",
            "3": "한 계정에 전송 게이트웨이를 구성하고 두 VPC를 전송 게이트웨이에 연결합니다. 이는 직접 피어링 연결 없이 중앙 집중식 라우팅을 가능하게 합니다.",
            "4": "한 VPC에서 다른 VPC로 피어링 연결 요청을 생성하고 대상 VPC 소유자의 계정 ID를 지정합니다. 두 VPC의 CIDR 범위가 겹치지 않도록 합니다."
        },
        "Correct Answer": "한 VPC에서 다른 VPC로 피어링 연결 요청을 생성하고 대상 VPC 소유자의 계정 ID를 지정합니다. 두 VPC의 CIDR 범위가 겹치지 않도록 합니다.",
        "Explanation": "서로 다른 AWS 계정의 두 VPC 간에 VPC 피어링 연결을 설정하려면 한 VPC에서 다른 VPC로 피어링 연결 요청을 생성해야 하며, CIDR 범위가 겹치지 않도록 해야 합니다. 이를 통해 두 VPC의 인스턴스가 개인 IP 주소를 사용하여 통신할 수 있습니다.",
        "Other Options": [
            "이 옵션은 전송 게이트웨이를 사용하는 것을 설명하고 있으며, 이는 직접 VPC 피어링 연결을 설정하는 데 필요하지 않습니다. 전송 게이트웨이는 여러 VPC 간의 연결을 단순화할 수 있지만 피어 투 피어 연결에는 필요하지 않습니다.",
            "VPN 연결을 설정하는 것은 VPC를 연결하는 유효한 옵션이지만, 이 시나리오에서 특정 요구 사항인 VPC 피어링을 활용하지 않습니다. VPC 피어링은 VPN의 오버헤드 없이 개인 IP를 통해 직접 통신할 수 있게 합니다.",
            "AWS Direct Connect는 온프레미스에서 AWS로 전용 연결을 설정하는 솔루션이지만, 서로 다른 계정 간의 VPC 피어링을 직접 지원하지 않습니다. Direct Connect는 서로 다른 계정의 VPC를 피어링하는 데 적용되지 않습니다."
        ]
    },
    {
        "Question Number": "49",
        "Situation": "한 회사가 AWS Organization 아래에 여러 개의 AWS 계정을 보유하고 있습니다. 보안 팀은 특정 작업이 모든 계정에서 제한되도록 하여 준수를 강제해야 합니다. 이를 달성하기 위해 Service Control Policies (SCPs)의 사용을 고려하고 있습니다. SCPs를 효과적으로 활용하기 위해 어떤 접근 방식을 취해야 할까요?",
        "Question": "보안 팀이 Service Control Policies를 사용하여 모든 계정에서 특정 작업을 어떻게 방지할 수 있나요?",
        "Options": {
            "1": "특정 작업을 허용하는 SCP를 생성하고 이를 루트 조직 단위에 연결합니다.",
            "2": "모든 작업을 허용하는 SCP를 생성하고 이를 개별 계정에 연결하여 제한합니다.",
            "3": "IAM 사용자에 대한 액세스를 거부하는 SCP를 생성하고 이를 조직의 루트 계정에 연결합니다.",
            "4": "작업을 명시적으로 거부하는 SCP를 생성하고 이를 루트 조직 단위에 연결합니다."
        },
        "Correct Answer": "작업을 명시적으로 거부하는 SCP를 생성하고 이를 루트 조직 단위에 연결합니다.",
        "Explanation": "특정 작업을 명시적으로 거부하는 SCP를 생성하고 이를 루트 조직 단위에 연결하면 해당 단위 내의 모든 계정에서 제한이 시행되어 회사 전체에서 해당 작업을 효과적으로 방지할 수 있습니다.",
        "Other Options": [
            "모든 작업을 허용하는 SCP를 생성하는 것은 제한을 시행하지 않으므로 준수 목적에 효과적이지 않습니다.",
            "특정 작업을 허용하는 SCP를 생성하는 것은 특정 작업을 방지하지 않으므로 특정 작업을 제한하는 목표와 모순됩니다.",
            "IAM 사용자에 대한 액세스를 거부하는 SCP를 생성하는 것은 특정 작업의 시행과 직접적으로 관련이 없으며, 사용자가 필요한 작업을 수행할 수 없게 만들 수 있습니다."
        ]
    },
    {
        "Question Number": "50",
        "Situation": "한 회사가 Amazon EC2 인스턴스에서 웹 애플리케이션을 운영하고 있으며, CPU 사용량을 모니터링하기 위해 Amazon CloudWatch를 구성했습니다. 회사는 인스턴스의 평균 CPU 사용량이 5분 동안 80%를 초과할 때 운영 팀에 알림을 보내는 CloudWatch 경고를 설정하고자 합니다.",
        "Question": "원하는 CloudWatch 경고를 성공적으로 생성하기 위한 구성은 무엇인가요?",
        "Options": {
            "1": "임계값 80%, 기간 10분, 통계 Sum으로 CloudWatch 경고를 생성합니다.",
            "2": "임계값 80%, 기간 5분, 통계 Minimum으로 CloudWatch 경고를 생성합니다.",
            "3": "임계값 80%, 기간 5분, 통계 Average로 CloudWatch 경고를 생성합니다.",
            "4": "임계값 80%, 기간 1분, 통계 Maximum으로 CloudWatch 경고를 생성합니다."
        },
        "Correct Answer": "임계값 80%, 기간 5분, 통계 Average로 CloudWatch 경고를 생성합니다.",
        "Explanation": "이 구성은 평균 CPU 사용량이 5분 동안 80%를 초과할 때 경고를 보내는 요구 사항을 충족하며, CPU 사용량을 효과적으로 모니터링하기 위한 바람직한 동작입니다.",
        "Other Options": [
            "이 옵션은 1분 기간과 Maximum 통계를 사용하여 평균 CPU 사용량을 더 긴 시간 동안 모니터링하는 요구 사항과 일치하지 않습니다.",
            "이 옵션은 10분 기간을 설정하고 Sum 통계를 사용하여 평균 CPU 사용량을 기준으로 경고를 트리거하는 데 적합하지 않으며, 알림이 지연될 수 있습니다.",
            "이 옵션은 Minimum 통계를 사용하여 CPU 사용량을 모니터링하는 데 적합하지 않으며, 최소 값이 임계값을 초과할 때만 경고를 트리거하므로 평균을 기준으로 하지 않습니다."
        ]
    },
    {
        "Question Number": "51",
        "Situation": "재무 분석가는 회사의 월간 AWS 지출을 검토해야 하며, 상세한 비용 데이터를 자동으로 검색하고자 합니다. 분석가는 서비스 사용량 및 태그별로 비용을 분류하는 데 특히 관심이 있습니다. 회사는 AWS Organizations 아래에서 통합 청구가 활성화된 AWS 계정을 보유하고 있습니다. 분석가는 비용 보고서가 적시에 효율적으로 분석할 수 있도록 제공되는 솔루션이 필요합니다.",
        "Question": "분석가가 특정 서비스 및 태그에 대해 분석할 수 있는 상세 비용 보고서를 자동으로 받기 위해 어떤 접근 방식을 취해야 하나요?",
        "Options": {
            "1": "AWS Lambda 함수를 예약하여 AWS Cost Explorer API에서 청구 데이터를 매일 추출합니다.",
            "2": "Amazon Athena 통합이 포함된 Cost & Usage Reports를 활성화하고, 보고서를 마스터 계정이 소유한 버킷에 저장합니다.",
            "3": "Amazon QuickSight와 통합된 Cost & Usage Reports를 설정하여 데이터를 시각화합니다.",
            "4": "Cost & Usage Reports를 구성하여 회원 계정이 소유한 Amazon S3 버킷에 게시합니다."
        },
        "Correct Answer": "Amazon Athena 통합이 포함된 Cost & Usage Reports를 활성화하고, 보고서를 마스터 계정이 소유한 버킷에 저장합니다.",
        "Explanation": "Amazon Athena 통합이 포함된 Cost & Usage Reports를 활성화하면 상세한 비용 데이터를 분석하기 위한 강력한 솔루션을 제공하며, 분석가는 SQL을 사용하여 데이터를 쉽게 쿼리하고 정보를 효율적으로 검색할 수 있습니다. 또한, 통합 청구를 사용할 때 보고서를 마스터 계정이 소유한 버킷에 저장하는 것이 필요합니다.",
        "Other Options": [
            "Cost & Usage Reports를 회원 계정이 소유한 Amazon S3 버킷에 게시하도록 구성하는 것은 잘못된 것입니다. 통합 청구를 사용할 때 버킷은 마스터 계정이 소유해야 합니다.",
            "Amazon QuickSight와 통합된 Cost & Usage Reports를 설정하는 것만으로는 충분하지 않으며, 데이터는 먼저 Athena 통합과 같은 접근 가능한 형식으로 제공되어야 의미 있는 분석이 가능합니다.",
            "AWS Cost Explorer API에서 청구 데이터를 매일 추출하기 위해 AWS Lambda 함수를 예약하는 것은 Cost & Usage Reports를 사용하는 것에 비해 비효율적이며, 추가 관리가 필요하고 비용 분류의 세부 사항과 정밀도를 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "52",
        "Situation": "SysOps 관리자가 AWS에서 애플리케이션 로그를 모니터링하는 임무를 맡았으며, 특정 패턴을 추적하기 위해 메트릭 필터를 생성해야 합니다. 관리자는 중요한 운영 메트릭이 캡처되고 즉각적인 대응을 위한 경고를 트리거할 수 있도록 보장하고자 합니다.",
        "Question": "CloudWatch Logs에서 효과적인 메트릭 필터를 생성하는 데 도움이 되는 다음 작업 중 어떤 것이 있습니까? (두 개 선택)",
        "Options": {
            "1": "API 호출 모니터링을 위해 CloudTrail 로그를 사용하여 메트릭 필터를 생성합니다.",
            "2": "CloudWatch Logs 구독 필터를 생성하여 로그를 S3 버킷으로 직접 스트리밍합니다.",
            "3": "로그 데이터가 특정 임계값을 초과할 때 경고를 트리거하는 메트릭 필터를 설정합니다.",
            "4": "특정 로그 필드를 기반으로 메트릭 필터를 생성하고 이를 CloudWatch 대시보드와 연결합니다.",
            "5": "특정 로그 이벤트 패턴과 일치하는 메트릭 필터를 정의하고 메트릭 이름을 지정합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "특정 로그 이벤트 패턴과 일치하는 메트릭 필터를 정의하고 메트릭 이름을 지정합니다.",
            "로그 데이터가 특정 임계값을 초과할 때 경고를 트리거하는 메트릭 필터를 설정합니다."
        ],
        "Explanation": "특정 로그 이벤트 패턴과 일치하는 메트릭 필터를 정의하면 관리자가 로그에서 관련 메트릭을 캡처할 수 있으며, 임계값에 따라 경고를 트리거하는 메트릭 필터를 설정하면 중요한 조건에 대한 사전 모니터링 및 경고를 보장합니다.",
        "Other Options": [
            "CloudWatch Logs 구독 필터를 생성하여 로그를 S3 버킷으로 직접 스트리밍하는 것은 메트릭 필터를 생성하는 방법이 아니며, 로그 저장을 위해 사용됩니다.",
            "CloudTrail 로그를 사용하여 메트릭 필터를 생성하는 것은 적용되지 않으며, 메트릭 필터는 CloudWatch Logs를 위해 특별히 설계된 것입니다.",
            "특정 로그 필드를 기반으로 메트릭 필터를 생성하고 이를 CloudWatch 대시보드와 연결하는 것은 메트릭을 직접 캡처하거나 경고를 트리거하지 않으며, 시각화를 위한 것입니다."
        ]
    },
    {
        "Question Number": "53",
        "Situation": "한 회사는 중요한 데이터가 우발적인 삭제 및 손상으로부터 보호되도록 하고자 합니다. 현재 Amazon S3를 저장소로 사용하고 있지만 백업 솔루션을 구현하지 않았습니다. SysOps 관리자는 데이터를 보호하기 위한 신뢰할 수 있는 백업 및 복원 전략을 수립하는 임무를 맡았습니다.",
        "Question": "SysOps 관리자가 Amazon S3에 저장된 데이터에 대한 강력한 백업 및 복원 솔루션을 달성하기 위해 구현해야 할 전략은 무엇입니까?",
        "Options": {
            "1": "Amazon S3 수명 주기 정책을 구현하여 오래된 데이터를 자동으로 삭제합니다.",
            "2": "버킷에서 S3 버전 관리를 활성화하여 객체의 여러 버전을 유지합니다.",
            "3": "Amazon S3 전송 가속을 사용하여 데이터를 다른 리전으로 백업합니다.",
            "4": "AWS 데이터 파이프라인을 활용하여 로컬 저장소에 정기적인 백업을 예약합니다."
        },
        "Correct Answer": "버킷에서 S3 버전 관리를 활성화하여 객체의 여러 버전을 유지합니다.",
        "Explanation": "S3 버전 관리를 활성화하면 회사는 버킷 내의 각 객체에 대한 여러 버전을 유지할 수 있어 우발적인 삭제 또는 수정 시 이전 버전을 복구할 수 있는 방법을 제공합니다. 이 전략은 데이터 무결성과 가용성을 보장하여 강력한 백업 및 복원 솔루션이 됩니다.",
        "Other Options": [
            "Amazon S3 전송 가속은 주로 S3로의 데이터 전송 속도를 높이지만 본질적으로 백업 솔루션을 제공하거나 데이터 손실로부터 보호하지 않습니다.",
            "AWS 데이터 파이프라인은 데이터를 이동하고 변환하는 데 더 적합하지만 S3 데이터를 로컬 저장소에 백업하는 것과 직접적으로 관련이 없으며 불필요한 복잡성을 초래할 수 있습니다.",
            "Amazon S3 수명 주기 정책을 구현하는 것은 객체의 수명 주기를 관리하는 데 중점을 두며(예: 저비용 저장소로 전환하거나 삭제) 백업 솔루션을 제공하지 않으며, 이는 영구적인 데이터 손실로 이어질 수 있습니다."
        ]
    },
    {
        "Question Number": "54",
        "Situation": "한 회사는 최소한의 다운타임으로 웹 애플리케이션의 새 버전을 배포할 계획입니다. 개발 팀은 새 버전이 안정성이 확인될 때까지 이전 버전을 운영 상태로 유지하면서 점진적으로 트래픽을 새 버전으로 전환할 수 있는 배포 전략을 추천했습니다. 이 요구 사항에 맞는 최상의 배포 전략을 선택해야 합니다.",
        "Question": "새 애플리케이션 버전을 검증하면서 최소한의 다운타임을 보장하기 위해 어떤 배포 전략을 구현해야 합니까?",
        "Options": {
            "1": "롤링 배포",
            "2": "카나리 배포",
            "3": "블루/그린 배포",
            "4": "재생성 배포"
        },
        "Correct Answer": "카나리 배포",
        "Explanation": "카나리 배포는 애플리케이션의 새 버전을 전체 사용자 기반에 배포하기 전에 소규모 사용자 집단에 출시할 수 있게 해줍니다. 이 전략은 새 버전의 성능과 안정성을 모니터링할 수 있게 하여, 전체 배포 전에 문제를 해결할 수 있도록 하여 다운타임을 최소화합니다.",
        "Other Options": [
            "롤링 배포는 인스턴스를 배치로 업데이트하지만, 적절히 관리되지 않으면 여전히 일부 다운타임이 발생할 수 있으며, 카나리 배포와 같은 수준의 위험 완화를 허용하지 않습니다.",
            "블루/그린 배포는 두 개의 별도 환경을 유지하는 것으로, 빠른 롤백을 제공하지만 더 많은 리소스를 요구하며 카나리 배포에 비해 점진적인 트래픽 검증에 덜 효율적입니다.",
            "재생성 배포는 새 버전을 시작하기 전에 이전 버전을 완전히 종료하므로 상당한 다운타임이 발생할 수 있으며 새 버전의 실시간 테스트를 허용하지 않습니다."
        ]
    },
    {
        "Question Number": "55",
        "Situation": "한 회사가 AWS에서 인프라를 빠르게 확장하고 있으며 특정 지역에서 20개의 EC2 인스턴스의 최대 한도에 도달했습니다. SysOps 관리자는 증가하는 애플리케이션 수요를 충족하기 위해 추가 인스턴스를 시작해야 합니다. 이 문제를 효과적으로 해결하기 위해 관리자는 인스턴스 한도를 처리하는 방법을 고려해야 합니다.",
        "Question": "SysOps 관리자가 InstanceLimitExceeded 오류를 해결하고 해당 지역에서 추가 EC2 인스턴스를 생성할 수 있도록 하려면 무엇을 해야 합니까?",
        "Options": {
            "1": "AWS Support Center를 통해 지정된 지역의 EC2 인스턴스에 대한 한도 증가를 요청합니다.",
            "2": "새 인스턴스를 위한 용량을 확보하기 위해 사용하지 않는 기존 EC2 인스턴스를 종료합니다.",
            "3": "한도에 도달하지 않은 다른 AWS 지역에서 추가 EC2 인스턴스를 생성합니다.",
            "4": "이미 실행 중인 EC2 인스턴스의 인스턴스 유형을 더 작은 인스턴스 유형으로 변경하여 수를 줄입니다."
        },
        "Correct Answer": "AWS Support Center를 통해 지정된 지역의 EC2 인스턴스에 대한 한도 증가를 요청합니다.",
        "Explanation": "AWS Support Center를 통해 한도 증가를 요청하는 것은 InstanceLimitExceeded 오류를 해결하는 가장 직접적이고 효과적인 방법으로, 관리자가 기존 인스턴스를 종료하거나 구성을 변경하지 않고도 동일한 지역에서 추가 인스턴스를 시작할 수 있도록 합니다.",
        "Other Options": [
            "기존 EC2 인스턴스를 종료하는 것은 해당 인스턴스가 지속적인 운영에 필요할 경우 실현 가능하지 않으며, 추가 인스턴스의 필요를 해결하지 않습니다.",
            "이미 실행 중인 인스턴스의 인스턴스 유형을 변경하는 것은 한도 문제를 해결하지 않으며, 단순히 해당 인스턴스에 할당된 리소스를 변경할 뿐 총 인스턴스 수를 증가시키지 않습니다.",
            "다른 지역에서 추가 EC2 인스턴스를 생성하는 것은 일시적으로 작동할 수 있지만, 원래 지역의 한도의 근본 원인을 해결하지 않으며 여러 지역에서 리소스를 관리하는 데 복잡성을 증가시킬 수 있습니다."
        ]
    },
    {
        "Question Number": "56",
        "Situation": "한 회사가 Elastic Load Balancing (ELB)을 사용하여 여러 가용 영역(AZ)에 걸쳐 웹 애플리케이션을 배포하여 들어오는 트래픽을 분산시키고 있습니다. 높은 가용성을 보장하기 위해 회사는 애플리케이션에 대한 헬스 체크를 구현하여 불건전한 인스턴스를 로드 밸런서의 대상 풀에서 제거하고자 합니다.",
        "Question": "회사가 ELB 헬스 체크가 적절하게 설정되고 트래픽이 건강한 인스턴스에만 전달되도록 보장하기 위해 어떤 구성을 구현해야 합니까?",
        "Options": {
            "1": "특정 포트와 경로에서 애플리케이션을 모니터링하도록 ELB 헬스 체크를 구성합니다.",
            "2": "CloudWatch 경고를 사용하여 인스턴스 건강을 수동으로 모니터링합니다.",
            "3": "ELB 헬스 체크 없이 DNS 장애 조치를 수행하도록 Route 53을 설정합니다.",
            "4": "일관된 연결을 보장하기 위해 ELB에서 스티키 세션을 활성화합니다."
        },
        "Correct Answer": "특정 포트와 경로에서 애플리케이션을 모니터링하도록 ELB 헬스 체크를 구성합니다.",
        "Explanation": "특정 포트와 경로에서 애플리케이션을 모니터링하도록 ELB 헬스 체크를 구성하면 로드 밸런서가 인스턴스의 건강을 자동으로 판단할 수 있습니다. 인스턴스가 헬스 체크를 통과하지 못하면 로드 밸런서의 풀에서 제거되어 건강한 인스턴스만 트래픽을 받게 됩니다.",
        "Other Options": [
            "스티키 세션을 활성화하면 사용자가 동일한 인스턴스에 연결된 상태를 유지하여 사용자 경험을 개선할 수 있지만, 헬스 체크의 필요를 해결하지 않으며 불건전한 인스턴스에 트래픽을 전달할 수 있습니다.",
            "ELB 헬스 체크 없이 Route 53을 설정하여 DNS 장애 조치를 수행하는 것은 건강한 인스턴스만 트래픽을 제공하는 것을 보장하지 않으며, 인스턴스 건강이 아닌 DNS 해상도에 의존합니다.",
            "CloudWatch 경고를 사용하여 인스턴스 건강을 수동으로 모니터링하는 것은 불건전한 인스턴스를 로드 밸런서에서 제거하는 프로세스를 자동화하지 않으며, 이는 ELB 헬스 체크를 구성하는 주요 이점입니다."
        ]
    },
    {
        "Question Number": "57",
        "Situation": "한 금융 서비스 회사가 Amazon SQS를 사용하여 마이크로서비스 간의 메시지 처리를 관리하고 있습니다. 때때로 일부 메시지는 예상치 못한 데이터 형식이나 일시적인 문제로 인해 처리되지 않습니다. 팀은 이러한 문제 메시지가 손실되지 않고 나중에 분석하여 처리 논리를 개선할 수 있도록 보장하고자 합니다.",
        "Question": "팀이 성공적으로 처리할 수 없는 메시지를 추가 분석을 위해 격리하는 방식으로 처리하기 위해 어떤 기능을 구현해야 합니까?",
        "Options": {
            "1": "메시지 순서를 유지하기 위해 소스 큐에 FIFO 큐를 구성합니다.",
            "2": "실패한 메시지를 캡처하기 위해 소스 큐에 데드레터 큐를 설정합니다.",
            "3": "메시지를 더 오래 저장하기 위해 소스 큐에서 메시지 보존을 활성화합니다.",
            "4": "소스 큐에서 메시지 지연을 구현하여 나중에 처리를 재시도합니다."
        },
        "Correct Answer": "실패한 메시지를 캡처하기 위해 소스 큐에 데드레터 큐를 설정합니다.",
        "Explanation": "데드레터 큐는 지정된 시도 횟수 후에 성공적으로 처리되지 않은 메시지를 처리하기 위해 특별히 설계되었습니다. 이는 이러한 메시지를 격리하고 분석할 수 있게 하여 메시지 처리 논리를 디버깅하고 개선하는 데 필수적입니다.",
        "Other Options": [
            "메시지 보존을 활성화하는 것은 단순히 메시지를 더 오래 저장하지만, 실패한 메시지를 분석을 위해 격리하지 않습니다. 메시지가 실패한 이유에 대한 필요한 통찰력을 제공하지 않습니다.",
            "메시지 지연을 구현하면 메시지 처리를 일시적으로 연기할 수 있지만, 궁극적으로 처리되지 않는 메시지 문제를 해결하지 않으며, 이러한 실패를 분석할 방법을 제공하지 않습니다.",
            "FIFO 큐를 구성하면 메시지가 순서대로 처리되도록 보장하지만, 성공적으로 처리되지 않는 메시지를 처리하는 메커니즘을 제공하지 않습니다. 이는 실패한 메시지를 격리하거나 분석하는 데 도움이 되지 않습니다."
        ]
    },
    {
        "Question Number": "58",
        "Situation": "귀하의 조직은 데이터 집약적인 애플리케이션을 AWS로 마이그레이션할 계획입니다. 이 애플리케이션은 높은 처리량과 낮은 대기 시간으로 대량의 데이터 세트를 처리할 수 있는 기능이 필요합니다. 귀하는 애플리케이션의 성능을 최적화하기 위해 가장 적합한 EC2 인스턴스 유형을 선택하는 임무를 맡았습니다.",
        "Question": "고속 IOPS를 요구하는 스토리지 집약적인 워크로드에 최적의 성능을 보장하기 위해 어떤 EC2 인스턴스 유형을 선택해야 합니까?",
        "Options": {
            "1": "균형 잡힌 리소스 할당을 위한 일반 목적 인스턴스.",
            "2": "고속 순차 I/O를 위해 설계된 스토리지 최적화 인스턴스.",
            "3": "높은 CPU 성능을 위한 컴퓨팅 최적화 인스턴스.",
            "4": "대용량 메모리 요구 사항을 위한 메모리 최적화 인스턴스."
        },
        "Correct Answer": "고속 순차 I/O를 위해 설계된 스토리지 최적화 인스턴스.",
        "Explanation": "스토리지 최적화 인스턴스는 대량의 데이터 세트에 빠르게 접근해야 하는 애플리케이션을 위해 높은 I/O 성능을 제공하도록 특별히 설계되었습니다. 이들은 낮은 대기 시간과 높은 처리량의 스토리지를 제공하여 고속 순차 읽기 및 쓰기 접근을 요구하는 워크로드에 이상적입니다.",
        "Other Options": [
            "컴퓨팅 최적화 인스턴스는 높은 CPU 성능을 제공하는 데 중점을 두지만, 스토리지 성능에 의존하는 I/O 집약적인 워크로드에는 적합하지 않습니다.",
            "일반 목적 인스턴스는 컴퓨팅, 메모리 및 네트워킹 리소스의 균형을 제공하지만, 스토리지 집약적인 작업을 위해 특별히 최적화되지 않습니다.",
            "메모리 최적화 인스턴스는 높은 메모리 할당이 필요한 애플리케이션을 위해 설계되었으며, 이는 높은 IOPS 및 스토리지 성능의 필요를 해결하지 않습니다."
        ]
    },
    {
        "Question Number": "59",
        "Situation": "한 회사가 PostgreSQL RDS 인스턴스에 의존하는 중요한 애플리케이션을 관리하고 있습니다. 최근에 회사는 데이터베이스 레코드 일부가 손상되는 주요 사건을 경험하여 데이터 손실이 발생했습니다. SysOps 관리자는 다운타임을 최소화하면서 손실된 데이터를 복구하기 위해 데이터베이스를 특정 시점으로 복원해야 합니다.",
        "Question": "SysOps 관리자가 데이터베이스를 효과적으로 복원하는 데 도움이 되는 두 가지 옵션은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "사건 발생 이전에 찍은 수동 스냅샷에서 데이터베이스를 복원합니다.",
            "2": "RDS 인스턴스에 대해 자동 장애 조치를 위한 Multi-AZ를 활성화합니다.",
            "3": "RDS 인스턴스의 스토리지 유형을 프로비저닝된 IOPS로 전환합니다.",
            "4": "자동 백업을 사용하여 시점 복원을 수행합니다.",
            "5": "RDS 인스턴스의 읽기 복제본을 생성하고 이를 승격합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "자동 백업을 사용하여 시점 복원을 수행합니다.",
            "사건 발생 이전에 찍은 수동 스냅샷에서 데이터베이스를 복원합니다."
        ],
        "Explanation": "자동 백업을 사용하여 시점 복원을 수행하면 SysOps 관리자가 데이터베이스를 특정 타임스탬프로 복원하여 손실된 데이터를 효과적으로 복구할 수 있습니다. 또한 사건 발생 이전에 찍은 수동 스냅샷에서 복원하면 스냅샷 당시의 데이터베이스 상태를 복구할 수 있어 데이터 손실에서 회복할 수 있는 또 다른 신뢰할 수 있는 방법을 제공합니다.",
        "Other Options": [
            "읽기 복제본을 생성하고 이를 승격하는 것은 손실된 데이터를 직접 복구하는 데 도움이 되지 않습니다. 읽기 복제본은 마스터의 데이터베이스 상태를 복제하므로 승격 이전에 발생한 손상이나 누락된 데이터를 포함합니다.",
            "RDS 인스턴스에 대해 Multi-AZ를 활성화하면 높은 가용성과 자동 장애 조치를 제공하지만, 장애 조치 이벤트 이전에 기본 인스턴스에서 발생한 데이터 손실을 복구하는 데는 도움이 되지 않습니다.",
            "스토리지 유형을 프로비저닝된 IOPS로 전환하면 성능이 향상되지만, 데이터 손실 복원에는 도움이 되지 않으며, 데이터 손상이라는 근본적인 문제를 해결하지 않습니다."
        ]
    },
    {
        "Question Number": "60",
        "Situation": "시스템 관리자가 임시 데이터 저장을 위해 인스턴스 스토어 볼륨을 사용하는 EC2 인스턴스의 성능을 모니터링하고 있습니다. 그들은 애플리케이션 성능을 최적화하기 위해 이러한 볼륨에서 수행되는 읽기 작업을 인지하고 싶어합니다.",
        "Question": "다음 중 EC2 인스턴스 스토어 볼륨과 관련하여 DiskReadOps 메트릭을 정확하게 설명하는 문장은 무엇입니까?",
        "Options": {
            "1": "DiskReadOps는 인스턴스 스토어 볼륨에서의 모든 읽기 작업을 계산하며 항상 보고됩니다.",
            "2": "DiskReadOps는 완료된 읽기 작업의 수를 나타내지만, 인스턴스 스토어 볼륨이 없으면 보고되지 않습니다.",
            "3": "DiskReadOps는 인스턴스 스토어 볼륨에서의 읽기 및 쓰기 작업을 모두 측정합니다.",
            "4": "DiskReadOps는 VPC 내 모든 EC2 인스턴스의 디스크 사용량을 추적하는 메트릭입니다."
        },
        "Correct Answer": "DiskReadOps는 완료된 읽기 작업의 수를 나타내지만, 인스턴스 스토어 볼륨이 없으면 보고되지 않습니다.",
        "Explanation": "DiskReadOps는 인스턴스 스토어 볼륨에서 완료된 읽기 작업의 수를 정확하게 반영합니다. 인스턴스 스토어 볼륨이 없으면 이 메트릭은 0의 값을 표시하거나 전혀 보고되지 않습니다.",
        "Other Options": [
            "이 옵션은 DiskReadOps가 인스턴스 스토어 볼륨이 있을 때만 보고되기 때문에 잘못되었습니다. 인스턴스 스토어 볼륨이 없으면 이 메트릭은 보고되지 않습니다.",
            "이 옵션은 DiskReadOps가 읽기 작업만 계산하고 쓰기 작업은 계산하지 않기 때문에 잘못되었습니다. 이 메트릭은 인스턴스 스토어 볼륨에서 완료된 읽기 작업만 추적합니다.",
            "이 옵션은 DiskReadOps가 VPC 내 모든 EC2 인스턴스의 디스크 사용량과 관련이 없고, 인스턴스 스토어 볼륨에서의 읽기 작업에만 해당하기 때문에 잘못되었습니다."
        ]
    },
    {
        "Question Number": "61",
        "Situation": "준수 담당자는 AWS CloudTrail에서 제공하는 로그 파일의 무결성이 유지되도록 하는 임무를 맡고 있습니다. 담당자는 이러한 로그의 무단 수정, 삭제 또는 변경을 감지할 수 있는 솔루션을 구현하고자 합니다. 담당자는 AWS CLI에 익숙하며 이 목적을 위해 AWS의 내장 기능을 활용하고자 합니다.",
        "Question": "CloudTrail 로그의 로그 파일 무결성 검증을 활성화하기 위해 담당자가 취해야 할 조치는 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "AWS CLI를 사용하여 로그 파일을 SHA-256 해시와 비교하여 검증합니다.",
            "2": "로그 파일 삭제에 대한 알림을 받기 위해 CloudWatch Alarm을 설정합니다.",
            "3": "CloudTrail 구성 설정에서 로그 파일 무결성 검증을 활성화합니다.",
            "4": "AWS Lambda를 사용하여 로그 파일 변경 사항을 실시간으로 모니터링합니다.",
            "5": "로그 파일을 다운로드하여 수동으로 수정 사항을 확인합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "CloudTrail 구성 설정에서 로그 파일 무결성 검증을 활성화합니다.",
            "AWS CLI를 사용하여 로그 파일을 SHA-256 해시와 비교하여 검증합니다."
        ],
        "Explanation": "CloudTrail에서 로그 파일 무결성 검증을 활성화하면 로그가 서명되고 해시되어 무결성을 검증할 수 있습니다. 또한, AWS CLI를 사용하여 로그를 검증하면 로그가 전달된 이후로 변경, 삭제 또는 위조되지 않았음을 확인하는 간단한 방법을 제공합니다.",
        "Other Options": [
            "AWS Lambda를 사용한 실시간 모니터링은 로그의 무결성을 직접 검증하지 않으며, CloudTrail의 내장 기능을 고려할 때 필요하지 않습니다.",
            "CloudWatch Alarm을 설정하면 삭제에 대한 경고를 받을 수 있지만, 로그 파일 자체의 무결성을 검증하는 메커니즘을 제공하지 않습니다.",
            "로그 파일을 수동으로 수정 사항을 확인하는 것은 비효율적이며 AWS에서 제공하는 자동화된 무결성 검증 기능을 활용하지 않습니다."
        ]
    },
    {
        "Question Number": "62",
        "Situation": "한 회사가 AWS Systems Manager를 사용하여 Amazon EC2 인스턴스의 집합을 관리하고 있습니다. SysOps 관리자는 중요한 보안 패치를 자동 승인하도록 패치 기준을 구성했습니다. 그러나 일부 인스턴스는 여전히 최신 보안 기준을 준수하지 않습니다. 관리자는 모든 인스턴스가 특정 기간 동안 자동으로 패치되도록 하여 중단을 최소화하고자 합니다.",
        "Question": "SysOps 관리자가 지정된 기간 동안 모든 인스턴스가 필요한 패치를 받을 수 있도록 하려면 무엇을 해야 합니까?",
        "Options": {
            "1": "사용 가능한 모든 패치를 포함하는 새로운 패치 기준을 생성하고 이를 인스턴스에 적용합니다.",
            "2": "EC2 인스턴스의 자동 등록을 활성화하여 패치 기준에 자동으로 추가되도록 합니다.",
            "3": "시스템 관리자가 인스턴스에 패치를 수동으로 설치하는 명령을 실행하도록 구성합니다.",
            "4": "시스템 관리자에서 인스턴스의 패치 프로세스를 자동화하기 위해 유지 관리 창을 예약합니다."
        },
        "Correct Answer": "시스템 관리자에서 인스턴스의 패치 프로세스를 자동화하기 위해 유지 관리 창을 예약합니다.",
        "Explanation": "시스템 관리자에서 유지 관리 창을 예약하면 SysOps 관리자가 패치를 자동으로 적용할 특정 시간을 정의할 수 있어 모든 인스턴스가 수동 개입 없이 업데이트되고 서비스 중단을 최소화할 수 있습니다.",
        "Other Options": [
            "사용 가능한 모든 패치를 포함하는 새로운 패치 기준을 생성하는 것은 특정 시간 프레임 동안 패치가 적용되도록 보장하지 않으며, 프로세스를 효과적으로 자동화하지도 않습니다.",
            "패치를 수동으로 설치하는 명령을 실행하는 것은 대규모 인스턴스 그룹에 대해 효율적이지 않으며 유지 관리 창 동안 패치 프로세스를 자동화하는 목표와 일치하지 않습니다.",
            "EC2 인스턴스의 자동 등록을 활성화하는 것은 패치 문제를 직접적으로 해결하지 않으며, 이는 인스턴스가 시스템 관리자에 의해 인식되도록 보장할 뿐, 패치가 적용되는 시기나 방법을 제어하지 않습니다."
        ]
    },
    {
        "Question Number": "63",
        "Situation": "모바일 애플리케이션은 사용자 인증이 필요하며 특정 AWS 리소스에 접근하기 위해 사용자에게 임시 자격 증명을 제공해야 합니다. 이 애플리케이션은 사용자 신원 및 권한 관리를 위해 Amazon Cognito 아이덴티티 풀을 사용합니다. 인증된 사용자와 게스트 사용자가 자신의 상태에 따라 적절한 접근 권한을 갖도록 해야 합니다.",
        "Question": "다음 중 Amazon Cognito 아이덴티티 풀에서 역할 할당 동작을 올바르게 설명하는 문장은 무엇입니까?",
        "Options": {
            "1": "Cognito 아이덴티티 풀은 게스트 사용자에 대한 역할 할당을 지원하지 않습니다.",
            "2": "ID 토큰의 클레임에 따라 인증된 사용자에 대한 IAM 역할을 정의할 수 있습니다.",
            "3": "인증된 사용자는 자신에게 할당된 기본 IAM 역할만 사용할 수 있습니다.",
            "4": "게스트 사용자는 인증된 사용자와 동일한 권한을 얻어야 합니다."
        },
        "Correct Answer": "ID 토큰의 클레임에 따라 인증된 사용자에 대한 IAM 역할을 정의할 수 있습니다.",
        "Explanation": "Amazon Cognito 아이덴티티 풀은 ID 토큰의 특정 클레임에 따라 인증된 사용자에게 IAM 역할을 할당할 수 있어 다양한 사용자 유형에 대한 권한 관리를 유연하게 제공합니다.",
        "Other Options": [
            "인증된 사용자는 정의된 기본 역할을 활용할 수 있지만, 이에 국한되지 않으며 역할은 ID 토큰 클레임에 따라 할당될 수 있습니다.",
            "게스트 사용자는 제한된 권한을 가지며 인증된 사용자와 동일한 권한을 자동으로 받지 않습니다.",
            "Cognito 아이덴티티 풀은 게스트 사용자에 대한 역할 할당을 지원하여 제한된 권한을 가진 별도의 IAM 역할을 정의할 수 있습니다."
        ]
    },
    {
        "Question Number": "64",
        "Situation": "소매 회사가 AWS CloudFormation을 사용하여 새로운 애플리케이션 스택을 배포하고 있습니다. 인프라에는 여러 개의 EC2 인스턴스, RDS 데이터베이스 및 S3 버킷이 포함됩니다. SysOps 관리자는 스택이 다운타임 없이 쉽게 업데이트될 수 있도록 해야 합니다.",
        "Question": "SysOps 관리자가 CloudFormation 스택의 업데이트가 다운타임을 초래하지 않도록 보장하기 위해 어떤 접근 방식을 취해야 합니까?",
        "Options": {
            "1": "충돌을 피하기 위해 각 업데이트마다 새로운 CloudFormation 스택을 생성합니다.",
            "2": "'ChangeSet' 기능을 사용하여 적용하기 전에 업데이트를 검토합니다.",
            "3": "Auto Scaling 그룹에 대해 'UpdatePolicy' 속성을 'RollingUpdate'로 설정합니다.",
            "4": "스택 업데이트를 적용하기 전에 리소스를 수동으로 조정합니다."
        },
        "Correct Answer": "Auto Scaling 그룹에 대해 'UpdatePolicy' 속성을 'RollingUpdate'로 설정합니다.",
        "Explanation": "'UpdatePolicy' 속성을 'RollingUpdate'로 설정하면 CloudFormation이 인스턴스를 제어된 방식으로 업데이트할 수 있어 일부 인스턴스는 업데이트되는 동안에도 사용 가능하게 유지되어 다운타임을 최소화하거나 제거할 수 있습니다.",
        "Other Options": [
            "'ChangeSet' 기능을 사용하는 것은 변경 사항을 검토하는 데 유용하지만 업데이트 과정에서 다운타임을 본질적으로 방지하지는 않습니다.",
            "각 업데이트마다 새로운 CloudFormation 스택을 생성하면 리소스 중복 및 관리 복잡성이 증가하여 원활한 업데이트 프로세스가 되지 않습니다.",
            "스택 업데이트를 적용하기 전에 리소스를 수동으로 조정하는 것은 CloudFormation의 자동화 기능을 활용하지 못하며 오류나 불일치를 초래할 수 있습니다."
        ]
    },
    {
        "Question Number": "65",
        "Situation": "중간 규모의 전자상거래 회사가 쇼핑 성수기 동안 변동하는 트래픽 패턴을 경험하고 있습니다. 그들은 높은 가용성을 보장하면서 비용과 성능을 모두 최적화하고 싶어합니다. 현재 회사는 자체 데이터베이스 및 컨테이너 오케스트레이션을 관리하고 있으며, 이는 점점 더 복잡하고 비용이 많이 들고 있습니다.",
        "Question": "SysOps 관리자가 회사의 데이터베이스 관리를 위한 비용 최적화 및 성능 향상을 도와줄 수 있는 관리형 서비스는 무엇입니까?",
        "Options": {
            "1": "데이터베이스 백업을 위한 객체 저장소로 Amazon S3.",
            "2": "자동화된 데이터베이스 관리를 위한 Amazon RDS.",
            "3": "서버리스 데이터베이스 작업을 위한 AWS Lambda.",
            "4": "데이터베이스 인스턴스를 직접 관리하기 위한 Amazon EC2."
        },
        "Correct Answer": "자동화된 데이터베이스 관리를 위한 Amazon RDS.",
        "Explanation": "Amazon RDS (Relational Database Service)는 하드웨어 프로비저닝, 데이터베이스 설정, 패치 및 백업과 같은 시간 소모적인 관리 작업을 자동화하는 관리형 데이터베이스 서비스입니다. Amazon RDS를 사용함으로써 회사는 운영 오버헤드를 줄이고 확장성을 향상시키며, 특히 트래픽이 많은 기간 동안 데이터베이스 운영과 관련된 비용을 최적화할 수 있습니다.",
        "Other Options": [
            "Amazon EC2는 인스턴스를 수동으로 관리해야 하며 RDS와 같은 수준의 자동화 및 비용 최적화를 제공하지 않으므로 회사의 요구에 덜 적합합니다.",
            "AWS Lambda는 주로 서버리스 컴퓨팅에 사용되며 전통적인 데이터베이스 관리에 설계되지 않았기 때문에 회사의 데이터베이스 최적화 요구를 효과적으로 충족하지 못합니다.",
            "Amazon S3는 객체 저장소 서비스이며 데이터베이스를 직접 관리하는 데 적합하지 않지만 백업 저장에는 사용할 수 있지만 데이터베이스 성능을 최적화하지는 않습니다."
        ]
    }
]