[
    {
        "Question Number": "1",
        "Situation": "개발자가 Amazon SQS 큐의 메시지를 처리하는 AWS Lambda 함수를 생성하고 있습니다. 이 함수는 큐의 메시지 수에 따라 자동으로 확장되어야 하며, 메시지가 최소한 한 번은 처리되도록 해야 합니다.",
        "Question": "개발자가 이를 달성하기 위해 어떤 구성을 적용해야 합니까?",
        "Options": {
            "1": "기본 설정으로 SQS 큐와 Lambda 함수 간의 이벤트 소스 매핑을 설정합니다.",
            "2": "Amazon SNS를 사용하여 메시지를 여러 Lambda 함수로 분산합니다.",
            "3": "Lambda 함수를 수동으로 SQS 큐를 폴링하도록 구성합니다.",
            "4": "자동 확장이 활성화된 Amazon ECS 클러스터에 Lambda 함수를 배포합니다."
        },
        "Correct Answer": "기본 설정으로 SQS 큐와 Lambda 함수 간의 이벤트 소스 매핑을 설정합니다.",
        "Explanation": "이벤트 소스 매핑을 설정하면 Lambda 함수가 SQS 큐에 도착하는 메시지에 따라 자동으로 트리거됩니다. 이 구성은 Lambda 함수가 메시지 수에 따라 자동으로 확장되고 최소한 한 번은 메시지를 처리하도록 보장합니다.",
        "Other Options": [
            "Amazon SNS를 사용하여 메시지를 여러 Lambda 함수로 분산하는 것은 SQS 큐에서 직접 메시지를 처리하는 데 가장 적합하지 않으며, SNS는 주로 pub/sub 메시징을 위해 설계되었고 SQS를 트리거로 사용할 때 최소한 한 번의 전송을 보장하지 않습니다.",
            "Lambda 함수를 수동으로 SQS 큐를 폴링하도록 구성하는 것은 Lambda의 자동 확장 기능을 활용하지 않으며, 더 많은 관리 오버헤드를 요구하므로 비효율적입니다.",
            "자동 확장이 활성화된 Amazon ECS 클러스터에 Lambda 함수를 배포하는 것은 이 작업에 불필요합니다. Lambda는 SQS 메시지를 처리하는 데 필요한 확장 기능을 이미 제공하므로 ECS를 사용하는 복잡성을 피할 수 있습니다."
        ]
    },
    {
        "Question Number": "2",
        "Situation": "개발자가 AWS SDK for Python (Boto3)을 사용하여 Amazon S3와 상호작용하는 클라우드 기반 애플리케이션을 구축하고 있습니다. 애플리케이션을 테스트하는 동안 개발자는 특정 S3 버킷에 접근할 때 무단 접근 시도를 나타내는 예외를 만납니다.",
        "Question": "개발자가 S3 상호작용 중에 발생하는 이러한 무단 접근 오류를 효과적으로 관리하기 위해 어떤 유형의 SDK 예외를 구체적으로 처리해야 합니까?",
        "Options": {
            "1": "NoCredentialsError: 이 예외는 SDK가 사용자를 인증할 유효한 AWS 자격 증명을 찾을 수 없을 때 발생합니다.",
            "2": "AccessDenied: 이 예외는 사용자가 S3 리소스에서 요청된 작업을 수행할 수 있는 충분한 권한이 없을 때 발생합니다.",
            "3": "BucketNotFound: 이 예외는 지정된 S3 버킷이 존재하지 않거나 잘못된 이름일 때 나타납니다.",
            "4": "ConnectionError: 이 예외는 SDK가 네트워크 문제로 인해 AWS 서비스에 연결할 수 없을 때 발생합니다."
        },
        "Correct Answer": "AccessDenied: 이 예외는 사용자가 S3 리소스에서 요청된 작업을 수행할 수 있는 충분한 권한이 없을 때 발생합니다.",
        "Explanation": "정답은 AccessDenied입니다. 이 예외는 사용자가 Amazon S3 내의 리소스에 접근하거나 조작할 수 있는 필요한 권한이 부족한 상황과 관련이 있습니다. 이 예외를 처리하면 개발자가 무단 접근 시도에 대한 적절한 오류 처리 및 알림을 구현할 수 있습니다.",
        "Other Options": [
            "NoCredentialsError는 AWS 자격 증명이 누락된 경우와 관련이 있으므로 권한이나 인증 문제와는 관련이 없습니다.",
            "BucketNotFound는 지정된 버킷의 존재와 관련이 있으므로 사용자의 접근 권한과는 관련이 없습니다.",
            "ConnectionError는 AWS 서비스에 연결하는 데 있어 네트워크 관련 문제를 나타내므로 리소스 접근과 관련된 권한 문제와는 관련이 없습니다."
        ]
    },
    {
        "Question Number": "3",
        "Situation": "한 회사가 API 관리를 위해 Amazon API Gateway를 사용하고 있으며, 새로운 업데이트가 발생할 때마다 캐시된 응답이 즉시 무효화되도록 해야 합니다. 또한 특정 사용자에게 필요에 따라 프로그래밍적으로 캐시 무효화를 트리거할 수 있는 권한을 부여하고자 합니다.",
        "Question": "회사가 API의 캐시 무효화를 효과적으로 관리하기 위해 어떤 단계를 밟아야 합니까?",
        "Options": {
            "1": "Cache-Control 헤더를 최대 3600초로 설정하고 API Gateway 단계의 설정을 업데이트하여 이러한 변경 사항을 반영합니다.",
            "2": "execute-api:InvalidateCache 작업을 허용하는 권한 정책을 추가하고 Cache-Control 헤더를 최대 0초로 설정하여 즉각적인 캐시 무효화를 보장합니다.",
            "3": "API Gateway 단계 설정에서 캐시 무효화 기능을 활성화하고 Cache-Control 헤더를 no-cache로 설정하여 즉각적인 업데이트를 표시합니다.",
            "4": "API Gateway 콘솔을 사용하여 수동으로 캐시를 지우고 Cache-Control 헤더를 최대 0초로 조정하여 신선한 데이터를 확보합니다."
        },
        "Correct Answer": "execute-api:InvalidateCache 작업을 허용하는 권한 정책을 추가하고 Cache-Control 헤더를 최대 0초로 설정하여 즉각적인 캐시 무효화를 보장합니다.",
        "Explanation": "execute-api:InvalidateCache 작업에 대한 권한 정책을 추가함으로써 회사는 특정 사용자에게 프로그래밍적으로 캐시를 무효화할 수 있는 능력을 부여합니다. Cache-Control 헤더를 최대 0초로 설정하면 캐시된 응답이 항상 오래된 것으로 간주되어 API Gateway가 요청 시 원본 서버에서 신선한 데이터를 가져오도록 강제합니다.",
        "Other Options": [
            "Cache-Control 헤더를 최대 3600초로 설정하면 캐시된 응답이 1시간 동안 유효하게 되어 업데이트 시 즉각적인 무효화 요구 사항을 충족하지 않습니다.",
            "API Gateway 단계 구성에서 캐시 무효화를 활성화하고 Cache-Control 헤더를 no-cache로 설정하는 것은 사용자가 프로그래밍적으로 캐시를 무효화할 수 있는 특정 권한을 제공하지 않으므로 회사의 필요에 맞지 않습니다.",
            "API Gateway 콘솔을 사용하여 수동으로 캐시를 지우는 것은 매번 업데이트 시 수동 개입이 필요하므로 확장 가능한 솔루션이 아니며, Cache-Control 헤더를 최대 0초로 설정하는 것은 사용자가 프로그래밍적으로 캐시를 무효화할 수 있는 권한을 자동으로 부여하지 않습니다."
        ]
    },
    {
        "Question Number": "4",
        "Situation": "VPC 내에 배포된 Lambda 함수가 인터넷에 위치한 외부 API에 연결해야 합니다. 이 Lambda 함수는 현재 프라이빗 서브넷과 연결되어 있어 인터넷에 직접 접근할 수 없습니다.",
        "Question": "Lambda 함수가 외부 API에 효과적으로 접근할 수 있도록 하려면 어떤 구성이 필요합니까?",
        "Options": {
            "1": "AWSLambdaBasicExecutionRole 정책을 Lambda 함수의 실행 역할에 연결하여 로깅 및 실행에 필요한 기본 권한을 보장합니다.",
            "2": "Lambda 함수에 Elastic IP를 추가하여 외부 통신을 위한 정적 공인 IP 주소를 부여합니다.",
            "3": "프라이빗 서브넷을 NAT Gateway를 통해 아웃바운드 트래픽을 라우팅하도록 구성하여 프라이빗 서브넷에서 인터넷 접근을 용이하게 합니다.",
            "4": "AWSLambdaVPCAccessExecutionRole을 사용하여 VPC 보안 기준을 준수하면서 아웃바운드 인터넷 접근을 허용합니다."
        },
        "Correct Answer": "프라이빗 서브넷을 NAT Gateway를 통해 아웃바운드 트래픽을 라우팅하도록 구성하여 프라이빗 서브넷에서 인터넷 접근을 용이하게 합니다.",
        "Explanation": "정답은 프라이빗 서브넷을 NAT Gateway를 통해 아웃바운드 트래픽을 라우팅하도록 구성하는 것입니다. 이 설정은 Lambda 함수와 같은 프라이빗 서브넷의 리소스가 안전하게 인터넷에 접근할 수 있도록 하며, 직접 노출되지 않습니다. NAT Gateway는 아웃바운드 트래픽을 위해 프라이빗 IP 주소를 공인 IP 주소로 변환하여 외부 API에 접근할 수 있게 합니다.",
        "Other Options": [
            "AWSLambdaBasicExecutionRole 정책을 연결하는 것은 프라이빗 서브넷에서 인터넷 접근을 가능하게 하는 데 충분하지 않습니다. 이 정책은 주로 로깅 및 실행 권한을 허용하지만 네트워킹 기능을 제공하지 않습니다.",
            "Lambda 함수에 Elastic IP를 추가하는 것은 적용할 수 없습니다. 프라이빗 서브넷의 Lambda 함수는 공인 IP를 직접 사용할 수 없으며, 아웃바운드 인터넷 접근을 위해 NAT Gateway에 의존합니다.",
            "AWSLambdaVPCAccessExecutionRole만 사용하는 것은 아웃바운드 인터넷 접근을 위한 필요한 라우팅을 구성하지 않습니다. 권한을 제공하지만 프라이빗 서브넷의 NAT Gateway 라우팅을 설정하지 않습니다."
        ]
    },
    {
        "Question Number": "5",
        "Situation": "Amazon DynamoDB를 백엔드 데이터베이스로 사용하는 확장 가능한 애플리케이션을 개발하고 있습니다. 애플리케이션은 높은 동시 읽기 및 쓰기 요청을 예상하며, 비용을 관리하면서 효율적인 성능을 보장해야 합니다.",
        "Question": "애플리케이션의 백엔드로 Amazon DynamoDB를 사용하고 있으며, 성능에 영향을 주지 않으면서 대량의 읽기 및 쓰기 작업을 지원하는 솔루션을 구현해야 합니다. 다음 옵션 중 어떤 것이 읽기 작업의 성능을 최적화하고 비용을 최소화하는 데 도움이 될까요?",
        "Options": {
            "1": "DynamoDB Streams를 활용하여 데이터를 보조 테이블로 복제하여 해당 테이블에서 읽기 작업을 수행합니다.",
            "2": "자주 쿼리되는 속성에 대해 Global Secondary Indexes (GSI)를 구현하여 읽기 성능을 향상시키고 더 효율적인 쿼리를 가능하게 합니다.",
            "3": "DynamoDB 테이블의 프로비저닝된 처리량을 증가시켜 다양한 트래픽 부하를 수용하도록 수동으로 관리합니다.",
            "4": "Amazon ElastiCache를 활용하여 DynamoDB 쿼리 결과를 캐시하여 더 빠른 접근을 제공하고 기본 데이터베이스의 부하를 줄입니다."
        },
        "Correct Answer": "자주 쿼리되는 속성에 대해 Global Secondary Indexes (GSI)를 구현하여 읽기 성능을 향상시키고 더 효율적인 쿼리를 가능하게 합니다.",
        "Explanation": "Global Secondary Indexes (GSI)를 구현하면 키가 아닌 속성에 대해 효율적인 쿼리가 가능해져 읽기 성능이 향상되며, 메인 테이블의 부하를 증가시키지 않습니다. 이 최적화는 더 목표 지향적인 쿼리를 가능하게 하여 읽기 용량 단위와 관련된 비용을 상당히 줄일 수 있습니다.",
        "Other Options": [
            "DynamoDB Streams를 사용하여 데이터를 보조 테이블로 복제하는 것은 특정 사용 사례에 이점을 제공할 수 있지만, 주로 데이터 처리에 초점을 맞추고 있어 읽기 성능을 직접 최적화하거나 빈번한 읽기 작업의 비용을 줄이지 않습니다.",
            "프로비저닝된 처리량을 증가시키면 더 높은 트래픽 부하를 처리할 수 있지만, 비용이 증가할 수 있으며, 적절히 관리하지 않으면 읽기 작업의 쿼리 성능이나 효율성을 본질적으로 개선하지 않습니다.",
            "Amazon ElastiCache를 사용하여 쿼리 결과를 캐시하면 성능을 향상시킬 수 있지만, 캐시 무효화 관리의 복잡성을 초래할 수 있습니다. 또한, 이 옵션은 신중하게 구현하지 않으면 DynamoDB와 관련된 읽기 비용을 직접 최소화하지 않을 수 있습니다."
        ]
    },
    {
        "Question Number": "6",
        "Situation": "개발자는 Amazon EC2 인스턴스를 관리하는 임무를 맡고 있으며, 메모리 및 디스크 공간 사용량을 면밀히 모니터링해야 합니다. 그러나 AWS에서 제공하는 표준 모니터링 도구는 기본적으로 이러한 특정 메트릭을 캡처하지 않습니다. 인스턴스가 효율적으로 실행되고 리소스가 적절히 할당되도록 하기 위해 개발자는 이러한 사용자 정의 메트릭에 대한 모니터링을 효과적으로 활성화할 방법을 찾아야 합니다.",
        "Question": "개발자가 EC2 인스턴스에서 메모리 및 디스크 공간 사용량과 같은 특정 사용자 정의 메트릭에 대한 포괄적인 모니터링을 활성화하기 위해 어떤 단계를 밟아야 합니까?",
        "Options": {
            "1": "EC2 인스턴스에 대한 상세 모니터링을 활성화하여 데이터 수집을 향상시키지만 메모리 및 디스크 메트릭은 포함되지 않습니다.",
            "2": "EC2 인스턴스에 CloudWatch 에이전트를 설치하고 구성하여 메모리 및 디스크 공간 사용량 메트릭을 CloudWatch에 수집하고 전송합니다.",
            "3": "AWS CLI를 사용하여 메트릭을 검색하지만, 이 방법은 기존 메트릭만 가져오며 메모리 및 디스크 공간에 대한 새로운 메트릭을 활성화하지 않습니다.",
            "4": "CloudWatch에 사용자 정의 네임스페이스를 생성하여 메트릭을 수동으로 업로드할 수 있으며, 이는 더 복잡하고 시간이 소요되는 솔루션입니다."
        },
        "Correct Answer": "EC2 인스턴스에 CloudWatch 에이전트를 설치하고 구성하여 메모리 및 디스크 공간 사용량 메트릭을 CloudWatch에 수집하고 전송합니다.",
        "Explanation": "정답은 EC2 인스턴스에 CloudWatch 에이전트를 설치하고 구성하는 것입니다. 이 에이전트는 기본적으로 캡처되지 않는 추가 메트릭, 즉 메모리 및 디스크 공간 사용량을 수집하고 해당 데이터를 CloudWatch에 전송하여 모니터링 및 분석을 가능하게 합니다.",
        "Other Options": [
            "EC2 인스턴스에 대한 상세 모니터링을 활성화하면 모니터링 빈도가 향상되지만 메모리 및 디스크 공간에 대한 메트릭을 제공하지 않아 개발자의 요구에 충분하지 않습니다.",
            "AWS CLI를 사용하여 메트릭을 검색하는 것은 이미 수집된 데이터에만 접근할 수 있으며, 메모리 및 디스크 공간에 대한 새로운 사용자 정의 메트릭을 활성화할 수 없으므로 요구 사항을 충족하지 못합니다.",
            "CloudWatch에 사용자 정의 네임스페이스를 생성하고 메트릭을 수동으로 업로드하는 것은 옵션이지만, 더 복잡한 프로세스를 포함하며 CloudWatch 에이전트처럼 실시간 모니터링을 제공하지 않으므로 효율성이 떨어집니다."
        ]
    },
    {
        "Question Number": "7",
        "Situation": "개발자가 AWS Lambda 함수의 성능을 향상시키기 위해 콜드 스타트 문제를 해결하고자 합니다. 콜드 스타트는 함수가 일정 시간 동안 유휴 상태일 때 호출될 경우 실행 지연을 초래할 수 있습니다. 이러한 지연을 최소화하는 것이 중요하다는 것을 인식한 개발자는 함수의 시작 시간을 최적화하기 위한 효과적인 전략을 찾고 있습니다.",
        "Question": "개발자가 AWS Lambda 함수의 콜드 스타트 시간을 효과적으로 최소화하기 위해 따라야 할 모범 사례는 무엇인가요?",
        "Options": {
            "1": "재귀 코드를 사용하여 실행 복잡성을 줄입니다.",
            "2": "모든 가능한 종속성을 포함하도록 배포 패키지의 크기를 늘립니다.",
            "3": "필요한 런타임 종속성만 포함하도록 배포 패키지 크기를 최소화합니다.",
            "4": "모든 종속성을 핸들러 함수에 직접 포함합니다."
        },
        "Correct Answer": "필요한 런타임 종속성만 포함하도록 배포 패키지 크기를 최소화합니다.",
        "Explanation": "배포 패키지 크기를 최소화하면 콜드 스타트 시 함수의 코드와 종속성을 로드하는 데 소요되는 시간을 줄일 수 있습니다. 더 작은 패키지는 필수 구성 요소만 포함하여 AWS Lambda가 함수를 더 빠르게 초기화할 수 있게 하여 궁극적으로 성능을 향상시킵니다.",
        "Other Options": [
            "재귀 코드를 사용하는 것은 콜드 스타트 시간에 직접적인 영향을 미치지 않으며, 재귀는 메모리 사용량 증가와 실행 시간을 늘릴 수 있어 오히려 실행을 복잡하게 만들 수 있습니다.",
            "모든 가능한 종속성을 포함하여 배포 패키지의 크기를 늘리면 더 큰 패키지가 메모리에 로드되는 데 더 많은 시간이 걸리므로 콜드 스타트 시간이 길어질 가능성이 높습니다.",
            "모든 종속성을 핸들러 함수에 직접 포함하면 코드베이스가 복잡해지고 복잡성이 증가할 수 있지만, 이는 패키지 크기와 관련된 콜드 스타트 문제를 효과적으로 해결하지 못합니다."
        ]
    },
    {
        "Question Number": "8",
        "Situation": "개발자가 다양한 AWS 서비스를 통합한 복잡한 서버리스 애플리케이션의 문제를 해결하고 있습니다. 이 애플리케이션은 사용자 상호작용에 매우 중요하며, 개발자는 지연이 발생하는 위치를 파악하여 성능을 향상시키고자 합니다. 이를 위해 개발자는 사용자 요청을 효과적으로 추적하고, 잠재적인 병목 현상을 식별하며, 애플리케이션이 사용하는 다양한 서비스의 지연 시간을 모니터링해야 합니다.",
        "Question": "사용자 요청을 추적하고 서버리스 애플리케이션의 성능을 분석하기 위해 개발자가 애플리케이션의 성능과 사용자 상호작용에 대한 통찰력을 얻기 위해 활용해야 할 AWS 서비스는 무엇인가요?",
        "Options": {
            "1": "Amazon CloudWatch",
            "2": "AWS X-Ray",
            "3": "AWS CloudTrail",
            "4": "Amazon DynamoDB Accelerator (DAX)"
        },
        "Correct Answer": "AWS X-Ray",
        "Explanation": "AWS X-Ray는 다양한 AWS 서비스를 통해 요청을 추적하도록 설계되어 있어 개발자가 서비스 맵을 시각화하고 지연이 발생할 수 있는 위치를 이해할 수 있게 합니다. 애플리케이션의 성능에 대한 자세한 통찰력을 제공하여 서버리스 아키텍처의 병목 현상을 해결하는 데 이상적인 선택입니다.",
        "Other Options": [
            "Amazon CloudWatch는 주로 모니터링 및 로그 메트릭에 중점을 두고 있으며, 서비스 간 요청 추적에 특화되어 있지 않아 이 특정 문제 해결 시나리오에 덜 적합합니다.",
            "AWS CloudTrail은 AWS 리소스에 대한 작업과 관련된 계정 활동을 기록하고 모니터링하는 데 중점을 두고 있으며, 애플리케이션의 성능이나 서비스 간 사용자 요청을 추적하는 데는 적합하지 않습니다.",
            "Amazon DynamoDB Accelerator (DAX)는 DynamoDB 쿼리의 성능을 개선하기 위해 설계된 캐싱 서비스로, 여러 AWS 서비스 간의 애플리케이션 성능에 대한 추적 기능이나 통찰력을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "9",
        "Situation": "한 회사가 Amazon RDS 데이터베이스와의 안전한 통신을 위해 개인 Amazon VPC 내에 AWS Lambda 함수를 배포했습니다. 이 Lambda 함수는 또한 인터넷에서 사용할 수 있는 다양한 외부 API에 접근해야 합니다. 개발 팀은 Lambda 함수가 개인 RDS 데이터베이스와 인터넷에 안전하게 연결될 수 있도록 하면서 VPC가 공용 액세스에 직접 노출되지 않도록 해야 합니다. 이 상황은 네트워크 구성 및 보안 모범 사례에 대한 신중한 고려가 필요합니다.",
        "Question": "개인 VPC의 무결성을 손상시키지 않으면서 이러한 보안 및 연결 요구 사항을 충족하기 위해 AWS Lambda 함수를 구성하는 가장 효과적인 방법은 무엇인가요?",
        "Options": {
            "1": "Lambda 함수에 Elastic IP를 연결합니다.",
            "2": "Lambda 함수를 인터넷 게이트웨이가 있는 공용 서브넷에 배치합니다.",
            "3": "Lambda 함수를 개인 서브넷에서 사용하도록 구성하고 NAT 게이트웨이를 설정합니다.",
            "4": "Lambda 함수의 VPC와 인터넷 게이트웨이 간에 VPC 피어링을 활성화합니다."
        },
        "Correct Answer": "Lambda 함수를 개인 서브넷에서 사용하도록 구성하고 NAT 게이트웨이를 설정합니다.",
        "Explanation": "Lambda 함수를 개인 서브넷에서 사용하고 NAT 게이트웨이를 설정하면 외부 API 호출을 위해 인터넷에 안전하게 접근하면서 RDS 데이터베이스에 대한 개인 연결을 유지할 수 있습니다. NAT 게이트웨이는 개인 서브넷에서의 아웃바운드 인터넷 트래픽을 가능하게 하여 VPC를 공용 액세스에 노출하지 않으므로 회사의 보안 및 연결 요구 사항을 충족합니다.",
        "Other Options": [
            "Lambda 함수에 Elastic IP를 연결하는 것은 불가능합니다. AWS Lambda 함수는 Elastic IP와 직접 연결을 지원하지 않으며, Elastic IP는 EC2 인스턴스에 할당할 수 있지만 Lambda 함수는 인터넷 접근을 위한 다른 접근 방식이 필요합니다.",
            "Lambda 함수를 인터넷 게이트웨이가 있는 공용 서브넷에 배치하면 함수가 공용 인터넷에 노출되어 VPC를 공용 액세스로부터 안전하게 유지해야 한다는 요구 사항에 위배됩니다.",
            "Lambda 함수의 VPC와 인터넷 게이트웨이 간에 VPC 피어링을 활성화하는 것은 인터넷 접근을 제공하지 않기 때문에 실행 가능한 솔루션이 아닙니다. 피어링은 두 VPC 간의 통신에 사용되며, 인터넷에 연결하는 데는 사용되지 않습니다."
        ]
    },
    {
        "Question Number": "10",
        "Situation": "개발자가 실시간으로 스트리밍 데이터를 처리하여 시의적절한 통찰력과 분석을 제공하는 애플리케이션을 작업하고 있습니다. 이 애플리케이션은 정보를 관련성 있고 실행 가능하게 유지하기 위해 최소한의 지연 시간으로 데이터를 효율적으로 수집, 처리 및 저장해야 합니다. 또한, 처리된 데이터는 AWS Lambda 함수에 의해 추가 처리 및 다양한 워크플로우를 트리거하는 데 사용됩니다.",
        "Question": "개발자가 스트리밍 데이터를 효과적으로 수집하면서 낮은 지연 시간과 높은 처리량을 보장하기 위해 어떤 AWS 서비스를 사용해야 합니까?",
        "Options": {
            "1": "Amazon S3",
            "2": "Amazon Kinesis Data Streams",
            "3": "Amazon SQS",
            "4": "Amazon SNS"
        },
        "Correct Answer": "Amazon Kinesis Data Streams",
        "Explanation": "Amazon Kinesis Data Streams는 실시간 데이터 수집, 처리 및 분석을 위해 특별히 설계되었습니다. 개발자는 대량의 데이터 레코드를 실시간으로 수집하고 처리할 수 있어, 상황에서 설명된 것처럼 낮은 지연 시간과 높은 처리량이 필요한 애플리케이션에 적합합니다. 이 서비스는 추가 처리를 위해 AWS Lambda와의 원활한 통합을 가능하게 합니다.",
        "Other Options": [
            "Amazon S3는 주로 대량의 데이터를 확장 가능한 방식으로 저장하고 검색하는 데 사용되지만, 실시간 데이터 수집 및 처리에 최적화되어 있지 않습니다. 이는 더 높은 지연 시간을 초래하여 즉각적인 데이터 가용성이 필요한 애플리케이션에는 적합하지 않습니다.",
            "Amazon SQS (Simple Queue Service)는 마이크로서비스의 분리 및 확장을 허용하는 메시지 큐잉 서비스이지만, 실시간 데이터 스트리밍을 위해 설계되지 않았습니다. 이는 지속적인 데이터 수집보다는 메시지 전달에 더 중점을 둡니다.",
            "Amazon SNS (Simple Notification Service)는 구독자에게 알림과 메시지를 전송하는 데 사용되지만, 실시간으로 스트리밍 데이터를 수집하거나 처리하는 기능을 제공하지 않습니다. 이는 실시간 데이터 워크플로우보다는 이벤트 기반 아키텍처에 더 적합합니다."
        ]
    },
    {
        "Question Number": "11",
        "Situation": "한 팀이 AWS에 호스팅된 중요한 애플리케이션의 모니터링 기능을 개선하는 임무를 맡았습니다. 그들은 Amazon CloudWatch에서 수집된 메트릭의 기본 세분성을 5분에서 1분으로 줄여 보다 시의적절한 통찰력을 얻고자 합니다.",
        "Question": "팀이 이 개선된 모니터링 해상도를 달성하기 위해 어떤 조치를 취해야 합니까?",
        "Options": {
            "1": "PutMetricData를 사용하여 CloudWatch에 1분 간격으로 사용자 정의 메트릭을 전송하여 더 자주 업데이트되도록 합니다.",
            "2": "모니터링되는 관련 서비스에 대해 고해상도 메트릭을 활성화하여 데이터 수집의 세부 사항을 더 세밀하게 합니다.",
            "3": "AWS 리소스에 대해 상세 모니터링을 활성화하여 향상된 가시성을 위해 일반적으로 1분 간격으로 메트릭을 제공합니다.",
            "4": "1분의 평가 기간으로 구성된 CloudWatch 경고를 설정하여 특정 메트릭 임계값에서 알림을 트리거합니다."
        },
        "Correct Answer": "PutMetricData를 사용하여 CloudWatch에 1분 간격으로 사용자 정의 메트릭을 전송하여 더 자주 업데이트되도록 합니다.",
        "Explanation": "PutMetricData를 사용하면 팀이 1분 간격으로 사용자 정의 메트릭을 전송할 수 있어, 중요한 애플리케이션을 면밀히 모니터링하는 데 필요한 세분성을 효과적으로 제공합니다. 이 방법은 1분 메트릭의 특정 요구 사항을 달성하는 가장 직접적인 접근 방식입니다.",
        "Other Options": [
            "고해상도 메트릭을 활성화하면 더 자세한 데이터를 제공하지만 모든 서비스에 적용되지 않습니다. 또한, 고해상도로 특별히 구성되지 않는 한 메트릭이 1분 간격으로 수집된다는 보장을 하지 않습니다.",
            "상세 모니터링을 활성화하면 일반적으로 1분 세분성을 허용하지만, 그 간격으로 사용자 정의 메트릭을 전송하는 것과는 다릅니다. 모든 리소스에 적용되지 않을 수 있으므로 팀의 중요한 애플리케이션에 대한 필요를 충족하지 못할 수 있습니다.",
            "1분의 평가 기간으로 CloudWatch 경고를 생성하는 것은 메트릭 수집의 세분성을 변경하기보다는 알림에 중점을 둡니다. 이는 응답 시간을 개선하는 데 도움이 될 수 있지만, 메트릭이 기록되는 빈도를 변경하지는 않습니다."
        ]
    },
    {
        "Question Number": "12",
        "Situation": "한 회사는 TEST AWS 계정의 개발자들이 PROD 계정의 Amazon S3 버킷에 일시적으로 접근할 수 있도록 하기를 원합니다. 개발자들은 버킷에 대한 읽기 전용 접근만 필요합니다.",
        "Question": "이 요구 사항을 충족하는 솔루션은 무엇입니까?",
        "Options": {
            "1": "PROD 계정에 IAM 사용자를 생성하고 접근 키를 개발자와 공유합니다.",
            "2": "TEST 계정에 대한 신뢰 관계를 가진 PROD 계정에 크로스 계정 IAM 역할을 생성하고 S3 버킷에 대한 읽기 전용 접근을 부여하는 정책을 첨부합니다.",
            "3": "TEST 계정에 대해 SAML 인증을 활성화하고 개발자를 PROD 계정에 매핑합니다.",
            "4": "TEST 계정의 개발자 IAM 사용자를 PROD 계정의 사용자 그룹에 추가하고 필요한 권한을 부여합니다."
        },
        "Correct Answer": "TEST 계정에 대한 신뢰 관계를 가진 PROD 계정에 크로스 계정 IAM 역할을 생성하고 S3 버킷에 대한 읽기 전용 접근을 부여하는 정책을 첨부합니다.",
        "Explanation": "크로스 계정 IAM 역할을 생성하면 개발자가 영구적인 접근 없이 역할을 일시적으로 맡을 수 있습니다. 이 방법은 보안성이 높고, 현재 작업에 필요한 권한만 제공하여 모범 사례를 따릅니다. 이 경우는 S3 버킷에 대한 읽기 전용 접근입니다.",
        "Other Options": [
            "PROD 계정에 IAM 사용자를 생성하고 접근 키를 공유하는 것은 보안 위험과 관리 오버헤드를 초래할 수 있으므로 권장되지 않는 접근 방식입니다. 또한 요구 사항에서 명시한 대로 일시적인 접근을 허용하지 않습니다.",
            "SAML 인증을 활성화하는 것은 연합 접근을 위한 유효한 접근 방식이지만, 이 시나리오에서는 더 간단한 크로스 계정 IAM 역할이 일시적인 읽기 접근을 위해 충분합니다.",
            "개발자의 IAM 사용자를 PROD 계정의 사용자 그룹에 추가하는 것은 추가 권한을 생성하고 관리해야 하므로 일시적인 접근에 적합하지 않습니다. 또한 S3 버킷에 대한 접근을 엄격하게 제한하는 간소화되고 안전한 방법을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "13",
        "Situation": "개발자가 AWS에 호스팅된 애플리케이션의 성능 저하 문제를 해결하고 있습니다. 이 애플리케이션은 Amazon EC2, Lambda 및 Amazon RDS를 포함한 여러 AWS 서비스를 사용하고 있습니다. 개발자는 CloudWatch 로그, X-Ray 추적 및 여러 서비스의 성능 메트릭에 접근할 수 있지만, 문제의 원인이 어디에 있는지 확신하지 못하고 있습니다.",
        "Question": "개발자가 성능 문제의 근본 원인을 효율적으로 식별하기 위해 어떤 접근 방식을 취해야 합니까?",
        "Options": {
            "1": "CloudWatch Logs Insights를 활용하여 로그에서 이상 징후를 쿼리한 다음, AWS X-Ray를 사용하여 애플리케이션 흐름을 추적하고 병목 현상을 식별합니다.",
            "2": "EC2 인스턴스 성능 메트릭을 검토하고 인스턴스 크기를 업그레이드하여 잠재적인 리소스 제한을 제거합니다.",
            "3": "AWS CloudTrail 로그를 분석하여 모든 API 호출을 검토하고 이를 애플리케이션의 성능 문제와 연관시켜 통찰력을 얻습니다.",
            "4": "Amazon RDS 성능 대시보드에 접근하여 느린 데이터베이스 쿼리를 조사하고 메트릭을 기반으로 최적화를 구현합니다."
        },
        "Correct Answer": "CloudWatch Logs Insights를 활용하여 로그에서 이상 징후를 쿼리한 다음, AWS X-Ray를 사용하여 애플리케이션 흐름을 추적하고 병목 현상을 식별합니다.",
        "Explanation": "이 접근 방식은 개발자가 로그에서 특정 문제를 나타낼 수 있는 이상 징후를 먼저 식별할 수 있게 해줍니다. 잠재적인 문제 영역이 식별되면, AWS X-Ray는 요청이 애플리케이션을 통해 흐르는 방식을 자세히 통찰할 수 있게 해주며, 병목 현상이나 느린 구성 요소를 강조하여 여러 AWS 서비스에서 성능 저하의 근본 원인을 파악하는 데 중요합니다.",
        "Other Options": [
            "EC2 인스턴스 성능 메트릭을 검토하고 인스턴스 크기를 증가시키는 것이 특정 경우에 도움이 될 수 있지만, 이는 성능 문제의 근본 원인을 직접적으로 해결하지 않으며, 특히 애플리케이션이 여러 서비스를 사용하고 문제가 다른 곳에 있을 수 있습니다.",
            "AWS CloudTrail 로그를 분석하면 API 호출에 대한 유용한 정보를 제공할 수 있지만, 성능 문제를 위해 특별히 설계된 것은 아니며 애플리케이션 성능 저하와 직접적으로 연관되지 않을 수 있습니다.",
            "Amazon RDS 성능 대시보드에 접근하여 느린 데이터베이스 쿼리를 확인하는 것은 좋은 관행이지만, 이는 데이터베이스 계층에만 집중합니다. 성능 저하에 기여할 수 있는 애플리케이션의 다른 구성 요소에서 발생하는 문제를 놓칠 수 있습니다."
        ]
    },
    {
        "Question Number": "14",
        "Situation": "한 회사가 AWS 서비스를 사용하여 애플리케이션의 빌드, 테스트 및 배포를 자동화하는 CI/CD 파이프라인을 설계하고 있습니다. 그들은 소스 코드 관리, 지속적인 통합 및 지속적인 배포를 단일 워크플로우 내에서 통합하는 것을 목표로 하고 있습니다.",
        "Question": "회사가 이 CI/CD 워크플로우를 효과적으로 구현하기 위해 어떤 AWS 서비스 조합을 사용해야 합니까?",
        "Options": {
            "1": "AWS CodeCommit, AWS CodeBuild, AWS CodeDeploy, AWS CodePipeline",
            "2": "Amazon S3, AWS Lambda, Amazon API Gateway, AWS CodePipeline",
            "3": "AWS CodeStar, AWS CodeArtifact, AWS CodeBuild, Amazon EC2",
            "4": "AWS CodeDeploy, AWS CodePipeline, AWS Elastic Beanstalk, Amazon RDS"
        },
        "Correct Answer": "AWS CodeCommit, AWS CodeBuild, AWS CodeDeploy, AWS CodePipeline",
        "Explanation": "이 서비스 조합은 전체 CI/CD 워크플로우를 지원하도록 특별히 설계되었습니다. AWS CodeCommit은 소스 코드 관리를 위해 사용되고, CodeBuild는 자동화된 빌드 및 테스트를 위해, CodeDeploy는 배포를 위해, CodePipeline은 전체 프로세스를 조정하여 회사의 요구에 효과적인 솔루션이 됩니다.",
        "Other Options": [
            "이 옵션은 CI/CD에 주로 집중하지 않은 서비스를 조합합니다. Amazon S3는 저장을 위해, AWS Lambda는 서버리스 컴퓨팅을 위해, Amazon API Gateway는 API 구축을 위해 사용되며, 이는 CI/CD 파이프라인에 직접적으로 기여하지 않습니다.",
            "이 옵션은 지속적인 통합에 유용한 AWS CodeBuild를 포함하고 있지만, 전용 소스 코드 관리 및 배포 서비스가 부족합니다. AWS CodeStar와 AWS CodeArtifact는 다른 목적을 가지고 있으며 CI/CD 주기를 포괄적으로 다루지 않습니다.",
            "AWS CodeDeploy와 AWS CodePipeline을 포함하고 있지만, 이 옵션은 AWS CodeCommit과 같은 소스 코드 관리 서비스를 부족하게 하고, AWS Elastic Beanstalk에 의존하여 포괄적인 워크플로우를 위한 전용 CI/CD 서비스만큼 사용자 정의가 용이하지 않습니다."
        ]
    },
    {
        "Question Number": "15",
        "Situation": "개발자가 데이터베이스에 접근해야 하는 웹 애플리케이션을 AWS Lambda에 배포하고 있습니다. 이를 위해 애플리케이션은 환경 변수를 사용하여 데이터베이스 연결 문자열을 안전하게 저장하고 있으며, 여기에는 사용자 이름과 비밀번호와 같은 민감한 정보가 포함되어 있습니다. 그러나 개발자는 평문으로 민감한 데이터를 저장하는 것과 관련된 잠재적인 보안 위험에 대해 우려하고 있으며, 이러한 환경 변수를 강화하고 무단 접근으로부터 보호하기 위한 효과적인 방법을 찾고 있습니다.",
        "Question": "개발자가 데이터베이스 연결 문자열과 같은 민감한 데이터를 포함하는 환경 변수가 배포 중에 적절하게 암호화되고 안전하게 보호되도록 하기 위해 어떤 구체적인 조치를 취해야 합니까?",
        "Options": {
            "1": "환경 변수 대신 애플리케이션 코드에 연결 문자열을 저장합니다.",
            "2": "AWS Key Management Service (AWS KMS)를 사용하여 환경 변수를 암호화합니다.",
            "3": "제한된 접근 권한을 가진 Amazon S3 버킷에 연결 문자열을 저장합니다.",
            "4": "AWS Systems Manager Parameter Store를 사용하여 암호화된 연결 문자열을 저장하고 이를 환경 변수에서 참조합니다."
        },
        "Correct Answer": "AWS Systems Manager Parameter Store를 사용하여 암호화된 연결 문자열을 저장하고 이를 환경 변수에서 참조합니다.",
        "Explanation": "AWS Systems Manager Parameter Store를 암호화와 함께 사용하면 개발자가 데이터베이스 연결 문자열과 같은 민감한 정보를 안전하게 저장할 수 있습니다. 이 방법은 내장된 암호화 기능을 제공하여 데이터가 저장 중 및 전송 중에 보호되도록 보장합니다. 또한, 애플리케이션 코드와 환경 변수 자체에서 민감한 정보를 제외하면서 런타임에 암호화된 데이터를 쉽게 검색할 수 있게 하여 전반적인 보안을 강화합니다.",
        "Other Options": [
            "애플리케이션 코드에 연결 문자열을 저장하는 것은 권장되지 않으며, 이는 소스 코드 내에서 민감한 정보를 직접 노출시켜 무단 접근 및 잠재적인 유출에 취약하게 만듭니다.",
            "AWS Key Management Service (AWS KMS)를 사용하여 환경 변수를 암호화하는 것은 유효한 접근 방식이지만, 비밀 관리에 대한 추가 관리가 필요하며 이 특정 사용 사례에 대해 Parameter Store를 사용하는 것만큼의 통합 및 단순성을 제공하지 않을 수 있습니다.",
            "제한된 접근 권한을 가진 Amazon S3 버킷에 연결 문자열을 저장하는 것은 데이터베이스 자격 증명과 같은 민감한 데이터에 이상적이지 않으며, 이는 우발적인 노출 위험을 초래하고 AWS Systems Manager Parameter Store와 같은 수준의 암호화 및 접근 관리 기능을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "16",
        "Situation": "한 회사가 웹 애플리케이션의 배포 프로세스를 효과적으로 자동화하기 위해 AWS CodePipeline을 설정했습니다. 그러나 프로덕션 환경에 변경 사항을 배포하기 전에, 그들은 수동 승인 단계를 포함하는 것이 중요하다는 것을 인식합니다. 이 단계는 승인된 인원만이 배포에 대한 동의를 제공할 수 있도록 하여 품질 관리와 보안을 유지하는 데 필수적입니다.",
        "Question": "회사가 AWS CodePipeline에 이 수동 승인 요구 사항을 성공적으로 구현하고 배포가 적절하게 승인되도록 하기 위해 어떤 특정 기능을 통합해야 합니까?",
        "Options": {
            "1": "배포 프로세스에서 기준이 충족되었는지 확인하기 위해 유효성 검사 체크를 수행하는 AWS Lambda 작업을 추가합니다.",
            "2": "AWS CodePipeline의 기본 승인 작업 유형을 활용하여 수동 승인 작업을 삽입하여 지정된 인원이 배포를 승인하거나 거부할 수 있도록 합니다.",
            "3": "AWS CodeBuild를 사용하여 승인 프로세스를 수행하고, 배포 전에 빌드를 검증할 수 있도록 합니다.",
            "4": "SNS 알림 시스템을 구현하여 이해관계자에게 배포에 대해 알리고 진행하기 전에 피드백을 수집합니다."
        },
        "Correct Answer": "AWS CodePipeline의 기본 승인 작업 유형을 활용하여 수동 승인 작업을 삽입하여 지정된 인원이 배포를 승인하거나 거부할 수 있도록 합니다.",
        "Explanation": "정답은 AWS CodePipeline의 승인 작업 유형을 사용하여 수동 승인 작업을 삽입하는 것입니다. 이 기능은 배포 프로세스에 수동 승인 단계를 추가하도록 특별히 설계되어 있으며, 승인된 인원이 변경 사항을 검토하고 승인할 수 있도록 합니다. 이는 배포가 승인되었음을 보장하고 프로덕션 환경의 무결성을 유지하는 데 도움이 됩니다.",
        "Other Options": [
            "유효성 검사를 위한 AWS Lambda 작업 추가는 수동 승인을 위한 직접적인 해결책이 아닙니다. Lambda는 다양한 작업을 자동화할 수 있지만, 수동 승인을 위한 메커니즘을 제공하지 않으며, 이는 명시된 요구 사항에 필수적입니다.",
            "AWS CodeBuild를 사용하여 승인 프로세스를 수행하는 것은 잘못된 것입니다. CodeBuild는 주로 코드 빌드 및 테스트에 중점을 두고 있으며, 수동 승인을 위한 내장 기능이 없어 이 특정 요구에 적합하지 않습니다.",
            "SNS 알림 시스템을 구현하는 것은 이해관계자에게 배포에 대해 알리는 데 도움이 될 수 있지만, 실제 승인 프로세스를 촉진하지는 않습니다. 알림만으로는 배포 전에 승인된 당사자가 동의를 제공하는 것을 보장하지 않습니다."
        ]
    },
    {
        "Question Number": "17",
        "Situation": "전 세계의 다양한 지역의 사용자들을 수용해야 하는 글로벌 애플리케이션을 위한 분산 시스템이 설계되고 있습니다. 팀은 기본 설계 원칙, 특히 데이터베이스 작업에서 강한 일관성의 중요성과 높은 가용성의 필요성을 저울질하고 있습니다. 네트워크 파티션과 잠재적인 실패의 복잡성을 탐색하면서, 그들은 결정 과정의 지침으로 CAP 정리를 참조합니다.",
        "Question": "CAP 정리는 글로벌 애플리케이션 설계 시 분산 시스템에 대해 일관성, 가용성 및 파티션 허용성 측면에서 무엇을 말합니까?",
        "Options": {
            "1": "일관성, 가용성 및 파티션 허용성을 모두 달성할 수 있습니다.",
            "2": "파티션 허용성이 있는 경우 일관성 또는 가용성 중에서 선택해야 합니다.",
            "3": "분산 시스템에서 파티션 허용성은 선택 사항입니다.",
            "4": "더 높은 성능을 위해 가용성을 희생할 수 있습니다."
        },
        "Correct Answer": "파티션 허용성이 있는 경우 일관성 또는 가용성 중에서 선택해야 합니다.",
        "Explanation": "CAP 정리는 Eric Brewer에 의해 제정되었으며, 분산 시스템에서 일관성, 가용성 및 파티션 허용성의 세 가지 속성을 동시에 보장하는 것은 불가능하다고 명시합니다. 네트워크 파티션이 발생하면 시스템은 일관성 또는 가용성 중 하나만 제공할 수 있으며, 이는 애플리케이션 팀이 특정 요구 사항과 시스템의 예상 동작에 따라 트레이드오프를 해야 함을 의미합니다.",
        "Other Options": [
            "이 옵션은 잘못된 것입니다. CAP 정리는 네트워크 파티션 중에 분산 시스템에서 세 가지 속성을 동시에 달성하는 것이 불가능하다고 명시합니다.",
            "이 옵션은 잘못된 것입니다. 파티션 허용성은 분산 시스템에서 기본 요구 사항이며, 네트워크 실패 중 시스템 신뢰성을 위험에 빠뜨리지 않고 선택 사항으로 간주될 수 없습니다.",
            "이 옵션은 잘못된 것입니다. CAP 정리는 성능 트레이드오프에 대해 다루지 않습니다. 이는 일관성, 가용성 및 파티션 허용성의 세 가지 속성에 대한 제한 사항에 중점을 둡니다."
        ]
    },
    {
        "Question Number": "18",
        "Situation": "개발 팀이 AWS에 새로운 웹 애플리케이션을 배포할 준비를 하고 있습니다. 이 애플리케이션은 데이터베이스 연결 문자열 및 기능 플래그를 포함한 다양한 구성 설정에 대한 접근이 필요합니다. 팀은 업데이트를 간소화하고 보안을 강화하기 위해 구성 관리를 중앙 집중화하고자 합니다.",
        "Question": "팀이 애플리케이션 구성 데이터를 안전하게 접근하기 위해 어떤 AWS 서비스를 사용해야 합니까?",
        "Options": {
            "1": "AWS AppConfig",
            "2": "Amazon S3",
            "3": "AWS Secrets Manager",
            "4": "Amazon RDS"
        },
        "Correct Answer": "AWS AppConfig",
        "Explanation": "AWS AppConfig는 애플리케이션 구성을 관리하기 위해 특별히 설계되었습니다. 팀이 애플리케이션 구성을 안전하고 효율적으로 생성, 관리 및 신속하게 배포할 수 있도록 합니다. 이 서비스는 애플리케이션이 구성 설정을 동적으로 검색할 수 있도록 하여 업데이트를 용이하게 하고 보안을 강화합니다.",
        "Other Options": [
            "Amazon S3는 주로 저장 서비스이며 구성 파일을 저장하는 데 사용할 수 있지만, 애플리케이션 구성을 안전하게 관리하고 배포하기 위한 전용 기능을 제공하지 않습니다.",
            "AWS Secrets Manager는 API 키 및 비밀번호와 같은 민감한 정보를 저장하고 관리하는 데 중점을 두고 있으며, 기능 플래그 및 연결 문자열과 같은 일반 애플리케이션 구성 데이터에는 적합하지 않습니다.",
            "Amazon RDS는 관리형 데이터베이스 서비스이며 구성 관리를 위한 것이 아닙니다. 이는 관계형 데이터베이스를 호스팅하는 데 사용되며 애플리케이션 설정을 관리하는 데 적합하지 않습니다."
        ]
    },
    {
        "Question Number": "19",
        "Situation": "개발자는 CloudWatch에서 PutMetricData API를 사용할 때 API 호출이 높은 비율로 발생하여 ThrottlingException 오류를 자주 겪고 있습니다. 이러한 오류는 개발자가 API 요청에 대한 허용 한도를 초과하고 있음을 나타내며, 이로 인해 메트릭을 기록하는 시도가 실패하게 됩니다. 이 상황은 개발 중인 애플리케이션의 전반적인 기능과 성능 모니터링에 지장을 줄 수 있습니다. 따라서 개발자는 향후 이러한 오류를 피하기 위해 API 호출 비율을 관리하고 최적화하는 효과적인 솔루션을 찾는 것이 중요합니다.",
        "Question": "개발자가 CloudWatch에서 PutMetricData API를 사용할 때 높은 API 호출 비율로 인해 ThrottlingException 오류를 효과적으로 해결하기 위해 어떤 조치를 취할 수 있습니까?",
        "Options": {
            "1": "CloudWatch에서 기본 API 호출 할당량을 늘린다.",
            "2": "지수 백오프와 지터를 사용하여 API 호출을 재시도한다.",
            "3": "API 호출을 시간에 걸쳐 고르게 분산시키고 여러 메트릭을 단일 API 호출로 결합한다.",
            "4": "AWS CLI를 사용하여 스로틀링 한계를 우회한다."
        },
        "Correct Answer": "지수 백오프와 지터를 사용하여 API 호출을 재시도한다.",
        "Explanation": "지수 백오프와 지터를 사용하여 API 호출을 재시도하는 것은 ThrottlingExceptions를 처리하기 위한 권장 전략입니다. 지수 백오프는 API 호출을 재시도하기 전에 점진적으로 더 긴 시간을 기다리는 것을 포함하여, API에 대한 부하를 줄이고 후속 시도에서 성공할 확률을 높입니다. 지터를 추가하면 대기 시간에 무작위성을 도입하여 추가 스로틀링을 초래할 수 있는 트래픽 급증을 피하는 데 도움이 됩니다.",
        "Other Options": [
            "CloudWatch에서 기본 API 호출 할당량을 늘리는 것은 ThrottlingExceptions에 대한 실행 가능한 솔루션이 아닙니다. AWS는 이러한 한계를 설정하는 이유가 있으며, 단순히 할당량을 늘리는 것이 문제를 관리하는 데 가능하거나 효과적이지 않을 수 있습니다.",
            "API 호출을 시간에 걸쳐 고르게 분산시키고 여러 메트릭을 단일 API 호출로 결합하는 것은 요청 수를 줄이는 데 도움이 될 수 있지만, 높은 부하 상황에서 스로틀링을 효과적으로 처리할 필요성을 해결하지는 않습니다.",
            "AWS CLI를 사용하여 스로틀링 한계를 우회하는 것은 정당한 솔루션이 아닙니다. 이는 AWS가 시행하는 기본 API 호출 한계를 변경하지 않으며, 이러한 한계를 우회하려고 하면 추가적인 복잡성과 AWS 서비스 계약 위반의 잠재적 위험이 발생할 수 있습니다."
        ]
    },
    {
        "Question Number": "20",
        "Situation": "AWS에 배포된 애플리케이션은 운영 중 다양한 HTTP 상태 코드를 반환합니다. 개발자는 사용자 경험과 전반적인 애플리케이션 신뢰성을 향상시키기 위해 특정 클라이언트 및 서버 오류 코드를 식별하고 적절하게 처리하는 임무를 맡고 있습니다. 이러한 상태 코드의 의미를 이해하는 것은 디버깅 및 사용자에게 의미 있는 피드백을 제공하는 데 중요합니다.",
        "Question": "HTTP 상태 코드의 맥락에서, 서버가 요청을 처리할 수 없게 만드는 잘못된 요청 구문으로 인해 발생하는 클라이언트 측 오류를 나타내는 특정 코드는 무엇입니까?",
        "Options": {
            "1": "서버로부터 성공적인 요청 및 응답을 나타내는 상태 코드 200.",
            "2": "리소스가 새 URL로 영구적으로 이동되었음을 나타내는 상태 코드 301.",
            "3": "클라이언트 측 구문 오류로 인해 잘못된 요청을 나타내는 상태 코드 400.",
            "4": "서버 측의 문제를 나타내는 내부 서버 오류 상태 코드 500."
        },
        "Correct Answer": "클라이언트 측 구문 오류로 인해 잘못된 요청을 나타내는 상태 코드 400.",
        "Explanation": "HTTP 상태 코드 400은 '잘못된 요청' 오류를 나타내며, 이는 서버가 잘못된 구문으로 인해 요청을 이해할 수 없을 때 발생합니다. 이는 클라이언트 측 오류로, 문제는 클라이언트가 보낸 요청에 있으며 서버 자체와는 관련이 없습니다. 이 오류를 인식하면 개발자는 사용자가 요청을 재전송하기 전에 입력을 수정하도록 유도할 수 있습니다.",
        "Other Options": [
            "상태 코드 200은 요청이 성공적이며 서버가 요청된 리소스를 반환했음을 나타냅니다. 이는 오류 코드가 아니므로 요청 구문 문제와는 관련이 없습니다.",
            "상태 코드 301은 요청된 리소스가 다른 URL로 영구적으로 이동되었음을 나타냅니다. 이는 클라이언트에게 요청을 업데이트하라는 정보를 제공하지만 구문 오류를 나타내지는 않습니다.",
            "상태 코드 500은 내부 서버 오류를 나타내며, 이는 서버가 요청을 이행하는 데 방해가 되는 예기치 않은 조건을 만났음을 시사합니다. 이는 서버 측 문제로, 클라이언트의 요청 구문과는 관련이 없습니다."
        ]
    },
    {
        "Question Number": "21",
        "Situation": "개발자는 AWS에 호스팅된 애플리케이션에 대한 강력한 접근 제어를 설정하는 임무를 맡고 있으며, 이는 보안 및 운영 무결성을 유지하는 데 중요합니다. 이 애플리케이션은 개발자, 테스터 및 관리자 역할에 맞춘 다양한 권한 수준을 필요로 하여 각 그룹이 민감한 데이터나 시스템 기능을 손상시키지 않고 효과적으로 작업을 수행할 수 있도록 합니다.",
        "Question": "개발자가 AWS 내에서 서로 다른 사용자 그룹에 이러한 다양한 권한 수준을 효과적으로 정의하고 할당하기 위해 어떤 IAM 기능을 활용해야 하며, 각 그룹이 보안 모범 사례를 준수하면서 지정된 기능을 수행할 수 있도록 해야 합니까?",
        "Options": {
            "1": "IAM 사용자",
            "2": "역할 기반 정책이 있는 IAM 그룹",
            "3": "신뢰 관계가 있는 IAM 역할",
            "4": "사용자에게 직접 연결된 IAM 정책"
        },
        "Correct Answer": "역할 기반 정책이 있는 IAM 그룹",
        "Explanation": "역할 기반 정책이 있는 IAM 그룹을 사용하면 개발자가 유사한 접근 필요를 가진 사용자를 그룹화하여 권한을 효율적으로 관리할 수 있습니다. 이 방법은 정책을 개별 사용자 대신 그룹에 적용할 수 있어 권한 할당을 간소화하고 팀 구조가 변경될 때 일관성과 관리 용이성을 보장합니다.",
        "Other Options": [
            "IAM 사용자는 각 사용자에 대해 개별적으로 권한을 관리해야 하므로 대규모 팀에는 효율적이지 않으며 접근 수준의 불일치를 초래할 수 있습니다.",
            "신뢰 관계가 있는 IAM 역할은 일반적으로 AWS 서비스나 리소스에 대한 임시 접근을 부여하는 데 사용되며, 애플리케이션 내에서 지속적인 사용자 권한 수준을 관리하는 데는 적합하지 않습니다.",
            "사용자에게 직접 연결된 IAM 정책은 각 사용자에게 특정 권한을 할당해야 하므로 관리가 번거로워지고 일관된 접근 제어를 시행하기 어려워집니다."
        ]
    },
    {
        "Question Number": "22",
        "Situation": "한 회사가 AWS 서비스를 기반으로 하는 마이크로서비스 애플리케이션에서 지연 문제를 겪고 있습니다. 개발 팀은 요청 흐름을 추적하고 분석하여 지연이 발생하는 위치를 정확히 파악할 수 있는 솔루션을 구현하려고 합니다.",
        "Question": "팀이 분산 추적을 구현하고 애플리케이션의 개별 서비스에서의 지연을 가시화하기 위해 어떤 AWS 서비스를 사용해야 합니까?",
        "Options": {
            "1": "AWS X-Ray를 사용하여 API Gateway, Lambda 및 모든 하위 서비스에 걸쳐 요청을 추적합니다.",
            "2": "AWS CloudTrail을 사용하여 각 서비스에서 이루어진 API 호출을 추적하고 감사하며 성능을 모니터링합니다.",
            "3": "Amazon CloudWatch를 사용하여 Lambda 메트릭을 모니터링하고 각 요청의 지연을 시각화합니다.",
            "4": "AWS Lambda의 내장 로깅을 사용하여 각 서비스의 성능과 관련된 로그를 캡처하고 저장합니다."
        },
        "Correct Answer": "AWS X-Ray를 사용하여 API Gateway, Lambda 및 모든 하위 서비스에 걸쳐 요청을 추적합니다.",
        "Explanation": "AWS X-Ray는 분산 추적을 위해 특별히 설계되어 팀이 AWS Lambda 및 API Gateway를 포함한 다양한 서비스 간의 요청 경로를 시각화할 수 있도록 합니다. 이는 서비스 성능에 대한 통찰력을 제공하며, 지연 및 오류를 포함하여 마이크로서비스 아키텍처에서 지연 문제를 식별하고 해결하는 데 가장 적합한 선택입니다.",
        "Other Options": [
            "AWS CloudTrail은 AWS 서비스에 대한 API 호출을 기록하고 감사하는 데 주로 사용됩니다. 이는 수행된 작업을 모니터링하는 데 도움이 되지만, 다양한 서비스 간의 지연을 분석하는 데 필요한 세부 추적을 제공하지 않습니다.",
            "Amazon CloudWatch는 AWS 서비스의 메트릭을 모니터링하고 기록하는 데 중점을 두지만, AWS X-Ray가 제공하는 분산 추적 기능을 제공하지 않습니다. 메트릭을 시각화할 수 있지만 개별 요청을 추적하는 세부 사항이 부족합니다.",
            "AWS Lambda의 내장 로깅은 함수 실행과 관련된 로그를 캡처하는 데 유용하지만, 여러 마이크로서비스 간의 요청 처리 방식을 포괄적으로 보여주지 않으므로 지연 문제를 진단하는 데 필수적인 정보가 부족합니다."
        ]
    },
    {
        "Question Number": "23",
        "Situation": "한 개발자가 전화기, 태블릿 및 데스크톱을 포함한 다양한 장치에서 사용자에게 서비스를 제공하기 위해 설계된 모바일 애플리케이션을 작업하고 있습니다. 이 애플리케이션은 원활한 경험을 제공해야 할 뿐만 아니라 사용자 선호도를 일관되게 기억해야 합니다. 모든 플랫폼에서 사용자 프로필 데이터를 동기화하고 효율적으로 관리하기 위해 개발자는 AWS Cognito가 제공하는 최고의 기능을 탐색하고 있습니다.",
        "Question": "개발자가 다양한 장치와 플랫폼에서 사용자 프로필 데이터를 효과적으로 동기화하기 위해 Amazon Cognito의 어떤 특정 기능을 활용해야 합니까?",
        "Options": {
            "1": "AWS 자격 증명을 생성하기 위한 Cognito Identity Pool",
            "2": "사용자 프로필 데이터를 동기화하기 위한 Cognito Sync",
            "3": "사용자 인증 흐름을 포함한 Cognito User Pool",
            "4": "사용자 선호도를 저장하고 검색하기 위한 DynamoDB 테이블 사용"
        },
        "Correct Answer": "사용자 프로필 데이터를 동기화하기 위한 Cognito Sync",
        "Explanation": "Cognito Sync는 여러 장치 간에 사용자 프로필 데이터를 동기화하기 위해 특별히 설계되었습니다. 이를 통해 애플리케이션은 클라우드에 사용자 선호도를 저장하고 자동으로 동기화하여 사용자가 사용하는 장치에 관계없이 일관된 경험을 보장합니다.",
        "Other Options": [
            "Cognito Identity Pool은 사용자가 AWS 리소스에 접근하기 위한 AWS 자격 증명을 제공하는 데 중점을 두지만, 사용자 프로필 데이터를 직접 관리하거나 동기화하지는 않습니다.",
            "Cognito User Pool은 사용자 인증 및 관리 기능을 제공하며, 사용자 인증 흐름을 포함하지만, 장치 간의 사용자 선호도 동기화를 처리하지 않습니다.",
            "DynamoDB 테이블을 사용하여 사용자 선호도를 저장할 수 있지만, 동기화를 관리하기 위해 추가 개발 작업이 필요하며, 반면 Cognito Sync는 이를 위해 특별히 구축되었습니다."
        ]
    },
    {
        "Question Number": "24",
        "Situation": "빠르게 성장하는 한 회사가 광범위한 AWS 인프라 내에서 API 활동에 대한 모니터링 기능을 강화하려고 노력하고 있습니다. 여기에는 다양한 AWS 리소스를 생성, 수정 또는 삭제하는 등의 필수 작업이 포함됩니다. 포괄적인 감독을 유지하고 규정을 준수하기 위해 회사는 운영하는 모든 AWS 리전에서 모든 활동에 대한 로깅을 중앙 집중화하려고 합니다.",
        "Question": "API 활동에 대한 가시성과 제어의 필요성을 고려할 때, 회사가 전체 AWS 인프라에서 포괄적인 로깅을 보장하기 위해 AWS CloudTrail의 어떤 특정 구성을 구현해야 합니까?",
        "Options": {
            "1": "모니터링을 단순화하고 복잡성을 줄이기 위해 기본 리전에서만 단일 리전 트레일을 활성화합니다.",
            "2": "모든 리전에서 다중 리전 트레일을 활성화하고 각 리전의 로그를 수동으로 집계하여 중앙 집중식 감독을 합니다.",
            "3": "모든 AWS 리전에서 이벤트를 자동으로 추적하는 다중 리전 트레일을 활성화하여 모든 활동에 대한 통합 로그를 제공합니다.",
            "4": "각 AWS 서비스에 대해 이벤트 기록 기능을 활성화하여 서비스별로 최근 활동에 대한 자세한 보기를 제공합니다."
        },
        "Correct Answer": "모든 AWS 리전에서 이벤트를 자동으로 추적하는 다중 리전 트레일을 활성화하여 모든 활동에 대한 통합 로그를 제공합니다.",
        "Explanation": "회사를 위한 올바른 구성은 AWS CloudTrail에서 다중 리전 트레일을 활성화하는 것입니다. 이 옵션은 모든 리전에서 API 활동이 자동으로 기록되도록 하여 회사의 AWS 인프라에 대한 중앙 집중식 보기를 가능하게 합니다. 이는 리소스 생성, 수정 및 삭제와 같은 이벤트를 추적하는 데 중요하며, 회사의 포괄적인 모니터링 및 규정 준수 요구 사항을 충족합니다.",
        "Other Options": [
            "기본 리전에서만 단일 리전 트레일을 활성화하는 것은 회사의 요구에 적합하지 않으며, 이는 다른 리전의 활동을 포착하지 못해 가시성을 제한합니다.",
            "모든 리전에서 다중 리전 트레일을 활성화하면 더 넓은 범위를 제공하지만, 각 리전의 로그를 수동으로 집계하는 것은 지연과 모니터링의 잠재적 격차를 초래할 수 있어 규정 준수 노력을 복잡하게 만듭니다.",
            "각 AWS 서비스에 대해 이벤트 기록 기능을 활성화하는 것은 중앙 집중식 로깅 솔루션을 제공하지 않으며, 전체 인프라에서 모든 API 호출을 포괄적으로 추적하기보다는 서비스별로 최근 활동에 중점을 둡니다."
        ]
    },
    {
        "Question Number": "25",
        "Situation": "한 회사가 AWS STS를 사용하여 AWS 리소스에 접근하기 위한 임시 자격 증명을 사용하고 있습니다. 이들은 SAML 어설션을 사용하여 제3자 신원 공급자와 통합하여 사용자를 인증하고 AWS에서 역할을 맡아야 합니다.",
        "Question": "사용자를 SAML로 인증하기 위해 어떤 AWS STS API 작업을 사용해야 합니까?",
        "Options": {
            "1": "AssumeRole",
            "2": "AssumeRoleSAML",
            "3": "AssumeRoleWithWebIdentity",
            "4": "GetFederationToken"
        },
        "Correct Answer": "AssumeRoleSAML",
        "Explanation": "AssumeRoleSAML 작업은 제3자 신원 공급자로부터 SAML 어설션을 기반으로 사용자가 IAM 역할을 맡을 수 있도록 특별히 설계되었습니다. 이는 SAML 기반 인증 시스템과 통합하기 위한 올바른 선택입니다.",
        "Other Options": [
            "AssumeRole은 SAML 어설션을 지원하지 않으며, AWS 계정 및 IAM 사용자에만 사용됩니다.",
            "AssumeRoleWithWebIdentity는 Google이나 Facebook과 같은 웹 신원 공급자를 통해 사용자를 인증하는 데 사용되며, SAML과는 관련이 없습니다.",
            "GetFederationToken은 AWS 리소스에 대한 임시 접근을 제공하지만, SAML 어설션과는 작동하지 않습니다."
        ]
    },
    {
        "Question Number": "26",
        "Situation": "개발자가 사용자 제출 거래를 효율적으로 처리하는 API를 구현하는 임무를 맡았습니다. 연결 끊김 및 클라이언트 측 재시도와 같은 네트워크 문제의 가능성을 고려할 때, 개발자는 중복 거래가 여러 번 처리되지 않도록 보장하는 것이 중요합니다. 이 요구 사항은 데이터 일관성을 유지하고 거래 기록의 오류를 방지하는 데 필수적입니다. 따라서 개발자는 이 문제를 효과적으로 처리하기 위한 전략을 탐색하고 있습니다.",
        "Question": "개발자가 멱등 거래 처리를 달성하고 중복 거래의 위험을 방지하기 위해 구현해야 할 구체적인 전략은 무엇입니까?",
        "Options": {
            "1": "고유한 거래 식별자를 사용하고 처리 전에 그 존재를 확인합니다.",
            "2": "API가 중복 여부에 관계없이 모든 거래를 처리하도록 허용합니다.",
            "3": "거래 처리를 위한 고정 지연이 있는 재시도 메커니즘을 구현합니다.",
            "4": "중복 처리를 방지하기 위해 거래 데이터를 암호화합니다."
        },
        "Correct Answer": "고유한 거래 식별자를 사용하고 처리 전에 그 존재를 확인합니다.",
        "Explanation": "고유한 거래 식별자를 구현하면 API가 중복 요청을 인식하고 무시할 수 있습니다. 동일한 식별자를 가진 거래가 이미 처리되었는지 확인함으로써, 개발자는 거래의 한 인스턴스만 기록되도록 보장하여 멱등성을 달성하고 데이터 일관성을 유지할 수 있습니다.",
        "Other Options": [
            "API가 중복 여부에 관계없이 모든 거래를 처리하도록 허용하면 동일한 거래에 대해 여러 항목이 생성되어 데이터의 불일치를 초래하고 멱등 처리의 목적을 무색하게 만듭니다.",
            "고정 지연이 있는 재시도 메커니즘을 구현하는 것은 중복 거래 문제를 해결하지 않습니다. 네트워크 신뢰성에는 도움이 될 수 있지만, 동일한 거래가 여러 번 처리되는 것을 방지하지는 않습니다.",
            "거래 데이터를 암호화하는 것은 중복을 방지하지 않으며, 데이터의 기밀성만 보호합니다. 중복 거래는 여전히 발생할 수 있으며, 암호화만으로는 멱등성 요구 사항을 해결하지 않습니다."
        ]
    },
    {
        "Question Number": "27",
        "Situation": "한 회사가 AWS SAM 템플릿을 사용하여 개발, 스테이징 및 프로덕션을 포함한 여러 환경에 애플리케이션을 배포하는 과정에 있습니다. 이러한 각 환경이 승인된 버전의 애플리케이션 리소스만 사용하도록 보장하는 것은 일관되고 신뢰할 수 있는 통합 테스트를 유지하는 데 중요합니다. 팀은 다양한 환경을 관리하기 위한 효과적인 관행을 찾고 있습니다.",
        "Question": "배포 과정 전반에 걸쳐 다양한 애플리케이션 환경의 무결성을 효과적으로 관리하고 유지하기 위해 팀이 구현해야 할 모범 사례는 무엇입니까?",
        "Options": {
            "1": "각 환경에 전념하는 별도의 AWS 계정을 설정하여 개발, 스테이징 및 프로덕션에 대한 완전한 격리 및 보안을 보장합니다.",
            "2": "SAM 템플릿 내에서 Lambda 별칭 및 버전 관리를 활용하여 다양한 환경에서 애플리케이션 리소스의 특정 버전 배포를 제어합니다.",
            "3": "모든 환경을 동일한 AWS SAM 템플릿을 사용하여 수정 없이 배포하고 기본 설정에 의존하여 일관성을 유지합니다.",
            "4": "모든 환경별 구성을 공유 S3 버킷에 저장하여 각 환경에 대한 설정 및 매개변수에 쉽게 접근할 수 있도록 합니다."
        },
        "Correct Answer": "SAM 템플릿 내에서 Lambda 별칭 및 버전 관리를 활용하여 다양한 환경에서 애플리케이션 리소스의 특정 버전 배포를 제어합니다.",
        "Explanation": "SAM 템플릿 내에서 Lambda 별칭 및 버전 관리를 활용하면 팀이 Lambda 함수 및 기타 리소스의 다양한 버전을 효과적으로 관리할 수 있습니다. 이 관행은 각 환경이 승인된 특정 버전의 애플리케이션 리소스를 가리킬 수 있도록 하여 신뢰할 수 있는 통합 테스트를 촉진하고 프로덕션에 테스트되지 않은 코드를 도입할 위험을 최소화합니다.",
        "Other Options": [
            "각 환경에 대해 별도의 AWS 계정을 설정하면 보안과 격리를 강화할 수 있지만, 관리가 복잡해지고 운영 오버헤드가 증가할 수 있어 효과적인 환경 관리에는 덜 실용적일 수 있습니다.",
            "모든 환경을 동일한 AWS SAM 템플릿을 사용하여 수정 없이 배포하면 불일치와 예상치 못한 동작을 초래할 수 있으며, 각 환경의 요구에 맞춘 특정 버전의 제어된 배포를 허용하지 않습니다.",
            "환경별 구성을 공유 S3 버킷에 저장하면 잘못된 구성 및 우발적인 덮어쓰기가 발생할 위험이 있으며, 이는 환경의 무결성을 손상시킬 수 있습니다. 이 접근 방식은 Lambda 별칭을 사용하여 제공되는 버전 관리 이점을 결여하고 있습니다."
        ]
    },
    {
        "Question Number": "28",
        "Situation": "한 회사가 AWS Key Management Service (AWS KMS)를 사용하여 애플리케이션의 암호화 키를 관리하고 있습니다. 보안 팀은 키 정책에 대한 완전한 제어와 내부 보안 기준을 준수하기 위한 키 회전 기능을 원합니다.",
        "Question": "회사가 이러한 요구 사항을 충족하기 위해 어떤 유형의 KMS 키를 사용해야 합니까?",
        "Options": {
            "1": "AWS-managed KMS key",
            "2": "Customer-managed KMS key",
            "3": "AWS-owned KMS key",
            "4": "Service-linked KMS key"
        },
        "Correct Answer": "Customer-managed KMS key",
        "Explanation": "Customer-managed KMS 키는 키 정책에 대한 가장 높은 수준의 제어를 제공하며, 키를 사용할 수 있는 사람과 사용 방법을 지정할 수 있는 기능을 포함합니다. 또한 수동 키 회전을 허용하여 회사의 내부 보안 기준을 충족하는 데 필수적입니다.",
        "Other Options": [
            "AWS-managed KMS 키는 AWS에 의해 생성되고 관리되므로 회사는 키 정책에 대한 완전한 제어를 갖지 못하며 내부 요구 사항에 따라 키 회전을 수행할 수 없습니다.",
            "AWS-owned KMS 키는 AWS 서비스에 사용되며 고객에게는 보이지 않으므로 키 정책이나 회전에 대한 제어를 제공하지 않아 회사의 필요에 적합하지 않습니다.",
            "Service-linked KMS 키는 AWS 서비스에 특정하며 고객을 대신하여 AWS가 관리하므로 제한된 제어만 제공하고 회사의 내부 기준에 따라 키를 회전할 수 없습니다."
        ]
    },
    {
        "Question Number": "29",
        "Situation": "개발자가 애플리케이션 빌드를 자동화하기 위해 AWS CodeBuild 프로젝트를 구성하고 있습니다. 개발자는 구성 파일에 빌드 명령을 지정하고 싶어합니다.",
        "Question": "개발자가 CodeBuild 프로젝트의 빌드 사양을 정의하기 위해 어떤 유형의 파일을 사용해야 합니까?",
        "Options": {
            "1": "buildspec.json이라는 JSON 파일",
            "2": "buildspec.yaml이라는 YAML 파일",
            "3": "buildspec.yml이라는 YAML 파일",
            "4": "buildspec이라는 이름의 YAML 또는 JSON 파일"
        },
        "Correct Answer": "buildspec.yml이라는 YAML 파일",
        "Explanation": "AWS CodeBuild는 주로 빌드 사양을 위해 YAML 파일을 사용합니다. 표준 파일 이름은 buildspec.yml이며, 프로젝트의 빌드 명령과 설정을 포함합니다. buildspec.yaml도 허용되지만, buildspec.yml이 더 일반적으로 사용되는 형식입니다.",
        "Other Options": [
            "이 옵션은 CodeBuild가 빌드 사양을 위해 JSON 파일을 사용하지 않기 때문에 잘못된 것입니다. 예상되는 형식은 YAML입니다.",
            "이 옵션은 buildspec.yaml이 유효한 파일 이름이지만, 더 널리 인식되는 확장자는 .yml이기 때문에 잘못된 것입니다.",
            "이 옵션은 CodeBuild가 YAML과 JSON 형식을 모두 허용하지만, 빌드 사양을 위해 buildspec.yml 또는 buildspec.yaml을 명시적으로 찾기 때문에 잘못된 것입니다."
        ]
    },
    {
        "Question Number": "30",
        "Situation": "개발자가 AWS Lambda와 통합된 API Gateway의 성능을 모니터링하고 있습니다. 그들은 API Gateway가 요청을 전달한 후 백엔드 서비스(Lambda)가 요청을 처리하는 데 걸리는 시간을 측정해야 합니다.",
        "Question": "개발자가 Lambda의 처리 시간을 알아내기 위해 모니터링해야 할 CloudWatch 메트릭은 무엇입니까?",
        "Options": {
            "1": "Latency",
            "2": "IntegrationLatency",
            "3": "CacheHitCount",
            "4": "CacheMissCount"
        },
        "Correct Answer": "IntegrationLatency",
        "Explanation": "IntegrationLatency 메트릭은 API Gateway가 요청을 전달한 후 백엔드 통합(AWS Lambda)이 요청을 처리하는 데 걸리는 시간을 측정합니다. 이는 API Gateway 요청에 대한 Lambda 함수의 성능과 직접적으로 관련된 메트릭입니다.",
        "Other Options": [
            "Latency는 API Gateway가 요청을 처리하는 데 걸리는 총 시간을 측정하며, 백엔드 통합이 응답하는 데 걸리는 시간을 포함하므로 Lambda 처리 시간에 특정하지 않습니다.",
            "CacheHitCount는 캐시에서 제공된 요청 수를 추적하며, Lambda의 처리 시간을 전혀 측정하지 않습니다.",
            "CacheMissCount는 캐시에서 찾을 수 없는 요청 수를 추적하며, CacheHitCount와 유사하게 Lambda의 처리 시간에 대한 정보를 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "31",
        "Situation": "당신은 AWS SAM을 사용하여 서버리스 애플리케이션을 개발하고 있습니다. AWS SAM은 AWS에서 서버리스 애플리케이션을 쉽게 정의하고 배포할 수 있게 해줍니다. 애플리케이션을 배포하기 전에 애플리케이션 코드뿐만 아니라 그 의존성도 배포 패키지에 포함하는 것이 중요합니다. 이렇게 하면 애플리케이션이 AWS에서 실행될 때 모든 필요한 구성 요소가 사용 가능하고 올바르게 구성됩니다. SAM CLI에서 제공하는 특정 명령어를 이해하면 이 과정을 간소화하고 원활한 배포를 보장하는 데 도움이 됩니다.",
        "Question": "AWS에 배포하기 전에 애플리케이션 코드와 그 의존성을 배포 패키지로 패키징하는 작업을 수행하기 위해 어떤 SAM CLI 명령어를 사용해야 합니까?",
        "Options": {
            "1": "sam init",
            "2": "sam validate",
            "3": "sam build",
            "4": "sam package"
        },
        "Correct Answer": "sam package",
        "Explanation": "'sam package'는 AWS SAM에서 애플리케이션 코드와 그 의존성을 배포 패키지로 패키징하는 데 사용해야 하는 올바른 명령어입니다. 이 명령어는 AWS에 배포할 수 있는 배포 패키지를 생성하여 최종 출력에 모든 필요한 파일이 포함되도록 합니다.",
        "Other Options": [
            "'sam init' 명령어는 템플릿에서 새로운 AWS SAM 애플리케이션을 생성하는 데 사용되지만, 기존 애플리케이션을 배포를 위해 패키징하지는 않습니다.",
            "'sam validate' 명령어는 SAM 템플릿의 구문과 구성을 검사하지만, 배포 패키지를 생성하지는 않습니다.",
            "'sam build' 명령어는 서버리스 애플리케이션을 빌드하는 데 사용되며, 배포를 위한 코드를 준비하지만, 애플리케이션을 배포 가능한 형식으로 패키징하지는 않습니다."
        ]
    },
    {
        "Question Number": "32",
        "Situation": "한 회사가 Amazon DynamoDB에 저장된 사용자 세션 데이터에 자주 접근하는 애플리케이션을 개발했습니다. 이 애플리케이션은 사용자 경험을 향상시키기 위해 이 데이터에 크게 의존하지만, 개발 팀은 지연 문제로 인해 성능에 영향을 받고 있음을 발견했습니다. 이러한 문제를 완화하고 읽기 성능을 크게 향상시키기 위해 팀은 캐싱 전략을 구현하고자 합니다. 이 전략은 데이터가 캐시에 있을 때 자동으로 캐시에서 데이터를 검색하고, 캐시에서 데이터를 찾을 수 없을 때 데이터베이스로 원활하게 되돌아가야 합니다. 적절한 접근 방식을 찾는 것은 사용자가 빠른 응답을 경험하면서 데이터 일관성을 유지하는 데 매우 중요합니다.",
        "Question": "팀이 캐시에서 데이터를 자동으로 가져오고 필요할 때 데이터베이스로 되돌아가는 원하는 동작을 달성하기 위해 구현해야 하는 특정 캐싱 전략은 무엇입니까?",
        "Options": {
            "1": "모든 쓰기가 캐시와 데이터베이스에 동시에 이루어져 일관성을 보장하지만 지연을 증가시킬 수 있는 Write-through caching.",
            "2": "캐시에서 찾을 수 없는 경우 캐시가 자동으로 데이터베이스에서 데이터를 검색하도록 허용하여 읽기 성능을 효과적으로 최적화하는 Read-through caching.",
            "3": "데이터가 요청될 때만 캐시에 로드되는 Lazy loading 전략으로, 초기 로드 시간을 줄일 수 있지만 예측할 수 없는 지연을 초래할 수 있습니다.",
            "4": "캐시된 데이터에 대한 만료 시간을 설정하여 일정 기간 후 데이터베이스에서 새로 고침을 필요로 하지만, 필요에 직접적으로 맞지 않는 Time-to-live (TTL) caching."
        },
        "Correct Answer": "Read-through caching, which allows the cache to automatically retrieve data from the database if it's not found in the cache, optimizing read performance effectively.",
        "Explanation": "정답은 Read-through caching입니다. 이 전략은 요청된 데이터를 먼저 캐시에서 찾도록 설계되었습니다. 데이터가 캐시에서 발견되면 직접 반환하여 지연을 최소화합니다. 데이터가 캐시에 없으면 자동으로 기본 데이터베이스(Amazon DynamoDB)에서 가져와서 향후 요청을 위해 캐시에 추가하고 애플리케이션에 반환합니다. 이 동작은 읽기 성능을 개선하면서 데이터베이스로의 원활한 되돌아가기를 유지하려는 팀의 요구 사항과 완벽하게 일치합니다.",
        "Other Options": [
            "Write-through caching은 데이터를 캐시와 데이터베이스에 동시에 쓰는 것이기 때문에 읽기 작업을 위한 데이터를 자동으로 검색해야 하는 필요와 일치하지 않으므로 잘못된 선택입니다.",
            "Lazy loading은 데이터가 특정 요청이 있을 때만 캐시에 로드되므로 초기 요청 시 더 높은 지연을 초래할 수 있어 성능을 향상시키기 위한 사전 데이터 검색과는 반대입니다.",
            "Time-to-live (TTL) caching은 캐시된 데이터의 수명을 제어하지만, 캐시에서 데이터를 찾을 수 없을 때 데이터베이스에서 자동으로 검색하는 메커니즘을 제공하지 않기 때문에 이 상황에 적합하지 않습니다."
        ]
    },
    {
        "Question Number": "33",
        "Situation": "한 개발자가 AWS Lambda 함수와 상호작용하기 위해 API Gateway를 사용하여 API를 구축하고 있습니다. 이 API는 콘텐츠 인코딩이나 캐싱이 필요하지 않으며, 개발자는 효율적인 운영을 위해 간소화된 설정을 선호합니다.",
        "Question": "이 간소화된 API 아키텍처를 위해 개발자가 선택해야 할 통합 유형은 무엇입니까?",
        "Options": {
            "1": "HTTP Proxy 통합은 API Gateway가 요청을 HTTP 엔드포인트로 직접 전달할 수 있게 하여 빠른 설정에 적합한 선택입니다.",
            "2": "LAMBDA_CUSTOM 통합은 요청 및 응답 매핑을 위한 추가 구성이 필요하여 이 시나리오에 불필요한 복잡성을 추가합니다.",
            "3": "LAMBDA_PROXY 통합은 요청 및 응답 매핑을 자동으로 처리하여 Lambda 함수에 간소화된 방식으로 연결하는 가장 효율적인 선택입니다.",
            "4": "Mock Integration은 백엔드 없이 테스트할 수 있게 하지만 실제 Lambda 함수에 연결되지 않으므로 이 경우 적합하지 않습니다."
        },
        "Correct Answer": "LAMBDA_PROXY integration automatically handles request and response mapping, making it the most efficient choice for connecting to Lambda functions in a streamlined manner.",
        "Explanation": "LAMBDA_PROXY 통합 유형은 API Gateway와 AWS Lambda 함수를 연결하는 과정을 간소화하기 때문에 이 시나리오에 가장 적합합니다. 요청 및 응답 매핑을 자동으로 관리하여 개발자가 추가 구성에 대해 걱정하지 않고 API의 핵심 기능에 집중할 수 있게 합니다. 이는 간소화된 설정에 이상적입니다.",
        "Other Options": [
            "HTTP Proxy 통합은 간단하지만 AWS Lambda 함수에 대해 최적이 아니며, HTTP 엔드포인트로 요청을 전달하는 대신 Lambda 실행 모델을 효과적으로 활용하지 않습니다.",
            "LAMBDA_CUSTOM 통합은 요청 및 응답 처리를 위한 더 복잡한 설정이 필요하므로 개발자의 간소화된 구성 선호와 모순됩니다.",
            "Mock Integration은 주로 테스트 목적으로 사용되며 실제 백엔드 서비스와의 연결을 제공하지 않으므로 Lambda 함수와 상호작용이 필요한 이 API에는 적합하지 않습니다."
        ]
    },
    {
        "Question Number": "34",
        "Situation": "현대 클라우드 환경에서 한 회사가 AWS Lambda와 Amazon DynamoDB를 활용하여 서버리스 애플리케이션을 운영하고 있습니다. 최근 이 애플리케이션은 사용자 트래픽의 간헐적인 급증에 직면하고 있으며, 이로 인해 Lambda 함수 중 일부가 동시성 한계 초과로 인해 실패하고 있습니다. 결과적으로 개발 팀은 애플리케이션이 이러한 예상치 못한 트래픽 급증을 원활하게 처리할 수 있도록 하면서도 자원 사용을 최적화하여 불필요한 비용을 피하고 일관된 성능을 보장할 수 있는 해결책을 찾아야 하는 압박을 받고 있습니다.",
        "Question": "팀이 AWS Lambda 함수 내에서 동시성을 효과적으로 관리하여 높은 수요 기간 동안 애플리케이션의 신뢰성과 가용성을 보장하기 위해 어떤 전략을 구현해야 합니까?",
        "Options": {
            "1": "Lambda 함수에 대해 예약된 동시성을 활성화하여 설정된 수의 동시 실행을 보장합니다.",
            "2": "Lambda 함수의 메모리 할당을 늘려 더 많은 동시 실행을 처리합니다.",
            "3": "Amazon SQS를 사용하여 들어오는 요청을 큐에 저장하고 Lambda로 순차적으로 처리합니다.",
            "4": "부하를 분산하기 위해 애플리케이션을 여러 AWS 리전으로 배포합니다."
        },
        "Correct Answer": "Lambda 함수에 대해 예약된 동시성을 활성화하여 설정된 수의 동시 실행을 보장합니다.",
        "Explanation": "Lambda 함수에 대해 예약된 동시성을 활성화하면 특정 수의 동시 실행이 항상 해당 함수에 대해 사용 가능하게 됩니다. 이는 트래픽 급증 시 애플리케이션이 실패하지 않고 증가된 부하를 처리할 수 있도록 하며, 예약된 동시성이 완충 역할을 합니다. 이 전략은 동시성 한계를 효과적으로 관리하고 다양한 부하에서 애플리케이션의 신뢰성을 높입니다.",
        "Other Options": [
            "Lambda 함수의 메모리 할당을 늘리는 것은 동시성을 직접적으로 증가시키지 않습니다. 개별 요청의 성능을 개선할 수는 있지만, 더 많은 요청이 동시 처리될 수 있다는 보장은 없으며, 이는 트래픽 급증을 처리하는 데 필수적입니다.",
            "Amazon SQS를 사용하여 들어오는 요청을 큐에 저장하는 것은 부하 관리를 위한 실행 가능한 전략이지만 요청이 순차적으로 처리되므로 지연 시간이 증가할 수 있습니다. 이는 즉각적인 처리가 필요한 높은 수요 기간 동안 수용할 수 없을 수 있습니다.",
            "애플리케이션을 여러 AWS 리전으로 배포하는 것은 부하 분산에 도움이 될 수 있지만 아키텍처의 복잡성을 증가시키고 Lambda 함수의 동시성 한계를 직접적으로 해결하지 않습니다. 또한, 더 나은 동시성 관리를 달성하기 위해 비용 효율적이지 않거나 필요하지 않을 수 있습니다."
        ]
    },
    {
        "Question Number": "35",
        "Situation": "한 개발자가 Lambda 함수의 새 버전을 배포하고 있습니다. 배포는 현재 버전에서 새 버전으로 트래픽을 점진적으로 전환하여 애플리케이션에 최소한의 중단을 보장해야 합니다.",
        "Question": "CodeDeploy는 이 배포를 어떻게 처리합니까?",
        "Options": {
            "1": "원래 Lambda 함수를 중지하고 새 버전을 즉시 배포합니다.",
            "2": "원래 Lambda 함수에서 새 버전으로 점진적으로 트래픽을 전환합니다.",
            "3": "트래픽을 전환하지 않고 새 버전을 별도의 Lambda 함수에 배포합니다.",
            "4": "트래픽 전환 관리를 위해 CodeDeploy 에이전트를 사용해야 합니다."
        },
        "Correct Answer": "원래 Lambda 함수에서 새 버전으로 점진적으로 트래픽을 전환합니다.",
        "Explanation": "CodeDeploy는 Lambda 함수 배포를 처리하여 이전 버전에서 새 버전으로 트래픽을 점진적으로 전환할 수 있도록 합니다. 이 점진적인 접근 방식은 모든 사용자에게 영향을 미치지 않고 문제를 식별하고 해결할 수 있도록 도와주어 중단을 최소화합니다.",
        "Other Options": [
            "이 옵션은 CodeDeploy가 원래 Lambda 함수를 즉시 중지하지 않기 때문에 잘못된 것입니다. 대신 점진적인 트래픽 전환을 허용합니다.",
            "이 옵션은 새 버전을 별도의 Lambda 함수에 배포하는 것이 현재 버전에서 점진적인 트래픽 전환을 촉진하지 않기 때문에 잘못된 것입니다.",
            "이 옵션은 Lambda 함수의 트래픽 전환 관리를 위해 CodeDeploy 에이전트가 필요하지 않기 때문에 잘못된 것입니다. Lambda 배포는 다르게 처리됩니다."
        ]
    },
    {
        "Question Number": "36",
        "Situation": "한 개발자가 단일 작업에서 여러 DynamoDB 항목을 업데이트해야 하는 애플리케이션을 설계하고 있습니다. 업데이트는 모든 항목에서 성공하거나 완전히 실패해야 하며, 데이터 일관성을 보장하고 부분 업데이트를 방지해야 합니다.",
        "Question": "개발자가 여러 항목에 대한 업데이트가 원자적으로 실행되어 모든 지정된 항목에서 데이터 일관성을 유지하도록 보장하기 위해 어떤 DynamoDB 기능을 사용해야 합니까?",
        "Options": {
            "1": "BatchWriteItems, 여러 쓰기 작업을 수행할 수 있지만 업데이트되는 모든 항목에 대해 원자성을 보장하지 않습니다.",
            "2": "TransactWriteItems, 개발자가 여러 쓰기 작업을 원자적으로 실행할 수 있도록 하여 모두 성공하거나 아무것도 성공하지 않도록 합니다.",
            "3": "Conditional Writes, 단일 항목 업데이트에 특정 조건을 적용할 수 있지만 여러 항목을 원자적으로 지원하지 않습니다.",
            "4": "DynamoDB Streams, 변경 사항을 캡처하지만 여러 항목에 대한 직접적인 원자적 쓰기 작업을 촉진하지 않습니다."
        },
        "Correct Answer": "TransactWriteItems, 개발자가 여러 쓰기 작업을 원자적으로 실행할 수 있도록 하여 모두 성공하거나 아무것도 성공하지 않도록 합니다.",
        "Explanation": "TransactWriteItems는 여러 쓰기 작업을 원자적으로 실행해야 하는 상황을 위해 특별히 설계되었습니다. 이는 지정된 모든 업데이트가 성공하거나 아무것도 적용되지 않음을 의미하며, 수정되는 항목 간의 일관성을 보장합니다. 이 기능은 데이터 무결성을 유지하는 것이 중요한 시나리오에 이상적입니다.",
        "Other Options": [
            "BatchWriteItems는 여러 쓰기 작업을 허용하지만 해당 항목 간의 원자성 보장을 결여하고 있습니다. 하나의 작업이 실패하면 다른 작업이 성공할 수 있어 일관되지 않은 데이터로 이어질 수 있습니다.",
            "Conditional Writes는 개별 항목에 대한 특정 조건에 따라 업데이트를 가능하게 하지만 여러 업데이트를 단일 원자적 트랜잭션으로 그룹화하지 않아 여러 항목 업데이트 요구 사항을 충족하지 못합니다.",
            "DynamoDB Streams는 항목 변경 사항을 캡처하는 방법을 제공하지만 직접적인 업데이트나 원자적 쓰기 작업을 촉진하지 않습니다. 이는 트랜잭션 무결성을 보장하기보다는 변경 사항을 추적하는 데 더 가깝습니다."
        ]
    },
    {
        "Question Number": "37",
        "Situation": "한 회사가 기존 애플리케이션을 AWS로 마이그레이션하는 과정에 있습니다. 이 마이그레이션의 일환으로, 애플리케이션은 사용자 업로드 파일을 저장하기 위해 Amazon S3를 사용하고, 사용자 경험을 향상시키기 위해 Amazon CloudFront를 콘텐츠 전송 네트워크(CDN)로 활용하고 있습니다. 그러나 사용자들은 파일의 구버전을 받는 경우가 있다고 보고하였으며, 이는 혼란과 불만을 초래할 수 있습니다. 이 문제는 주로 캐싱 동작에서 발생하며, 이는 CDN을 사용할 때 흔히 발생하는 도전 과제입니다.",
        "Question": "개발자가 사용자가 항상 최신 버전의 파일을 받을 수 있도록 보장하기 위해 어떤 조치를 취할 수 있습니까? 이를 통해 캐싱 문제를 효과적으로 해결할 수 있습니다.",
        "Options": {
            "1": "CloudFront가 모든 쿼리 문자열을 원본으로 전달하도록 구성합니다.",
            "2": "S3에서 파일이 업데이트될 때마다 CloudFront에서 캐시된 객체를 무효화합니다.",
            "3": "S3 버킷에서 버전 관리를 활성화합니다.",
            "4": "CloudFront 캐시 만료 시간을 늘립니다."
        },
        "Correct Answer": "S3에서 파일이 업데이트될 때마다 CloudFront에서 캐시된 객체를 무효화합니다.",
        "Explanation": "S3에서 파일이 업데이트될 때마다 CloudFront에서 캐시된 객체를 무효화하면 CDN이 사용자에게 최신 버전의 파일을 제공하도록 보장합니다. 이 과정은 캐시에서 구버전을 제거하고 CloudFront가 S3 원본에서 새로운 버전을 가져오도록 강제하여 사용자가 오래된 콘텐츠를 받는 문제를 해결합니다.",
        "Other Options": [
            "CloudFront가 모든 쿼리 문자열을 원본으로 전달하도록 구성하는 것은 일부 시나리오에서 도움이 될 수 있지만, 구버전 캐시 파일 문제를 직접적으로 해결하지는 않습니다. 이 옵션은 사용자가 최신 버전의 파일을 받도록 보장하는 가장 효과적인 솔루션이 아닙니다.",
            "S3 버킷에서 버전 관리를 활성화하는 것은 파일 업데이트를 관리하는 좋은 방법이지만, CloudFront의 캐싱 문제를 본질적으로 해결하지는 않습니다. 캐시가 무효화되지 않으면 사용자는 여전히 구버전에 접근할 수 있습니다.",
            "CloudFront 캐시 만료 시간을 늘리면 사용자가 구버전 파일을 받는 문제를 악화시킬 가능성이 높습니다. 만료 시간이 길어지면 파일이 더 오랜 기간 캐시되므로, 사용자가 최신 콘텐츠를 갖도록 보장하는 데 역효과를 낳습니다."
        ]
    },
    {
        "Question Number": "38",
        "Situation": "한 개발자가 Amazon S3에 저장된 개인 식별 정보(PII)를 처리하는 애플리케이션을 구축하고 있습니다. 개발자는 민감한 데이터가 저장되기 전에 암호화되고, 권한이 있는 사용자가 접근할 때 복호화되도록 보장해야 합니다. 이 애플리케이션은 암호화를 위해 AWS Key Management Service (KMS)를 사용합니다.",
        "Question": "애플리케이션 코드에서 암호화를 구현하기 위한 권장 접근 방식은 무엇입니까? 민감한 데이터가 저장되기 전에 암호화되고 접근할 때 복호화되도록 보장합니다.",
        "Options": {
            "1": "KMS를 사용하여 데이터 암호화 키를 생성하고, 키를 S3에 저장하며, 클라이언트 측 암호화를 사용하여 데이터를 암호화하고 복호화합니다.",
            "2": "KMS를 사용하여 S3에 쓰고 읽을 때 데이터를 즉시 암호화합니다(서버 측 암호화 사용).",
            "3": "EC2 인스턴스를 사용하여 암호화 키를 관리하고 데이터를 S3에 저장하기 전에 암호화합니다.",
            "4": "AWS Secrets Manager를 사용하여 암호화 키를 저장하고 애플리케이션 코드 내에서 암호화 및 복호화를 수행합니다."
        },
        "Correct Answer": "KMS를 사용하여 S3에 쓰고 읽을 때 데이터를 즉시 암호화합니다(서버 측 암호화 사용).",
        "Explanation": "KMS와 서버 측 암호화(SSE-KMS)를 사용하면 데이터가 S3에 업로드될 때 자동으로 암호화되고 접근할 때 복호화됩니다. 이 방법은 AWS가 암호화 및 복호화 프로세스를 처리하므로 키 관리가 간소화되어 민감한 데이터가 추가적인 코딩 복잡성 없이 보호됩니다.",
        "Other Options": [
            "S3에 데이터 암호화 키를 저장하는 것은 안전하지 않으며, 키가 무단 접근에 노출될 수 있습니다. 클라이언트 측 암호화는 키를 별도로 관리해야 하므로 복잡성이 증가하며 AWS의 내장 기능을 활용하지 않습니다.",
            "EC2 인스턴스에서 암호화 키를 관리하는 것은 추가적인 운영 오버헤드와 잠재적인 보안 위험을 초래합니다. 또한 AWS의 기본 암호화 기능을 활용하지 않으므로 효율성이 떨어집니다.",
            "AWS Secrets Manager를 사용하여 암호화 키를 저장하는 것은 이 시나리오에 가장 효율적인 방법이 아닙니다. 이는 암호화 및 복호화 프로세스를 복잡하게 만들며, SSE-KMS가 S3와의 더 원활한 통합을 제공합니다."
        ]
    },
    {
        "Question Number": "39",
        "Situation": "한 글로벌 회사가 다양한 대륙에 분포된 다양한 사용자 기반을 가지고 있습니다. 사용자 경험을 향상시키고 지연 시간을 줄이기 위해, 이들은 인증 워크플로우의 성능을 최적화할 방법을 적극적으로 모색하고 있습니다. 목표는 인증 요청이 사용자와 최대한 가까운 곳에서 처리되어 지연을 최소화하고 응답 시간을 개선하는 것입니다. 이러한 맥락에서 회사는 이 최적화를 촉진할 수 있는 다양한 AWS 서비스를 탐색하고 있습니다.",
        "Question": "회사가 인증 요청을 사용자와 더 가까운 곳에서 효과적으로 처리하여 전체 성능을 개선하고 지연 시간을 줄이기 위해 어떤 AWS 서비스를 활용해야 합니까?",
        "Options": {
            "1": "AWS Step Functions는 복잡한 워크플로우를 조정하기 위해 설계되었습니다.",
            "2": "AWS Lambda@Edge는 전 세계 사용자 가까이에서 코드를 실행할 수 있게 해줍니다.",
            "3": "AWS Cloud9는 클라우드에서 통합 개발 환경입니다.",
            "4": "AWS SWF는 분산 애플리케이션을 조정하는 서비스입니다."
        },
        "Correct Answer": "AWS Lambda@Edge는 전 세계 사용자 가까이에서 코드를 실행할 수 있게 해줍니다.",
        "Explanation": "AWS Lambda@Edge는 개발자가 Amazon CloudFront 이벤트에 응답하여 코드를 실행할 수 있도록 특별히 설계되었습니다. 이는 AWS 위치에서 사용자와 더 가까운 곳에서 기능을 실행할 수 있음을 의미합니다. 이 기능은 인증 워크플로우를 최적화하는 데 이상적이며, 요청을 최종 사용자와 지리적으로 더 가까운 곳에서 처리하여 지연을 줄이고 사용자 경험을 개선합니다.",
        "Other Options": [
            "AWS Step Functions는 여러 서비스를 포함하는 복잡한 워크플로우를 조정하는 데 주로 사용되며, 엣지에서 저지연 처리를 필요로 하는 문제를 직접적으로 해결하지 않습니다.",
            "AWS Cloud9는 코드를 작성하고 디버깅하는 데 도움을 주는 통합 개발 환경이지만, 사용자와 더 가까운 곳에서 요청을 처리하는 데 필요한 기능을 제공하지 않습니다.",
            "AWS SWF(단순 워크플로우 서비스)는 복잡한 분산 애플리케이션을 구축하는 데 사용되지만, 엣지 위치에서 사용자 요청의 성능을 최적화하지는 않습니다."
        ]
    },
    {
        "Question Number": "40",
        "Situation": "한 회사가 사용자가 개인 노트를 원활하게 생성, 조회, 업데이트 및 삭제할 수 있는 웹 애플리케이션을 개발하고 있습니다. 애플리케이션이 효율적으로 작동하기 위해서는 백엔드가 이러한 기본 작업을 신속하고 신뢰성 있게 수행할 수 있어야 합니다.",
        "Question": "사용자 노트를 효과적으로 관리하기 위해 애플리케이션에 필요한 필수 CRUD 기능과 일치하는 특정 작업 세트는 무엇입니까?",
        "Options": {
            "1": "Connect, Run, Upload, Download - 네트워크 상호작용 및 파일 관리를 제안하지만 핵심 데이터 작업이 부족한 세트입니다.",
            "2": "Create, Read, Update, Delete - 애플리케이션 내에서 데이터를 관리하는 데 필요한 기본 작업을 포괄하는 포괄적인 작업 세트입니다.",
            "3": "Configure, Render, Update, Deploy - 직접 데이터 조작보다는 설정 및 배포 프로세스에 더 중점을 둔 그룹입니다.",
            "4": "Calculate, Report, Update, Destroy - 일부 관련 작업을 포함하지만 데이터 관리의 본질을 포착하지 못하는 컬렉션입니다."
        },
        "Correct Answer": "Create, Read, Update, Delete - 애플리케이션 내에서 데이터를 관리하는 데 필요한 기본 작업을 포괄하는 포괄적인 작업 세트입니다.",
        "Explanation": "'Create, Read, Update, Delete'라는 정답은 CRUD로 알려져 있으며, 이는 지속적인 저장을 위해 필요한 네 가지 기본 작업을 나타냅니다. 이 세트는 사용자가 새로운 데이터를 입력하고, 기존 데이터를 검색하며, 해당 데이터를 수정하고, 필요에 따라 제거할 수 있도록 하여 사용자 생성 콘텐츠(예: 노트)를 다루는 모든 애플리케이션에 필수적입니다.",
        "Other Options": [
            "'Connect, Run, Upload, Download' 옵션은 개인 노트와 같은 데이터 레코드를 관리하는 데 필요한 핵심 작업이 아닌 네트워킹 및 데이터 전송 프로세스에 중점을 둡니다.",
            "'Configure, Render, Update, Deploy' 옵션은 데이터 항목을 생성하고 관리하는 데 필요한 기본 작업보다는 애플리케이션 설정 및 프레젠테이션과 더 관련이 있습니다.",
            "'Calculate, Report, Update, Destroy' 옵션은 데이터와 관련될 수 있는 일부 작업을 포함하지만, 필수 CRUD 프레임워크를 정확하게 나타내지 않아 효과적인 데이터 관리를 위한 요구 사항을 충족하지 못합니다."
        ]
    },
    {
        "Question Number": "41",
        "Situation": "개발자가 Amazon RDS 데이터베이스와 상호작용하는 AWS Lambda 함수를 생성하고 있습니다. 이 맥락에서 함수가 일시적인 데이터베이스 연결 문제를 우아하게 처리하는 것이 중요합니다. 이러한 문제는 네트워크 불안정성이나 데이터베이스의 일시적인 사용 불가능으로 인해 자주 발생할 수 있습니다. 개발자는 지연을 최소화하면서 연결 시도의 신뢰성과 견고성을 보장하는 효율적인 재시도 메커니즘을 구현하는 것을 목표로 하고 있습니다. 이는 요청으로 데이터베이스를 압도하지 않으면서 재시도를 관리하는 방법에 대한 신중한 고려를 포함합니다.",
        "Question": "일시적인 연결 문제를 처리하면서도 상당한 지연을 초래하지 않도록 이 재시도 메커니즘을 효과적으로 구현하기 위해 개발자가 AWS Lambda 함수에서 따라야 할 프로그래밍 관행은 무엇입니까?",
        "Options": {
            "1": "연결이 성공할 때까지 무한 루프를 사용하여 계속 재시도합니다.",
            "2": "재시도 시도에 대해 지터가 있는 지수 백오프를 구현합니다.",
            "3": "모든 재시도 시도 사이에 고정 지연을 사용합니다.",
            "4": "여러 재시도를 수용하기 위해 Lambda 함수의 타임아웃을 늘립니다."
        },
        "Correct Answer": "재시도 시도에 대해 지터가 있는 지수 백오프를 구현합니다.",
        "Explanation": "지수 백오프와 지터를 구현하는 것은 네트워크 작업에서 재시도를 관리하는 모범 사례입니다. 이 접근 방식은 연속 재시도 시도 사이의 대기 시간을 점진적으로 증가시켜 데이터베이스의 부하를 줄이고 각 시도에서 성공할 가능성을 높입니다. 지터를 추가하면 여러 연결이 동시에 재시도하여 추가 혼잡과 지연을 초래할 수 있는 '천둥 무리' 문제를 방지하는 데 도움이 됩니다.",
        "Other Options": [
            "연결이 성공할 때까지 무한 루프를 사용하여 계속 재시도하는 것은 비효율적이며 자원 고갈이나 서비스 거부를 초래할 수 있습니다. 이는 지연을 포함하지 않으며 데이터베이스를 압도할 수 있습니다.",
            "모든 재시도 시도 사이에 고정 지연을 사용하는 것은 연결 문제가 일시적일 경우 불필요한 대기 시간을 초래할 수 있습니다. 이는 상황에 따라 적응하지 않으므로 대기 시간을 변동시키는 접근 방식보다 비효율적일 수 있습니다.",
            "여러 재시도를 수용하기 위해 Lambda 함수의 타임아웃을 늘리는 것은 일시적인 연결 문제에 대한 해결책이 아닙니다. 재시도를 위한 더 많은 시간을 허용하지만, 데이터베이스를 압도하지 않고 재시도를 지능적으로 관리하는 방법에 대한 근본적인 문제를 해결하지 않습니다."
        ]
    },
    {
        "Question Number": "42",
        "Situation": "한 회사의 애플리케이션이 Amazon DynamoDB 테이블에 자주 접근하며 사용 최적화를 위해 특정 성능 지표를 모니터링해야 합니다. 개발 팀은 애플리케이션 동작 및 DynamoDB 상호작용에 대한 더 깊은 통찰력을 얻기 위해 사용자 정의 지표를 발행하고자 합니다.",
        "Question": "개발자가 사용자 정의 애플리케이션 지표를 효과적으로 구현하기 위해 어떤 접근 방식을 취해야 합니까?",
        "Options": {
            "1": "Amazon CloudWatch의 내장 메트릭 형식(EMF)을 활용하여 애플리케이션 코드에서 CloudWatch로 사용자 정의 메트릭을 원활하게 발행하여 실시간 모니터링을 가능하게 합니다.",
            "2": "Amazon CloudWatch에서 제공하는 DynamoDB의 내장 메트릭에만 의존하여 애플리케이션 특정 성능 데이터를 모두 포착하지 못할 수 있습니다.",
            "3": "사용자 정의 메트릭을 Amazon S3 버킷에 저장하여 나중에 분석하는데, 이는 통찰력을 지연시키고 검색을 위한 추가 처리가 필요할 수 있습니다.",
            "4": "메트릭에 대한 사용자 정의 로깅을 생성하고 Amazon Athena를 사용하여 해당 로그에 대한 쿼리를 수행하는데, 이는 실시간 모니터링 프로세스를 복잡하게 만들 수 있습니다."
        },
        "Correct Answer": "Amazon CloudWatch의 내장 메트릭 형식(EMF)을 활용하여 애플리케이션 코드에서 CloudWatch로 사용자 정의 메트릭을 원활하게 발행하여 실시간 모니터링을 가능하게 합니다.",
        "Explanation": "Amazon CloudWatch의 내장 메트릭 형식(EMF)을 사용하면 개발자가 애플리케이션 코드에서 직접 사용자 정의 메트릭을 전송할 수 있습니다. 이 방법은 실시간 성능 모니터링을 가능하게 하며 애플리케이션 동작 및 DynamoDB와의 상호작용에 대한 더 깊은 통찰력을 제공합니다. 이는 팀의 요구에 효율적인 접근 방식입니다.",
        "Other Options": [
            "Amazon CloudWatch에서 사용할 수 있는 DynamoDB의 내장 메트릭에만 의존하는 것은 심층적인 애플리케이션 분석에 필요한 모든 특정 메트릭을 포착하지 못할 수 있어 성능 최적화 능력을 제한합니다.",
            "사용자 정의 메트릭을 Amazon S3 버킷에 저장하여 나중에 분석하는 것은 해당 메트릭에 접근하는 데 지연을 초래하고 데이터를 처리하고 분석하기 위한 추가 단계를 요구하므로 실시간 통찰력에 이상적이지 않습니다.",
            "메트릭에 대한 사용자 정의 로깅을 구현하고 Amazon Athena를 사용하여 해당 로그를 쿼리하는 것은 모니터링 프로세스를 복잡하게 만들고 피드백 루프를 느리게 하여 즉각적인 통찰력을 위해 EMF를 활용하는 것보다 덜 효과적일 수 있습니다."
        ]
    },
    {
        "Question Number": "43",
        "Situation": "개발자는 높은 트래픽의 애플리케이션을 위한 캐싱 솔루션을 설계하는 임무를 맡았습니다. 이 애플리케이션은 상당한 양의 요청을 효율적으로 처리할 것으로 예상됩니다. 애플리케이션은 빠른 응답 시간을 보장하기 위해 여러 스레드가 동시에 작업할 때 잘 작동해야 합니다. 성능과 단순성이 중요하지만, 애플리케이션은 높은 가용성이나 데이터 지속성에 대한 요구 사항이 없으므로 캐싱 메커니즘을 보다 간단하게 구현할 수 있습니다.",
        "Question": "이러한 요구 사항을 고려할 때, ElastiCache 옵션 중 어떤 것이 이 높은 트래픽 애플리케이션에 가장 적합합니까?",
        "Options": {
            "1": "ElastiCache for Redis with replication enabled.",
            "2": "ElastiCache for Redis without replication.",
            "3": "ElastiCache for Memcached.",
            "4": "Amazon DynamoDB with on-demand mode."
        },
        "Correct Answer": "ElastiCache for Memcached.",
        "Explanation": "ElastiCache for Memcached는 높은 성능의 캐싱을 위해 설계되었으며, 복제의 오버헤드 없이 간단한 캐싱을 요구하는 애플리케이션에 특히 적합합니다. Memcached는 뛰어난 멀티 스레드 성능을 제공하며, 불필요한 복잡성 없이 애플리케이션의 요구를 충족하는 경량 옵션입니다.",
        "Other Options": [
            "ElastiCache for Redis with replication enabled는 애플리케이션이 높은 가용성이나 복제가 제공하는 데이터 지속성 이점을 요구하지 않기 때문에 여기에는 적합하지 않으며, 필요 이상으로 복잡합니다.",
            "ElastiCache for Redis without replication은 실행 가능한 옵션이지만, 특히 Redis의 추가 기능이 필요하지 않은 시나리오에서는 간단한 캐싱 요구에 대해 Memcached보다 더 많은 복잡성을 도입합니다.",
            "Amazon DynamoDB with on-demand mode는 주로 데이터베이스 서비스이지 캐싱 솔루션이 아닙니다. 속도와 단순성이 가장 중요한 캐싱 시나리오에 최적화되어 있지 않으므로 개발자의 요구 사항에 덜 적합합니다."
        ]
    },
    {
        "Question Number": "44",
        "Situation": "개발 팀은 애플리케이션 코드의 버전 관리를 위해 Git을 사용합니다. 그들은 개발, 테스트 및 프로덕션 릴리스를 관리하기 위해 Git 브랜칭 전략을 따릅니다. 팀은 AWS에 자동 배포를 위해 Git 리포지토리를 CI/CD 파이프라인과 통합해야 합니다.",
        "Question": "팀이 리포지토리를 관리하고 AWS CodePipeline과 원활하게 통합하기 위해 어떤 Git 기반 도구를 사용해야 합니까?",
        "Options": {
            "1": "Subversion",
            "2": "GitHub",
            "3": "AWS CodeCommit",
            "4": "Mercurial"
        },
        "Correct Answer": "AWS CodeCommit",
        "Explanation": "AWS CodeCommit은 팀이 안전하고 확장 가능한 Git 리포지토리를 호스팅할 수 있도록 쉽게 해주는 완전 관리형 소스 제어 서비스입니다. AWS CodePipeline을 포함한 AWS 서비스와 직접 통합되므로 팀의 AWS에 대한 자동 배포 요구에 가장 적합한 선택입니다.",
        "Other Options": [
            "Subversion은 Git 기반 도구가 아니며, 다른 버전 관리 시스템을 사용하므로 팀의 Git 기반 워크플로우와 호환되지 않습니다.",
            "GitHub은 인기 있는 Git 리포지토리 호스팅 서비스이지만, AWS CodeCommit만큼 AWS 서비스와 원활하게 통합되지 않을 수 있습니다.",
            "Mercurial은 Git 기반이 아닌 또 다른 버전 관리 시스템이므로 팀의 Git 기반 도구 요구 사항에 맞지 않습니다."
        ]
    },
    {
        "Question Number": "45",
        "Situation": "조직은 Amazon Kinesis를 통해 대량의 데이터를 수집하는 실시간 분석 플랫폼을 AWS에 배포하고 있습니다. 이 플랫폼은 데이터 스트림을 효율적으로 처리하고 분석하도록 설계되었으며, Amazon Redshift에서 복잡한 쿼리를 수행하여 실행 가능한 통찰력을 도출합니다. 애플리케이션이 사용자에게 높은 가용성과 낮은 대기 시간을 유지하도록 보장하기 위해 팀은 성능 메트릭을 추적하고 특정 운영 임계값이 초과될 때 자동 스케일링을 트리거할 수 있는 강력한 모니터링 전략을 구현해야 합니다. 이를 통해 잠재적인 병목 현상을 사전에 해결할 수 있습니다.",
        "Question": "팀이 수요에 따라 시스템이 자동으로 확장될 수 있도록 보장하면서 애플리케이션 성능을 효과적으로 모니터링하기 위해 어떤 구체적인 조치를 취해야 합니까?",
        "Options": {
            "1": "Amazon CloudWatch를 사용하여 Kinesis 처리량, Redshift 쿼리 시간 및 Lambda 함수 호출 대기 시간에 대한 사용자 정의 메트릭을 생성합니다.",
            "2": "AWS X-Ray를 사용하여 각 데이터 요청을 추적한 다음 CloudTrail 로그를 모니터링하여 잠재적인 리소스 소진 이벤트를 검토합니다.",
            "3": "CloudWatch Alarms를 사용하여 Lambda 함수 오류 및 EC2 인스턴스 메모리 사용량을 모니터링한 다음 스케일링 정책을 조정합니다.",
            "4": "CloudWatch를 사용하여 Kinesis에 대한 사용자 정의 메트릭을 생성하고 미리 정의된 임계값에 따라 수동으로 스케일링 정책을 트리거합니다."
        },
        "Correct Answer": "Amazon CloudWatch를 사용하여 Kinesis 처리량, Redshift 쿼리 시간 및 Lambda 함수 호출 대기 시간에 대한 사용자 정의 메트릭을 생성합니다.",
        "Explanation": "Amazon CloudWatch를 사용하여 사용자 정의 메트릭을 생성하면 팀은 Kinesis 및 Redshift와 같은 다양한 구성 요소에서 애플리케이션 성능에 대한 정확한 통찰력을 얻을 수 있습니다. 이 사전 예방적인 접근 방식은 특정 성능 임계값에 도달했을 때 자동으로 스케일링 작업을 트리거할 수 있는 알람을 설정할 수 있게 하여 애플리케이션의 높은 가용성과 반응성을 보장합니다.",
        "Other Options": [
            "AWS X-Ray를 사용하여 데이터 요청을 추적하는 것은 요청 흐름과 대기 시간에 대한 통찰력을 제공할 수 있지만, 스케일링 메트릭을 모니터링하거나 자동 스케일링이 효과적으로 트리거되도록 보장하는 필요를 직접적으로 해결하지는 않습니다.",
            "CloudWatch Alarms를 통해 Lambda 함수 오류 및 EC2 인스턴스 메모리 사용량을 모니터링하는 것은 유용하지만, 분석 플랫폼의 전반적인 성능에 중요한 Kinesis 및 Redshift에 필요한 더 넓은 범위의 모니터링을 포함하지 않습니다.",
            "Kinesis에 대한 사용자 정의 메트릭을 생성하고 미리 정의된 임계값에 따라 수동으로 스케일링 정책을 트리거하는 것은 모니터링에 도움이 될 수 있지만, 반응형 시스템에 필요한 자동화가 부족하여 성능 문제가 발생할 때 스케일링 작업의 지연을 초래할 수 있습니다."
        ]
    },
    {
        "Question Number": "46",
        "Situation": "개발자가 Amazon S3 버킷에 저장된 파일을 관리하는 프로젝트에서 작업하고 있습니다. AWS CLI 명령 aws s3 ls를 사용하여 버킷의 내용을 나열하는 동안, 개발자는 기본 출력 형식이 사용자 친화적이지 않다는 것을 깨닫습니다. 출력의 가독성을 높이기 위해, 개발자는 결과를 보다 조직적이고 구조화된 형식으로 표시할 수 있는 특정 명령줄 인터페이스(CLI) 옵션을 찾고 있습니다.",
        "Question": "개발자가 aws s3 ls 명령의 출력을 가독성과 이해도를 향상시키는 표 형식으로 표시하기 위해 어떤 특정 CLI 옵션을 사용해야 합니까?",
        "Options": {
            "1": "--output text 옵션, 특별한 구조 없이 일반 텍스트 출력 형식을 제공합니다.",
            "2": "--output json 옵션, 프로그래밍적 접근에 이상적인 구조화된 JSON 형식으로 출력을 반환합니다.",
            "3": "--output yaml 옵션, 구성 파일에 자주 사용되는 사람이 읽기 쉬운 YAML 형식으로 출력을 제공합니다.",
            "4": "--output table 옵션, 가독성과 조직성을 향상시키는 시각적으로 구조화된 표 형식으로 출력을 형식화합니다."
        },
        "Correct Answer": "--output table 옵션, 가독성과 조직성을 향상시키는 시각적으로 구조화된 표 형식으로 출력을 형식화합니다.",
        "Explanation": "--output table 옵션이 정답입니다. 이 옵션은 aws s3 ls 명령의 출력을 구조화된 표 형식으로 명시적으로 형식화하여 개발자가 S3 버킷의 내용을 한눈에 쉽게 읽고 해석할 수 있도록 합니다. 이 옵션은 대량의 데이터를 처리할 때 특히 유용하며, 정보를 명확하게 행과 열로 정리합니다.",
        "Other Options": [
            "--output text 옵션은 구조가 없는 간단한 일반 텍스트 출력을 제공하므로 결과를 효과적으로 읽고 분석하기 어렵습니다.",
            "--output json 옵션은 구조화된 출력 형식을 제공하지만, 주로 프로그래밍적 접근을 위해 설계되어 있어 개발자가 요구하는 가독성 향상에 부합하지 않습니다.",
            "--output yaml 옵션은 사람이 읽기 쉬운 형식을 제공하지만, 표 형식의 데이터를 표시하도록 설계되지 않았습니다. 대신 구성 설정에 더 적합하며 S3 내용 목록의 가시성을 향상시키지 않을 수 있습니다."
        ]
    },
    {
        "Question Number": "47",
        "Situation": "소프트웨어 엔지니어가 Amazon ECS를 사용하여 마이크로서비스 애플리케이션을 배포하고 있으며, 관련된 컨테이너의 작업 정의를 정의하고 있습니다.",
        "Question": "Amazon ECS에서 작업 정의를 정의할 때, 다음 중 컨테이너 정보 구성의 일부가 아닌 것은 무엇입니까?",
        "Options": {
            "1": "배포에 사용할 컨테이너를 지정하는 Docker 이미지",
            "2": "작업 실행 중 권한을 부여할 IAM 역할",
            "3": "로그가 전송되고 저장될 위치를 결정하는 로깅 구성",
            "4": "애플리케이션 데이터의 구조를 설명하는 데이터베이스 스키마"
        },
        "Correct Answer": "애플리케이션 데이터의 구조를 설명하는 데이터베이스 스키마",
        "Explanation": "데이터베이스 스키마는 애플리케이션의 데이터 구조와 관련이 있으며, Amazon ECS 작업 정의의 컨테이너 정보 구성의 일부가 아닙니다. 다른 옵션들은 ECS 환경 내에서 컨테이너가 어떻게 작동하는지를 정의하는 필수 구성 요소입니다.",
        "Other Options": [
            "Docker 이미지는 실제 환경과 컨테이너에서 실행될 애플리케이션 코드를 정의하므로 작업 정의의 중요한 부분입니다.",
            "IAM 역할은 작업이 다른 AWS 서비스와 안전하게 상호작용할 수 있도록 하므로 컨테이너 구성에 포함됩니다.",
            "로깅 구성은 애플리케이션 모니터링 및 문제 해결에 필요하며, 로그가 어떻게 처리되는지를 지정하는 중요한 측면입니다."
        ]
    },
    {
        "Question Number": "48",
        "Situation": "한 회사가 Amazon S3 Glacier에 자주 접근하지 않는 대량의 데이터를 아카이브하고 있으며, 이는 저렴한 비용으로 장기 데이터 저장에 적합한 솔루션입니다. 그러나 이번 경우, 회사는 중요한 분석을 위해 10GB의 특정 데이터 세트를 긴급하게 검색해야 하는 상황에 직면했습니다. 그들은 S3 Glacier에서 다양한 검색 옵션이 있다는 것을 알고 있으며, 일반적으로 비용 고려가 중요하지만 이번 경우에는 속도가 가장 중요합니다. 그들은 데이터를 가능한 한 빨리 검색하기 위해 옵션을 신중하게 고려해야 합니다.",
        "Question": "상황의 긴급성을 고려할 때, 회사가 중요한 분석을 위해 10GB 데이터 세트를 가능한 한 빨리 검색하기 위해 선택해야 할 S3 Glacier 검색 옵션은 무엇입니까?",
        "Options": {
            "1": "신속 검색",
            "2": "표준 검색",
            "3": "대량 검색",
            "4": "온디맨드 검색"
        },
        "Correct Answer": "신속 검색",
        "Explanation": "Amazon S3 Glacier의 신속 검색 옵션은 데이터에 빠르게 접근해야 하는 상황을 위해 특별히 설계되었습니다. 이 옵션은 사용자가 몇 분 내에 데이터를 검색할 수 있도록 하여, 중요한 분석을 위해 10GB 데이터 세트를 긴급하게 필요로 하는 회사에 가장 적합한 선택입니다. 이 옵션은 비용보다 속도를 우선시하여 회사의 현재 요구에 완벽하게 부합합니다.",
        "Other Options": [
            "표준 검색은 일반적으로 완료하는 데 몇 시간이 걸리므로 회사의 긴급한 데이터 세트 접근 요구를 충족하지 않습니다.",
            "대량 검색은 더 낮은 비용으로 대량의 데이터를 검색하기 위해 설계되었지만, 12시간 이상 걸릴 수 있어 즉각적인 접근 요구에 적합하지 않습니다.",
            "온디맨드 검색은 S3 Glacier의 표준 옵션이 아니며, 필요에 따라 데이터를 검색할 수 있는 일반적인 능력을 나타냅니다. 따라서 검색 속도나 방법을 지정하지 않습니다."
        ]
    },
    {
        "Question Number": "49",
        "Situation": "개발자가 다양한 AWS 서비스 간의 요청 흐름을 추적하기 위해 주석을 추가하여 분산 애플리케이션의 관찰 가능성을 향상시키고 있습니다. 이 과정은 개발자가 요청 경로를 시각화하고 성능 문제를 효과적으로 진단할 수 있도록 보장하는 데 중요합니다. 적절한 도구와 관행을 구현함으로써 개발자는 마이크로서비스 간의 요청 처리 방식에 대한 더 깊은 통찰력을 얻고, 궁극적으로 애플리케이션의 성능과 신뢰성을 향상시키는 것을 목표로 하고 있습니다.",
        "Question": "개발자가 분산 AWS 아키텍처에서 서비스를 효과적으로 추적하기 위해 주석을 추가하기 위해 따라야 할 모범 사례는 무엇입니까?",
        "Options": {
            "1": "Amazon CloudWatch Logs Insights를 사용하여 로그 항목에 수동으로 주석을 태그합니다.",
            "2": "애플리케이션 코드에 AWS X-Ray SDK를 통합하여 자동으로 주석을 추가하고 요청을 추적합니다.",
            "3": "추적 서비스를 사용하지 않고 추적 정보를 포함하는 사용자 정의 로깅 문을 구현합니다.",
            "4": "Amazon SNS를 활용하여 구독자에게 추적 주석을 게시합니다."
        },
        "Correct Answer": "애플리케이션 코드에 AWS X-Ray SDK를 통합하여 자동으로 주석을 추가하고 요청을 추적합니다.",
        "Explanation": "AWS X-Ray SDK를 애플리케이션 코드에 통합하면 요청의 자동 계측이 가능합니다. 이는 SDK가 추적 데이터와 주석 생성을 처리하여 다양한 AWS 서비스 간의 요청 흐름에 대한 보다 포괄적이고 정확한 뷰를 제공함을 의미합니다. 이로 인해 추적 프로세스가 간소화되고 수동 개입 없이 성능 병목 현상을 진단하기가 더 쉬워집니다.",
        "Other Options": [
            "Amazon CloudWatch Logs Insights를 사용하여 로그 항목에 수동으로 주석을 태그하는 것은 비효율적입니다. 이는 수동 노력이 필요하고 AWS X-Ray와 같은 전용 추적 도구가 제공하는 자동화가 부족합니다.",
            "추적 서비스를 사용하지 않고 추적 정보를 포함하는 사용자 정의 로깅 문을 구현하는 것은 요청 흐름에 대한 전체적인 뷰를 제공하지 않습니다. 이는 전용 추적 도구가 제공할 수 있는 통합된 뷰가 부족하기 때문입니다.",
            "Amazon SNS를 활용하여 구독자에게 추적 주석을 게시하는 것은 요청을 추적하는 데 적합하지 않습니다. SNS는 주로 메시징 및 알림을 위해 설계되었으며, 상세한 추적 기능을 제공하기 위한 것이 아닙니다."
        ]
    },
    {
        "Question Number": "50",
        "Situation": "한 회사가 모바일 애플리케이션의 사용자 인증 관리를 위해 Amazon Cognito를 사용하고 있습니다. 이는 사용자 데이터에 대한 안전한 접근을 보장하는 데 중요합니다. 개발 팀은 특정 인증 및 권한 부여 요구 사항을 가장 잘 충족하기 위해 사용자 풀과 아이덴티티 풀 중에서 선택해야 하는 중요한 결정을 내리고 있습니다. 각 옵션의 고유한 기능을 이해하는 것은 강력한 사용자 관리 시스템을 구현하는 데 필수적입니다.",
        "Question": "Amazon Cognito에서 사용자 풀과 아이덴티티 풀의 역할과 기능을 정확하게 비교하여 인증 프로세스에서의 각자의 목적을 강조하는 진술은 무엇입니까?",
        "Options": {
            "1": "사용자 풀은 인증을 제공하고, 아이덴티티 풀은 권한 부여를 제공합니다.",
            "2": "사용자 풀은 사용자 역할을 관리하고, 아이덴티티 풀은 사용자 가입 및 로그인을 처리합니다.",
            "3": "아이덴티티 풀은 사용자 자격 증명을 저장하고, 사용자 풀은 AWS 리소스에 대한 접근을 관리합니다.",
            "4": "아이덴티티 풀은 연합된 아이덴티티에 사용되고, 사용자 풀은 SAML 기반 인증을 위해 사용됩니다."
        },
        "Correct Answer": "사용자 풀은 인증을 제공하고, 아이덴티티 풀은 권한 부여를 제공합니다.",
        "Explanation": "Amazon Cognito의 사용자 풀은 주로 사용자 인증을 담당하며, 여기에는 가입 및 로그인 프로세스가 포함됩니다. 반면 아이덴티티 풀은 인증된 사용자가 AWS 리소스에 접근할 수 있도록 권한 부여를 제공합니다. 이 구분은 개발자가 안전하고 효율적인 사용자 관리 시스템을 설정할 때 매우 중요합니다.",
        "Other Options": [
            "이 옵션은 잘못되었습니다. 사용자 풀은 사용자 가입 및 로그인을 담당하며, 사용자 역할 관리는 일반적으로 아이덴티티 풀과 관련된 기능입니다.",
            "이 옵션은 잘못되었습니다. 아이덴티티 풀은 사용자 자격 증명을 저장하지 않으며, 대신 사용자 풀은 사용자 자격 증명 및 프로필 데이터를 관리하고, 아이덴티티 풀은 인증된 사용자의 AWS 리소스 접근을 관리합니다.",
            "이 옵션은 사용자 풀과 아이덴티티 풀의 기능을 잘못 설명하고 있습니다. 아이덴티티 풀은 연합된 아이덴티티를 촉진하지만, 사용자 풀은 SAML 기반 인증에 국한되지 않으며 OAuth 및 기타 인증 방법도 지원합니다."
        ]
    },
    {
        "Question Number": "51",
        "Situation": "한 회사가 애플리케이션의 새 버전을 배포하고 있으며, 배포 프로세스가 관찰 가능하도록 하여 팀이 배포 중 발생하는 문제를 추적하고 진단할 수 있도록 하기를 원합니다. 그들은 배포 워크플로우와 애플리케이션 동작을 동시에 모니터링하기 위해 추적을 구현해야 합니다.",
        "Question": "회사가 배포 프로세스와 애플리케이션 동작 모두에 대한 추적을 구현하기 위해 사용해야 할 AWS 서비스 및 도구의 조합은 무엇입니까?",
        "Options": {
            "1": "AWS CodeDeploy 및 AWS CloudTrail",
            "2": "AWS CodePipeline 및 Amazon CloudWatch Logs",
            "3": "AWS CodePipeline과 AWS X-Ray 통합",
            "4": "AWS CodeBuild 및 AWS X-Ray"
        },
        "Correct Answer": "AWS CodePipeline과 AWS X-Ray 통합",
        "Explanation": "AWS CodePipeline은 애플리케이션의 빌드, 테스트 및 릴리스 단계를 자동화하는 지속적 배포 서비스를 제공합니다. AWS X-Ray를 통합함으로써 회사는 배포 중 애플리케이션에 대한 요청을 추적할 수 있어 성능을 모니터링하고 실시간으로 문제를 식별할 수 있습니다. 이 도구들은 배포 프로세스와 애플리케이션 동작 모두를 추적하기 위한 포괄적인 솔루션을 제공합니다.",
        "Other Options": [
            "AWS CodeDeploy와 AWS CloudTrail은 애플리케이션 동작에 대한 필요한 추적 기능을 제공하지 않습니다. CloudTrail은 주로 API 활동 로깅에 사용되며, 애플리케이션 성능의 실시간 모니터링에는 적합하지 않습니다.",
            "AWS CodePipeline과 Amazon CloudWatch Logs는 배포 이벤트를 추적할 수 있지만, 문제 진단에 필수적인 애플리케이션 요청 및 상호작용에 대한 상세한 추적 기능을 제공하지 않습니다.",
            "AWS CodeBuild와 AWS X-Ray는 빌드 프로세스와 추적에 중점을 두지만, 배포 워크플로우를 직접적으로 다루지 않으므로 전체 배포 생애 주기를 모니터링하는 데 적합하지 않습니다."
        ]
    },
    {
        "Question Number": "52",
        "Situation": "개발자가 사용자 제출 데이터를 Amazon S3에 저장하는 기능을 구현하고 있습니다. 데이터 무결성과 일관성을 보장하기 위해 개발자는 데이터를 저장소에 저장하기 전에 직렬화해야 합니다.",
        "Question": "개발자가 데이터 저장소에 지속성을 제공하기 위해 따라야 할 프로세스는 무엇입니까?",
        "Options": {
            "1": "S3에 저장하기 전에 AWS KMS를 사용하여 데이터를 암호화합니다.",
            "2": "데이터를 JSON 형식으로 직렬화하고 S3 버킷에 업로드합니다.",
            "3": "S3에 업로드하기 전에 저장 비용을 줄이기 위해 데이터를 압축합니다.",
            "4": "처리하기 전에 Amazon SQS를 사용하여 데이터를 큐에 넣습니다."
        },
        "Correct Answer": "데이터를 JSON 형식으로 직렬화하고 S3 버킷에 업로드합니다.",
        "Explanation": "데이터를 JSON 형식으로 직렬화하면 개발자가 복잡한 데이터 구조를 쉽게 저장하고 검색할 수 있는 평면 형식으로 변환할 수 있습니다. 이 과정은 데이터에 대한 지속성을 제공하는 데 필수적이며, 나중에 접근할 때 데이터를 정확하게 재구성할 수 있도록 보장합니다.",
        "Other Options": [
            "데이터를 암호화하는 것은 보안에 중요하지만, 직렬화 없이 단독으로는 지속성이나 데이터 무결성을 보장하지 않습니다.",
            "데이터를 압축하면 저장 비용을 줄이는 데 도움이 될 수 있지만, 데이터 검색 및 일관성을 위한 구조화된 형식의 필요성을 해결하지 않습니다.",
            "Amazon SQS를 사용하는 것은 메시징과 관련이 있으며 S3에서 데이터 지속성을 직접 제공하지 않습니다. 이는 저장보다는 임시 데이터 처리를 위한 것입니다."
        ]
    },
    {
        "Question Number": "53",
        "Situation": "개발자가 소스 코드를 관리하기 위해 Git을 통해 AWS CodeCommit 리포지토리에 접근하는 임무를 맡았습니다. 개발자는 IAM 사용자 계정을 사용하고 있으며, HTTPS 프로토콜을 통해 접근의 보안을 보장하는 데 주의를 기울이고 있습니다. 이는 암호화된 통신으로 자주 선호됩니다.",
        "Question": "개발자가 HTTPS를 통해 연결의 보안을 보장하면서 리포지토리에 적절하게 접근하기 위해 어떤 구체적인 단계를 밟아야 합니까?",
        "Options": {
            "1": "SSH 프로토콜을 사용하여 연결한 다음 IAM 사용자의 공개 키를 리포지토리에 안전하게 연결하여 연결을 설정합니다.",
            "2": "IAM 사용자를 위한 Git 자격 증명을 설정하여 HTTPS 접근을 구성하고, 인증을 위해 안전한 사용자 이름과 비밀번호 조합을 사용합니다.",
            "3": "AWS CLI를 사용하여 추가 구성이나 설정 조정 없이 리포지토리를 직접 클론합니다.",
            "4": "리포지토리 설정을 변경하여 공개 접근을 활성화하고, 표준 Git 명령을 사용하여 모든 클라이언트에서 직접 상호작용합니다."
        },
        "Correct Answer": "IAM 사용자를 위한 Git 자격 증명을 설정하여 HTTPS 접근을 구성하고, 인증을 위해 안전한 사용자 이름과 비밀번호 조합을 사용합니다.",
        "Explanation": "IAM 사용자를 사용하여 Git으로 AWS CodeCommit 리포지토리에 안전하게 접근하기 위한 모범 사례는 HTTPS 접근을 위해 특별히 설계된 Git 자격 증명을 설정하는 것입니다. 이는 안전한 사용자 이름과 비밀번호를 생성하는 것을 포함하며, 이를 통해 개발자는 보안을 손상시키지 않고 인증할 수 있으며, 데이터 전송 중 연결이 암호화된 상태로 유지됩니다.",
        "Other Options": [
            "이 옵션은 SSH 프로토콜을 사용하면 개발자가 SSH 키를 설정해야 하므로 HTTPS 접근 요구 사항과 모순되기 때문에 잘못된 것입니다. 또한 SSH 접근은 HTTPS와 같은 방식으로 IAM 사용자 자격 증명을 직접 포함하지 않습니다.",
            "이 옵션은 처음에는 실행 가능해 보일 수 있지만, HTTPS 접근을 위한 사용자 이름과 비밀번호 조합을 사용하는 것은 IAM 사용자와 특별히 연관된 Git 자격 증명의 적절한 구성이 필요하다는 점을 주목해야 합니다. 이 옵션은 이를 명확히 하지 않습니다.",
            "이 옵션은 AWS CLI가 CodeCommit과의 상호작용을 용이하게 할 수 있지만, Git을 통해 리포지토리에 안전하게 접근하는 방법을 제공하지 않으며, 상황에서 요구하는 HTTPS를 사용하지 않습니다."
        ]
    },
    {
        "Question Number": "54",
        "Situation": "개발자가 데이터에 대한 저지연 접근이 필요하고 초당 수백만 건의 요청을 지원해야 하는 새로운 애플리케이션을 설계하고 있습니다. 애플리케이션은 예측 가능한 트래픽 패턴을 가지고 있으며, 비용 최적화가 우선 사항입니다.",
        "Question": "이러한 요구 사항에 가장 잘 맞는 AWS 데이터베이스 옵션은 무엇입니까?",
        "Options": {
            "1": "Amazon DynamoDB with DAX",
            "2": "Amazon RDS with Multi-AZ Deployment",
            "3": "Amazon ElastiCache for Redis",
            "4": "Amazon Aurora with Read Replicas"
        },
        "Correct Answer": "Amazon DynamoDB with DAX",
        "Explanation": "Amazon DynamoDB with DAX(DynamoDB Accelerator)는 인메모리 캐싱을 제공하여 읽기 작업에 대해 마이크로초 응답 시간을 제공하므로 저지연 접근에 이상적입니다. 초당 수백만 건의 요청을 처리할 수 있으며, 예측 가능한 트래픽 패턴을 위해 설계되어 개발자의 요구 사항에 완벽하게 맞습니다.",
        "Other Options": [
            "Amazon RDS with Multi-AZ Deployment는 주로 고가용성과 장애 조치 지원에 중점을 두며, 저지연 접근 및 수백만 건의 요청에 대한 확장성보다는 그에 중점을 두고 있습니다.",
            "Amazon ElastiCache for Redis는 훌륭한 캐싱 솔루션이지만 주 데이터베이스 옵션이 아니며, 성능을 개선하기 위해 데이터베이스를 보완하는 역할을 합니다.",
            "Amazon Aurora with Read Replicas는 읽기를 확장할 수 있지만, 특히 쓰기 중심 애플리케이션의 경우 DynamoDB만큼 저지연 요구 사항을 효과적으로 충족하지 못할 수 있습니다."
        ]
    },
    {
        "Question Number": "55",
        "Situation": "클라우드 컴퓨팅 분야에서 AWS는 개발자가 인프라를 효율적으로 관리할 수 있도록 다양한 도구와 프레임워크를 제공합니다. 그 중 하나가 AWS Serverless Application Model (SAM)으로, 서버리스 애플리케이션을 구축하는 과정을 간소화합니다. AWS CloudFormation은 구조화된 방식으로 리소스를 배포하는 강력한 도구이지만, SAM은 표준 CloudFormation 템플릿과 구별되는 특정 기능과 선언적 구문을 도입합니다. 이러한 차이를 이해하는 것은 AWS 서비스를 효과적으로 활용하려는 개발자에게 매우 중요합니다.",
        "Question": "서버리스 애플리케이션의 맥락에서 SAM의 고유한 기능을 강조하며 파일을 AWS SAM 템플릿으로 식별하는 특정 선언 또는 기능은 무엇입니까?",
        "Options": {
            "1": "AWS::CloudFormation 구문 사용",
            "2": "Transform: AWS::Serverless-2016-10-31 선언",
            "3": "AWS::Serverless::Lambda 구문 사용",
            "4": "Resources 및 Outputs 섹션 포함"
        },
        "Correct Answer": "Transform: AWS::Serverless-2016-10-31 선언",
        "Explanation": "'Transform: AWS::Serverless-2016-10-31' 선언은 파일을 AWS SAM 템플릿으로 구체적으로 식별하는 요소입니다. 이 선언은 SAM 프레임워크가 템플릿을 처리할 수 있도록 하며, 개발자가 표준 CloudFormation 템플릿에서는 사용할 수 없는 SAM 전용 리소스 및 기능을 사용할 수 있게 합니다.",
        "Other Options": [
            "AWS::CloudFormation 구문 사용은 AWS SAM과 CloudFormation 템플릿 모두에 공통적이므로 SAM 템플릿을 CloudFormation 템플릿과 구별하지 않습니다.",
            "AWS::Serverless::Lambda 구문 사용은 서버리스 리소스를 나타내지만 Transform 선언 없이 파일을 AWS SAM 템플릿으로 식별하지는 않습니다.",
            "Resources 및 Outputs 섹션 포함은 CloudFormation과 SAM 템플릿 모두에서 표준 관행이므로 두 템플릿을 구별하는 데 도움이 되지 않습니다."
        ]
    },
    {
        "Question Number": "56",
        "Situation": "개발자는 Amazon SQS 큐와 상호작용하여 수신 메시지를 처리하는 AWS Lambda 함수를 구축하고 있습니다. 애플리케이션의 일시적인 실패에 대한 복원력을 높이고 메시지 처리의 신뢰성을 보장하기 위해 개발자는 내결함성 설계 패턴을 구현해야 합니다.",
        "Question": "개발자가 신뢰할 수 있는 메시지 처리를 보장하고 일시적인 실패에 대한 복원력을 확보하기 위해 어떤 설계 패턴을 도입해야 합니까?",
        "Options": {
            "1": "실패한 메시지 처리를 위한 지수 백오프 및 지터를 사용하여 재시도를 구현하여 성공률을 높입니다.",
            "2": "단일 처리 스레드를 사용하여 메시지를 순차적으로 처리하여 각 메시지가 중복 없이 개별적으로 처리되도록 합니다.",
            "3": "중복 메시지 처리를 방지하기 위해 자동 재시도를 비활성화하여 워크플로를 단순화하고 잠재적인 오류를 줄입니다.",
            "4": "Lambda 함수를 고정된 수의 동시 실행으로 확장하여 수신 메시지에 대한 안정적인 처리 속도를 유지합니다."
        },
        "Correct Answer": "실패한 메시지 처리를 위한 지수 백오프 및 지터를 사용하여 재시도를 구현하여 성공률을 높입니다.",
        "Explanation": "지수 백오프 및 지터를 사용한 재시도 구현은 Lambda 함수가 SQS 큐에서 메시지를 처리할 때 일시적인 실패를 우아하게 처리할 수 있도록 합니다. 이 접근 방식은 연속 재시도 간의 대기 시간을 늘려 성공적인 메시지 처리 가능성을 높이며, 지터는 여러 재시도가 동시에 발생하는 것을 방지하여 다운스트림 서비스가 과부하되는 위험을 최소화합니다.",
        "Other Options": [
            "단일 처리 스레드를 사용하여 메시지를 순차적으로 처리하면 비효율적인 처리와 지연이 증가할 수 있으며, 특히 부하가 높은 경우에는 내결함성을 제공하지 못하고 실패가 발생하면 처리되지 않은 메시지가 남을 수 있습니다.",
            "자동 재시도를 비활성화하면 워크플로를 단순화할 수 있지만, 일시적인 실패 동안 메시지 손실의 위험이 크게 증가합니다. 메시지 처리가 실패하면 재시도되지 않아 데이터 손실 및 애플리케이션의 불일치가 발생할 수 있습니다.",
            "Lambda 함수를 고정된 수의 동시 실행으로 확장하면 부하를 관리하는 데 도움이 될 수 있지만 일시적인 실패 문제를 직접적으로 해결하지는 않습니다. 재시도 전략이 없으면 메시지가 여전히 처리되지 않고 재처리 시도가 이루어지지 않을 수 있습니다."
        ]
    },
    {
        "Question Number": "57",
        "Situation": "클라우드 컴퓨팅 환경에서 개발자는 Amazon ECS를 사용하여 애플리케이션 배포를 최적화하려고 합니다. 그들은 구성 노력을 최소화하면서 효율적인 리소스 활용을 보장하는 작업 배치 전략을 선택해야 합니다.",
        "Question": "어떤 Amazon ECS 작업 배치 전략이 사용 가능한 인스턴스에 작업을 무작위로 할당하고 최소한의 구성을 요구하며, 모든 작업이 실행에 충분한 리소스를 가진 인스턴스에 예약되도록 보장합니까?",
        "Options": {
            "1": "binpack 전략은 작업을 더 적은 인스턴스에 집중시켜 리소스 활용을 극대화하지만 구성을 복잡하게 만듭니다.",
            "2": "random 전략은 인스턴스에 작업을 편향 없이 분배하며 구성하기 쉬워 이 시나리오에 이상적입니다.",
            "3": "spread 전략은 지정된 그룹의 모든 인스턴스에 작업을 고르게 분배하지만 더 자세한 구성이 필요합니다.",
            "4": "host 전략은 특정 호스트의 리소스를 기반으로 작업을 배치하며, 이는 복잡할 수 있고 덜 무작위적입니다."
        },
        "Correct Answer": "random 전략은 인스턴스에 작업을 편향 없이 분배하며 구성하기 쉬워 이 시나리오에 이상적입니다.",
        "Explanation": "Amazon ECS의 무작위 배치 전략은 사용 가능한 인스턴스에 작업을 비결정적으로 할당하도록 설계되었습니다. 이 접근 방식은 구성과 관련된 관리 부담을 최소화하면서 작업이 효과적으로 운영하는 데 필요한 적절한 리소스를 가진 인스턴스에 할당되도록 보장합니다.",
        "Other Options": [
            "binpack 전략은 작업을 최소한의 인스턴스에 배치하여 리소스 사용을 최적화하는 데 중점을 두므로 구성 노력을 최소화하는 데 덜 이상적입니다.",
            "spread 전략은 내결함성을 위해 작업을 인스턴스에 고르게 분배하는 것을 목표로 하며, 무작위 접근 방식에 비해 올바르게 설정하기 위해 더 많은 구성이 필요할 수 있습니다.",
            "host 전략은 작업 배치를 위해 특정 호스트 리소스를 사용하므로 복잡성이 증가하고 이 시나리오에서 요구되는 무작위성을 보장하지 않습니다."
        ]
    },
    {
        "Question Number": "58",
        "Situation": "개발자는 사용자 업로드 파일을 저장하기 위해 Amazon S3를 활용하고, 이러한 파일의 전송 속도와 성능을 향상시키기 위해 Amazon CloudFront를 콘텐츠 전송 네트워크(CDN)로 사용하는 정교한 애플리케이션을 설계하는 과정에 있습니다. 애플리케이션의 특성상 특정 민감한 파일에 대한 접근 제한을 두는 것이 중요하며, 인증된 사용자만 해당 파일을 다운로드할 수 있도록 해야 합니다. 개발자는 이러한 파일을 안전하게 보호하고, 보안을 해치지 않으면서도 통제된 공유가 가능하도록 시간 제한이 있는 접근을 제공하는 강력한 솔루션을 구현하고자 합니다.",
        "Question": "개발자가 S3에 저장된 제한된 파일에 대해 안전하게 시간 제한이 있는 접근을 제공하기 위해 구현해야 할 기능은 무엇입니까?",
        "Options": {
            "1": "버킷에서 S3 공개 접근 차단을 활성화합니다.",
            "2": "AWS Identity and Access Management (IAM) 정책을 사용하여 접근을 제한합니다.",
            "3": "S3 객체에 대한 사전 서명된 URL을 생성합니다.",
            "4": "모든 요청에 대해 HTTPS를 요구하도록 CloudFront를 구성합니다."
        },
        "Correct Answer": "S3 객체에 대한 사전 서명된 URL을 생성합니다.",
        "Explanation": "S3 객체에 대한 사전 서명된 URL을 생성하는 것은 특정 파일에 대해 안전하고 시간 제한이 있는 접근을 제공하는 가장 적합한 솔루션입니다. 사전 서명된 URL은 AWS 사용자의 자격 증명을 사용하여 서명된 URL로, S3의 특정 객체에 대한 임시 접근을 허용합니다. 개발자는 URL의 만료 시간을 지정할 수 있어, 제한된 기간 동안만 접근이 허용되도록 하여 보안을 유지하면서 정당한 사용자가 파일을 다운로드할 수 있도록 합니다.",
        "Other Options": [
            "버킷에서 S3 공개 접근 차단을 활성화하는 것은 전체 버킷에 대한 공개 접근만 차단하며, 시간 제한이 있는 접근이나 인증된 사용자에 대한 제어를 제공하지 않습니다. 이 옵션은 시간 민감한 권한의 특정 요구에 적합하지 않습니다.",
            "AWS Identity and Access Management (IAM) 정책을 사용하여 접근을 제한하는 것은 기본적인 보안 관행이지만, 이 시나리오에서 요구되는 시간 제한이 있는 접근의 유연성을 제공하지 않습니다. IAM 정책은 더 정적이며 개별 파일에 대한 임시 접근을 제공하지 않습니다.",
            "모든 요청에 대해 HTTPS를 요구하도록 CloudFront를 구성하는 것은 전송 중 데이터의 보안을 강화하지만, 사용자 인증이나 시간 제한에 따라 특정 파일에 대한 접근을 제어할 필요를 해결하지 않습니다."
        ]
    },
    {
        "Question Number": "59",
        "Situation": "당신은 AWS Step Functions를 활용하여 작업의 순서를 조정하는 정교한 서버리스 애플리케이션을 설계하는 임무를 맡고 있습니다. 이 애플리케이션은 AWS Lambda 함수를 호출하고, 잠재적인 오류를 우아하게 관리하며, 성능을 최적화하기 위해 특정 작업을 병렬로 실행하는 등 다양한 작업을 수행해야 합니다. 이 워크플로를 효과적으로 구현하기 위해서는 분기 로직을 지원하고 작업의 병렬 실행을 허용하며 강력한 오류 처리 메커니즘을 통합할 수 있는 Step Functions의 최적 구성을 선택해야 합니다.",
        "Question": "AWS Step Functions에서 분기 로직과 작업의 병렬 실행을 효과적으로 구현하고, 워크플로 전반에 걸쳐 오류가 신뢰성 있게 처리되도록 하려면 어떤 구성을 사용해야 합니까?",
        "Options": {
            "1": "분기를 위해 Pass 상태를 사용하고, 오류 처리를 위해 Fail 상태를 사용하며, 병렬 처리를 위해 Map 상태를 사용합니다.",
            "2": "분기를 위해 Task 상태를 사용하고, 오류 처리를 위해 Catch 필드를 사용하며, 병렬 실행을 위해 Parallel 상태를 사용합니다.",
            "3": "Lambda 함수를 호출하기 위해 Lambda 상태를 사용하고, 분기를 위해 Choice 상태를 사용하며, 순차 실행을 위해 Wait 상태를 사용합니다.",
            "4": "병렬 실행을 위해 Task 상태를 사용하고, 오류 처리를 위해 Catch 필드를 사용하며, 워크플로를 종료하기 위해 Succeed 상태를 사용합니다."
        },
        "Correct Answer": "분기를 위해 Task 상태를 사용하고, 오류 처리를 위해 Catch 필드를 사용하며, 병렬 실행을 위해 Parallel 상태를 사용합니다.",
        "Explanation": "올바른 구성은 작업을 실행하기 위해 Task 상태를 사용하고, 실행 중 발생할 수 있는 오류를 관리하기 위해 Catch 필드를 사용하며, 여러 작업이 동시에 실행될 수 있도록 Parallel 상태를 사용하는 것입니다. 이 조합은 분기 로직을 효과적으로 구현하고, 병렬 실행을 지원하며, 발생하는 오류를 적절히 포착하고 처리하여 워크플로를 견고하고 효율적으로 만듭니다.",
        "Other Options": [
            "분기를 위해 Pass 상태를 사용하는 것은 동적 결정이나 작업 실행을 허용하지 않으며, Fail 상태는 오류를 처리하기 위한 좋은 선택이 아닙니다. Fail 상태는 워크플로를 종료하기 때문에 복구 메커니즘을 제공하지 않습니다.",
            "Lambda 상태는 Lambda 함수를 호출하는 데 사용할 수 있지만, 필요한 분기 기능을 제공하지 않습니다. Wait 상태는 작업 간의 지연을 위해 설계되었기 때문에 병렬 실행에 적합하지 않습니다.",
            "Task 상태는 실행에 사용할 수 있지만, 지정된 Parallel 상태 없이 병렬 실행만을 위해 사용하는 것은 진정한 병렬 실행 기능을 제공하지 않습니다. Succeed 상태는 오류 처리를 다루지 않고 단순히 워크플로의 끝을 표시합니다."
        ]
    },
    {
        "Question Number": "60",
        "Situation": "개발자는 DynamoDB 테이블을 설정하여 항목 변경 사항을 추적하고, 테이블에서 데이터 변경이 발생할 때마다 알림을 보내기 위해 Lambda 함수를 자동으로 트리거하도록 합니다. Lambda 함수는 변경된 항목의 이전 버전과 새 버전 모두에 접근해야 변경 사항을 정확하게 처리하고 적절한 알림을 보낼 수 있습니다.",
        "Question": "개발자가 Lambda 함수가 변경된 항목의 이전 버전과 새 버전 모두를 수신하도록 DynamoDB 스트림에 대해 어떤 StreamViewType을 구성해야 합니까?",
        "Options": {
            "1": "KEYS_ONLY - 이 옵션은 변경된 항목의 기본 키 속성만 캡처하며, 전체 데이터를 포함하지 않습니다.",
            "2": "NEW_IMAGE - 이 옵션은 변경된 항목의 새 버전만 캡처하며, 변경 전의 이전 데이터를 생략합니다.",
            "3": "OLD_IMAGE - 이 옵션은 변경된 항목의 이전 버전만 캡처하며, 변경 후 항목의 새 상태에 대한 정보를 제공하지 않습니다.",
            "4": "NEW_AND_OLD_IMAGES - 이 옵션은 변경된 항목의 새 버전과 이전 버전 모두를 캡처하여 Lambda 함수가 변경 사항을 이해하는 데 필요한 데이터를 제공합니다."
        },
        "Correct Answer": "NEW_AND_OLD_IMAGES - 이 옵션은 변경된 항목의 새 버전과 이전 버전 모두를 캡처하여 Lambda 함수가 변경 사항을 이해하는 데 필요한 데이터를 제공합니다.",
        "Explanation": "'NEW_AND_OLD_IMAGES' 옵션이 올바른 선택인 이유는 Lambda 함수가 항목의 이전 상태와 현재 상태 모두에 접근할 수 있도록 하기 때문입니다. 이는 함수가 데이터가 어떻게 수정되었는지에 따라 정보에 기반한 결정을 내리는 데 필수적이며, 변경 사항에 대한 정확한 알림을 가능하게 합니다.",
        "Other Options": [
            "'KEYS_ONLY' 옵션은 변경된 항목의 키만 제공하고 추가 데이터를 포함하지 않기 때문에 Lambda 함수의 요구 사항에 불충분합니다.",
            "'NEW_IMAGE' 옵션은 변경 후 항목의 새 상태만 포함하므로 이전 상태에 대한 맥락이 없어 Lambda 함수가 효과적으로 활용할 수 없습니다.",
            "'OLD_IMAGE' 옵션은 변경된 항목의 이전 버전만 제공하므로 수정 후의 현재 상태를 생략하여 전체 변경 사항을 이해하는 데 필수적인 정보를 제공합니다."
        ]
    },
    {
        "Question Number": "61",
        "Situation": "개발자가 전체 테이블에서 비키 속성에 대한 쿼리가 필요한 DynamoDB 테이블을 설계하고 있습니다. 애플리케이션은 최종 일관성을 허용할 수 있으며, 테이블은 이미 프로덕션에 존재합니다.",
        "Question": "이 시나리오에서 비키 속성을 쿼리하기 위한 최상의 인덱스는 무엇입니까?",
        "Options": {
            "1": "로컬 보조 인덱스 (LSI)",
            "2": "글로벌 보조 인덱스 (GSI)",
            "3": "인덱스 없이 파티션 키 및 정렬 키",
            "4": "병렬 스캔"
        },
        "Correct Answer": "글로벌 보조 인덱스 (GSI)",
        "Explanation": "글로벌 보조 인덱스 (GSI)는 비키 속성에 대한 쿼리를 허용하며, 전체 테이블을 아우를 수 있기 때문에 이 시나리오에 이상적입니다. 최종 일관성이 허용되므로 GSI는 기존 프로덕션 설정을 수용하면서 쿼리를 위한 유연성을 제공합니다.",
        "Other Options": [
            "로컬 보조 인덱스 (LSI)는 기본 테이블의 파티션 키에 연결되어 있으며, 전체 테이블에서 비키 속성을 쿼리하는 데 도움이 되지 않습니다.",
            "인덱스 없이 파티션 키 및 정렬 키를 사용하는 것은 쿼리 기능을 제한하며 비키 속성을 효과적으로 검색하는 것을 지원하지 않습니다.",
            "병렬 스캔은 데이터를 검색할 수 있지만 인덱스가 아니며, 대규모 데이터 세트에서 특정 비키 속성을 쿼리하는 데 비효율적입니다."
        ]
    },
    {
        "Question Number": "62",
        "Situation": "개발자가 DynamoDB를 사용하여 웹사이트 방문자 수를 추적하는 기능을 설계하고 있습니다. 시스템은 정확한 수치를 요구하지 않으며, 가끔 과다 집계 또는 과소 집계가 허용됩니다.",
        "Question": "개발자가 가끔의 부정확성을 수용하면서 효율적으로 방문자 수를 추적하기 위해 어떤 접근 방식을 사용해야 합니까?",
        "Options": {
            "1": "UpdateItem 작업을 사용하여 발생하는 대로 방문자 수를 신속하게 조정하는 원자 카운터를 구현합니다.",
            "2": "정해진 간격으로 방문자 수를 검색하고 업데이트하는 스캔 작업을 활용하여 데이터 처리를 최소화합니다.",
            "3": "DynamoDB Streams를 사용하여 변경 사항을 모니터링하고 기록된 이벤트에 따라 방문자 수를 동적으로 조정합니다.",
            "4": "조건부 업데이트를 활용하여 각 새로운 항목과 함께 방문자 수가 정확하게 유지되도록 합니다."
        },
        "Correct Answer": "UpdateItem 작업을 사용하여 발생하는 대로 방문자 수를 신속하게 조정하는 원자 카운터를 구현합니다.",
        "Explanation": "UpdateItem 작업과 함께 원자 카운터를 사용하는 것은 방문자 수를 추적하기 위한 최상의 접근 방식입니다. 이는 정확한 정밀도가 필요 없이 카운트를 효율적이고 실시간으로 업데이트할 수 있게 해줍니다. 이 방법은 가끔의 부정확성 요구 사항에 적합하며, 방문이 발생할 때 카운트를 신속하고 효과적으로 증가시킬 수 있도록 보장합니다.",
        "Other Options": [
            "방문자 수를 주기적으로 검색하고 업데이트하기 위해 스캔 작업을 사용하는 것은 비효율적이며, 모든 항목을 읽어야 하므로 느리고 자원 집약적일 수 있습니다, 특히 트래픽이 많은 경우.",
            "DynamoDB Streams를 사용하여 변경 사항을 모니터링하는 것은 단순한 방문자 수 집계에 불필요한 복잡성과 지연을 초래할 수 있습니다. 이는 주로 항목의 변경 사항을 캡처하기 위해 설계되었기 때문입니다.",
            "방문자 수를 유지하기 위해 조건부 업데이트를 활용하는 것은 성능 문제를 초래할 수 있습니다. 이는 업데이트 전에 조건을 확인해야 하므로, 정확한 수치가 중요하지 않은 시스템에서는 불필요합니다."
        ]
    },
    {
        "Question Number": "63",
        "Situation": "개발자가 Amazon S3 버킷에 대한 서버 액세스 로깅을 구성하여 버킷에 대한 액세스 요청을 추적하고 있습니다. 로그는 로깅되는 동일한 버킷에 저장되도록 설정되어 있습니다. 몇 주간의 로깅 활동 후, 버킷이 예상치 못하게 커지고 개발자가 예상하지 못한 높은 저장 비용이 발생했습니다.",
        "Question": "S3 버킷의 저장 크기 및 관련 비용의 예상치 못한 증가의 가장 가능성이 높은 원인은 무엇입니까?",
        "Options": {
            "1": "S3 버킷에 버전 관리가 활성화되어 있어 시간이 지남에 따라 로그 파일의 여러 버전이 축적되고 있습니다.",
            "2": "서버 액세스 로깅이 자신의 로그 항목을 재귀적으로 지속적으로 기록하여 로그의 기하급수적 성장을 초래하고 있습니다.",
            "3": "S3 버킷이 로그를 다른 저장 클래스으로 전환하여 비용을 관리하는 생애 주기 정책으로 구성되어 있습니다.",
            "4": "S3 Select가 로그 파일을 쿼리하는 데 사용되고 있어 로그 항목의 중복과 불필요한 저장 사용이 발생하고 있습니다."
        },
        "Correct Answer": "서버 액세스 로깅이 자신의 로그 항목을 재귀적으로 지속적으로 기록하여 로그의 기하급수적 성장을 초래하고 있습니다.",
        "Explanation": "S3 버킷 크기의 예상치 못한 증가의 가장 가능성이 높은 원인은 서버 액세스 로깅이 자신의 로그 항목을 기록하는 것입니다. 이 경우 로그에 대한 각 액세스 요청이 기록되어 재귀적인 로깅 효과가 발생하여 버킷에 저장되는 데이터 양이 빠르게 증가할 수 있습니다.",
        "Other Options": [
            "버전 관리는 여러 버전의 파일이 존재하게 할 수 있지만, 로그의 급격한 증가의 주요 원인은 아닙니다. 이 경우 자신의 항목을 로깅하는 재귀적인 성격이 더 중요합니다.",
            "생애 주기 정책은 로그를 더 저렴한 저장 클래스로 전환하여 저장 비용을 관리하는 데 도움이 될 수 있지만, 로그 크기의 갑작스러운 증가를 직접적으로 초래하지는 않습니다. 따라서 가장 가능성이 높은 원인은 아닙니다.",
            "S3 Select는 전체 객체를 다운로드할 필요 없이 S3에서 직접 데이터를 쿼리할 수 있지만, 로그 항목의 중복을 본질적으로 초래하지는 않습니다. 따라서 이 옵션은 예상치 못한 증가를 설명하지 않습니다."
        ]
    },
    {
        "Question Number": "64",
        "Situation": "개발자는 Amazon API Gateway와 AWS Lambda 함수를 활용하여 RESTful API를 설계하는 과정에 있습니다. 주요 목표는 API가 진화하는 요구 사항을 수용할 수 있도록 여러 버전을 지원하면서 기존 클라이언트와의 호환성을 유지하는 것입니다. 이는 현재 사용자나 그들의 API 상호작용에 방해가 되지 않는 신중한 버전 관리 접근이 필요합니다. 개발자는 API 설계 내에서 효과적으로 버전 관리를 구현하기 위한 다양한 옵션을 탐색하고 있습니다.",
        "Question": "개발자가 Amazon API Gateway에서 기존 클라이언트에 영향을 주지 않으면서 효과적인 API 버전 관리를 달성하기 위해 고려해야 할 접근 방식은 무엇입니까?",
        "Options": {
            "1": "각 API 버전에 대해 별도의 API Gateway를 사용합니다.",
            "2": "단일 API Gateway 내에 여러 단계를 배포하여 각 단계가 다른 버전을 나타내도록 합니다.",
            "3": "리소스 경로에 버전 번호를 포함합니다 (예: /v1/resource, /v2/resource).",
            "4": "쿼리 매개변수를 사용하여 API 버전을 지정합니다."
        },
        "Correct Answer": "리소스 경로에 버전 번호를 포함합니다 (예: /v1/resource, /v2/resource).",
        "Explanation": "리소스 경로에 버전 번호를 포함하는 것은 API 버전 관리에 널리 수용되는 관행입니다. 이 접근 방식은 클라이언트가 사용하고자 하는 API 버전을 명확히 지정할 수 있도록 하여, 기존 클라이언트가 중단 없이 계속 작동할 수 있도록 하고 새로운 클라이언트는 최신 기능과 개선 사항에 접근할 수 있도록 합니다. 또한 API 문서의 명확성과 조직성을 향상시킵니다.",
        "Other Options": [
            "각 버전에 대해 별도의 API Gateway를 사용하는 것은 관리 및 배포의 복잡성을 증가시킬 수 있으며, 각 버전은 별도의 구성 및 유지 관리가 필요하므로 비효율적입니다.",
            "단일 API Gateway 내에 여러 단계를 배포하는 것은 유효한 방법이지만, 버전 관리에 대한 혼란을 초래할 수 있으며, 서로 다른 버전 간의 명확한 구분을 허용하지 않을 수 있어 클라이언트가 잘못된 버전에 접근하는 문제를 일으킬 수 있습니다.",
            "쿼리 매개변수를 사용하여 API 버전을 지정하는 것은 클라이언트에게 덜 투명하고 직관적일 수 있습니다. 또한 제대로 관리되지 않으면 API 동작의 일관성을 해칠 수 있어 클라이언트가 상호작용하는 버전을 이해하기 어렵게 만들 수 있습니다."
        ]
    },
    {
        "Question Number": "65",
        "Situation": "개발자는 Amazon Web Services (AWS)와 작업하고 있으며 S3 PutObject 작업을 실행하는 데 어려움을 겪고 있습니다. 이 작업을 허용하는 정책을 첨부했음에도 불구하고 여전히 접근 거부 오류가 발생하고 있습니다. 이로 인해 권한 및 정책에 대한 혼란이 생겼으며, 근본적인 문제를 진단하기 위한 강력한 방법이 필요합니다. AWS의 신원 및 접근 관리의 복잡성을 이해하는 것은 이러한 문제를 해결하는 데 중요합니다.",
        "Question": "개발자가 S3 PutObject 작업의 문제를 효과적으로 식별하고 문제를 해결하기 위해 어떤 진단 도구나 방법을 사용해야 합니까?",
        "Options": {
            "1": "IAM 신뢰 정책",
            "2": "AWS IAM 정책 시뮬레이터",
            "3": "AWS 관리 콘솔",
            "4": "AWS STS AssumeRole"
        },
        "Correct Answer": "AWS IAM 정책 시뮬레이터",
        "Explanation": "AWS IAM 정책 시뮬레이터는 특정 작업에 대한 IAM 정책의 영향을 테스트하고 평가하기 위해 설계된 전문 도구입니다. 이 시뮬레이터를 사용하여 개발자는 S3 PutObject 작업의 세부 정보를 입력하고 첨부된 정책이 권한에 미치는 영향을 확인하여 접근 거부를 초래하는 불일치나 추가 정책이 있는지 식별할 수 있습니다.",
        "Other Options": [
            "IAM 신뢰 정책은 교차 계정 접근과 관련이 있으며 역할을 맡을 수 있는 대상을 정의하지만, S3의 PutObject와 같은 작업과 관련된 권한 오류를 구체적으로 진단하지는 않습니다.",
            "AWS 관리 콘솔은 AWS 서비스를 관리하기 위한 그래픽 인터페이스를 제공하지만 IAM 정책의 효과를 구체적으로 분석하거나 시뮬레이션하지 않으므로 권한 문제를 진단하는 데 가장 적합한 도구는 아닙니다.",
            "AWS STS AssumeRole은 역할을 맡기 위해 임시 보안 자격 증명을 얻는 데 사용되지만, 기존 IAM 정책 및 그 효과와 관련된 권한 문제를 직접적으로 진단하는 데 도움이 되지 않습니다."
        ]
    }
]