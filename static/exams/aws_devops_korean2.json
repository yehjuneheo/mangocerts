[
    {
        "Question Number": "1",
        "Situation": "글로벌 전자상거래 회사가 가용성과 복원력을 향상시키기 위해 AWS로 애플리케이션을 마이그레이션하고 있습니다. 그들의 아키텍처는 웹 애플리케이션 계층, 애플리케이션 서버 및 데이터베이스 계층으로 구성되어 있습니다. 그들은 재해 복구를 위해 여러 가용 영역(AZ)과 지역에서 솔루션이 높은 가용성을 유지하도록 보장하고자 합니다. DevOps 엔지니어로서 이러한 요구 사항을 충족하는 솔루션을 설계해야 합니다.",
        "Question": "이 시나리오에서 여러 AZ와 지역에서 높은 가용성과 복원력을 달성하기 위한 가장 효과적인 아키텍처는 무엇입니까?",
        "Options": {
            "1": "웹 애플리케이션 계층, 애플리케이션 서버 및 데이터베이스 계층을 단일 AWS 지역의 여러 AZ에 배포하고, 지역 장애 발생 시 Route 53을 사용하여 보조 지역으로 DNS 장애 조치를 수행합니다.",
            "2": "웹 애플리케이션 계층, 애플리케이션 서버 및 데이터베이스 계층을 여러 지역과 AZ에 배포하고, 재해 복구를 위해 Amazon RDS의 교차 지역 복제를 활용합니다.",
            "3": "웹 애플리케이션 계층을 한 지역에 배포하고, 애플리케이션 서버를 다른 지역에 배포하며, 정적 콘텐츠 전송을 위해 Amazon S3를 사용하고, 데이터베이스 계층은 단일 AZ에 호스팅하여 관리의 단순화를 꾀합니다.",
            "4": "웹 애플리케이션 계층과 애플리케이션 서버를 단일 AWS 지역의 여러 AZ에 배포하고, AWS Database Migration Service를 사용하여 데이터베이스 계층을 별도의 지역에 복제합니다."
        },
        "Correct Answer": "웹 애플리케이션 계층, 애플리케이션 서버 및 데이터베이스 계층을 여러 지역과 AZ에 배포하고, 재해 복구를 위해 Amazon RDS의 교차 지역 복제를 활용합니다.",
        "Explanation": "이 아키텍처는 모든 중요한 구성 요소가 여러 지역과 AZ에 분산되어 높은 가용성과 복원력을 제공합니다. Amazon RDS의 교차 지역 복제를 활용하면 지역 장애 발생 시 신속한 장애 조치를 가능하게 하는 강력한 재해 복구 솔루션을 제공합니다.",
        "Other Options": [
            "이 옵션은 단일 지역에만 초점을 맞추어 복원력과 가용성을 제한합니다. AWS Database Migration Service를 사용한 복제는 유익하지만, 높은 가용성 아키텍처에 필요한 수준의 재해 복구를 제공하지 않습니다.",
            "여러 AZ에 배포하는 것은 지역 내 가용성을 향상시키지만, 잠재적인 지역 장애를 해결하지는 않습니다. DNS 장애 조치는 복잡할 수 있으며, 전자상거래 애플리케이션에 필수적인 즉각적인 장애 조치를 제공하지 않을 수 있습니다.",
            "이 옵션은 가용성과 복원력을 크게 저하시킵니다. 데이터베이스 계층을 단일 AZ에 호스팅하면 다운타임의 위험이 증가하고, 적절한 장애 조치 메커니즘 없이 지역 간 구성 요소를 분리하는 것은 높은 가용성 요구 사항을 충족하지 않습니다."
        ]
    },
    {
        "Question Number": "2",
        "Situation": "한 회사는 여러 AWS 계정에 걸쳐 일관된 인프라 관리 전략을 구현하고자 합니다. DevOps 팀은 배포된 모든 리소스가 보안 기준 및 거버넌스 통제를 준수하도록 하면서 다양한 환경에서 쉽게 재사용될 수 있도록 해야 합니다. 이를 위해 AWS CloudFormation을 사용하는 것을 고려하고 있습니다.",
        "Question": "어떤 접근 방식이 팀이 거버넌스 통제 및 보안 기준을 강화하면서 중복 작업을 최소화하는 재사용 가능한 인프라 패턴을 생성하는 데 가장 적합합니까?",
        "Options": {
            "1": "AWS CDK를 사용하여 모든 인프라 리소스를 단일 모놀리식 애플리케이션으로 정의하고, 코드 리뷰를 통해 준수를 보장합니다.",
            "2": "각 환경에 대해 모든 리소스 정의를 포함하는 단일 CloudFormation 템플릿을 만들고, 보안 통제를 위한 인라인 정책을 포함합니다.",
            "3": "Terraform을 구현하여 인프라를 코드로 관리하고, 외부 정책-코드 도구를 사용하여 보안 기준을 정의합니다.",
            "4": "각 인프라 구성 요소에 대해 모듈화된 CloudFormation 템플릿을 개발하고, AWS Service Catalog와 통합하여 거버넌스 및 보안 기준을 강화합니다."
        },
        "Correct Answer": "각 인프라 구성 요소에 대해 모듈화된 CloudFormation 템플릿을 개발하고, AWS Service Catalog와 통합하여 거버넌스 및 보안 기준을 강화합니다.",
        "Explanation": "모듈화된 CloudFormation 템플릿을 사용하면 관심사를 분리할 수 있어 다양한 환경에서 구성 요소를 관리하고 재사용하기가 더 쉬워집니다. AWS Service Catalog와 통합하면 거버넌스 통제 및 보안 기준을 강화할 수 있는 방법을 제공하여 승인된 템플릿만 배포에 사용되도록 보장합니다.",
        "Other Options": [
            "각 환경에 대해 단일 CloudFormation 템플릿을 만드는 것은 중복 작업을 초래할 수 있으며, 모든 변경 사항이 여러 템플릿에 적용되어야 하므로 유지 관리가 더 어려워질 수 있습니다.",
            "모놀리식 애플리케이션에 대해 AWS CDK를 사용하는 것은 준수 및 거버넌스를 복잡하게 만들 수 있으며, 별도의 템플릿만큼의 모듈성과 재사용성을 제공하지 않을 수 있어 보안 기준 관리에 어려움을 초래할 수 있습니다.",
            "Terraform을 구현하면 워크플로우에 추가 도구가 도입되어 기존 AWS 서비스 및 거버넌스 모델과 일치하지 않을 수 있으므로, CloudFormation과 Service Catalog와 같은 AWS 네이티브 솔루션을 활용하는 것보다 최적이 아닐 수 있습니다."
        ]
    },
    {
        "Question Number": "3",
        "Situation": "한 회사는 Auto Scaling Group(ASG)을 사용하여 다양한 트래픽 부하에 동적으로 조정하는 애플리케이션을 관리하고 있습니다. DevOps 엔지니어는 유지 관리를 위해 인스턴스를 서비스에서 일시적으로 제거할 수 있도록 하면서 애플리케이션에 중단이 발생하지 않도록 해야 합니다. 또한 팀은 ASG의 시작 구성 업데이트 프로세스를 간소화하고자 합니다.",
        "Question": "DevOps 엔지니어가 ASG를 효과적으로 관리하고 이러한 요구 사항을 충족하기 위해 어떤 조치를 취해야 합니까?",
        "Options": {
            "1": "ASG에 대한 새로운 시작 구성을 만들고 update-auto-scaling-group 명령을 사용하여 모든 인스턴스에 새 구성을 적용합니다.",
            "2": "인스턴스가 종료되기 전에 일시 중지할 수 있도록 라이프사이클 훅을 구현하고, 기존 시작 구성을 삭제합니다.",
            "3": "enter-standby 명령을 사용하여 유지 관리를 위해 인스턴스를 대기 상태로 이동하고, 최신 애플리케이션 버전으로 시작 구성을 업데이트합니다.",
            "4": "exit-standby 명령을 사용하여 유지 관리 후 인스턴스를 다시 서비스로 가져오고, 실행 중인 인스턴스 수를 자동으로 조정하기 위해 스케일링 정책을 설정합니다."
        },
        "Correct Answer": "enter-standby 명령을 사용하여 유지 관리를 위해 인스턴스를 대기 상태로 이동하고, 최신 애플리케이션 버전으로 시작 구성을 업데이트합니다.",
        "Explanation": "enter-standby 명령을 사용하면 인스턴스를 유지 관리를 위해 서비스에서 일시적으로 제거하면서 애플리케이션이 계속 운영되도록 보장할 수 있습니다. 시작 구성을 업데이트하면 유지 관리 후에 시작되는 새로운 인스턴스가 최신 버전의 애플리케이션을 실행하도록 보장합니다.",
        "Other Options": [
            "라이프사이클 훅을 구현하는 것은 유지 관리를 위해 인스턴스를 대기 상태로 이동하는 필요를 직접적으로 해결하지 않습니다. 또한 기존 시작 구성을 삭제하면 최신 애플리케이션 버전으로 새로운 인스턴스를 생성할 수 없습니다.",
            "인스턴스를 서비스로 복귀시키기 위해 exit-standby 명령을 사용하는 것은 유효한 조치지만, 시작 구성을 업데이트하거나 유지 관리를 효과적으로 관리하는 필요를 해결하지 않습니다.",
            "새로운 시작 구성을 만드는 것은 중요하지만, 유지 관리를 위해 제거해야 하는 인스턴스에 대한 문제를 해결하지 않습니다. update-auto-scaling-group 명령만으로는 현재 실행 중인 인스턴스를 관리하는 데 도움이 되지 않습니다."
        ]
    },
    {
        "Question Number": "4",
        "Situation": "한 회사가 AWS 인프라 전반에 걸쳐 보안 이벤트를 모니터링하기 위해 Amazon CloudWatch Logs를 사용한 중앙 집중식 로깅 솔루션을 구현했습니다. 보안 팀은 잠재적인 보안 문제를 식별하고 산업 표준 준수를 보장하기 위해 이러한 로그를 정기적으로 분석해야 합니다. 그들은 안전한 환경을 유지하면서 로그와 메트릭을 집계하고 분석할 수 있는 효율적인 방법을 찾고 있습니다.",
        "Question": "DevOps 엔지니어가 준수를 보장하면서 로그와 보안 발견 사항을 효과적으로 분석하기 위해 어떤 조치를 취해야 합니까? (두 가지 선택)",
        "Options": {
            "1": "Amazon GuardDuty를 설정하여 악의적인 활동과 무단 행동을 지속적으로 모니터링합니다.",
            "2": "AWS CloudTrail을 활성화하여 모든 API 호출을 기록하고 Amazon CloudWatch Logs와 통합합니다.",
            "3": "AWS Config 규칙을 구현하여 보안 표준에 대한 준수를 평가하고 변경 사항을 기록합니다.",
            "4": "새 로그 항목이 생성될 때마다 보안 발견 사항에 대한 경고를 보내는 Lambda 함수를 생성합니다.",
            "5": "Amazon Athena를 활용하여 CloudWatch Logs에서 SQL 쿼리를 실행하여 심층 분석을 수행합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "AWS CloudTrail을 활성화하여 모든 API 호출을 기록하고 Amazon CloudWatch Logs와 통합합니다.",
            "Amazon Athena를 활용하여 CloudWatch Logs에서 SQL 쿼리를 실행하여 심층 분석을 수행합니다."
        ],
        "Explanation": "AWS CloudTrail을 활성화하면 모든 API 호출이 기록되어 감사 및 준수에 필수적입니다. 이를 Amazon CloudWatch Logs와 통합하면 보안 이벤트를 모니터링하고 분석하는 데 중요한 중앙 집중식 로깅이 가능합니다. Amazon Athena를 사용하면 팀이 SQL 쿼리를 통해 로그에 대한 유연하고 심층적인 분석을 수행할 수 있어 보안 문제를 식별하기가 더 쉬워집니다.",
        "Other Options": [
            "Amazon GuardDuty를 설정하는 것은 보안 위협을 모니터링하는 데 유용하지만, 이 시나리오에서 요구되는 CloudWatch Logs의 로그나 메트릭을 직접 분석하지는 않습니다.",
            "모든 보안 발견 사항에 대한 경고를 보내는 Lambda 함수를 생성하는 것은 경고 피로를 초래할 수 있으며, 로그나 메트릭에 대한 포괄적인 분석을 제공하지 않을 수 있습니다. 이는 사후 대응 솔루션일 뿐입니다.",
            "AWS Config 규칙을 구현하는 것은 준수에 중요하지만, 로그와 메트릭을 직접 분석하는 데 초점을 맞추지 않습니다. 이는 리소스 구성을 평가할 뿐 로그 데이터에 대한 통찰력을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "5",
        "Situation": "한 회사가 AWS에 호스팅된 웹 애플리케이션의 성능을 모니터링하고자 합니다. 이 애플리케이션은 응답 시간, 오류율 및 트래픽 양과 같은 다양한 메트릭을 생성합니다. 회사는 이러한 메트릭을 시각화하여 이해를 높이고 이해관계자에게 보고할 필요가 있습니다. 그들은 시각화를 위해 Amazon QuickSight를 사용하는 것을 고려하고 있지만, 동시에 Amazon CloudWatch에서 실시간 모니터링을 위한 포괄적인 대시보드를 만들 수 있도록 보장하고 싶어합니다. 이 솔루션은 다양한 서비스의 메트릭과 로그를 쉽게 상관관계 지을 수 있는 방법을 제공해야 합니다.",
        "Question": "어떤 접근 방식이 회사가 애플리케이션 메트릭과 로그를 효과적으로 시각화하면서 CloudWatch와 QuickSight 모두와의 접근성과 통합을 보장할 수 있게 할까요?",
        "Options": {
            "1": "Amazon CloudWatch를 사용하여 애플리케이션 메트릭을 모니터링하고 대시보드를 생성합니다. CloudWatch Logs 구독 필터를 설정하여 로그를 Amazon Kinesis Data Firehose로 전송하고, 이후 Amazon S3에 데이터를 저장하여 QuickSight가 분석할 수 있도록 합니다.",
            "2": "애플리케이션 메트릭을 Amazon CloudWatch로 전송하고 실시간 모니터링을 위한 사용자 정의 대시보드를 생성합니다. 메트릭을 매일 Amazon S3로 내보내고 QuickSight를 연결하여 S3의 데이터를 시각화합니다.",
            "3": "Amazon CloudWatch를 활용하여 메트릭을 수집하고 대시보드를 생성하며, Amazon Elasticsearch Service를 사용하여 로그를 저장하고 시각화합니다. QuickSight를 Elasticsearch에 연결하여 추가 분석을 수행합니다.",
            "4": "애플리케이션을 구성하여 메트릭을 직접 Amazon QuickSight로 전송하고 CloudWatch를 사용하지 않고 대시보드와 보고서를 생성하는 내장 기능을 사용합니다."
        },
        "Correct Answer": "Amazon CloudWatch를 사용하여 애플리케이션 메트릭을 모니터링하고 대시보드를 생성합니다. CloudWatch Logs 구독 필터를 설정하여 로그를 Amazon Kinesis Data Firehose로 전송하고, 이후 Amazon S3에 데이터를 저장하여 QuickSight가 분석할 수 있도록 합니다.",
        "Explanation": "이 접근 방식은 회사가 CloudWatch 대시보드를 통해 애플리케이션 메트릭을 실시간으로 모니터링할 수 있도록 하며, 로그를 S3에 저장하여 QuickSight를 통해 분석할 수 있게 합니다. CloudWatch와 Kinesis Data Firehose 간의 통합은 원활하여 시각화를 위한 효율적인 데이터 흐름을 가능하게 합니다.",
        "Other Options": [
            "이 옵션은 메트릭을 매일 S3로 내보내는 것을 제안하는데, 이는 실시간 데이터 접근에 지연을 초래합니다. 또한 CloudWatch가 실시간 통찰력을 직접 제공할 수 있기 때문에 워크플로우를 복잡하게 만듭니다.",
            "이 옵션은 QuickSight를 사용하여 시각화를 언급하지만, QuickSight가 메트릭을 직접 받을 수 있다고 잘못 암시하고 있습니다. QuickSight는 주로 S3나 데이터베이스와 같은 데이터 소스에 연결됩니다.",
            "이 옵션은 Amazon Elasticsearch Service를 사용하는 것을 제안하는데, 이는 이 시나리오에 과도한 복잡성을 추가합니다. CloudWatch와 Kinesis가 더 간단하고 통합된 솔루션을 제공할 수 있을 때 불필요한 복잡성을 더합니다."
        ]
    },
    {
        "Question Number": "6",
        "Situation": "한 회사가 AWS에 호스팅된 웹 애플리케이션을 보호하기 위한 보안 전략을 구현하고 있습니다. DevOps 엔지니어는 환경 전반에 걸쳐 여러 보안 제어 계층이 효과적으로 적용되도록 해야 합니다. 이 전략은 다양한 AWS 서비스를 활용하여 강력한 방어 체계를 구축해야 합니다.",
        "Question": "DevOps 엔지니어가 웹 애플리케이션의 보안 태세를 강화하기 위해 어떤 보안 조치를 구현해야 합니까? (두 가지 선택)",
        "Options": {
            "1": "AWS Config 규칙을 활성화하여 보안 모범 사례에 대한 준수를 지속적으로 모니터링합니다.",
            "2": "Amazon Detective를 설정하여 웹 애플리케이션에 대한 의심스러운 트래픽을 자동으로 차단합니다.",
            "3": "AWS WAF를 구성하여 악의적인 웹 트래픽을 필터링하고 일반적인 웹 공격으로부터 보호합니다.",
            "4": "AWS Certificate Manager를 활용하여 안전한 통신을 위한 SSL/TLS 인증서를 관리합니다.",
            "5": "신뢰할 수 있는 IP에 대해서만 인바운드 및 아웃바운드 트래픽을 제한하는 보안 그룹을 구현합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "AWS WAF를 구성하여 악의적인 웹 트래픽을 필터링하고 일반적인 웹 공격으로부터 보호합니다.",
            "AWS Config 규칙을 활성화하여 보안 모범 사례에 대한 준수를 지속적으로 모니터링합니다."
        ],
        "Explanation": "AWS WAF를 구현하면 HTTP 요청을 필터링하고 모니터링하여 일반적인 웹 공격에 대한 첫 번째 방어선을 제공합니다. AWS Config 규칙을 활성화하면 지속적인 준수 모니터링이 가능하여 조직이 보안 모범 사례를 준수하고 신속하게 편차를 식별할 수 있습니다.",
        "Other Options": [
            "Amazon Detective는 주로 보안 조사 및 분석에 사용되며, 트래픽을 사전 차단하는 데 효과적이지 않으므로 이 시나리오에서 즉각적인 보안 제어에 덜 효과적입니다.",
            "AWS Certificate Manager는 SSL/TLS 인증서를 관리하는 데 중요하지만, 악의적인 트래픽 필터링이나 준수 모니터링에 초점을 맞춘 방어 체계 전략에 직접 기여하지 않습니다.",
            "보안 그룹은 트래픽을 제어하는 데 필수적이지만, AWS WAF와 AWS Config 규칙이 제공하는 포괄적인 모니터링 및 필터링 기능을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "7",
        "Situation": "DevOps 팀은 AWS에 배포된 여러 마이크로서비스에서 사용하는 자격 증명의 자동 회전을 위한 솔루션을 구현해야 합니다. 이러한 자격 증명은 AWS Secrets Manager에 저장되어 있으며 보안 정책을 준수하기 위해 30일마다 회전해야 합니다. 팀은 새로운 자격 증명이 다운타임 없이 마이크로서비스에 자동으로 업데이트되도록 하기를 원합니다.",
        "Question": "마이크로서비스의 자격 증명 회전을 자동화하기 위한 가장 안전하고 효율적인 솔루션은 어떤 접근 방식입니까?",
        "Options": {
            "1": "CloudWatch Events 규칙에 의해 30일마다 트리거되는 Lambda 함수를 생성하여 Secrets Manager의 자격 증명을 회전합니다. 마이크로서비스를 업데이트하여 시작 시 Secrets Manager에서 새로운 자격 증명을 직접 읽도록 합니다.",
            "2": "30일마다 Secrets Manager에서 자격 증명을 회전하는 예약된 AWS Lambda 함수를 설정합니다. Secrets Manager의 내장 통합을 사용하여 코드 변경 없이 새로운 자격 증명으로 마이크로서비스를 자동으로 업데이트합니다.",
            "3": "각 마이크로서비스에 대해 Secrets Manager에 접근할 수 있는 사용자 지정 IAM 역할을 구현합니다. 30일마다 자격 증명을 회전하는 CloudFormation 스택을 생성하고, 마이크로서비스가 정기적으로 Secrets Manager에서 업데이트를 폴링하도록 합니다.",
            "4": "AWS Lambda를 활용하여 30일마다 Secrets Manager에서 자격 증명을 회전합니다. 성능을 위해 마이크로서비스가 메모리에 자격 증명을 캐시하도록 구성하고, 자격 증명이 변경될 때마다 캐시된 자격 증명을 업데이트하는 수동 프로세스를 구현합니다."
        },
        "Correct Answer": "30일마다 Secrets Manager에서 자격 증명을 회전하는 예약된 AWS Lambda 함수를 설정합니다. Secrets Manager의 내장 통합을 사용하여 코드 변경 없이 새로운 자격 증명으로 마이크로서비스를 자동으로 업데이트합니다.",
        "Explanation": "이 접근 방식은 AWS Secrets Manager의 내장 기능을 활용하여 자격 증명 회전을 원활하게 처리합니다. 마이크로서비스와의 통합을 사용하여 새로운 자격 증명을 자동으로 검색할 수 있어 다운타임을 방지하고 보안 정책을 준수하며 수동 개입을 최소화하여 보안을 강화합니다.",
        "Other Options": [
            "CloudWatch Events에 의해 트리거되는 Lambda 함수를 생성하는 것은 자격 증명을 회전하는 유효한 방법이지만, 마이크로서비스를 업데이트하여 새로운 자격 증명을 시작 시에만 읽도록 하면 회전이 발생할 때 서비스가 실행 중일 경우 다운타임이 발생할 수 있습니다.",
            "메모리에 자격 증명을 캐시하면 성능이 향상될 수 있지만, 수동 프로세스가 없으면 구식 자격 증명을 사용할 위험이 있습니다. 이 접근 방식은 자동 업데이트를 위한 내장 통합을 사용하는 것에 비해 보안성과 효율성이 떨어집니다.",
            "각 마이크로서비스에 대해 Secrets Manager에 접근할 수 있는 사용자 지정 IAM 역할을 구현하는 것은 가능하지만, 회전을 위해 CloudFormation 스택에 의존하고 업데이트를 폴링해야 하므로 자격 증명 업데이트에 지연이 발생할 수 있으며 마이크로서비스 관리의 복잡성이 증가합니다."
        ]
    },
    {
        "Question Number": "8",
        "Situation": "조직은 여러 SAML 2.0 지원 애플리케이션 및 AWS 계정에 대한 접근 관리를 위해 AWS IAM Identity Center를 구현하고 있습니다. 조직은 AWS Organizations를 사용하며 사용자 접근 관리를 효율적으로 수행하기 위한 적절한 아이덴티티 소스를 결정해야 합니다. 기존 아이덴티티 공급자와 원활하게 통합할 수 있기를 원합니다.",
        "Question": "다음 구성 중 어떤 것이 조직이 SAML 2.0 지원 애플리케이션, 비즈니스 앱 및 AWS 계정을 지원하면서 단일 아이덴티티 소스를 통해 사용자 접근을 관리할 수 있게 합니까?",
        "Options": {
            "1": "Okta와 같은 외부 아이덴티티 공급자를 아이덴티티 소스로 선택하여 AWS 계정과 비즈니스 애플리케이션 모두에 대해 SAML 2.0을 활성화합니다.",
            "2": "Microsoft Entra ID와 통합하여 아이덴티티 소스로 설정하고 AWS 계정에 대한 SAML 2.0 연합을 설정하며 비즈니스 앱은 외부에서 관리합니다.",
            "3": "Active Directory를 아이덴티티 소스로 사용하고 AWS 계정에 대해 SAML 2.0을 구성하지만 비즈니스 앱은 별도로 관리합니다.",
            "4": "Identity Center 디렉토리를 아이덴티티 소스로 선택하고 AWS IAM Identity Center 내에서 SAML 2.0 애플리케이션 접근을 직접 구성합니다."
        },
        "Correct Answer": "Identity Center 디렉토리를 아이덴티티 소스로 선택하고 AWS IAM Identity Center 내에서 SAML 2.0 애플리케이션 접근을 직접 구성합니다.",
        "Explanation": "Identity Center 디렉토리를 사용하면 AWS 계정과 SAML 2.0 지원 애플리케이션에 대한 접근을 중앙에서 관리할 수 있어 원활한 사용자 경험과 관리의 단순성을 제공합니다.",
        "Other Options": [
            "Microsoft Entra ID와 통합하면 외부 관리가 가능하지만, 조직이 AWS Organizations를 사용하므로 단일 아이덴티티 소스 요구 사항이 복잡해집니다.",
            "Active Directory를 사용하면 앱 관리의 분리가 발생할 수 있으며, IAM Identity Center가 AWS 계정과 비즈니스 애플리케이션 모두에 대해 제공하는 통합 접근 관리 기능을 제공하지 않습니다.",
            "Okta와 같은 외부 아이덴티티 공급자를 선택하면 단일 아이덴티티 소스 관리와 유사한 문제가 발생할 수 있으며, 추가 구성이 필요하고 AWS의 통합된 IAM Identity Center 기능을 완전히 활용하지 못할 수 있습니다."
        ]
    },
    {
        "Question Number": "9",
        "Situation": "회사는 Amazon Inspector를 구현하여 취약성 평가를 통해 클라우드 인프라에 대한 보안 우선 접근 방식을 채택하고 있습니다. 보안 팀은 애플리케이션 코드와 인프라가 정기적으로 보안 취약성 평가를 받도록 하기를 원합니다. 이 프로세스를 간소화하기 위해 Amazon Inspector에서 제공하는 내장 평가 템플릿을 사용하고자 합니다.",
        "Question": "보안 팀이 Amazon Inspector를 효과적으로 사용하여 애플리케이션 코드와 인프라 취약성에 대한 정기 평가를 자동화하려면 어떻게 해야 합니까?",
        "Options": {
            "1": "Amazon Inspector 평가를 애플리케이션과 인프라에 대해 매주 수동으로 실행하고, 결과를 검토하며 필요에 따라 패치를 적용하되 자동 알림은 사용하지 않습니다.",
            "2": "Amazon Inspector에서 애플리케이션 코드 취약성만을 타겟으로 하는 사용자 지정 평가 템플릿을 생성하고 인프라 점검을 포함하지 않고 수동으로 평가를 예약합니다.",
            "3": "Amazon Inspector의 내장 평가 템플릿을 인프라 전용으로 활용하고, 배포 후 평가를 트리거하는 CI/CD 파이프라인을 설정하되 애플리케이션 코드에 대해서는 평가를 수행하지 않습니다.",
            "4": "애플리케이션 코드와 인프라 모두에 대해 Amazon Inspector의 내장 평가 템플릿을 사용하여 정기 평가를 예약합니다. 식별된 취약성에 대해 팀에 알림을 설정하고 준수를 위한 보고서를 생성합니다."
        },
        "Correct Answer": "애플리케이션 코드와 인프라 모두에 대해 Amazon Inspector의 내장 평가 템플릿을 사용하여 정기 평가를 예약합니다. 식별된 취약성에 대해 팀에 알림을 설정하고 준수를 위한 보고서를 생성합니다.",
        "Explanation": "이 옵션은 애플리케이션 코드와 인프라 모두에 대해 정기적으로 취약성을 평가하도록 보장합니다. 정기 평가를 예약하고 알림을 구성함으로써 보안 팀은 발견된 문제를 사전에 해결하고 시간이 지남에 따라 준수를 유지할 수 있습니다.",
        "Other Options": [
            "이 옵션은 자동화 및 사전 모니터링이 부족합니다. 매주 평가를 수동으로 실행하는 것은 취약성을 적시에 식별하지 못하게 하며, 자동 알림을 생략하면 중요한 문제에 대한 대응이 지연될 수 있습니다.",
            "애플리케이션 코드만을 위한 사용자 지정 평가 템플릿을 생성하는 것은 인프라 취약성을 포함한 포괄적인 보안 평가의 필요성을 간과합니다. 정기 평가는 애플리케이션 스택의 모든 계층을 포함해야 합니다.",
            "평가를 인프라 전용으로 제한하면 애플리케이션 코드의 잠재적 취약성을 놓칠 수 있습니다. CI/CD 트리거는 유용하지만, 인프라 및 애플리케이션 평가를 모두 포함해야 철저한 보안 태세를 보장할 수 있습니다."
        ]
    },
    {
        "Question Number": "10",
        "Situation": "한 금융 서비스 회사가 검증 및 알림을 포함한 여러 단계를 요구하는 거래 처리를 자동화하려고 합니다. 이들은 AWS Lambda 기능과 AWS Step Functions를 활용하여 서버리스 워크플로를 만들고자 합니다. 회사는 워크플로 실행 중 발생하는 오류가 기록되고, 엔지니어링 팀에 즉각적인 조치를 위한 알림이 전송되도록 해야 합니다.",
        "Question": "이 서버리스 워크플로에 가장 효과적인 오류 처리 및 알림 전략을 제공하는 솔루션은 무엇입니까?",
        "Options": {
            "1": "AWS Step Functions를 사용하여 워크플로를 관리합니다. 실패한 거래가 전송되는 Amazon SQS 큐를 통합하고, 큐에서 메시지를 처리하고 엔지니어링 팀에 알림을 보내는 Lambda 함수를 설정합니다.",
            "2": "AWS Step Functions를 구현하여 Lambda 기능을 조정합니다. 오류를 캡처하기 위해 CloudWatch 로그 그룹을 구성하고, 오류가 발생할 때 SNS 주제를 통해 엔지니어링 팀에 알림을 보내는 CloudWatch 알람을 설정합니다.",
            "3": "전체 워크플로를 처리하는 단일 Lambda 함수를 개발하고, 오류 관리를 위해 try/catch 블록을 사용합니다. 오류가 발생하면 Amazon SES를 사용하여 엔지니어링 팀에 이메일 알림을 보냅니다.",
            "4": "오류 캐처가 있는 AWS Step Functions 상태 머신을 생성하여 오류를 기록하기 위해 Lambda 함수를 트리거합니다. 이 Lambda 함수를 구성하여 엔지니어링 팀을 위한 SNS 주제로 오류 알림을 직접 게시합니다."
        },
        "Correct Answer": "AWS Step Functions를 구현하여 Lambda 기능을 조정합니다. 오류를 캡처하기 위해 CloudWatch 로그 그룹을 구성하고, 오류가 발생할 때 SNS 주제를 통해 엔지니어링 팀에 알림을 보내는 CloudWatch 알람을 설정합니다.",
        "Explanation": "AWS Step Functions를 사용하면 내장된 오류 처리 기능을 활용할 수 있으며, CloudWatch와 결합하여 오류를 기록하고 SNS를 통해 알림을 보내는 것은 요구 사항을 효과적으로 충족하는 강력한 솔루션을 만듭니다.",
        "Other Options": [
            "Amazon SQS를 사용하여 오류 처리를 하는 것은 유효한 접근 방식이지만, 엔지니어링 팀에 알림을 보내기 전에 큐에서 메시지를 처리해야 하므로 불필요한 복잡성과 잠재적인 지연을 초래합니다.",
            "try/catch 블록을 사용하는 단일 Lambda 함수는 조정 및 오류 처리를 위한 AWS Step Functions의 이점을 활용하지 않으므로 여러 단계를 요구하는 복잡한 워크플로에 덜 효과적입니다.",
            "Step Functions 내에서 오류 캐처를 구성하는 것은 좋은 관행이지만, 단순히 Lambda 함수를 트리거하여 기록하는 것은 CloudWatch의 모니터링 및 오류 경고 기능을 완전히 활용하지 못할 수 있습니다."
        ]
    },
    {
        "Question Number": "11",
        "Situation": "한 회사가 AWS로 중요한 애플리케이션을 마이그레이션하고 있으며, 재해 발생 시 애플리케이션이 계속 사용 가능하고 복구 가능하도록 해야 합니다. DevOps 팀은 아키텍처에 구현할 다양한 백업 및 복구 전략을 평가하고 있습니다. 이들은 비용 효율성과 복구 시간 목표(RTO) 및 복구 지점 목표(RPO) 간의 균형을 맞추고자 합니다. 팀은 재해 복구 계획을 위한 여러 옵션을 고려하고 있습니다.",
        "Question": "전체 자원의 완전한 중복성에 비해 낮은 비용으로 빠른 복구 시간을 제공하는 백업 및 복구 전략은 무엇입니까?",
        "Options": {
            "1": "Pilot Light",
            "2": "Warm Standby",
            "3": "Full Redundancy",
            "4": "Cold Backup"
        },
        "Correct Answer": "Warm Standby",
        "Explanation": "Warm Standby는 완전한 기능 환경의 축소된 버전을 유지하여 차가운 백업에 비해 더 빠른 복구 시간을 제공하면서도 전체 중복성을 유지하는 것보다 비용이 덜 드는 재해 복구 전략입니다. 필요할 때 전체 생산 용량으로 신속하게 확장할 수 있습니다.",
        "Other Options": [
            "Pilot Light는 환경의 최소 버전을 유지하지만 전체 용량으로 확장하는 데 더 많은 시간이 필요하여 Warm Standby에 비해 더 긴 복구 시간을 초래합니다.",
            "Cold Backup은 전체 환경을 처음부터 다시 시작해야 하므로 상당한 시간 지연이 발생하며, 빠른 복구가 필요한 시나리오에는 적합하지 않습니다.",
            "Full Redundancy는 환경의 완전하고 완전히 운영되는 복제본을 유지하므로 가장 비용이 많이 드는 옵션이며, Warm Standby 전략에 비해 비용 효율적이지 않습니다."
        ]
    },
    {
        "Question Number": "12",
        "Situation": "한 DevOps 엔지니어가 Amazon EC2 인스턴스에서 실행 중인 중요한 애플리케이션을 모니터링하고 있으며, 성능에 대한 더 깊은 통찰력을 얻기 위해 사용자 정의 메트릭을 수집하고자 합니다. 메트릭은 수집되어 Amazon CloudWatch로 전송되어 시각화 및 경고에 사용되어야 합니다. 엔지니어는 구현을 위한 여러 옵션을 고려하고 있습니다.",
        "Question": "DevOps 엔지니어가 사용자 정의 메트릭을 효율적으로 수집하기 위해 구현해야 할 단계의 조합은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "EC2 인스턴스에서 자세한 모니터링을 활성화하여 추가 메트릭을 자동으로 수집합니다.",
            "2": "사용자 정의 메트릭 파일을 생성하고 CloudWatch 에이전트를 구성하여 이 파일을 사용하여 메트릭을 CloudWatch로 전송합니다.",
            "3": "EC2 인스턴스에 CloudWatch 에이전트를 설치하고 이를 구성하여 사용자 정의 메트릭을 CloudWatch로 전송합니다.",
            "4": "AWS Lambda 함수를 사용하여 EC2 인스턴스에서 메트릭을 주기적으로 가져와 CloudWatch로 푸시합니다.",
            "5": "Amazon CloudWatch Logs를 사용하여 애플리케이션 로그를 캡처하고 이를 통해 사용자 정의 메트릭을 자동으로 추출합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "EC2 인스턴스에 CloudWatch 에이전트를 설치하고 이를 구성하여 사용자 정의 메트릭을 CloudWatch로 전송합니다.",
            "사용자 정의 메트릭 파일을 생성하고 CloudWatch 에이전트를 구성하여 이 파일을 사용하여 메트릭을 CloudWatch로 전송합니다."
        ],
        "Explanation": "EC2 인스턴스에 CloudWatch 에이전트를 설치하면 애플리케이션의 요구에 맞춘 사용자 정의 메트릭을 수집할 수 있습니다. 또한 사용자 정의 메트릭 파일을 사용하면 수집할 메트릭과 이를 CloudWatch에 보고하는 방법을 정의하는 데 더 많은 유연성을 제공합니다.",
        "Other Options": [
            "이 작업에 AWS Lambda 함수를 사용하는 것은 CloudWatch 에이전트의 직접적인 접근 방식에 비해 불필요한 복잡성과 잠재적인 지연을 초래합니다.",
            "EC2 인스턴스에서 자세한 모니터링을 활성화하면 추가 메트릭을 제공하지만 사용자 정의 애플리케이션 특정 메트릭을 수집할 수는 없습니다.",
            "CloudWatch Logs를 사용하는 것은 애플리케이션 모니터링에 도움이 될 수 있지만, 추가 로그 처리 및 메트릭 추출 구성이 없이는 사용자 정의 메트릭을 수집하는 직접적인 방법을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "13",
        "Situation": "귀하의 조직은 다양한 환경에서 일관되게 구성해야 하는 여러 소프트웨어 구성 요소가 필요한 새로운 웹 애플리케이션을 배포하고 있습니다. 이러한 구성 요소의 구성 관리를 자동화하여 기본 인프라와 관계없이 항상 원하는 상태를 유지하도록 하려 합니다. 이 솔루션을 구현하기 위해 다양한 AWS 서비스를 고려하고 있습니다.",
        "Question": "소프트웨어 애플리케이션의 구성을 자동화하여 원하는 상태를 유지하도록 하는 데 가장 적합한 AWS 서비스는 무엇입니까?",
        "Options": {
            "1": "AWS CodeDeploy",
            "2": "AWS Elastic Beanstalk",
            "3": "AWS OpsWorks",
            "4": "AWS CloudFormation"
        },
        "Correct Answer": "AWS OpsWorks",
        "Explanation": "AWS OpsWorks는 Chef 또는 Puppet을 사용하여 애플리케이션과 서버를 관리할 수 있는 구성 관리 서비스를 제공합니다. 이는 애플리케이션의 배포, 구성 및 관리를 자동화하여 항상 원하는 상태를 유지하도록 도와줍니다.",
        "Other Options": [
            "AWS CloudFormation은 애플리케이션의 지속적인 구성 관리보다는 인프라 프로비저닝에 주로 초점을 맞추고 있습니다.",
            "AWS CodeDeploy는 애플리케이션 배포를 자동화하는 데 사용되지만 포괄적인 구성 관리 기능을 제공하지 않습니다.",
            "AWS Elastic Beanstalk는 애플리케이션 배포 및 관리를 간소화하지만 AWS OpsWorks와 같은 수준의 구성 제어를 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "14",
        "Situation": "한 회사가 사용자 데이터와 로그를 위한 지속적인 저장소가 필요한 새로운 마이크로서비스 애플리케이션을 개발하고 있습니다. DevOps 엔지니어는 성능과 확장성을 최적화하면서 비용을 최소화할 수 있는 적절한 저장소 솔루션을 선택해야 합니다.",
        "Question": "마이크로서비스 애플리케이션의 요구 사항을 가장 잘 충족하는 저장소 옵션 세트는 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "저지연 액세스가 필요한 사용자 데이터를 저장하기 위한 Amazon EBS.",
            "2": "내구성과 확장성 덕분에 애플리케이션 로그를 저장하기 위한 Amazon S3.",
            "3": "여러 마이크로서비스 인스턴스 간에 애플리케이션 로그를 공유하기 위한 Amazon EFS.",
            "4": "높은 처리량을 보장하기 위한 애플리케이션 로그 저장을 위한 Amazon EBS.",
            "5": "저렴한 비용과 드문 액세스 패턴 덕분에 사용자 데이터를 저장하기 위한 Amazon S3."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "내구성과 확장성 덕분에 애플리케이션 로그를 저장하기 위한 Amazon S3.",
            "저지연 액세스가 필요한 사용자 데이터를 저장하기 위한 Amazon EBS."
        ],
        "Explanation": "Amazon S3는 애플리케이션 로그를 저장하기 위한 매우 내구성이 뛰어나고 확장 가능한 솔루션으로, 대량의 로그 데이터를 생성하는 마이크로서비스에 이상적입니다. Amazon EBS는 저지연 블록 저장소를 제공하여 빠른 액세스가 필요한 사용자 데이터에 적합합니다. 이 조합은 효율적인 저장소 관리와 최적화된 성능을 가능하게 합니다.",
        "Other Options": [
            "Amazon EFS는 파일 저장을 위해 설계되었으며 로그에 사용할 수 있지만 일반적으로 더 비쌀 수 있으며 대량의 로그에 대해 S3와 같은 확장성 이점을 제공하지 않을 수 있습니다.",
            "S3는 비용 효율적이지만 사용자 데이터를 저장하면 EBS와 비교할 때 더 높은 지연으로 인해 성능 문제가 발생할 수 있습니다. EBS는 이러한 작업에 최적화되어 있습니다.",
            "애플리케이션 로그에 Amazon EBS를 사용하는 것은 최적이 아닙니다. EBS는 빠르고 일관된 성능이 필요한 데이터에 더 적합하며 로그 저장은 S3에서 효율적으로 처리할 수 있습니다."
        ]
    },
    {
        "Question Number": "15",
        "Situation": "한 회사가 AWS를 사용하여 인프라를 관리하고 있으며 모니터링 및 응답 기능을 향상시키고자 합니다. 운영 팀은 AWS Health 이벤트에 대해 신속하게 통보받도록 해야 합니다. 또한 AWS CloudTrail 로그인 실패와 같은 특정 이벤트에 따라 자동으로 수정 조치를 취하고자 합니다. 팀은 이 기능을 달성하기 위해 Amazon EventBridge를 사용하고자 합니다.",
        "Question": "어떤 솔루션이 팀이 AWS Health 이벤트를 모니터링하고 CloudTrail 로그인 실패에 자동으로 응답할 수 있도록 합니까?",
        "Options": {
            "1": "CloudTrail 로그에서 로그인 실패를 폴링하고 운영 팀에 SNS 알림을 보내는 전용 AWS Lambda 함수를 생성합니다.",
            "2": "CloudTrail 로그인 실패 이벤트를 캡처하고 운영 팀이 구독하는 SNS 주제로 알림을 보내는 Lambda 함수를 호출하는 Amazon EventBridge 규칙을 생성합니다.",
            "3": "로그인 실패를 모니터링하기 위해 Amazon CloudWatch 규칙을 설정하고 실패가 발생할 때마다 운영 팀에 직접 이메일을 보내도록 구성합니다.",
            "4": "Amazon EventBridge를 사용하여 AWS Health 이벤트를 AWS Step Functions 워크플로우로 라우팅하여 이벤트 유형에 따라 알림 및 수정 조치를 처리합니다."
        },
        "Correct Answer": "CloudTrail 로그인 실패 이벤트를 캡처하고 운영 팀이 구독하는 SNS 주제로 알림을 보내는 Lambda 함수를 호출하는 Amazon EventBridge 규칙을 생성합니다.",
        "Explanation": "Amazon EventBridge를 사용하여 CloudTrail 로그인 실패 이벤트를 캡처하면 실시간 모니터링이 가능합니다. 알림을 SNS 주제로 보내는 Lambda 함수를 호출함으로써 운영 팀은 즉시 경고를 받을 수 있어 신속한 통보 및 응답 요구 사항을 충족합니다.",
        "Other Options": [
            "Amazon CloudWatch 규칙을 설정하는 것은 최선의 접근 방식이 아닙니다. EventBridge는 이벤트 기반 아키텍처를 위해 특별히 설계되었으며 이벤트 라우팅 및 처리에 더 많은 유연성을 제공합니다.",
            "AWS Health 이벤트와 Step Functions에 EventBridge를 사용하는 것도 가능하지만, CloudTrail 로그인 실패에 응답해야 하는 요구 사항을 구체적으로 다루지 않으며, 이는 EventBridge의 직접적인 조치를 필요로 합니다.",
            "CloudTrail 로그를 Lambda 함수로 폴링하는 것은 EventBridge를 사용하는 것보다 비효율적입니다. EventBridge는 이벤트가 발생할 때 즉시 반응할 수 있는 반면, 주기적으로 확인해야 합니다."
        ]
    },
    {
        "Question Number": "16",
        "Situation": "소프트웨어 개발 팀이 개발 워크플로우를 향상시키기 위해 Continuous Integration/Continuous Deployment (CI/CD) 파이프라인을 구현하고 있습니다. 그들은 애플리케이션이 파이프라인의 다양한 단계에서 철저하게 테스트되어 높은 품질과 보안 기준을 유지할 수 있도록 하고자 합니다. 팀은 파이프라인에 포함해야 할 다양한 유형의 테스트를 평가하고 있습니다.",
        "Question": "애플리케이션의 포괄적인 검증을 보장하기 위해 CI/CD 파이프라인에 포함해야 할 테스트 유형은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "애플리케이션의 다양한 구성 요소 간의 상호작용을 검증하기 위한 통합 테스트.",
            "2": "높은 트래픽 시나리오를 시뮬레이션하고 애플리케이션 성능을 측정하기 위한 부하 테스트.",
            "3": "애플리케이션의 UI 기능과 외관을 검증하기 위한 사용자 인터페이스 테스트.",
            "4": "애플리케이션이 비즈니스 요구 사항과 사용자 기대를 충족하는지 확인하기 위한 수용 테스트.",
            "5": "애플리케이션의 개별 구성 요소와 기능을 검증하기 위한 단위 테스트."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "애플리케이션의 개별 구성 요소와 기능을 검증하기 위한 단위 테스트.",
            "애플리케이션의 다양한 구성 요소 간의 상호작용을 검증하기 위한 통합 테스트."
        ],
        "Explanation": "단위 테스트는 개별 구성 요소의 기능을 검증하는 데 필수적이며, 통합 테스트는 애플리케이션의 다양한 구성 요소가 의도한 대로 함께 작동하는지 확인합니다. 두 가지 모두 코드 품질을 유지하고 개발 과정 초기에 문제를 발견하는 데 중요합니다.",
        "Other Options": [
            "부하 테스트는 성능 평가에 중요하지만, CI/CD의 초기 단계에서는 애플리케이션의 핵심 기능에 집중하는 단위 및 통합 테스트만큼 중요하지 않습니다.",
            "수용 테스트는 일반적으로 CI/CD 파이프라인 단계에서가 아니라 개발 과정 후반에 비즈니스 요구 사항을 검증하기 위해 수행됩니다.",
            "사용자 인터페이스 테스트는 가치가 있지만, 애플리케이션 내의 핵심 기능과 상호작용을 보장하기 위한 단위 및 통합 테스트만큼 기본적이지 않을 수 있습니다."
        ]
    },
    {
        "Question Number": "17",
        "Situation": "한 회사가 Chef를 구성 관리 도구로 사용하여 AWS OpsWorks를 통해 인프라를 관리하고 있습니다. DevOps 팀은 애플리케이션의 배포 프로세스를 최적화하는 임무를 맡고 있습니다. 그들은 애플리케이션이 효율적으로 배포되고, 기본 인프라가 부하에 따라 확장될 수 있도록 해야 합니다.",
        "Question": "DevOps 엔지니어가 OpsWorks 기능을 활용하면서 애플리케이션 배포가 자동화되고 원하는 상태 구성을 준수하도록 하기 위해 어떤 조치를 취해야 합니까?",
        "Options": {
            "1": "Elastic Beanstalk를 활용하여 애플리케이션을 배포하고 기본 인프라를 관리하되, 프로세스를 간소화하기 위해 OpsWorks 기능을 무시합니다.",
            "2": "AWS CloudFormation을 사용하여 리소스를 프로비저닝하고 애플리케이션을 배포하되, 구성 관리를 위해 Chef와 OpsWorks의 사용을 우회합니다.",
            "3": "필요한 소프트웨어가 설치된 EC2 인스턴스를 수동으로 생성하고 구성한 다음, OpsWorks 기능을 사용하지 않고 애플리케이션을 직접 배포합니다.",
            "4": "OpsWorks Agent를 구성하여 애플리케이션에 필요한 라이브러리와 프레임워크로 EC2 인스턴스를 프로비저닝하는 Chef 레시피를 실행하고, 배포를 위한 생애 주기 이벤트 훅을 설정합니다."
        },
        "Correct Answer": "OpsWorks Agent를 구성하여 애플리케이션에 필요한 라이브러리와 프레임워크로 EC2 인스턴스를 프로비저닝하는 Chef 레시피를 실행하고, 배포를 위한 생애 주기 이벤트 훅을 설정합니다.",
        "Explanation": "OpsWorks Agent를 사용하여 Chef 레시피를 실행하면 원하는 상태 구성을 준수하는 간소화된 배포 프로세스가 가능합니다. 이 접근 방식은 인프라의 프로비저닝 및 구성을 자동화하여 OpsWorks의 이점을 극대화하며, 애플리케이션 배포를 효과적으로 관리하기 위해 생애 주기 이벤트를 활용합니다.",
        "Other Options": [
            "EC2 인스턴스를 수동으로 생성하고 구성하는 것은 자동화의 목적을 무색하게 하며, OpsWorks가 제공하는 구성 관리 기능을 활용하지 않습니다.",
            "AWS CloudFormation을 사용하는 것은 Chef와 OpsWorks의 이점을 우회하여 구성 관리 및 배포 자동화 능력을 제한합니다.",
            "Elastic Beanstalk를 배포에 활용하는 것은 구성 관리와 인프라 프로비저닝 자동화를 촉진하기 위해 설계된 OpsWorks의 특정 기능과 이점을 무시합니다."
        ]
    },
    {
        "Question Number": "18",
        "Situation": "한 회사가 S3 버킷에 업로드된 로그 파일을 처리해야 합니다. 로그는 관련 정보를 추출하고, 추출된 데이터를 OpenSearch Service 도메인으로 전송하는 Lambda 함수로 처리되어야 합니다. 회사는 로그 처리의 성공 및 실패에 대한 알림을 받기를 원합니다. 이를 달성하기 위한 가장 효과적인 솔루션은 무엇입니까?",
        "Question": "회사가 S3 이벤트를 구성하여 로그 파일 처리를 트리거하고 OpenSearch Service에 결과를 전달하며 처리 상태에 대한 알림을 보장하려면 어떻게 해야 합니까?",
        "Options": {
            "1": "새 로그 파일이 업로드될 때마다 Lambda 함수를 트리거하는 S3 이벤트 알림을 구성합니다. Lambda 함수는 로그 파일을 처리하고 결과를 OpenSearch Service에 전송합니다. Amazon SNS를 사용하여 Lambda 함수에서 직접 성공 및 실패 처리에 대한 알림을 보냅니다.",
            "2": "로그 파일이 S3 버킷에 업로드될 때마다 AWS Step Functions 워크플로우를 호출하는 S3 이벤트 알림을 설정합니다. 워크플로우에는 로그 파일을 처리하고 결과를 OpenSearch Service에 전송하는 Lambda 함수가 포함됩니다. Step Functions를 구성하여 Amazon SNS를 통해 알림을 보냅니다.",
            "3": "로그 파일을 처리하고 결과를 OpenSearch Service에 전송하는 AWS Batch 작업을 호출하는 S3 이벤트 알림을 생성합니다. Batch 작업의 완료를 모니터링하고 SNS를 통해 알림을 보내기 위해 CloudWatch Events를 사용합니다.",
            "4": "로그 파일을 처리하고 결과를 OpenSearch Service에 전송하는 Lambda 함수를 트리거하는 S3 이벤트 알림을 설정합니다. Lambda 호출을 모니터링하고 오류 또는 성공적인 완료에 대한 알림을 SNS로 보내기 위해 CloudTrail을 구현합니다."
        },
        "Correct Answer": "새 로그 파일이 업로드될 때마다 Lambda 함수를 트리거하는 S3 이벤트 알림을 구성합니다. Lambda 함수는 로그 파일을 처리하고 결과를 OpenSearch Service에 전송합니다. Amazon SNS를 사용하여 Lambda 함수에서 직접 성공 및 실패 처리에 대한 알림을 보냅니다.",
        "Explanation": "이 옵션은 추가 복잡성 없이 S3 이벤트 알림을 효과적으로 활용하여 Lambda 함수를 트리거합니다. Lambda 함수는 로그 파일 처리와 알림 로직을 모두 처리하여 효율적인 워크플로우 관리와 최소한의 지연을 보장합니다.",
        "Other Options": [
            "이 옵션은 Lambda 함수가 직접 처리할 수 있는 작업에 대해 AWS Step Functions를 사용하여 불필요한 복잡성을 도입합니다. 더 복잡한 워크플로우를 허용하지만, S3 이벤트 알림에서 Lambda 함수를 직접 호출하는 것보다 이점이 없습니다.",
            "AWS Batch 작업을 사용하는 것은 로그 파일 처리를 위한 오버헤드를 추가하며, Batch는 장기 실행 또는 리소스 집약적인 작업에 더 적합합니다. 간단한 로그 파일 처리를 위해 Lambda 함수를 호출하는 것이 더 효율적이고 비용 효과적입니다.",
            "CloudTrail은 주로 API 호출 감사 및 모니터링에 사용되며 Lambda 함수 실행에 대한 알림을 받는 직접적인 방법을 제공하지 않습니다. 호출을 모니터링할 수 있지만, 처리 결과에 대한 알림을 보내는 데 적합하지 않습니다."
        ]
    },
    {
        "Question Number": "19",
        "Situation": "한 회사가 AWS에서 Amazon ECS 및 AWS Lambda와 같은 서비스를 활용하여 대규모 마이크로서비스 아키텍처를 운영하고 있습니다. DevOps 팀은 성능 문제와 실패를 사전에 식별하고 대응하기 위해 전체 환경에 대한 자동 모니터링 및 로깅을 구현하고자 합니다. 그들은 솔루션이 비용 효율적이며 기존 인프라와 원활하게 통합되도록 해야 합니다.",
        "Question": "DevOps 팀이 마이크로서비스 아키텍처 전반에 걸쳐 모니터링 및 이벤트 관리를 자동화하기 위해 어떤 접근 방식을 취해야 합니까?",
        "Options": {
            "1": "각 마이크로서비스에 사용자 정의 모니터링 스크립트를 배포하여 메트릭과 로그를 수집합니다. 로그를 Amazon S3에 저장하고 로그를 분석하기 위해 예약 작업을 설정합니다.",
            "2": "분산 추적 및 모니터링을 위해 AWS X-Ray를 구현합니다. 애플리케이션 로그 저장을 위해 Amazon CloudWatch Logs를 사용하고, 오류 감지를 위한 메트릭 필터를 구성합니다.",
            "3": "중앙 집중식 로깅 및 모니터링을 위해 Amazon CloudWatch를 활용합니다. 주요 메트릭에 대한 CloudWatch 알람을 설정하고 경고 알림을 위한 Amazon SNS 주제를 생성합니다.",
            "4": "타사 모니터링 도구를 사용하여 각 마이크로서비스에서 로그와 메트릭을 수집합니다. 이러한 도구를 Amazon CloudWatch와 통합하여 경고 및 보고를 수행합니다."
        },
        "Correct Answer": "중앙 집중식 로깅 및 모니터링을 위해 Amazon CloudWatch를 활용합니다. 주요 메트릭에 대한 CloudWatch 알람을 설정하고 경고 알림을 위한 Amazon SNS 주제를 생성합니다.",
        "Explanation": "Amazon CloudWatch를 사용하면 AWS 리소스를 모니터링하고 로깅하기 위한 내장형, 확장 가능하며 비용 효율적인 솔루션을 제공합니다. 중앙 집중식 로그 수집, 메트릭 추적 및 SNS를 통한 자동 경고 기능을 제공하여 사전 이벤트 관리에 필수적입니다.",
        "Other Options": [
            "AWS X-Ray는 중앙 집중식 모니터링보다는 분산 추적에 주로 초점을 맞추고 있습니다. 마이크로서비스의 성능 병목 현상에 도움을 줄 수 있지만, CloudWatch와 같은 수준의 중앙 집중식 로깅이나 경고 기능을 제공하지 않습니다.",
            "사용자 정의 모니터링 스크립트는 유지 관리가 어려울 수 있으며 마이크로서비스 아키텍처와 잘 확장되지 않을 수 있습니다. 이 접근 방식은 운영 오버헤드를 증가시키고 분석을 위한 예약 작업에 의존하기 때문에 문제 식별에 지연을 초래할 수 있습니다.",
            "타사 도구는 추가 비용, 복잡성 및 데이터 수집 및 경고에 잠재적인 지연을 초래할 수 있습니다. 또한, 실시간 모니터링 및 경고를 위해 AWS 서비스와 통합할 때 네이티브 AWS 서비스를 사용할 때와 같은 원활한 경험을 제공하지 않을 수 있습니다."
        ]
    },
    {
        "Question Number": "20",
        "Situation": "한 회사가 AWS 서비스를 사용하여 실시간 로그 처리 솔루션을 구현하고 있습니다. 그들은 Amazon Kinesis Data Streams를 사용하여 로그를 수집하고 AWS Lambda를 사용하여 처리할 계획입니다. 팀은 Kinesis 스트림을 생성하고, 필요한 권한을 설정하며, 실시간으로 로그를 처리하기 위해 구독 필터를 구성해야 합니다.",
        "Question": "AWS 서비스를 사용하여 실시간 로그 처리를 설정하기 위해 어떤 단계를 수행해야 합니까?",
        "Options": {
            "1": "Kinesis Firehose 배달 스트림을 생성하고 데이터를 S3로 전송하도록 구성한 후 Lambda 처리 단계를 건너뜁니다.",
            "2": "aws kinesis create-stream을 실행하여 스트림을 생성하고, permissions.json을 스트림 및 역할 ARN으로 업데이트한 후 aws logs put-subscription-filter를 실행합니다.",
            "3": "aws kinesis describe-stream을 실행하여 스트림 세부 정보를 확인한 후 permissions를 업데이트하지 않고 aws logs put-subscription-filter를 실행합니다.",
            "4": "AWS CloudFormation을 사용하여 Kinesis 스트림과 Lambda 함수를 프로비저닝한 후 추가 구성 없이 스택을 배포합니다."
        },
        "Correct Answer": "aws kinesis create-stream을 실행하여 스트림을 생성하고, permissions.json을 스트림 및 역할 ARN으로 업데이트한 후 aws logs put-subscription-filter를 실행합니다.",
        "Explanation": "정답은 AWS CLI를 사용하여 Kinesis 스트림을 생성하고, Lambda 함수가 스트림에 필요한 접근 권한을 갖도록 권한 파일을 업데이트한 후 구독 필터를 사용하여 실시간으로 로그 처리를 시작하는 것입니다. 이는 로그 처리를 위한 필수 구성 요소를 설정하는 적절한 순서입니다.",
        "Other Options": [
            "이 옵션은 스트림과 권한을 생성하기 위한 필수 단계를 자세히 설명하지 않고 AWS CloudFormation을 사용하는 것을 잘못 제안하고 있습니다.",
            "이 옵션은 스트림을 생성하는 대신 설명하는 데 초점을 맞추고 있으며, 필요한 권한 업데이트 없이 구독 필터를 실행하라고 제안하여 로그 처리 실패로 이어질 수 있습니다.",
            "이 옵션은 Kinesis Data Streams 대신 Kinesis Firehose 배달 스트림을 생성하라고 잘못 제안하며, 실시간 로그 처리를 위해 중요한 Lambda 처리 단계를 무시하고 있습니다."
        ]
    },
    {
        "Question Number": "21",
        "Situation": "한 DevOps 엔지니어가 AWS에 배포된 애플리케이션의 로깅 인프라를 관리하는 책임을 맡고 있습니다. 이 애플리케이션은 민감한 정보를 포함한 상당량의 로그 데이터를 생성합니다. 엔지니어는 로그가 안전하게 저장되고 승인된 인원만 접근할 수 있도록 보장해야 합니다.",
        "Question": "다음 솔루션 중 애플리케이션 로그를 저장하고 관리하는 가장 안전한 방법은 무엇입니까?",
        "Options": {
            "1": "서버 측 암호화가 활성화된 Amazon S3를 사용하고 AWS Identity and Access Management (IAM) 정책을 사용하여 접근을 제한합니다.",
            "2": "애플리케이션이 실행되고 있는 EC2 인스턴스에 로그를 직접 저장하여 로그 파일에 대한 로컬 접근만 보장합니다.",
            "3": "기본 암호화 설정으로 Amazon CloudWatch Logs를 사용하고 계정의 모든 IAM 사용자와 접근을 공유합니다.",
            "4": "Amazon RDS를 사용하여 데이터베이스에 로그를 저장하고 쉽게 검색할 수 있도록 공개 접근을 활성화합니다."
        },
        "Correct Answer": "서버 측 암호화가 활성화된 Amazon S3를 사용하고 AWS Identity and Access Management (IAM) 정책을 사용하여 접근을 제한합니다.",
        "Explanation": "서버 측 암호화가 활성화된 Amazon S3를 사용하면 로그가 안전하게 저장됩니다. IAM 정책과 결합하면 로그에 대한 접근을 세밀하게 제어할 수 있어 보안 모범 사례를 준수할 수 있습니다.",
        "Other Options": [
            "로그를 EC2 인스턴스에 직접 저장하는 것은 보안 위험을 초래할 수 있으며, 인스턴스가 실패할 경우 데이터 손실로 이어질 수 있고 S3에 비해 적절한 접근 제어 메커니즘을 제공하지 않습니다.",
            "기본 암호화 설정으로 Amazon CloudWatch Logs를 사용하는 것은 S3와 함께 IAM 정책을 구현하는 것만큼 접근 및 보안에 대한 제어 수준을 제공하지 않으므로 민감한 로그에 대해 덜 안전합니다.",
            "로그를 위해 Amazon RDS를 사용하는 것은 권장되지 않는 관행이며, 로그 관리를 위해 설계되지 않았고 공개 접근을 활성화하는 것은 상당한 보안 위험을 초래합니다."
        ]
    },
    {
        "Question Number": "22",
        "Situation": "금융 서비스 회사는 여러 계정과 서비스를 포함하는 AWS 환경의 보안 및 규정 준수를 보장해야 합니다. 회사는 리소스 구성의 변경 사항을 모니터링하고 무단 변경 사항이 감지되도록 해야 합니다. 보안 팀은 이러한 변경 사항에 대해 적시에 대응할 수 있도록 알림을 받고자 합니다. 회사는 AWS Organizations를 사용하여 여러 계정과 리소스를 관리합니다.",
        "Question": "회사가 AWS 계정 전반에 걸쳐 구성 변경 사항을 효과적으로 모니터링하고 규정 준수를 보장하기 위해 구현해야 할 AWS 서비스의 조합은 무엇입니까?",
        "Options": {
            "1": "AWS Config 규칙을 구현하여 계정 간의 규정 준수를 평가하고 VPC Flow Logs를 활용하여 네트워크 트래픽을 모니터링합니다. 비용 이상에 대한 알림을 위해 AWS Budgets를 설정합니다.",
            "2": "모든 계정에서 AWS CloudTrail을 활성화하고 AWS CloudFormation 드리프트 감지를 활용하여 스택의 변경 사항을 식별합니다. AWS Lambda를 사용하여 알림을 자동화합니다.",
            "3": "모든 계정에서 API 호출을 기록하기 위해 AWS CloudTrail을 활성화하고 AWS Config를 사용하여 리소스 구성을 모니터링합니다. AWS Config 규칙 위반에 대한 SNS 알림을 설정합니다.",
            "4": "AWS Config를 사용하여 모든 계정에서 리소스 추적을 활성화하고 AWS Systems Manager와 통합하여 수정 작업을 수행합니다. 알림을 위해 CloudWatch Events를 설정합니다."
        },
        "Correct Answer": "모든 계정에서 API 호출을 기록하기 위해 AWS CloudTrail을 활성화하고 AWS Config를 사용하여 리소스 구성을 모니터링합니다. AWS Config 규칙 위반에 대한 SNS 알림을 설정합니다.",
        "Explanation": "AWS CloudTrail을 활성화하면 AWS 환경에서 이루어진 모든 API 호출의 포괄적인 로그가 제공되며, 이는 감사 및 보안 규정 준수에 필수적입니다. AWS Config를 사용하면 회사가 리소스 구성 변경 사항을 모니터링하고 규칙에 대한 준수를 평가할 수 있습니다. SNS 알림을 설정하면 보안 팀이 위반 사항에 대해 신속하게 통보받아 적시에 대응할 수 있습니다.",
        "Other Options": [
            "AWS Config와 Systems Manager를 사용하는 것은 모든 API 호출의 로그를 제공하지 않기 때문에 최선의 선택이 아닙니다. 이는 완전한 감사 추적에 필수적입니다.",
            "AWS CloudTrail과 CloudFormation 드리프트 감지는 구성 변경 사항을 식별할 수 있지만, AWS Config가 제공하는 모든 리소스에 대한 규정 준수의 포괄적인 뷰를 제공하지 않습니다.",
            "AWS Config 규칙과 VPC Flow Logs를 구현하는 것은 규정 준수 및 네트워크 모니터링에 중점을 두지만, 감사에 필수적인 CloudTrail이 제공하는 로그 기능을 놓치고 있습니다."
        ]
    },
    {
        "Question Number": "23",
        "Situation": "회사는 Amazon S3 버킷이 조직 정책을 준수하도록 자동화된 보안 제어를 구현해야 합니다. DevOps 엔지니어는 버킷 구성을 모니터링하기 위해 AWS Config를 구성합니다. 그러나 일부 중요한 S3 버킷은 여전히 필요한 암호화가 활성화되지 않은 상태로 생성되고 있습니다. 회사는 모든 S3 버킷에 대해 암호화를 자동으로 시행하는 것을 목표로 하고 있습니다.",
        "Question": "다음 솔루션 중 DevOps 엔지니어가 새로 생성된 모든 S3 버킷에 대해 기본적으로 암호화가 활성화되도록 보장하는 데 가장 적합한 것은 무엇입니까?",
        "Options": {
            "1": "AWS 서비스 제어 정책(SCP)을 사용하여 암호화가 활성화되지 않은 경우 S3 버킷 생성을 거부합니다.",
            "2": "모든 S3 버킷 리소스에 대한 암호화 구성을 포함하는 AWS CloudFormation 템플릿을 구현합니다.",
            "3": "암호화가 없는 S3 버킷을 플래그하는 AWS Config 규칙을 설정하고 관리자를 수동 개입을 위해 알립니다.",
            "4": "S3 버킷 생성 이벤트에 트리거되는 AWS Lambda 함수를 생성하여 암호화를 확인하고 시행합니다."
        },
        "Correct Answer": "S3 버킷 생성 이벤트에 트리거되는 AWS Lambda 함수를 생성하여 암호화를 확인하고 시행합니다.",
        "Explanation": "S3 버킷 생성 이벤트에 트리거되는 AWS Lambda 함수를 생성하면 버킷이 생성될 때마다 암호화를 실시간으로 시행할 수 있습니다. 이 사전 예방적 접근 방식은 새 버킷이 생성 즉시 보안 및 규정 준수 요구 사항을 준수하도록 보장합니다.",
        "Other Options": [
            "암호화가 없는 S3 버킷을 플래그하는 AWS Config 규칙을 설정하면 비준수 문제를 해결하기 위해 수동 개입이 필요합니다. 이는 버킷 생성 시 암호화를 자동으로 시행하지 않습니다.",
            "AWS 서비스 제어 정책(SCP)을 사용하여 암호화가 활성화되지 않은 경우 S3 버킷 생성을 거부하는 것은 제한적일 수 있으며, 생성 시 암호화가 불가능한 합법적인 사용 사례를 허용하지 않을 수 있습니다.",
            "암호화 구성을 포함하는 AWS CloudFormation 템플릿을 구현하는 것은 CloudFormation을 통해 생성된 리소스에 대해서만 효과적이며, AWS Management Console이나 CLI와 같은 다른 방법으로 생성된 버킷은 포함되지 않습니다."
        ]
    },
    {
        "Question Number": "24",
        "Situation": "귀 조직은 빠르게 확장하고 있으며, 일관된 보안 태세를 유지하기 위해 여러 AWS 계정에서 방화벽 규칙을 관리할 수 있는 솔루션이 필요합니다. 이 솔루션은 AWS WAF 규칙, 보안 그룹 및 AWS Network Firewall 구성을 중앙에서 적용할 수 있어야 합니다. 또한, 조직 내에서 생성된 새로운 계정에도 이러한 구성을 자동으로 적용해야 합니다.",
        "Question": "귀 조직 내 여러 계정에서 방화벽 규칙을 중앙에서 관리하고 적용하는 요구 사항을 가장 잘 충족하는 AWS 서비스는 무엇입니까?",
        "Options": {
            "1": "AWS Organizations를 설정하고 서비스 제어 정책(SCP)을 사용하여 조직 단위 수준에서 방화벽 규칙을 시행합니다.",
            "2": "AWS Firewall Manager를 사용하여 조직 내 모든 계정에 대해 AWS WAF 규칙, 보안 그룹 및 AWS Network Firewall을 관리하는 보안 정책을 생성합니다.",
            "3": "Amazon GuardDuty를 구현하여 계정 간의 네트워크 활동을 분석하고 모니터링하며 발견된 내용을 기반으로 잠재적 위협에 대응합니다.",
            "4": "AWS Config를 활용하여 모든 계정의 방화벽 규칙 구성을 모니터링하고 평가하여 지정된 정책에 대한 준수를 보장합니다."
        },
        "Correct Answer": "AWS Firewall Manager를 사용하여 조직 내 모든 계정에 대해 AWS WAF 규칙, 보안 그룹 및 AWS Network Firewall을 관리하는 보안 정책을 생성합니다.",
        "Explanation": "AWS Firewall Manager는 AWS Organizations 내 여러 계정에서 방화벽 규칙을 관리하도록 특별히 설계되었습니다. 이는 AWS WAF 규칙, 보안 그룹 및 AWS Network Firewall의 중앙 관리가 가능하며, 새로운 계정에도 이러한 규칙을 자동으로 적용합니다.",
        "Other Options": [
            "AWS Config는 주로 구성 변경 사항을 모니터링하고 기록하는 데 사용되지만, 여러 계정에서 방화벽 규칙을 직접 관리하거나 시행하지는 않습니다.",
            "Amazon GuardDuty는 의심스러운 활동과 잠재적 위협을 모니터링하는 위협 탐지 서비스이지만, 계정 간의 방화벽 규칙이나 구성을 관리하지는 않습니다.",
            "서비스 제어 정책(SCP)은 AWS 계정에 대한 거버넌스 및 제어를 제공하지만, 방화벽 규칙을 직접 관리하거나 구성하도록 설계되지 않았습니다."
        ]
    },
    {
        "Question Number": "25",
        "Situation": "최근 배포 중에 귀하의 애플리케이션이 일련의 예기치 않은 실패를 겪어 상당한 다운타임이 발생했습니다. 경영진은 향후 유사한 사건을 방지하기 위해 포괄적인 근본 원인 분석을 요청했습니다.",
        "Question": "최근 애플리케이션 실패에 대한 근본 원인 분석을 효과적으로 수행하기 위해 어떤 접근 방식을 취해야 합니까?",
        "Options": {
            "1": "애플리케이션 로그를 검토하고 실패에 이르기까지 발생한 오류나 경고를 식별합니다. 근본 원인을 나타낼 수 있는 패턴이나 이상 징후를 찾습니다.",
            "2": "엔지니어링 팀과의 사후 분석 회의를 수행하여 사건에 대해 논의하고 실패 중 그들의 관찰 및 경험에 대한 의견을 수집합니다.",
            "3": "자동화된 모니터링 도구를 구현하여 애플리케이션에서 메트릭을 수집하고 향후 사건에 대한 경고를 생성하여 현재 상황이 해결되도록 합니다.",
            "4": "AWS CloudTrail을 활용하여 애플리케이션에 대한 API 호출을 분석하고, 실패에 앞서 발생한 작업에 집중하며 승인되지 않은 변경 사항을 식별합니다."
        },
        "Correct Answer": "애플리케이션 로그를 검토하고 실패에 이르기까지 발생한 오류나 경고를 식별합니다. 근본 원인을 나타낼 수 있는 패턴이나 이상 징후를 찾습니다.",
        "Explanation": "애플리케이션 로그를 검토하는 것은 실패 이전에 발생한 특정 문제를 식별하는 데 필수적입니다. 이는 무엇이 잘못되었는지에 대한 직접적인 통찰력을 제공하여 근본 원인을 명확히 이해할 수 있게 합니다.",
        "Other Options": [
            "사후 분석 회의를 수행하는 것은 귀중한 통찰력을 수집할 수 있지만, 기술적 관점에서 정확한 근본 원인을 파악하는 데 필요한 구체적인 증거를 제공하지 않을 수 있습니다.",
            "AWS CloudTrail을 사용하여 API 호출을 분석하는 것은 변경 사항을 모니터링하는 데 유용하지만, 실패를 초래한 애플리케이션의 특정 오류나 경고를 직접적으로 드러내지 않을 수 있습니다.",
            "자동화된 모니터링 도구를 구현하는 것은 향후 사건에 대해 선제적이지만, 현재 실패를 분석하고 그 근본 원인을 식별하는 즉각적인 필요를 해결하지 않습니다."
        ]
    },
    {
        "Question Number": "26",
        "Situation": "모바일 애플리케이션은 사용자가 웹 아이덴티티 제공자(WIP)를 통해 AWS 리소스에 안전하게 접근할 수 있도록 인증할 수 있게 합니다. 애플리케이션은 사용자가 WIP에 의해 인증된 후 AWS Security Token Service (STS)를 통해 임시 접근 자격 증명을 얻을 수 있는 원활한 프로세스가 필요합니다.",
        "Question": "모바일 사용자가 웹 아이덴티티 제공자로 인증한 후 임시 접근 자격 증명을 얻을 수 있도록 어떤 프로세스를 구현해야 합니까?",
        "Options": {
            "1": "모바일 앱에 정적 접근 키를 설정하여 사용자가 인증 없이 AWS 서비스에 접근할 수 있도록 합니다.",
            "2": "모바일 앱을 AWS Lambda와 통합하여 사용자를 인증한 후 각 사용자 세션에 대해 STS 토큰을 수동으로 생성합니다.",
            "3": "모바일 앱을 WIP를 사용하여 사용자를 인증하도록 구성한 후, WIP 토큰을 사용하여 필요한 권한을 가진 역할을 맡기 위해 STS를 호출합니다.",
            "4": "모바일 사용자가 AWS IAM에 직접 인증하고, 이후 AWS 서비스에 대한 직접 접근을 위해 영구 접근 키를 발급합니다."
        },
        "Correct Answer": "모바일 앱을 WIP를 사용하여 사용자를 인증하도록 구성한 후, WIP 토큰을 사용하여 필요한 권한을 가진 역할을 맡기 위해 STS를 호출합니다.",
        "Explanation": "이 옵션은 인증을 위해 웹 아이덴티티 제공자를 사용하고 이후 STS를 통해 임시 AWS 자격 증명을 얻는 프로세스를 올바르게 설명합니다. 이는 WIP 토큰을 사용하여 AWS에서 안전하게 역할을 맡는 웹 아이덴티티 연합의 표준 접근 방식입니다.",
        "Other Options": [
            "이 옵션은 잘못된 것으로, 영구 접근 키를 직접 발급하는 것은 임시 자격 증명의 보안 이점을 우회하며 AWS 보안 모범 사례를 따르지 않습니다.",
            "이 옵션은 잘못된 것으로, 인증을 위해 AWS Lambda와 통합하는 것은 WIP를 효과적으로 활용하지 않으며 불필요한 복잡성을 초래합니다. STS는 WIP 인증 후 직접 호출해야 합니다.",
            "이 옵션은 잘못된 것으로, 정적 접근 키를 사용하는 것은 AWS의 보안 모델을 저해하며, 모바일 앱에서 민감한 정보를 노출시켜 남용에 취약하게 만듭니다."
        ]
    },
    {
        "Question Number": "27",
        "Situation": "귀하는 다중 계정 AWS 환경에서 종속성을 관리하는 책임이 있는 DevOps 엔지니어입니다. 귀하의 팀은 패키지 관리를 위해 AWS CodeArtifact를 사용하고 있으며, 특정 리포지토리에 대한 교차 계정 접근을 허용해야 할 필요가 있습니다. 요구 사항은 외부 연결이 하나만 설정될 수 있으며, 이는 종속성의 캐시 역할을 해야 한다고 명시하고 있습니다. 또한, 구성은 리포지토리의 패키지가 외부 계정에 대해 완전히 접근 가능하거나 전혀 접근할 수 없도록 보장해야 합니다. 이 솔루션을 가장 효율적인 방법으로 구현해야 합니다.",
        "Question": "업스트림 리포지토리 및 외부 연결의 제약을 준수하면서 AWS CodeArtifact를 교차 계정 접근 요구 사항에 맞게 구성하는 가장 좋은 방법은 무엇입니까?",
        "Options": {
            "1": "업스트림 연결이 있는 CodeArtifact 리포지토리를 구성하고, 외부 계정에 대한 특정 패키지 접근을 제한하기 위해 리소스 정책을 사용합니다.",
            "2": "외부 계정에 대해 모든 패키지에 대한 읽기 접근을 허용하는 정책을 가진 단일 AWS CodeArtifact 리포지토리를 생성합니다.",
            "3": "외부 리포지토리에 연결된 단일 CodeArtifact 리포지토리를 구현하여 모든 패키지가 외부 계정에서 읽을 수 있도록 합니다.",
            "4": "각 업스트림 종속성에 대해 여러 CodeArtifact 리포지토리를 설정하고, 외부 계정이 필요한 패키지에 대해서만 읽기 접근을 허용합니다."
        },
        "Correct Answer": "외부 계정에 대해 모든 패키지에 대한 읽기 접근을 허용하는 정책을 가진 단일 AWS CodeArtifact 리포지토리를 생성합니다.",
        "Explanation": "정답은 외부 계정이 리포지토리에 대해 명확하고 완전한 접근을 보장하여 모든 패키지에 대한 교차 계정 접근 요구 사항을 충족하며, 여러 리포지토리의 복잡성을 피합니다. 이 구성은 외부 연결이 하나만 있다는 제약을 준수하며 종속성 관리를 위한 간단한 솔루션을 제공합니다.",
        "Other Options": [
            "이 옵션은 잘못된 것으로, 여러 리포지토리를 설정하면 종속성 관리가 복잡해지고 외부 계정에 대해 완전한 접근 또는 전혀 접근할 수 없다는 요구 사항을 준수하지 않습니다.",
            "이 옵션은 잘못된 것으로, 여러 업스트림 리포지토리를 구현하는 것을 제안하며, 이는 종속성 캐싱을 위한 단일 외부 연결 요구 사항과 모순됩니다.",
            "이 옵션은 잘못된 것으로, 특정 패키지에 대한 접근을 제한하기 위해 리소스 정책을 사용하는 것을 암시하며, 이는 외부 계정이 모든 패키지를 읽거나 전혀 읽을 수 없다는 요구 사항에 위배됩니다."
        ]
    },
    {
        "Question Number": "28",
        "Situation": "한 회사가 인프라 배포를 표준화하고 모든 구성이 코드로 관리되도록 하려고 합니다. DevOps 팀은 리소스의 프로비저닝 및 관리를 자동화하기 위해 AWS 서비스를 활용하기로 결정했습니다. 그들은 특히 버전 관리되고 동료 검토된 구성만 배포하도록 제한하고자 합니다.",
        "Question": "DevOps 팀이 이러한 목표를 달성하기 위해 사용할 수 있는 방법은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "AWS CloudFormation을 구현하고 템플릿의 버전 관리를 위해 AWS CodeCommit과 통합합니다.",
            "2": "AWS Systems Manager Parameter Store를 활용하여 구성 매개변수를 일반 텍스트로 관리합니다.",
            "3": "AWS Config를 사용하여 정의된 구성에 따라 준수하는 리소스만 배포되도록 합니다.",
            "4": "AWS CloudFormation StackSets를 활용하여 여러 계정과 리전에서 구성을 배포합니다.",
            "5": "AWS CloudFormation을 CI/CD 파이프라인과 통합하여 배포 전에 동료 검토를 강제합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "AWS CloudFormation을 구현하고 템플릿의 버전 관리를 위해 AWS CodeCommit과 통합합니다.",
            "AWS CloudFormation을 CI/CD 파이프라인과 통합하여 배포 전에 동료 검토를 강제합니다."
        ],
        "Explanation": "AWS CloudFormation과 AWS CodeCommit을 통합하면 팀은 CloudFormation 템플릿을 버전 관리할 수 있어 검토되고 승인된 구성만 배포되도록 보장합니다. 또한 CI/CD 파이프라인을 통합하면 모든 변경 사항이 배포되기 전에 동료 검토 프로세스를 거치게 되어 인프라의 무결성을 유지할 수 있습니다.",
        "Other Options": [
            "AWS Systems Manager Parameter Store는 구성 데이터를 관리하는 데 유용하지만 인프라 구성에 대한 버전 관리나 동료 검토를 강제하지는 않습니다.",
            "AWS Config는 준수 검사를 위해 유용하지만 리소스의 배포를 직접 제어하거나 버전 관리되도록 보장하지는 않습니다.",
            "AWS CloudFormation StackSets는 여러 계정과 리전에서 배포를 가능하게 하지만 템플릿에 대한 버전 관리나 동료 검토를 본질적으로 관리하지는 않습니다."
        ]
    },
    {
        "Question Number": "29",
        "Situation": "한 회사가 사용자가 AWS 서비스에 대한 깊은 지식 없이 AWS 인프라 리소스를 시작할 수 있도록 권한을 부여하려고 합니다. 회사는 프로세스를 가능한 한 원활하게 유지하면서 거버넌스와 준수를 보장하고자 합니다. 이를 위해 AWS Service Catalog를 사용할 계획입니다. 관리자는 사용자가 셀프 서비스 포털을 통해 시작할 수 있는 제품 세트를 정의할 것입니다.",
        "Question": "AWS Service Catalog의 기능 및 사용자에게 주는 이점에 관해 다음 중 어떤 설명이 TRUE입니까?",
        "Options": {
            "1": "AWS Service Catalog는 사용자가 제품을 시작하기 전에 CloudFormation 템플릿에 대한 포괄적인 이해가 필요합니다.",
            "2": "AWS Service Catalog는 사용자가 제한 없이 CloudFormation 템플릿을 사용하여 AWS 리소스를 직접 배포할 수 있도록 합니다.",
            "3": "AWS Service Catalog는 사용자가 셀프 서비스 포털을 통해 미리 정의된 제품을 시작할 수 있도록 하며, 준수 및 거버넌스를 보장합니다.",
            "4": "AWS Service Catalog는 주로 조직 내 사용자 및 그룹에 대한 IAM 정책 관리를 위해 사용됩니다."
        },
        "Correct Answer": "AWS Service Catalog는 사용자가 셀프 서비스 포털을 통해 미리 정의된 제품을 시작할 수 있도록 하며, 준수 및 거버넌스를 보장합니다.",
        "Explanation": "AWS Service Catalog는 사용자가 미리 정의된 제품을 시작할 수 있는 셀프 서비스 포털을 제공하며, 이러한 제품은 일반적으로 CloudFormation 템플릿을 사용하여 정의됩니다. 이를 통해 사용자는 깊은 AWS 지식 없이도 AWS 리소스를 사용할 수 있으며, 거버넌스와 준수를 유지할 수 있습니다.",
        "Other Options": [
            "이 옵션은 잘못된 것입니다. AWS Service Catalog는 사용자가 CloudFormation 템플릿을 사용하여 리소스를 직접 배포하는 것을 제한하며, 대신 미리 정의된 제품을 통해 배포를 관리합니다.",
            "이 옵션은 잘못된 것입니다. AWS Service Catalog를 사용하기 위해 사용자가 CloudFormation 템플릿에 대한 광범위한 지식을 가져야 한다고 암시하지만, 이는 사실이 아닙니다. 이 서비스는 그 복잡성을 추상화하도록 설계되었습니다.",
            "이 옵션은 잘못된 것입니다. AWS Service Catalog는 제품 카탈로그를 통해 AWS 리소스를 배포하고 관리하는 데 중점을 두며, IAM 정책 관리를 다루지 않습니다."
        ]
    },
    {
        "Question Number": "30",
        "Situation": "한 회사가 소프트웨어 개발 생명 주기(SDLC)를 자동화하고 배포 단계에서 애플리케이션 상태를 측정하는 방법을 구현해야 합니다. 애플리케이션은 Amazon ECS에 의해 오케스트레이션되는 컨테이너에서 실행되며, 애플리케이션이 반환하는 종료 코드를 기반으로 배포의 성공을 평가하는 것이 중요합니다. DevOps 엔지니어는 이러한 종료 코드를 기반으로 애플리케이션 상태를 평가하는 최선의 접근 방식을 정의하는 임무를 맡고 있습니다.",
        "Question": "다음 전략 중 어떤 것이 DevOps 엔지니어가 배포 중 애플리케이션 종료 코드를 기반으로 애플리케이션 상태를 측정하는 데 가장 적합합니까?",
        "Options": {
            "1": "AWS X-Ray를 애플리케이션과 통합하여 종료 코드를 추적하고 애플리케이션 상태 메트릭을 시각화하는 대시보드를 설정합니다.",
            "2": "배포 중 애플리케이션이 0이 아닌 종료 코드를 반환하면 트리거되는 CloudWatch 경고를 구현하고, AWS CodeDeploy를 사용하여 롤백을 자동화합니다.",
            "3": "AWS CodePipeline을 사용하여 애플리케이션을 배포하고, 종료 코드가 0일 때만 빌드 아티팩트를 생성하여 결함 있는 배포를 방지합니다.",
            "4": "Amazon ECS 헬스 체크를 사용하여 컨테이너 종료 코드를 모니터링하고, 0이 아닌 종료 코드를 분석하기 위해 Lambda 함수를 구성하여 알림을 트리거합니다."
        },
        "Correct Answer": "배포 중 애플리케이션이 0이 아닌 종료 코드를 반환하면 트리거되는 CloudWatch 경고를 구현하고, AWS CodeDeploy를 사용하여 롤백을 자동화합니다.",
        "Explanation": "CloudWatch 경고를 사용하여 0이 아닌 종료 코드를 모니터링하면 배포 중 문제를 즉시 감지할 수 있습니다. AWS CodeDeploy를 사용하여 롤백을 자동화함으로써 시스템은 안정적인 상태로 신속하게 되돌릴 수 있어 사용자에게 최소한의 중단을 보장합니다.",
        "Other Options": [
            "Amazon ECS 헬스 체크를 사용하는 것은 좋은 관행이지만, 로그를 분석하기 위해 Lambda 함수에만 의존하는 것은 문제 감지에 지연을 초래하고 즉각적인 롤백 조치를 촉진하지 않습니다.",
            "AWS X-Ray를 통합하면 애플리케이션 성능에 대한 통찰력을 제공하지만, 배포 중 종료 코드를 직접 측정하지 않으므로 즉각적인 상태 평가에는 덜 효과적입니다.",
            "종료 코드가 0일 때만 빌드 아티팩트를 생성하는 것은 결함 있는 배포를 방지하는 데 도움이 되지만, 배포 과정 중 상태 모니터링을 다루지 않으므로 즉각적인 롤백에 중요합니다."
        ]
    },
    {
        "Question Number": "31",
        "Situation": "소프트웨어 회사가 사용자 데이터를 저장하고 검색하기 위해 Amazon DynamoDB를 활용하는 데이터 집약적인 애플리케이션을 개발하고 있습니다. 이 애플리케이션은 높은 성능을 요구하며 단일 항목 가져오기, 여러 항목 검색, 배치 쓰기 수행 등 다양한 데이터 접근 패턴을 처리해야 합니다. 애플리케이션이 확장됨에 따라 개발 팀은 DynamoDB 작업을 효율적으로 사용하면서도 어떤 한계를 초과하지 않도록 해야 합니다.",
        "Question": "데이터 접근 및 관리를 최적화하기 위해 팀이 구현할 수 있는 DynamoDB 작업은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "UpdateItem을 활용하여 기존 항목을 먼저 읽지 않고도 변경하여 읽기 용량 사용을 줄입니다.",
            "2": "데이터 분리를 보장하고 접근 패턴을 단순화하기 위해 새로운 데이터 엔티티마다 새 테이블을 생성합니다.",
            "3": "BatchGetItem을 구현하여 단일 요청으로 여러 항목을 검색하고 총 크기가 16MB를 초과하지 않도록 합니다.",
            "4": "Scan 작업을 사용하여 테이블의 모든 항목을 검색하여 데이터 세트에 대한 포괄적인 뷰를 제공합니다.",
            "5": "GetItem API를 활용하여 중요한 데이터 접근 요구 사항에 대해 강력한 일관성을 가진 항목을 검색합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "BatchGetItem을 구현하여 단일 요청으로 여러 항목을 검색하고 총 크기가 16MB를 초과하지 않도록 합니다.",
            "UpdateItem을 활용하여 기존 항목을 먼저 읽지 않고도 변경하여 읽기 용량 사용을 줄입니다."
        ],
        "Explanation": "BatchGetItem을 사용하면 팀이 단일 요청으로 여러 항목을 효율적으로 검색할 수 있으며, 16MB 크기 제한을 준수하여 성능을 최적화하고 DynamoDB에 대한 왕복 횟수를 줄입니다. UpdateItem 작업은 기존 항목을 먼저 읽지 않고도 수정할 수 있게 하여 읽기 용량 단위를 절약하고 성능을 향상시킵니다, 특히 대량의 시나리오에서.",
        "Other Options": [
            "강력한 일관성을 가진 GetItem을 사용하는 것은 대부분의 접근 패턴에 필요하지 않으며, 결국 일관된 읽기가 충분할 때 지연 시간이 증가하고 처리량이 감소할 수 있습니다.",
            "Scan 작업은 테이블의 모든 항목을 읽기 때문에 대규모 데이터 세트에 비효율적이며, 특정 쿼리나 배치 작업에 비해 더 많은 읽기 용량과 시간을 소모합니다.",
            "새로운 데이터 엔티티마다 새 테이블을 생성하면 관리 오버헤드가 증가하고 접근 패턴이 복잡해져 적절한 인덱싱을 가진 단일 테이블을 사용하는 것보다 비효율적입니다."
        ]
    },
    {
        "Question Number": "32",
        "Situation": "DevOps 팀이 AWS CodeArtifact를 중앙 아티팩트 저장소로 사용하여 종속성을 저장하고 공유하는 애플리케이션을 관리하고 있습니다. 그들은 특정 사용자와 서비스만 저장소에 접근할 수 있도록 보안 권한을 구성해야 하며, 최소 권한 원칙을 준수해야 합니다. 팀은 시간이 지나도 관리 및 유지가 용이한 솔루션을 원합니다.",
        "Question": "CodeArtifact의 아티팩트 저장소에 대한 접근 권한을 관리하는 가장 안전하고 효율적인 방법은 무엇입니까?",
        "Options": {
            "1": "CodeArtifact 저장소에 대한 접근을 허용하는 권한을 가진 단일 IAM 그룹을 사용하고 모든 사용자와 서비스를 이 그룹에 추가합니다. 이렇게 하면 권한 관리가 간소화됩니다.",
            "2": "CodeArtifact 저장소에 대한 전체 접근을 부여하는 IAM 정책을 생성하고 접근이 필요한 모든 사용자와 서비스에 연결합니다. 이렇게 하면 모든 사용자에 대해 단일 정책으로 관리가 간소화됩니다.",
            "3": "CodeArtifact 저장소에 대한 광범위한 권한을 가진 IAM 역할을 설정하고 모든 사용자가 저장소에 접근할 때 이 역할을 맡도록 허용합니다. 이 접근 방식은 접근 관리를 중앙 집중화합니다.",
            "4": "저장소에 접근이 필요한 각 사용자와 서비스에 대해 최소 권한을 지정하는 개별 IAM 정책을 생성합니다. 이러한 정책을 해당 IAM 사용자 및 역할에 연결합니다."
        },
        "Correct Answer": "저장소에 접근이 필요한 각 사용자와 서비스에 대해 최소 권한을 지정하는 개별 IAM 정책을 생성합니다. 이러한 정책을 해당 IAM 사용자 및 역할에 연결합니다.",
        "Explanation": "각 사용자와 서비스에 맞춤화된 개별 IAM 정책을 생성하면 접근 권한이 최소 권한 원칙에 부합하여 각 역할에 필요한 것만 접근할 수 있도록 제한함으로써 보안을 강화합니다.",
        "Other Options": [
            "모든 사용자와 서비스에 대한 전체 접근을 가진 단일 IAM 정책을 생성하는 것은 최소 권한 원칙을 위반하며 저장소에 대한 무단 접근 위험을 증가시킵니다.",
            "모든 사용자가 맡을 수 있는 광범위한 IAM 역할을 설정하는 것도 최소 권한 원칙을 위반하며, 특정 요구 사항에 따라 접근을 제한하기보다는 모든 사용자에게 과도한 권한을 부여합니다.",
            "모든 사용자와 서비스에 대한 단일 IAM 그룹을 사용하는 것은 관리가 간소화되지만, 특정 역할에 필요하지 않은 접근을 허용할 수 있어 최소 권한 원칙을 준수하지 않습니다."
        ]
    },
    {
        "Question Number": "33",
        "Situation": "Amazon SQS를 사용하여 메시지를 처리하는 분산 시스템을 개발하고 있습니다. 메시지가 효율적으로 처리되면서도 큐 전반에 걸쳐 가시성과 보안을 유지해야 합니다. 애플리케이션은 메시지의 가시성 타임아웃을 변경하고, 큐 속성을 설정하며, 다양한 AWS 리소스에 대한 권한을 관리할 수 있어야 합니다. 또한 CPU 사용량을 줄이기 위해 메시지 폴링을 최적화하고자 합니다.",
        "Question": "이 요구 사항을 충족하기 위해 어떤 옵션 조합을 구현해야 합니까? (두 가지 선택)",
        "Options": {
            "1": "add-permission 명령을 호출하여 특정 AWS 리소스에 SQS 큐에 대한 접근을 부여합니다.",
            "2": "receive-message 명령에서 wait-time-sec 매개변수를 사용하여 롱 폴링을 구현합니다.",
            "3": "delete-message를 사용하여 성공적으로 처리된 메시지를 큐에서 제거합니다.",
            "4": "change-message-visibility를 사용하여 메시지의 가시성 타임아웃을 최대 12시간 연장합니다.",
            "5": "set-queue-attribute 명령을 사용하여 큐의 가시성 타임아웃 설정을 구성합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "set-queue-attribute 명령을 사용하여 큐의 가시성 타임아웃 설정을 구성합니다.",
            "receive-message 명령에서 wait-time-sec 매개변수를 사용하여 롱 폴링을 구현합니다."
        ],
        "Explanation": "set-queue-attribute 명령을 사용하면 SQS 큐의 다양한 속성을 구성할 수 있으며, 가시성 타임아웃 설정도 포함됩니다. 또한, receive-message 명령에서 wait-time-sec 매개변수를 사용하여 롱 폴링을 구현하면 SQS 서비스가 메시지가 사용 가능할 때까지 요청을 열어 두어 CPU 작업을 줄이고 빈 응답 수를 최소화하여 효율성을 높입니다.",
        "Other Options": [
            "add-permission 명령은 특정 AWS 리소스에 접근을 부여하는 데 사용되지만, 메시지 가시성이나 폴링 효율성과 관련된 요구 사항을 직접적으로 해결하지는 않습니다.",
            "change-message-visibility 명령은 메시지의 가시성 타임아웃을 변경할 수 있지만, 롱 폴링을 설정하거나 큐 속성을 구성하는 데 도움이 되지 않아 전체 요구 사항과 관련성이 떨어집니다.",
            "delete-message 명령은 처리 후 메시지를 큐에서 제거하는 데 필수적이지만, 가시성 설정 구성이나 메시지 검색 최적화에는 도움이 되지 않아 귀하의 시나리오에 중요합니다."
        ]
    },
    {
        "Question Number": "34",
        "Situation": "당신은 고속 거래 데이터를 처리해야 하는 금융 애플리케이션을 위한 실시간 데이터 처리 파이프라인을 구현하는 임무를 맡은 DevOps 엔지니어입니다. 애플리케이션은 들어오는 거래를 처리하고, 사기 활동을 필터링하며, 의심스러운 활동이 감지되면 관련 팀에 알림을 보내야 합니다. 지연 시간을 최소화하고 다양한 작업 부하에 따라 자동으로 확장되는 솔루션을 설계하고자 합니다.",
        "Question": "다음 아키텍처 중 실시간 처리 및 의심스러운 거래 활동에 대한 경고를 가장 효율적으로 달성할 수 있는 것은 무엇입니까?",
        "Options": {
            "1": "Amazon EventBridge를 활용하여 거래 이벤트를 캡처하고, AWS Step Functions를 트리거하여 처리 워크플로를 실행하며, 의심스러운 활동이 감지되면 Amazon Chime을 통해 팀에 알림을 보냅니다.",
            "2": "Amazon Kinesis Data Streams를 사용하여 거래 데이터를 수집하고, AWS Lambda로 실시간 필터링을 수행한 후, Amazon SNS에 경고를 게시하여 관련 팀에 알림을 보냅니다.",
            "3": "Amazon SQS 큐를 구현하여 거래 데이터를 저장하고, AWS Batch를 사용하여 데이터를 주기적으로 처리하며, Amazon CloudWatch를 구성하여 처리 메트릭을 모니터링합니다.",
            "4": "Amazon DynamoDB를 활용하여 거래 데이터를 기록하고, AWS Glue를 설정하여 레코드를 배치 처리하며, Amazon SES를 통해 경고를 위한 알림을 보냅니다."
        },
        "Correct Answer": "Amazon Kinesis Data Streams를 사용하여 거래 데이터를 수집하고, AWS Lambda로 실시간 필터링을 수행한 후, Amazon SNS에 경고를 게시하여 관련 팀에 알림을 보냅니다.",
        "Explanation": "Amazon Kinesis Data Streams를 사용하면 고속 거래 데이터를 실시간으로 수집할 수 있으며, AWS Lambda는 낮은 지연 시간으로 서버리스 처리를 제공합니다. 이 조합은 사기 활동을 즉시 필터링할 수 있게 하며, Amazon SNS는 관련 팀에 실시간으로 경고를 효과적으로 알릴 수 있습니다.",
        "Other Options": [
            "Amazon SQS는 실시간 처리를 위해 설계되지 않았으며, 폴링 메커니즘으로 인해 지연을 초래합니다. AWS Batch는 실시간 요구 사항보다는 배치 처리에 더 적합합니다.",
            "Amazon DynamoDB는 주로 NoSQL 데이터베이스이며 스트리밍 데이터의 실시간 처리에 적합하지 않습니다. AWS Glue는 일반적으로 배치 지향의 ETL 작업에 사용되며, Amazon SES는 즉각적인 경고에 적합하지 않습니다.",
            "EventBridge는 이벤트를 캡처할 수 있지만 이벤트 기반 아키텍처에 더 적합합니다. AWS Step Functions는 간단한 거래 처리에 불필요한 복잡성을 추가하며, Amazon Chime을 통해 팀에 알림을 보내는 것은 SNS를 사용하는 것만큼 효율적이지 않을 수 있습니다."
        ]
    },
    {
        "Question Number": "35",
        "Situation": "한 회사는 AWS EventBridge를 사용하여 애플리케이션 이벤트를 모니터링하고 자동으로 응답합니다. 그들은 특정 이벤트 패턴이 발생할 때마다 알림을 보내도록 EventBridge를 구성하고 싶어합니다. 예를 들어, 새로운 사용자가 서비스에 가입할 때 알림이 발생해야 합니다. 알림은 추가 처리를 위해 Amazon SNS 주제로 전송되어야 합니다. DevOps 팀은 구성이 이벤트를 정확하게 캡처하고 알림을 적절히 트리거하도록 해야 합니다.",
        "Question": "DevOps 팀이 특정 이벤트 패턴에 따라 EventBridge가 SNS 주제로 알림을 보내도록 구성하기 위해 따라야 할 단계는 무엇입니까?",
        "Options": {
            "1": "원하는 이벤트 패턴으로 새로운 EventBridge 규칙을 생성하고 SNS 주제를 대상으로 지정합니다. 규칙이 활성화되어 있는지 확인합니다.",
            "2": "원하는 이벤트 패턴으로 새로운 EventBridge 규칙을 생성하되, 대상을 SNS 주제로 게시하는 AWS Lambda 함수로 설정합니다.",
            "3": "SNS 주제를 생성하고 EventBridge 규칙을 구성하여 이벤트 패턴을 지정하지 않고 모든 이벤트를 SNS 주제로 전달합니다.",
            "4": "EventBridge 이벤트 버스를 설정하고 CloudWatch 경고를 구성하여 이벤트 버스의 메트릭에 따라 SNS 주제로 알림을 트리거합니다."
        },
        "Correct Answer": "원하는 이벤트 패턴으로 새로운 EventBridge 규칙을 생성하고 SNS 주제를 대상으로 지정합니다. 규칙이 활성화되어 있는지 확인합니다.",
        "Explanation": "원하는 이벤트와 일치하는 이벤트 패턴으로 새로운 EventBridge 규칙을 생성하고 SNS 주제를 대상으로 지정하면 특정 이벤트가 발생할 때마다 알림을 효과적으로 보낼 수 있습니다. 이는 필요한 알림 설정을 달성하는 가장 직접적이고 효율적인 접근 방식입니다.",
        "Other Options": [
            "이 옵션은 AWS Lambda 함수를 추가하여 불필요한 복잡성을 도입합니다. 이 시나리오에서는 이벤트 패턴에 따라 SNS 주제에 직접 알림을 보내는 것이 목표입니다.",
            "이 옵션은 EventBridge의 이벤트 패턴 기능을 활용하지 못합니다. 모든 이벤트를 전달하면 가입 이벤트와 관련 없는 과도한 알림이 발생할 수 있습니다.",
            "이 옵션은 특정 이벤트 패턴에 따라 알림을 보내는 데 필요하지 않은 이벤트 버스와 함께 CloudWatch 경고를 사용하는 것을 잘못 제안합니다. EventBridge 규칙은 이 목적을 위해 특별히 설계되었습니다."
        ]
    },
    {
        "Question Number": "36",
        "Situation": "개발 팀은 AWS CodeDeploy를 사용하여 EC2 인스턴스에서 애플리케이션 배포를 자동화하고 있습니다. 그들은 배포 속도에 대한 특정 요구 사항이 있으며, 모든 대상 인스턴스에서 CodeDeploy 에이전트가 올바르게 구성되어 있는지 확인해야 합니다. 팀은 또한 배포 프로세스의 다양한 단계에서 필요한 스크립트를 실행하기 위해 배포 후크를 활용하여 애플리케이션 업데이트가 원활하게 이루어지도록 하고자 합니다.",
        "Question": "DevOps 엔지니어가 이 시나리오를 효과적으로 구성하기 위해 AWS CodeDeploy를 설정하는 데 사용할 조합은 무엇입니까? (두 개 선택)",
        "Options": {
            "1": "AWS Lambda 함수를 설정하여 배포 프로세스를 관리하고 특정 이벤트에 따라 CodeDeploy 배포를 트리거합니다.",
            "2": "모든 대상 EC2 인스턴스에서 CodeDeploy 에이전트를 실행하도록 구성하고, 배포 매니페스트를 위해 S3에 접근할 수 있도록 합니다.",
            "3": "AWS Elastic Beanstalk를 사용하여 애플리케이션 업데이트 중 트래픽을 관리하는 블루/그린 배포 전략을 구현합니다.",
            "4": "모든 인스턴스가 동시에 업데이트되도록 하여 배포 시간을 최소화하는 AllAtOnce 배포 전략을 사용합니다.",
            "5": "CodeDeploy의 배포 후크를 활용하여 'BeforeInstall' 및 'AfterInstall'과 같은 스크립트를 실행하여 애플리케이션 환경을 준비하고 배포 후 검증합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "모든 대상 EC2 인스턴스에서 CodeDeploy 에이전트를 실행하도록 구성하고, 배포 매니페스트를 위해 S3에 접근할 수 있도록 합니다.",
            "CodeDeploy의 배포 후크를 활용하여 'BeforeInstall' 및 'AfterInstall'과 같은 스크립트를 실행하여 애플리케이션 환경을 준비하고 배포 후 검증합니다."
        ],
        "Explanation": "정확한 답변은 EC2 인스턴스에서 CodeDeploy 에이전트가 올바르게 설정되어 배포를 관리하고, 배포 후크를 활용하여 필요한 배포 전후 작업을 수행하여 업데이트 후 애플리케이션이 원활하게 실행되도록 보장합니다.",
        "Other Options": [
            "AllAtOnce 배포 전략을 사용하는 것은 다운타임을 최소화하는 것이 우선이라면 최선의 선택이 아닐 수 있습니다. 모든 인스턴스를 동시에 업데이트하면 서비스 중단이 발생할 수 있습니다.",
            "AWS Elastic Beanstalk를 사용하여 블루/그린 배포 전략을 구현하는 것은 이 시나리오에 적용되지 않습니다. 질문은 AWS CodeDeploy를 사용하는 것에 중점을 두고 있으며, CodeDeploy는 자체 배포 전략을 가지고 있습니다.",
            "AWS Lambda 함수를 설정하여 배포를 관리하는 것은 유익하게 들릴 수 있지만, 배포 프로세스를 불필요하게 복잡하게 만들며 CodeDeploy를 직접 사용할 때의 표준 관행이 아닙니다."
        ]
    },
    {
        "Question Number": "37",
        "Situation": "글로벌 전자상거래 회사가 AWS에 호스팅된 마이크로서비스 아키텍처의 배포 및 구성을 자동화하려고 합니다. 그들은 모든 구성이 버전 관리되고 재현 가능하며 여러 환경(개발, 테스트 및 프로덕션)에서 일관되게 배포될 수 있도록 보장하고자 합니다. 팀은 인프라를 코드(IaC)로 관리하기 위해 AWS 서비스와 오픈 소스 도구를 사용하고 있습니다.",
        "Question": "DevOps 엔지니어로서, 회사의 마이크로서비스 자동 배포 및 구성 관리 요구 사항을 가장 잘 충족하는 솔루션은 무엇입니까?",
        "Options": {
            "1": "Terraform을 사용하여 마이크로서비스에 대한 인프라를 코드로 정의하고 구성 파일을 S3에 저장합니다. S3 버킷에 변경이 있을 때마다 Lambda 함수를 사용하여 서비스를 배포합니다.",
            "2": "AWS Elastic Beanstalk를 사용하여 마이크로서비스를 배포하고 관리 콘솔을 사용하여 구성합니다. 환경 변수를 관리하기 위해 AWS Systems Manager Parameter Store를 사용합니다.",
            "3": "AWS CloudFormation과 AWS CodePipeline을 함께 사용하여 마이크로서비스의 배포를 자동화합니다. CloudFormation 템플릿을 AWS CodeCommit과 같은 버전 관리 저장소에 저장하고 코드 변경 시 파이프라인을 트리거합니다.",
            "4": "AWS CDK를 구현하여 마이크로서비스에 대한 인프라를 코드로 생성하고 AWS AppConfig를 사용하여 여러 환경에서 구성을 관리합니다. CDK 코드를 버전 관리 저장소에 저장합니다."
        },
        "Correct Answer": "AWS CloudFormation과 AWS CodePipeline을 함께 사용하여 마이크로서비스의 배포를 자동화합니다. CloudFormation 템플릿을 AWS CodeCommit과 같은 버전 관리 저장소에 저장하고 코드 변경 시 파이프라인을 트리거합니다.",
        "Explanation": "AWS CloudFormation을 사용하면 인프라를 코드로 정의할 수 있어 배포가 일관되고 버전 관리됩니다. AWS CodePipeline과 통합하면 전체 CI/CD 프로세스가 자동화되어 다양한 환경에서 마이크로서비스를 관리하는 데 적합합니다. 템플릿을 버전 관리 저장소에 저장하면 추적 가능성과 협업이 향상됩니다.",
        "Other Options": [
            "Terraform을 활용하는 것은 IaC에 대한 유효한 접근 방식이지만, 구성 파일에 S3를 사용하는 것은 CodeCommit만큼의 자동화 또는 버전 관리를 제공하지 않습니다. 또한, 배포를 위해 Lambda 함수에만 의존하는 것은 전용 CI/CD 도구를 사용하는 것보다 프로세스를 복잡하게 만들 수 있습니다.",
            "AWS CDK를 구현하는 것은 IaC에 대한 현대적인 접근 방식이지만, 많은 조직에서 CloudFormation보다 덜 일반적입니다. 유연성을 제공하지만, 기존 CI/CD 파이프라인과의 통합이 CloudFormation만큼 원활하지 않을 수 있어 이 맥락에서의 효과가 제한될 수 있습니다.",
            "AWS Elastic Beanstalk를 통해 마이크로서비스를 배포하는 것은 배포를 간소화하지만, 인프라를 코드로 관리하는 데 필요한 수준의 제어 및 자동화를 제공하지 않습니다. 구성 관리를 위해 관리 콘솔에만 의존하는 것은 불일치로 이어질 수 있으며 대규모 환경에는 적합하지 않습니다."
        ]
    },
    {
        "Question Number": "38",
        "Situation": "회사는 다양한 지역에서 여러 AWS 계정을 관리하여 리소스 활용을 최적화하고 보안을 유지하고 있습니다. 그들은 새로운 AWS 계정의 온보딩 프로세스를 자동화하면서 보안 모범 사례가 처음부터 시행되도록 해야 합니다. 솔루션에는 계정 생성, 보안 정책 적용 및 필요한 리소스 구성 등이 포함되어야 합니다.",
        "Question": "다중 계정 환경에서 보안 모범 사례 준수를 보장하면서 새로운 AWS 계정의 생성 및 온보딩을 자동화하는 데 사용할 수 있는 AWS 서비스는 무엇입니까?",
        "Options": {
            "1": "AWS CloudFormation",
            "2": "AWS Control Tower",
            "3": "AWS Organizations",
            "4": "AWS Config"
        },
        "Correct Answer": "AWS Control Tower",
        "Explanation": "AWS Control Tower는 안전한 다중 계정 AWS 환경을 설정하고 관리하도록 특별히 설계되었습니다. 새로운 계정의 생성을 자동화하고 보안 모범 사례를 적용하며 필요한 리소스를 구성하여 보안 기준에 따라 새로운 계정을 온보딩하는 데 이상적인 선택입니다.",
        "Other Options": [
            "AWS Organizations는 여러 AWS 계정을 관리하는 데 도움이 되는 서비스이지만, 온보딩 프로세스를 자동화하거나 보안 모범 사례를 직접 시행하지는 않습니다. 주로 계정 관리 및 청구에 사용됩니다.",
            "AWS CloudFormation은 인프라를 코드로 배포하는 서비스입니다. 단일 계정에서 리소스를 생성하는 데 사용할 수 있지만, AWS Control Tower가 제공하는 계정 온보딩 기능이나 보안 거버넌스를 제공하지 않습니다.",
            "AWS Config는 리소스 인벤토리, 구성 이력 및 구성 변경 알림을 제공하는 서비스입니다. 이는 이미 프로비저닝된 리소스의 준수 및 모니터링에 중점을 두며, 새로운 계정의 온보딩을 자동화하는 것과는 관련이 없습니다."
        ]
    },
    {
        "Question Number": "39",
        "Situation": "회사는 애플리케이션을 AWS로 마이그레이션하고 있으며, 직원들이 여러 계정에서 AWS 리소스에 안전하고 효율적으로 접근할 수 있는 방법을 구현하고자 합니다. 회사는 이미 Active Directory를 사용하여 기업 아이덴티티 관리 시스템을 갖추고 있습니다. 그들은 사용자에 대한 단일 로그인(SSO) 기능을 활성화하고, 접근 권한이 중앙에서 관리되도록 하면서 사용자가 다양한 AWS 계정에서 역할을 맡을 수 있도록 하기를 원합니다. 회사는 사용자 접근 관리 및 보안 모범 사례 유지를 위한 관리 오버헤드를 최소화하는 데 특히 관심이 있습니다.",
        "Question": "다음 솔루션 중 회사의 AWS 계정 간 아이덴티티 연합 및 역할 위임 요구 사항을 가장 잘 충족하는 것은 무엇입니까?",
        "Options": {
            "1": "Active Directory에 연결되는 SAML 2.0을 사용하여 사용자 정의 아이덴티티 공급자를 배포하고, 교차 계정 접근을 위한 신뢰 정책으로 IAM 역할을 구성합니다.",
            "2": "AWS Directory Service를 사용하여 새 디렉토리를 생성하고 Active Directory에서 사용자 계정을 복제하여 AWS에서 역할 관리를 수행합니다.",
            "3": "AWS Single Sign-On(SSO)을 설정하여 사용자 접근을 관리하고, 이를 Active Directory와 통합하여 여러 계정 간 역할 위임을 수행합니다.",
            "4": "각 AWS 계정에 IAM 사용자를 생성하고, 각 사용자의 접근 필요에 따라 수동으로 권한을 구성합니다."
        },
        "Correct Answer": "AWS Single Sign-On(SSO)을 설정하여 사용자 접근을 관리하고, 이를 Active Directory와 통합하여 여러 계정 간 역할 위임을 수행합니다.",
        "Explanation": "AWS Single Sign-On(SSO)은 여러 AWS 계정에서 사용자 아이덴티티 및 접근을 관리하는 중앙 집중식 서비스를 제공하며, Active Directory와 원활하게 통합됩니다. 이 솔루션은 관리 오버헤드를 최소화하고, 사용자가 여러 계정에서 IAM 사용자를 필요로 하지 않고 리소스에 접근할 수 있도록 하여 보안을 강화합니다.",
        "Other Options": [
            "각 AWS 계정에 IAM 사용자를 생성하는 것은 권한 관리의 복잡성을 증가시키고 관리 오버헤드를 초래할 수 있으며, 각 사용자는 모든 계정에서 개별적으로 구성해야 합니다.",
            "SAML 2.0을 사용하여 사용자 정의 아이덴티티 공급자를 배포하는 것은 유효한 접근 방식이지만, AWS SSO를 사용하는 것보다 추가적인 설정 및 관리 노력이 필요합니다.",
            "AWS Directory Service를 사용하여 새 디렉토리를 생성하는 것은 역할 위임 및 교차 계정 접근의 필요를 직접적으로 해결하지 않으며, 기존 아이덴티티 관리를 효율적으로 활용하기보다는 사용자 계정을 복제하는 것을 포함합니다."
        ]
    },
    {
        "Question Number": "40",
        "Situation": "한 회사가 AWS에서 마이크로서비스 아키텍처를 사용하고 있으며, 인프라 관리를 위해 AWS CloudFormation을 활용하고 있습니다. DevOps 팀은 성능과 보안을 개선하기 위해 구성 업데이트를 자주 수행합니다. 최근 사건 이후, 팀은 구성 변경이 실행 중인 서비스에 방해가 되지 않도록 하고 필요 시 롤백할 수 있도록 해야 합니다. 팀은 여러 환경에서 구성 변경을 안전하게 적용하기 위한 전략을 평가하고 있습니다.",
        "Question": "어떤 접근 방식이 팀이 서비스 중단의 위험을 최소화하면서 마이크로서비스에 구성 변경을 적용할 수 있게 해줄까요?",
        "Options": {
            "1": "AWS CodeDeploy와 카나리 배포 전략을 채택하여 초기에는 새로운 구성으로의 트래픽을 소량으로 전환하여 문제를 모니터링한 후 전체 배포를 진행합니다.",
            "2": "AWS CloudFormation StackSets를 사용하여 여러 계정과 리전에서 변경 사항을 동시에 적용하고, 각 스택에 대해 롤백 기능이 활성화되도록 합니다.",
            "3": "AWS Elastic Beanstalk를 사용하여 블루/그린 배포 전략을 구현하여 새로운 구성이 업데이트된 버전으로 트래픽을 전환하기 전에 별도의 환경에서 테스트되도록 합니다.",
            "4": "AWS OpsWorks를 활용하여 애플리케이션을 관리하고 구성 변경을 단계적으로 배포하여 문제가 발생할 경우 이전 버전으로 쉽게 롤백할 수 있도록 합니다."
        },
        "Correct Answer": "AWS Elastic Beanstalk를 사용하여 블루/그린 배포 전략을 구현하여 새로운 구성이 업데이트된 버전으로 트래픽을 전환하기 전에 별도의 환경에서 테스트되도록 합니다.",
        "Explanation": "블루/그린 배포 전략을 구현하면 팀은 현재 버전(그린)이 활성 상태인 동안 새로운 구성(블루)을 격리된 환경에서 테스트할 수 있습니다. 이는 서비스 중단의 위험을 최소화하며, 새로운 구성이 안정성이 확인되면 트래픽을 전환할 수 있습니다. 또한, 트래픽을 그린 환경으로 다시 라우팅하여 빠르게 롤백할 수 있습니다.",
        "Other Options": [
            "AWS CloudFormation StackSets를 사용하면 동시에 변경할 수 있지만, 실행 중인 서비스에 영향을 주지 않고 구성을 테스트하기 위해 필요한 격리 수준을 제공하지 않을 수 있습니다. 롤백은 가능하지만 배포 중 서비스 중단의 위험은 여전히 존재합니다.",
            "AWS OpsWorks는 구성 배포를 효과적으로 관리할 수 있지만, 블루/그린 배포와 같은 수준의 격리를 본질적으로 제공하지 않으므로 업데이트 중 실행 중인 서비스에 잠재적인 중단을 초래할 수 있습니다.",
            "AWS CodeDeploy와 카나리 배포 전략은 실행 가능한 옵션이지만, 세심한 모니터링이 필요하며 초기 롤아웃 중 소수의 사용자에게 여전히 영향을 미칠 수 있습니다. 문제가 발생할 경우, 블루/그린 설정에서의 간단한 트래픽 재라우팅에 비해 롤백이 복잡할 수 있습니다."
        ]
    },
    {
        "Question Number": "41",
        "Situation": "소프트웨어 개발 팀이 AWS 서비스를 사용하여 소프트웨어 배포 프로세스를 자동화하고 있습니다. 그들은 컨테이너 이미지, 라이브러리 및 애플리케이션 바이너리와 같은 다양한 유형의 아티팩트를 저장하고 관리하기 위한 중앙 집중식 아티팩트 리포지토리를 만들고자 합니다. 팀은 리포지토리가 CI/CD 파이프라인과 쉽게 통합되고 버전 관리 및 접근 제어를 지원할 수 있도록 해야 합니다. 이 리포지토리를 설정하기 위한 여러 옵션을 고려하고 있습니다.",
        "Question": "버전 관리, 접근 제어 및 CI/CD 파이프라인과의 원활한 통합을 지원하는 중앙 집중식 아티팩트 리포지토리를 만들기 위해 팀이 선택해야 할 AWS 서비스는 무엇인가요?",
        "Options": {
            "1": "버전 관리가 활성화된 Amazon S3와 접근 제어를 위한 버킷 정책.",
            "2": "다양한 아티팩트 유형에 적합한 도메인과 리포지토리로 구성된 AWS CodeArtifact.",
            "3": "아티팩트 업로드를 처리하고 S3에 대한 접근을 직접 관리하는 AWS Lambda 함수.",
            "4": "보안 준수를 위한 이미지 스캔이 활성화된 Amazon Elastic Container Registry (ECR)."
        },
        "Correct Answer": "다양한 아티팩트 유형에 적합한 도메인과 리포지토리로 구성된 AWS CodeArtifact.",
        "Explanation": "AWS CodeArtifact는 다양한 패키지 관리자의 아티팩트를 관리하기 위해 특별히 설계되었으며, 내장된 버전 관리, 접근 제어를 제공하고 CI/CD 파이프라인과 원활하게 통합됩니다. 다양한 아티팩트 유형을 지원하여 팀의 요구에 적합합니다.",
        "Other Options": [
            "Amazon S3는 아티팩트 저장에 사용할 수 있으며 버전 관리를 지원할 수 있지만, CI/CD 프로세스를 간소화하기 위해 CodeArtifact가 제공하는 네이티브 통합 기능과 아티팩트 관리 기능이 부족합니다.",
            "Amazon Elastic Container Registry (ECR)는 Docker 컨테이너 이미지를 관리하는 데 뛰어나지만, 컨테이너 이미지에만 제한되며 CodeArtifact가 제공하는 다른 아티팩트 유형 관리의 유연성을 제공하지 않습니다.",
            "아티팩트 관리를 위해 AWS Lambda 함수를 사용하는 것은 추가적인 복잡성과 오버헤드를 초래하며, Lambda는 아티팩트 저장 및 관리에 적합하지 않으므로 CodeArtifact와 같은 전용 서비스에 비해 비효율적인 솔루션입니다."
        ]
    },
    {
        "Question Number": "42",
        "Situation": "한 회사가 데이터 저장 요구를 위해 Amazon DynamoDB를 사용하고 있으며, TTL(유효 기간)을 구현하여 테이블에서 만료된 항목을 자동으로 삭제하고 있습니다. 그들은 또한 DynamoDB 테이블의 변경 사항을 처리하기 위해 AWS Lambda에서 특정 작업을 트리거하고자 합니다. 이 설정의 일환으로, Lambda 함수가 DynamoDB Streams에서 읽을 때 성능을 유지하면서 스로틀링 문제를 피할 수 있도록 올바르게 구성되어야 합니다.",
        "Question": "다음 구성 중 Lambda 함수로 DynamoDB Streams에서 이벤트를 처리할 때 스로틀링을 가장 잘 방지할 수 있는 구성은 무엇인가요?",
        "Options": {
            "1": "DynamoDB Stream의 모든 이벤트를 읽고 순차적으로 처리하기 위해 단일 Lambda 함수를 설정하여 스로틀링을 피합니다.",
            "2": "Amazon SNS를 사용하여 DynamoDB Stream 이벤트를 여러 Lambda 함수로 분산 처리하는 팬 아웃 아키텍처를 구현합니다.",
            "3": "DynamoDB Stream의 단일 샤드에서 여러 Lambda 함수를 동시에 읽도록 구성하여 처리량을 극대화합니다.",
            "4": "DynamoDB Streams를 활성화하고 단일 Lambda 함수가 스트림의 여러 샤드에서 읽도록 하여 처리 용량을 증가시킵니다."
        },
        "Correct Answer": "Amazon SNS를 사용하여 DynamoDB Stream 이벤트를 여러 Lambda 함수로 분산 처리하는 팬 아웃 아키텍처를 구현합니다.",
        "Explanation": "Amazon SNS와 함께 팬 아웃 아키텍처를 사용하면 DynamoDB Streams에서 이벤트를 처리하는 부하를 여러 Lambda 함수에 분산시켜 스로틀링을 효과적으로 방지할 수 있습니다. 이는 한 샤드에서 동시에 두 개의 프로세스만 읽도록 보장합니다.",
        "Other Options": [
            "단일 샤드에서 여러 Lambda 함수를 읽도록 구성하면 스로틀링이 발생할 수 있습니다. DynamoDB Streams는 샤드당 최대 두 개의 동시 리더만 지원합니다.",
            "단일 Lambda 함수를 설정하여 이벤트를 순차적으로 처리하면 아키텍처는 단순해지지만 처리량을 극대화하지 못하고 처리 지연이 증가할 수 있습니다.",
            "단일 Lambda 함수가 여러 샤드에서 읽도록 활성화하는 것은 스로틀링 가능성을 해결하지 않으며, 여전히 단일 샤드에서 여러 리더가 있을 위험이 있습니다."
        ]
    },
    {
        "Question Number": "43",
        "Situation": "당신은 클라우드 기반 애플리케이션의 인프라를 유지 관리하는 책임이 있으며, 이 애플리케이션은 간헐적인 성능 문제를 겪고 있습니다. 철저한 조사를 한 결과, 특정 EC2 인스턴스가 잘못 구성되어 있어 과도한 리소스 소비가 발생하고 애플리케이션의 전반적인 성능에 영향을 미치고 있음을 발견했습니다. 이 원치 않는 시스템 상태를 효과적으로 수정해야 합니다.",
        "Question": "잘못 구성된 EC2 인스턴스를 수정하고 애플리케이션의 최적 성능을 복원하기 위한 최선의 접근 방법은 무엇입니까?",
        "Options": {
            "1": "AWS Config를 활용하여 EC2 인스턴스의 구성을 평가하고 비준수 설정에 대한 수정 작업을 적용합니다.",
            "2": "Amazon CloudWatch 경고를 생성하여 Auto Scaling 정책을 트리거하여 인스턴스를 종료하고 새 인스턴스를 시작합니다.",
            "3": "수동으로 EC2 인스턴스에 SSH로 접속하여 리소스 소비를 줄이기 위해 구성 설정을 조정합니다.",
            "4": "AWS Systems Manager를 사용하여 EC2 인스턴스에 대한 준수 스캔을 실행하고 비준수 문제를 자동으로 수정합니다."
        },
        "Correct Answer": "AWS Config를 활용하여 EC2 인스턴스의 구성을 평가하고 비준수 설정에 대한 수정 작업을 적용합니다.",
        "Explanation": "AWS Config를 사용하면 AWS 리소스의 구성을 지속적으로 모니터링하고 비준수 설정을 자동으로 수정할 수 있습니다. 이는 EC2 인스턴스가 정의된 규칙에 따라 올바르게 구성되도록 보장하고 수동 개입 없이 최적의 성능을 유지하는 데 도움을 줍니다.",
        "Other Options": [
            "AWS Systems Manager로 준수 스캔을 실행하면 문제를 식별할 수 있지만, 특별히 구성되지 않는 한 자동으로 수정하지 않으므로 즉각적인 해결에 덜 효율적입니다.",
            "EC2 인스턴스에 수동으로 SSH로 접속하여 설정을 조정하는 것은 인간의 개입이 필요하고 오류가 발생할 가능성이 있어 일관되고 신뢰할 수 있는 수정 방법으로는 바람직하지 않습니다.",
            "CloudWatch 경고를 생성하여 Auto Scaling 정책을 트리거하는 것은 보다 반응적인 접근 방식입니다. 인스턴스를 관리하는 데 도움이 될 수 있지만, 기존 인스턴스의 잘못 구성된 원인을 해결하지는 않습니다."
        ]
    },
    {
        "Question Number": "44",
        "Situation": "한 회사는 AWS 서비스를 사용하여 AWS 계정 활동 및 시스템 상태를 실시간으로 모니터링하고자 합니다. DevOps 엔지니어는 리소스 상태 변경이나 AWS Health에서 보고된 사고와 같은 AWS 환경 내에서 발생하는 특정 이벤트에 대한 자동 응답을 설정하는 임무를 맡고 있습니다. 엔지니어는 이벤트 처리를 중앙 집중화하고 이러한 이벤트에 따라 작업을 트리거하는 것을 목표로 하고 있습니다.",
        "Question": "DevOps 엔지니어가 AWS 서비스 이벤트 및 사고에 자동으로 시스템이 응답하도록 보장하기 위해 어떤 접근 방식을 구현해야 합니까?",
        "Options": {
            "1": "AWS Config를 사용하여 리소스 변경 사항을 모니터링하고 수동 검토를 위해 Amazon SNS 주제로 업데이트를 보냅니다.",
            "2": "Amazon EventBridge 규칙을 설정하여 AWS Health 이벤트와 일치시키고 사고 대응을 위해 AWS Lambda 함수를 호출합니다.",
            "3": "매시간 AWS Health를 폴링하고 변경 사항을 기록하는 예약된 AWS Lambda 함수를 구현합니다.",
            "4": "AWS Lambda 함수를 구성하여 CloudTrail 로그를 처리하고 특정 API 호출이 발생할 때 알림을 트리거합니다."
        },
        "Correct Answer": "Amazon EventBridge 규칙을 설정하여 AWS Health 이벤트와 일치시키고 사고 대응을 위해 AWS Lambda 함수를 호출합니다.",
        "Explanation": "Amazon EventBridge와 AWS Health를 통합하면 AWS 서비스에 영향을 미치는 이벤트에 대한 실시간 모니터링 및 자동 응답이 가능합니다. 이 설정은 사고가 보고될 때 즉각적인 조치를 취할 수 있도록 보장하여 사고 대응 능력을 크게 향상시킵니다.",
        "Other Options": [
            "AWS Lambda 함수를 구성하여 CloudTrail 로그를 처리하는 것은 AWS Health 이벤트의 실시간 모니터링을 제공하지 않으며, 이는 적시 사고 대응에 중요합니다.",
            "AWS Config를 사용하여 리소스 변경 사항을 모니터링하는 것은 이 경우 덜 효율적입니다. 왜냐하면 AWS Health 사고에 대한 즉각적인 응답을 제공하지 않기 때문입니다. 이는 서비스 건강을 유지하는 데 중요합니다.",
            "예약된 AWS Lambda 함수를 구현하여 매시간 AWS Health를 폴링하는 것은 사고 대응에 지연을 초래하며, 이는 능동적인 사고 관리 전략에 적합하지 않습니다."
        ]
    },
    {
        "Question Number": "45",
        "Situation": "한 금융 서비스 회사는 AWS를 활용하여 Amazon S3 버킷에 민감한 고객 데이터를 저장하고 있습니다. 그들은 AWS 서비스에서 생성된 모든 로그 데이터가 안전한 방법으로 저장 시 암호화되도록 해야 합니다. 이 회사는 암호화 키 관리를 위해 AWS Key Management Service (KMS)를 활용하기로 결정했습니다. DevOps 엔지니어는 상당한 운영 오버헤드를 발생시키지 않으면서 이 요구 사항을 충족하도록 로깅 솔루션을 구성하는 임무를 맡고 있습니다.",
        "Question": "모든 로그 데이터가 AWS KMS를 사용하여 암호화되도록 보장하기 위해 엔지니어가 취해야 할 단계는 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "특정 사용자에게 KMS 키를 생성할 수 있는 권한을 부여하는 IAM 정책을 설정하여 권한이 있는 인원만 암호화 설정을 관리할 수 있도록 합니다.",
            "2": "로그 데이터를 저장할 S3 버킷을 생성할 때 AWS KMS 키를 사용하여 서버 측 암호화를 활성화하고 암호화에 사용할 KMS 키를 지정합니다.",
            "3": "AWS CloudTrail 서비스를 구성하여 로그를 KMS 암호화된 Amazon S3 버킷으로 직접 전송하여 암호화가 적용되도록 합니다.",
            "4": "Amazon CloudWatch를 사용하여 로그를 수집하고 모니터링하며, 수집된 모든 로그 데이터에 KMS 암호화를 자동으로 적용하도록 구성합니다.",
            "5": "로그 생성 시 트리거되는 AWS Lambda 함수를 설정하여 Amazon S3에 저장하기 전에 KMS를 사용하여 로그 데이터를 암호화합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "로그 데이터를 저장할 S3 버킷을 생성할 때 AWS KMS 키를 사용하여 서버 측 암호화를 활성화하고 암호화에 사용할 KMS 키를 지정합니다.",
            "AWS CloudTrail 서비스를 구성하여 로그를 KMS 암호화된 Amazon S3 버킷으로 직접 전송하여 암호화가 적용되도록 합니다."
        ],
        "Explanation": "S3 버킷을 생성할 때 AWS KMS 키로 서버 측 암호화를 활성화하면 해당 버킷에 저장된 모든 로그 데이터가 자동으로 저장 시 암호화됩니다. AWS CloudTrail을 KMS 암호화된 S3 버킷으로 로그를 전송하도록 구성하면 모든 로그가 저장 중에 암호화되도록 보장하는 추가 보안 계층이 추가됩니다.",
        "Other Options": [
            "AWS Lambda 함수를 설정하여 로그 데이터를 암호화하는 것은 불필요한 복잡성과 운영 오버헤드를 추가하며, AWS 서비스의 내장 기능이 암호화를 자동으로 처리할 수 있습니다.",
            "Amazon CloudWatch를 로그 수집에 사용하는 것은 본질적으로 암호화를 제공하지 않으며, 로그가 저장될 때 암호화되도록 보장하기 위해 추가 구성이 필요합니다. 이는 요구 사항을 직접 충족하지 않습니다.",
            "KMS 키 관리를 위한 IAM 정책을 설정하는 것은 로그 데이터의 암호화와 직접적인 관련이 없으며, 실제 암호화 프로세스보다는 권한에 초점을 맞추고 있습니다."
        ]
    },
    {
        "Question Number": "46",
        "Situation": "개발자가 Amazon S3에 저장된 정적 웹사이트 파일을 효율적으로 관리해야 하는 프로젝트를 진행하고 있습니다. 개발자는 버킷에 대한 버전 관리를 구현하고 파일 업로드에 대한 알림을 구성해야 합니다. 이 프로젝트는 또한 S3 API를 사용하여 파일을 프로그래밍 방식으로 이동하고 삭제할 수 있는 기능이 필요합니다.",
        "Question": "S3 리소스를 관리하기 위한 운영 요구 사항을 달성하기 위해 필요한 단계는 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "put-bucket-versioning API 호출을 사용하여 S3 버킷에서 버전 관리를 활성화합니다. 이를 통해 개발자는 버킷에 저장된 파일의 다양한 버전을 추적할 수 있습니다.",
            "2": "AWS CLI의 sync 명령을 사용하여 로컬 파일을 S3 버킷과 자동으로 동기화합니다. 이를 통해 로컬 파일의 변경 사항이 S3 버킷에 업데이트됩니다.",
            "3": "put-bucket-notification-configuration API 호출을 사용하여 버킷 알림 설정을 구성합니다. 이를 통해 파일 업로드와 같은 특정 이벤트에 대한 알림을 활성화할 수 있습니다.",
            "4": "head-object API를 사용하여 S3 버킷의 특정 객체 메타데이터를 확인합니다. 이를 통해 객체에 올바른 버전 관리가 활성화되어 있는지에 대한 통찰력을 제공합니다.",
            "5": "rm 명령을 구현하여 S3 버킷에서 파일을 직접 삭제합니다. 이 명령은 확인 없이 파일을 제거합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "put-bucket-versioning API 호출을 사용하여 S3 버킷에서 버전 관리를 활성화합니다. 이를 통해 개발자는 버킷에 저장된 파일의 다양한 버전을 추적할 수 있습니다.",
            "put-bucket-notification-configuration API 호출을 사용하여 버킷 알림 설정을 구성합니다. 이를 통해 파일 업로드와 같은 특정 이벤트에 대한 알림을 활성화할 수 있습니다."
        ],
        "Explanation": "put-bucket-versioning API 호출을 사용하여 S3 버킷에서 버전 관리를 활성화하면 모든 객체 버전이 유지되어 변경 이력을 제공합니다. 버킷 알림 설정을 구성하면 개발자가 새로운 파일 업로드와 같은 특정 이벤트에 대해 알림을 받을 수 있어 웹사이트 콘텐츠 유지에 중요합니다.",
        "Other Options": [
            "sync 명령을 사용하는 것은 S3 버킷을 로컬 변경 사항으로 업데이트하는 데 유용하지만, 이는 버전 관리나 알림과 같은 작업의 핵심 요구 사항을 관리하기 위한 필수 단계는 아닙니다.",
            "rm 명령을 사용하면 S3 버킷에서 파일을 삭제할 수 있지만, 이 작업은 버전 관리나 알림 구성의 운영 요구 사항을 지원하지 않습니다. 삭제는 버전 유지에 역효과를 줍니다.",
            "head-object API는 메타데이터를 확인하는 데 유용하지만, 이 시나리오의 주요 목표인 버전 관리나 알림 구성을 설정하는 데 직접적으로 기여하지 않습니다."
        ]
    },
    {
        "Question Number": "47",
        "Situation": "고성능 애플리케이션에 적합한 Amazon EC2 인스턴스 유형을 선택하는 임무를 맡았습니다. 이 애플리케이션은 향상된 네트워킹과 최소한의 지연 시간을 요구합니다. 사용 가능한 인스턴스 유형을 고려하는 동안 HVM 및 PV 인스턴스를 모두 발견했습니다. 조직 내 일부 오래된 애플리케이션은 매력적인 스팟 가격 때문에 여전히 PV 인스턴스를 사용하고 있습니다.",
        "Question": "HVM 유형에 비해 제한이 있음에도 불구하고 오래된 PV 인스턴스 유형을 사용하는 주요 이유는 무엇입니까?",
        "Options": {
            "1": "모든 현대 HVM 인스턴스에서 사용할 수 있는 기능과 호환됩니다.",
            "2": "향상된 네트워킹 기능이 필요한 작업 부하에 대해 더 나은 성능을 제공합니다.",
            "3": "비용을 상당히 줄일 수 있는 매력적인 스팟 가격 옵션을 제공합니다.",
            "4": "GPU 작업 부하를 효과적으로 지원하는 유일한 인스턴스 유형입니다."
        },
        "Correct Answer": "비용을 상당히 줄일 수 있는 매력적인 스팟 가격 옵션을 제공합니다.",
        "Explanation": "PV 인스턴스는 향상된 네트워킹과 같은 고급 기능을 지원하지 않을 수 있지만, 매력적인 스팟 가격 덕분에 특정 사용 사례, 특히 성능이 중요하지 않은 작업 부하에 대해 비용 효율적인 옵션이 됩니다.",
        "Other Options": [
            "이 옵션은 PV 인스턴스가 HVM 인스턴스에 비해 더 나은 성능을 제공하지 않기 때문에 잘못된 것입니다. 특히 향상된 네트워킹의 이점을 누리는 작업 부하에 대해서는 더욱 그렇습니다.",
            "이 옵션은 PV 인스턴스가 현대 HVM 인스턴스에서 사용할 수 있는 모든 기능을 지원하지 않기 때문에 잘못된 것입니다. 이는 특정 애플리케이션의 사용성을 제한할 수 있습니다.",
            "이 옵션은 PV 인스턴스가 일반적으로 GPU 작업 부하를 위해 설계되지 않았기 때문에 잘못된 것입니다. GPU 작업 부하는 특정 HVM 인스턴스 유형에서 더 잘 지원됩니다."
        ]
    },
    {
        "Question Number": "48",
        "Situation": "개발 팀이 AWS CodePipeline을 사용하여 애플리케이션 배포를 자동화하는 CI/CD 파이프라인을 구현하고 있습니다. 그들은 Amazon EC2 인스턴스에 배포 에이전트를 구성하여 배포가 신뢰할 수 있고 효율적으로 실행되도록 해야 합니다. 팀은 수동 개입 없이 배포 에이전트를 자동으로 업데이트할 수 있는 솔루션이 필요하며, 항상 최신 버전을 실행하도록 보장해야 합니다.",
        "Question": "DevOps 엔지니어로서 EC2 인스턴스의 배포 에이전트를 어떻게 구성해야 합니까? (두 가지 선택)",
        "Options": {
            "1": "CodeDeploy 에이전트가 미리 설치된 Amazon Machine Image (AMI)를 생성하고 이 AMI에서 인스턴스를 시작하여 배포합니다.",
            "2": "AWS Systems Manager를 사용하여 CodeDeploy 에이전트를 자동으로 설치하고 업데이트하는 State Manager 연관을 생성합니다.",
            "3": "각 EC2 인스턴스에 수동으로 SSH로 접속하여 CodeDeploy 에이전트를 설치하고 필요에 따라 정기적으로 업데이트합니다.",
            "4": "CodeDeploy 에이전트 설치 스크립트를 사용하는 시작 템플릿으로 Auto Scaling 그룹을 구성하여 모든 인스턴스에 에이전트가 있도록 합니다.",
            "5": "모든 EC2 인스턴스에서 매주 CodeDeploy 에이전트를 업데이트하는 AWS Lambda 함수를 설정합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "AWS Systems Manager를 사용하여 CodeDeploy 에이전트를 자동으로 설치하고 업데이트하는 State Manager 연관을 생성합니다.",
            "CodeDeploy 에이전트 설치 스크립트를 사용하는 시작 템플릿으로 Auto Scaling 그룹을 구성하여 모든 인스턴스에 에이전트가 있도록 합니다."
        ],
        "Explanation": "AWS Systems Manager를 사용하여 State Manager 연관을 생성하면 EC2 인스턴스에서 CodeDeploy 에이전트를 자동으로 설치하고 업데이트할 수 있어 수동 개입 없이 항상 최신 상태를 유지할 수 있습니다. 또한 CodeDeploy 에이전트 설치 스크립트를 포함하는 시작 템플릿으로 Auto Scaling 그룹을 구성하면 새로 시작된 인스턴스가 자동으로 최신 에이전트를 설치하도록 보장하여 배포 자동화의 모범 사례에 부합합니다.",
        "Other Options": [
            "각 EC2 인스턴스에 수동으로 SSH로 접속하여 CodeDeploy 에이전트를 설치하고 필요에 따라 정기적으로 업데이트하는 것은 확장성이 없고 시간이 지남에 따라 불일치와 오류를 초래할 수 있는 수동 단계를 도입합니다.",
            "CodeDeploy 에이전트가 미리 설치된 Amazon Machine Image (AMI)를 생성하고 이 AMI에서 인스턴스를 시작하여 배포하는 것은 가능하지만, 기존 인스턴스에서 에이전트를 자동으로 업데이트하는 방법을 제공하지 않으므로 자동화 요구 사항을 완전히 충족하지 않습니다.",
            "모든 EC2 인스턴스에서 매주 CodeDeploy 에이전트를 업데이트하는 AWS Lambda 함수를 설정하는 것은 불필요한 복잡성을 도입하며, 에이전트를 항상 최신 상태로 유지하는 가장 효율적이거나 신뢰할 수 있는 방법이 아닙니다."
        ]
    },
    {
        "Question Number": "49",
        "Situation": "AWS Lambda에서 실행되는 애플리케이션의 코드 품질과 성능을 개선하는 임무를 맡았습니다. 관리 팀은 코드 저장소에 하드코딩된 비밀이 존재하는 것에 대해 우려를 표명했으며, 애플리케이션이 효율적으로 실행되도록 하면서도 상당한 오버헤드를 추가하지 않기를 원합니다.",
        "Question": "하드코딩된 비밀을 식별하고 Lambda 함수의 성능 최적화를 모두 해결하기 위해 어떤 AWS 서비스를 구현해야 합니까?",
        "Options": {
            "1": "AWS CodePipeline을 구현하여 배포 프로세스를 자동화하고 AWS CloudTrail을 사용하여 잠재적인 보안 문제에 대한 API 호출을 모니터링합니다.",
            "2": "AWS CloudWatch를 배포하여 애플리케이션 성능 메트릭을 모니터링하고 AWS Config를 구성하여 리소스 준수를 평가하고 구성을 관리합니다.",
            "3": "Amazon CodeGuru Reviewer를 활용하여 정적 코드 분석을 수행하고 하드코딩된 비밀을 식별하며, CodeGuru Profiler를 사용하여 성능 권장 사항을 제공합니다.",
            "4": "Amazon Inspector를 활용하여 취약성 평가를 수행하고 AWS Lambda와 통합하여 지속적인 보안 모니터링을 합니다."
        },
        "Correct Answer": "Amazon CodeGuru Reviewer를 활용하여 정적 코드 분석을 수행하고 하드코딩된 비밀을 식별하며, CodeGuru Profiler를 사용하여 성능 권장 사항을 제공합니다.",
        "Explanation": "Amazon CodeGuru는 코드에서 하드코딩된 비밀을 식별하기 위한 Reviewer 기능과 애플리케이션 성능을 최적화하기 위한 Profiler 기능을 모두 제공합니다. 이 이중 기능은 코드 품질과 런타임 효율성을 원활하게 향상시킬 수 있게 해줍니다.",
        "Other Options": [
            "AWS CodePipeline은 주로 지속적인 통합 및 배포에 중점을 두며, 배포 자동화에 도움을 주지만 정적 코드 분석이나 성능 최적화 기능을 제공하지 않습니다.",
            "AWS CloudWatch는 애플리케이션 성능 메트릭을 모니터링하는 데 사용되지만 하드코딩된 비밀을 구체적으로 식별하지는 않습니다. AWS Config는 리소스 준수 관리에 중점을 두며 코드 품질을 직접적으로 다루지 않습니다.",
            "Amazon Inspector는 보안 평가 및 취약성 스캔을 위한 것이지만 정적 코드 분석이나 애플리케이션 성능 프로파일링 기능을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "50",
        "Situation": "DevOps 엔지니어는 여러 소스에서 실시간 데이터를 처리하기 위한 확장 가능하고 탄력적인 이벤트 기반 아키텍처를 설계하는 임무를 맡았습니다. 데이터는 적시에 처리되어야 하며, 데이터 손실이 없도록 하고 시스템이 데이터 양의 급증을 처리할 수 있어야 합니다. 솔루션은 비동기 처리를 허용하고 서비스의 분리를 통해 유지 관리성과 확장성을 향상시켜야 합니다.",
        "Question": "이 시나리오에서 실시간 데이터 처리를 위한 요구 사항을 가장 잘 충족하는 아키텍처 설계는 무엇입니까?",
        "Options": {
            "1": "Amazon Kinesis Data Stream을 배포하여 실시간 데이터를 수집하고, 데이터 도착 시 호출되는 여러 AWS Lambda 함수를 생성하여 데이터를 병렬로 처리합니다. Amazon S3를 저장소로 사용합니다.",
            "2": "AWS Step Functions를 사용하여 Amazon Kinesis Data Stream에서 들어오는 이벤트 처리를 조정하여 각 이벤트가 일관성을 위해 순차적으로 처리되도록 합니다.",
            "3": "Amazon SNS 주제를 구성하여 AWS Lambda 및 Amazon SQS를 포함한 여러 구독자에게 메시지를 게시하여 실시간 이벤트의 팬 아웃 처리를 허용합니다.",
            "4": "Amazon SQS 큐를 구현하여 들어오는 요청을 버퍼링하고 EC2 인스턴스가 큐를 폴링하여 메시지를 처리하도록 합니다. 이는 데이터가 순서대로 처리되도록 하지만 지연을 초래합니다."
        },
        "Correct Answer": "Amazon SNS 주제를 구성하여 AWS Lambda 및 Amazon SQS를 포함한 여러 구독자에게 메시지를 게시하여 실시간 이벤트의 팬 아웃 처리를 허용합니다.",
        "Explanation": "Amazon SNS를 사용한 팬 아웃 아키텍처는 메시지를 여러 구독자에게 동시에 게시할 수 있게 하여 AWS Lambda 함수로 처리하고 Amazon SQS로 메시지를 버퍼링할 수 있습니다. 이 설계는 확장성을 제공하고 서비스를 분리하며 모든 메시지가 손실 없이 처리되도록 하여 실시간 데이터 처리 요구 사항을 충족합니다.",
        "Other Options": [
            "Amazon Kinesis Data Stream을 배포하면 실시간 데이터 수집이 가능하지만 팬 아웃 메커니즘이 없으면 확장성과 유연성이 제한되어 한 번에 단일 소비자만 처리할 수 있습니다.",
            "Amazon SQS 큐를 구현하면 EC2 인스턴스가 큐를 폴링하여 메시지 처리 지연이 발생하므로 실시간 처리 요구 사항을 충족하지 못하고 비용과 복잡성이 증가할 수 있습니다.",
            "AWS Step Functions를 사용하여 이벤트를 순차적으로 처리하면 병목 현상과 데이터 처리 지연이 발생할 수 있으며, 이는 데이터 양의 급증을 처리하는 데 중요한 비동기 처리를 활용하지 않기 때문입니다."
        ]
    },
    {
        "Question Number": "51",
        "Situation": "데이터 분석 팀은 온프레미스 MySQL 데이터베이스에서 데이터를 정기적으로 추출하고 변환하여 Amazon Redshift에 로드하여 분석할 수 있는 솔루션이 필요합니다. 이 프로세스를 자동화할 수 있는 신뢰할 수 있고 확장 가능한 방법을 찾고 있습니다.",
        "Question": "이 시나리오에서 AWS Data Pipeline의 어떤 기능이 도움이 될 수 있습니까? (두 가지 선택)",
        "Options": {
            "1": "온프레미스 데이터 추출을 위한 Amazon RDS.",
            "2": "데이터 처리 단계를 정의하는 활동.",
            "3": "활동을 예약하기 위한 파이프라인 정의.",
            "4": "ETL 작업을 위한 AWS Glue.",
            "5": "EC2 인스턴스 작업 관리를 위한 태스크 러너."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "활동을 예약하기 위한 파이프라인 정의.",
            "데이터 처리 단계를 정의하는 활동."
        ],
        "Explanation": "AWS Data Pipeline의 파이프라인 정의 기능을 사용하면 데이터 워크플로의 일정과 구조를 지정할 수 있으며, 활동은 데이터 추출, 변환 및 Amazon Redshift로의 로드와 같은 실행해야 할 특정 단계를 정의합니다.",
        "Other Options": [
            "태스크 러너는 작업을 실행하는 데 사용되지만 전체 데이터 파이프라인에 필요한 예약 및 조정 기능을 본질적으로 제공하지 않습니다.",
            "AWS Glue는 ETL을 위한 별도의 서비스이며 유사한 기능을 수행할 수 있지만 AWS Data Pipeline의 일부가 아니며 질문에 명시되어 있지 않습니다.",
            "Amazon RDS는 관리형 데이터베이스 서비스이며 추가 구성 없이 온프레미스 MySQL 데이터베이스에서 직접 데이터를 추출할 수 없습니다. 예를 들어 데이터 파이프라인이나 유사한 서비스를 사용하는 것이 필요합니다."
        ]
    },
    {
        "Question Number": "52",
        "Situation": "한 회사가 애플리케이션의 다양한 구성 요소 간에 신뢰할 수 있는 메시징이 필요한 마이크로서비스 아키텍처를 개발하고 있습니다. DevOps 엔지니어는 서비스를 분리하고 메시지 전달을 보장하기 위해 Amazon SQS를 사용하기로 결정했습니다. 애플리케이션은 다양한 작업 부하를 처리하고 높은 가용성을 유지해야 합니다.",
        "Question": "Amazon SQS의 사용을 최적화하기 위해 엔지니어가 구현해야 할 기능 및 구성의 조합은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "빈 응답 수를 줄이기 위해 롱 폴링을 사용합니다.",
            "2": "더 큰 메시지 크기를 위해 SQS 확장 클라이언트 라이브러리를 구현합니다.",
            "3": "높은 우선 순위 메시지와 낮은 우선 순위 메시지를 위해 두 개의 SQS 큐를 구성합니다.",
            "4": "메시지 전달 순서를 보장하기 위해 FIFO 큐를 설정합니다.",
            "5": "비용 절감을 위해 메시지 보존 기간을 7일로 제한합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "높은 우선 순위 메시지와 낮은 우선 순위 메시지를 위해 두 개의 SQS 큐를 구성합니다.",
            "빈 응답 수를 줄이기 위해 롱 폴링을 사용합니다."
        ],
        "Explanation": "높은 우선 순위 메시지와 낮은 우선 순위 메시지를 위해 두 개의 SQS 큐를 구성하면 서로 다른 메시지 유형을 효율적으로 처리할 수 있어 중요한 메시지가 신속하게 처리됩니다. 롱 폴링을 사용하면 큐가 비어 있을 때 요청 수를 줄여 비용을 최소화하고 효율성을 향상시킬 수 있습니다.",
        "Other Options": [
            "메시지 보존 기간을 7일로 제한하는 것은 최적이 아닙니다. Amazon SQS는 최대 14일의 보존을 허용하므로, 더 긴 기간 동안 메시지를 보존하는 것이 지연 처리에 유리할 수 있습니다.",
            "SQS 확장 클라이언트 라이브러리를 구현하는 것은 더 큰 메시지 크기에 유용하지만, 이 시나리오에서 SQS 큐의 성능이나 신뢰성을 직접적으로 최적화하지는 않습니다.",
            "FIFO 큐를 설정하는 것은 메시지 순서가 중요하지 않은 시나리오에서는 필요하지 않기 때문에 요구 사항과 모순되며, 추가 지연을 초래할 수 있습니다."
        ]
    },
    {
        "Question Number": "53",
        "Situation": "한 온라인 소매 회사가 애플리케이션 모니터링 기능을 향상시키고자 합니다. 개발 팀은 Amazon CloudWatch를 사용하여 서비스의 성능과 건강을 나타내는 다양한 메트릭을 추적하고 있습니다. 그들은 특히 서로 다른 메트릭 간의 관계를 이해하고 네임스페이스, 차원 및 메트릭 해상도를 효과적으로 활용하는 방법에 관심이 있습니다.",
        "Question": "DevOps 엔지니어가 Amazon CloudWatch 메트릭을 사용하여 애플리케이션 성능을 정확하게 모니터링하기 위해 어떤 접근 방식을 사용해야 합니까?",
        "Options": {
            "1": "각 애플리케이션에 대해 고유한 네임스페이스로 CloudWatch에서 사용자 정의 메트릭을 생성하고 인스턴스 및 애플리케이션 버전을 구분하기 위해 관련 차원을 포함합니다.",
            "2": "CloudWatch를 구성하여 오류율 및 지연 메트릭만 추적하도록 하여 애플리케이션 성능의 가장 중요한 지표를 모니터링합니다.",
            "3": "AWS에서 제공하는 기본 CloudWatch 메트릭을 활용하고, 모든 서비스에 대해 가장 세분화된 데이터를 캡처하기 위해 높은 해상도로 설정합니다.",
            "4": "차원을 지정하지 않고 서로 다른 네임스페이스의 모든 메트릭을 집계하는 단일 CloudWatch 대시보드를 구현하여 전체 애플리케이션 건강에 대한 단순화된 뷰를 제공합니다."
        },
        "Correct Answer": "각 애플리케이션에 대해 고유한 네임스페이스로 CloudWatch에서 사용자 정의 메트릭을 생성하고 인스턴스 및 애플리케이션 버전을 구분하기 위해 관련 차원을 포함합니다.",
        "Explanation": "고유한 네임스페이스로 사용자 정의 메트릭을 생성하면 각 애플리케이션에 특정한 메트릭을 더 잘 조직하고 추적할 수 있습니다. 차원을 포함하면 인스턴스 간의 차별화된 모니터링이 가능해져 특정 애플리케이션 버전이나 환경 속성에 따라 성능 문제를 식별하기가 더 쉬워집니다.",
        "Other Options": [
            "기본 CloudWatch 메트릭을 활용하는 것은 유익하지만, 이를 단독으로 사용하는 것은 애플리케이션 특정 성능에 대한 맞춤화나 심층 분석을 허용하지 않으므로 정확한 모니터링에 필수적입니다.",
            "차원을 지정하지 않고 모든 메트릭을 집계하면 세분화가 손실되어 특정 인스턴스나 구성과 관련된 문제를 파악하기 어려워져 모니터링의 효과가 감소할 수 있습니다.",
            "오류율 및 지연 메트릭에만 집중하면 CPU 사용률, 메모리 사용량 및 요청 수와 같은 다른 중요한 메트릭을 간과하게 되어 애플리케이션 성능에 대한 전체적인 관점을 놓칠 수 있습니다."
        ]
    },
    {
        "Question Number": "54",
        "Situation": "DevOps 엔지니어가 컨테이너화 및 서버리스 기능을 활용하는 새로운 마이크로서비스 애플리케이션을 AWS에 배포하는 임무를 맡았습니다. 배포 전략은 가동 중단 시간을 최소화하면서 높은 가용성을 보장해야 합니다. 엔지니어는 여러 배포 전략을 고려하고 있으며 최상의 접근 방식을 찾고 있습니다.",
        "Question": "DevOps 엔지니어가 애플리케이션의 컨테이너화된 구성 요소와 서버리스 구성 요소 모두에 대해 최소한의 가동 중단 시간과 높은 가용성을 보장하기 위해 어떤 배포 전략을 구현해야 합니까?",
        "Options": {
            "1": "불변 인프라 접근 방식을 사용하여 컨테이너화된 서비스를 배포하고, AWS SAM을 사용하여 서버리스 기능의 이전 버전과의 호환성을 유지합니다.",
            "2": "컨테이너 서비스에 대해 롤링 배포를 구현하고, AWS Lambda를 사용하여 서버리스 기능을 단일 배포 단계에서 배포하여 복잡성을 줄입니다.",
            "3": "AWS CloudFormation을 사용하여 모든 구성 요소를 동시에 배포하고, 컨테이너와 서버리스 기능에 대해 동일한 스택을 사용합니다.",
            "4": "AWS CodeDeploy를 사용하여 컨테이너화된 서비스에 대해 블루/그린 배포를 구현하고, 서버리스 기능에 대해 카나리 배포를 사용하여 점진적인 트래픽 전환을 허용합니다."
        },
        "Correct Answer": "AWS CodeDeploy를 사용하여 컨테이너화된 서비스에 대해 블루/그린 배포를 구현하고, 서버리스 기능에 대해 카나리 배포를 사용하여 점진적인 트래픽 전환을 허용합니다.",
        "Explanation": "컨테이너화된 서비스에 대한 블루/그린 배포 전략은 기존 버전과 함께 새 버전을 배포할 수 있어 쉽게 롤백할 수 있는 옵션을 제공합니다. 서버리스 기능에 대한 카나리 배포는 초기에는 소량의 트래픽만 새 버전으로 전환되도록 하여 모니터링 및 문제가 감지될 경우 신속한 롤백을 가능하게 하여 가동 중단 시간을 최소화하고 높은 가용성을 보장합니다.",
        "Other Options": [
            "롤링 배포는 인스턴스가 하나씩 업데이트되므로 짧은 서비스 중단을 초래할 수 있으며, 이는 최소한의 가동 중단 시간 요구 사항을 충족하지 못할 수 있습니다. 서버리스 기능을 단일 단계에서 배포하면 새로운 배포에 문제가 발생할 경우 위험이 발생할 수 있습니다.",
            "불변 인프라는 안정성을 제공할 수 있지만, 빠른 업데이트가 필요한 환경에는 최적의 선택이 아닐 수 있습니다. AWS SAM은 서버리스 배포에 효과적이지만, 카나리 배포와 같은 점진적인 트래픽 전환 전략 없이 최소한의 가동 중단 시간을 보장하지 않을 수 있습니다.",
            "모든 구성 요소를 동시에 배포하면 새 버전과 이전 버전 간의 호환성 문제로 인해 복잡성이 발생할 수 있습니다. 이 접근 방식은 본질적으로 롤백 메커니즘을 제공하지 않거나 가동 중단 시간을 효과적으로 최소화하지 않습니다."
        ]
    },
    {
        "Question Number": "55",
        "Situation": "귀하는 AWS 서비스를 사용하여 애플리케이션의 CI/CD 파이프라인을 개발하고 있습니다. 코드 자동 컴파일, 테스트 실행 및 배포를 위한 아티팩트 생성을 수행할 수 있는 빌드 프로세스를 설정해야 합니다. 빌드 프로세스가 효율적이고 확장 가능하며 다른 AWS 서비스와 잘 통합되도록 하고 싶습니다. 이를 달성하기 위해 어떤 서비스를 사용해야 할까요?",
        "Question": "CI/CD 파이프라인에서 빌드 프로세스를 자동화하기 위해 어떤 AWS 서비스를 사용하시겠습니까?",
        "Options": {
            "1": "AWS Lambda",
            "2": "AWS CodeBuild",
            "3": "AWS CodePipeline",
            "4": "AWS CodeDeploy"
        },
        "Correct Answer": "AWS CodeBuild",
        "Explanation": "AWS CodeBuild는 소스 코드를 컴파일하고, 테스트를 실행하며, 배포 준비가 완료된 소프트웨어 패키지를 생성하는 완전 관리형 빌드 서비스입니다. 다른 AWS 서비스와 원활하게 통합되어 CI/CD 파이프라인에서 빌드 프로세스를 자동화하는 데 가장 적합한 선택입니다.",
        "Other Options": [
            "AWS CodeDeploy는 애플리케이션을 다양한 컴퓨팅 서비스에 배포하는 데 주로 초점을 맞추고 있으며, 빌드 프로세스를 관리하는 데 중점을 두지 않습니다.",
            "AWS CodePipeline은 소프트웨어 릴리스 프로세스를 자동화하는 오케스트레이션 서비스이지만, 실제 빌드 작업을 처리하기 위해 CodeBuild와 같은 빌드 서비스가 필요합니다.",
            "AWS Lambda는 이벤트에 응답하여 코드를 실행하는 서버리스 컴퓨팅 서비스이지만, 애플리케이션을 빌드하거나 빌드 프로세스를 관리하도록 설계되지 않았습니다."
        ]
    },
    {
        "Question Number": "56",
        "Situation": "한 회사가 수동 개입 없이 다양한 부하를 효율적으로 처리할 수 있는 새로운 사진 처리 애플리케이션을 개발하고 있습니다. 애플리케이션은 들어오는 요청 수에 따라 자동으로 확장되어야 하며, 사용하지 않을 때 비용을 최소화해야 합니다. 회사는 이 솔루션을 위해 서버리스 아키텍처를 활용하고자 합니다.",
        "Question": "AWS 서비스를 사용하여 이 사진 처리 애플리케이션을 구현하기 위한 가장 적절한 아키텍처는 무엇입니까?",
        "Options": {
            "1": "AWS Step Functions를 트리거하는 엔드포인트를 노출하기 위해 Amazon API Gateway를 사용하여 서버리스 애플리케이션을 설정하고, 여러 Lambda 함수를 조정하여 사진 처리를 수행합니다.",
            "2": "Amazon S3 이벤트에 의해 트리거되는 AWS Lambda 함수를 사용하여 사진이 업로드될 때 처리하고, 처리된 이미지를 Amazon S3 버킷에 저장합니다.",
            "3": "다양한 부하를 처리하기 위해 Auto Scaling이 있는 Amazon EC2 인스턴스를 사용하여 애플리케이션을 배포하고, 들어오는 요청을 분산하기 위해 Elastic Load Balancer를 활용합니다.",
            "4": "Amazon ECS와 Fargate를 사용하여 사진 처리를 수행하는 컨테이너를 실행하고, CloudWatch Events 규칙을 설정하여 일정 간격에 따라 처리를 트리거합니다."
        },
        "Correct Answer": "Amazon S3 이벤트에 의해 트리거되는 AWS Lambda 함수를 사용하여 사진이 업로드될 때 처리하고, 처리된 이미지를 Amazon S3 버킷에 저장합니다.",
        "Explanation": "S3 이벤트에 의해 트리거되는 AWS Lambda 함수를 사용하면 수요에 따라 자동으로 확장되는 완전 서버리스 솔루션을 제공하여 애플리케이션이 다양한 부하를 효율적으로 처리할 수 있도록 하며, 수동 확장이나 프로비저닝이 필요하지 않습니다. 이는 시나리오의 요구 사항과 일치합니다.",
        "Other Options": [
            "EC2 인스턴스를 사용하여 애플리케이션을 배포하는 것은 기본 인프라를 관리해야 하며, 확장 및 로드 밸런싱을 포함하여 서버리스 아키텍처 목표에 반합니다.",
            "Amazon ECS와 Fargate를 사용하는 것은 컨테이너화된 솔루션을 제공하지만, 여전히 일부 인프라 관리가 필요하며 요청이 없을 때는 비용 효율적이지 않습니다. 이는 완전 서버리스 아키텍처와는 다릅니다.",
            "AWS Step Functions와 함께 API Gateway를 설정하는 것은 사진 처리라는 사용 사례에 불필요한 복잡성을 추가하며, 여러 서비스를 포함하고 지연을 초래할 수 있어 간단한 처리 작업에는 이상적이지 않습니다."
        ]
    },
    {
        "Question Number": "57",
        "Situation": "한 회사가 사용자 인증이 필요한 새로운 웹 애플리케이션을 개발하고 있습니다. 사용자가 애플리케이션에서 별도의 계정을 생성하지 않고도 로그인할 수 있도록 기존의 아이덴티티 공급자를 활용하고자 합니다. 이 솔루션은 사용자가 소셜 네트워크 계정을 사용하여 인증할 수 있도록 하며, 안전한 접근 제어를 보장하면서 원활한 경험을 유지해야 합니다.",
        "Question": "DevOps 엔지니어가 애플리케이션에 대해 웹 아이덴티티 연합을 활성화하기 위해 구현해야 할 방법은 무엇입니까?",
        "Options": {
            "1": "AWS Lambda를 사용하여 사용자 인증 요청을 처리하고, 서드파티 아이덴티티 공급자 API를 직접 구현합니다. 사용자 토큰을 저장하고 Lambda 함수 내에서 사용자 세션을 관리하여 접근 제어를 제공합니다.",
            "2": "OAuth 2.0과 통합된 사용자 정의 인증 서비스를 생성합니다. 사용자 자격 증명을 저장하고 세션을 수동으로 관리하여 모든 접근 제어가 애플리케이션 내에서 처리되도록 합니다.",
            "3": "Amazon Cognito를 구성하여 사용자가 Google 또는 Facebook과 같은 소셜 아이덴티티 공급자를 통해 인증할 수 있도록 합니다. IAM에서 인증된 사용자에게 권한을 부여하는 역할을 설정하여 AWS 리소스에 안전하게 접근할 수 있도록 합니다.",
            "4": "사용자가 기존 자격 증명을 사용하여 로그인할 수 있는 IAM 사용자 풀을 설정합니다. 추가 보안을 위해 다단계 인증(MFA)을 활성화하지만, 모든 사용자 계정을 AWS IAM 내에서 관리합니다."
        },
        "Correct Answer": "Amazon Cognito를 구성하여 사용자가 Google 또는 Facebook과 같은 소셜 아이덴티티 공급자를 통해 인증할 수 있도록 합니다. IAM에서 인증된 사용자에게 권한을 부여하는 역할을 설정하여 AWS 리소스에 안전하게 접근할 수 있도록 합니다.",
        "Explanation": "웹 아이덴티티 연합을 위해 Amazon Cognito를 사용하면 애플리케이션이 신뢰할 수 있는 서드파티 아이덴티티 공급자를 통해 사용자를 인증할 수 있으며, 사용자 계정을 직접 관리할 필요가 없습니다. 이는 IAM 역할을 활용하여 인증된 사용자가 접근할 수 있는 것을 결정함으로써 접근 제어를 단순화하고 보안 및 사용자 경험을 향상시킵니다.",
        "Other Options": [
            "사용자 정의 인증 서비스를 생성하는 것은 사용자 계정, 자격 증명 및 세션을 관리하는 데 상당한 오버헤드를 요구하며, 이는 사용자 관리 복잡성을 줄이는 목표에 반합니다.",
            "AWS Lambda를 사용자 인증에 사용하는 것은 서드파티 API와의 직접 상호작용 및 사용자 세션 관리를 요구하므로 가장 효율적인 방법이 아닙니다. 이는 복잡성을 증가시키고 잠재적인 보안 위험을 초래할 수 있습니다.",
            "IAM 사용자 풀을 설정하는 것은 이 시나리오에 적합하지 않으며, 기존 소셜 네트워크 계정을 인증에 활용하지 않기 때문에 사용자가 원하는 원활한 경험을 달성하지 못합니다."
        ]
    },
    {
        "Question Number": "58",
        "Situation": "금융 서비스 회사가 AWS 리소스를 활용하여 애플리케이션을 호스팅하고 있습니다. 관련 데이터의 민감한 특성으로 인해 보안 팀은 예상치 못한 보안 이벤트나 이상 징후가 즉시 감지되고 보고될 수 있도록 해야 합니다. 그들은 로그에서 비정상적인 패턴을 자동으로 분석하고 이상이 감지될 때 경고를 트리거할 수 있는 솔루션을 원합니다.",
        "Question": "다음 구성 중 회사의 예상치 못한 보안 이벤트 경고 요구 사항을 가장 잘 충족하는 것은 무엇입니까?",
        "Options": {
            "1": "AWS Config를 구성하여 리소스 구성의 변경 사항을 모니터링하고 변경 사항이 감지될 때마다 Amazon EventBridge를 통해 알림을 전송합니다. AWS Lambda를 사용하여 로그에서 이상 징후를 분석합니다.",
            "2": "AWS Lambda 함수를 배포하여 CloudTrail 로그에서 이상 징후를 스캔하고, 제3자 서비스를 사용하지 않고 보안 팀에 직접 이메일로 경고를 보냅니다.",
            "3": "AWS WAF를 활용하여 악의적인 요청을 차단하고 CloudWatch Alarms를 설정하여 웹 트래픽을 모니터링합니다. 임계값이 초과될 때 보안 팀에 알림을 보내도록 알람을 구성합니다.",
            "4": "AWS CloudTrail을 구현하여 모든 API 호출을 기록하고, Amazon GuardDuty를 설정하여 비정상적인 활동을 모니터링합니다. GuardDuty 결과에 따라 Amazon SNS를 사용하여 보안 팀에 경고를 보냅니다."
        },
        "Correct Answer": "AWS CloudTrail을 구현하여 모든 API 호출을 기록하고, Amazon GuardDuty를 설정하여 비정상적인 활동을 모니터링합니다. GuardDuty 결과에 따라 Amazon SNS를 사용하여 보안 팀에 경고를 보냅니다.",
        "Explanation": "이 솔루션은 API 호출을 기록하기 위해 AWS CloudTrail을 효과적으로 활용하고, 실시간 위협 탐지를 위해 Amazon GuardDuty를 사용합니다. 이러한 서비스를 Amazon SNS와 통합함으로써 이상이 감지될 때 보안 팀에 즉시 경고를 보낼 수 있어 보안 이벤트에 대한 신속한 대응을 보장합니다.",
        "Other Options": [
            "AWS Config는 구성 변경 사항을 모니터링할 수 있지만 API 활동을 기반으로 예상치 못한 보안 이벤트를 감지하기 위한 포괄적인 솔루션을 제공하지 않습니다. 이 옵션은 GuardDuty가 제공하는 실시간 이상 탐지 기능이 부족합니다.",
            "AWS WAF는 주로 웹 애플리케이션 보안에 중점을 두고 있으며 API 호출을 직접 모니터링하거나 비정상적인 활동을 감지하지 않습니다. CloudWatch Alarms는 트래픽 임계값을 기반으로 알림을 보낼 수 있지만 예상치 못한 보안 이벤트에 대한 필요한 맥락을 제공하지 않습니다.",
            "이 옵션은 사용자 정의 Lambda 함수에만 의존하며, GuardDuty와 같은 전용 서비스를 사용하는 것만큼 강력하거나 확장 가능하지 않을 수 있습니다. 또한 보안 사고 대응에 중요한 실시간 모니터링 및 경고 기능을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "59",
        "Situation": "DevOps 엔지니어가 Amazon EC2 인스턴스 및 관련 리소스의 생애 주기를 관리하는 업무를 맡고 있습니다. 엔지니어는 중지된 인스턴스에서 EBS 기반 AMI를 생성할 수 있는 자동화된 프로세스를 만들고, 스냅샷이 효율적으로 생성되고 관리되도록 해야 합니다. 또한, 리소스 관리를 용이하게 하기 위해 태깅 전략을 구현해야 합니다.",
        "Question": "엔지니어가 이러한 요구 사항을 충족하기 위해 어떤 조치를 취해야 합니까? (두 가지 선택)",
        "Options": {
            "1": "copy-image 명령을 사용하여 AMI를 다른 리전으로 복사하고 'prune'라는 키로 태그를 추가합니다.",
            "2": "describe-tags 명령을 사용하여 인스턴스와 관련된 태그를 설명하여 모든 필요한 태그가 존재하는지 확인합니다.",
            "3": "인스턴스를 종료하기 전에 create-snapshot 명령을 사용하여 인스턴스의 볼륨에 대한 스냅샷을 생성합니다.",
            "4": "stop-instances 명령을 사용하여 인스턴스를 중지하고 즉시 루트 볼륨의 스냅샷을 생성합니다.",
            "5": "create-image 명령을 사용하여 중지된 인스턴스에서 AMI를 생성하고 백업을 위한 태그를 포함합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "create-image 명령을 사용하여 중지된 인스턴스에서 AMI를 생성하고 백업을 위한 태그를 포함합니다.",
            "copy-image 명령을 사용하여 AMI를 다른 리전으로 복사하고 'prune'라는 키로 태그를 추가합니다."
        ],
        "Explanation": "중지된 인스턴스에서 create-image 명령을 사용하여 AMI를 생성하는 것은 인스턴스를 백업하는 데 필수적입니다. AMI에 'backup' 태그를 추가하면 리소스 관리에 도움이 됩니다. 또한, AMI를 다른 리전으로 복사하면 가용성과 중복성을 보장하며, 'prune' 태그를 추가하면 생애 주기 정책 관리에 도움이 됩니다.",
        "Other Options": [
            "인스턴스를 중지하고 즉시 스냅샷을 생성하는 것은 최적이 아닙니다. AMI는 중지된 인스턴스에서 생성되며, 라이브 인스턴스의 스냅샷은 불일치를 초래할 수 있습니다.",
            "인스턴스를 종료하기 전에 인스턴스의 볼륨에 대한 스냅샷을 생성하는 것은 AMI가 생성되면 필요하지 않습니다. AMI에는 볼륨의 스냅샷이 포함되어 있습니다.",
            "인스턴스와 관련된 태그를 설명하는 것은 AMI 생성이나 스냅샷 관리를 효과적으로 충족하지 않습니다."
        ]
    },
    {
        "Question Number": "60",
        "Situation": "개발 팀이 AWS 서비스를 사용하여 애플리케이션의 신속한 테스트 및 배포를 보장하는 자동화된 CI/CD 파이프라인을 구현하고 있습니다. 그들은 배포 전에 코드 변경 사항을 검증하기 위해 파이프라인 내에 자동화된 테스트 단계를 포함해야 합니다. 팀은 파이프라인 내에서 효과적인 테스트 및 통합을 위해 어떤 AWS 서비스를 활용할지 고려하고 있습니다.",
        "Question": "CI/CD 파이프라인 내에서 자동화된 테스트를 가장 잘 가능하게 하는 옵션의 조합은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "AWS CodePipeline을 구성하여 배포에 AWS CodeDeploy를 사용하되, 프로세스를 가속화하기 위해 테스트 단계를 생략합니다.",
            "2": "AWS Lambda 함수를 사용하여 코드 리포지토리의 변경에 따라 자동화된 테스트를 트리거하되, 다른 서비스를 사용하지 않습니다.",
            "3": "AWS CodePipeline과 AWS CodeBuild를 통합하여 새로운 코드 변경 사항에 대한 단위 테스트를 실행하고 결과를 파이프라인에 보고합니다.",
            "4": "AWS CodeBuild를 설정하여 통합 테스트를 실행하고 배포 프로세스의 일환으로 AWS CodePipeline에 결과를 알립니다.",
            "5": "Amazon S3를 사용하여 테스트 결과를 저장하고 해당 결과를 기반으로 수동으로 경고를 트리거합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "AWS CodePipeline과 AWS CodeBuild를 통합하여 새로운 코드 변경 사항에 대한 단위 테스트를 실행하고 결과를 파이프라인에 보고합니다.",
            "AWS CodeBuild를 설정하여 통합 테스트를 실행하고 배포 프로세스의 일환으로 AWS CodePipeline에 결과를 알립니다."
        ],
        "Explanation": "AWS CodePipeline과 AWS CodeBuild를 통합하면 코드 변경 사항이 푸시될 때 자동화된 단위 테스트를 수행할 수 있어, 테스트를 통과한 코드만 파이프라인에서 진행할 수 있습니다. 또한, CodeBuild를 설정하여 통합 테스트를 실행하면 배포 전에 애플리케이션의 다양한 구성 요소가 올바르게 작동하는지 검증하여 테스트 프로세스를 더욱 향상시킵니다.",
        "Other Options": [
            "AWS Lambda 함수를 사용하여 다른 서비스 없이 자동화된 테스트를 트리거하는 것은 CI/CD 파이프라인에서 테스트를 실행하기 위한 확장 가능하거나 관리 가능한 솔루션을 제공하지 않습니다. Lambda는 광범위한 테스트 워크플로우를 위해 설계되지 않았습니다.",
            "AWS CodePipeline에서 테스트 단계를 생략하여 프로세스를 가속화하면 테스트되지 않거나 손상된 코드를 배포하게 되어 프로덕션 환경에서 심각한 문제를 일으킬 수 있습니다. 테스트는 품질 유지를 위해 중요합니다.",
            "테스트 결과를 Amazon S3에 저장하고 수동으로 경고를 트리거하는 것은 자동화된 솔루션이 아닙니다. 이는 지속적인 통합의 이점을 우회하며 개발자에게 피드백 지연을 초래할 수 있습니다."
        ]
    },
    {
        "Question Number": "61",
        "Situation": "Auto Scaling Group (ASG)에서 실행되는 웹 애플리케이션이 변동하는 트래픽 패턴을 경험하여 높은 수요와 낮은 수요가 모두 발생합니다. DevOps 팀은 ASG의 용량을 효과적으로 관리하면서 인스턴스를 필요에 따라 원활하게 서비스에 추가하거나 제거할 수 있는 솔루션을 구현해야 합니다. 또한 배포 프로세스를 향상시키기 위해 라이프사이클 훅을 활용하고자 합니다.",
        "Question": "효율성을 극대화하면서 이러한 요구 사항을 충족하기 위해 DevOps 팀이 취해야 할 행동은 무엇입니까?",
        "Options": {
            "1": "트래픽이 낮은 기간 동안 인스턴스를 대기 상태로 전환하기 위해 enter-standby 작업을 사용하고, 인스턴스를 종료하기 전에 정리 작업을 수행하기 위해 라이프사이클 훅을 사용합니다.",
            "2": "현재의 시작 구성을 삭제하고 성능을 향상시키기 위해 다른 인스턴스 유형을 지정하는 새로운 구성을 사용합니다.",
            "3": "ASG를 위한 새로운 시작 구성을 만들고 CloudWatch 메트릭을 기반으로 원하는 용량을 증가시키기 위해 스케일링 정책을 업데이트합니다.",
            "4": "스케일 아웃 시 인스턴스를 일시 중지하기 위해 라이프사이클 훅을 사용하고, 트래픽이 증가할 때 인스턴스를 재개하기 위해 exit-standby 작업을 사용합니다."
        },
        "Correct Answer": "트래픽이 낮은 기간 동안 인스턴스를 대기 상태로 전환하기 위해 enter-standby 작업을 사용하고, 인스턴스를 종료하기 전에 정리 작업을 수행하기 위해 라이프사이클 훅을 사용합니다.",
        "Explanation": "enter-standby 작업을 사용하면 팀이 ASG의 인스턴스를 종료하지 않고 유지할 수 있어, 빠르게 다시 온라인으로 전환해야 할 수 있는 인스턴스를 원활하게 전환하는 데 유리합니다. 또한 라이프사이클 훅을 사용하면 인스턴스가 완전히 종료되기 전에 필요한 정리 작업을 실행할 수 있어 스케일링 이벤트 동안 더 원활한 프로세스를 보장합니다.",
        "Other Options": [
            "새로운 시작 구성을 만들고 스케일링 정책을 업데이트하는 것은 스케일링에 도움이 될 수 있지만, 스케일링 이벤트 동안 원활한 인스턴스 관리 및 라이프사이클 작업의 필요성을 해결하지 않습니다.",
            "스케일 아웃 중 인스턴스를 일시 중지하기 위해 라이프사이클 훅을 사용하는 것은 좋은 관행이지만, exit-standby 작업은 인스턴스를 대기 상태에서 제거하는 데 사용되며, 낮은 트래픽 기간 동안 인스턴스를 관리하는 것과는 직접적인 관련이 없습니다.",
            "시작 구성을 삭제하고 새로운 것으로 교체하는 것은 ASG의 동적 스케일링 능력에 영향을 미치며, 다양한 부하 동안 인스턴스를 관리하는 방법을 제공하지 않으며, 라이프사이클 훅을 활용하지 않습니다."
        ]
    },
    {
        "Question Number": "62",
        "Situation": "한 회사가 각 서비스가 데이터베이스 비밀번호 및 API 키와 같은 민감한 자격 증명에 접근해야 하는 마이크로서비스 애플리케이션을 개발하고 있습니다. DevOps 엔지니어는 CI/CD 파이프라인 동안 이러한 비밀을 관리하기 위한 안전한 솔루션을 구현해야 하며, 최소한의 수동 개입과 강력한 보안 관행을 보장해야 합니다.",
        "Question": "엔지니어가 빌드 및 배포 비밀을 안전하게 관리하기 위해 어떤 접근 방식을 취해야 합니까? (두 가지 선택)",
        "Options": {
            "1": "민감한 자격 증명을 애플리케이션 코드에 직접 포함시켜 배포 중 항상 사용할 수 있도록 합니다.",
            "2": "민감한 자격 증명을 저장하기 위해 공개 액세스가 있는 S3 버킷을 구성하고 버킷 정책을 사용하여 액세스를 관리합니다.",
            "3": "AWS Secrets Manager를 사용하여 모든 민감한 자격 증명을 저장하고 IAM 역할을 사용하여 빌드 프로세스에서 참조합니다.",
            "4": "민감한 자격 증명을 버전 관리 시스템에 직접 저장하여 빌드 프로세스 중 액세스를 간소화합니다.",
            "5": "AWS Systems Manager Parameter Store를 활용하여 비밀을 관리하고 Lambda 함수가 이러한 매개변수에 안전하게 접근할 수 있도록 IAM 역할을 구성합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "AWS Secrets Manager를 사용하여 모든 민감한 자격 증명을 저장하고 IAM 역할을 사용하여 빌드 프로세스에서 참조합니다.",
            "AWS Systems Manager Parameter Store를 활용하여 비밀을 관리하고 Lambda 함수가 이러한 매개변수에 안전하게 접근할 수 있도록 IAM 역할을 구성합니다."
        ],
        "Explanation": "AWS Secrets Manager를 사용하면 민감한 정보를 안전하게 저장, 관리 및 검색할 수 있어, 승인된 사용자와 애플리케이션만이 접근할 수 있도록 보장합니다. AWS Systems Manager Parameter Store는 구성 데이터와 비밀을 관리하는 안전한 방법을 제공하며, 다른 AWS 서비스와의 통합 및 액세스 제어를 위한 IAM 역할 사용의 이점도 있습니다.",
        "Other Options": [
            "민감한 자격 증명을 버전 관리 시스템에 저장하는 것은 상당한 보안 위험을 초래합니다. 저장소에 접근할 수 있는 누구나 자격 증명을 볼 수 있어 무단 접근으로 이어질 수 있습니다.",
            "민감한 자격 증명을 애플리케이션 코드에 포함시키는 것은 코드 유출을 통해 애플리케이션이 노출될 위험이 있으며, 비밀 관리에 대한 모범 사례를 따르지 않습니다.",
            "민감한 자격 증명을 공개적으로 접근 가능한 S3 버킷에 저장하는 것은 보안 모범 사례를 위반하는 것으로, 이는 무단 접근 및 잠재적인 데이터 유출로 이어질 수 있습니다."
        ]
    },
    {
        "Question Number": "63",
        "Situation": "DevOps 팀은 스테이징 및 프로덕션을 포함한 여러 환경에서 웹 애플리케이션의 배포를 자동화하는 임무를 맡고 있습니다. 그들은 다운타임을 최소화하면서 일관된 배포를 보장하고자 합니다. 팀은 이 목표를 달성하기 위해 다양한 AWS 서비스를 고려하고 있습니다.",
        "Question": "팀이 여러 환경에서 다운타임 없이 애플리케이션 배포를 자동화하기 위해 주로 사용해야 할 AWS 서비스는 무엇입니까?",
        "Options": {
            "1": "Amazon EC2 Image Builder",
            "2": "AWS CodePipeline",
            "3": "AWS CodeDeploy",
            "4": "AWS CloudFormation"
        },
        "Correct Answer": "AWS CodeDeploy",
        "Explanation": "AWS CodeDeploy는 EC2 인스턴스 및 Lambda 함수와 같은 다양한 컴퓨팅 서비스에 애플리케이션을 자동으로 배포하도록 설계되었습니다. 블루/그린과 같은 배포 전략을 지원하며, 애플리케이션 업데이트 중 다운타임을 제로로 달성하는 데 도움을 줄 수 있습니다.",
        "Other Options": [
            "AWS CloudFormation은 주로 인프라를 코드로 관리하고 리소스를 관리하는 데 사용되며, 애플리케이션 배포를 직접 자동화하는 데는 사용되지 않습니다. 프로비저닝에는 유용하지만, 다운타임을 최소화하기 위한 배포 전략을 처리하지 않습니다.",
            "AWS CodePipeline은 빌드, 테스트 및 릴리스 프로세스를 자동화하는 지속적 통합 및 지속적 배포 서비스입니다. 그러나 실제 배포 단계에서는 CodeDeploy와 같은 다른 서비스에 의존하므로 배포를 위한 주요 서비스는 아닙니다.",
            "Amazon EC2 Image Builder는 EC2 인스턴스를 위한 Golden AMI(Amazon Machine Image)를 생성하고 유지 관리하는 서비스입니다. 이미지를 만드는 데 유용하지만, 애플리케이션 배포를 자동화하지 않으며, 특히 다운타임 제로 전략을 사용하지 않습니다."
        ]
    },
    {
        "Question Number": "64",
        "Situation": "대규모 금융 서비스 조직이 AWS Service Catalog를 구현하여 클라우드 리소스를 관리하고 있습니다. 이들은 제품이 배포될 때 여러 AWS 계정 및 리전에서 특정 배포 옵션과 제한 사항을 준수하도록 보장하고자 합니다. 또한, 조직은 지정된 IAM 역할만 특정 제품을 시작할 수 있도록 요구합니다. 오버헤드를 최소화하고 템플릿에 대한 제한된 액세스를 제공하기 위해, 조직은 StackSets와 배포 제약 조건을 효과적으로 활용하는 것을 목표로 하고 있습니다.",
        "Question": "AWS Service Catalog를 사용할 때 배포 옵션과 권한을 강제하기 위해 DevOps 엔지니어가 취할 수 있는 조치는 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "AWS CloudFormation에서 StackSet을 생성하여 지정된 제약 조건으로 여러 계정 및 리전에서 AWS Service Catalog 제품을 배포합니다.",
            "2": "AWS Organizations를 활용하여 조직 단위에 따라 특정 AWS Service Catalog 제품에 대한 계정 액세스를 제한합니다.",
            "3": "사용자가 미리 정의된 포트폴리오에서만 제품을 시작할 수 있도록 허용하는 IAM 정책을 생성하여 배포 지침 준수를 보장합니다.",
            "4": "AWS Service Catalog 제품에 대해 제품을 시작할 때 사용할 IAM 역할을 지정하는 배포 제약 조건을 정의합니다.",
            "5": "AWS CloudTrail을 구현하여 AWS Service Catalog를 통해 이루어진 모든 배포를 모니터링하고 기록하여 내부 정책 준수를 보장합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "AWS CloudFormation에서 StackSet을 생성하여 지정된 제약 조건으로 여러 계정 및 리전에서 AWS Service Catalog 제품을 배포합니다.",
            "AWS Service Catalog 제품에 대해 제품을 시작할 때 사용할 IAM 역할을 지정하는 배포 제약 조건을 정의합니다."
        ],
        "Explanation": "StackSets를 사용하면 여러 계정 및 리전에서 AWS Service Catalog 제품을 배포하면서 배포 옵션과 제한 사항을 유지할 수 있습니다. 배포 제약 조건을 정의하면 특정 IAM 역할만 제품을 시작할 수 있도록 보장하여 보안과 준수를 강화합니다.",
        "Other Options": [
            "AWS Organizations를 활용하면 계정 수준에서 권한을 관리하는 데 도움이 되지만, AWS Service Catalog 제품에 대한 배포 옵션이나 특정 IAM 역할 제약 조건을 직접적으로 강제하지는 않습니다.",
            "AWS CloudTrail을 구현하면 기록 및 모니터링을 제공하지만, 제품 시작 시 배포 옵션이나 권한을 직접적으로 강제하지는 않습니다.",
            "미리 정의된 포트폴리오에서 제품 시작을 제한하는 IAM 정책을 생성하면 액세스 제어에 도움이 되지만, 배포 옵션이나 배포 제약 조건에서 사용되는 IAM 역할의 세부 사항을 다루지는 않습니다."
        ]
    },
    {
        "Question Number": "65",
        "Situation": "한 회사가 프로덕션 및 개발과 같은 다양한 환경을 위해 여러 AWS 계정을 운영하고 있습니다. DevOps 팀은 개발 계정의 개발자가 하드코딩된 액세스 키 없이 프로덕션 계정의 리소스에 접근할 수 있도록 안전한 크로스 계정 액세스 메커니즘을 설정해야 합니다. 이들은 AWS IAM 역할을 사용하고 보안 및 관리 가능성에 대한 모범 사례를 따르는 솔루션을 구현하고자 합니다.",
        "Question": "DevOps 팀이 IAM 역할과 AWS STS를 사용하여 개발 계정에서 프로덕션 계정으로의 크로스 계정 액세스를 활성화하기 위해 어떤 단계를 밟아야 합니까?",
        "Options": {
            "1": "프로덕션 계정에 로그인하여 리소스에 대한 액세스를 허용하는 새로운 IAM 정책을 생성하고 역할을 사용하지 않고 개발 계정의 개발자에게 연결합니다.",
            "2": "프로덕션 계정에 로그인하여 개발 계정 사용자가 이를 가정할 수 있도록 신뢰 정책이 있는 IAM 역할을 생성하고, 필요한 권한을 부여한 후 개발자에게 역할 ARN을 제공합니다.",
            "3": "개발 계정에 로그인하여 프로덕션 계정의 각 개발자를 위한 새로운 IAM 사용자를 생성하고, 필요한 권한을 부여한 후 액세스 키를 사용하여 인증합니다.",
            "4": "프로덕션 계정에 로그인하여 원하는 리소스에 대한 리소스 정책을 구성하여 개발 계정의 액세스를 허용합니다."
        },
        "Correct Answer": "프로덕션 계정에 로그인하여 개발 계정 사용자가 이를 가정할 수 있도록 신뢰 정책이 있는 IAM 역할을 생성하고, 필요한 권한을 부여한 후 개발자에게 역할 ARN을 제공합니다.",
        "Explanation": "신뢰 정책이 있는 IAM 역할을 생성하면 개발 계정의 사용자가 프로덕션 계정에서 해당 역할을 가정할 수 있습니다. 이 방법은 자격 증명을 하드코딩할 필요 없이 안전하고 임시 액세스를 보장합니다. 이는 크로스 계정 액세스에 대한 AWS 모범 사례를 준수합니다.",
        "Other Options": [
            "프로덕션 계정에서 각 개발자를 위한 IAM 사용자를 생성하는 것은 확장 가능하거나 안전한 솔루션이 아닙니다. 관리 오버헤드를 증가시키고 액세스 키를 노출시켜 모범 사례에 반합니다.",
            "새로운 IAM 정책을 생성하고 개발 계정의 개발자에게 연결하는 것은 크로스 계정 액세스를 촉진하지 않습니다. 정책은 다른 계정의 사용자가 가정할 수 있는 IAM 역할에 연결되어야 합니다.",
            "리소스 정책을 구성하여 개발 계정에서의 액세스를 허용하는 것은 IAM 역할이 제공하는 유연성과 보안을 제공하지 않습니다. 리소스 정책은 더 제한적이며 역할 가정을 효과적으로 처리하지 않습니다."
        ]
    },
    {
        "Question Number": "66",
        "Situation": "한 회사가 AWS에서 호스팅되는 웹 애플리케이션의 새 버전을 배포하고 있습니다. 애플리케이션은 최소한의 다운타임과 위험으로 업데이트되어야 하며, 문제가 발생할 경우 빠른 롤백이 가능해야 합니다. DevOps 엔지니어는 이러한 목표를 달성하기 위해 적절한 배포 전략을 선택하는 임무를 맡고 있습니다.",
        "Question": "DevOps 엔지니어가 최소한의 다운타임과 위험을 보장하기 위해 어떤 배포 방법을 구현해야 합니까? (두 가지 선택)",
        "Options": {
            "1": "불변 인프라 패턴을 사용하여 애플리케이션을 배포하여 버전 관리를 용이하게 합니다.",
            "2": "새 버전을 테스트하기 위해 트래픽의 소량을 새로운 버전으로 라우팅하는 카나리 배포를 설정합니다.",
            "3": "즉각적인 롤백 기능을 제공하기 위해 블루/그린 배포 전략을 구현합니다.",
            "4": "성능 비교를 위해 이전 버전과 새로운 버전 간에 트래픽을 분할하는 A/B 테스트 프레임워크를 활용합니다.",
            "5": "인스턴스를 점진적으로 교체하여 모니터링을 허용하는 롤링 배포를 사용합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "즉각적인 롤백 기능을 제공하기 위해 블루/그린 배포 전략을 구현합니다.",
            "새 버전을 테스트하기 위해 트래픽의 소량을 새로운 버전으로 라우팅하는 카나리 배포를 설정합니다."
        ],
        "Explanation": "블루/그린 배포 전략은 현재 환경과 새로운 환경을 유지하여 트래픽을 전환함으로써 쉽게 롤백할 수 있게 합니다. 카나리 배포 방법은 전체 롤아웃 전에 소수의 사용자로 새로운 버전을 테스트하여 위험을 줄이고 새로운 버전의 성능을 모니터링할 수 있게 합니다.",
        "Other Options": [
            "롤링 배포는 인스턴스를 점진적으로 교체하므로 즉각적인 롤백 기능을 제공하지 않습니다. 문제가 발생하면 이전 버전으로 되돌리는 데 더 오랜 시간이 걸릴 수 있습니다.",
            "불변 인프라는 기존 인스턴스를 업데이트하는 것보다 새로운 버전으로 새로운 인스턴스를 배포하는 데 중점을 두므로 블루/그린 또는 카나리 배포에 비해 다운타임을 본질적으로 최소화하지 않습니다.",
            "A/B 테스트는 배포 전략보다는 성능 비교에 더 적합합니다. 새로운 버전을 배포할 때 다운타임이나 위험을 본질적으로 최소화하지 않습니다."
        ]
    },
    {
        "Question Number": "67",
        "Situation": "개발 팀은 AWS 리소스의 보안, 특히 AWS 액세스 키의 노출과 Amazon EC2 인스턴스의 비정상적인 사용에 대해 우려하고 있습니다. 그들은 이러한 잠재적인 보안 문제를 자동으로 모니터링하고 필요할 때 경고하는 솔루션을 구현하고자 합니다.",
        "Question": "팀이 AWS Trusted Advisor를 활용하고 노출된 액세스 키와 비정상적인 EC2 활동에 대해 알림을 받을 수 있도록 어떤 솔루션을 구현해야 합니까?",
        "Options": {
            "1": "AWS Trusted Advisor를 이벤트 소스로 사용하는 Amazon EventBridge 규칙을 생성합니다. 공개 코드 리포지토리에서 액세스 키가 발견되거나 비정상적인 EC2 사용이 감지될 때마다 Amazon SNS 주제에 알림을 트리거하도록 규칙을 구성합니다.",
            "2": "AWS Config 규칙을 활용하여 액세스 키와 EC2 인스턴스의 준수를 모니터링합니다. 노출된 키나 비정상적인 EC2 행동과 관련된 비준수 이벤트에 대해 팀에 알림을 보내는 CloudWatch 경고를 생성합니다.",
            "3": "AWS Systems Manager Run Command를 구현하여 리포지토리에서 노출된 액세스 키를 정기적으로 스캔하고 EC2 인스턴스 사용 패턴을 확인하여 팀에 결과를 알립니다.",
            "4": "AWS Lambda 함수를 설정하여 일정에 따라 Trusted Advisor를 쿼리하여 노출된 액세스 키와 비정상적인 EC2 사용 패턴을 확인하고, 개발 팀에 경고를 보냅니다."
        },
        "Correct Answer": "AWS Trusted Advisor를 이벤트 소스로 사용하는 Amazon EventBridge 규칙을 생성합니다. 공개 코드 리포지토리에서 액세스 키가 발견되거나 비정상적인 EC2 사용이 감지될 때마다 Amazon SNS 주제에 알림을 트리거하도록 규칙을 구성합니다.",
        "Explanation": "이 옵션은 AWS Trusted Advisor와 EventBridge를 직접 활용하여 노출된 액세스 키와 비정상적인 EC2 사용에 대한 특정 보안 문제를 자동으로 모니터링하고 경고합니다. 개발 팀이 관련 문제에 대해 신속하게 알림을 받을 수 있도록 보장합니다.",
        "Other Options": [
            "AWS Config는 준수를 모니터링할 수 있지만, 노출된 액세스 키나 비정상적인 EC2 사용을 감지하기 위해 Trusted Advisor의 기능을 특별히 활용하지 않습니다. 따라서 팀이 요구하는 즉각적인 알림을 제공하지 않을 수 있습니다.",
            "AWS Lambda 함수를 사용하여 Trusted Advisor를 쿼리하는 것은 예약된 실행에 의존하므로 실시간 모니터링이나 알림을 제공하지 않습니다. 이 접근 방식은 EventBridge가 제공하는 즉각성과 자동화가 부족합니다.",
            "노출된 키를 스캔하기 위해 AWS Systems Manager를 사용하는 것은 Trusted Advisor와 EventBridge를 활용하는 것만큼 효율적이지 않으며, 비정상적인 EC2 활동에 대한 실시간 알림 필요를 직접적으로 해결하지 못할 수 있습니다."
        ]
    },
    {
        "Question Number": "68",
        "Situation": "한 회사는 배포 중에 다운타임이 없는 중요한 애플리케이션을 운영하고 있습니다. 엔지니어링 팀은 신뢰성을 높이고 사용자 경험에 영향을 주지 않으면서 원활한 업데이트를 보장하기 위해 다양한 배포 전략을 탐색하고 있습니다.",
        "Question": "어떤 배포 전략 조합이 요구 사항을 충족합니까? (두 가지 선택)",
        "Options": {
            "1": "Rolling Deployment 접근 방식을 활용하여 프로덕션 환경에서 인스턴스를 점진적으로 교체하면서 항상 최소한의 인스턴스가 서비스 중인 상태를 유지합니다.",
            "2": "Blue Green Deployment 전략을 구현하여 현재 환경에서 새로 업데이트된 환경으로 트래픽을 전환하고, 문제가 발생할 경우 쉽게 롤백할 수 있도록 합니다.",
            "3": "Minimum in-service Deployment 전략을 사용하여 자동화된 테스트와 다운타임 없이 단계별 업데이트를 달성합니다.",
            "4": "All-at-Once Deployment 방법을 채택하여 모든 인스턴스에 동시에 변경 사항을 푸시하여 배포 시간을 최소화하지만 오류가 발생할 경우 다운타임의 위험이 있습니다.",
            "5": "레거시 시스템을 위한 Single Target Deployment 전략을 선택하여 빠른 업데이트를 가능하게 하지만, 이 과정에서 다운타임이 발생합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Blue Green Deployment 전략을 구현하여 현재 환경에서 새로 업데이트된 환경으로 트래픽을 전환하고, 문제가 발생할 경우 쉽게 롤백할 수 있도록 합니다.",
            "Rolling Deployment 접근 방식을 활용하여 프로덕션 환경에서 인스턴스를 점진적으로 교체하면서 항상 최소한의 인스턴스가 서비스 중인 상태를 유지합니다."
        ],
        "Explanation": "Blue Green Deployment와 Rolling Deployment 전략 모두 다운타임이 없음을 보장하고 프로덕션에서 테스트를 허용합니다. Blue Green Deployment는 쉽게 롤백할 수 있고 깔끔한 전환을 제공하며, Rolling Deployment는 업그레이드 과정에서 최소한의 인스턴스가 항상 사용 가능하도록 보장합니다.",
        "Other Options": [
            "All-at-Once Deployment 방법은 모든 인스턴스가 동시에 업데이트되므로 다운타임의 위험을 초래합니다. 배포 중 오류가 발생하면 서비스 중단으로 이어질 수 있습니다.",
            "Single Target Deployment는 업데이트 중 다운타임이 발생하므로 중요한 애플리케이션에 적합하지 않습니다. 이 방법은 더 작거나 덜 중요한 프로젝트에 더 적합합니다.",
            "Minimum in-service Deployment는 좋은 전략이지만, Rolling Deployment 방법만큼 여러 단계를 효율적으로 허용하지 않으며, 더 통제된 업데이트 프로세스를 제공할 수 있습니다."
        ]
    },
    {
        "Question Number": "69",
        "Situation": "한 회사는 기업 사용자가 AWS Management Console에 접근할 수 있도록 안전한 Single Sign-On (SSO) 솔루션을 구현하고자 합니다. 사용자는 Active Directory Federation Services (AD FS)에 대해 인증하며, 회사는 애플리케이션을 위한 전용 연합 프록시를 유지할 필요가 없고 프록시에 대한 IAM 권한이 필요하지 않도록 보장하고자 합니다.",
        "Question": "기업 사용자가 AWS Management Console에 접근하기 위한 SAML 기반 인증 흐름을 올바르게 설명하는 단계의 순서는 무엇입니까?",
        "Options": {
            "1": "기업 사용자가 AD FS에 접근하면, AD FS는 Active Directory에 대해 그들을 인증합니다. AD FS는 그룹 멤버십 세부정보를 포함하는 SAML 토큰을 생성하고, 사용자는 이를 사용하여 AWS Sign-in Endpoint에 로그인합니다. AssumeRoleWithSAML 요청이 STS에 전송되고, STS는 임시 보안 자격 증명을 반환합니다. 마지막으로, AWS는 사용자를 AWS Console URL로 리디렉션합니다.",
            "2": "기업 사용자가 AD FS에 접근한 후, 서비스는 그들을 인증하고 SAML 토큰 대신 JWT 토큰을 생성하며, 이 토큰은 자격 증명을 요청하는 STS와 함께 AWS Sign-in Endpoint로 전송됩니다.",
            "3": "기업 사용자가 자신의 기업 자격 증명을 사용하여 직접 AWS Management Console에 로그인합니다. AWS 서비스는 IAM 정책에 대해 그들의 신원을 확인하고 미리 정의된 역할에 따라 접근을 허용합니다.",
            "4": "사용자가 AWS Management Console에 접근하고 AD FS에서 액세스 토큰을 얻기 위해 OAuth 흐름을 시작한 다음, 이 토큰을 사용하여 STS를 호출하지 않고 AWS 서비스에 직접 인증합니다."
        },
        "Correct Answer": "기업 사용자가 AD FS에 접근하면, AD FS는 Active Directory에 대해 그들을 인증합니다. AD FS는 그룹 멤버십 세부정보를 포함하는 SAML 토큰을 생성하고, 사용자는 이를 사용하여 AWS Sign-in Endpoint에 로그인합니다. AssumeRoleWithSAML 요청이 STS에 전송되고, STS는 임시 보안 자격 증명을 반환합니다. 마지막으로, AWS는 사용자를 AWS Console URL로 리디렉션합니다.",
        "Explanation": "이 옵션은 SAML 인증 흐름을 정확하게 설명하며, SAML 토큰의 생성, STS에서 임시 자격 증명을 얻기 위한 AssumeRoleWithSAML의 사용, 그리고 AWS Console로의 최종 리디렉션을 포함합니다.",
        "Other Options": [
            "이 옵션은 IAM 정책을 사용하여 AWS Management Console에 직접 로그인하는 것을 설명하며, SSO에 필요한 SAML 또는 AD FS 인증 프로세스를 포함하지 않습니다.",
            "이 옵션은 SAML 토큰 대신 JWT 토큰이 생성된다고 잘못 설명합니다. 이 과정은 AD FS 및 AWS와의 통합을 위해 SAML을 요구합니다.",
            "이 옵션은 SAML 기반 흐름 대신 OAuth 흐름을 제안하여 인증 흐름을 잘못 표현하고 있으며, 이 맥락에서는 적용되지 않습니다."
        ]
    },
    {
        "Question Number": "70",
        "Situation": "한 금융 서비스 회사가 애플리케이션을 AWS로 마이그레이션하고 있으며, 민감한 고객 데이터를 보호하기 위한 엄격한 규정 준수 요구 사항이 있습니다. 그들은 Amazon S3와 Amazon RDS에 저장된 모든 데이터가 휴지 상태에서 암호화되고, 서비스 간 전송되는 데이터도 암호화되도록 해야 합니다. 이러한 요구 사항을 충족하기 위해 다양한 AWS 서비스를 고려하고 있습니다.",
        "Question": "AWS 서비스를 사용할 때 모든 전송 중 및 휴지 상태의 데이터가 안전하게 암호화되도록 보장하는 가장 좋은 방법은 무엇입니까?",
        "Options": {
            "1": "AWS Certificate Manager (ACM)를 활용하여 모든 서비스의 SSL/TLS 인증서를 관리합니다. S3와 RDS에 데이터를 저장하기 전에 클라이언트 측 암호화를 사용하여 암호화된 데이터만 전송되도록 합니다.",
            "2": "AWS CloudHSM을 사용하여 암호화 키를 생성하고 저장합니다. Amazon S3와 RDS에 데이터를 전송하기 전에 암호화하고, 성능 최적화를 위해 서비스 간에 일반 텍스트 통신을 사용합니다.",
            "3": "AWS Key Management Service (KMS)를 사용하여 Amazon S3와 RDS의 암호화 키를 생성하고 관리합니다. S3에 대해 서버 측 암호화를 활성화하고 RDS에 대해 KMS 관리 키를 사용합니다. 서비스 간 모든 통신에 대해 HTTPS를 구현합니다.",
            "4": "Amazon S3 Transfer Acceleration을 구현하여 더 빠른 업로드를 지원하고 전송 중 데이터에 대해 SSL을 활성화합니다. 성능 문제를 피하기 위해 휴지 상태의 데이터에 대해 암호화 없이 Amazon RDS를 사용합니다."
        },
        "Correct Answer": "AWS Key Management Service (KMS)를 사용하여 Amazon S3와 RDS의 암호화 키를 생성하고 관리합니다. S3에 대해 서버 측 암호화를 활성화하고 RDS에 대해 KMS 관리 키를 사용합니다. 서비스 간 모든 통신에 대해 HTTPS를 구현합니다.",
        "Explanation": "AWS KMS를 활용하면 암호화 키를 중앙에서 관리할 수 있어 규정 준수에 매우 중요합니다. S3에 대한 서버 측 암호화를 활성화하면 휴지 상태의 데이터가 보호되고, RDS에 대한 KMS 관리 키는 유사한 보호를 제공합니다. HTTPS를 구현하면 전송 중 데이터가 암호화되어 회사의 보안 요구 사항을 효과적으로 충족합니다.",
        "Other Options": [
            "Amazon S3 Transfer Acceleration을 사용하는 것은 본질적으로 데이터 암호화를 제공하지 않습니다. 전송 중 데이터에 대해 SSL이 활성화되지만, RDS에서 휴지 상태의 데이터를 암호화하지 않는 것은 규정 준수 요구 사항에 위배됩니다.",
            "AWS CloudHSM은 암호화 키 관리에 적합하지만 일반 텍스트 통신을 요구하면 전송 중 데이터의 보안이 저하됩니다. 이 접근 방식은 민감한 정보를 안전하게 전송하기 위한 규정 준수 요구 사항을 충족하지 않습니다.",
            "AWS Certificate Manager는 SSL/TLS 인증서를 관리하는 데 유용하지만, 클라이언트 측 암호화에만 의존하는 것은 복잡성을 추가합니다. 이 옵션은 키가 분실되거나 제대로 처리되지 않을 경우 데이터 관리 및 복구에 문제를 일으킬 수 있습니다."
        ]
    },
    {
        "Question Number": "71",
        "Situation": "운영 팀은 Amazon CloudWatch를 사용하여 애플리케이션의 성능을 모니터링하는 임무를 맡고 있습니다. 그들은 EC2 인스턴스의 CPU 사용률이 특정 임계값을 초과할 때마다 알림을 받기를 원합니다. CloudWatch 메트릭 및 알람을 효과적으로 구성해야 합니다.",
        "Question": "운영 팀이 EC2 인스턴스의 CPU 사용률이 80%를 초과할 때 트리거되는 알람을 설정하기 위해 어떤 단계를 수행해야 합니까?",
        "Options": {
            "1": "get-metric-statistic를 사용하여 CPU 사용률을 모니터링하고 80%를 초과할 때 작업을 트리거하는 알람을 설정합니다.",
            "2": "list-metrics를 사용하여 기존 메트릭을 검색한 다음 set-alarm-state를 사용하여 CPU 사용률이 80%를 초과할 때 알림을 설정합니다.",
            "3": "put-metric-data를 사용하여 CPU 사용률 메트릭을 게시한 다음 put-metric-alarm을 사용하여 알람을 생성합니다.",
            "4": "put-metric-alarm을 사용하여 알람을 생성하고 CPU 사용률이 80%를 초과할 때 알림을 활성화합니다."
        },
        "Correct Answer": "put-metric-alarm을 사용하여 알람을 생성하고 CPU 사용률이 80%를 초과할 때 알림을 활성화합니다.",
        "Explanation": "CPU 사용률에 대한 알람을 설정하는 올바른 방법은 put-metric-alarm API 호출을 사용하여 알람을 생성하고 임계값을 지정한 다음, 임계값이 초과될 때 팀에 알림을 보내도록 알람 작업을 활성화하는 것입니다.",
        "Other Options": [
            "put-metric-data를 사용하는 것은 메트릭을 게시하는 데 필요하지만, 자동으로 알람을 생성하거나 임계값이 초과될 때 알림을 제공하지 않습니다.",
            "get-metric-statistic는 메트릭 데이터 포인트를 검색하는 데 사용되지만, 알람을 생성하거나 임계값에 따라 알림을 트리거하지 않습니다.",
            "list-metrics는 기존 메트릭을 볼 수 있지만, 알람 상태를 설정하거나 메트릭 임계값에 따라 알람을 생성하는 기능을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "72",
        "Situation": "한 금융 기관은 조직 내 모든 AWS 계정이 특정 AWS 서비스의 사용을 금지하는 엄격한 보안 정책을 준수하도록 해야 합니다. 이 기관은 이러한 서비스의 사용을 모든 계정에서 자동으로 거부하면서 특정 예외에 대한 유연성을 허용하는 솔루션을 구현하고자 합니다.",
        "Question": "Service Control Policies (SCPs)를 사용하여 이 정책을 가장 잘 시행하기 위한 단계의 조합은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "AWS Organizations를 사용하여 특정 계정이 거부된 서비스를 사용할 수 있도록 허용하는 IAM 정책을 생성합니다.",
            "2": "CloudTrail 트레일을 설정하여 조직 내에서 거부된 서비스에 대한 모든 API 호출을 기록합니다.",
            "3": "SCP를 루트 조직 단위(OU)에 연결하여 모든 자식 계정에 적용되도록 합니다.",
            "4": "AWS Config 규칙을 구현하여 모든 계정에서 SCP 준수를 모니터링합니다.",
            "5": "조직 내 모든 계정에 대해 지정된 서비스의 사용을 거부하는 SCP를 생성합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "조직 내 모든 계정에 대해 지정된 서비스의 사용을 거부하는 SCP를 생성합니다.",
            "SCP를 루트 조직 단위(OU)에 연결하여 모든 자식 계정에 적용되도록 합니다."
        ],
        "Explanation": "지정된 서비스의 사용을 거부하는 SCP를 생성하면 조직 내 어떤 계정도 해당 서비스를 사용할 수 없도록 하여 보안 정책 준수를 강제합니다. SCP를 루트 OU에 연결하면 정책이 조직 내 모든 계정에 적용되므로 포괄적인 거버넌스 접근 방식이 됩니다.",
        "Other Options": [
            "IAM 정책을 사용하는 것은 모든 계정에 대해 일괄적으로 거부를 시행하지 않으며, IAM 정책은 계정별로 적용되므로 조직 전체의 규정 준수에는 효과적이지 않습니다.",
            "AWS Config 규칙을 구현하는 것은 준수를 모니터링할 뿐 이를 강제하지 않으며, 리소스가 비준수일 경우 알림을 제공할 수 있지만 서비스 사용을 직접적으로 방지할 수는 없습니다.",
            "CloudTrail로 API 호출을 기록하는 것은 감사에 유용하지만, 제한이나 준수를 강제하지 않습니다. 이는 계정에서 수행된 작업에 대한 가시성만 제공하며 서비스 사용을 적극적으로 방지할 수 없습니다."
        ]
    },
    {
        "Question Number": "73",
        "Situation": "한 회사가 AWS에 호스팅된 웹 애플리케이션의 배포 전략을 평가하고 있습니다. 그들은 가변 또는 불변 배포 패턴을 사용하는 것을 고려하고 있습니다. 팀은 잠재적인 다운타임과 배포를 보다 효율적으로 롤백할 수 있는 능력에 대해 우려하고 있습니다. 그들은 어떤 배포 패턴이 제로 다운타임 배포를 달성하고 롤백 기능을 쉽게 할 수 있는 가장 신뢰할 수 있는 방법을 제공하는지 이해하고자 합니다.",
        "Question": "다음 배포 패턴 중 다운타임을 최소화하고 롤백 프로세스를 단순화하는 데 가장 적합한 것은 무엇입니까?",
        "Options": {
            "1": "가변 배포는 기존 인스턴스에 직접 변경을 할 수 있게 합니다.",
            "2": "불변 배포는 기존 리소스에 대한 인플레이스 업데이트에 의존하며, 이는 배포 중 문제를 일으킬 수 있습니다.",
            "3": "가변 배포 패턴은 변경 사항을 효과적으로 관리하기 위해 기능 플래그를 사용해야 합니다.",
            "4": "불변 배포는 각 릴리스를 위해 새로운 인스턴스를 생성하여 변경 사항이 기존 인스턴스에 영향을 미치지 않도록 합니다."
        },
        "Correct Answer": "불변 배포는 각 릴리스를 위해 새로운 인스턴스를 생성하여 변경 사항이 기존 인스턴스에 영향을 미치지 않도록 합니다.",
        "Explanation": "불변 배포는 각 릴리스를 위해 새로운 인스턴스를 생성하도록 설계되어, 깨끗한 상태를 유지하고 현재 실행 중인 인스턴스에 영향을 주지 않습니다. 이 패턴은 배포 실패의 위험을 크게 줄이고 롤백을 단순화합니다. 현재 실행 중인 인스턴스에 영향을 주지 않고 이전 버전으로 쉽게 되돌릴 수 있습니다.",
        "Other Options": [
            "가변 배포는 기존 인스턴스에 직접 변경을 할 수 있게 하여 일관되지 않은 상태를 초래하고 업데이트 과정에서 다운타임을 유발할 수 있습니다.",
            "가변 배포 패턴은 변경 사항을 효과적으로 관리하기 위해 기능 플래그를 사용해야 하지만, 기능 플래그가 있더라도 배포 중 다운타임과 불일치의 위험이 남아 있습니다.",
            "불변 배포는 기존 리소스에 대한 인플레이스 업데이트에 의존하며, 이는 새로운 리소스를 프로비저닝하는 불변 배포의 핵심 원칙에 반하는 것으로 배포 중 문제를 일으킬 수 있습니다."
        ]
    },
    {
        "Question Number": "74",
        "Situation": "한 회사가 AWS CloudTrail을 사용하여 계정에서 이루어진 API 호출을 기록하고 있습니다. 그들은 준수 및 감사 목적을 위해 모든 필요한 로그를 캡처하고 있는지 확인하고자 합니다. 그러나 특정 API 호출이 예상대로 기록되지 않는 것을 발견했습니다.",
        "Question": "모든 관련 API 호출이 기록되고 있는지 확인하기 위해 DevOps 엔지니어가 검토해야 할 구성은 무엇입니까? (두 개 선택)",
        "Options": {
            "1": "사용자 역할과 관련된 IAM 정책이 필요한 권한을 허용합니다.",
            "2": "CloudTrail 이벤트 선택기가 올바르게 구성되어 있습니다.",
            "3": "CloudTrail이 글로벌 서비스 이벤트를 기록하도록 구성되어 있습니다.",
            "4": "CloudTrail 로그 파일 검증이 활성화되어 있습니다.",
            "5": "CloudTrail이 관리 이벤트만 기록하도록 설정되어 있습니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "CloudTrail이 글로벌 서비스 이벤트를 기록하도록 구성되어 있습니다.",
            "CloudTrail 이벤트 선택기가 올바르게 구성되어 있습니다."
        ],
        "Explanation": "정확한 답변은 준수를 위해 모든 필요한 API 호출이 캡처되도록 보장합니다. CloudTrail을 글로벌 서비스 이벤트를 기록하도록 구성함으로써, 회사는 전 세계적으로 운영되는 서비스의 이벤트가 로그에 포함되도록 합니다. 또한, 이벤트 선택기를 올바르게 구성하면 관리 및 데이터 이벤트의 선택적 로그를 가능하게 하여 관련 활동이 캡처되도록 합니다.",
        "Other Options": [
            "CloudTrail 로그 파일 검증이 활성화되어 있습니다. 이 옵션은 로그 파일의 무결성만 보장하며 어떤 이벤트가 기록되는지에는 영향을 미치지 않습니다.",
            "사용자 역할과 관련된 IAM 정책이 필요한 권한을 허용합니다. IAM 정책은 접근을 제어하지만, CloudTrail이 모든 API 호출을 기록하고 있다는 보장은 없습니다.",
            "CloudTrail이 관리 이벤트만 기록하도록 설정되어 있습니다. 이는 로그를 관리 이벤트로만 제한하여 준수에 중요한 데이터 이벤트를 생략할 수 있습니다."
        ]
    },
    {
        "Question Number": "75",
        "Situation": "DevOps 엔지니어로서, 다양한 레이어 7 공격으로부터 웹 애플리케이션을 보호하는 임무를 맡고 있습니다. 귀하의 조직은 AWS WAF를 구현하여 들어오는 트래픽을 필터링하고 모든 요청을 로그로 기록하여 추가 분석을 수행하기로 결정했습니다. 또한, AWS WAF가 특정 규칙에 맞는 요청을 효율적으로 레이블링할 수 있도록 하고, 규칙 평가를 위한 명확한 구조를 유지해야 합니다.",
        "Question": "어떤 접근 방식이 AWS WAF를 효과적으로 활용하여 애플리케이션을 보호하고 로깅을 강화하며 특정 요청 레이블링을 가능하게 할 수 있습니까?",
        "Options": {
            "1": "AWS WAF를 사용하여 요청을 필터링하기 위한 범위 축소 문구가 있는 관리 규칙 그룹을 생성하고, 분석을 위해 Amazon S3에 로그를 전송합니다.",
            "2": "AWS WAF를 구성하여 범위 축소 문구나 로깅 메커니즘을 포함하지 않는 비율 기반 규칙을 사용합니다.",
            "3": "AWS WAF를 설정하여 트래픽을 CloudWatch에 직접 로그로 기록하고 모든 요청을 시각화하기 위한 사용자 대시보드를 생성합니다.",
            "4": "AWS WAF에서 모든 트래픽 로그를 필터링 없이 AWS Kinesis Data Firehose로 직접 전송하는 사용자 정의 규칙을 구현합니다."
        },
        "Correct Answer": "AWS WAF를 사용하여 요청을 필터링하기 위한 범위 축소 문구가 있는 관리 규칙 그룹을 생성하고, 분석을 위해 Amazon S3에 로그를 전송합니다.",
        "Explanation": "AWS WAF를 관리 규칙 그룹과 범위 축소 문구와 함께 사용하면 특정 유형의 요청을 효율적으로 필터링하면서 해당 요청의 로그를 Amazon S3에 기록할 수 있습니다. 이는 레이어 7 공격을 관리하는 구조화된 접근 방식을 제공하고 트래픽에 대한 상세한 분석을 가능하게 합니다.",
        "Other Options": [
            "이 옵션은 특정 레이어 7 공격을 효과적으로 완화하는 데 필수적인 관리 규칙 그룹을 통한 필터링을 사용하지 않습니다. 필터링 없이 Kinesis Data Firehose에 로그를 전송하는 것은 동일한 수준의 제어를 제공하지 않습니다.",
            "이 옵션은 범위 축소 문구나 적절한 로깅을 사용하지 않습니다. 비율 기반 규칙만으로는 추가적인 세분화 없이 다양한 레이어 7 공격으로부터 보호하기에 불충분합니다.",
            "이 옵션은 CloudWatch에 로그를 기록하는 것을 제안하지만, 관리 규칙 그룹이나 범위 축소 문구를 통한 요청 필터링이라는 중요한 측면을 포함하지 않으며, 이는 효과적인 보호 및 분석에 필수적입니다."
        ]
    }
]