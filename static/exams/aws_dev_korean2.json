[
    {
        "Question Number": "1",
        "Situation": "개발 팀이 ECS 작업이 코드베이스나 구성 파일에 민감한 정보를 포함하지 않고도 Amazon S3 버킷에 안전하게 접근할 수 있도록 하는 프로젝트를 진행하고 있습니다.",
        "Question": "가장 안전한 방법은 무엇인가요?",
        "Options": {
            "1": "각 ECS 작업에 필요한 S3 접근 정책을 가진 IAM 사용자를 할당하여 S3 리소스에 직접 접근할 수 있도록 합니다.",
            "2": "ECS 작업 실행 역할에 필요한 S3 접근 정책을 가진 IAM 역할을 연결하여 작업이 자동으로 임시 자격 증명을 사용할 수 있도록 합니다.",
            "3": "IAM 사용자를 위한 장기 접근 키를 생성하고 해당 키를 ECS 작업 환경 변수에 구성하여 S3 접근을 설정합니다.",
            "4": "루트 계정을 사용하여 모든 ECS 작업에 전체 S3 접근 권한을 부여하여 S3 리소스를 관리할 수 있는 무제한 기능을 보장합니다."
        },
        "Correct Answer": "ECS 작업 실행 역할에 필요한 S3 접근 정책을 가진 IAM 역할을 연결하여 작업이 자동으로 임시 자격 증명을 사용할 수 있도록 합니다.",
        "Explanation": "필요한 S3 접근 정책을 가진 IAM 역할을 ECS 작업 실행 역할에 연결하면 작업이 임시 보안 자격 증명을 사용할 수 있습니다. 이는 AWS에서 권장되는 모범 사례로, 자격 증명을 하드코딩할 필요가 없고 자격 증명 노출 위험을 줄입니다. 임시 자격 증명은 AWS에 의해 자동으로 회전되고 관리되어 보안을 강화합니다.",
        "Other Options": [
            "각 ECS 작업에 필요한 S3 접근 정책을 가진 IAM 사용자를 할당하는 것은 정적 자격 증명을 관리해야 하므로 이상적이지 않으며, 이러한 자격 증명이 손상되거나 잘못 관리될 경우 보안 위험을 초래할 수 있습니다.",
            "IAM 사용자를 위한 장기 접근 키를 생성하고 이를 ECS 작업 환경 변수에 구성하는 것은 민감한 정보를 하드코딩하는 것이므로 안전하지 않으며, 이는 우발적인 노출이나 유출로 이어질 수 있습니다.",
            "루트 계정을 사용하여 모든 ECS 작업에 전체 S3 접근 권한을 부여하는 것은 최소 권한 원칙을 위반하므로 강력히 권장되지 않으며, 과도한 권한을 부여하고 잠재적인 오용이나 중요한 리소스에 대한 우발적인 변경의 위험을 증가시킵니다."
        ]
    },
    {
        "Question Number": "2",
        "Situation": "전담 개발 팀이 고품질 애플리케이션을 만들기 위해 노력하고 있으며, 산업 모범 사례를 준수하는 것의 중요성을 잘 알고 있습니다. 그들은 애플리케이션 코드가 잘 구조화될 뿐만 아니라 프로덕션에서 심각한 문제를 일으킬 수 있는 일반적인 보안 취약점이 없도록 하기를 원합니다. 그들은 전체 코드베이스를 자동으로 검토하고 잠재적인 문제에 대한 자세한 피드백을 제공하여 이러한 문제를 사전에 해결할 수 있는 솔루션을 찾고 있습니다.",
        "Question": "팀이 애플리케이션 코드의 자동 분석을 수행하고 모범 사례 및 취약성에 대한 통찰력을 얻기 위해 어떤 AWS 서비스를 활용해야 하나요?",
        "Options": {
            "1": "AWS CodeDeploy는 애플리케이션 배포를 자동화하기 위해 설계된 서비스이지만 코드 분석을 위한 것은 아닙니다.",
            "2": "AWS CodePipeline은 애플리케이션의 빌드, 테스트 및 릴리스 단계를 자동화하는 지속적 배포 서비스이지만 코드 분석에 중점을 두고 있지 않습니다.",
            "3": "AWS CodeGuru는 머신 러닝 기반의 서비스로, 자동 코드 리뷰를 제공하고 코드베이스의 중요한 문제를 식별하며 개선을 위한 제안을 제공합니다.",
            "4": "AWS CloudFormation은 AWS 인프라를 코드로 정의하고 프로비저닝하는 방법을 제공하지만 코드 분석 기능은 제공하지 않습니다."
        },
        "Correct Answer": "AWS CodeGuru는 머신 러닝 기반의 서비스로, 자동 코드 리뷰를 제공하고 코드베이스의 중요한 문제를 식별하며 개선을 위한 제안을 제공합니다.",
        "Explanation": "AWS CodeGuru는 애플리케이션 코드를 분석하기 위해 특별히 설계되었으며, 머신 러닝을 활용하여 잠재적인 취약점을 식별하고 모범 사례를 제안합니다. 이는 코드가 견고하고 안전하도록 보장하려는 개발 팀에게 이상적인 선택입니다.",
        "Other Options": [
            "AWS CodeDeploy는 애플리케이션의 배포 프로세스를 자동화하는 데 중점을 두고 있지만 코드 품질이나 잠재적 취약성에 대한 분석을 제공하지 않습니다.",
            "AWS CodePipeline은 애플리케이션의 빌드 및 배포 워크플로우를 관리하는 지속적 배포 서비스로, 상세한 코드 분석에 필요한 기능이 부족합니다.",
            "AWS CloudFormation은 인프라를 코드로 정의하고 프로비저닝하기 위한 것이지 애플리케이션 코드를 분석하거나 검토하기 위한 것이 아닙니다."
        ]
    },
    {
        "Question Number": "3",
        "Situation": "개발자가 AWS Lambda를 사용하여 데이터 처리 애플리케이션을 설계하고 있습니다. 이 애플리케이션에서는 함수가 대규모 데이터 세트를 처리하고 작업을 효율적으로 완료하기 위해 최대 10분 동안 실행될 수 있어야 합니다. 함수의 타임아웃을 적절하게 구성하는 것이 중요하여 조기에 종료되지 않고 완전히 실행될 수 있도록 해야 합니다.",
        "Question": "Lambda 함수가 중단되거나 타임아웃으로 실패하지 않고 최대 10분 동안 실행될 수 있도록 적절한 타임아웃 구성은 무엇인가요?",
        "Options": {
            "1": "타임아웃을 기본값인 3초로 설정합니다.",
            "2": "타임아웃을 10분(600초)으로 설정합니다.",
            "3": "타임아웃을 15분(900초)으로 늘립니다.",
            "4": "3초 제한을 초과하는 작업을 처리하기 위해 외부 서비스를 사용합니다."
        },
        "Correct Answer": "타임아웃을 10분(600초)으로 설정합니다.",
        "Explanation": "타임아웃을 10분(600초)으로 설정하면 Lambda 함수가 작업을 효과적으로 실행할 수 있도록 요구 사항을 정확히 충족합니다. 이 구성은 개발자가 AWS Lambda가 단일 호출에 대해 지원하는 최대 실행 시간을 활용할 수 있도록 하여 함수가 작업을 완료할 충분한 시간을 보장합니다.",
        "Other Options": [
            "타임아웃을 기본값인 3초로 설정하는 것은 애플리케이션의 요구 사항에 비해 너무 짧아 함수가 처리를 완료하기 전에 타임아웃이 발생할 것입니다.",
            "타임아웃을 15분(900초)으로 늘리는 것은 AWS Lambda 함수에 허용된 최대 실행 기간인 15분을 초과하므로 유효한 구성은 아닙니다. 이 옵션은 기술적으로 요구 사항보다 길지만 유효하지 않습니다.",
            "3초 제한을 초과하는 작업을 처리하기 위해 외부 서비스를 사용하는 것은 함수가 최대 10분 동안 실행될 수 있도록 하는 요구 사항을 해결하지 않으며, 불필요한 복잡성을 도입하고 데이터 일관성과 성능 문제를 초래할 수 있습니다."
        ]
    },
    {
        "Question Number": "4",
        "Situation": "개발자가 AWS Lambda를 사용하여 서버리스 애플리케이션을 배포할 준비를 하고 있으며, 최적의 성능을 위해 배포 패키지의 크기 제한을 고려하고 있습니다.",
        "Question": "컨테이너 이미지를 사용할 때 AWS Lambda 함수 배포 패키지에 허용되는 최대 크기는 얼마입니까?",
        "Options": {
            "1": "컨테이너 이미지를 사용하는 Lambda 함수 배포 패키지의 최대 크기는 압축 시 50 MB입니다.",
            "2": "컨테이너 이미지를 사용하여 Lambda 함수를 배포할 때, 압축 해제된 배포 패키지는 최대 250 MB까지 가능합니다.",
            "3": "AWS Lambda 콘솔의 편집기는 배포 패키지 크기를 단 3 MB로 제한하므로 매우 제한적입니다.",
            "4": "컨테이너 이미지를 사용하는 AWS Lambda 함수의 경우, 최대 배포 패키지 크기는 상당한 10 GB입니다."
        },
        "Correct Answer": "컨테이너 이미지를 사용하는 AWS Lambda 함수의 경우, 최대 배포 패키지 크기는 상당한 10 GB입니다.",
        "Explanation": "AWS Lambda는 배포를 위해 컨테이너 이미지를 사용할 수 있으며, 이러한 이미지의 최대 크기는 압축 해제 시 10 GB입니다. 이 큰 크기는 추가 라이브러리 및 종속성이 필요한 보다 복잡한 애플리케이션을 수용할 수 있습니다.",
        "Other Options": [
            "50 MB 압축된 옵션은 전통적인 Lambda 함수 배포 패키지의 제한을 나타내며, 컨테이너 이미지와는 관련이 없습니다. 따라서 이 답변은 잘못되었습니다.",
            "압축 해제된 250 MB는 전통적인 배포 패키지의 일반적인 크기 제한이지만, 컨테이너 이미지에는 적용되지 않으므로 이 옵션은 잘못되었습니다.",
            "언급된 3 MB 제한은 AWS Lambda 콘솔에서 제공하는 인라인 코드 편집기에만 해당하며, 컨테이너 이미지를 사용할 때는 관련이 없습니다."
        ]
    },
    {
        "Question Number": "5",
        "Situation": "AWS X-Ray에 의해 적극적으로 모니터링되는 애플리케이션에서 HTTP 상태 코드 429로 표시되는 스로틀링 오류가 급증하고 있습니다. 이는 애플리케이션이 처리할 수 있는 것보다 더 많은 요청을 받고 있음을 나타냅니다. 개발 팀은 이러한 오류의 근본 원인을 진단하고 문제를 완화하기 위한 효과적인 솔루션을 구현하여 최적의 성능과 사용자 만족을 보장하고자 합니다.",
        "Question": "애플리케이션의 추적에서 보고된 높은 스로틀링 오류를 효과적으로 진단하고 해결하기 위해 개발 팀이 우선적으로 수행해야 할 구체적인 조치는 무엇입니까?",
        "Options": {
            "1": "애플리케이션의 전체 용량을 늘려 사용자와 클라이언트로부터 들어오는 더 많은 요청을 효과적으로 관리할 수 있도록 고려합니다.",
            "2": "AWS X-Ray 내에서 필터 표현식을 구현하여 429 스로틀링 오류를 포함하는 추적을 정확히 찾아 분석합니다.",
            "3": "AWS X-Ray에서 세그먼트의 하위 세그먼트를 면밀히 모니터링하여 스로틀링 문제에 대한 자세한 통찰력과 특정 정보를 얻습니다.",
            "4": "메타데이터 저장소를 활용하여 스로틀링 관련 정보를 추적하고, 이를 향후 분석 및 문제 해결에 참조합니다."
        },
        "Correct Answer": "AWS X-Ray 내에서 필터 표현식을 구현하여 429 스로틀링 오류를 포함하는 추적을 정확히 찾아 분석합니다.",
        "Explanation": "AWS X-Ray에서 필터 표현식을 사용하면 팀이 429 오류를 생성하는 특정 추적에 집중할 수 있어 패턴, 출처 및 스로틀링의 잠재적 원인을 신속하게 식별하는 데 도움이 됩니다. 이러한 목표 분석은 문제를 효과적으로 진단하고 적절한 솔루션을 결정하는 데 중요합니다.",
        "Other Options": [
            "애플리케이션의 용량을 늘리는 것은 장기적으로 도움이 될 수 있지만, 현재 보고되고 있는 스로틀링 오류를 분석하고 이해하는 즉각적인 필요를 직접적으로 해결하지는 않습니다.",
            "세그먼트의 하위 세그먼트를 모니터링하는 것은 유용한 통찰력을 제공할 수 있지만, 특정 오류를 먼저 필터링하지 않으면 팀이 429 상태 코드와 관련된 중요한 패턴을 놓칠 수 있습니다.",
            "미래 참조를 위해 메타데이터에 스로틀링 관련 정보를 저장하는 것은 유익할 수 있지만, 현재 높은 스로틀링 오류 문제에 대한 즉각적인 통찰력이나 솔루션을 제공하지는 않습니다."
        ]
    },
    {
        "Question Number": "6",
        "Situation": "개발자가 AWS Step Functions를 활용하여 일련의 AWS Lambda 함수를 조정하는 복잡한 애플리케이션을 구축하고 있습니다. 이 워크플로우는 특정 중요한 단계에 대한 포괄적인 오류 처리 및 재시도 메커니즘을 포함하도록 설계되었습니다. 개발자의 목표는 Lambda 함수 실패 시 Step Functions 워크플로우가 최대 세 번까지 함수를 재시도할 수 있도록 하여, 후속 시도의 성공 가능성을 최적화하기 위해 지수 백오프 전략을 사용하는 것입니다.",
        "Question": "AWS Step Functions 상태 머신 내에서 원하는 오류 처리 및 재시도 기능을 달성하기 위해 개발자가 Lambda 함수가 실패할 때 적절하게 재시도되도록 보장하기 위해 구현해야 할 구체적인 구성은 무엇입니까?",
        "Options": {
            "1": "여러 분기를 가진 병렬 상태를 사용합니다.",
            "2": "상태 정의에서 재시도 정책과 함께 Catch 블록을 구성합니다.",
            "3": "Lambda 함수의 타임아웃 값을 높게 설정합니다.",
            "4": "실패를 수동으로 처리하기 위해 선택 상태를 사용합니다."
        },
        "Correct Answer": "상태 정의에서 재시도 정책과 함께 Catch 블록을 구성합니다.",
        "Explanation": "AWS Step Functions에서 오류 처리와 함께 재시도를 구현하는 올바른 접근 방식은 Lambda 함수의 상태 정의 내에서 Catch 블록과 재시도 정책을 구성하는 것입니다. 이 설정은 최대 재시도 횟수 및 시도 간 지연과 같은 특정 조건을 통해 자동 재시도를 가능하게 하며, 필요할 경우 지수 백오프를 포함합니다. 이를 통해 워크플로우는 수동 개입 없이도 실패를 효과적으로 처리할 수 있습니다.",
        "Other Options": [
            "여러 분기를 가진 병렬 상태를 사용하는 것은 실패 시 단일 Lambda 함수를 재시도하는 것과는 관련이 없습니다. 이 구성은 실패한 실행에 대한 재시도를 처리하기보다는 여러 작업을 동시에 실행하는 데 더 적합합니다.",
            "Lambda 함수의 타임아웃 값을 높게 설정하는 것은 실패 시 재시도의 필요성을 직접적으로 해결하지 않습니다. 타임아웃을 늘리는 것은 장기 실행 프로세스의 경우 도움이 될 수 있지만, 이 시나리오에서 필요한 재시도 로직을 구현하지는 않습니다.",
            "실패를 수동으로 처리하기 위해 선택 상태를 사용하는 것은 자동 재시도에 대한 실용적인 솔루션이 아닙니다. 선택 상태는 조건에 따라 워크플로우를 분기하는 데 설계되었지만, 실패한 작업을 재시도하는 고유한 메커니즘을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "7",
        "Situation": "한 회사가 AWS 서비스를 사용하여 확장 가능한 전자상거래 애플리케이션을 개발하고 있습니다. 아키텍처는 다양한 트래픽 부하를 효율적으로 처리하면서 서로 다른 구성 요소가 독립적으로 발전할 수 있도록 해야 합니다. 개발 팀은 이를 달성하기 위해 다양한 아키텍처 패턴을 고려하고 있습니다.",
        "Question": "이 요구 사항을 충족하기 위해 팀이 채택해야 할 아키텍처 패턴은 무엇입니까?",
        "Options": {
            "1": "모놀리식 아키텍처로 모든 구성 요소를 단일 애플리케이션으로 배포합니다.",
            "2": "느슨하게 결합된 서비스로 구성된 이벤트 기반 마이크로서비스 아키텍처.",
            "3": "긴밀하게 통합된 백엔드 서비스로 구성된 클라이언트-서버 아키텍처.",
            "4": "각 레이어 간의 의존성이 있는 계층화된 아키텍처."
        },
        "Correct Answer": "느슨하게 결합된 서비스로 구성된 이벤트 기반 마이크로서비스 아키텍처.",
        "Explanation": "이벤트 기반 마이크로서비스 아키텍처는 독립적인 확장성과 다양한 트래픽 부하를 처리하는 유연성을 제공합니다. 느슨하게 결합된 서비스를 사용함으로써 팀은 한 서비스의 변경이 다른 서비스에 큰 영향을 미치지 않도록 보장할 수 있어, 시간이 지남에 따라 구성 요소의 발전을 지원합니다. 이 패턴은 트래픽이 크게 변동할 수 있는 전자상거래와 같은 동적 환경에 적합합니다.",
        "Other Options": [
            "모놀리식 아키텍처는 모든 구성 요소가 긴밀하게 결합되어 함께 배포되므로 독립적인 확장을 지원하지 않으며, 애플리케이션의 특정 부분을 발전시키기 어렵습니다.",
            "클라이언트-서버 아키텍처는 일반적으로 긴밀하게 통합된 백엔드 서비스를 포함하여 병목 현상을 초래하고 확장을 제한할 수 있으며, 확장을 위해서는 전체 애플리케이션을 확장해야 합니다.",
            "계층화된 아키텍처는 레이어 간의 의존성을 도입하여 구성 요소의 확장 및 발전을 복잡하게 만들어, 서비스의 유연성과 독립적인 발전이 필요한 환경에 덜 적합합니다."
        ]
    },
    {
        "Question Number": "8",
        "Situation": "솔루션 아키텍트가 특정 사용자에 의해 수행될 수 있는 특정 작업을 허용하는 AWS 리소스에 대한 액세스 권한을 정의해야 합니다. 아키텍트는 정책이 사용자에게가 아니라 리소스에 직접 연결되도록 하기를 원합니다.",
        "Question": "이를 달성하기 위해 아키텍트가 사용해야 할 정책 유형은 무엇입니까?",
        "Options": {
            "1": "주체 정책",
            "2": "서비스 제어 정책",
            "3": "리소스 기반 정책",
            "4": "신원 기반 정책"
        },
        "Correct Answer": "리소스 기반 정책",
        "Explanation": "AWS의 리소스 기반 정책은 권한을 리소스 자체에 직접 연결할 수 있게 하여 특정 작업을 사용자나 역할이 수행할 수 있도록 합니다. 이 접근 방식은 아키텍트가 사용자 수준이 아닌 리소스 수준에서 액세스를 관리해야 하는 요구 사항에 적합합니다.",
        "Other Options": [
            "주체 정책은 AWS에서 인식되는 정책 유형이 아니므로 제시된 시나리오에 적용되지 않습니다.",
            "서비스 제어 정책은 AWS Organizations에서 서로 다른 계정 간의 권한을 관리하는 데 사용되지만 리소스에 직접 연결되지 않습니다.",
            "신원 기반 정책은 사용자나 역할과 같은 신원에 연결되므로 정책을 리소스에 직접 연결해야 하는 요구 사항을 충족하지 않습니다."
        ]
    },
    {
        "Question Number": "9",
        "Situation": "개발자가 민감한 데이터 처리 애플리케이션에 대한 암호화를 구현하고 있습니다. 이 애플리케이션은 평문 키를 사용하여 로컬에서 데이터를 암호화해야 하며, 나중에 사용할 수 있도록 암호화된 버전의 키를 안전하게 저장해야 합니다.",
        "Question": "이 요구 사항을 충족하기 위해 개발자가 사용해야 할 AWS KMS API 작업은 무엇입니까?",
        "Options": {
            "1": "GenerateDataKey",
            "2": "GenerateDataKeyPlainText",
            "3": "Encrypt",
            "4": "Decrypt"
        },
        "Correct Answer": "GenerateDataKey",
        "Explanation": "AWS KMS의 GenerateDataKey 작업은 데이터를 암호화하는 데 사용할 수 있는 데이터 키를 생성합니다. 이 작업은 평문 키와 그 암호화된 버전을 모두 반환하므로 개발자는 평문 키를 로컬 암호화에 사용하고 암호화된 버전을 안전하게 저장할 수 있습니다. 이는 애플리케이션의 요구 사항을 완벽하게 충족합니다.",
        "Other Options": [
            "GenerateDataKeyPlainText는 유효한 AWS KMS 작업이 아닙니다. 올바른 작업은 GenerateDataKey로, 평문 키와 암호화된 키를 모두 제공합니다.",
            "Encrypt는 주어진 키로 데이터를 암호화하는 데 사용되지만 키의 암호화된 버전을 생성하고 반환하는 기능은 제공하지 않습니다.",
            "Decrypt는 이전에 암호화된 데이터를 복호화하는 데 사용되지만 키를 생성하거나 키 관리 기능을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "10",
        "Situation": "개발자가 Amazon DynamoDB를 사용하여 사용자 세션 데이터를 저장하고 있습니다. 데이터가 파티션에 고르게 분포되고 성능 병목 현상을 피하기 위해, 개발자는 확장성과 효율성을 지원할 수 있는 적절한 파티션 키를 선택해야 합니다.",
        "Question": "DynamoDB에서 균형 잡힌 파티션 접근을 달성하기 위해 파티션 키는 어떤 특성을 가져야 합니까?",
        "Options": {
            "1": "고유 값이 몇 개만 포함된 저 카디널리티의 파티션 키로, 데이터 분포가 고르지 않을 수 있습니다.",
            "2": "고유 값이 많은 고 카디널리티의 파티션 키로, 파티션 간의 고른 분포를 보장합니다.",
            "3": "예측 가능한 접근 패턴으로 인해 핫스팟을 생성할 수 있는 순차적 값을 사용하는 파티션 키.",
            "4": "여러 속성으로 구성된 복합 파티션 키로, 데이터 검색 및 접근 패턴을 복잡하게 만들 수 있습니다."
        },
        "Correct Answer": "고유 값이 많은 고 카디널리티의 파티션 키로, 파티션 간의 고른 분포를 보장합니다.",
        "Explanation": "정답은 파티션 키가 고 카디널리티를 가져야 한다는 것입니다. 즉, 많은 고유 값을 가져야 합니다. 이 특성은 DynamoDB가 여러 파티션에 걸쳐 작업 부하를 고르게 분산시킬 수 있게 하여 성능을 향상시키고 병목 현상을 피할 수 있게 합니다. 고유 값이 많을수록 데이터가 더 효과적으로 분산되어, 단일 파티션이 과도한 접근으로 인해 핫스팟이 되는 위험을 최소화합니다.",
        "Other Options": [
            "이 옵션은 저 카디널리티의 파티션 키가 고유 값의 수가 제한적이기 때문에 잘못된 것입니다. 이러한 키는 데이터 분포가 고르지 않게 되고, 여러 항목이 동일한 파티션에 클러스터링되어 성능 문제를 일으킬 수 있습니다.",
            "이 옵션은 순차적 값이 정리된 것처럼 보일 수 있지만, 실제로는 접근 패턴에서 핫스팟을 생성할 수 있기 때문에 잘못된 것입니다. 이러한 순차적 값으로 인해 많은 요청이 동일한 파티션으로 향하게 되면 성능 저하를 초래할 수 있습니다.",
            "이 옵션은 복합 키가 유연성을 제공할 수 있지만, 데이터 접근 및 검색을 복잡하게 만들 수 있기 때문에 잘못된 것입니다. 이러한 추가 복잡성은 효과적인 파티션 접근을 방해할 수 있으며, 파티션 간의 균형 잡힌 분포를 보장하지 못할 수 있습니다."
        ]
    },
    {
        "Question Number": "11",
        "Situation": "개발자가 이벤트를 처리하기 위해 Lambda 함수를 성공적으로 배포했지만, 함수가 오류 없이 실행되는 것처럼 보임에도 불구하고 CloudWatch에 로그가 나타나지 않는 것을 발견했습니다. 로그가 없으면 함수의 성능을 디버깅하고 모니터링하기가 어렵습니다. 개발자는 함수의 실행 역할을 수정하여 로깅 기능이 활성화되도록 하여 함수의 활동을 효과적으로 추적할 수 있도록 하려고 합니다.",
        "Question": "Lambda 함수의 실행 역할에 어떤 특정 IAM 정책을 포함해야 CloudWatch에서 로그가 제대로 생성되고 표시되어 모니터링 및 문제 해결에 도움이 될까요?",
        "Options": {
            "1": "AWSLambdaVPCAccessExecutionRole, 주로 Lambda 함수의 VPC 접근을 가능하게 하지만 로깅 기능을 다루지 않습니다.",
            "2": "AWSLambdaBasicExecutionRole, CloudWatch에 함수 실행 세부 정보를 로깅하는 데 필수적인 권한을 부여하여 효과적인 모니터링을 가능하게 합니다.",
            "3": "CloudWatchLambdaInsightsExecutionRolePolicy, 모니터링을 향상시키기 위해 설계되었지만 CloudWatch에 필요한 기본 로깅 권한을 직접적으로 다루지 않을 수 있습니다.",
            "4": "AWSLambdaKinesisExecutionRole, Kinesis 데이터 스트림에 맞춰져 있으며 CloudWatch 로깅 기능과는 관련이 없습니다."
        },
        "Correct Answer": "AWSLambdaBasicExecutionRole, CloudWatch에 함수 실행 세부 정보를 로깅하는 데 필수적인 권한을 부여하여 효과적인 모니터링을 가능하게 합니다.",
        "Explanation": "정답은 AWSLambdaBasicExecutionRole입니다. 이 IAM 정책은 Lambda 함수가 CloudWatch에 로그를 작성하는 데 필요한 권한을 포함하고 있습니다. 이러한 권한이 없으면 Lambda 함수의 성공적인 실행조차도 로그 항목을 생성하지 않게 되어 성능을 추적하거나 문제를 효과적으로 해결할 수 없습니다.",
        "Other Options": [
            "AWSLambdaVPCAccessExecutionRole은 Lambda 함수가 VPC의 리소스에 접근할 수 있도록 허용하는 데 중점을 두고 있어 이 시나리오에 적합하지 않습니다. CloudWatch에 로깅을 위한 필요한 권한을 제공하지 않습니다.",
            "CloudWatchLambdaInsightsExecutionRolePolicy는 모니터링 기능을 향상시키는 데 유용하지만, Lambda 함수가 CloudWatch에 로그를 생성하기 위한 기본 로깅 권한이 부여되지 않도록 보장하지 않습니다.",
            "AWSLambdaKinesisExecutionRole은 Kinesis 데이터 스트림과의 상호작용에 맞춰져 있으며 Lambda 함수 활동을 CloudWatch에 로깅하는 데 필요한 권한을 포함하지 않기 때문에 이 맥락에서는 관련이 없습니다."
        ]
    },
    {
        "Question Number": "12",
        "Situation": "개발자가 사용자가 파일을 업로드할 수 있는 애플리케이션을 만들고 있습니다. 이 파일에는 종종 개인 식별 번호, 신용 카드 세부 정보 및 기밀 문서와 같은 민감한 정보가 포함되어 있습니다. 이러한 정보의 프라이버시와 보안을 보장하기 위해, 개발자는 애플리케이션 로그나 오류 메시지에 민감한 데이터가 노출되지 않도록 하는 모범 사례를 준수해야 합니다. 이는 사용자 신뢰뿐만 아니라 다양한 데이터 보호 규정을 준수하는 데도 중요합니다.",
        "Question": "개발자가 애플리케이션 내에서 민감한 데이터를 효과적으로 세척하고 로그에 우발적으로 기록되지 않도록 하기 위해 어떤 특정 관행을 구현해야 합니까?",
        "Options": {
            "1": "애플리케이션에서 처리하기 전에 모든 데이터를 암호화합니다.",
            "2": "로그를 작성하기 전에 민감한 정보를 제거하거나 마스킹합니다.",
            "3": "로그 대신 환경 변수에 민감한 데이터를 저장합니다.",
            "4": "로깅을 위한 암호화 키 관리를 위해 AWS KMS를 사용합니다."
        },
        "Correct Answer": "로그를 작성하기 전에 민감한 정보를 제거하거나 마스킹합니다.",
        "Explanation": "로그를 작성하기 전에 민감한 정보를 제거하거나 마스킹하는 것은 로그에 민감한 데이터가 노출되지 않도록 보장하는 직접적인 접근 방식입니다. 이 관행은 사용자 기밀성을 유지하고 보안 모범 사례에 부합하여 이 맥락에서 민감한 데이터를 세척하는 가장 효과적인 방법입니다.",
        "Other Options": [
            "모든 데이터를 처리하기 전에 암호화하는 것은 민감한 정보가 로그에 기록되는 문제를 구체적으로 해결하지 않으며, 적절히 처리되지 않으면 로그에 암호화되지 않은 데이터가 포함될 수 있습니다.",
            "민감한 데이터를 로그 대신 환경 변수에 저장하는 것은 민감한 정보를 처리하는 모범 사례가 아니며, 환경 변수도 다양한 방법으로 노출될 수 있고 로깅 문제를 해결하지 않습니다.",
            "로깅을 위한 암호화 키 관리를 위해 AWS KMS를 사용하는 것은 세척보다는 암호화 관리에 관한 것이며, 이 옵션은 민감한 데이터가 암호화되기 전에 로그에 나타나는 것을 방지하지 않습니다."
        ]
    },
    {
        "Question Number": "13",
        "Situation": "한 회사가 AWS Lambda 함수를 사용하여 서버리스 애플리케이션을 개발하고 있습니다. 이 애플리케이션은 Amazon S3 버킷에 업로드된 이미지를 처리해야 하며, 이미지를 크기 조정하고 조정된 이미지를 다른 S3 버킷에 저장해야 합니다. 회사는 새로운 이미지가 업로드될 때마다 이미지 처리가 자동으로 트리거되도록 하기를 원합니다.",
        "Question": "어떤 솔루션이 이러한 요구 사항을 충족할 수 있습니까?",
        "Options": {
            "1": "Amazon S3 이벤트 알림을 구성하여 소스 버킷에 새로운 객체가 생성될 때마다 AWS Lambda 함수를 자동으로 트리거하여 이미지 처리를 시작합니다.",
            "2": "Amazon CloudWatch Events를 사용하여 AWS Lambda 함수를 정의된 간격으로 실행하도록 예약하고 S3 버킷에서 새로운 이미지를 확인하여 적절히 처리합니다.",
            "3": "정기적으로 실행되는 사용자 정의 스크립트를 개발하여 S3 버킷을 폴링하고 새로운 이미지를 식별하여 필요에 따라 AWS Lambda 함수를 호출합니다.",
            "4": "Amazon SNS 주제를 설정하여 S3 버킷에 새로운 이미지가 업로드될 때마다 AWS Lambda 함수에 알림을 보내어 반응적인 처리를 가능하게 합니다."
        },
        "Correct Answer": "Amazon S3 이벤트 알림을 구성하여 소스 버킷에 새로운 객체가 생성될 때마다 AWS Lambda 함수를 자동으로 트리거하여 이미지 처리를 시작합니다.",
        "Explanation": "올바른 솔루션은 지정된 S3 버킷에 새로운 객체가 생성될 때마다 AWS Lambda 함수를 자동으로 트리거하는 Amazon S3 이벤트 알림을 구성하는 것입니다. 이 접근 방식은 수동 개입이나 지연 없이 즉시 효율적으로 이미지 처리가 이루어지도록 보장합니다.",
        "Other Options": [
            "Amazon CloudWatch Events를 사용하여 AWS Lambda 함수를 몇 분마다 실행하도록 예약하는 것은 비효율적이며, 함수가 실행된 직후에 업로드된 이미지를 처리하는 데 불필요한 지연을 초래할 수 있습니다.",
            "S3 버킷을 정기적으로 폴링하는 사용자 정의 스크립트를 개발하는 것은 복잡성을 추가하고 비용과 지연을 증가시킬 수 있으므로 이상적인 솔루션이 아닙니다. 함수가 업로드 직후에 트리거되지 않을 수 있습니다.",
            "새로운 이미지가 업로드될 때 AWS Lambda 함수에 알림을 보내기 위해 Amazon SNS 주제를 설정하는 것은 추가 구성이 필요할 수 있으며, S3 이벤트 알림을 사용하는 것만큼 직접적이지 않으므로 이 특정 사용 사례에 대해 비효율적인 솔루션입니다."
        ]
    },
    {
        "Question Number": "14",
        "Situation": "한 개발자가 Amazon S3에 민감한 고객 데이터를 저장하고 클라이언트와 서버 간에 인터넷을 통해 데이터를 전송하는 웹 애플리케이션을 구축하고 있습니다. 이 애플리케이션은 보안 정책 및 데이터 보호를 위한 모범 사례를 준수하기 위해 데이터가 저장 중 및 전송 중 모두 암호화되도록 해야 합니다.",
        "Question": "개발자가 저장 중 및 전송 중 암호화를 달성하기 위해 어떤 AWS 기능 조합을 구현해야 합니까?",
        "Options": {
            "1": "Amazon S3 서버 측 암호화를 AWS KMS 관리 키(SSE-KMS)로 활성화하고 모든 클라이언트 통신에 HTTPS를 사용하여 강력한 보안을 보장합니다.",
            "2": "클라이언트 측 암호화를 사용하여 Amazon S3에 업로드하기 전에 데이터를 암호화하고 클라이언트 통신에 HTTP를 사용하는 것은 민감한 데이터에 대해 충분히 안전하지 않습니다.",
            "3": "Amazon S3 관리 키(SSE-S3)로 Amazon S3 서버 측 암호화를 활성화하고 클라이언트-서버 통신에 TLS를 사용하여 좋은 수준의 보호를 제공합니다.",
            "4": "Amazon S3에 저장하기 전에 애플리케이션 내에서 데이터를 암호화하고 클라이언트 통신에 SSH를 사용하는 것은 웹 애플리케이션의 표준이 아닙니다."
        },
        "Correct Answer": "Amazon S3 서버 측 암호화를 AWS KMS 관리 키(SSE-KMS)로 활성화하고 모든 클라이언트 통신에 HTTPS를 사용하여 강력한 보안을 보장합니다.",
        "Explanation": "AWS KMS 관리 키를 사용하여 Amazon S3에서 서버 측 암호화를 수행하는 조합은 저장 중인 데이터가 높은 수준의 보안으로 암호화되도록 보장합니다. 또한 클라이언트와 서버 간의 모든 통신에 HTTPS를 사용하면 전송 중인 데이터가 암호화되어 보안 정책을 준수하고 민감한 고객 정보를 효과적으로 보호합니다.",
        "Other Options": [
            "Amazon S3에 데이터를 업로드하기 전에 클라이언트 측 암호화를 사용하는 것은 유효한 방법이지만, HTTP 대신 HTTPS를 사용하면 전송 중인 데이터의 보안이 저하되어 민감한 고객 데이터에 대해 이 옵션이 부적절합니다.",
            "SSE-S3는 저장 중 암호화를 제공하지만, 클라이언트-서버 통신에 TLS를 사용하는 것은 웹 애플리케이션의 최고 보안을 보장하는 데 HTTPS보다 덜 효과적입니다. 따라서 암호화 요구 사항을 포괄적으로 충족하지 않습니다.",
            "Amazon S3에 저장하기 전에 애플리케이션 내에서 데이터를 암호화하는 것은 좋은 관행이지만, 클라이언트 통신에 SSH를 사용하는 것은 웹 애플리케이션의 표준이 아니며, 일반적으로 HTTPS를 사용합니다. 이로 인해 이 옵션은 이 시나리오에 덜 적용됩니다."
        ]
    },
    {
        "Question Number": "15",
        "Situation": "한 개발자가 업로드된 파일을 처리하기 위해 Lambda 함수를 Amazon S3와 통합하고 있습니다. 이 함수는 즉시 응답을 반환하면서 이벤트를 나중에 처리하도록 큐에 추가해야 합니다.",
        "Question": "이 시나리오에서 개발자가 어떤 호출 유형을 사용해야 합니까?",
        "Options": {
            "1": "동기 호출",
            "2": "비동기 호출",
            "3": "Lambda 레이어 호출",
            "4": "EventBridge 호출"
        },
        "Correct Answer": "비동기 호출",
        "Explanation": "비동기 호출이 올바른 선택입니다. 이 호출 방식은 Lambda 함수가 이벤트를 백그라운드에서 처리하는 동안 즉시 응답을 반환할 수 있게 해줍니다. 이는 응답 시간이 중요한 시나리오에 이상적이며, 함수가 나중에 처리를 할 수 있도록 하여 호출자를 차단하지 않습니다.",
        "Other Options": [
            "동기 호출은 함수가 응답을 반환하기 전에 처리를 완료해야 하므로 이 시나리오에서 즉시 응답 요구 사항과 모순됩니다.",
            "Lambda 레이어 호출은 Lambda에서 코드 종속성을 관리하기 위해 레이어를 사용하는 것을 의미하며, 이벤트 처리를 위한 호출 유형과 관련이 없습니다.",
            "EventBridge 호출은 Amazon EventBridge에서 이벤트를 트리거하는 것과 관련이 있지만, 나중에 처리를 위해 이벤트를 큐에 추가하는 동안 즉시 응답이 필요하다는 요구를 직접적으로 해결하지 않습니다."
        ]
    },
    {
        "Question Number": "16",
        "Situation": "개발자는 고트래픽 애플리케이션의 사용자 데이터를 저장하기 위해 Amazon DynamoDB 테이블을 설계하는 임무를 맡았습니다. 이 애플리케이션은 다양한 접근 패턴을 효율적으로 처리해야 하며, 사용자가 데이터를 빠르고 신뢰성 있게 검색할 수 있도록 해야 합니다. 이를 달성하기 위해 개발자는 DynamoDB 테이블 내에서 키와 인덱스를 어떻게 구조화할지를 신중하게 고려해야 하며, 이러한 선택은 쿼리 성능과 전체 애플리케이션 반응성에 상당한 영향을 미칠 것입니다.",
        "Question": "쿼리 성능 최적화와 다양한 접근 패턴 수용의 필요성을 고려할 때, 개발자가 여러 쿼리 패턴을 효율적으로 지원하기 위해 구현해야 할 DynamoDB 키와 인덱스의 조합은 무엇입니까?",
        "Options": {
            "1": "보조 인덱스 없이 단일 기본 키를 사용합니다.",
            "2": "복합 기본 키를 사용하고 추가 접근 패턴을 위해 글로벌 보조 인덱스를 추가합니다.",
            "3": "파티션 키만 사용하고 모든 쿼리에 대해 스캔 작업에 의존합니다.",
            "4": "정렬 키만 사용하고 추가 쿼리를 위해 로컬 보조 인덱스를 구현합니다."
        },
        "Correct Answer": "복합 기본 키를 사용하고 추가 접근 패턴을 위해 글로벌 보조 인덱스를 추가합니다.",
        "Explanation": "복합 기본 키를 사용하면 개발자가 파티션 키와 정렬 키를 모두 정의할 수 있어 쿼리의 유연성을 크게 향상시킬 수 있습니다. 글로벌 보조 인덱스를 추가하면 다양한 접근 패턴을 지원하여 기본 키 구조에만 의존하지 않는 효율적인 쿼리를 가능하게 합니다. 이 접근 방식은 여러 쿼리 유형을 신속하게 실행할 수 있도록 하여 고트래픽 애플리케이션의 성능을 최적화합니다.",
        "Other Options": [
            "보조 인덱스 없이 단일 기본 키를 사용하는 것은 쿼리의 유연성과 효율성을 제한하여 여러 접근 패턴을 효과적으로 처리하기 어렵게 만듭니다.",
            "파티션 키에만 의존하고 모든 쿼리에 대해 스캔 작업을 사용하는 것은 비효율적이며, 스캔 작업은 느릴 수 있고 특히 고트래픽 시나리오에서 더 많은 읽기 용량 단위를 소모할 수 있습니다.",
            "정렬 키만 구현하는 것은 불충분하며, 효율적인 데이터 검색을 위한 필요한 파티셔닝을 제공하지 않으며, 로컬 보조 인덱스는 파티션 키를 기반으로 한 쿼리로 제한됩니다."
        ]
    },
    {
        "Question Number": "17",
        "Situation": "개발 팀은 버전 관리를 위해 Git을 사용하고 있으며, AWS CodeCommit에 리포지토리를 호스팅하고 있습니다. 그들은 메인 브랜치에 대한 모든 커밋이 수동 개입 없이 자동으로 빌드 및 배포 프로세스를 트리거하도록 보장하고 싶어합니다.",
        "Question": "이 자동화를 달성하기 위해 팀이 구현해야 할 Git 기반 작업은 무엇입니까?",
        "Options": {
            "1": "로컬 리포지토리에서 Git 후크를 활성화하여 AWS CodeBuild 및 CodeDeploy를 트리거합니다.",
            "2": "AWS CodePipeline을 구성하여 AWS CodeCommit의 메인 브랜치를 소스 단계로 사용합니다.",
            "3": "메인 브랜치에 대한 각 커밋 후 AWS CodeBuild 프로젝트를 수동으로 시작합니다.",
            "4": "AWS Lambda를 사용하여 Git 리포지토리를 모니터링하고 새로운 커밋에 대한 배포를 트리거합니다."
        },
        "Correct Answer": "AWS CodePipeline을 구성하여 AWS CodeCommit의 메인 브랜치를 소스 단계로 사용합니다.",
        "Explanation": "AWS CodePipeline을 구성하여 AWS CodeCommit의 메인 브랜치를 소스 단계로 사용하면 새로운 커밋이 이루어질 때마다 빌드 및 배포 프로세스가 자동으로 트리거됩니다. 이는 수동 개입 없이 원하는 자동화를 제공합니다.",
        "Other Options": [
            "Git 후크를 활성화하면 일부 프로세스를 로컬에서 시작할 수 있지만, 클라우드에서 빌드 및 배포를 관리하는 신뢰할 수 있는 중앙 집중식 방법을 제공하지 않습니다. 후크는 로컬 리포지토리 설정에 의존하며 클라우드 서비스를 자동으로 트리거하지 않습니다.",
            "메인 브랜치에 대한 각 커밋 후 AWS CodeBuild 프로젝트를 수동으로 시작하는 것은 자동화의 목적을 무색하게 하며 지속적인 인간 개입이 필요하므로 팀이 피하고자 하는 것입니다.",
            "AWS Lambda를 사용하여 리포지토리를 모니터링하는 것은 빌드 및 배포를 트리거하는 가장 효율적인 방법이 아닙니다. 이 접근 방식은 CodePipeline을 직접 활용하여 원활한 자동화를 구현하는 것에 비해 불필요한 복잡성을 추가할 것입니다."
        ]
    },
    {
        "Question Number": "18",
        "Situation": "한 회사는 Amazon CloudFront를 통해 웹 애플리케이션을 사용자에게 효율적으로 제공하는 데 크게 의존하고 있습니다. 그러나 최근 사용자들은 HTTP 504 오류를 경험하고 있으며, 이는 게이트웨이 타임아웃을 나타내며, 웹사이트 로그인 과정에서 눈에 띄는 지연이 발생하고 있습니다. 이 상황은 애플리케이션의 가용성과 전반적인 사용자 경험에 대한 우려를 불러일으켰으며, 회사는 이러한 문제를 완화하고 사용자에게 더 원활한 접근을 보장하기 위한 해결책을 모색하고 있습니다.",
        "Question": "회사가 웹 애플리케이션의 가용성을 향상시키고 향후 이러한 HTTP 504 오류를 효과적으로 피하기 위해 구현할 수 있는 효과적인 조치는 무엇입니까?",
        "Options": {
            "1": "여러 파일에 접근하기 위해 서명된 쿠키를 활성화합니다.",
            "2": "AWS WAF를 사용하여 무단 트래픽을 차단합니다.",
            "3": "두 개의 오리진으로 오리진 그룹을 생성하여 오리진 장애 조치를 설정합니다.",
            "4": "CloudFront에서 동적 콘텐츠의 캐싱을 활성화합니다."
        },
        "Correct Answer": "두 개의 오리진으로 오리진 그룹을 생성하여 오리진 장애 조치를 설정합니다.",
        "Explanation": "두 개의 오리진으로 오리진 그룹을 생성하여 오리진 장애 조치를 설정하는 것은 가용성을 향상시키기 위한 선제적 접근 방식입니다. 하나의 오리진이 사용할 수 없게 될 경우, CloudFront는 자동으로 요청을 두 번째 오리진으로 라우팅하여 타임아웃으로 인한 HTTP 504 오류의 위험을 줄이고 보다 신뢰할 수 있는 사용자 경험을 보장합니다.",
        "Other Options": [
            "서명된 쿠키를 활성화하는 것은 주로 접근 제어에 초점을 맞추고 있으며, 가용성과는 관련이 없습니다. 콘텐츠를 보호하지만 HTTP 504 오류를 유발하는 근본적인 문제를 해결하지 않습니다.",
            "AWS WAF를 사용하여 무단 트래픽을 차단하는 것은 악의적인 공격으로부터 애플리케이션을 보호하는 보안 조치이지만, 가용성을 직접적으로 개선하거나 로그인 중 타임아웃 문제를 해결하지는 않습니다.",
            "CloudFront에서 동적 콘텐츠의 캐싱을 활성화하면 로드 시간을 줄여 성능을 향상시킬 수 있지만, 오리진 서버 자체에 문제가 발생하는 경우 HTTP 504 오류의 근본 원인을 효과적으로 해결하지 못할 수 있습니다."
        ]
    },
    {
        "Question Number": "19",
        "Situation": "팀이 Amazon ECS를 사용하여 컨테이너화된 애플리케이션을 배포하고 있습니다. 이를 통해 Docker 컨테이너를 대규모로 실행할 수 있습니다. 애플리케이션 코드는 Git 리포지토리에 저장되어 있으며, 팀은 개발 프로세스를 위한 강력한 자동화 전략을 구현하고자 합니다. 그들은 모든 새로운 코드 커밋이 자동 빌드, 철저한 테스트 및 개발, 스테이징, 프로덕션 등 다양한 환경에 원활하게 배포되도록 하는 지속적 통합 및 지속적 배포(CI/CD) 파이프라인을 설정하고 싶어합니다. 이 설정은 애플리케이션의 높은 품질과 빠른 전달을 유지하는 데 도움이 될 것입니다.",
        "Question": "컨테이너화된 애플리케이션에 대한 이 CI/CD 파이프라인 워크플로를 효과적으로 구현하기 위해 팀이 각 코드 커밋이 완전 자동화된 빌드, 테스트 및 배포 주기로 이어지도록 보장하기 위해 어떤 특정 AWS 서비스 순서를 활용해야 합니까?",
        "Options": {
            "1": "AWS CodePipeline, AWS CodeBuild, AWS CodeDeploy, 및 Amazon ECS",
            "2": "AWS CodeCommit, AWS Lambda, AWS CloudFormation, 및 Amazon ECS",
            "3": "AWS CodePipeline, AWS CodeBuild, AWS Lambda, 및 Amazon ECS",
            "4": "AWS CodeCommit, AWS CodeBuild, AWS Lambda, 및 AWS CodeDeploy"
        },
        "Correct Answer": "AWS CodePipeline, AWS CodeBuild, AWS CodeDeploy, 및 Amazon ECS",
        "Explanation": "컨테이너화된 애플리케이션을 위한 CI/CD 파이프라인을 구현하기 위한 올바른 AWS 서비스 순서는 AWS CodePipeline을 사용하여 워크플로를 조정하고, AWS CodeBuild를 사용하여 애플리케이션을 빌드하며, AWS CodeDeploy를 사용하여 애플리케이션을 Amazon ECS에 배포하고, 물론 Amazon ECS를 사용하여 컨테이너화된 애플리케이션을 실행하는 것입니다. 이 조합은 모든 코드 커밋이 자동으로 필요한 빌드, 테스트 및 배포 프로세스를 트리거하도록 보장합니다.",
        "Other Options": [
            "이 옵션은 AWS CodeCommit을 소스 제어로 포함하고 있지만, Amazon ECS에 애플리케이션을 배포하는 데 필수적인 적절한 배포 서비스인 AWS CodeDeploy가 부족하므로 잘못된 옵션입니다.",
            "이 옵션은 일반적으로 서버리스 애플리케이션에 사용되는 AWS Lambda를 포함하고 있어 잘못된 옵션입니다. 또한, 배포에 필수적인 AWS CodeDeploy를 사용하지 않습니다.",
            "이 옵션은 AWS CodeDeploy 대신 AWS Lambda를 포함하고 있어 잘못된 옵션입니다. Lambda는 컨테이너화된 애플리케이션을 배포하는 데 적합하지 않으며, 배포 프로세스를 효과적으로 관리하기 위해 AWS CodeDeploy와 같은 서비스가 필요합니다."
        ]
    },
    {
        "Question Number": "20",
        "Situation": "개발자가 Amazon S3와 작업하고 있으며 특정 버킷을 삭제할 수 있는 필요한 권한이 있는지 확인해야 합니다. 그러나 데이터 손실이나 중단을 방지하기 위해 삭제 명령을 실행하는 것을 피하고 싶어합니다. 이를 위해 개발자는 삭제 작업을 시뮬레이션하고 실제 삭제를 수행하지 않고 권한 문제를 확인할 수 있는 방법을 찾고 있습니다.",
        "Question": "개발자가 Amazon S3 버킷의 삭제를 시뮬레이션하고 삭제 작업을 실행하지 않고 권한을 확인하기 위해 어떤 특정 AWS CLI 옵션을 사용해야 합니까?",
        "Options": {
            "1": "--debug",
            "2": "--dry-run",
            "3": "--output",
            "4": "--no-paginate"
        },
        "Correct Answer": "--dry-run",
        "Explanation": "--dry-run 옵션은 AWS CLI 명령에서 실제 변경을 수행하지 않고 작업 실행을 시뮬레이션하는 데 사용됩니다. 이를 통해 개발자는 S3 버킷을 삭제할 수 있는 필요한 권한이 있는지 확인할 수 있습니다.",
        "Other Options": [
            "--debug는 요청 및 응답 주기에 대한 자세한 정보를 제공하는 플래그이지만, 작업을 시뮬레이션하거나 권한을 확인하지 않습니다.",
            "--output은 명령의 출력 형식을 지정하지만, 명령의 실행이나 권한에 영향을 미치지 않습니다.",
            "--no-paginate는 출력이 페이지 매김되지 않도록 방지하지만, 권한 확인이나 명령 실행 시뮬레이션과는 관련이 없습니다."
        ]
    },
    {
        "Question Number": "21",
        "Situation": "한 회사가 강력한 보안 조치를 요구하는 민감한 데이터를 처리하고 있습니다. 이를 달성하기 위해 AWS Key Management Service (KMS)를 사용하여 암호화를 수행하고 있습니다. 회사는 효율적이고 안전한 방식으로 대용량 파일을 암호화하는 것을 목표로 하고 있습니다. 그들의 접근 방식은 데이터 키를 사용하여 실제 데이터를 암호화하고, 데이터 키 자체는 마스터 키로 암호화하는 것입니다. 마스터 키는 민감한 정보의 무결성과 기밀성을 유지하기 위해 AWS KMS에 의해 안전하게 관리되고 통제되어야 합니다.",
        "Question": "회사가 민감한 데이터를 가장 잘 보호하기 위해 어떤 특정 암호화 기술과 키 관리 전략을 구현해야 하며, 효율성과 보안을 모두 보장할 수 있습니까?",
        "Options": {
            "1": "모든 작업에 KMS 키를 사용하는 대칭 암호화로, 암호화 및 복호화 프로세스 관리를 단순화합니다.",
            "2": "고객 관리 KMS 고객 마스터 키(CMK)를 활용한 봉투 암호화로, 데이터 키에 대한 추가 보안 계층을 제공합니다.",
            "3": "KMS 공개 및 개인 키를 사용하는 비대칭 암호화로, 일반적으로 더 작은 데이터 세트나 안전한 키 교환에 사용됩니다.",
            "4": "로컬에서 제어되는 마스터 키로 관리되는 일반 텍스트 암호화로, 중앙 집중식 관리 및 감독 부족으로 인해 상당한 위험을 초래합니다."
        },
        "Correct Answer": "고객 관리 KMS 고객 마스터 키(CMK)를 활용한 봉투 암호화로, 데이터 키에 대한 추가 보안 계층을 제공합니다.",
        "Explanation": "정답은 고객 관리 KMS 고객 마스터 키(CMK)를 사용하는 봉투 암호화입니다. 이 접근 방식은 회사가 실제 데이터 암호화를 위해 데이터 키를 먼저 사용하여 대용량 파일을 효율적으로 암호화할 수 있게 합니다. 데이터 키는 AWS KMS가 관리하는 마스터 키로 암호화되어 안전한 키 관리를 가능하게 하고, 처리되는 데이터의 기밀성을 보장합니다. 이 방법은 효율적인 암호화 및 복호화를 가능하게 하면서 마스터 키를 클라우드에서 안전하게 관리할 수 있도록 하여 확장 가능하고 안전합니다.",
        "Other Options": [
            "모든 작업에 KMS 키를 사용하는 대칭 암호화는 작업을 단순화하지만, 대용량 파일 관리를 위한 봉투 암호화가 제공하는 유연성과 추가 보안 계층을 제공하지 않으므로 최선의 선택이 아닙니다.",
            "KMS 공개 및 개인 키를 사용하는 비대칭 암호화는 일반적으로 복잡성과 성능 오버헤드로 인해 더 작은 데이터 세트나 안전한 키 교환에 더 적합하므로 대용량 파일 암호화에는 비효율적입니다.",
            "로컬에서 제어되는 마스터 키로 관리되는 일반 텍스트 암호화는 AWS KMS가 제공하는 중앙 집중식 관리 및 강력한 보안 통제가 부족하여 민감한 데이터를 상당한 위험에 노출시키므로 매우 안전하지 않습니다."
        ]
    },
    {
        "Question Number": "22",
        "Situation": "개발자가 사용자 프로필, 거래 데이터 및 제품 카탈로그를 저장하기 위한 데이터베이스가 필요한 새로운 애플리케이션을 설계하고 있습니다. 이 애플리케이션은 복잡한 쿼리를 지원하고 거래에 대한 ACID(원자성, 일관성, 격리성, 지속성) 속성을 유지해야 합니다.",
        "Question": "개발자가 이러한 요구 사항을 충족하기 위해 어떤 유형의 데이터베이스를 선택해야 합니까?",
        "Options": {
            "1": "Amazon DynamoDB (NoSQL)",
            "2": "Amazon Aurora (Relational)",
            "3": "Amazon Redshift (Data Warehouse)",
            "4": "Amazon ElastiCache (In-memory)"
        },
        "Correct Answer": "Amazon Aurora (Relational)",
        "Explanation": "Amazon Aurora는 ACID 속성을 지원하는 관계형 데이터베이스로, 복잡한 쿼리와 신뢰할 수 있는 거래 관리를 요구하는 애플리케이션에 적합합니다. 성능과 확장성을 위해 설계되었으며, 전통적인 관계형 데이터베이스의 강력함을 유지합니다.",
        "Other Options": [
            "Amazon DynamoDB는 여러 항목에 걸쳐 ACID 거래를 본질적으로 지원하지 않는 NoSQL 데이터베이스로, 거래 애플리케이션에 필수적입니다.",
            "Amazon Redshift는 거래 작업보다는 분석 쿼리에 최적화된 데이터 웨어하우스이며, ACID 속성을 지원하지 않습니다.",
            "Amazon ElastiCache는 데이터를 캐싱하여 애플리케이션의 성능을 향상시키기 위해 설계된 인메모리 캐싱 서비스이지만, ACID 준수를 갖춘 지속적인 데이터베이스를 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "23",
        "Situation": "개발자가 AWS CloudFormation을 사용하여 코드로 인프라를 관리하고 있습니다. 모듈성을 유지하고 값을 하드코딩하지 않기 위해 한 CloudFormation 스택에서 내보낸 값을 다른 스택에서 참조해야 합니다.",
        "Question": "개발자가 다른 스택에서 내보낸 값을 가져오기 위해 어떤 내장 함수를 사용해야 합니까?",
        "Options": {
            "1": "Fn::Join",
            "2": "Fn::GetAtt",
            "3": "Fn::ImportValue",
            "4": "Ref"
        },
        "Correct Answer": "Fn::ImportValue",
        "Explanation": "Fn::ImportValue 내장 함수는 CloudFormation 스택이 다른 스택에서 내보낸 값을 가져올 수 있도록 합니다. 이는 CloudFormation 템플릿에서 모듈성과 재사용성을 유지하는 데 필수적이며, 한 스택이 다른 스택의 출력을 원활하게 참조할 수 있게 합니다.",
        "Other Options": [
            "Fn::Join은 값을 단일 문자열로 연결하는 데 사용되지만, 다른 스택에서 값을 가져오는 데는 도움이 되지 않습니다.",
            "Fn::GetAtt는 동일한 스택의 리소스에서 속성 값을 검색하지만, 다른 스택에서 값을 가져오지는 않습니다.",
            "Ref는 동일한 스택 내에서 논리 ID로 리소스를 참조하는 데 사용되지만, 다른 스택에서 값을 가져오는 데는 사용할 수 없습니다."
        ]
    },
    {
        "Question Number": "24",
        "Situation": "미디어 회사가 프리미엄 콘텐츠를 무단 접근으로부터 보호하고, 유료 사용자만 이를 볼 수 있도록 조치를 취하고 있습니다.",
        "Question": "이 요구 사항에 가장 적합한 솔루션은 무엇입니까?",
        "Options": {
            "1": "사용자 인증을 위한 서명된 URL 사용",
            "2": "사용자 권한 부여를 위한 AWS WAF 사용",
            "3": "인증 및 권한 부여를 처리하기 위한 Lambda@Edge 사용",
            "4": "향상된 보안을 위한 AWS Shield Advanced 설정"
        },
        "Correct Answer": "사용자 인증을 위한 서명된 URL 사용",
        "Explanation": "서명된 URL은 프리미엄 콘텐츠에 대한 접근을 제어하는 강력한 솔루션입니다. 이를 통해 미디어 회사는 각 인증된 사용자에 대해 고유하고 시간 제한이 있는 URL을 생성할 수 있어, 유효한 자격 증명을 가진 사용자만 콘텐츠에 접근할 수 있도록 보장합니다. 이 방법은 비유료 사용자가 콘텐츠를 보기 위해 필요한 URL을 얻기 어렵게 만들어 무단 접근을 효과적으로 방지합니다.",
        "Other Options": [
            "AWS WAF는 일반적인 웹 공격으로부터 애플리케이션을 보호하는 데 주로 사용되지만, 사용자 인증을 특별히 제공하지 않아 유료 콘텐츠에 대한 무단 접근을 방지하는 데는 적합하지 않습니다.",
            "Lambda@Edge는 인증 및 권한 부여를 처리할 수 있지만, 아키텍처에 복잡성을 추가하며, 간단한 접근 제어 시나리오에서는 서명된 URL을 사용하는 것만큼 효율적이지 않을 수 있습니다.",
            "AWS Shield Advanced는 DDoS 공격으로부터 보호하기 위해 설계되었으며, 사용자 인증이나 권한 부여를 특별히 다루지 않으므로 무단 요청 필터링 요구 사항과는 관련이 없습니다."
        ]
    },
    {
        "Question Number": "25",
        "Situation": "한 회사가 AWS Lambda를 사용하여 클라우드 네이티브 애플리케이션을 설계하고 있습니다. 이 애플리케이션은 사용자 요청을 처리하고 트래픽 양에 따라 자동으로 확장됩니다. 개발 팀은 사용자 세션 관리를 위해 무상태(stateless) 또는 상태(stateful) 애플리케이션 모델을 사용할지 고민하고 있습니다.",
        "Question": "개발 팀이 AWS Lambda에 대해 무상태 애플리케이션 모델을 선호해야 하는 이유는 무엇입니까?",
        "Options": {
            "1": "무상태 애플리케이션은 자동으로 확장할 수 있으며 서버리스 환경에서 관리가 더 쉽습니다.",
            "2": "상태 애플리케이션은 성능이 더 좋으며 무상태 애플리케이션보다 초당 더 많은 요청을 처리할 수 있습니다.",
            "3": "무상태 애플리케이션은 AWS Lambda에 배포할 수 없습니다.",
            "4": "상태 애플리케이션은 상태가 Lambda 자체에 저장되므로 더 나은 보안으로 AWS Lambda에 배포할 수 있습니다."
        },
        "Correct Answer": "무상태 애플리케이션은 자동으로 확장할 수 있으며 서버리스 환경에서 관리가 더 쉽습니다.",
        "Explanation": "무상태 애플리케이션은 AWS Lambda와 같은 서버리스 아키텍처에 이상적입니다. 이는 애플리케이션이 들어오는 트래픽에 따라 원활하게 확장할 수 있도록 해줍니다. 각 요청은 독립적이므로 관리가 간소화되고 복잡한 세션 처리가 필요하지 않습니다. 이는 Lambda의 이벤트 기반 모델과 잘 맞아떨어지며, 함수는 이벤트에 의해 트리거되고 상태를 유지할 필요 없이 병렬로 실행될 수 있습니다.",
        "Other Options": [
            "상태 애플리케이션은 사용자 세션 관리 및 확장에서 복잡성을 초래할 수 있어 AWS Lambda와 같은 서버리스 환경에 덜 적합합니다.",
            "이 진술은 무상태 애플리케이션이 실제로 AWS Lambda에 배포될 수 있으므로 잘못되었습니다. 이는 서버리스 컴퓨팅의 기본 특성입니다.",
            "상태 애플리케이션은 AWS Lambda에 배포될 수 있지만, 일반적으로 상태 유지를 위해 외부 저장 솔루션이 필요하므로 보안 및 관리가 복잡해질 수 있습니다."
        ]
    },
    {
        "Question Number": "26",
        "Situation": "한 개발자가 Amazon DynamoDB를 활용하여 사용자 세션 데이터를 효율적으로 저장하는 강력한 웹 애플리케이션을 구축하고 있습니다. 이 애플리케이션은 다양한 트래픽 패턴을 가질 것으로 예상되며, 때때로 사용자 활동에서 상당한 급증을 경험합니다. 이러한 급증은 DynamoDB 테이블에서 읽기 및 쓰기 작업의 증가로 이어지며, 적절히 관리되지 않으면 시스템이 과부하될 수 있습니다. 성능을 유지하고 사용자가 이러한 고트래픽 기간 동안 원활한 경험을 할 수 있도록 하기 위해, 개발자는 수동 개입 없이 변화하는 수요에 자동으로 조정할 수 있는 솔루션을 찾고 있습니다.",
        "Question": "예측할 수 없는 트래픽 급증을 효과적으로 처리하고 웹 애플리케이션의 최적 성능을 유지하기 위해, 개발자가 애플리케이션이 자동으로 확장할 수 있도록 구현해야 하는 Amazon DynamoDB의 특정 기능은 무엇입니까?",
        "Options": {
            "1": "DynamoDB Accelerator (DAX)",
            "2": "DynamoDB Streams",
            "3": "DynamoDB 테이블의 자동 확장",
            "4": "예약 용량을 가진 프로비저닝 처리량"
        },
        "Correct Answer": "DynamoDB 테이블의 자동 확장",
        "Explanation": "DynamoDB 테이블의 자동 확장은 실제 트래픽 패턴에 따라 DynamoDB 테이블의 프로비저닝 처리량 용량을 자동으로 조정하도록 설계되었습니다. 이 기능은 수동 개입 없이 읽기 및 쓰기 요청의 급증을 처리할 수 있게 하여 성능이 일관되게 유지되고 사용자가 고트래픽 기간 동안 지연을 경험하지 않도록 보장합니다.",
        "Other Options": [
            "DynamoDB Accelerator (DAX)는 읽기 작업을 가속화하는 캐싱 서비스이지만, 트래픽 급증 동안 용량을 자동으로 조정하지 않으므로 개발자의 요구에 덜 적합합니다.",
            "DynamoDB Streams는 DynamoDB 테이블의 항목 변경 사항을 캡처하여 실시간 처리를 가능하게 하는 기능이지만, 트래픽 급증 동안 읽기 및 쓰기 용량의 자동 확장 문제를 해결하지 않습니다.",
            "예약 용량을 가진 프로비저닝 처리량은 고정된 읽기 및 쓰기 용량을 설정할 수 있지만, 수요에 따라 자동으로 조정되지 않기 때문에 트래픽 급증 동안 제한이 발생할 수 있습니다."
        ]
    },
    {
        "Question Number": "27",
        "Situation": "한 회사가 Amazon S3 버킷에 민감한 데이터를 안전하게 저장하는 중요한 과제에 직면해 있습니다. 이 데이터의 특성상, 버킷 내의 모든 객체는 저장 중에 암호화되어야 합니다. 또한, 회사는 이 데이터를 보호하는 데 사용되는 암호화 키에 대한 완전한 제어를 유지하고, 이러한 키에 대한 접근을 효과적으로 감사하고 모니터링할 수 있어야 합니다. 키 제어와 감사라는 이중 요구 사항은 가장 적절한 암호화 옵션을 선택하는 데 상당한 도전을 제공합니다.",
        "Question": "암호화 키에 대한 제어를 유지하고 이러한 키에 대한 접근을 효과적으로 감사하기 위한 회사의 엄격한 요구 사항을 고려할 때, 이러한 요구 사항을 충족하기 위해 회사가 선택해야 하는 암호화 옵션은 무엇입니까?",
        "Options": {
            "1": "Amazon S3-Managed Keys (SSE-S3), 자동으로 암호화 및 복호화 프로세스를 처리하지만 고객이 사용하는 암호화 키에 대한 제어를 제공하지 않습니다.",
            "2": "고객 제공 키를 사용하는 서버 측 암호화 (SSE-C), 회사가 자체 암호화 키를 제공할 수 있지만 키 접근 추적을 위한 강력한 감사 기능이 부족합니다.",
            "3": "AWS KMS 키를 사용하는 서버 측 암호화 (SSE-KMS), 암호화 키에 대한 향상된 제어를 제공하며 키 접근을 효과적으로 모니터링하기 위한 내장 감사 기능을 포함합니다.",
            "4": "AWS Encryption SDK를 사용하는 클라이언트 측 암호화, 회사가 데이터를 S3에 전송하기 전에 암호화하여 키에 대한 완전한 제어를 부여하지만 암호화 프로세스의 추가 관리가 필요합니다."
        },
        "Correct Answer": "AWS KMS 키를 사용하는 서버 측 암호화 (SSE-KMS), 암호화 키에 대한 향상된 제어를 제공하며 키 접근을 효과적으로 모니터링하기 위한 내장 감사 기능을 포함합니다.",
        "Explanation": "정답은 AWS KMS 키를 사용하는 서버 측 암호화 (SSE-KMS)입니다. 이는 회사가 암호화 키에 대한 완전한 제어를 유지하면서 중요한 감사 기능을 제공하기 때문입니다. SSE-KMS는 Amazon S3와 원활하게 통합되며 키 사용에 대한 세부 추적을 가능하게 하여 규정 준수 및 보안 목적에 필수적입니다.",
        "Other Options": [
            "Amazon S3-Managed Keys (SSE-S3)는 고객이 암호화 키를 제어할 수 없도록 합니다. 키 관리를 자동으로 처리하여 암호화 프로세스를 간소화하지만, 회사의 키 제어 및 감사 요구 사항을 충족하지 않습니다.",
            "고객 제공 키를 사용하는 서버 측 암호화 (SSE-C)는 회사가 자체 키를 제공할 수 있도록 하여 암호화에 대한 제어를 부여합니다. 그러나 키 접근 추적을 위한 필요한 감사 기능이 부족하여 중요한 요구 사항 중 하나를 충족하지 못합니다.",
            "AWS Encryption SDK를 사용하는 클라이언트 측 암호화는 회사가 S3에 업로드하기 전에 데이터를 암호화하여 암호화 키에 대한 완전한 제어를 제공합니다. 그러나 이 방법은 암호화 프로세스에 대한 추가 관리와 감독이 필요하므로 규정 준수 및 감사 요구 사항을 복잡하게 만들 수 있습니다."
        ]
    },
    {
        "Question Number": "28",
        "Situation": "개발자가 AWS SAM을 사용하여 새로운 서버리스 애플리케이션을 구축하고자 합니다. 개발자는 템플릿 파일과 구성 파일을 포함한 기본 프로젝트 구조를 생성해야 합니다.",
        "Question": "개발자가 가장 먼저 실행해야 할 AWS SAM 명령어는 무엇인가요?",
        "Options": {
            "1": "sam build",
            "2": "sam deploy",
            "3": "sam init",
            "4": "sam transform"
        },
        "Correct Answer": "sam init",
        "Explanation": "'sam init' 명령어는 새로운 AWS SAM 프로젝트를 생성하는 데 사용됩니다. 이 명령어는 서버리스 애플리케이션 개발에 필요한 템플릿 파일과 구성 파일을 생성하여 기본 프로젝트 구조를 설정합니다.",
        "Other Options": [
            "'sam build'는 프로젝트의 코드와 종속성을 컴파일하는 데 사용되지만, 프로젝트 구조가 생성된 후에 실행해야 합니다.",
            "'sam deploy'는 애플리케이션을 AWS에 배포하는 데 사용되며, 프로젝트가 초기화되고 빌드된 후에 사용할 수 있습니다.",
            "'sam transform'은 AWS CloudFormation 템플릿을 변환하는 데 사용되며, 새로운 SAM 프로젝트를 설정하는 첫 번째 단계가 아닙니다."
        ]
    },
    {
        "Question Number": "29",
        "Situation": "개발자는 Amazon S3 버킷에 업로드되는 모든 객체가 저장 시 암호화되도록 보장하는 임무를 맡고 있습니다. 버킷은 서버 측 암호화를 사용하지 않는 업로드를 거부해야 하며, 데이터 보안 정책을 준수해야 합니다.",
        "Question": "이 요구 사항을 효과적으로 시행하기 위해 개발자가 구현해야 할 솔루션은 무엇인가요?",
        "Options": {
            "1": "S3 기본 암호화를 활성화하고 모든 업로드에 대해 x-amz-server-side-encryption 매개변수가 포함된 업로드 요청 헤더를 보장합니다.",
            "2": "버킷에 업로드되는 모든 객체에 대해 암호화를 의무화하는 S3 수명 주기 정책을 활용하여 기존 및 새로운 객체에 규칙을 적용합니다.",
            "3": "x-amz-server-side-encryption 헤더가 누락되었거나 AES256으로 설정되지 않은 업로드 시도를 명시적으로 거부하는 버킷 정책을 구현합니다.",
            "4": "AWS Key Management Service (KMS)를 구성하여 S3 버킷에 파일이 업로드된 후 자동으로 암호화되도록 하여 업로드 후 암호화가 적용되도록 합니다."
        },
        "Correct Answer": "x-amz-server-side-encryption 헤더가 누락되었거나 AES256으로 설정되지 않은 업로드 시도를 명시적으로 거부하는 버킷 정책을 구현합니다.",
        "Explanation": "정답은 옵션 3입니다. 암호화 기준을 충족하지 않는 업로드를 거부하는 버킷 정책을 설정하면 버킷에 암호화된 객체만 저장되도록 보장할 수 있습니다. 이 정책은 비준수 업로드를 직접 거부하여 보안 기준을 유지하는 강력한 시행 메커니즘으로 작용합니다.",
        "Other Options": [
            "옵션 1은 S3 기본 암호화를 활성화하면 모든 새로운 객체가 자동으로 암호화되지만, 요청에서 서버 측 암호화를 지정하지 않은 업로드를 거부하지 않기 때문에 잘못된 것입니다.",
            "옵션 2는 수명 주기 정책이 객체의 저장 클래스를 시간에 따라 관리하는 데 주로 사용되며, 업로드 시 암호화를 직접 시행하지 않기 때문에 잘못된 것입니다. 이들은 처음에 암호화되지 않은 객체의 업로드를 방지할 수 없습니다.",
            "옵션 4는 AWS KMS를 사용하여 업로드 후 파일을 암호화하는 것이며, 암호화되지 않은 업로드를 거부하는 요구 사항을 충족하지 않기 때문에 잘못된 것입니다. 이 접근 방식은 단순히 업로드 후 암호화를 추가할 뿐이며, 업로드 시 즉각적인 암호화 시행의 필요성과 일치하지 않습니다."
        ]
    },
    {
        "Question Number": "30",
        "Situation": "개발자는 AWS Lambda 함수와 Amazon API Gateway를 함께 활용하는 서버리스 애플리케이션을 구축하는 과정에 있습니다. 이 애플리케이션은 Lambda 함수가 요청을 처리하기 전에 들어오는 요청에 대해 복잡한 데이터 변환을 수행해야 하는 특정 요구 사항이 있습니다. 효율성을 최적화하기 위해 개발자는 처리 시간을 최소화하고 Lambda 함수의 작업 부담을 줄여 사용자 요청을 보다 효과적으로 처리할 수 있도록 하고자 합니다.",
        "Question": "개발자가 Lambda 함수로 요청이 전달되기 전에 필요한 데이터 변환을 효율적으로 관리하기 위해 API Gateway에서 구현해야 할 특정 기능은 무엇인가요?",
        "Options": {
            "1": "Custom Authorizers",
            "2": "Mapping Templates",
            "3": "API Keys",
            "4": "Usage Plans"
        },
        "Correct Answer": "Mapping Templates",
        "Explanation": "Mapping Templates는 들어오는 요청 데이터를 AWS Lambda 함수와 같은 백엔드 서비스가 쉽게 처리할 수 있는 형식으로 변환하도록 특별히 설계되었습니다. Mapping Templates를 사용함으로써 개발자는 Lambda에 도달하기 전에 들어오는 데이터를 효율적으로 조작하고 형식을 지정하여 처리 시간을 줄이고 함수의 부담을 최소화할 수 있습니다.",
        "Other Options": [
            "Custom Authorizers는 들어오는 요청을 검증하여 API에 대한 접근을 제어하는 데 사용되지만, 데이터 변환을 수행하지 않습니다.",
            "API Keys는 API의 접근 및 사용을 관리하는 데 사용되지만, 요청 데이터를 변환하는 기능은 없습니다.",
            "Usage Plans는 개발자가 API 사용을 제어하고 속도 제한을 적용할 수 있도록 하지만, 데이터 변환 기능은 포함되어 있지 않습니다."
        ]
    },
    {
        "Question Number": "31",
        "Situation": "금융 기관은 하드웨어 보안 모듈(HSM)에서 암호화 키를 안전하게 저장하고 관리해야 합니다. 이 솔루션은 FIPS 140-2 표준을 준수해야 하며, Java 애플리케이션과 통합되고 VPC 내에서 고성능 암호화 가속을 제공해야 합니다.",
        "Question": "기관이 높은 수준의 보안과 성능을 보장하면서 암호화 키 관리 요구 사항을 충족하기 위해 어떤 AWS 서비스를 활용해야 합니까?",
        "Options": {
            "1": "AWS Key Management Service (KMS)는 애플리케이션의 암호화 키 관리를 간소화하는 완전 관리형 서비스입니다.",
            "2": "AWS Secrets Manager는 비밀을 관리하고 검색하는 데 도움을 주지만, 여기서 필요한 고급 하드웨어 보안 모듈 기능을 제공하지 않습니다.",
            "3": "AWS CloudHSM은 FIPS 140-2 준수 요구 사항을 충족하면서 암호화 키를 관리할 수 있는 전용 하드웨어 보안 모듈을 제공합니다.",
            "4": "AWS Certificate Manager는 SSL/TLS 인증서를 관리하기 위해 설계되었으며, 암호화 키 관리 또는 HSM 기능에 중점을 두지 않습니다."
        },
        "Correct Answer": "AWS CloudHSM은 FIPS 140-2 준수 요구 사항을 충족하면서 암호화 키를 관리할 수 있는 전용 하드웨어 보안 모듈을 제공합니다.",
        "Explanation": "AWS CloudHSM은 FIPS 140-2 표준을 준수하면서 고성능 암호화 작업 및 키 관리를 위해 특별히 설계되었습니다. 이는 금융 기관이 VPC 내에서 암호화 키를 안전하게 저장하고 관리하는 데 이상적인 선택입니다.",
        "Other Options": [
            "AWS Key Management Service (KMS)는 암호화 키 관리를 위한 강력한 서비스이지만, 기관의 준수 요구 사항에 의해 요구되는 전용 하드웨어 보안 모듈 기능을 제공하지 않습니다.",
            "AWS Secrets Manager는 비밀번호 및 API 키와 같은 민감한 정보를 관리하는 데 유용한 서비스이지만, FIPS 140-2 준수를 위한 강력한 암호화 키 관리에 필요한 하드웨어 보안 모듈 기능이 부족합니다.",
            "AWS Certificate Manager는 SSL/TLS 인증서 관리를 중심으로 하며, 이 맥락에서 암호화 키 관리와 관련이 없으므로 기관의 특정 요구 사항에 적합하지 않습니다."
        ]
    },
    {
        "Question Number": "32",
        "Situation": "개발자는 Amazon Elastic Container Service (ECS)와 Fargate 시작 유형을 사용하여 컨테이너화된 애플리케이션을 배포하는 과정에 있습니다. 이 애플리케이션은 데이터베이스 자격 증명 및 API 키와 같은 다양한 비밀에 대한 안전한 접근이 필요하므로, 무단 접근을 방지하기 위해 안전하게 저장하고 관리해야 합니다. 개발자는 이러한 비밀을 효과적으로 관리하고 ECS 환경과 원활하게 통합할 수 있는 적절한 AWS 서비스를 선택해야 합니다.",
        "Question": "개발자가 ECS와 통합하여 이러한 비밀을 안전하게 관리하고 컨테이너에 제공하기 위해 어떤 AWS 서비스를 사용해야 하며, 민감한 정보가 기밀로 유지되고 애플리케이션이 실행 중에 쉽게 접근할 수 있도록 해야 합니까?",
        "Options": {
            "1": "AWS Secrets Manager",
            "2": "Amazon S3",
            "3": "Amazon DynamoDB",
            "4": "AWS Systems Manager Parameter Store"
        },
        "Correct Answer": "AWS Secrets Manager",
        "Explanation": "AWS Secrets Manager는 API 키, 데이터베이스 자격 증명 및 기타 민감한 정보를 관리하기 위해 특별히 설계되었습니다. 안전한 저장을 허용할 뿐만 아니라 비밀의 자동 회전 기능을 제공하여 보안 및 준수를 강화합니다. Secrets Manager를 Amazon ECS와 통합하면 비밀이 애플리케이션 코드에 하드코딩되지 않고 실행 중에 컨테이너에 안전하게 전달됩니다.",
        "Other Options": [
            "Amazon S3는 주로 저장 서비스이며 비밀을 저장할 수 있지만, AWS Secrets Manager가 제공하는 자동 회전 및 세분화된 접근 제어와 같은 비밀 관리에 필요한 전문 기능을 제공하지 않습니다.",
            "Amazon DynamoDB는 데이터를 저장하는 데 사용할 수 있는 NoSQL 데이터베이스 서비스이지만, 비밀을 안전하게 관리하기 위한 전용 기능이 부족합니다. 민감한 정보 관리를 위해 설계되지 않았으며 자동 회전과 같은 기능을 제공하지 않습니다.",
            "AWS Systems Manager Parameter Store는 구성 데이터와 비밀을 저장할 수 있지만, AWS Secrets Manager는 비밀 회전 및 통합 감사 기능과 같은 고급 기능으로 인해 비밀 관리에 일반적으로 선호됩니다. 따라서 더 적합한 선택입니다."
        ]
    },
    {
        "Question Number": "33",
        "Situation": "기술 회사는 Amazon Kinesis Data Streams를 활용하여 웹사이트에서 사용자가 생성한 실시간 클릭스트림 데이터를 처리하고 분석하고 있습니다. 이 스트림은 다양한 데이터 부하를 수용하고 효율적인 처리를 보장하기 위해 10개의 샤드로 구성되어 있습니다. 각 샤드는 한 번에 하나의 작업자에 의해 처리될 수 있으므로 데이터 처리 아키텍처의 확장성에 대한 중요한 질문이 제기됩니다.",
        "Question": "Kinesis Data Streams는 여러 소비자가 데이터를 처리할 수 있도록 설계되었음을 고려할 때, 10개의 샤드가 있는 이 스트림의 데이터를 효과적으로 처리할 수 있는 Kinesis Client Library (KCL) 작업자의 최대 수는 얼마입니까?",
        "Options": {
            "1": "5",
            "2": "10",
            "3": "20",
            "4": "무제한"
        },
        "Correct Answer": "10",
        "Explanation": "Kinesis 스트림에서 데이터를 처리할 수 있는 KCL 작업자의 최대 수는 샤드 수에 직접적으로 연결되어 있습니다. 각 샤드는 한 번에 하나의 KCL 작업자에 의해만 처리될 수 있으므로, 10개의 샤드가 있을 경우 동시에 작동할 수 있는 KCL 작업자의 최대 수는 10입니다. 이는 각 샤드가 겹치지 않고 동시에 읽힐 수 있도록 보장합니다.",
        "Other Options": [
            "이 옵션은 잘못되었습니다. KCL 작업자가 5명만 있으면 모든 샤드가 활용되지 않아 데이터 처리 성능이 저하될 수 있습니다.",
            "이 옵션은 잘못되었습니다. KCL 작업자가 20명이라면 사용 가능한 샤드 수를 초과하게 됩니다. 각 샤드는 하나의 작업자만 처리할 수 있으므로 추가 작업자는 유휴 상태로 남게 됩니다.",
            "이 옵션은 잘못되었습니다. 작업자 수가 무제한이라고 말하는 것은 샤드 수에 의해 부과된 아키텍처 제약과 일치하지 않습니다. 각 샤드는 한 번에 하나의 작업자에 의해서만 처리될 수 있습니다."
        ]
    },
    {
        "Question Number": "34",
        "Situation": "개발 팀이 Amazon API Gateway를 사용하여 API의 여러 단계(개발, 스테이징, 프로덕션)를 관리하고 있습니다. 팀은 새로운 버전이 완전히 테스트될 때까지 프로덕션 트래픽에 영향을 주지 않고 API 업데이트를 배포하고자 합니다.",
        "Question": "팀이 이러한 배포 단계를 효과적으로 관리하기 위해 사용해야 할 API Gateway의 기능은 무엇입니까?",
        "Options": {
            "1": "API Gateway Stages",
            "2": "API Gateway Deployments",
            "3": "API Gateway Integrations",
            "4": "API Gateway Custom Domains"
        },
        "Correct Answer": "API Gateway Stages",
        "Explanation": "API Gateway Stages는 팀이 API의 다양한 버전을 구조적으로 관리할 수 있도록 합니다. 단계를 사용함으로써 팀은 프로덕션 트래픽에 영향을 주지 않고 별도의 환경에서 API의 새로운 버전을 테스트할 수 있습니다. 이는 서비스 가용성을 유지하면서 새로운 업데이트가 라이브로 전환되기 전에 완전히 테스트되도록 하는 데 필수적입니다.",
        "Other Options": [
            "API Gateway Deployments는 API 구성을 단계에 배포하는 프로세스를 의미하지만, API 트래픽의 여러 버전을 직접 관리할 수 있는 방법을 제공하지 않습니다.",
            "API Gateway Integrations는 API를 백엔드 서비스에 연결하는 데 중점을 두지만, 다양한 배포 단계를 관리하는 데는 역할을 하지 않습니다.",
            "API Gateway Custom Domains는 API에 대한 사용자 지정 도메인 이름을 구성하는 데 사용되지만, 다양한 배포 단계를 관리하는 데 도움을 주지 않습니다."
        ]
    },
    {
        "Question Number": "35",
        "Situation": "개발자가 API Gateway 엔드포인트의 캐싱을 구성하여 성능을 개선하고 있습니다. 팀은 데이터 변경 시 캐시 무효화를 위한 강력한 메커니즘이 필요하며, 권한이 있는 사용자만 안전하게 캐시된 데이터에 접근할 수 있도록 해야 합니다.",
        "Question": "개발자가 이러한 요구 사항을 충족하기 위해 어떤 조치를 취해야 합니까?",
        "Options": {
            "1": "API Gateway 캐시 암호화를 활성화하고 Cache-Control 헤더를 max-age=0으로 설정하여 데이터 변경 시 즉각적인 캐시 무효화를 보장합니다.",
            "2": "단계 변수를 활용하여 캐시 무효화를 촉진하고 사용자 지정 권한 부여 Lambda 함수를 구현하여 권한이 있는 접근만 보장합니다.",
            "3": "IAM 정책 내에서 execute-api:InvalidateCache 작업을 사용하여 권한을 부여하고 캐시 제어를 위해 Cache-Control 헤더를 max-age=0으로 구성합니다.",
            "4": "HTTP 프록시 통합을 활성화하고 특정 HTTP 헤더를 활용하여 캐시 동작을 동적으로 관리하여 캐시 무효화를 설정합니다."
        },
        "Correct Answer": "단계 변수를 활용하여 캐시 무효화를 촉진하고 사용자 지정 권한 부여 Lambda 함수를 구현하여 권한이 있는 접근만 보장합니다.",
        "Explanation": "단계 변수를 사용하면 개발자가 캐시 설정을 동적으로 관리하고 필요할 때 캐시를 무효화할 수 있습니다. 사용자 지정 권한 부여 Lambda 함수를 구현하면 올바른 권한을 가진 사용자만 캐시된 데이터에 접근할 수 있도록 하여 보안 요구 사항을 효과적으로 해결합니다.",
        "Other Options": [
            "API Gateway 캐시 암호화를 활성화하고 Cache-Control 헤더를 max-age=0으로 설정하는 것은 데이터 변경에 따른 신뢰할 수 있는 캐시 무효화 방법을 제공하지 않으며, 캐시에 접근하는 사용자 권한을 보장하지도 않습니다.",
            "IAM 정책 내에서 execute-api:InvalidateCache 작업으로 권한을 부여하는 것은 중요한 단계이지만, 캐시 무효화 메커니즘이나 사용자 권한 관리를 효과적으로 제공하지 않습니다.",
            "HTTP 프록시 통합을 활성화하고 HTTP 헤더를 사용하여 캐시 무효화를 설정하는 것은 캐시에 대한 접근을 적절히 제어하지 못할 수 있으며, 데이터 변경에 따른 캐시 무효화를 보장하는 강력한 메커니즘이 부족합니다."
        ]
    },
    {
        "Question Number": "36",
        "Situation": "개발자가 AWS Lambda를 사용하여 서버리스 애플리케이션을 작업하고 있으며, 들어오는 요청을 효율적으로 처리하기 위해 필요한 동시성을 계산해야 합니다. 애플리케이션은 초당 200개의 요청을 지속적으로 수신하며, 각 요청은 4초 동안 처리됩니다.",
        "Question": "지연 없이 들어오는 요청을 처리하기 위해 필요한 총 동시 Lambda 실행 수는 얼마입니까?",
        "Options": {
            "1": "효율적으로 요청을 처리하기 위해 200개의 동시 실행이 필요합니다.",
            "2": "400개의 동시 실행이 요청 처리에 여유를 제공합니다.",
            "3": "800개의 동시 실행이 요청이 처리되지 않고 남지 않도록 보장합니다.",
            "4": "1000개의 동시 실행이 최대 부하에 충분한 용량을 제공합니다."
        },
        "Correct Answer": "800개의 동시 실행이 요청이 처리되지 않고 남지 않도록 보장합니다.",
        "Explanation": "필요한 동시성을 찾기 위해 다음 공식을 사용할 수 있습니다: 필요한 동시성 = (초당 요청 수) * (초 단위 실행 시간). 이 경우, 200 요청/초 * 4초 = 800개의 동시 실행이 필요하여 모든 요청을 지연 없이 처리할 수 있습니다.",
        "Other Options": [
            "200개의 동시 실행은 각 요청이 즉시 완료될 경우에만 충분하며, 여기서는 각 요청이 4초가 걸리므로 해당되지 않습니다.",
            "400개의 동시 실행은 각 요청이 소요되는 총 시간을 고려하지 않기 때문에 병목 현상을 초래하여 추가 요청 처리에 지연을 발생시킵니다.",
            "1000개의 동시 실행은 필요 이상으로 많은 용량을 제공하여 비효율적인 자원 사용과 비용 증가를 초래할 수 있으며, 요청 처리 개선에는 도움이 되지 않습니다."
        ]
    },
    {
        "Question Number": "37",
        "Situation": "한 회사가 하드웨어 장애가 발생하더라도 운영이 지속될 수 있는 애플리케이션 아키텍처를 설계하고 있습니다. 그러나 비용을 최소화하고 싶어합니다.",
        "Question": "고가용성과 내결함성의 차이는 무엇이며, 운영 지속성의 필요성을 고려할 때 회사는 무엇을 우선시해야 합니까?",
        "Options": {
            "1": "고가용성은 서비스가 최소한의 다운타임으로 접근 가능하도록 보장하는 반면, 내결함성은 시스템이 중단 없이 계속 작동하도록 보장합니다. 회사는 완전한 신뢰성을 위해 내결함성을 우선시해야 합니다.",
            "2": "고가용성은 서비스 중단을 최소화하고 빠른 복구를 보장하는 반면, 내결함성은 실패에도 불구하고 시스템이 지속적으로 작동할 수 있도록 합니다. 회사는 사용자 만족을 위해 고가용성을 달성하는 데 집중해야 합니다.",
            "3": "고가용성은 실패에서 신속하게 복구할 수 있는 자동화된 시스템을 포함하는 반면, 내결함성은 서비스에 영향을 주지 않고 운영을 유지하는 것입니다. 회사는 비용 고려 사항으로 인해 고가용성을 목표로 해야 합니다.",
            "4": "고가용성과 내결함성은 종종 혼동되지만 동일하지 않습니다; 고가용성은 다운타임을 최소화하는 데 중점을 두고 내결함성은 원활한 운영에 중점을 둡니다. 회사는 회복력을 보장하기 위해 두 가지 모두를 추구해야 합니다."
        },
        "Correct Answer": "고가용성은 서비스가 최소한의 다운타임으로 접근 가능하도록 보장하는 반면, 내결함성은 시스템이 중단 없이 계속 작동하도록 보장합니다. 회사는 완전한 신뢰성을 위해 내결함성을 우선시해야 합니다.",
        "Explanation": "정답은 고가용성과 내결함성의 차이를 강조합니다. 고가용성은 서비스를 접근 가능하게 하기 위해 다운타임을 줄이는 것이고, 내결함성은 서비스 중단이 없도록 보장하는 것입니다. 하드웨어 장애 동안 지속적인 운영이 필요한 회사의 요구를 고려할 때, 내결함성을 우선시하는 것이 완전한 신뢰성을 위해 필수적입니다.",
        "Other Options": [
            "이 옵션은 내결함성이 완전한 신뢰성을 보장한다고 잘못 설명하고 있으며, 이는 사실이지만 고가용성의 목적을 다운타임이 없도록 보장하는 것으로 잘못 표현하고 있습니다. 고가용성은 최소한의 다운타임을 허용하며, 다운타임이 전혀 없는 것은 아닙니다.",
            "이 옵션은 고가용성이 더 큰 우선사항이라고 제안하여 두 개념을 혼동하고 있으며, 이는 하드웨어 장애 동안 운영 지속성에 대한 회사의 특정 요구와 일치하지 않을 수 있습니다. 내결함성이 그들의 상황에 더 적합합니다.",
            "이 옵션은 고가용성을 단순히 자동화된 시스템을 포함하는 것으로 부정확하게 설명하고 있으며, 다운타임을 줄이는 것과 관련된 고가용성의 본질을 포착하지 못하고 있습니다. 비용 고려 사항에 대한 초점은 이 시나리오에서 내결함성의 중요성을 감소시킵니다."
        ]
    },
    {
        "Question Number": "38",
        "Situation": "개발자가 민감한 데이터베이스 자격 증명에 접근해야 하는 AWS Serverless Application Model (SAM) 애플리케이션을 구성하고 있습니다. 이러한 자격 증명은 애플리케이션의 기능에 필수적이며 배포 과정에서 안전하게 검색되어야 합니다. 개발자는 보안 취약점을 방지하기 위해 이러한 민감한 세부 정보를 애플리케이션 코드에 하드코딩하지 않도록 해야 합니다. 문제는 코드베이스에 노출되지 않으면서 이 구성 데이터에 안전하게 접근할 수 있는 적절한 AWS 서비스를 선택하는 것입니다.",
        "Question": "개발자가 배포 중 애플리케이션의 구성 데이터, 특히 민감한 데이터베이스 자격 증명에 안전하게 접근하기 위해 어떤 AWS 서비스를 사용해야 합니까?",
        "Options": {
            "1": "AWS AppConfig",
            "2": "AWS Systems Manager Parameter Store with SecureString",
            "3": "Amazon S3 with server-side encryption",
            "4": "AWS Identity and Access Management (IAM) Roles"
        },
        "Correct Answer": "AWS Systems Manager Parameter Store with SecureString",
        "Explanation": "AWS Systems Manager Parameter Store with SecureString은 데이터베이스 자격 증명과 같은 민감한 구성 데이터를 안전하게 저장하고 접근하기 위한 이상적인 서비스입니다. 이를 통해 개발자는 애플리케이션에 하드코딩하지 않고도 런타임에 이러한 자격 증명을 검색할 수 있어, 민감한 정보를 처리하는 모범 사례를 준수하며 안전하게 유지할 수 있습니다.",
        "Other Options": [
            "AWS AppConfig는 애플리케이션 구성 및 기능 플래그 관리를 위해 주로 사용되지만, 민감한 데이터에 대해 Parameter Store와 같은 수준의 보안을 제공하지 않습니다.",
            "Amazon S3 with server-side encryption은 데이터를 안전하게 저장하기 위해 설계되었지만, 애플리케이션 배포 중 민감한 구성 데이터를 안전하게 검색하는 직접적인 방법을 제공하지 않습니다.",
            "AWS Identity and Access Management (IAM) Roles는 AWS 리소스에 대한 권한 및 접근 제어를 관리하는 데 사용되지만, 데이터베이스 자격 증명과 같은 민감한 구성 데이터를 저장하거나 검색하지 않습니다."
        ]
    },
    {
        "Question Number": "39",
        "Situation": "한 회사는 저장 비용을 최소화하기 위해 Amazon S3에 자주 접근하지 않는 대량의 데이터를 저장하고 있습니다. 이 데이터는 규정 준수를 위해 필요할 경우 몇 시간 이내에 검색 가능해야 합니다.",
        "Question": "회사가 이러한 요구 사항을 가장 비용 효율적으로 충족하기 위해 어떤 S3 저장 클래스와 라이프사이클 관리 정책을 사용해야 합니까?",
        "Options": {
            "1": "S3 Standard 저장 클래스와 라이프사이클 정책 없음, 고접근 데이터 검색에 이상적입니다.",
            "2": "S3 Standard-Infrequent Access (S3 Standard-IA)와 30일 후 객체 전환을 위한 라이프사이클 정책, 비용과 접근 속도의 균형을 맞춥니다.",
            "3": "S3 Glacier Deep Archive와 90일 후 객체 전환을 위한 라이프사이클 정책, 장기 아카이빙 요구에 적합합니다.",
            "4": "S3 Intelligent-Tiering과 자동 비용 최적화, 접근 패턴에 따라 동적으로 저장소를 조정합니다."
        },
        "Correct Answer": "S3 Standard-Infrequent Access (S3 Standard-IA)와 30일 후 객체 전환을 위한 라이프사이클 정책, 비용과 접근 속도의 균형을 맞춥니다.",
        "Explanation": "S3 Standard-IA 저장 클래스는 자주 접근하지 않는 데이터를 위해 설계되어, 낮은 저장 비용을 제공하면서 몇 시간 이내에 검색할 수 있도록 합니다. 30일 후 객체를 전환하는 라이프사이클 정책을 구현함으로써, 회사는 비용을 효율적으로 관리하면서 데이터 접근이 필요할 때 규정 준수 요구 사항을 충족할 수 있습니다.",
        "Other Options": [
            "S3 Standard 저장 클래스는 자주 접근하는 데이터를 위해 설계되었기 때문에 자주 접근하지 않는 데이터에 대해 비용 효율적이지 않으며, 회사의 요구를 충족하지 못하고 더 높은 저장 비용을 초래합니다.",
            "S3 Glacier Deep Archive는 장기 아카이빙 저장을 위해 설계되었으며, 데이터를 검색하는 데 몇 시간이 걸릴 수 있어 몇 시간 이내에 검색해야 하는 요구 사항을 충족하지 않습니다.",
            "S3 Intelligent-Tiering은 비용을 자동으로 최적화하는 데 유용하지만, 자주 접근하지 않는 데이터에 대해 S3 Standard-IA만큼 비용 효율적이지 않을 수 있으며, 동적 티어링이 필요하지 않습니다."
        ]
    },
    {
        "Question Number": "40",
        "Situation": "개발자가 캐시에서 데이터를 읽는 요청이 대부분인 애플리케이션을 위한 캐싱 솔루션을 설계하고 있습니다. 캐시는 데이터가 특별히 요청될 때만 업데이트되어야 하며, 불필요한 캐시 업데이트를 최소화하는 것이 우선 사항입니다.",
        "Question": "개발자가 불필요한 업데이트를 최소화하면서 데이터를 읽는 최적화를 위해 어떤 캐싱 전략을 선택해야 합니까?",
        "Options": {
            "1": "쓰기-통과 캐싱, 데이터베이스에 대한 업데이트와 동시에 캐시에 업데이트가 발생하여 일관성을 보장하지만 쓰기 작업이 증가할 수 있습니다.",
            "2": "지연 로딩, 데이터가 실제로 필요할 때까지 로딩을 연기하는 전략으로, 초기 로드 시간을 줄이고 자원 사용을 효율적으로 할 수 있습니다.",
            "3": "읽기-통과 캐싱, 캐시 미스 시 캐시가 자동으로 데이터베이스에서 데이터를 검색하여 불필요한 업데이트 없이 원활한 데이터 접근을 제공하는 방법입니다.",
            "4": "캐시 무효화, 업데이트가 발생할 때 캐시에서 오래된 데이터를 제거하거나 표시하는 과정으로, 사용자에게 신선한 데이터만 제공되도록 합니다."
        },
        "Correct Answer": "읽기-통과 캐싱, 캐시가 자동으로 데이터베이스에서 데이터를 검색하여 불필요한 업데이트 없이 원활한 데이터 접근을 제공하는 방법입니다.",
        "Explanation": "읽기-통과 캐싱은 캐시가 읽기 요청을 효율적으로 처리하면서 데이터가 특별히 요청될 때만 업데이트되도록 하여 불필요한 캐시 업데이트를 최소화할 수 있기 때문에 이 시나리오에 가장 적합한 전략입니다. 이는 개발자의 목표와 완벽하게 일치합니다.",
        "Other Options": [
            "쓰기-통과 캐싱은 데이터베이스에 쓰기가 있을 때마다 캐시를 업데이트하므로 이상적이지 않으며, 이는 업데이트 수를 과도하게 증가시켜 최소화하는 목표와 반대됩니다.",
            "지연 로딩은 자원 관리에 유익할 수 있지만, 업데이트를 최소화하는 데 본질적으로 기여하지 않으며, 데이터가 로드되는 시점에 더 중점을 두고 있습니다.",
            "캐시 무효화는 주로 오래된 데이터를 관리하기 위한 전략이지 읽기 작업을 최적화하기 위한 것이 아니며, 데이터가 자주 무효화되는 상황을 초래할 수 있어 불필요한 캐시 업데이트를 줄이는 목표와 일치하지 않습니다."
        ]
    },
    {
        "Question Number": "41",
        "Situation": "애플리케이션은 AWS에 배포된 여러 마이크로서비스로 구성되어 있습니다. 개발 팀은 이러한 서비스 간의 통신을 설계하여 유연성과 확장성을 향상시키는 방법을 평가하고 있습니다.",
        "Question": "어떤 접근 방식이 밀접하게 결합된 구성 요소와 느슨하게 결합된 구성 요소의 차이를 가장 잘 설명합니까?",
        "Options": {
            "1": "서비스 간에 직접 API 호출을 사용하여 즉각적인 응답을 보장합니다.",
            "2": "서비스가 이벤트를 게시하고 구독하는 이벤트 버스를 구현합니다.",
            "3": "각 마이크로서비스의 코드베이스 내에 서비스 종속성을 포함합니다.",
            "4": "모든 마이크로서비스 간에 데이터 일관성을 위해 공통 데이터베이스 스키마를 공유합니다."
        },
        "Correct Answer": "서비스가 이벤트를 게시하고 구독하는 이벤트 버스를 구현합니다.",
        "Explanation": "이벤트 버스를 구현하면 마이크로서비스가 느슨하게 결합된 방식으로 통신할 수 있어 서비스가 독립적으로 작동하고 게시된 이벤트를 통해서만 상호작용할 수 있습니다. 이는 서비스가 서로의 구현에 대해 알 필요가 없으므로 확장성과 유연성을 향상시킵니다.",
        "Other Options": [
            "직접 API 호출을 사용하면 서비스 간에 밀접한 결합이 발생하므로 각 서비스가 다른 서비스와 직접 통신하는 방법을 알아야 하며, 이는 변경을 복잡하게 만들고 잠재적으로 중단을 초래할 수 있습니다.",
            "각 마이크로서비스의 코드베이스 내에 서비스 종속성을 포함하면 밀접한 결합이 발생하여 한 서비스의 변경이 다른 서비스에 직접적인 영향을 미쳐 독립적으로 서비스를 확장하거나 수정할 수 있는 능력을 제한합니다.",
            "모든 마이크로서비스 간에 공통 데이터베이스 스키마를 공유하면 모든 서비스가 동일한 데이터 구조에 의존하게 되어 서비스가 서로 영향을 주지 않고 독립적으로 발전하기 어려워집니다."
        ]
    },
    {
        "Question Number": "42",
        "Situation": "개발자는 사용자가 콘텐츠를 생성하고 업로드할 수 있는 혁신적인 애플리케이션을 설계하는 과정에 있습니다. 이 콘텐츠는 확장 가능한 저장 솔루션인 Amazon S3에 저장됩니다. 애플리케이션이 인기를 끌 것으로 예상됨에 따라 개발자는 저장 비용을 최적화하기 위해 스마트한 라이프사이클 관리 정책을 구현하고자 합니다. 이는 사용자가 콘텐츠에 접근하는 빈도에 따라 객체를 더 저렴한 저장 계층으로 자동 전환하는 것을 포함합니다. 개발자의 목표는 저장 비용을 최소화하면서도 콘텐츠에 효율적으로 접근할 수 있도록 하는 것입니다.",
        "Question": "개발자가 시간이 지남에 따라 객체가 드물게 접근되기 시작하면 자동으로 더 비용 효율적인 저장 클래스로 이동하도록 S3 라이프사이클 정책을 어떻게 구성해야 합니까?",
        "Options": {
            "1": "30일 후 객체를 S3 Glacier로 전환합니다.",
            "2": "60일 후 객체를 S3 Standard-IA로 전환합니다.",
            "3": "90일 후 객체를 삭제합니다.",
            "4": "자동 비용 최적화를 위해 객체를 S3 Intelligent-Tiering으로 전환합니다."
        },
        "Correct Answer": "60일 후 객체를 S3 Standard-IA로 전환합니다.",
        "Explanation": "객체가 자주 접근되지 않을 때 비용 최적화를 위해 60일 후 객체를 S3 Standard-IA(비정기적 접근)로 전환하는 것이 가장 좋은 선택입니다. S3 Standard-IA는 덜 자주 접근되지만 필요할 때 신속한 접근이 필요한 데이터를 위해 설계되어 이 시나리오에 적합한 옵션입니다.",
        "Other Options": [
            "30일 후 객체를 S3 Glacier로 전환하는 것은 잘못된 선택입니다. Glacier는 아카이브 저장을 위한 것이며, 빠르게 접근해야 할 수 있는 데이터에는 적합하지 않으며, 검색 수수료와 긴 검색 시간이 있습니다.",
            "90일 후 객체를 삭제하는 것은 데이터를 영구적으로 제거하므로 잘못된 접근 방식이며, 이는 드물게 사용되는 콘텐츠에 대한 접근을 유지하면서 저장 비용을 최적화하는 목표와 일치하지 않습니다.",
            "객체를 S3 Intelligent-Tiering으로 전환하는 것은 이 맥락에서 최선의 선택이 아닙니다. 이는 변경되는 접근 패턴에 따라 두 개의 접근 계층 간에 데이터를 자동으로 이동하지만, 설정된 기간 후 드물게 접근되는 데이터에 대해 Standard-IA로 직접 전환하는 것만큼의 비용 절감 효과를 제공하지 않을 수 있습니다."
        ]
    },
    {
        "Question Number": "43",
        "Situation": "개발 팀은 마이크로서비스 기반 애플리케이션의 관측 가능성을 향상시키고 분산 구성 요소 전반에 걸쳐 성능 병목 현상을 신속하게 식별하기 위해 애플리케이션을 개선하고 있습니다. 그들은 여러 서비스 간의 요청 흐름을 캡처하는 추적 솔루션을 구현하기로 결정했습니다.",
        "Question": "팀이 애플리케이션에 대한 분산 추적을 구현하기 위해 어떤 AWS 서비스를 사용해야 합니까?",
        "Options": {
            "1": "Amazon CloudWatch Logs",
            "2": "AWS X-Ray",
            "3": "AWS CloudTrail",
            "4": "Amazon SNS"
        },
        "Correct Answer": "AWS X-Ray",
        "Explanation": "AWS X-Ray는 분산 추적을 위해 특별히 설계되어 개발자가 다양한 서비스 간에 요청을 추적하여 마이크로서비스 애플리케이션을 분석하고 디버깅할 수 있도록 합니다. 이는 성능 병목 현상과 서비스 종속성에 대한 통찰력을 제공하여 팀의 요구에 이상적입니다.",
        "Other Options": [
            "Amazon CloudWatch Logs는 주로 로깅 및 모니터링에 사용되며, 분산 추적에는 적합하지 않으므로 서비스 간의 요청 흐름을 효과적으로 캡처하지 못합니다.",
            "AWS CloudTrail은 계정 활동 및 API 사용에 대한 로깅 및 모니터링에 중점을 두고 있으며, 분산 구성 요소 간의 요청 추적과는 다릅니다.",
            "Amazon SNS는 분산 시스템 간의 통신을 촉진하는 메시징 서비스이지만 추적 기능을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "44",
        "Situation": "개발자는 AWS Elastic Beanstalk를 사용하여 웹 애플리케이션을 배포하는 과정에 있습니다. 이 애플리케이션은 중요하며 배포 단계에서 잠재적인 다운타임을 최소화해야 합니다. 또한, 개발자는 롤백이 필요할 경우 이전 버전의 애플리케이션이 계속 접근 가능해야 합니다. 팀은 전체 배포 과정 동안 완전한 용량을 유지하는 것에 대해서도 우려하고 있으며, 용량 감소는 사용자 경험에 영향을 미칠 수 있습니다.",
        "Question": "이러한 요구 사항을 고려할 때, 개발자가 최소한의 다운타임을 보장하고 롤백을 위한 가용성을 유지하며 배포 중 용량 감소를 피하기 위해 선택해야 할 배포 유형은 무엇입니까?",
        "Options": {
            "1": "모두 한 번에, 이는 애플리케이션의 새 버전을 모든 인스턴스에 동시에 배포하는 방법으로, 상당한 다운타임을 초래할 수 있습니다.",
            "2": "롤링, 배포가 순차적으로 진행되어 몇 개의 인스턴스를 한 번에 업데이트하면서 다른 인스턴스는 계속 실행되는 방법이지만, 여전히 짧은 다운타임이 발생할 수 있습니다.",
            "3": "배치 롤링, 인스턴스 그룹을 점진적으로 업데이트하는 배포 전략으로, 프로세스 전반에 걸쳐 일부 인스턴스가 항상 사용 가능하도록 보장하지만, 여전히 롤백 요구 사항을 완전히 충족하지 못할 수 있습니다.",
            "4": "불변, 새 버전으로 새로운 인스턴스를 생성하면서 이전 인스턴스는 새 인스턴스가 완전히 작동할 때까지 계속 실행되는 배포 방법으로, 최소한의 다운타임과 쉬운 롤백을 보장합니다."
        },
        "Correct Answer": "불변, 새 버전으로 새로운 인스턴스를 생성하면서 이전 인스턴스는 새 인스턴스가 완전히 작동할 때까지 계속 실행되는 배포 방법으로, 최소한의 다운타임과 쉬운 롤백을 보장합니다.",
        "Explanation": "불변 배포 방법은 개발자가 기존 인스턴스가 트래픽을 계속 처리하는 동안 업데이트된 애플리케이션 버전으로 새로운 인스턴스를 생성할 수 있게 해주므로 이 시나리오에 이상적입니다. 이 접근 방식은 다운타임을 크게 최소화하고 이전 버전이 새 버전이 안정적이라고 확인될 때까지 롤백을 위해 사용 가능하도록 보장합니다.",
        "Other Options": [
            "모두 한 번에 배포 전략은 새 버전이 모든 인스턴스에 동시에 배포되므로 상당한 다운타임을 초래하여 이 과정 동안 애플리케이션이 사용할 수 없게 됩니다.",
            "롤링 배포 방법은 인스턴스를 한 번에 하나씩 업데이트하므로 업데이트 중 일부 인스턴스가 서비스 중단될 수 있어 짧은 다운타임이 발생할 수 있으며, 이는 명시된 요구 사항에 덜 이상적입니다.",
            "배치 롤링 배포 전략은 인스턴스를 점진적으로 업데이트하지만, 모든 인스턴스가 작동하지 않을 수 있는 기간이 있을 수 있어 롤백에 필요한 가용성을 제공하지 못할 수 있으므로 팀의 목표와 완전히 일치하지 않습니다."
        ]
    },
    {
        "Question Number": "45",
        "Situation": "개발자는 AWS Elastic Beanstalk에서 애플리케이션을 배포하고 있습니다. 배포 과정의 일환으로, 개발자는 애플리케이션 성능 모니터링과 잠재적인 병목 현상 식별의 중요성을 인식합니다. 이를 위해 개발자는 애플리케이션 동작에 대한 통찰력을 제공하는 서비스인 AWS X-Ray를 활성화하기로 결정했습니다. 그러나 개발자는 X-Ray를 Elastic Beanstalk 환경에 효과적으로 통합하는 올바른 단계에 대해 확신이 없습니다.",
        "Question": "최적의 성능 통찰력을 위해 Elastic Beanstalk 환경에서 AWS X-Ray 모니터링을 활성화하기 위해 개발자가 취해야 할 구체적인 조치는 무엇입니까?",
        "Options": {
            "1": "인스턴스 초기화 중에 X-Ray 데몬을 시작하기 위해 사용자 데이터 스크립트를 사용합니다.",
            "2": ".ebextensions/xray-daemon.config 파일에 XRayEnabled: true를 추가합니다.",
            "3": "X-Ray 데몬이 설치된 사용자 정의 Docker 이미지를 생성합니다.",
            "4": "구성 파일을 수정하지 않고 AWS Management Console에서 X-Ray를 활성화합니다."
        },
        "Correct Answer": ".ebextensions/xray-daemon.config 파일에 XRayEnabled: true를 추가합니다.",
        "Explanation": "Elastic Beanstalk 환경에서 AWS X-Ray를 활성화하려면, 특정 구성 파일인 .ebextensions/xray-daemon.config에 'XRayEnabled: true'를 추가하여 환경 구성을 수정하는 것이 올바른 방법입니다. 이렇게 하면 X-Ray 데몬이 애플리케이션과 함께 자동으로 시작되어 효과적인 모니터링 및 디버깅이 가능합니다.",
        "Other Options": [
            "사용자 데이터 스크립트를 사용하면 X-Ray 데몬을 시작할 수 있지만, Elastic Beanstalk에 대한 권장 접근 방식이 아니며, 더 많은 수동 구성이 필요하고 환경의 라이프사이클 이벤트와 원활하게 통합되지 않습니다.",
            "X-Ray 데몬이 설치된 사용자 정의 Docker 이미지를 생성하는 것은 Elastic Beanstalk에서 X-Ray를 활성화하는 데 필요하지 않으며, 구성 파일을 통해 제공되는 내장 방법이 프로세스를 단순화합니다.",
            "AWS Management Console에서 X-Ray를 활성화하는 것은 간단해 보일 수 있지만, Elastic Beanstalk 환경이 X-Ray 데몬을 효과적으로 활용하는 데 필요한 구성을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "46",
        "Situation": "개발자가 고객 주문 데이터를 저장하기 위해 DynamoDB 테이블을 설계하고 있습니다. 이 테이블은 빈번한 쓰기 및 읽기 작업이 필요하며, 각 항목은 고유하게 식별 가능해야 합니다.",
        "Question": "다음 중 파티션 키로 가장 적합한 선택은 무엇입니까?",
        "Options": {
            "1": "고객 ID와 타임스탬프의 조합",
            "2": "'OrderData'와 같은 정적 값",
            "3": "각 항목에 대해 무작위로 생성된 UUID",
            "4": "테이블의 모든 항목에 대해 동일한 키 값"
        },
        "Correct Answer": "고객 ID와 타임스탬프의 조합",
        "Explanation": "고객 ID와 타임스탬프의 조합을 파티션 키로 사용하면 각 주문이 고유하게 식별 가능하고 파티션에 고르게 분산됩니다. 이 설계는 빈번한 작업이 있는 테이블의 읽기 및 쓰기 성능을 최적화하는 데 중요합니다.",
        "Other Options": [
            "'OrderData'와 같은 정적 값은 모든 항목이 동일한 파티션 키를 공유하게 되어 고유 식별이 불가능하며, 성능 병목 현상을 초래할 수 있습니다.",
            "각 항목에 대해 무작위로 생성된 UUID는 고유하지만, 파티션 간 데이터 분포가 고르지 않아 성능 문제를 일으킬 수 있습니다.",
            "테이블의 모든 항목에 대해 동일한 키 값을 사용하면 모든 데이터가 하나의 파티션에 저장되어 처리량과 확장성이 심각하게 제한됩니다."
        ]
    },
    {
        "Question Number": "47",
        "Situation": "개발자는 애플리케이션의 건강과 성능에 대한 포괄적인 가시성을 보장하기 위해 로깅, 모니터링 및 관찰 가능성을 구분하는 작업을 맡고 있습니다. 이는 각 개념의 역할과 시스템 동작에 대한 통찰력을 제공하기 위해 어떻게 상호작용하는지에 대한 명확한 이해가 필요합니다. 궁극적으로 애플리케이션의 신뢰성을 유지하는 데 도움이 됩니다. 개발자는 이러한 세 가지 개념이 어떻게 상호 연관되고 서로를 지원하여 애플리케이션의 신뢰성을 유지하는지 설명해야 합니다. 특히 여러 시스템이 상호작용하는 복잡한 환경에서 그렇습니다.",
        "Question": "애플리케이션 성능 및 신뢰성의 맥락에서 로깅, 모니터링 및 관찰 가능성 간의 관계를 가장 잘 설명하는 진술은 무엇입니까?",
        "Options": {
            "1": "로깅은 상세한 이벤트 데이터를 캡처하고, 모니터링은 주요 메트릭을 추적하며, 관찰 가능성은 둘을 결합하여 시스템 동작에 대한 통찰력을 제공합니다.",
            "2": "모니터링과 로깅은 관찰 가능성의 하위 집합으로, 실시간 경고에만 초점을 맞춥니다.",
            "3": "관찰 가능성은 자동 진단을 제공하여 로깅 및 모니터링의 필요성을 대체합니다.",
            "4": "로깅과 모니터링은 독립적인 프로세스로, 관찰 가능성에 기여하지 않습니다."
        },
        "Correct Answer": "로깅은 상세한 이벤트 데이터를 캡처하고, 모니터링은 주요 메트릭을 추적하며, 관찰 가능성은 둘을 결합하여 시스템 동작에 대한 통찰력을 제공합니다.",
        "Explanation": "정답은 로깅, 모니터링 및 관찰 가능성이 어떻게 함께 작동하는지를 강조합니다. 로깅은 시스템 내의 이벤트 및 트랜잭션에 대한 상세 정보를 제공하여 개발자가 특정 사건 동안 발생한 일을 이해할 수 있도록 합니다. 모니터링은 CPU 사용량 및 응답 시간과 같은 주요 메트릭을 추적하여 전체 시스템 성능에 초점을 맞춥니다. 관찰 가능성은 로깅 및 모니터링을 통해 캡처된 데이터를 활용하여 시스템 동작에 대한 통찰력을 얻고, 개발자가 문제를 진단하고 시스템의 내부 작동을 이해할 수 있도록 합니다.",
        "Other Options": [
            "이 옵션은 모니터링과 로깅이 단순히 관찰 가능성의 하위 집합이라고 잘못 제시하고, 관찰 가능성을 실시간 경고에만 초점을 맞춘 것으로 잘못 표현하므로 부정확합니다. 사실 관찰 가능성은 시스템 동작에 대한 더 넓은 분석을 포함합니다.",
            "이 옵션은 관찰 가능성이 로깅과 모니터링을 완전히 대체할 수 있다고 암시하므로 부정확하며, 이러한 프로세스가 관찰 가능성이 효과적으로 기능하는 데 필요한 데이터를 제공하는 필수 역할을 무시합니다.",
            "이 옵션은 로깅과 모니터링이 독립적으로 작동하며 관찰 가능성에 기여하지 않는다고 잘못 주장하므로 부정확합니다. 실제로 두 프로세스 모두 효과적인 관찰 가능성에 필수적이며 시스템에 대한 이해를 향상시킵니다."
        ]
    },
    {
        "Question Number": "48",
        "Situation": "개발자는 사용자가 로그인한 후 S3 및 DynamoDB와 같은 AWS 리소스에 접근할 수 있는 애플리케이션을 구축하고 있습니다. 이 애플리케이션은 또한 인증되지 않은 사용자가 제한된 리소스를 탐색할 수 있도록 해야 합니다.",
        "Question": "개발자가 사용해야 할 Cognito 기능의 조합은 무엇입니까?",
        "Options": {
            "1": "인증을 위한 Cognito User Pool과 권한 부여를 위한 Cognito Identity Pool",
            "2": "인증 및 권한 부여를 위한 Cognito Identity Pool",
            "3": "사용자 가입 및 로그인 기능을 위한 Cognito User Pool만",
            "4": "사용자 프로필 및 AWS 자격 증명을 동기화하기 위한 Cognito Sync"
        },
        "Correct Answer": "인증을 위한 Cognito User Pool과 권한 부여를 위한 Cognito Identity Pool",
        "Explanation": "개발자는 사용자 가입 및 로그인을 관리하기 위해 Cognito User Pool을 사용하여 안전한 인증 메커니즘을 제공합니다. 그런 다음 Cognito Identity Pool을 사용하여 권한 부여를 수행하여 사용자가 AWS 리소스에 접근할 수 있도록 하고 인증되지 않은 사용자에게 특정 리소스에 대한 제한된 접근을 허용합니다. 이 조합은 필요한 리소스에 대한 인증된 접근과 인증되지 않은 접근을 모두 보장합니다.",
        "Other Options": [
            "Cognito Identity Pool은 권한 부여를 제공할 수 있지만, 이 애플리케이션에 필요한 사용자 인증을 처리하지 않으므로 Identity Pool만 사용하는 것은 불충분합니다.",
            "Cognito User Pool만 사용하는 것은 AWS 리소스에 접근하기 위한 권한 부여를 허용하지 않으므로 애플리케이션에 필수적입니다. 인증 후 사용자가 접근할 수 있는 리소스를 결정하기 위해 권한 부여가 필요합니다.",
            "Cognito Sync는 장치 간 사용자 데이터를 동기화하는 데 사용되지만 인증이나 권한 부여 기능을 제공하지 않으므로 사용자를 로그인시키고 리소스 접근을 허용하는 요구 사항과는 관련이 없습니다."
        ]
    },
    {
        "Question Number": "49",
        "Situation": "개발자가 사용자 업로드 파일을 Amazon S3에 저장하고 AWS Lambda 함수로 처리하는 애플리케이션을 구축하고 있습니다. 애플리케이션은 동일한 파일이 여러 번 업로드되더라도 각 파일이 한 번만 처리되도록 보장해야 합니다.",
        "Question": "파일의 멱등성 처리를 보장하기 위해 개발자가 구현해야 할 솔루션은 무엇입니까?",
        "Options": {
            "1": "처리된 파일 식별자를 추적하기 위해 DynamoDB 테이블을 구현합니다.",
            "2": "객체 버전 관리가 활성화된 S3 이벤트 알림을 사용합니다.",
            "3": "처리 후 S3에서 파일을 삭제하도록 Lambda 함수를 구성합니다.",
            "4": "각 파일 업로드에 대해 메시지를 게시하기 위해 Amazon SNS를 활용합니다."
        },
        "Correct Answer": "처리된 파일 식별자를 추적하기 위해 DynamoDB 테이블을 구현합니다.",
        "Explanation": "DynamoDB 테이블을 사용하여 처리된 파일 식별자를 추적하면 각 고유 파일 업로드가 기록됩니다. 애플리케이션은 파일을 처리하기 전에 이 테이블을 확인하여 이미 처리되었는지 확인함으로써 멱등성을 보장할 수 있습니다. 이렇게 하면 동일한 파일이 여러 번 업로드되더라도 처리 로직이 중복 작업을 피할 수 있습니다.",
        "Other Options": [
            "객체 버전 관리가 활성화된 S3 이벤트 알림을 사용하는 것은 파일이 처리되었는지 여부를 추적하는 방법을 본질적으로 제공하지 않습니다. 버전 관리는 변경 사항만 추적하며 각 파일의 처리 상태는 추적하지 않습니다.",
            "처리 후 S3에서 파일을 삭제하도록 Lambda 함수를 구성하는 것은 파일이 여러 번 업로드되었을 때 다시 처리되는 것을 방지하지 않습니다. 삭제는 이미 처리가 발생했는지 여부를 추적하지 않습니다.",
            "각 파일 업로드에 대해 메시지를 게시하기 위해 Amazon SNS를 활용하는 것은 파일이 한 번만 처리되도록 보장하지 않습니다. SNS는 메시징을 위해 설계되었으며 파일 처리 상태를 추적하는 메커니즘을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "50",
        "Situation": "개발자가 Lambda 함수가 필요한 리소스에 안전하게 접근할 수 있도록 IAM 역할을 설정하고 있습니다.",
        "Question": "이 역할의 신뢰 관계를 올바르게 정의하는 문장은 무엇입니까?",
        "Options": {
            "1": "\"Principal\": {\"AWS\": \"arn:aws:iam::123456789012:user/ExampleUser\"}",
            "2": "\"Principal\": {\"Service\": \"lambda.amazonaws.com\"}",
            "3": "\"Principal\": {\"Action\": \"sts:AssumeRole\"}",
            "4": "\"Principal\": {\"Policy\": \"ReadOnlyAccess\"}"
        },
        "Correct Answer": "\"Principal\": {\"Service\": \"lambda.amazonaws.com\"}",
        "Explanation": "이 문장은 AWS 서비스, 특히 Lambda가 이 IAM 역할을 맡을 수 있도록 허용된다는 것을 올바르게 정의합니다. 신뢰 정책은 역할을 맡을 수 있는 서비스를 지정해야 하며, 이 경우 Lambda 서비스입니다.",
        "Other Options": [
            "이 옵션은 사용자 ARN을 지정하고 있으며, 이는 Lambda 함수가 역할을 맡는 데 적합하지 않습니다. 사용자는 서비스용으로 설계된 역할을 맡을 수 없습니다.",
            "이 옵션은 역할을 맡을 수 있는 서비스나 사용자가 아닌 작업을 잘못 지정하고 있습니다. 신뢰 관계는 주체를 정의해야 하며, 작업이 아닙니다.",
            "이 옵션은 주체 대신 정책을 정의하고 있습니다. 신뢰 관계는 누가 역할을 맡을 수 있는지를 지정해야 하며, 어떤 권한이 부여되는지를 지정하는 것이 아닙니다."
        ]
    },
    {
        "Question Number": "51",
        "Situation": "개발자가 AWS Lambda와 Amazon API Gateway를 사용하여 마이크로서비스 기반 애플리케이션을 설계하고 있습니다. 애플리케이션은 사용자 세션을 유지하고 사용자 특정 데이터를 임시로 저장해야 합니다. 개발자는 Lambda 함수와 원활하게 통합되고 고가용성 및 확장성이 뛰어난 저장 솔루션을 선택하고자 합니다.",
        "Question": "세션 데이터를 저장하기 위해 개발자가 사용해야 할 AWS 서비스는 무엇입니까?",
        "Options": {
            "1": "Amazon RDS",
            "2": "Amazon DynamoDB",
            "3": "Amazon S3",
            "4": "Amazon ElastiCache"
        },
        "Correct Answer": "Amazon DynamoDB",
        "Explanation": "Amazon DynamoDB는 높은 가용성, 확장성 및 AWS Lambda와의 원활한 통합 덕분에 마이크로서비스 아키텍처에서 세션 데이터를 저장하는 데 이상적인 선택입니다. 이는 높은 읽기 및 쓰기 작업량을 처리할 수 있는 NoSQL 데이터베이스로, 사용자 특정 데이터에 대한 빠른 접근이 필요한 세션 관리에 적합합니다.",
        "Other Options": [
            "Amazon RDS는 관계형 데이터에 대해 신뢰할 수 있지만, DynamoDB만큼 확장성이 뛰어나거나 일시적인 세션 데이터에 적합하지 않습니다.",
            "Amazon S3는 주로 객체 저장소로 사용되며 세션 데이터에 필요한 빠른 접근을 위해 최적화되어 있지 않습니다.",
            "Amazon ElastiCache는 임시 데이터에 유용한 캐싱 솔루션이지만, 세션 데이터 저장에 필요한 지속성을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "52",
        "Situation": "개발자가 SQS 큐와 상호작용하는 애플리케이션을 설계하고 있습니다. 큐에 있는 메시지는 드물게 추가되며, 개발자는 메시지가 도착하는 즉시 검색되도록 하면서 API 호출 수를 최소화하고 비용을 줄이기를 원합니다.",
        "Question": "개발자가 비용과 API 호출을 최소화하면서 SQS 큐에서 메시지를 효율적으로 검색하기 위해 어떤 폴링 메커니즘을 사용해야 합니까?",
        "Options": {
            "1": "WaitTimeSeconds를 0으로 설정한 Short Polling, 즉시 검색이 가능하지만 API 호출이 더 빈번해집니다.",
            "2": "WaitTimeSeconds를 20으로 설정한 Long Polling, 메시지가 도착할 때까지 기다렸다가 다시 확인하여 API 호출을 줄입니다.",
            "3": "ReceiveMessageWaitTimeSeconds를 0으로 설정한 Short Polling, 즉시 메시지를 확인할 수 있지만 비용이 증가할 수 있습니다.",
            "4": "ReceiveMessageWaitTimeSeconds를 0으로 설정한 Long Polling, 대기 시간 없이 메시지를 확인하지만 불필요한 API 호출을 초래합니다."
        },
        "Correct Answer": "WaitTimeSeconds를 20으로 설정한 Long Polling, 메시지가 도착할 때까지 기다렸다가 다시 확인하여 API 호출을 줄입니다.",
        "Explanation": "이 상황에 적합한 접근 방식은 WaitTimeSeconds를 20으로 설정한 Long Polling을 사용하는 것입니다. 이 방법은 애플리케이션이 메시지가 도착할 때까지 최대 20초까지 기다리도록 하여 Short Polling에 비해 API 호출 수를 크게 줄입니다. 이는 적시에 메시지를 검색하면서 비용 효율성을 유지하는 균형을 이루어, 메시지가 드물게 추가되는 시나리오에 이상적입니다.",
        "Other Options": [
            "WaitTimeSeconds를 0으로 설정한 Short Polling은 즉시 메시지를 검색할 수 있지만, 메시지가 드물게 추가되는 점을 고려할 때 API 호출 수가 증가하여 비용 효율적이지 않습니다.",
            "ReceiveMessageWaitTimeSeconds를 0으로 설정한 Short Polling도 즉시 메시지를 확인할 수 있지만, 메시지가 도착할 때까지 기다리지 않아 API 호출과 비용이 증가하며 Long Polling의 이점을 누리지 못합니다.",
            "ReceiveMessageWaitTimeSeconds를 0으로 설정한 Long Polling은 대기 시간을 완전히 피하지만, 이는 애플리케이션이 메시지를 위해 큐를 지속적으로 확인하게 되어 불필요한 API 호출과 더 높은 비용을 초래합니다."
        ]
    },
    {
        "Question Number": "53",
        "Situation": "개발자는 이해관계자에게 시각적으로 매력적이고 이해하기 쉬운 방식으로 애플리케이션의 실시간 메트릭 및 운영 데이터를 제공하는 임무를 맡고 있습니다. 이는 다양한 핵심 성과 지표(KPI), 트렌드 및 통찰력을 동적으로 표시할 수 있는 인터랙티브 대시보드를 만드는 것을 포함합니다. 개발자는 다른 AWS 서비스와 잘 통합되며 광범위한 코딩 없이 풍부한 시각화를 생성할 수 있는 솔루션을 찾고 있습니다.",
        "Question": "개발자가 애플리케이션의 성과 메트릭을 효과적으로 보여주는 이러한 인터랙티브 데이터 시각화 및 대시보드를 만들기 위해 가장 적합한 AWS 서비스는 무엇입니까?",
        "Options": {
            "1": "Amazon QuickSight",
            "2": "AWS Glue",
            "3": "Amazon S3",
            "4": "AWS Step Functions"
        },
        "Correct Answer": "Amazon QuickSight",
        "Explanation": "Amazon QuickSight는 개발자가 시각적으로 매력적이고 인터랙티브한 대시보드를 만들 수 있도록 하는 비즈니스 분석 서비스입니다. 데이터 시각화를 위해 특별히 설계되었으며 다양한 데이터 소스에 연결할 수 있어 이해관계자에게 실시간 메트릭과 핵심 성과 지표를 이해하기 쉬운 형식으로 제공하는 데 이상적입니다.",
        "Other Options": [
            "AWS Glue는 주로 ETL(추출, 변환, 로드) 프로세스를 지원하는 데이터 준비 서비스이지만, 대시보드를 만드는 데 필요한 시각화 기능을 제공하지 않습니다.",
            "Amazon S3는 데이터를 저장할 수 있는 서비스이지만, 인터랙티브 대시보드 형태로 데이터를 시각화하는 데 필요한 내장 도구를 제공하지 않습니다.",
            "AWS Step Functions는 여러 AWS 서비스를 조정할 수 있는 서버리스 오케스트레이션 서비스이지만, 시각화나 대시보드를 만드는 데 사용되지 않습니다."
        ]
    },
    {
        "Question Number": "54",
        "Situation": "한 회사가 클라우드 저장소 기능을 확장하고 있으며, 엄격한 규제 기준을 준수하기 위해 서로 다른 AWS 리전에 위치한 두 개의 S3 버킷 간에 데이터가 일관되게 복제되도록 해야 합니다. 목표는 효율성을 유지하면서 새로 생성된 객체만 포함하도록 복제 프로세스를 간소화하는 것입니다.",
        "Question": "Cross-Region Replication (CRR)을 올바르게 구성하기 위해 충족해야 하는 조건은 무엇입니까?",
        "Options": {
            "1": "소스 버킷에서만 버전 관리가 활성화되어야 하며, 이를 통해 새 객체의 효율적인 복제를 허용합니다.",
            "2": "소스와 대상 버킷은 서로 다른 AWS 리전에 있어야 하며, 준수를 보장하기 위해 두 버킷 모두에서 버전 관리가 활성화되어야 합니다.",
            "3": "복제는 소스 버킷이 대상 버킷과 동일한 리전에 있을 때만 발생할 수 있으며, 이는 크로스 리전 요구에 적합하지 않습니다.",
            "4": "소스 버킷은 버전 관리가 활성화되어야 하며, 대상 버킷도 적절한 복제를 위해 동일한 AWS 리전에 있어야 합니다."
        },
        "Correct Answer": "소스와 대상 버킷은 서로 다른 AWS 리전에 있어야 하며, 준수를 보장하기 위해 두 버킷 모두에서 버전 관리가 활성화되어야 합니다.",
        "Explanation": "Cross-Region Replication (CRR)을 성공적으로 구성하려면 소스와 대상 버킷이 서로 다른 AWS 리전에 있어야 하며, 두 버킷 모두에서 버전 관리가 활성화되어야 합니다. 이는 객체의 변경 사항을 추적하고 새로 생성되거나 수정된 객체만 대상 버킷으로 복제되도록 보장하여 규제 준수 요구 사항을 충족하는 데 필요합니다.",
        "Other Options": [
            "이 옵션은 소스 버킷에서만 버전 관리가 활성화되어 있는 것이 CRR에 충분하지 않기 때문에 잘못된 것입니다. 두 버킷 모두에서 버전 관리가 활성화되어야 객체의 적절한 추적 및 복제를 보장할 수 있습니다.",
            "이 옵션은 복제가 동일한 리전에서만 발생할 수 있다고 잘못 진술하고 있기 때문에 잘못된 것입니다. CRR은 소스와 대상 버킷이 서로 다른 리전에 있어야 합니다.",
            "이 옵션은 대상 버킷이 소스 버킷과 동일한 AWS 리전에 있어야 한다고 진술하고 있어, Cross-Region Replication의 기본 요구 사항과 모순되기 때문에 잘못된 것입니다."
        ]
    },
    {
        "Question Number": "55",
        "Situation": "개발자가 Amazon S3에서 이벤트를 처리하는 AWS Lambda 함수에 대한 단위 테스트를 작성하고 있습니다. 개발자는 Lambda 함수가 AWS에 배포하지 않고도 다양한 유형의 S3 이벤트를 처리할 때 올바르게 작동하는지 확인하고자 합니다.",
        "Question": "개발자가 이러한 단위 테스트를 로컬에서 작성하고 실행하기 위해 어떤 도구를 사용해야 합니까?",
        "Options": {
            "1": "AWS CloudFormation",
            "2": "AWS Serverless Application Model (AWS SAM)",
            "3": "Amazon CloudWatch",
            "4": "AWS CodeDeploy"
        },
        "Correct Answer": "AWS Serverless Application Model (AWS SAM)",
        "Explanation": "AWS SAM은 서버리스 애플리케이션을 위해 특별히 설계되었으며, 개발자가 Lambda 함수와 관련 리소스를 로컬에서 빌드, 테스트 및 디버그할 수 있도록 합니다. AWS 클라우드를 시뮬레이션하는 로컬 환경을 제공하여 Lambda 함수를 AWS에 배포하지 않고도 단위 테스트를 수행하는 데 이상적인 선택입니다.",
        "Other Options": [
            "AWS CloudFormation은 주로 인프라를 코드로 배포하고 관리하는 데 사용되며, Lambda 함수의 로컬 테스트에는 사용되지 않습니다.",
            "Amazon CloudWatch는 AWS 리소스 및 애플리케이션을 모니터링하는 서비스이며, Lambda 함수의 로컬 테스트를 위한 프레임워크를 제공하지 않습니다.",
            "AWS CodeDeploy는 다양한 컴퓨팅 서비스에 애플리케이션 배포를 자동화하는 서비스이지만, 서버리스 애플리케이션의 로컬 테스트를 지원하지 않습니다."
        ]
    },
    {
        "Question Number": "56",
        "Situation": "개발자가 Amazon Web Services (AWS)에 호스팅된 고트래픽 웹 애플리케이션을 최적화하는 업무를 맡았습니다. 이 애플리케이션은 특정 데이터에 대한 빈번한 접근으로 인해 지연 시간과 느린 응답 시간과 관련된 문제에 직면해 있습니다. 성능을 향상시키기 위해 개발자는 강력한 캐싱 전략을 구현하기로 결정했습니다. 이 전략은 지연 시간을 줄이는 것뿐만 아니라 사용자로부터 특정 요청 헤더에 기반한 개인화된 응답을 제공하는 특정 요구 사항도 충족해야 합니다.",
        "Question": "지연 시간을 줄이고 응답 시간을 개선하며 개인화된 콘텐츠를 위한 특정 요청 헤더를 고려한 효과적인 캐싱 전략을 달성하기 위해 개발자가 어떤 AWS 서비스와 기능을 활용해야 합니까?",
        "Options": {
            "1": "요청 헤더에 따라 캐시 키를 수정하는 Lambda@Edge 기능이 포함된 Amazon CloudFront.",
            "2": "요청 헤더에 따라 키 태깅이 적용된 Amazon ElastiCache for Redis.",
            "3": "서버 측 암호화 및 버전 관리가 활성화된 Amazon S3.",
            "4": "헤더에 기반한 사용자 정의 라우팅 정책이 포함된 AWS Global Accelerator."
        },
        "Correct Answer": "요청 헤더에 따라 캐시 키를 수정하는 Lambda@Edge 기능이 포함된 Amazon CloudFront.",
        "Explanation": "Amazon CloudFront는 엣지 위치에서 콘텐츠를 캐시할 수 있는 콘텐츠 전송 네트워크(CDN)로, 사용자에게 지연 시간을 크게 줄여줍니다. Lambda@Edge의 통합을 통해 개발자는 특정 요청 헤더에 따라 캐싱 동작을 사용자 정의할 수 있습니다. 이를 통해 캐시된 콘텐츠가 각 사용자에 맞춰 조정되어 개인화된 경험을 제공하면서도 높은 성능을 유지할 수 있습니다.",
        "Other Options": [
            "Amazon ElastiCache for Redis는 주로 인메모리 데이터 캐싱에 사용되지만, 개인화된 응답을 위해 요청 헤더에 따라 캐시 키를 본질적으로 수정하지 않으므로 이 특정 사용 사례에 덜 적합합니다.",
            "Amazon S3는 객체 저장 기능을 제공하는 저장 서비스입니다. 버전 관리 및 암호화를 지원하지만 요청 헤더에 따라 콘텐츠를 캐시하는 데 설계되지 않아 이 시나리오에서 효과적이지 않습니다.",
            "AWS Global Accelerator는 네트워크 라우팅을 최적화하고 애플리케이션 가용성과 성능을 개선하도록 설계되었지만, 캐싱 기능이나 요청 헤더에 따라 캐시 동작을 수정하는 기능을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "57",
        "Situation": "웹 애플리케이션이 가변적인 트래픽을 경험하고 있으며 최소한의 지연 시간으로 효율적인 데이터 접근이 필요합니다. 기본 데이터베이스의 부하를 줄이고 응답 시간을 개선하기 위해 개발 팀은 캐싱 전략을 구현하고자 합니다.",
        "Question": "데이터가 일관되게 사용 가능하고 최신 상태를 유지하면서 캐시 미스를 최소화하기 위해 팀이 사용해야 할 캐싱 전략은 무엇입니까?",
        "Options": {
            "1": "Write-through caching",
            "2": "Read-through caching",
            "3": "Lazy loading",
            "4": "Time-to-live (TTL) caching"
        },
        "Correct Answer": "Write-through caching",
        "Explanation": "Write-through caching은 데이터가 캐시에 기록될 때, 동시에 기본 데이터베이스에도 기록되도록 보장합니다. 이 접근 방식은 일관성을 유지하고 오래된 데이터의 가능성을 줄이는 데 도움이 되며, 최신 정보가 필요한 애플리케이션에 매우 중요합니다. 결과적으로 캐시 미스를 최소화하고 필요할 때 데이터를 쉽게 사용할 수 있도록 합니다.",
        "Other Options": [
            "Read-through caching은 캐시 미스가 발생할 때만 데이터베이스에서 데이터를 검색합니다. 성능을 개선할 수 있지만, 캐시를 적극적으로 업데이트하지 않으므로 특정 시나리오에서 오래된 데이터가 발생할 수 있습니다.",
            "Lazy loading은 데이터가 실제로 필요할 때까지 로딩을 연기하여, 캐시에 데이터가 이미 존재하지 않을 경우 캐시 미스를 초래할 수 있습니다. 이 전략은 데이터를 최신 상태로 유지하는 것을 우선시하지 않으므로 불일치가 발생할 수 있습니다.",
            "Time-to-live (TTL) caching은 데이터가 만료되기 전까지 캐시에 남아 있는 특정 기간을 설정합니다. 오래된 데이터를 관리하는 데 도움이 될 수 있지만, 접근할 때 데이터가 최신 상태인지 보장하지 않으므로 캐시 미스가 발생할 수 있습니다."
        ]
    },
    {
        "Question Number": "58",
        "Situation": "소프트웨어 개발자가 Amazon EC2 인스턴스에서 실행되는 애플리케이션의 새 버전을 배포하는 중요한 작업을 맡았습니다. 이 배포 과정은 매우 중요하며, 새로운 인프라를 생성할 필요 없이 동일한 인스턴스 집합에서 수행되어야 합니다. 개발자는 애플리케이션이 중단되고, 원활하게 업데이트된 후, 사용자에게 최신 기능과 수정 사항을 제공하기 위해 최소한의 다운타임으로 다시 시작되도록 해야 합니다.",
        "Question": "다운타임을 최소화하고 이전 애플리케이션 버전에서 새 버전으로의 원활한 전환을 보장하기 위해 동일한 EC2 인스턴스를 사용해야 하는 상황에서, 개발자가 구현해야 할 CodeDeploy 배포 유형은 무엇입니까?",
        "Options": {
            "1": "Blue/green deployment",
            "2": "In-place deployment",
            "3": "Canary deployment",
            "4": "Rolling deployment"
        },
        "Correct Answer": "In-place deployment",
        "Explanation": "In-place deployment는 기존 EC2 인스턴스에서 애플리케이션을 직접 업데이트하는 방법이기 때문에 이 시나리오에 적합한 선택입니다. 이 방법은 애플리케이션을 중단하고 업데이트한 후 동일한 인프라에서 다시 시작할 수 있게 하여, 새로운 인프라를 프로비저닝할 필요 없이 동일한 인스턴스 집합을 사용하는 요구 사항과 완벽하게 일치합니다.",
        "Other Options": [
            "Blue/green deployment는 새로운 애플리케이션 버전을 호스팅하기 위해 새로운 인스턴스 집합을 생성하는 것을 포함하므로, 배포에 동일한 인스턴스를 사용해야 한다는 요구 사항과 모순됩니다.",
            "Canary deployment는 일반적으로 새로운 버전을 먼저 소규모 인스턴스 집합에 배포하는 것을 포함하므로, 모든 인스턴스를 한 번에 업데이트해야 하는 요구 사항에는 적합하지 않습니다.",
            "Rolling deployment는 인스턴스를 배치로 업데이트하므로, 시나리오에서는 애플리케이션이 중단되고 업데이트된 후 동일한 인스턴스 집합에서 다시 시작해야 한다고 명시되어 있어 적합하지 않습니다."
        ]
    },
    {
        "Question Number": "59",
        "Situation": "개발자가 API Gateway와 Lambda를 사용하여 API를 구축하고 있습니다. 그들은 여러 단계(예: dev, test, prod)에서 동일한 Lambda 함수를 사용하고 싶지만, 호출되는 단계에 따라 다른 DynamoDB 테이블에서 읽도록 함수를 설정하고자 합니다.",
        "Question": "개발자가 이를 달성하기 위해 무엇을 사용해야 합니까?",
        "Options": {
            "1": "각 단계에 대해 별도의 Lambda 함수를 배포합니다.",
            "2": "API Gateway에서 단계 변수를 구성하고 이를 Lambda 함수에 전달합니다.",
            "3": "Lambda 레이어를 사용하여 단계별 구성을 관리합니다.",
            "4": "Lambda 함수에서 환경 변수를 사용하여 단계를 동적으로 결정합니다."
        },
        "Correct Answer": "API Gateway에서 단계 변수를 구성하고 이를 Lambda 함수에 전달합니다.",
        "Explanation": "API Gateway에서 단계 변수를 사용하면 개발자가 각 단계에 대한 키-값 쌍을 정의할 수 있으며, 이를 Lambda 함수에 매개변수로 전달할 수 있습니다. 이렇게 하면 함수가 호출되는 단계에 따라 동적으로 다른 DynamoDB 테이블에서 읽을 수 있으며, 각 단계에 대해 별도의 Lambda 배포가 필요하지 않습니다.",
        "Other Options": [
            "각 단계에 대해 별도의 Lambda 함수를 배포하면 관리가 복잡해지고 오버헤드가 증가하며, 동일한 함수의 여러 버전을 유지해야 하므로 비효율적입니다.",
            "Lambda 레이어는 주로 함수 간에 코드와 라이브러리를 공유하기 위한 것이며, 구성을 관리할 수 있지만 호출 단계에 따라 단계별 테이블 선택을 직접 허용하지는 않습니다.",
            "Lambda 함수에서 환경 변수를 사용하는 것은 유효한 접근 방식이지만, API Gateway에서 단계 변수를 구성하는 것이 함수 코드를 변경하지 않고 다양한 환경을 관리하는 데 더 간단합니다."
        ]
    },
    {
        "Question Number": "60",
        "Situation": "한 회사가 Amazon Web Services (AWS) 환경을 보다 효율적으로 관리하고 사용자 권한을 간소화하려고 합니다. 그들은 액세스 권한 관리를 단순화하기 위해 AWS에서 제공하는 일반적인 사용 사례에 대한 미리 정의된 정책을 활용하기로 결정했습니다. 이는 IAM(Identity and Access Management) 구성에서 시간을 절약하고 복잡성을 줄이기 위한 접근 방식입니다.",
        "Question": "이 맥락에서 회사가 AWS에서 제공하는 미리 정의된 정책을 사용하여 목표에 가장 잘 부합하는 IAM 정책 유형은 무엇입니까?",
        "Options": {
            "1": "AWS 계정 소유자가 생성하고 관리하는 고객 관리 정책으로, 유연성을 제공하지만 더 많은 노력이 필요합니다.",
            "2": "단일 사용자, 그룹 또는 역할에 직접 연결된 인라인 정책으로, 밀접하게 결합된 액세스를 제공하지만 재사용성이 부족합니다.",
            "3": "AWS에서 생성하고 유지 관리하는 미리 구성된 정책으로, 일반적인 사용 시나리오에 맞게 설계되어 쉽게 구현할 수 있는 AWS 관리 정책입니다.",
            "4": "특정 서비스에 대해 AWS에서 자동으로 생성된 서비스 연결 정책으로, 해당 서비스가 제대로 작동하는 데 필요한 권한을 부여합니다."
        },
        "Correct Answer": "AWS에서 생성하고 유지 관리하는 미리 구성된 정책으로, 일반적인 사용 시나리오에 맞게 설계되어 쉽게 구현할 수 있는 AWS 관리 정책입니다.",
        "Explanation": "정답은 AWS 관리 정책입니다. 이러한 정책은 AWS에서 제공하는 미리 정의된 정책으로, 권한 관리를 단순화하기 위해 설계되었습니다. 일반적인 사용 사례에 맞게 설계되고 AWS에서 유지 관리되므로, 광범위한 사용자 정의 없이 권한을 신속하게 구현하려는 회사에 적합합니다.",
        "Other Options": [
            "고객 관리 정책은 유연성을 제공하지만 수동으로 생성하고 관리해야 하므로, 미리 정의된 옵션을 활용하려는 회사의 목표와 일치하지 않습니다.",
            "인라인 정책은 개별 사용자, 그룹 또는 역할에 연결되어 있어 재사용성이 제한되고, 더 넓은 조직적 맥락에서 관리하기 복잡합니다.",
            "서비스 연결 정책은 특정 AWS 서비스에 대해 설계되었으며 AWS에서 자동으로 생성되지만, 회사가 찾고 있는 일반적인 사용 사례에 대한 일반 정책으로는 적합하지 않습니다."
        ]
    },
    {
        "Question Number": "61",
        "Situation": "당신은 Amazon Web Services (AWS)에서 호스팅되는 애플리케이션을 개발 중이며, 이 애플리케이션은 강력한 보안 모델이 필요합니다. 이 애플리케이션은 사용자가 조직 내에서 자신의 역할에 따라 특정 리소스에 접근할 수 있도록 합니다. 안전한 환경을 유지하기 위해 최소 권한 원칙을 구현하는 것이 중요하며, 이는 사용자가 자신의 업무를 수행하는 데 필요한 최소한의 접근 권한만 가지도록 보장합니다. 애플리케이션 아키텍처를 전략적으로 계획하면서, 세분화된 접근 제어를 용이하게 하고 민감한 리소스를 무단 접근으로부터 보호할 수 있는 가장 적합한 AWS 기능을 선택해야 합니다. 다음 중 어떤 AWS 기능이 이를 달성하는 데 도움이 될까요?",
        "Question": "AWS에서 사용자의 역할에 따라 특정 리소스에 접근할 수 있는 애플리케이션을 개발하고 있습니다. 애플리케이션이 최소 권한 원칙을 준수하고 리소스에 대한 접근을 승인된 사용자로 제한하도록 해야 합니다. 다음 중 어떤 AWS 기능이 이를 달성하는 데 도움이 될까요?",
        "Options": {
            "1": "AWS Identity and Access Management (IAM) Policies",
            "2": "AWS Key Management Service (KMS)",
            "3": "AWS Security Token Service (STS)",
            "4": "AWS Secrets Manager"
        },
        "Correct Answer": "AWS Identity and Access Management (IAM) Policies",
        "Explanation": "AWS Identity and Access Management (IAM) Policies는 AWS 리소스에 대한 권한을 관리하기 위해 특별히 설계되었습니다. 세분화된 정책을 정의함으로써 최소 권한 원칙을 시행할 수 있으며, 사용자가 자신의 역할에 필요한 리소스에만 접근할 수 있도록 보장합니다. 이 기능은 사용자별 또는 그룹별 정책을 생성하여 어떤 리소스에서 어떤 작업을 수행할 수 있는지를 정확하게 규정할 수 있게 해주므로 이 시나리오에 가장 적합한 선택입니다.",
        "Other Options": [
            "AWS Key Management Service (KMS)는 주로 암호화 키를 관리하는 데 사용되며, AWS 리소스에 대한 사용자 접근을 직접적으로 제어하지 않습니다. KMS는 데이터를 보호하는 데 중요하지만, 최소 권한 원칙을 시행하지는 않습니다.",
            "AWS Security Token Service (STS)는 사용자가 AWS 서비스에 접근할 수 있도록 임시 보안 자격 증명을 제공합니다. 그러나 STS만으로는 장기적인 접근 권한을 정의하거나 관리하지 않으며, 이는 최소 권한을 효과적으로 구현하는 데 필수적입니다.",
            "AWS Secrets Manager는 데이터베이스 자격 증명 및 API 키와 같은 비밀을 관리하는 서비스입니다. 민감한 정보를 제어하여 보안을 강화하지만, 사용자의 역할에 따라 AWS 리소스에 대한 접근을 직접적으로 관리하지는 않습니다."
        ]
    },
    {
        "Question Number": "62",
        "Situation": "개발자는 AWS Lambda에서 운영되는 서버리스 애플리케이션을 위한 로깅 전략을 구현하는 임무를 맡고 있습니다. 이 애플리케이션은 개인 정보 및 결제 데이터와 같은 민감한 사용자 정보를 처리하므로 매우 중요합니다. 이러한 데이터의 중요성을 고려할 때, 개발자는 애플리케이션에서 생성된 로그가 안전할 뿐만 아니라 쉽게 검색 가능하고 효율적인 분석을 위해 구조화되어야 함을 보장해야 합니다. 로깅 전략의 선택은 모니터링, 문제 해결 및 데이터 보호 규정을 준수하는 능력에 큰 영향을 미칠 것입니다.",
        "Question": "개발자가 서버리스 애플리케이션에서 생성된 로그의 보안, 검색 가능성 및 분석을 위한 구조적 요구 사항을 효과적으로 충족하기 위해 어떤 로깅 접근 방식을 채택해야 합니까?",
        "Options": {
            "1": "특별한 구조 없이 Amazon S3에 작성된 일반 텍스트 로그를 사용합니다.",
            "2": "로그 항목을 JSON 형식으로 포맷하고 Amazon CloudWatch Logs에 전송하여 구조화된 로깅을 구현합니다.",
            "3": "비구조적 형식을 사용하여 로그 메시지를 기록하고 Amazon DynamoDB에 저장합니다.",
            "4": "민감한 데이터의 노출을 최소화하기 위해 로깅을 비활성화합니다."
        },
        "Correct Answer": "로그 항목을 JSON 형식으로 포맷하고 Amazon CloudWatch Logs에 전송하여 구조화된 로깅을 구현합니다.",
        "Explanation": "로그 항목을 JSON 형식으로 포맷하고 Amazon CloudWatch Logs에 전송하여 구조화된 로깅을 구현하는 것은 로그의 효율적인 쿼리 및 분석을 가능하게 하므로 최선의 접근 방식입니다. JSON 형식은 키-값 쌍을 포함할 수 있어 로그를 필터링하고 검색하기 쉽게 만듭니다. CloudWatch Logs는 민감한 데이터를 처리하는 애플리케이션의 보안 및 성능 유지를 위해 필수적인 알림 및 모니터링과 같은 로그 관리 기능을 제공합니다.",
        "Other Options": [
            "Amazon S3에 작성된 일반 텍스트 로그를 사용하는 것은 구조가 부족하여 로그 검색이 비효율적이므로 민감한 정보를 처리하는 애플리케이션에는 적합하지 않습니다.",
            "비구조적 형식을 사용하여 로그 메시지를 기록하고 Amazon DynamoDB에 저장하는 것은 효과적인 분석을 위한 필요한 검색 가능성과 구조를 제공하지 않으며, 특히 데이터의 민감한 특성을 고려할 때 더욱 그렇습니다.",
            "로깅을 완전히 비활성화하는 것은 애플리케이션의 모니터링이나 문제 해결을 방지하므로 실행 가능한 옵션이 아니며, 이는 감지되지 않은 문제나 보안 위반의 위험을 증가시킵니다."
        ]
    },
    {
        "Question Number": "63",
        "Situation": "개발자는 Amazon RDS를 활용하여 읽기 중심의 애플리케이션 워크로드를 위한 강력한 솔루션을 설계하는 임무를 맡고 있습니다. 애플리케이션의 인기가 높아짐에 따라 성능을 저하시키지 않으면서 증가하는 읽기 작업을 효과적으로 수용할 필요성이 절실합니다. 개발자는 현재의 요구를 충족할 뿐만 아니라 사용자 트래픽이 증가함에 따라 원활하게 확장할 수 있는 구성을 선택하는 것이 중요합니다.",
        "Question": "애플리케이션의 요구 사항을 고려할 때, 개발자가 증가하는 읽기 작업을 최적의 방식으로 처리하기 위해 선택해야 할 구성은 무엇입니까?",
        "Options": {
            "1": "RDS 인스턴스에 대해 Multi-AZ 배포를 활성화합니다.",
            "2": "RDS 인스턴스에서 투명 데이터 암호화(TDE)를 활성화합니다.",
            "3": "RDS 인스턴스에 대해 하나 이상의 읽기 복제본을 생성합니다.",
            "4": "쿼리 성능을 최적화하기 위해 느린 쿼리 로그를 활성화합니다."
        },
        "Correct Answer": "RDS 인스턴스에 대해 하나 이상의 읽기 복제본을 생성합니다.",
        "Explanation": "RDS 인스턴스에 대해 하나 이상의 읽기 복제본을 생성하는 것은 읽기 중심의 애플리케이션에 가장 적합한 구성 선택입니다. 읽기 복제본은 읽기 작업의 수평적 확장을 가능하게 하여 여러 인스턴스에 읽기 트래픽을 분산시킵니다. 이는 성능을 효과적으로 개선하고 기본 데이터베이스 인스턴스의 부하를 줄여 애플리케이션이 증가하는 읽기 요청을 효율적으로 처리할 수 있도록 보장합니다.",
        "Other Options": [
            "Multi-AZ 배포를 활성화하는 것은 주로 고가용성 및 장애 조치 지원에 중점을 두며, 읽기 작업의 확장과는 관련이 없습니다. 데이터 중복성과 신뢰성을 향상시키지만, 증가하는 읽기 트래픽을 처리하는 필요를 해결하지는 않습니다.",
            "투명 데이터 암호화(TDE)를 활성화하는 것은 데이터 보안 및 저장 시 암호화와 관련이 있으며, 읽기 작업의 성능이나 확장성에 영향을 미치지 않습니다. 이 옵션은 읽기 중심의 워크로드를 관리하는 데 이점을 제공하지 않습니다.",
            "느린 쿼리 로그를 활성화하면 쿼리 내 성능 문제를 식별하는 데 도움이 될 수 있지만, 읽기 작업을 처리하는 능력을 본질적으로 증가시키지는 않습니다. 이 옵션은 최적화에 중점을 두며, 증가하는 읽기 요청을 관리하는 데 적합하지 않습니다."
        ]
    },
    {
        "Question Number": "64",
        "Situation": "한 회사가 여러 환경에서 애플리케이션을 자동으로 빌드, 테스트 및 배포하는 CI/CD 파이프라인을 구현해야 합니다. 이들은 CodeCommit, CodeBuild 및 CodeDeploy와 같은 AWS 서비스와 GitHub 및 Jenkins와 같은 서드파티 도구와 통합할 수 있는 도구가 필요합니다.",
        "Question": "회사가 CI/CD 파이프라인을 효과적으로 관리하기 위해 어떤 AWS 서비스를 사용해야 합니까?",
        "Options": {
            "1": "AWS CodeDeploy",
            "2": "AWS CodePipeline",
            "3": "AWS CodeBuild",
            "4": "AWS CloudFormation"
        },
        "Correct Answer": "AWS CodePipeline",
        "Explanation": "AWS CodePipeline은 CI/CD 파이프라인을 구현하는 데 이상적인 서비스로, 파이프라인의 다양한 단계를 조정하며 CodeCommit, CodeBuild 및 CodeDeploy와 같은 여러 AWS 서비스와 GitHub 및 Jenkins와 같은 서드파티 도구와의 통합을 허용합니다. 빌드, 테스트 및 배포 프로세스를 자동화하여 회사의 요구에 대한 포괄적인 솔루션을 제공합니다.",
        "Other Options": [
            "AWS CodeDeploy는 주로 애플리케이션의 배포에 중점을 둡니다. CI/CD 프로세스의 중요한 부분이지만, 빌드 및 테스트 단계를 포함한 전체 파이프라인을 관리하지는 않습니다.",
            "AWS CodeBuild는 소스 코드를 컴파일하고, 테스트를 실행하며, 소프트웨어 패키지를 생성하는 서비스입니다. 그러나 완전한 CI/CD 파이프라인에 필요한 조정 및 관리 기능을 제공하지 않습니다.",
            "AWS CloudFormation은 AWS 인프라를 코드로 정의하고 프로비저닝하는 데 사용됩니다. 지속적인 통합 및 배포 프로세스를 직접 지원하지 않으므로 CI/CD 파이프라인을 관리하는 데 적합하지 않습니다."
        ]
    },
    {
        "Question Number": "65",
        "Situation": "개발자가 평균 4 KB 크기의 항목을 저장할 DynamoDB 테이블을 설계하는 과정에 있습니다. 이 애플리케이션은 매초 50개의 강력하게 일관된 읽기를 처리해야 하며, 이를 통해 사용자가 실시간으로 가장 정확하고 최신 정보를 받을 수 있도록 해야 합니다.",
        "Question": "애플리케이션의 요구 사항을 고려할 때, 4 KB 크기의 각 항목에 대해 매초 50개의 강력하게 일관된 읽기를 수용하기 위해 필요한 읽기 용량 단위(RCUs)는 몇 개입니까?",
        "Options": {
            "1": "25",
            "2": "50",
            "3": "100",
            "4": "200"
        },
        "Correct Answer": "100",
        "Explanation": "DynamoDB에서 강력하게 일관된 읽기를 위한 필요한 읽기 용량 단위(RCUs)를 계산하기 위해 다음 공식을 사용할 수 있습니다: RCUs = (항목 크기(KB) * 읽기 수) / 4. 이 경우 항목 크기는 4 KB이고, 매초 필요한 강력하게 일관된 읽기 수는 50입니다. 따라서 RCUs = (4 * 50) / 4 = 50이지만, 강력하게 일관된 읽기는 RCUs의 두 배가 필요하므로 총합은 50 * 2 = 100이 됩니다.",
        "Other Options": [
            "25는 항목 크기와 읽기 빈도로 인해 강력하게 일관된 읽기의 요구 사항을 고려하지 않기 때문에 잘못된 답변입니다.",
            "50은 초당 읽기 수와 일치하는 것처럼 보일 수 있지만, 4 KB 항목의 각 강력하게 일관된 읽기가 실제로 2 RCUs를 필요로 한다는 점을 고려하지 않아 과소 평가됩니다.",
            "200은 계산을 잘못 적용하거나 지정된 것보다 더 큰 항목 크기를 가정하여 필요 이상으로 요구 사항을 두 배로 늘려 RCUs의 수를 과대 평가하므로 잘못된 답변입니다."
        ]
    }
]