[
    {
        "Question Number": "1",
        "Situation": "Uma empresa de mídia está desenvolvendo um aplicativo que requer acesso compartilhado a arquivos para várias instâncias EC2. O aplicativo processará arquivos multimídia que mudam com frequência e precisam ser acessíveis com semântica de sistema de arquivos POSIX. A empresa está considerando usar o Amazon EFS para esse propósito e quer garantir a disponibilidade e durabilidade dos dados em caso de falhas regionais.",
        "Question": "Qual configuração a empresa deve implementar para garantir alta disponibilidade e recuperação rápida de seu sistema de arquivos Amazon EFS em várias Regiões da AWS?",
        "Options": {
            "1": "Criar um sistema de arquivos Amazon EFS e habilitar a replicação para outro sistema de arquivos Amazon EFS em uma Região da AWS diferente.",
            "2": "Configurar uma instância EC2 para gerenciar transferências de arquivos entre o sistema de arquivos EFS primário e um sistema de arquivos EFS secundário em uma região diferente.",
            "3": "Usar o Amazon S3 para armazenamento de arquivos e configurar uma política de ciclo de vida do S3 para arquivar arquivos multimídia mais antigos.",
            "4": "Implantar o sistema de arquivos Amazon EFS em uma única Zona de Disponibilidade e usar o AWS Backup para criar backups regulares."
        },
        "Correct Answer": "Criar um sistema de arquivos Amazon EFS e habilitar a replicação para outro sistema de arquivos Amazon EFS em uma Região da AWS diferente.",
        "Explanation": "Habilitar a replicação para um sistema de arquivos Amazon EFS permite a sincronização automática e contínua de dados entre os sistemas de arquivos primário e secundário em diferentes regiões. Isso proporciona alta disponibilidade e atende aos objetivos de ponto de recuperação e tempo de recuperação exigidos pela empresa.",
        "Other Options": [
            "Implantar o sistema de arquivos Amazon EFS em uma única Zona de Disponibilidade não fornece a durabilidade e disponibilidade necessárias em caso de falha regional, pois está limitado a uma zona.",
            "Usar o Amazon S3 não é adequado para aplicativos que requerem semântica de sistema de arquivos compatível com POSIX, que são necessárias para o aplicativo de processamento multimídia.",
            "Configurar uma instância EC2 para gerenciar transferências de arquivos adiciona complexidade desnecessária e não fornece a replicação automatizada e contínua que o EFS oferece."
        ]
    },
    {
        "Question Number": "2",
        "Situation": "Uma empresa de mídia opera uma plataforma de streaming de vídeo utilizando recursos da AWS, incluindo várias instâncias EC2 para processar uploads de vídeo e um Elastic Load Balancer (ELB) para distribuir o tráfego de entrada. Os usuários relataram buffering intermitente e tempos de carregamento lentos durante as horas de pico. O arquiteto de soluções precisa elaborar uma estratégia para melhorar o desempenho do aplicativo enquanto otimiza os custos.",
        "Question": "Qual das seguintes estratégias melhoraria o desempenho da plataforma de streaming de vídeo durante as horas de pico?",
        "Options": {
            "1": "Aumentar os tipos de instância da frota EC2 para tamanhos maiores e alocar endereços IP Elásticos adicionais para lidar com mais solicitações de usuários simultaneamente.",
            "2": "Migrar as tarefas de processamento de vídeo para um serviço gerenciado como o AWS Lambda e usar o S3 para armazenar arquivos de vídeo com acesso direto dos usuários.",
            "3": "Implementar Auto Scaling para as instâncias EC2 com base em métricas de utilização da CPU e configurar uma distribuição CloudFront para armazenar em cache o conteúdo de vídeo mais próximo dos usuários.",
            "4": "Implantar uma única instância EC2 maior para lidar com todas as tarefas de processamento de vídeo e garantir que a instância tenha um volume EBS anexado com IOPS provisionados."
        },
        "Correct Answer": "Implementar Auto Scaling para as instâncias EC2 com base em métricas de utilização da CPU e configurar uma distribuição CloudFront para armazenar em cache o conteúdo de vídeo mais próximo dos usuários.",
        "Explanation": "Implementar Auto Scaling permite que o aplicativo ajuste dinamicamente o número de instâncias EC2 com base na demanda real, o que ajuda a gerenciar picos de tráfego de forma eficaz. Além disso, usar o CloudFront como uma rede de entrega de conteúdo (CDN) reduz a latência ao armazenar em cache o conteúdo de vídeo mais próximo dos usuários, melhorando significativamente os tempos de carregamento e reduzindo problemas de buffering.",
        "Other Options": [
            "Aumentar os tipos de instância pode fornecer mais recursos, mas não aborda a escalabilidade necessária durante as horas de pico e pode levar a custos mais altos sem garantir desempenho ideal.",
            "Implantar uma única instância EC2 maior cria um único ponto de falha e não escala efetivamente durante o uso intenso. Esta opção também não utiliza os benefícios do balanceamento de carga ou redundância.",
            "Migrar para o AWS Lambda pode não ser adequado para tarefas de processamento de vídeo que requerem tempos de execução mais longos, pois o Lambda tem um limite de tempo. Além disso, esta opção não aborda os problemas imediatos de desempenho relacionados às solicitações dos usuários."
        ]
    },
    {
        "Question Number": "3",
        "Situation": "Uma empresa gerencia uma grande frota de instâncias Amazon EC2 que fazem parte de uma infraestrutura de aplicativo dinâmica. A infraestrutura precisa ser mantida de forma eficiente, garantindo conformidade com políticas de segurança e melhores práticas operacionais. A empresa está considerando implementar uma solução de gerenciamento de configuração para automatizar tarefas operacionais, como patching, monitoramento e gerenciamento de inventário.",
        "Question": "Qual dos seguintes serviços da AWS atenderia melhor aos requisitos da empresa para gerenciamento de configuração neste cenário?",
        "Options": {
            "1": "Implementar o AWS CloudFormation para gerenciar infraestrutura como código e automatizar a implantação de instâncias EC2.",
            "2": "Usar o AWS Systems Manager para automatizar tarefas operacionais em todas as instâncias EC2 e garantir conformidade com as políticas de segurança.",
            "3": "Aproveitar o Amazon CloudWatch para monitorar o desempenho do aplicativo e gerar alertas com base em métricas.",
            "4": "Utilizar o AWS Config para rastrear configurações de recursos e garantir conformidade com as políticas da empresa."
        },
        "Correct Answer": "Usar o AWS Systems Manager para automatizar tarefas operacionais em todas as instâncias EC2 e garantir conformidade com as políticas de segurança.",
        "Explanation": "O AWS Systems Manager fornece um conjunto abrangente de ferramentas para gerenciamento de configuração, permitindo a automação de tarefas operacionais, gerenciamento de patches e monitoramento de conformidade. Ele é projetado especificamente para gerenciar grandes frotas de instâncias de forma eficiente.",
        "Other Options": [
            "O AWS CloudFormation é focado em provisionar e gerenciar recursos da AWS como código, em vez de automatizar tarefas operacionais contínuas, tornando-o menos adequado para as necessidades da empresa neste contexto.",
            "O AWS Config é usado principalmente para rastrear configurações de recursos e conformidade, mas não automatiza tarefas operacionais como patching ou monitoramento, que são cruciais neste cenário.",
            "O Amazon CloudWatch é principalmente um serviço de monitoramento que rastreia métricas e logs, mas não fornece as capacidades de gerenciamento de configuração necessárias para automatizar tarefas operacionais e garantir conformidade."
        ]
    },
    {
        "Question Number": "4",
        "Situation": "Uma empresa de serviços financeiros está analisando seus gastos com a nuvem na AWS. Eles têm uma mistura de projetos de curto prazo e operações de longo prazo. A empresa deseja otimizar custos enquanto garante que tenha a flexibilidade para se adaptar às necessidades de negócios em mudança. Eles estão particularmente interessados em minimizar custos para suas cargas de trabalho em estado estável e estão considerando vários modelos de preços.",
        "Question": "Qual modelo de preços o Arquiteto de Soluções deve recomendar para otimizar os custos da empresa enquanto mantém a flexibilidade para projetos de curto prazo?",
        "Options": {
            "1": "Comprar Instâncias Reservadas para todas as instâncias do Amazon EC2 para garantir a menor taxa horária ao longo de um ou três anos.",
            "2": "Utilizar Savings Plans que oferecem flexibilidade entre diferentes famílias de instâncias e regiões, proporcionando economias significativas em relação ao preço On-Demand.",
            "3": "Usar apenas Instâncias On-Demand para evitar qualquer compromisso de longo prazo e manter a máxima flexibilidade.",
            "4": "Aproveitar Instâncias Spot para todas as cargas de trabalho para alcançar o menor preço possível sem qualquer forma de compromisso."
        },
        "Correct Answer": "Utilizar Savings Plans que oferecem flexibilidade entre diferentes famílias de instâncias e regiões, proporcionando economias significativas em relação ao preço On-Demand.",
        "Explanation": "Savings Plans fornecem um modelo de preços flexível que permite à empresa otimizar custos ao se comprometer com uma certa quantidade de uso por um período de um ou três anos. Este modelo suporta vários tipos de instâncias e regiões, tornando-o ideal para cargas de trabalho em estado estável e flutuantes.",
        "Other Options": [
            "Comprar Instâncias Reservadas garantiria preços mais baixos, mas à custa da flexibilidade, o que não é adequado para uma empresa com projetos de curto e longo prazo.",
            "Usar apenas Instâncias On-Demand pode proporcionar máxima flexibilidade, mas não otimiza os custos de forma eficaz, levando a despesas mais altas em comparação com Savings Plans.",
            "Aproveitar Instâncias Spot oferece os preços mais baixos, mas introduz o risco de interrupções, tornando-o inadequado para cargas de trabalho em estado estável que requerem confiabilidade."
        ]
    },
    {
        "Question Number": "5",
        "Situation": "Uma empresa de serviços financeiros está planejando implementar uma nova solução de armazenamento de dados para suas aplicações locais que requerem alta disponibilidade e acesso rápido a dados frequentemente utilizados. A empresa está considerando usar o AWS Storage Gateway e precisa escolher entre Volumes em Cache e Volumes Armazenados. Eles querem garantir que tenham acesso de baixa latência a todo o seu conjunto de dados enquanto ainda utilizam armazenamento em nuvem para backups.",
        "Question": "Qual das seguintes configurações a empresa deve escolher para atender melhor aos seus requisitos de acesso de baixa latência a todo o conjunto de dados, enquanto também aproveita o armazenamento em nuvem para backups?",
        "Options": {
            "1": "Implantar o Volume Gateway em uma configuração híbrida onde os dados são acessados diretamente do Amazon S3 sem nenhum armazenamento local.",
            "2": "Usar uma combinação de Volumes em Cache e Volumes Armazenados para permitir o armazenamento local de dados frequentemente acessados e manter backups no Amazon S3.",
            "3": "Configurar o Volume Gateway para usar Volumes em Cache, onde os dados são armazenados no Amazon S3 e os dados frequentemente acessados são retidos localmente.",
            "4": "Configurar o Volume Gateway para usar Volumes Armazenados, permitindo que todos os dados sejam armazenados localmente primeiro e copiados assíncronamente para o Amazon S3."
        },
        "Correct Answer": "Configurar o Volume Gateway para usar Volumes Armazenados, permitindo que todos os dados sejam armazenados localmente primeiro e copiados assíncronamente para o Amazon S3.",
        "Explanation": "Volumes Armazenados fornecem acesso de baixa latência a todo o conjunto de dados armazenando todos os dados localmente, o que é crucial para aplicações que requerem desempenho rápido. Além disso, os dados podem ser copiados assíncronamente para o Amazon S3, atendendo ao requisito de backups em nuvem.",
        "Other Options": [
            "Volumes em Cache retêm apenas dados frequentemente acessados localmente, o que não atende ao requisito de acesso de baixa latência a todo o conjunto de dados.",
            "Usar uma combinação de Volumes em Cache e Volumes Armazenados é desnecessário e pode complicar a arquitetura, já que os Volumes Armazenados sozinhos atendem aos requisitos de forma eficaz.",
            "Implantar o Volume Gateway em uma configuração híbrida sem armazenamento local não fornece acesso de baixa latência e não é adequado para aplicações que precisam de disponibilidade imediata dos dados."
        ]
    },
    {
        "Question Number": "6",
        "Situation": "Uma empresa de serviços financeiros está buscando automatizar sua gestão de configuração em várias contas e regiões da AWS para garantir conformidade e reduzir erros manuais. Eles querem uma solução que se integre bem com os serviços existentes da AWS e suporte ambientes Linux e Windows. A solução também deve fornecer controle de versão e capacidades de auditoria.",
        "Question": "Qual serviço da AWS o arquiteto de soluções deve recomendar para habilitar a automação da gestão de configuração?",
        "Options": {
            "1": "AWS CloudFormation com StackSets para gerenciamento entre contas",
            "2": "AWS Config com AWS Systems Manager para verificações de conformidade",
            "3": "AWS OpsWorks com Chef para gestão de configuração",
            "4": "AWS Systems Manager com recursos de State Manager e Automação"
        },
        "Correct Answer": "AWS Systems Manager com recursos de State Manager e Automação",
        "Explanation": "AWS Systems Manager fornece um conjunto abrangente de ferramentas para gestão de configuração, incluindo o State Manager para impor estados desejados e Automação para executar scripts em instâncias. Este serviço suporta ambientes Linux e Windows e oferece controle de versão e capacidades de auditoria, tornando-o ideal para as necessidades da empresa.",
        "Other Options": [
            "AWS CloudFormation é usado principalmente para provisionamento e gerenciamento de infraestrutura, não especificamente para gestão de configuração e automação contínuas, que são necessárias neste caso.",
            "AWS Config é focado em conformidade e monitoramento de recursos, em vez de automação da gestão de configuração. Embora possa funcionar com o Systems Manager, não lida diretamente com o aspecto de automação.",
            "AWS OpsWorks é um serviço de gestão de configuração que usa Chef, mas é menos integrado com outros serviços da AWS em comparação com o Systems Manager, tornando-o uma escolha menos ideal para este requisito específico."
        ]
    },
    {
        "Question Number": "7",
        "Situation": "Uma empresa de serviços financeiros está implantando um novo aplicativo de alta disponibilidade que requer várias instâncias do Amazon EC2 para acessar dados compartilhados simultaneamente. O aplicativo foi projetado para lidar com cargas de trabalho de alta I/O e usará o Amazon EBS para armazenamento. O arquiteto precisa garantir que os volumes do EBS possam ser compartilhados entre várias instâncias do EC2 para melhorar o tempo de atividade e a disponibilidade do aplicativo.",
        "Question": "Qual das seguintes configurações o Arquiteto de Soluções deve implementar para atender aos requisitos do aplicativo? (Selecione Dois)",
        "Options": {
            "1": "Anexar um único volume SSD de IOPS Provisionados a cada instância do EC2 para minimizar problemas de latência.",
            "2": "Usar o Amazon EBS Multi-Attach para conectar um único volume SSD de IOPS Provisionados a várias instâncias do EC2 dentro da mesma Zona de Disponibilidade.",
            "3": "Usar o Amazon EBS Multi-Attach para conectar vários volumes HDD Otimizados para Throughput a uma única instância do EC2.",
            "4": "Implantar vários volumes padrão do Amazon EBS em cada instância do EC2 e configurá-los para replicar dados entre instâncias manualmente.",
            "5": "Implementar o Amazon EFS para fornecer um sistema de arquivos compartilhado que pode ser acessado por várias instâncias do EC2 simultaneamente."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Usar o Amazon EBS Multi-Attach para conectar um único volume SSD de IOPS Provisionados a várias instâncias do EC2 dentro da mesma Zona de Disponibilidade.",
            "Implementar o Amazon EFS para fornecer um sistema de arquivos compartilhado que pode ser acessado por várias instâncias do EC2 simultaneamente."
        ],
        "Explanation": "Usar o Amazon EBS Multi-Attach permite que um único volume SSD de IOPS Provisionados seja anexado a várias instâncias do EC2, proporcionando alta disponibilidade e desempenho para cargas de trabalho que requerem acesso simultâneo de leitura e gravação. Além disso, o Amazon EFS oferece uma solução de armazenamento de arquivos escalável que pode ser acessada por várias instâncias, sendo também adequada para aplicativos de alta disponibilidade.",
        "Other Options": [
            "Implantar vários volumes padrão do EBS e replicar dados manualmente é ineficiente e não fornece a alta disponibilidade ou simplicidade necessária para acesso simultâneo.",
            "Usar o EBS Multi-Attach com vários volumes HDD Otimizados para Throughput anexados a uma única instância do EC2 não atende ao requisito de compartilhar um volume entre várias instâncias.",
            "Anexar um único volume SSD de IOPS Provisionados a cada instância do EC2 não permite acesso compartilhado e não melhora o tempo de atividade ou a disponibilidade entre instâncias."
        ]
    },
    {
        "Question Number": "8",
        "Situation": "Uma empresa de serviços financeiros está planejando migrar seus aplicativos locais para a AWS. A empresa deseja avaliar seu portfólio de aplicativos existente e acompanhar o progresso da migração em diferentes serviços da AWS. Ela precisa de uma ferramenta centralizada para visualizar o status da migração e receber recomendações para os serviços da AWS mais adequados durante o processo de migração.",
        "Question": "Quais das seguintes ferramentas são adequadas para avaliação e acompanhamento de migração? (Selecione Dois)",
        "Options": {
            "1": "AWS Cost Explorer",
            "2": "AWS CloudTrail",
            "3": "AWS Migration Hub",
            "4": "AWS Config",
            "5": "AWS Application Discovery Service"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "AWS Migration Hub",
            "AWS Application Discovery Service"
        ],
        "Explanation": "O AWS Migration Hub fornece um local central para acompanhar o progresso das migrações de aplicativos em ambientes da AWS e locais. Ele permite que os usuários visualizem o status da migração e obtenham insights sobre onde otimizar recursos. O AWS Application Discovery Service ajuda a identificar dependências de aplicativos e utilização de recursos, o que é essencial para avaliar o portfólio existente durante a migração.",
        "Other Options": [
            "O AWS CloudTrail é usado principalmente para rastrear chamadas de API e mudanças em contas da AWS para fins de segurança e conformidade, não especificamente para avaliação ou acompanhamento de migração.",
            "O AWS Cost Explorer é focado na análise e gerenciamento de custos da AWS, em vez de auxiliar no processo de migração ou avaliar portfólios de aplicativos.",
            "O AWS Config é usado principalmente para gerenciamento de configuração de recursos e monitoramento de conformidade na AWS, e não fornece funcionalidades específicas de avaliação ou acompanhamento de migração."
        ]
    },
    {
        "Question Number": "9",
        "Situation": "Uma empresa de serviços financeiros opera um aplicativo crítico que processa transações em tempo real. O aplicativo está hospedado na AWS e foi projetado para manter alta disponibilidade para seus usuários. No entanto, a empresa está preocupada com possíveis interrupções devido a desastres naturais ou outros eventos catastróficos. Eles desejam implementar uma estratégia de recuperação de desastres que minimize o tempo de inatividade e a perda de dados, garantindo a conformidade com os requisitos regulatórios. A empresa tem opções para diferentes estratégias de recuperação de desastres e busca orientação sobre a melhor abordagem.",
        "Question": "Qual estratégia de recuperação de desastres a empresa deve implementar para alcançar o mínimo de tempo de inatividade e perda de dados para seu aplicativo crítico?",
        "Options": {
            "1": "Utilizar uma estratégia de luz piloto, mantendo uma versão mínima do aplicativo em outra região que pode ser rapidamente escalada em caso de falha.",
            "2": "Adotar uma estratégia de múltiplos sites com configuração ativa-ativa, onde o aplicativo é executado simultaneamente em várias regiões da AWS para garantir alta disponibilidade.",
            "3": "Implementar uma estratégia de espera quente onde uma versão reduzida do aplicativo é executada em outra região da AWS, pronta para assumir em caso de falha.",
            "4": "Usar o AWS Elastic Disaster Recovery para replicar continuamente o aplicativo e restaurá-lo rapidamente em um novo ambiente em caso de desastre."
        },
        "Correct Answer": "Usar o AWS Elastic Disaster Recovery para replicar continuamente o aplicativo e restaurá-lo rapidamente em um novo ambiente em caso de desastre.",
        "Explanation": "O AWS Elastic Disaster Recovery fornece uma maneira eficiente e automatizada de replicar continuamente seus aplicativos, garantindo que você possa restaurá-los rapidamente em um novo ambiente com o mínimo de tempo de inatividade e perda de dados. Essa abordagem se alinha perfeitamente com os requisitos da empresa para alta disponibilidade e conformidade.",
        "Other Options": [
            "Implementar uma estratégia de espera quente envolve manter uma versão reduzida do aplicativo. Embora possa proporcionar um tempo de recuperação reduzido, pode não atender totalmente ao requisito de mínimo tempo de inatividade e perda de dados em comparação com a replicação contínua.",
            "Uma estratégia de múltiplos sites com configuração ativa-ativa pode ser complexa e cara, pois requer a execução de instâncias em plena escala em várias regiões. Embora forneça alta disponibilidade, pode não ser a solução mais eficiente para todos os cenários, especialmente para uma empresa que busca minimizar custos.",
            "Utilizar uma estratégia de luz piloto envolve manter uma versão mínima do aplicativo que pode ser escalada. Essa estratégia pode levar a tempos de recuperação mais longos, o que pode não se alinhar com a necessidade da empresa de mínimo tempo de inatividade em situações críticas."
        ]
    },
    {
        "Question Number": "10",
        "Situation": "Uma empresa de serviços financeiros está experimentando um crescimento rápido e precisa garantir que sua aplicação web possa lidar com cargas de tráfego variáveis enquanto minimiza custos. A aplicação é executada em instâncias do Amazon EC2 e deve manter alta disponibilidade e desempenho. O Arquiteto de Soluções deve projetar uma arquitetura que permita escalonamento dinâmico com base nos padrões de tráfego e utilize recursos de forma otimizada em várias zonas de disponibilidade.",
        "Question": "Quais das seguintes ações o Arquiteto de Soluções deve implementar para atender aos requisitos da empresa? (Selecione Dois)",
        "Options": {
            "1": "Utilizar grupos de colocação para garantir que todas as instâncias do EC2 estejam localizadas na mesma zona de disponibilidade para baixa latência.",
            "2": "Usar Instâncias Spot do Amazon EC2 para reduzir custos enquanto garante que capacidade suficiente esteja disponível durante os horários de pico.",
            "3": "Implantar a aplicação em vários tipos de instâncias do EC2 dentro de um grupo de Auto Scaling para otimizar desempenho e custo.",
            "4": "Implementar o Auto Scaling do Amazon EC2 com uma política de escalonamento de rastreamento de alvo baseada na utilização média da CPU.",
            "5": "Configurar um Amazon Elastic Load Balancer (ELB) com sessões persistentes para manter as informações da sessão dos usuários."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Implementar o Auto Scaling do Amazon EC2 com uma política de escalonamento de rastreamento de alvo baseada na utilização média da CPU.",
            "Usar Instâncias Spot do Amazon EC2 para reduzir custos enquanto garante que capacidade suficiente esteja disponível durante os horários de pico."
        ],
        "Explanation": "Implementar o Auto Scaling do Amazon EC2 com uma política de escalonamento de rastreamento de alvo permite que a aplicação ajuste dinamicamente a capacidade com base na carga atual, garantindo alta disponibilidade e desempenho. Usar Instâncias Spot do EC2 ajuda a otimizar custos ao utilizar a capacidade excedente na nuvem da AWS, o que é uma ótima maneira de gerenciar despesas sem sacrificar o desempenho.",
        "Other Options": [
            "Usar um ELB com sessões persistentes pode levar a uma distribuição desigual do tráfego e não é ideal para arquiteturas escaláveis, especialmente sob cargas variáveis, pois pode causar sobrecarga em algumas instâncias enquanto outras permanecem subutilizadas.",
            "Implantar em vários tipos de instâncias é uma boa prática para otimizar a utilização de recursos, mas não aborda diretamente os requisitos de escalonamento tão efetivamente quanto usar Auto Scaling com rastreamento de alvo.",
            "Utilizar grupos de colocação pode melhorar o desempenho da rede ao garantir baixa latência entre as instâncias, mas não fornece inherentemente escalonamento dinâmico ou otimização de custos, que são críticos para gerenciar cargas variáveis."
        ]
    },
    {
        "Question Number": "11",
        "Situation": "Sua organização está gerenciando várias contas da AWS para facilitar diferentes equipes e projetos. No entanto, há preocupações em relação à governança, gerenciamento de custos e segurança entre essas contas. A liderança está buscando uma maneira de implementar um modelo de governança que garanta conformidade, faturamento centralizado e gerenciamento eficaz de acesso para todas as contas. (Selecione Dois)",
        "Question": "Quais das seguintes ações ajudarão a estabelecer um robusto modelo de governança multi-conta na AWS?",
        "Options": {
            "1": "Gerenciar manualmente o faturamento para cada conta para manter a visibilidade das despesas.",
            "2": "Usar um provedor de identidade externo para gerenciamento de acesso federado entre contas.",
            "3": "Implementar o AWS Organizations para gerenciar contas de forma centralizada e aplicar políticas de controle de serviço.",
            "4": "Ativar o AWS CloudTrail em todas as contas para registro centralizado da atividade da API.",
            "5": "Criar uma conta separada da AWS para cada equipe e permitir acesso irrestrito a todos os serviços da AWS."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Implementar o AWS Organizations para gerenciar contas de forma centralizada e aplicar políticas de controle de serviço.",
            "Ativar o AWS CloudTrail em todas as contas para registro centralizado da atividade da API."
        ],
        "Explanation": "Implementar o AWS Organizations permite gerenciar centralmente várias contas e aplicar políticas de controle de serviço para impor governança em todas as contas. Ativar o AWS CloudTrail garante que você tenha registro centralizado da atividade da API, o que é crucial para conformidade e auditoria.",
        "Other Options": [
            "Criar uma conta separada da AWS para cada equipe com acesso irrestrito apresenta riscos significativos de segurança e não impõe nenhum modelo de governança.",
            "Usar um provedor de identidade externo para gerenciamento de acesso federado pode ser benéfico, mas não é um modelo de governança autônomo e carece do controle mais amplo que o AWS Organizations oferece.",
            "Gerenciar manualmente o faturamento para cada conta é ineficiente e não fornece a visão centralizada dos custos que o AWS Organizations pode oferecer."
        ]
    },
    {
        "Question Number": "12",
        "Situation": "Uma aplicação de saúde processa dados de pacientes e se comunica com vários serviços de terceiros para análises e relatórios. Atualmente, todos os serviços estão fortemente acoplados, causando problemas de latência e dificultando a implementação de mudanças. O Arquiteto de Soluções precisa identificar oportunidades para desacoplar os componentes da aplicação para melhorar o desempenho e a manutenibilidade.",
        "Question": "Qual das seguintes soluções desacoplará melhor os componentes da aplicação enquanto melhora o desempenho e a manutenibilidade?",
        "Options": {
            "1": "Migrar a aplicação para o Amazon ECS, garantindo que cada serviço se comunique diretamente com os outros usando chamadas HTTP para manter o acoplamento forte.",
            "2": "Refatorar a aplicação para rodar inteiramente no AWS Lambda, utilizando chamadas síncronas para todos os serviços de terceiros para processamento de dados em tempo real.",
            "3": "Implementar o Amazon SQS para enfileirar solicitações entre a aplicação e serviços de terceiros, permitindo que eles processem mensagens de forma independente.",
            "4": "Usar o Amazon API Gateway para criar APIs RESTful para cada componente, permitindo escalonamento e comunicação independentes entre os serviços."
        },
        "Correct Answer": "Usar o Amazon API Gateway para criar APIs RESTful para cada componente, permitindo escalonamento e comunicação independentes entre os serviços.",
        "Explanation": "Usar o Amazon API Gateway para criar APIs RESTful permite que cada componente se comunique de forma independente e escale conforme necessário. Essa abordagem desacopla efetivamente os serviços, permitindo atualizações e manutenção mais fáceis sem afetar toda a aplicação.",
        "Other Options": [
            "Implementar o Amazon SQS é uma boa prática para desacoplamento, mas pode não aproveitar totalmente as capacidades de escalonamento independente e gerenciamento de API tão efetivamente quanto o API Gateway.",
            "Refatorar a aplicação para rodar inteiramente no AWS Lambda com chamadas síncronas introduz um risco de latência e acoplamento forte, contradizendo o objetivo de desacoplar os componentes.",
            "Migrar a aplicação para o Amazon ECS e usar chamadas HTTP entre serviços mantém o acoplamento forte e não aborda a necessidade de escalonamento independente ou melhor manutenibilidade."
        ]
    },
    {
        "Question Number": "13",
        "Situation": "Uma empresa precisa migrar suas cargas de trabalho de transferência de arquivos existentes para a AWS usando o Protocolo de Transferência de Arquivos Secure Shell (SFTP). Eles querem garantir que os usuários possam continuar usando seus clientes SFTP existentes sem alterações. Além disso, a empresa deseja autenticar os usuários usando uma combinação de identidades gerenciadas pelo serviço e seu provedor de identidade corporativo. Os arquivos transferidos devem ser armazenados em um bucket do Amazon S3. O arquiteto de soluções é encarregado de implementar uma solução que atenda a esses requisitos enquanto minimiza a sobrecarga operacional.",
        "Question": "Qual das seguintes soluções o Arquiteto de Soluções deve implementar para satisfazer os requisitos da empresa?",
        "Options": {
            "1": "Implantar uma instância EC2 executando um aplicativo de servidor SFTP e configurá-la para usar funções IAM para autenticação. Configurar um script para transferir arquivos para um bucket do Amazon S3 após cada upload.",
            "2": "Criar um servidor SFTP da AWS Transfer Family e configurá-lo para usar identidades gerenciadas pelo serviço para autenticação. Mapear o domínio para o endpoint do servidor e selecionar o bucket do Amazon S3 apropriado para armazenamento.",
            "3": "Implementar um servidor SFTP da AWS Transfer Family com um provedor de identidade personalizado para autenticação de usuários. Configurar o servidor para transferir arquivos diretamente para um sistema de arquivos Amazon EFS para armazenamento.",
            "4": "Configurar uma função Lambda para lidar com solicitações SFTP e autenticar usuários usando o AWS SDK. Armazenar arquivos transferidos em um banco de dados Amazon RDS."
        },
        "Correct Answer": "Criar um servidor SFTP da AWS Transfer Family e configurá-lo para usar identidades gerenciadas pelo serviço para autenticação. Mapear o domínio para o endpoint do servidor e selecionar o bucket do Amazon S3 apropriado para armazenamento.",
        "Explanation": "Usar a AWS Transfer Family permite a integração perfeita de cargas de trabalho SFTP com mínima sobrecarga de gerenciamento. Ele suporta identidades gerenciadas pelo serviço para autenticação e se integra diretamente ao Amazon S3 para armazenamento de arquivos, atendendo a todos os requisitos da empresa.",
        "Other Options": [
            "Implantar uma instância EC2 para SFTP introduz complexidade adicional de gerenciamento e não aproveita os recursos integrados da AWS Transfer Family para cargas de trabalho SFTP.",
            "Usar um provedor de identidade personalizado com a AWS Transfer Family é desnecessário, uma vez que identidades gerenciadas pelo serviço são suficientes para as necessidades da empresa, e transferir arquivos para um sistema de arquivos EFS não está alinhado com o requisito de usar S3.",
            "Implementar uma função Lambda para manipulação de SFTP é excessivamente complexo e não é adequado para transferências de arquivos de alta frequência. Além disso, o RDS não é apropriado para armazenamento de arquivos, pois é projetado para dados estruturados."
        ]
    },
    {
        "Question Number": "14",
        "Situation": "Uma organização de saúde precisa gerenciar de forma segura o acesso e as permissões dos usuários para seus funcionários que requerem diferentes níveis de acesso aos dados dos pacientes armazenados na AWS. A organização deseja garantir que o controle de acesso seja gerenciado centralmente e possa se integrar facilmente ao Active Directory da Microsoft existente no local. O arquiteto de soluções deve implementar uma solução que permita tanto a autenticação federada quanto o controle de acesso granular. (Selecione Dois)",
        "Question": "Quais dos seguintes serviços o arquiteto de soluções deve implementar para atender aos requisitos?",
        "Options": {
            "1": "Implementar o AWS Directory Service para conectar o Active Directory local aos recursos da AWS.",
            "2": "Aproveitar o AWS Single Sign-On para acesso contínuo a várias contas e aplicativos da AWS.",
            "3": "Configurar o AWS Secrets Manager para armazenar e gerenciar com segurança as chaves de acesso para aplicativos.",
            "4": "Usar o AWS IAM Identity Center para gerenciar o acesso e as permissões dos usuários em contas da AWS.",
            "5": "Utilizar o Amazon Cognito para gerenciar identidades de usuários e sincronizar dados de usuários entre dispositivos."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Usar o AWS IAM Identity Center para gerenciar o acesso e as permissões dos usuários em contas da AWS.",
            "Implementar o AWS Directory Service para conectar o Active Directory local aos recursos da AWS."
        ],
        "Explanation": "O AWS IAM Identity Center simplifica o gerenciamento de acesso dos usuários e fornece uma maneira centralizada de gerenciar permissões para usuários em várias contas da AWS. O AWS Directory Service permite a integração com o Active Directory local, possibilitando autenticação federada e melhor controle de acesso para usuários que precisam acessar recursos da AWS.",
        "Other Options": [
            "O Amazon Cognito é usado principalmente para gerenciar identidades de usuários para aplicativos web e móveis, o que não é a principal preocupação neste cenário, onde o acesso federado aos recursos da AWS é necessário.",
            "O AWS Secrets Manager é projetado para gerenciar segredos, como chaves de API e senhas, mas não fornece gerenciamento de acesso de usuários ou controle de permissões.",
            "O AWS Single Sign-On simplifica o acesso a várias contas da AWS, mas não aborda diretamente a integração com o Active Directory local existente, que é crucial para este cenário."
        ]
    },
    {
        "Question Number": "15",
        "Situation": "Uma equipe de TI está procurando automatizar a implantação de seu aplicativo em uma frota de instâncias Amazon EC2 usando o AWS CodeDeploy. Eles querem garantir que o processo de implantação seja controlado e que possam facilmente reverter para uma versão anterior, se necessário.",
        "Question": "Qual configuração de implantação a equipe de TI deve usar para garantir que eles implementem gradualmente a nova versão em 20% das instâncias a cada 5 minutos até que todas as instâncias tenham sido atualizadas?",
        "Options": {
            "1": "CodeDeployDefault.ECSCanary10Percent5Minutes",
            "2": "CodeDeployDefault.OneAtATime",
            "3": "CodeDeployDefault.AllAtOnce",
            "4": "CodeDeployDefault.HalfAtATime"
        },
        "Correct Answer": "CodeDeployDefault.ECSCanary10Percent5Minutes",
        "Explanation": "A configuração ECSCanary10Percent5Minutes permite que a implantação prossiga de forma canária, onde 10% das instâncias são atualizadas a cada 5 minutos. Essa configuração permite uma implantação gradual enquanto monitora a saúde do aplicativo antes de implantá-lo em todas as instâncias.",
        "Other Options": [
            "HalfAtATime atualizaria metade das instâncias de uma vez, o que não atende ao requisito de uma implantação gradual de 20%.",
            "AllAtOnce implantaria a nova versão em todas as instâncias simultaneamente, o que não permite uma implantação controlada e monitoramento.",
            "OneAtATime atualizaria uma instância de cada vez, o que não é eficiente para o requisito de implantar rapidamente em 20% das instâncias."
        ]
    },
    {
        "Question Number": "16",
        "Situation": "Uma empresa está implantando instâncias EC2 dentro de uma Nuvem Privada Virtual (VPC) e precisa garantir que as instâncias com endereços IP públicos possam resolver nomes de host DNS públicos. A configuração da VPC requer configurações específicas para habilitar esse recurso.",
        "Question": "Quais duas configurações devem ser ajustadas para garantir que as instâncias EC2 em uma VPC possam resolver nomes de host DNS públicos? (Selecione Duas)",
        "Options": {
            "1": "Defina enableDnsSupport como true.",
            "2": "Defina enableDnsHostnames como false.",
            "3": "Defina enableDnsSupport como false.",
            "4": "Defina enableDnsSupport como true para endereços IP privados.",
            "5": "Defina enableDnsHostnames como true."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Defina enableDnsSupport como true.",
            "Defina enableDnsHostnames como true."
        ],
        "Explanation": "Para que as instâncias EC2 em uma VPC resolvam nomes de host DNS públicos, ambos os atributos enableDnsSupport e enableDnsHostnames devem ser definidos como true. enableDnsSupport permite que as instâncias usem o servidor DNS fornecido pela Amazon, e enableDnsHostnames garante que as instâncias com endereços IP públicos recebam nomes DNS públicos correspondentes.",
        "Other Options": [
            "Definir enableDnsHostnames como false impediria que as instâncias recebessem nomes de host DNS públicos, o que é necessário para a resolução.",
            "Definir enableDnsSupport como false desabilitaria o servidor DNS fornecido pela Amazon, impedindo qualquer resolução DNS, incluindo nomes de host públicos.",
            "Definir enableDnsSupport como true para endereços IP privados não atende ao requisito de resolver nomes de host DNS públicos, pois não impacta a resolução de endereços IP públicos."
        ]
    },
    {
        "Question Number": "17",
        "Situation": "Uma organização de saúde está migrando seus dados de pacientes para a AWS. Dada a natureza sensível dessas informações, a organização deve cumprir as regulamentações HIPAA e garantir que os dados sejam retidos por um período mínimo de seis anos. A organização está avaliando suas opções para armazenar, gerenciar e proteger esses dados de acordo com os requisitos regulatórios.",
        "Question": "Qual serviço ou recurso da AWS a organização deve utilizar para garantir a conformidade com os requisitos de retenção e sensibilidade de dados, ao mesmo tempo em que simplifica a gestão de seus dados sensíveis de pacientes?",
        "Options": {
            "1": "Implantar o Amazon RDS com backups automatizados e snapshots para armazenar dados de pacientes, garantindo que sejam retidos pelo período necessário.",
            "2": "Utilizar o AWS Backup para gerenciar políticas de backup para todos os recursos da AWS, incluindo a imposição de períodos de retenção para dados de pacientes.",
            "3": "Usar o Amazon S3 com Object Lock para impor políticas de retenção e impedir a exclusão de dados de pacientes pelo período exigido.",
            "4": "Armazenar dados de pacientes no Amazon DynamoDB com Time to Live (TTL) habilitado para excluir automaticamente registros após seis anos."
        },
        "Correct Answer": "Usar o Amazon S3 com Object Lock para impor políticas de retenção e impedir a exclusão de dados de pacientes pelo período exigido.",
        "Explanation": "O Amazon S3 com Object Lock é projetado especificamente para atender aos requisitos de retenção de dados, impedindo a exclusão de objetos por um período de tempo especificado, tornando-o adequado para conformidade com as regulamentações HIPAA. Isso permite que a organização de saúde garanta que os dados dos pacientes não sejam excluídos antes que o período de retenção obrigatório termine.",
        "Other Options": [
            "Implantar o Amazon RDS com backups automatizados e snapshots é uma boa prática para gerenciamento de banco de dados, mas não fornece o mesmo nível de imposição de retenção que o Object Lock no S3, potencialmente levando a riscos de conformidade.",
            "Armazenar dados de pacientes no Amazon DynamoDB com TTL habilitado permite a exclusão automática, o que contradiz o requisito de reter dados sensíveis por um mínimo de seis anos.",
            "Utilizar o AWS Backup é benéfico para gerenciar backups entre os serviços da AWS, mas não impõe inherentemente políticas de retenção da mesma maneira que o S3 Object Lock, que é crucial para a conformidade com as regulamentações de sensibilidade de dados."
        ]
    },
    {
        "Question Number": "18",
        "Situation": "Uma empresa de serviços financeiros precisa analisar seus gastos mensais na AWS para identificar áreas de otimização de custos. A empresa utiliza vários serviços da AWS, incluindo EC2, S3 e RDS, e possui uma estrutura de faturamento complexa. Eles desejam aprofundar-se em seus Relatórios de Custo e Uso da AWS (CUR) para entender melhor seus padrões de uso, identificar anomalias e alocar custos com precisão entre diferentes departamentos. A equipe não tem certeza de como utilizar efetivamente o CUR para alcançar esses objetivos.",
        "Question": "Qual das seguintes abordagens é a melhor maneira para a empresa investigar seus Relatórios de Custo e Uso da AWS em um nível granular?",
        "Options": {
            "1": "Utilizar o AWS Cost Explorer para visualizar tendências de uso e filtrar por serviço, conta vinculada e tags para identificar drivers de custo específicos e anomalias.",
            "2": "Configurar uma função Lambda agendada que processa o Relatório de Custo e Uso diariamente para gerar arquivos CSV para cada departamento, permitindo um rastreamento mais fácil dos custos.",
            "3": "Baixar o Relatório de Custo e Uso para um bucket S3 e analisar os dados usando o Amazon Athena para consultas ad-hoc e alocação de custos entre diferentes departamentos.",
            "4": "Usar o AWS Budgets para criar alertas com base em limites de uso de serviços específicos, permitindo que a equipe reaja a mudanças nos custos antes que se tornem significativas."
        },
        "Correct Answer": "Baixar o Relatório de Custo e Uso para um bucket S3 e analisar os dados usando o Amazon Athena para consultas ad-hoc e alocação de custos entre diferentes departamentos.",
        "Explanation": "Baixar o Relatório de Custo e Uso para um bucket S3 e usar o Amazon Athena fornece a capacidade de realizar análises detalhadas e consultas ad-hoc sobre os dados, permitindo uma compreensão mais granular dos custos e padrões de uso. Esse método permite que a empresa investigue de forma eficiente áreas específicas de interesse e aloque custos com precisão entre os departamentos.",
        "Other Options": [
            "Embora o AWS Cost Explorer seja útil para visualizar tendências e entender padrões de uso em alto nível, ele não possui as capacidades de consulta detalhada do Athena para análise aprofundada dos Relatórios de Custo e Uso.",
            "Configurar uma função Lambda agendada para gerar arquivos CSV pode ser útil, mas pode não fornecer o mesmo nível de detalhe e flexibilidade para análise que consultar os dados brutos no Athena.",
            "O AWS Budgets é eficaz para monitorar gastos em relação a limites, mas não fornece as percepções detalhadas que a empresa precisa para aprofundar-se na alocação de custos e padrões de uso."
        ]
    },
    {
        "Question Number": "19",
        "Situation": "Uma empresa de serviços financeiros está implantando um aplicativo web em uma VPC na AWS. O aplicativo requer controle rigoroso sobre o tráfego de entrada e saída para cumprir com os padrões regulatórios. O arquiteto de soluções precisa implementar medidas de segurança para definir os fluxos de tráfego permitidos, garantindo que o tráfego legítimo não seja bloqueado. O arquiteto deve utilizar grupos de segurança e ACLs de rede de forma eficaz para gerenciar esses fluxos. (Selecione Dois)",
        "Question": "Quais das seguintes ações o arquiteto de soluções deve tomar para atender aos requisitos?",
        "Options": {
            "1": "Configurar uma ACL de rede para negar todo o tráfego de entrada, exceto para conexões estabelecidas.",
            "2": "Implementar uma regra de ACL de rede para permitir tráfego de entrada de um bloco CIDR específico.",
            "3": "Configurar um grupo de segurança para permitir todo o tráfego de saída para qualquer destino.",
            "4": "Criar um grupo de segurança que permita tráfego HTTP e HTTPS de endereços IP específicos.",
            "5": "Ativar logs de fluxo nas ACLs de rede para monitorar todo o tráfego e analisar padrões."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Criar um grupo de segurança que permita tráfego HTTP e HTTPS de endereços IP específicos.",
            "Implementar uma regra de ACL de rede para permitir tráfego de entrada de um bloco CIDR específico."
        ],
        "Explanation": "As respostas corretas envolvem o uso de grupos de segurança para permitir tráfego específico de HTTP e HTTPS de endereços IP confiáveis, garantindo que apenas solicitações legítimas sejam processadas. Além disso, implementar uma regra de ACL de rede para permitir tráfego de entrada de um bloco CIDR específico complementa isso, fornecendo controle sobre fluxos de tráfego mais amplos enquanto mantém a conformidade de segurança.",
        "Other Options": [
            "Configurar uma ACL de rede para negar todo o tráfego de entrada, exceto para conexões estabelecidas, é muito restritivo e pode bloquear tráfego legítimo que não faz parte de uma conexão estabelecida.",
            "Ativar logs de fluxo nas ACLs de rede para monitorar todo o tráfego e analisar padrões não controla diretamente os fluxos de tráfego e é mais uma solução de monitoramento do que uma medida de segurança.",
            "Configurar um grupo de segurança para permitir todo o tráfego de saída para qualquer destino não é uma boa prática de segurança e pode expor o aplicativo a riscos desnecessários."
        ]
    },
    {
        "Question Number": "20",
        "Situation": "Uma empresa de serviços financeiros está migrando seus aplicativos para a AWS e precisa garantir uma rastreabilidade abrangente das ações dos usuários e interações dos serviços em sua infraestrutura de nuvem. Ela deseja implementar uma solução que permita rastrear e analisar atividades para fins de segurança e conformidade. A empresa está usando vários serviços da AWS, incluindo Amazon S3, Amazon RDS e AWS Lambda, e requer um mecanismo de registro centralizado que capture todos os eventos relevantes.",
        "Question": "Qual das seguintes soluções fornece a melhor abordagem para alcançar uma rastreabilidade abrangente de usuários e serviços no ambiente AWS?",
        "Options": {
            "1": "Ativar o AWS CloudTrail em todas as contas e regiões para capturar chamadas de API e atividades de usuários para todos os serviços da AWS, e configurar o Amazon CloudWatch Logs para monitorar e analisar os logs.",
            "2": "Implantar o Amazon CloudWatch Events para capturar eventos de serviços da AWS e usar o AWS Lambda para processar esses eventos, mas não ativar o AWS CloudTrail para rastreamento de chamadas de API.",
            "3": "Implementar o Amazon GuardDuty para monitorar continuamente atividades maliciosas e comportamentos não autorizados, confiando apenas nele para registro de eventos de segurança no ambiente AWS.",
            "4": "Usar o AWS Config para rastrear alterações de configuração para recursos da AWS e configurar notificações SNS para alterações específicas, sem uma solução de registro centralizada para ações de usuários."
        },
        "Correct Answer": "Ativar o AWS CloudTrail em todas as contas e regiões para capturar chamadas de API e atividades de usuários para todos os serviços da AWS, e configurar o Amazon CloudWatch Logs para monitorar e analisar os logs.",
        "Explanation": "Ativar o AWS CloudTrail fornece uma visão abrangente de todas as chamadas de API feitas por usuários e serviços, o que é essencial para rastreabilidade. Juntamente com o Amazon CloudWatch Logs, permite o monitoramento e análise em tempo real dos logs, garantindo conformidade e segurança.",
        "Other Options": [
            "Implementar o Amazon GuardDuty sozinho não fornece rastreabilidade abrangente de todas as ações dos usuários e interações dos serviços, pois se concentra principalmente na detecção de ameaças e pode perder o registro detalhado das atividades dos usuários.",
            "Usar o AWS Config é limitado ao rastreamento de alterações de configuração e não captura ações de usuários ou chamadas de API, que são críticas para rastreabilidade abrangente e conformidade.",
            "Implantar o Amazon CloudWatch Events sem ativar o AWS CloudTrail limita a capacidade de rastrear chamadas de API e atividades de usuários, tornando-o insuficiente para rastreabilidade abrangente de ações no ambiente AWS."
        ]
    },
    {
        "Question Number": "21",
        "Situation": "Uma empresa de mídia está usando o Amazon S3 para armazenar seu conteúdo de vídeo, que é acessado por usuários em todo o mundo. Eles querem garantir que apenas usuários autorizados possam acessar os vídeos, mantendo as URLs intactas para facilitar o uso. Além disso, precisam fornecer acesso seguro a vários vídeos sem gerar URLs individuais para cada um. O Arquiteto de Soluções deve projetar uma solução que atenda a esses requisitos.",
        "Question": "Qual é a melhor abordagem para o Arquiteto de Soluções implementar a assinatura de URL para o conteúdo de vídeo da empresa de mídia?",
        "Options": {
            "1": "Configurar políticas de bucket S3 para permitir acesso público aos vídeos, mas restringir o acesso com base em endereços IP.",
            "2": "Criar um sistema de autenticação personalizado que gera URLs exclusivas para cada solicitação de vídeo, permitindo acesso apenas a usuários autenticados.",
            "3": "Configurar o CloudFront para usar URLs assinadas e cookies assinados, permitindo que os usuários acessem vários vídeos com um único cookie assinado, mantendo o controle sobre o acesso.",
            "4": "Usar o AWS Lambda para gerar URLs pré-assinadas para cada vídeo e enviá-las aos usuários, garantindo que tenham uma vida útil limitada."
        },
        "Correct Answer": "Configurar o CloudFront para usar URLs assinadas e cookies assinados, permitindo que os usuários acessem vários vídeos com um único cookie assinado, mantendo o controle sobre o acesso.",
        "Explanation": "Usar URLs assinadas e cookies assinados do CloudFront permite que a empresa de mídia controle o acesso a vários arquivos de vídeo de forma eficiente, sem alterar as URLs, proporcionando uma experiência mais amigável ao usuário enquanto garante segurança.",
        "Other Options": [
            "Usar o AWS Lambda para gerar URLs pré-assinadas para cada vídeo pode levar a um número excessivo de URLs geradas, complicando o acesso para usuários que precisam visualizar vários vídeos.",
            "Configurar políticas de bucket S3 para acesso público com base em endereços IP pode expor o conteúdo a usuários não autorizados se o intervalo de IP não for controlado rigorosamente.",
            "Criar um sistema de autenticação personalizado adiciona complexidade e sobrecarga de gerenciamento desnecessárias, tornando-o menos eficiente do que usar os recursos existentes do CloudFront."
        ]
    },
    {
        "Question Number": "22",
        "Situation": "Uma empresa de varejo está coletando dados de vendas em tempo real de seus sistemas de ponto de venda (POS) localizados em lojas em todo o país. Eles querem analisar esses dados para obter insights sobre os comportamentos e tendências de compra dos clientes. Para alcançar isso, estão considerando usar um serviço que possa carregar dados de streaming de forma confiável em seu data lake para análise posterior.",
        "Question": "Qual serviço da AWS o arquiteto de soluções deve recomendar para capturar e carregar dados de streaming no Amazon S3 com mínima sobrecarga de gerenciamento?",
        "Options": {
            "1": "Amazon Kinesis Data Firehose",
            "2": "Amazon SQS",
            "3": "AWS Lambda",
            "4": "Amazon Kinesis Data Streams"
        },
        "Correct Answer": "Amazon Kinesis Data Firehose",
        "Explanation": "O Amazon Kinesis Data Firehose é projetado especificamente para carregar dados de streaming em serviços como o Amazon S3 sem a necessidade de gerenciamento contínuo, tornando-o ideal para este caso de uso. Ele pode lidar com a transformação e o carregamento de dados diretamente no data lake, proporcionando capacidades de análise em tempo real.",
        "Other Options": [
            "O Amazon Kinesis Data Streams requer mais gerenciamento e configuração, pois é projetado para fornecer capacidades de processamento em tempo real, necessitando do uso de clientes Kinesis para ler e processar os dados.",
            "O AWS Lambda é um serviço de computação sem servidor que pode ser usado para processar dados, mas não é especificamente projetado para carregar dados de streaming em um data lake, tornando-o menos adequado para este cenário.",
            "O Amazon SQS é um serviço de enfileiramento de mensagens que permite que microsserviços desacoplados se comuniquem, mas não fornece as capacidades para carregar dados de streaming diretamente em data lakes ou outros serviços de análise."
        ]
    },
    {
        "Question Number": "23",
        "Situation": "Uma empresa de serviços financeiros está implementando um pipeline de CI/CD para sua arquitetura de microsserviços hospedada na AWS. Eles requerem uma estratégia de implantação que minimize o tempo de inatividade e permita um rápido rollback em caso de falhas. O aplicativo deve suportar testes automatizados e integração com ferramentas de monitoramento existentes. A empresa está particularmente preocupada em garantir uma experiência de usuário contínua durante as implantações.",
        "Question": "Qual estratégia de implantação o Arquiteto de Soluções deve recomendar para atender aos requisitos da empresa de minimizar o tempo de inatividade e permitir rollbacks rápidos?",
        "Options": {
            "1": "Usar uma estratégia de implantação rolling com o AWS CodeDeploy. Atualizar instâncias em lotes enquanto mantém uma parte da versão antiga em execução. Isso permite uma transição gradual, mas pode complicar os processos de rollback.",
            "2": "Implementar uma estratégia de implantação blue/green usando o AWS Elastic Beanstalk. Criar dois ambientes idênticos, um para a versão atual e um para a nova versão. Roteie o tráfego para o novo ambiente após testes bem-sucedidos e volte facilmente se surgirem problemas.",
            "3": "Utilizar uma estratégia de implantação all-at-once com o AWS CodeDeploy. Implantar a nova versão em todas as instâncias simultaneamente e monitorar por problemas. Fazer rollback se necessário, mas esperar um possível tempo de inatividade durante a implantação.",
            "4": "Adotar uma estratégia de implantação canary com o AWS Lambda. Implantar a nova versão inicialmente para um pequeno subconjunto de usuários e monitorar as respostas antes de liberar para toda a base de usuários."
        },
        "Correct Answer": "Implementar uma estratégia de implantação blue/green usando o AWS Elastic Beanstalk. Criar dois ambientes idênticos, um para a versão atual e um para a nova versão. Roteie o tráfego para o novo ambiente após testes bem-sucedidos e volte facilmente se surgirem problemas.",
        "Explanation": "Uma estratégia de implantação blue/green permite uma troca contínua entre versões de aplicativos, minimizando o tempo de inatividade e proporcionando um mecanismo de rollback fácil se surgirem problemas após a implantação. Essa abordagem garante que a experiência do usuário permaneça ininterrupta durante as atualizações.",
        "Other Options": [
            "Uma estratégia de implantação all-at-once pode levar a um tempo de inatividade significativo, pois todas as instâncias são atualizadas simultaneamente. Embora o rollback seja possível, o potencial de interrupção para o usuário torna essa abordagem menos adequada para as necessidades da empresa.",
            "Uma estratégia de implantação rolling atualiza instâncias em lotes, o que pode ajudar a reduzir o tempo de inatividade. No entanto, isso complica os processos de rollback, pois alguns usuários podem ainda estar na versão antiga enquanto outros estão na nova versão, levando a um comportamento inconsistente.",
            "Uma estratégia de implantação canary é benéfica para testar novas versões com um pequeno subconjunto primeiro. No entanto, não fornece uma opção de rollback completa tão eficaz quanto a blue/green, e pode exigir configuração e monitoramento adicionais para as funções Lambda."
        ]
    },
    {
        "Question Number": "24",
        "Situation": "Uma empresa está desenvolvendo um aplicativo de microsserviços que requer um serviço de enfileiramento de mensagens confiável. Eles estão considerando usar o Amazon SQS para esse propósito. Uma das principais restrições que precisam considerar é o tamanho máximo das mensagens que podem ser enviadas através do SQS.",
        "Question": "Qual é o tamanho máximo de uma mensagem que pode ser enviada através do Amazon SQS?",
        "Options": {
            "1": "128.000 bytes",
            "2": "512.000 bytes",
            "3": "262.144 bytes",
            "4": "256.000 bytes"
        },
        "Correct Answer": "262.144 bytes",
        "Explanation": "O tamanho máximo da mensagem para o Amazon SQS é 262.144 bytes (256 KB). Esse limite se aplica ao tamanho de cada mensagem individual que pode ser enviada para a fila SQS, garantindo que as mensagens permaneçam leves e a transmissão seja eficiente.",
        "Other Options": [
            "128.000 bytes está incorreto porque está bem abaixo do limite real de tamanho máximo da mensagem de 262.144 bytes.",
            "256.000 bytes está incorreto porque também está abaixo do limite máximo de tamanho da mensagem de 262.144 bytes, que é 256 KB.",
            "512.000 bytes está incorreto porque excede o limite máximo de tamanho da mensagem de 262.144 bytes, tornando-o uma opção inválida para o SQS."
        ]
    },
    {
        "Question Number": "25",
        "Situation": "Uma empresa está usando Amazon Redshift para análise de dados e deseja aprimorar sua estratégia de recuperação de desastres. Eles têm a necessidade de fazer backup automático de seus dados para outra Região da AWS. O cluster Redshift é criptografado com KMS e eles querem garantir que os snapshots possam ser copiados entre regiões, respeitando os requisitos de conformidade.",
        "Question": "Qual é o processo correto para habilitar snapshots entre regiões para um cluster Amazon Redshift criptografado com KMS?",
        "Options": {
            "1": "Habilitar snapshots automatizados e especificar a Região de destino nas configurações do cluster.",
            "2": "Criar uma concessão para o Redshift usar uma chave mestra de cliente KMS na Região de destino antes de habilitar a cópia de snapshots.",
            "3": "Copiar manualmente os snapshots para a Região de destino usando o AWS Management Console.",
            "4": "Alterar a configuração do cluster para usar S3 para backups em vez de criptografia KMS."
        },
        "Correct Answer": "Criar uma concessão para o Redshift usar uma chave mestra de cliente KMS na Região de destino antes de habilitar a cópia de snapshots.",
        "Explanation": "Para habilitar snapshots entre regiões para clusters Amazon Redshift criptografados com KMS, você deve criar uma concessão que permita ao Amazon Redshift usar uma chave mestra de cliente KMS (CMK) na Região de destino. Este passo é essencial para garantir que o cluster possa acessar a chave de criptografia necessária para os snapshots na outra Região.",
        "Other Options": [
            "Apenas habilitar snapshots automatizados e especificar a Região de destino não é suficiente, pois você precisa lidar com a concessão KMS para criptografia.",
            "Copiar snapshots manualmente não é uma solução viável ou automatizada para backup contínuo; a funcionalidade de snapshot entre regiões é projetada para ser automatizada.",
            "Alterar a configuração do cluster para usar S3 para backups não se aplica à cópia de snapshots do Redshift e não atende ao requisito de snapshots automatizados entre regiões."
        ]
    },
    {
        "Question Number": "26",
        "Situation": "Uma empresa global deseja implementar uma estratégia de múltiplas contas usando AWS Organizations para gerenciar suas várias unidades de negócios. A empresa também planeja aproveitar o AWS Control Tower para governança e conformidade. O Arquiteto de Soluções precisa projetar uma solução que permita gerenciamento centralizado, faturamento e conformidade em todas as contas, enquanto permite que as unidades de negócios individuais tenham autonomia sobre seus próprios recursos.",
        "Question": "Qual das seguintes soluções o Arquiteto de Soluções deve implementar para atender melhor aos requisitos?",
        "Options": {
            "1": "Criar várias OUs dentro da AWS Organization para cada unidade de negócios, aplicando SCPs no nível da OU para gerenciar conformidade e gerenciamento centralizado.",
            "2": "Configurar uma única AWS Organization com todas as contas na OU raiz e habilitar Políticas de Controle de Serviço (SCPs) para cada conta para impor conformidade.",
            "3": "Implementar o AWS Control Tower para criar uma estrutura de governança e colocar todas as contas em uma única OU com SCPs rigorosos aplicados no nível da conta.",
            "4": "Utilizar o AWS Control Tower para configurar uma landing zone com contas pré-configuradas e implementar SCPs na OU raiz para impor conformidade em todas as unidades de negócios."
        },
        "Correct Answer": "Criar várias OUs dentro da AWS Organization para cada unidade de negócios, aplicando SCPs no nível da OU para gerenciar conformidade e gerenciamento centralizado.",
        "Explanation": "Criar várias OUs permite uma melhor organização e gerenciamento das contas que correspondem a diferentes unidades de negócios, enquanto a aplicação de SCPs no nível da OU fornece uma maneira flexível de impor conformidade adaptada às necessidades de cada unidade.",
        "Other Options": [
            "Configurar todas as contas na OU raiz sem OUs específicas para cada unidade de negócios pode levar a uma complexidade de gerenciamento e a uma aplicação de conformidade menos eficaz, pois não haveria políticas adaptadas para unidades individuais.",
            "Embora utilizar o AWS Control Tower para configurar uma landing zone seja benéfico, aplicar SCPs apenas na OU raiz pode limitar a granularidade do gerenciamento de conformidade entre diferentes unidades de negócios.",
            "Colocar todas as contas em uma única OU com SCPs rigorosos aplicados no nível da conta pode prejudicar a autonomia das unidades de negócios individuais e complicar a governança, pois não permite políticas específicas adaptadas às necessidades de cada unidade."
        ]
    },
    {
        "Question Number": "27",
        "Situation": "Uma empresa de serviços financeiros está implantando um novo aplicativo na AWS que processa dados sensíveis de clientes. A empresa precisa garantir que o aplicativo atenda a requisitos rigorosos de conformidade de segurança, minimizando o risco de acesso não autorizado aos seus recursos.",
        "Question": "Qual estratégia a empresa deve implementar para aumentar a segurança de seu ambiente AWS enquanto garante conformidade com as regulamentações do setor?",
        "Options": {
            "1": "Habilitar o AWS CloudTrail para registrar todas as chamadas de API e configurar o AWS Config para monitorar a conformidade com as políticas de segurança em todos os recursos.",
            "2": "Criar um bucket Amazon S3 para armazenar dados sensíveis e habilitar o acesso público para permitir a recuperação sem interrupções pelo aplicativo.",
            "3": "Implementar uma função AWS Lambda que execute periodicamente para excluir funções IAM e chaves de acesso não utilizadas para reduzir a superfície de ataque.",
            "4": "Configurar um host bastião dentro de uma sub-rede pública que permita acesso SSH a recursos em sub-redes privadas, enquanto desabilita todo o tráfego de entrada."
        },
        "Correct Answer": "Habilitar o AWS CloudTrail para registrar todas as chamadas de API e configurar o AWS Config para monitorar a conformidade com as políticas de segurança em todos os recursos.",
        "Explanation": "Habilitar o AWS CloudTrail permite registrar todas as chamadas de API feitas em sua conta AWS, fornecendo um registro de auditoria abrangente para fins de conformidade. Além disso, o AWS Config ajuda a rastrear alterações nos recursos e avaliar a conformidade com as políticas de segurança definidas, tornando-se uma estratégia eficaz para aumentar a segurança e atender aos requisitos regulatórios.",
        "Other Options": [
            "Configurar um host bastião pode melhorar a segurança para acesso SSH, mas não aborda o monitoramento geral de conformidade ou registro, que são críticos para aplicativos sensíveis.",
            "Embora implementar uma função Lambda para excluir funções IAM e chaves de acesso não utilizadas possa reduzir a superfície de ataque, isso não fornece a auditoria abrangente e o monitoramento de conformidade necessários para o processamento de dados sensíveis.",
            "Criar um bucket S3 com acesso público compromete diretamente a segurança ao expor dados sensíveis, o que contradiz o objetivo de aumentar a segurança e a conformidade no ambiente AWS."
        ]
    },
    {
        "Question Number": "28",
        "Situation": "Uma empresa de serviços financeiros está planejando migrar suas aplicações locais para a AWS. Eles estão particularmente preocupados com a segurança de seus dados durante o processo de migração. A empresa utiliza uma combinação do AWS Database Migration Service (DMS) e do AWS Application Migration Service (AWS MGN) para gerenciar a migração. Eles querem garantir que os dados sensíveis permaneçam seguros durante o trânsito e em repouso.",
        "Question": "Quais dos seguintes métodos a empresa deve implementar para aumentar a segurança dos dados durante o processo de migração? (Selecione Dois)",
        "Options": {
            "1": "Garantir que todas as instâncias de migração sejam lançadas em uma sub-rede pública para permitir um acesso mais fácil durante a migração.",
            "2": "Ativar o AWS CloudTrail para rastrear chamadas de API feitas pelos serviços de migração para fins de conformidade e auditoria.",
            "3": "Usar o AWS Key Management Service (KMS) para gerenciar chaves de criptografia para dados em repouso no ambiente AWS de destino.",
            "4": "Configurar políticas de bucket S3 para permitir acesso irrestrito para ferramentas de migração armazenarem dados temporários.",
            "5": "Implementar criptografia em trânsito usando TLS para DMS e AWS MGN para proteger dados sensíveis durante a migração."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Implementar criptografia em trânsito usando TLS para DMS e AWS MGN para proteger dados sensíveis durante a migração.",
            "Usar o AWS Key Management Service (KMS) para gerenciar chaves de criptografia para dados em repouso no ambiente AWS de destino."
        ],
        "Explanation": "Implementar criptografia em trânsito usando TLS garante que os dados em movimento entre o ambiente local e a AWS estejam protegidos contra interceptação. Além disso, usar o AWS KMS para gerenciar chaves de criptografia para dados em repouso garante que os dados sensíveis armazenados na AWS estejam seguros, cumprindo as melhores práticas para proteção de dados.",
        "Other Options": [
            "Lançar instâncias de migração em uma sub-rede pública as expõe à internet pública, aumentando o risco de acesso não autorizado a dados sensíveis durante a migração. É recomendado usar sub-redes privadas com medidas de segurança apropriadas.",
            "Embora ativar o AWS CloudTrail seja uma boa prática para rastrear atividades, isso não melhora diretamente a segurança dos dados durante a migração. Ele se concentra em registrar em vez de proteger os dados em si.",
            "Permitir acesso irrestrito nas políticas de bucket S3 pode levar a acessos não autorizados e vazamentos de dados. É crucial implementar acesso de menor privilégio para restringir quem pode acessar os dados durante a migração."
        ]
    },
    {
        "Question Number": "29",
        "Situation": "Uma empresa de serviços financeiros está implementando criptografia do lado do servidor com chaves fornecidas pelo cliente (SSE-C) para proteger dados sensíveis armazenados no Amazon S3. O aplicativo fará chamadas de API REST para fazer upload e recuperar objetos criptografados, e é crucial garantir que os cabeçalhos HTTP corretos sejam incluídos em cada solicitação para manter a integridade e a segurança dos dados. A equipe de desenvolvimento precisa entender os cabeçalhos necessários para a criptografia SSE-C ao usar URLs pré-assinadas.",
        "Question": "Quais dos seguintes cabeçalhos de solicitação HTTP devem ser incluídos ao usar URLs pré-assinadas para criptografia do lado do servidor com chaves fornecidas pelo cliente (SSE-C) no Amazon S3?",
        "Options": {
            "1": "x-amz-server-side-encryption-customer-algorithm, x-amz-server-side-encryption-customer-key, x-amz-server-side-encryption-customer-key-MD5",
            "2": "x-amz-server-side-encryption-customer-key, x-amz-server-side-encryption-customer-key-MD5",
            "3": "x-amz-server-side-encryption-customer-algorithm, x-amz-server-side-encryption-customer-key",
            "4": "x-amz-server-side-encryption-customer-algorithm"
        },
        "Correct Answer": "x-amz-server-side-encryption-customer-algorithm",
        "Explanation": "Ao usar URLs pré-assinadas para SSE-C no Amazon S3, o único cabeçalho HTTP obrigatório é 'x-amz-server-side-encryption-customer-algorithm' para especificar o algoritmo de criptografia. Os outros cabeçalhos não são necessários ao usar URLs pré-assinadas, pois a chave do cliente e seu hash MD5 não estão incluídos na solicitação inicial.",
        "Other Options": [
            "Esta opção está incorreta porque inclui cabeçalhos desnecessários que não são exigidos para URLs pré-assinadas; apenas o cabeçalho do algoritmo é obrigatório.",
            "Esta opção está incorreta, pois falta o cabeçalho necessário para especificar o algoritmo de criptografia ao usar URLs pré-assinadas.",
            "Esta opção está incorreta porque não inclui o cabeçalho do algoritmo exigido para SSE-C ao usar URLs pré-assinadas."
        ]
    },
    {
        "Question Number": "30",
        "Situation": "Uma empresa de serviços financeiros está implantando um aplicativo de múltiplas camadas na AWS, que inclui uma camada web, uma camada de aplicativo e uma camada de banco de dados. A empresa precisa de uma estratégia abrangente de registro e monitoramento para garantir conformidade com requisitos regulatórios, solucionar problemas e otimizar o desempenho. O aplicativo utilizará instâncias do Amazon EC2 para as camadas web e de aplicativo e o Amazon RDS para o banco de dados. A empresa visa implementar uma solução que minimize a sobrecarga operacional enquanto maximiza a segurança e o controle de acesso.",
        "Question": "Qual estratégia de registro e monitoramento a empresa deve adotar para atender aos seus requisitos?",
        "Options": {
            "1": "Implantar uma solução de registro de código aberto em instâncias EC2 que colete e centralize logs. Usar o Amazon CloudWatch para monitoramento básico e configurar um cron job para backups regulares dos dados de log para o S3 para fins de conformidade.",
            "2": "Implementar o Amazon CloudWatch para monitoramento de aplicativos e infraestrutura, e usar o AWS CloudTrail para registrar todas as chamadas de API. Configurar métricas e alarmes personalizados para notificar a equipe de operações sobre possíveis problemas. Integrar o Amazon GuardDuty para monitoramento de segurança e detecção de ameaças.",
            "3": "Aproveitar o Amazon CloudWatch Logs para agregar logs de aplicativos de instâncias EC2 e RDS. Configurar o AWS Lambda para processar logs e enviar alertas via Amazon SNS para eventos críticos. Usar o AWS Systems Manager para gerenciar e automatizar tarefas operacionais.",
            "4": "Utilizar o AWS X-Ray para rastrear solicitações através do aplicativo, combinado com o Amazon CloudWatch para monitorar o desempenho do sistema. Empregar o AWS Config para rastrear mudanças de configuração e o AWS CloudTrail para registro de chamadas de API, garantindo trilhas de auditoria abrangentes."
        },
        "Correct Answer": "Implementar o Amazon CloudWatch para monitoramento de aplicativos e infraestrutura, e usar o AWS CloudTrail para registrar todas as chamadas de API. Configurar métricas e alarmes personalizados para notificar a equipe de operações sobre possíveis problemas. Integrar o Amazon GuardDuty para monitoramento de segurança e detecção de ameaças.",
        "Explanation": "Esta opção fornece uma estratégia abrangente de registro e monitoramento que atende à conformidade regulatória, permite a solução de problemas e otimiza o desempenho. O Amazon CloudWatch permite monitoramento e alerta em tempo real, o AWS CloudTrail garante uma trilha de auditoria completa das chamadas de API, e o Amazon GuardDuty adiciona uma camada essencial de monitoramento de segurança.",
        "Other Options": [
            "Embora usar o AWS X-Ray para rastreamento e o Amazon CloudWatch para monitoramento seja benéfico, falta a abrangente capacidade de monitoramento de segurança e detecção de ameaças fornecida pelo Amazon GuardDuty, bem como o registro de API focado oferecido pelo AWS CloudTrail.",
            "Agregando logs com o Amazon CloudWatch Logs e processando-os via AWS Lambda fornece algumas capacidades de monitoramento, mas não entrega os extensos recursos de registro de API e segurança que são essenciais para a conformidade regulatória.",
            "Implantar uma solução de registro de código aberto pode levar a um aumento na sobrecarga operacional e desafios de manutenção, e não aproveita totalmente os serviços gerenciados da AWS para monitoramento e registro, que são projetados para garantir segurança, conformidade e facilidade de uso."
        ]
    },
    {
        "Question Number": "31",
        "Situation": "Uma empresa de serviços financeiros está avaliando sua estratégia de recuperação de desastres para suas aplicações críticas hospedadas na AWS. Eles querem garantir o mínimo de tempo de inatividade e perda de dados em caso de um desastre. A empresa definiu um Objetivo de Tempo de Recuperação (RTO) de 4 horas e um Objetivo de Ponto de Recuperação (RPO) de 1 hora para suas aplicações. Eles estão considerando diferentes estratégias de backup e replicação para atender a esses objetivos.",
        "Question": "Qual das seguintes estratégias permitirá que a empresa atenda melhor aos seus requisitos de RTO e RPO?",
        "Options": {
            "1": "Utilizar o Amazon S3 para armazenamento com versionamento habilitado e configurar uma implantação multi-AZ para o Amazon RDS.",
            "2": "Implementar replicação entre regiões para todos os dados e usar o AWS Elastic Beanstalk para a implantação de aplicações.",
            "3": "Usar o AWS Backup para criar backups diários de todos os recursos e implantar aplicações em instâncias do Amazon EC2 em uma única Zona de Disponibilidade.",
            "4": "Agendar snapshots horários do Amazon RDS e usar o AWS Lambda para automatizar a recuperação de banco de dados para uma região secundária."
        },
        "Correct Answer": "Utilizar o Amazon S3 para armazenamento com versionamento habilitado e configurar uma implantação multi-AZ para o Amazon RDS.",
        "Explanation": "Utilizar o Amazon S3 com versionamento fornece armazenamento de dados confiável com controle de versão, o que ajuda a minimizar a perda de dados e atender ao RPO de 1 hora. Enquanto isso, uma implantação multi-AZ para o Amazon RDS garante alta disponibilidade e capacidades de failover rápido, alinhando-se ao RTO de 4 horas.",
        "Other Options": [
            "Implementar replicação entre regiões pode levar a um aumento na latência e custos, e embora possa fornecer durabilidade, pode não atender suficientemente aos requisitos de RTO e RPO tão efetivamente quanto a implantação multi-AZ.",
            "Agendar snapshots horários pode não ser frequente o suficiente para atender ao RPO de 1 hora, e embora a automação para failover seja benéfica, pode não garantir o tempo de recuperação rápido necessário para atender ao RTO.",
            "Criar backups diários não atende ao RPO de 1 hora, pois os backups não capturariam as alterações de dados feitas dentro dessa hora, e implantar aplicações em uma única Zona de Disponibilidade não fornece a resiliência necessária para atender ao RTO."
        ]
    },
    {
        "Question Number": "32",
        "Situation": "Uma empresa está planejando migrar um grande banco de dados local para a AWS. O banco de dados tem aproximadamente 10 TB de tamanho e requer um tempo de inatividade mínimo durante a migração. A equipe está considerando vários serviços da AWS para facilitar essa migração, garantindo a integridade e segurança dos dados.",
        "Question": "Qual serviço e estratégia da AWS a equipe deve usar para migrar o banco de dados com tempo de inatividade mínimo?",
        "Options": {
            "1": "AWS DataSync com AWS Schema Conversion Tool (SCT)",
            "2": "AWS Snowball com AWS Database Migration Service (DMS)",
            "3": "AWS Transfer Family com Amazon RDS Migration Readiness Review",
            "4": "AWS Direct Connect com exportação e importação de dados manuais"
        },
        "Correct Answer": "AWS Snowball com AWS Database Migration Service (DMS)",
        "Explanation": "O AWS Snowball permite a transferência eficiente de grandes quantidades de dados para a AWS. Ao usar o AWS Database Migration Service (DMS) em conjunto, a equipe pode realizar replicação contínua durante a transferência de dados, garantindo um tempo de inatividade mínimo e mantendo a integridade dos dados durante todo o processo de migração.",
        "Other Options": [
            "O AWS DataSync é usado principalmente para transferir arquivos em vez de bancos de dados, e embora o AWS Schema Conversion Tool (SCT) seja útil para conversão de esquema, não atende aos requisitos para uma migração em grande escala com tempo de inatividade mínimo.",
            "O AWS Direct Connect é útil para estabelecer uma conexão de rede dedicada, mas não facilita a migração de grandes bancos de dados diretamente. A exportação e importação de dados manuais provavelmente resultariam em um tempo de inatividade significativo e não é ideal para esta situação.",
            "O AWS Transfer Family é projetado para transferir arquivos usando protocolos como SFTP ou FTP e não se aplica a migrações de bancos de dados. Além disso, uma Revisão de Prontidão para Migração do Amazon RDS é uma etapa preparatória em vez de uma estratégia de migração."
        ]
    },
    {
        "Question Number": "33",
        "Situation": "Uma empresa de tecnologia está implementando um sistema que requer acesso temporário a recursos da AWS para usuários que se autenticam usando um aplicativo web. O aplicativo precisa fornecer aos usuários acesso por tempo limitado a serviços específicos da AWS sem criar usuários permanentes do AWS IAM. A arquitetura deve garantir que a solução seja escalável e não introduza um único ponto de falha. Você foi encarregado de selecionar a abordagem certa para gerenciar o acesso dos usuários, considerando segurança e gerenciabilidade.",
        "Question": "Qual abordagem deve ser implementada para fornecer acesso temporário a recursos da AWS enquanto minimiza o risco de um único ponto de falha?",
        "Options": {
            "1": "Usar o AWS Security Token Service (STS) para gerar credenciais temporárias que podem ser fornecidas aos usuários após a autenticação, e garantir que as credenciais tenham permissões limitadas.",
            "2": "Implementar um Modelo Tradicional de Validação de Token (TVM) para gerenciar o acesso dos usuários, permitindo permissões específicas de serviço e entrega de credenciais aos usuários.",
            "3": "Usar o Amazon Cognito para gerenciar a autenticação de usuários e emitir credenciais temporárias através do AWS STS, fornecendo uma solução escalável e segura sem um único ponto de falha.",
            "4": "Implantar uma instância EC2 executando um código personalizado para o Modelo de Validação de Token (TVM) para gerenciar a autenticação e acesso dos usuários, garantindo que as credenciais sejam entregues de forma segura."
        },
        "Correct Answer": "Usar o Amazon Cognito para gerenciar a autenticação de usuários e emitir credenciais temporárias através do AWS STS, fornecendo uma solução escalável e segura sem um único ponto de falha.",
        "Explanation": "O Amazon Cognito fornece uma solução robusta para autenticação de usuários e se integra perfeitamente com o AWS STS para emitir credenciais temporárias. Essa abordagem evita o único ponto de falha associado a uma implementação personalizada de TVM e oferece escalabilidade e segurança para gerenciar o acesso dos usuários.",
        "Other Options": [
            "Usar o AWS STS sozinho fornece credenciais temporárias, mas não gerencia a autenticação de usuários diretamente. Essa abordagem carece dos recursos adicionais fornecidos pelo Amazon Cognito, como gerenciamento de pool de usuários e segurança aprimorada.",
            "Implementar um Modelo Tradicional de Validação de Token (TVM) pode introduzir um único ponto de falha, especialmente se hospedado em EC2. Além disso, o TVM é considerado desatualizado em comparação com soluções modernas como o Amazon Cognito.",
            "Implantar uma instância EC2 para um TVM personalizado adiciona complexidade e sobrecarga operacional, aumentando o risco de falha. Esse método não fornece o mesmo nível de escalabilidade e segurança que o Amazon Cognito na gestão do acesso dos usuários."
        ]
    },
    {
        "Question Number": "34",
        "Situation": "Uma empresa de varejo está planejando lançar um novo aplicativo de e-commerce que requer alta disponibilidade e a capacidade de escalar automaticamente com base no tráfego. O aplicativo experimentará padrões de tráfego imprevisíveis, especialmente durante promoções e vendas de feriados. A empresa quer garantir que sua estratégia de implantação minimize o tempo de inatividade e forneça experiências de usuário contínuas.",
        "Question": "Qual estratégia de implantação a empresa deve implementar para garantir alta disponibilidade e escalabilidade para seu aplicativo de e-commerce?",
        "Options": {
            "1": "Implantar o aplicativo em uma única instância EC2 com um grande volume EBS e configurar um alarme do CloudWatch para enviar notificações para escalonamento.",
            "2": "Utilizar um ambiente do Elastic Beanstalk com várias instâncias EC2 atrás de um balanceador de carga, configurando auto-escalonamento com base em métricas de utilização da CPU.",
            "3": "Usar funções do AWS Lambda para lidar com todas as solicitações recebidas, garantindo que não haja instâncias EC2 para gerenciar e escalar automaticamente.",
            "4": "Implementar um cluster do Amazon ECS com várias instâncias de contêiner, usando o Fargate para gerenciar o escalonamento e a implantação do aplicativo."
        },
        "Correct Answer": "Utilizar um ambiente do Elastic Beanstalk com várias instâncias EC2 atrás de um balanceador de carga, configurando auto-escalonamento com base em métricas de utilização da CPU.",
        "Explanation": "Usar o Elastic Beanstalk com várias instâncias EC2 garante que o aplicativo possa lidar com cargas de tráfego variadas. O balanceador de carga distribui o tráfego recebido, e o auto-escalonamento ajusta o número de instâncias com base na utilização da CPU, levando a alta disponibilidade e uso eficiente de recursos.",
        "Other Options": [
            "Implantar o aplicativo em uma única instância EC2 não fornece alta disponibilidade, pois introduz um único ponto de falha. Alarmes do CloudWatch podem notificar sobre necessidades de escalonamento, mas não podem escalar automaticamente sem várias instâncias desde o início.",
            "Embora usar o AWS Lambda possa fornecer escalonamento automático e eliminar a gestão de servidores, pode não ser adequado para todos os tipos de solicitações, particularmente para cargas de trabalho que requerem conexões persistentes ou sessões com estado.",
            "O Amazon ECS com Fargate é uma opção válida para gerenciar contêineres, mas pode introduzir complexidade desnecessária para um novo aplicativo que pode ser gerenciado de forma eficaz com o modelo de implantação mais simples do Elastic Beanstalk."
        ]
    },
    {
        "Question Number": "35",
        "Situation": "Uma empresa está desenvolvendo uma arquitetura de microserviços para melhorar a escalabilidade e a manutenibilidade. A arquitetura requer que os serviços permaneçam independentes e possam evoluir separadamente sem acoplamento forte. A equipe de desenvolvimento está considerando vários serviços da AWS para implementar dependências fracamente acopladas entre microserviços.",
        "Question": "Qual é a solução MAIS adequada que o Arquiteto de Soluções deve recomendar para permitir dependências fracamente acopladas entre microserviços?",
        "Options": {
            "1": "Implantar funções do AWS Lambda com endpoints diretos do API Gateway para cada microserviço, garantindo que estejam fortemente integrados e possam chamar uns aos outros diretamente.",
            "2": "Utilizar o Amazon SNS para publicar eventos de um microserviço que podem ser assinados por outros microserviços, permitindo uma arquitetura orientada a eventos desacoplada.",
            "3": "Implementar o Amazon SQS para comunicação assíncrona entre serviços, permitindo que processem mensagens de forma independente, sem dependências diretas.",
            "4": "Usar o AWS AppSync para estabelecer uma API GraphQL que conecta todos os microserviços, garantindo comunicação síncrona e acesso a dados compartilhados."
        },
        "Correct Answer": "Utilizar o Amazon SNS para publicar eventos de um microserviço que podem ser assinados por outros microserviços, permitindo uma arquitetura orientada a eventos desacoplada.",
        "Explanation": "Utilizar o Amazon SNS fornece um mecanismo robusto para implementar dependências fracamente acopladas, permitindo que os microserviços se comuniquem por meio de eventos publicados. Essa abordagem permite que os serviços operem de forma independente e escalem sem estarem fortemente integrados, promovendo uma arquitetura orientada a eventos.",
        "Other Options": [
            "Implementar o Amazon SQS para comunicação assíncrona é benéfico, mas se concentra principalmente em enfileiramento de mensagens, em vez de um modelo orientado a eventos, que é mais adequado para dependências fracamente acopladas.",
            "Usar o AWS AppSync estabelece uma API GraphQL que promove comunicação síncrona, o que pode criar um acoplamento mais forte entre os serviços, ao contrário do objetivo de manter a independência.",
            "Implantar funções do AWS Lambda com endpoints diretos do API Gateway leva a um acoplamento forte, pois os serviços chamariam uns aos outros diretamente, dificultando a evolução independente."
        ]
    },
    {
        "Question Number": "36",
        "Situation": "Uma empresa está planejando migrar seus aplicativos locais para a AWS. Eles têm uma mistura de aplicativos legados que estão fortemente acoplados entre si e alguns aplicativos mais novos, nativos da nuvem. Os aplicativos são críticos para as operações comerciais, e a empresa quer minimizar o tempo de inatividade durante o processo de migração. O Arquiteto de Soluções precisa determinar a abordagem de migração ideal para essas cargas de trabalho.",
        "Question": "Qual das seguintes estratégias de migração o Arquiteto de Soluções deve recomendar para garantir o mínimo de tempo de inatividade ao migrar os aplicativos para a AWS?",
        "Options": {
            "1": "Descontinuar os aplicativos legados e migrar os dados para o Amazon RDS, enquanto substitui a funcionalidade comercial por aplicativos nativos da nuvem.",
            "2": "Lift-and-shift dos aplicativos legados para a AWS usando o AWS Application Migration Service, garantindo que permaneçam operacionais durante o processo de migração.",
            "3": "Rehospedar os aplicativos legados em instâncias do Amazon EC2 enquanto gradualmente refatora os aplicativos mais novos para containerização usando o Amazon ECS.",
            "4": "Refatorar todos os aplicativos em microserviços e implantá-los como funções do AWS Lambda para aproveitar a arquitetura serverless."
        },
        "Correct Answer": "Lift-and-shift dos aplicativos legados para a AWS usando o AWS Application Migration Service, garantindo que permaneçam operacionais durante o processo de migração.",
        "Explanation": "A abordagem lift-and-shift usando o AWS Application Migration Service permite que a empresa migre rapidamente seus aplicativos legados com o mínimo de tempo de inatividade. Esse método permite que os aplicativos sejam executados na AWS sem mudanças significativas, garantindo a continuidade dos negócios durante a transição.",
        "Other Options": [
            "Rehospedar os aplicativos legados enquanto gradualmente refatora os aplicativos mais novos pode introduzir risco de tempo de inatividade e complexidade, uma vez que os sistemas legados fortemente acoplados não são facilmente adaptáveis a uma migração escalonada.",
            "Refatorar todos os aplicativos em microserviços e implantá-los como funções do AWS Lambda é uma abordagem ambiciosa que pode exigir uma re-arquitetura extensa, levando a um potencial tempo de inatividade durante a transição.",
            "Descontinuar os aplicativos legados e migrar dados para o Amazon RDS enquanto substitui a funcionalidade comercial por aplicativos nativos da nuvem pode resultar em tempo de inatividade significativo e interrupção dos negócios à medida que a organização se afasta de sistemas legados críticos."
        ]
    },
    {
        "Question Number": "37",
        "Situation": "Uma startup está desenvolvendo uma aplicação de microserviços que será executada na AWS. A aplicação terá múltiplos serviços, cada um responsável por uma capacidade de negócio específica. A startup está considerando várias opções para implantar seus contêineres e deseja garantir que escolha uma solução que ofereça alta escalabilidade, balanceamento de carga automático e mínima sobrecarga operacional.",
        "Question": "Qual das seguintes opções atende melhor aos requisitos da startup para implantar sua aplicação de microserviços de maneira econômica e eficiente?",
        "Options": {
            "1": "Implantar os microserviços no AWS Fargate com Amazon ECS. Esta opção serverless permite que a startup execute contêineres sem gerenciar a infraestrutura subjacente. Configure o Auto Scaling de Serviço e use os recursos de balanceamento de carga integrados do ECS para distribuir o tráfego.",
            "2": "Implantar os microserviços no Amazon ECS com tipo de lançamento EC2. Configure o Auto Scaling para lidar com cargas variáveis e use o Elastic Load Balancer para distribuição de tráfego. Gerencie as instâncias EC2 subjacentes e garanta que estejam devidamente mantidas.",
            "3": "Implantar os microserviços no Amazon EKS. Utilize o Kubernetes para gerenciar a implantação e escalabilidade dos serviços. Configure um Cluster Autoscaler para escalabilidade dinâmica e use serviços do Kubernetes para balanceamento de carga. Esta opção requer gerenciamento do ambiente Kubernetes.",
            "4": "Implantar os microserviços no AWS Lambda. Divida cada microserviço em funções serverless que podem escalar automaticamente com base na demanda. Use o API Gateway para balanceamento de carga e gerenciamento de tráfego, eliminando a necessidade de orquestração de contêineres."
        },
        "Correct Answer": "Implantar os microserviços no AWS Fargate com Amazon ECS. Esta opção serverless permite que a startup execute contêineres sem gerenciar a infraestrutura subjacente. Configure o Auto Scaling de Serviço e use os recursos de balanceamento de carga integrados do ECS para distribuir o tráfego.",
        "Explanation": "Implantar os microserviços no AWS Fargate com Amazon ECS permite que a startup execute seus contêineres em um ambiente serverless, eliminando a necessidade de gerenciar as instâncias EC2 subjacentes. Esta opção oferece escalabilidade automática e balanceamento de carga integrado, tornando-a ideal para suas necessidades, enquanto minimiza a sobrecarga operacional e os custos.",
        "Other Options": [
            "Implantar os microserviços no Amazon ECS com tipo de lançamento EC2 exige que a startup gerencie as instâncias EC2 subjacentes, o que adiciona sobrecarga operacional e complexidade. Embora possa escalar, não corresponde à facilidade de gerenciamento proporcionada pelo Fargate.",
            "Implantar os microserviços no Amazon EKS requer gerenciamento de um ambiente Kubernetes, o que pode ser complexo para startups sem experiência em orquestração de contêineres. Embora ofereça escalabilidade, não fornece o mesmo nível de simplicidade operacional que o Fargate.",
            "Implantar os microserviços no AWS Lambda não é adequado, pois requer dividir a aplicação em funções individuais, o que pode levar a uma complexidade aumentada na gestão das funções e potenciais problemas de inicialização a frio, ao contrário da abordagem em contêineres preferida pela startup."
        ]
    },
    {
        "Question Number": "38",
        "Situation": "Uma grande empresa de e-commerce tem enfrentado picos inesperados nos custos da AWS devido ao aumento do uso de vários serviços em nuvem. Para gerenciar essa situação, a empresa precisa implementar uma estratégia abrangente de conscientização sobre gastos e uso. O arquiteto de soluções foi encarregado de propor uma solução que permita à empresa monitorar, analisar e controlar seus gastos na AWS de forma eficaz.",
        "Question": "Qual das seguintes opções fornece a melhor estratégia para desenvolver controles de conscientização sobre gastos e uso na AWS?",
        "Options": {
            "1": "Implementar AWS Budgets para definir orçamentos personalizados de custo e uso. Usar AWS CloudTrail para registrar o uso de serviços e revisar os logs regularmente para identificar padrões de gastos anômalos.",
            "2": "Utilizar AWS Trusted Advisor para obter insights sobre otimização de custos e uso de serviços. Combinar isso com o rastreamento manual das faturas da AWS para uma visão abrangente.",
            "3": "Aproveitar AWS Organizations para consolidar a cobrança entre várias contas. Implementar AWS Cost Explorer com relatórios pré-definidos para obter insights sobre gastos entre equipes.",
            "4": "Implantar Amazon CloudWatch para monitorar o uso de serviços e configurar alarmes para limites específicos. Usar AWS Cost Explorer para analisar tendências de gastos e criar relatórios."
        },
        "Correct Answer": "Implementar AWS Budgets para definir orçamentos personalizados de custo e uso. Usar AWS CloudTrail para registrar o uso de serviços e revisar os logs regularmente para identificar padrões de gastos anômalos.",
        "Explanation": "Esta opção combina efetivamente a gestão proativa de orçamentos com o registro detalhado do uso de serviços, permitindo que a empresa defina limites financeiros e investigue gastos irregulares, o que é crucial para manter a conscientização sobre gastos.",
        "Other Options": [
            "Embora implantar o Amazon CloudWatch possa ajudar a monitorar o uso, não aborda diretamente a necessidade de gestão orçamentária e pode levar a medidas reativas em vez de controle proativo de custos.",
            "Utilizar o AWS Trusted Advisor fornece insights úteis para otimização de custos, mas depender apenas do rastreamento manual das faturas é ineficiente e pode levar a uma conscientização atrasada sobre problemas de custo.",
            "Aproveitar o AWS Organizations pode ajudar na consolidação de cobrança, mas sem incorporar uma estratégia de orçamento ou monitoramento detalhado de uso, pode não fornecer os controles necessários para a conscientização sobre gastos."
        ]
    },
    {
        "Question Number": "39",
        "Situation": "Uma empresa de serviços financeiros está executando uma aplicação crítica em instâncias do Amazon EC2 em uma única Zona de Disponibilidade. A aplicação está enfrentando interrupções ocasionais devido à indisponibilidade da infraestrutura subjacente. O Arquiteto de Soluções foi encarregado de projetar uma arquitetura altamente disponível que possa lidar com failover sem impactar o desempenho da aplicação.",
        "Question": "Qual das seguintes soluções remediaria melhor o ponto único de falha nesta arquitetura?",
        "Options": {
            "1": "Implantar a aplicação em várias instâncias do EC2 em diferentes Zonas de Disponibilidade e usar um Elastic Load Balancer para distribuir o tráfego.",
            "2": "Configurar uma pilha do CloudFormation que recrie automaticamente a aplicação em uma Zona de Disponibilidade diferente em caso de falha.",
            "3": "Criar uma réplica de leitura do Amazon RDS em uma Zona de Disponibilidade diferente para lidar com o failover da camada de banco de dados.",
            "4": "Implementar o Amazon Route 53 com uma política de roteamento de failover para direcionar o tráfego para uma instância secundária da aplicação em outra região."
        },
        "Correct Answer": "Implantar a aplicação em várias instâncias do EC2 em diferentes Zonas de Disponibilidade e usar um Elastic Load Balancer para distribuir o tráfego.",
        "Explanation": "Implantar a aplicação em várias instâncias do EC2 em diferentes Zonas de Disponibilidade e usar um Elastic Load Balancer garante que, se uma Zona de Disponibilidade se tornar indisponível, o tráfego ainda possa ser direcionado para instâncias nas outras Zonas de Disponibilidade, proporcionando assim alta disponibilidade e minimizando o tempo de inatividade.",
        "Other Options": [
            "Criar uma réplica de leitura do Amazon RDS em uma Zona de Disponibilidade diferente aborda apenas a camada de banco de dados e não fornece alta disponibilidade para toda a aplicação, que ainda poderia falhar se a instância principal da aplicação se tornar indisponível.",
            "Implementar o Amazon Route 53 com uma política de roteamento de failover pode redirecionar o tráfego para uma instância secundária, mas essa abordagem não gerencia ativamente o balanceamento de carga ou fornece failover em tempo real para a aplicação, levando a potenciais períodos de inatividade da aplicação.",
            "Configurar uma pilha do CloudFormation para recriar a aplicação em uma Zona de Disponibilidade diferente introduz complexidade e pode não fornecer capacidades imediatas de failover, o que ainda poderia deixar a aplicação vulnerável durante o processo de recriação."
        ]
    },
    {
        "Question Number": "40",
        "Situation": "Uma empresa de serviços financeiros está projetando um novo aplicativo em múltiplas camadas hospedado na AWS. Este aplicativo lida com dados sensíveis de clientes e deve atender a requisitos rigorosos de confiabilidade. A arquitetura consiste em uma camada web baseada em Amazon EC2, um balanceador de carga e um banco de dados Amazon RDS no backend. A empresa deseja garantir alta disponibilidade e tolerância a falhas para o aplicativo em várias Zonas de Disponibilidade. Eles também estão considerando como lidar com a possível perda de dados e garantir que o aplicativo possa se recuperar rapidamente de interrupções. Quais estratégias a empresa deve implementar?",
        "Question": "Quais das seguintes estratégias ajudarão a atender aos requisitos de confiabilidade? (Selecione duas)",
        "Options": {
            "1": "Implantar a camada web em instâncias Amazon EC2 em várias Zonas de Disponibilidade com um Elastic Load Balancer.",
            "2": "Usar implantações Amazon RDS Multi-AZ para o banco de dados backend para garantir suporte a failover.",
            "3": "Implementar uma única instância EC2 para a camada web para reduzir custos e complexidade.",
            "4": "Utilizar S3 para backups do banco de dados RDS para permitir uma rápida recuperação de dados.",
            "5": "Configurar um grupo de Auto Scaling para a camada web para lidar com picos de tráfego e garantir disponibilidade."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Implantar a camada web em instâncias Amazon EC2 em várias Zonas de Disponibilidade com um Elastic Load Balancer.",
            "Usar implantações Amazon RDS Multi-AZ para o banco de dados backend para garantir suporte a failover."
        ],
        "Explanation": "A primeira resposta correta garante que a camada web esteja distribuída em várias Zonas de Disponibilidade, proporcionando redundância e alta disponibilidade. A segunda resposta correta garante que o banco de dados RDS possa falhar automaticamente para uma instância de espera em outra Zona de Disponibilidade, garantindo tempo de inatividade e perda de dados mínimos.",
        "Other Options": [
            "Esta opção carece de redundância e criaria um único ponto de falha, o que não atende aos requisitos de confiabilidade.",
            "Embora os backups sejam importantes, eles não fornecem capacidades imediatas de failover, que são essenciais para atender aos requisitos de alta disponibilidade.",
            "Esta opção ajuda na gestão de tráfego, mas não aborda a necessidade de alta disponibilidade em Zonas de Disponibilidade para a camada web."
        ]
    },
    {
        "Question Number": "41",
        "Situation": "Uma empresa está migrando seus dados locais para a AWS e deseja otimizar os custos de transferência de dados durante o processo de migração. Eles estão considerando as diferentes opções disponíveis para transferir grandes volumes de dados para o Amazon S3 e estão preocupados com os custos associados às taxas de transferência de dados.",
        "Question": "Qual das seguintes estratégias minimizaria melhor os custos de transferência de dados ao migrar grandes volumes de dados para o Amazon S3?",
        "Options": {
            "1": "Utilizar Amazon Direct Connect para transferência contínua de dados para o S3.",
            "2": "Fazer o upload dos dados diretamente para o S3 usando o AWS CLI pela Internet.",
            "3": "Transferir dados para o Amazon EC2 primeiro, e depois copiá-los para o S3.",
            "4": "Usar AWS Snowball para transferir dados fisicamente para a AWS."
        },
        "Correct Answer": "Usar AWS Snowball para transferir dados fisicamente para a AWS.",
        "Explanation": "Usar o AWS Snowball permite a transferência física de grandes conjuntos de dados para a AWS, o que minimiza os custos de transferência de dados associados à transferência de grandes volumes de dados pela Internet. O Snowball é especialmente econômico para migrações em grande escala, evitando cobranças de largura de banda onerosas.",
        "Other Options": [
            "Fazer o upload dos dados diretamente para o S3 usando o AWS CLI pela Internet pode incorrer em custos significativos de transferência de dados, especialmente com grandes volumes de dados, pois depende da largura de banda da Internet pública.",
            "Transferir dados para o Amazon EC2 primeiro e depois copiá-los para o S3 não aborda a preocupação principal de reduzir os custos de transferência de dados e pode introduzir cobranças adicionais pela transferência de dados do EC2.",
            "Utilizar Amazon Direct Connect pode reduzir os custos de transferência de dados contínuos para transferências grandes, mas requer uma configuração que pode ser cara e demorada, tornando-a menos ideal para migrações em massa iniciais."
        ]
    },
    {
        "Question Number": "42",
        "Situation": "Uma empresa de serviços financeiros está projetando uma camada de cache para seu aplicativo de negociação de alta frequência. Eles requerem uma solução de cache que possa lidar com grandes conjuntos de dados de forma eficiente e permitir escalabilidade rápida com base na demanda flutuante. A equipe também prefere uma arquitetura simples, sem complexidades como criptografia ou persistência de dados. Dadas essas exigências, o arquiteto de soluções precisa escolher uma solução de cache apropriada.",
        "Question": "Qual solução de cache o arquiteto de soluções deve escolher para atender aos requisitos da empresa?",
        "Options": {
            "1": "Escolher Memcached, pois oferece uma arquitetura simples e suporta uso multi-core para grandes nós.",
            "2": "Optar por uma solução de cache baseada em disco que possa persistir dados e fornecer criptografia.",
            "3": "Usar Redis por suas estruturas de dados avançadas e recursos de persistência, mesmo que não sejam necessários.",
            "4": "Implementar Amazon ElastiCache com Redis e configurá-lo para alta disponibilidade."
        },
        "Correct Answer": "Escolher Memcached, pois oferece uma arquitetura simples e suporta uso multi-core para grandes nós.",
        "Explanation": "Memcached é a escolha ideal para este cenário, pois fornece um modelo de cache simples, não requer criptografia e utiliza efetivamente múltiplos núcleos, permitindo desempenho ideal no manuseio de grandes nós. Além disso, suporta escalabilidade para cima e para baixo com base na demanda.",
        "Other Options": [
            "Redis, embora poderoso, introduz complexidade que é desnecessária dadas as exigências da empresa por simplicidade e a falta de necessidade por seus recursos avançados.",
            "Implementar Redis com alta disponibilidade adicionaria complexidade e custos desnecessários, já que a empresa está buscando uma solução simples sem a necessidade de persistência ou configurações avançadas.",
            "Uma solução de cache baseada em disco não é adequada, pois contradiz os requisitos de simplicidade e escalabilidade rápida, e a empresa declarou explicitamente que não precisa de persistência de dados."
        ]
    },
    {
        "Question Number": "43",
        "Situation": "Uma empresa de serviços financeiros processa dados sensíveis de clientes e é obrigada a cumprir rigorosos requisitos regulatórios em relação à proteção de dados. Eles precisam implementar criptografia tanto para dados em repouso quanto para dados em trânsito. A empresa está em busca de uma solução eficaz que garanta a confidencialidade e a integridade de seus dados ao longo de seu ciclo de vida.",
        "Question": "Qual das seguintes soluções de criptografia a empresa deve implementar para atender aos requisitos de dados em repouso e dados em trânsito?",
        "Options": {
            "1": "Implementar o AWS Secrets Manager para criptografar informações sensíveis e usar o AWS Direct Connect para transferência segura de dados entre o local e o AWS.",
            "2": "Usar o AWS Key Management Service (KMS) para criar e gerenciar chaves de criptografia para objetos do Amazon S3 e habilitar SSL/TLS para dados transmitidos pela Internet.",
            "3": "Configurar a criptografia do lado do servidor do Amazon S3 com uma solução de gerenciamento de chaves personalizada e configurar uma VPN para transmissão segura de dados.",
            "4": "Utilizar o Amazon RDS com armazenamento criptografado e habilitar conexões criptografadas usando autenticação IAM para dados transmitidos entre a aplicação e o banco de dados."
        },
        "Correct Answer": "Usar o AWS Key Management Service (KMS) para criar e gerenciar chaves de criptografia para objetos do Amazon S3 e habilitar SSL/TLS para dados transmitidos pela Internet.",
        "Explanation": "Usar o AWS Key Management Service (KMS) permite que a empresa gerencie chaves de criptografia de forma eficaz, garantindo que os dados em repouso no Amazon S3 estejam criptografados. Além disso, habilitar SSL/TLS garante que os dados em trânsito estejam criptografados, atendendo assim aos requisitos regulatórios para proteção de dados.",
        "Other Options": [
            "Embora usar o Amazon RDS com armazenamento criptografado forneça criptografia para dados em repouso, a autenticação IAM não criptografa diretamente os dados em trânsito; ela apenas autoriza o acesso, tornando esta opção incompleta para as necessidades da empresa.",
            "O AWS Secrets Manager é projetado para gerenciar segredos em vez de criptografar dados em repouso ou dados em trânsito de forma abrangente. O AWS Direct Connect, embora seguro, não fornece criptografia por si só, o que não atende completamente ao requisito.",
            "A criptografia do lado do servidor do Amazon S3 pode proteger dados em repouso, mas usar uma solução de gerenciamento de chaves personalizada pode introduzir complexidade e potenciais problemas de conformidade. Uma VPN pode proteger dados em trânsito, mas não garante criptografia para dados em trânsito pela Internet."
        ]
    },
    {
        "Question Number": "44",
        "Situation": "Uma empresa de serviços financeiros está planejando migrar suas aplicações de um data center local para o AWS usando o AWS Application Migration Service (AWS MGN). A empresa possui várias aplicações legadas que requerem tempo de inatividade mínimo durante a transição. Eles especificaram que desejam uma abordagem que automatize o processo de migração e reduza o risco de erros comumente associados a migrações manuais.",
        "Question": "Qual das seguintes estratégias utiliza melhor o AWS Application Migration Service (AWS MGN) para este cenário, garantindo uma migração lift-and-shift suave enquanto otimiza a aplicação para a nuvem?",
        "Options": {
            "1": "A empresa deve primeiro refatorar suas aplicações para serem nativas da nuvem antes de usar o AWS MGN, o que permitirá uma migração mais tranquila e melhor otimização no ambiente AWS.",
            "2": "A empresa deve usar a abordagem de snapshot sem agente do AWS MGN para criar um snapshot único de cada servidor, depois transferir manualmente as aplicações para o AWS, permitindo uma migração lift-and-shift rápida.",
            "3": "A empresa deve instalar o agente do AWS MGN em cada servidor de origem para replicar dados continuamente, permitindo um tempo de inatividade mínimo durante a transição, garantindo que as aplicações sejam migradas em seu estado original.",
            "4": "A empresa deve utilizar a abordagem de migração híbrida do AWS MGN, executando tanto os servidores locais quanto o ambiente AWS juntos por um período prolongado, garantindo que as aplicações estejam sincronizadas antes da transição final."
        },
        "Correct Answer": "A empresa deve instalar o agente do AWS MGN em cada servidor de origem para replicar dados continuamente, permitindo um tempo de inatividade mínimo durante a transição, garantindo que as aplicações sejam migradas em seu estado original.",
        "Explanation": "Usar o agente do AWS MGN em cada servidor de origem permite a replicação contínua de dados, reduzindo o tempo de inatividade e minimizando os riscos associados a processos de migração manuais. Isso garante que as aplicações possam ser migradas em seu estado original e ajuda a manter a continuidade dos negócios durante a migração.",
        "Other Options": [
            "Usar uma abordagem de snapshot sem agente cria apenas um snapshot único, que pode não capturar mudanças em andamento e pode resultar em perda de dados ou inconsistências durante o processo de migração.",
            "Refatorar aplicações antes de usar o AWS MGN não é necessário para uma migração lift-and-shift. O AWS MGN é projetado especificamente para facilitar migrações sem exigir alterações nas próprias aplicações.",
            "Utilizar uma abordagem de migração híbrida pode complicar o processo de migração e aumentar a duração de ter dois ambientes funcionando simultaneamente, o que não é ideal para minimizar o tempo de inatividade durante a migração lift-and-shift."
        ]
    },
    {
        "Question Number": "45",
        "Situation": "Uma organização está enfrentando problemas intermitentes de conectividade com um bucket do Amazon S3 a partir de várias aplicações em execução em instâncias EC2 em várias Zonas de Disponibilidade. As aplicações estão implantadas em uma Virtual Private Cloud (VPC) e usam endpoints da VPC para acessar o bucket S3 diretamente. A organização deseja identificar a causa raiz dos problemas de conectividade.",
        "Question": "Qual abordagem ajudará a organização a solucionar os problemas de conectividade com o bucket S3 usando ferramentas da AWS?",
        "Options": {
            "1": "Utilizar o AWS Trusted Advisor para analisar a configuração do bucket S3 e identificar quaisquer configurações incorretas.",
            "2": "Executar as regras do AWS Config para garantir que as instâncias EC2 estejam em conformidade com as melhores práticas para acesso ao S3.",
            "3": "Usar os Logs do Amazon CloudWatch para verificar os logs da aplicação em busca de mensagens de erro de timeout ou conexão relacionadas ao acesso ao S3.",
            "4": "Habilitar os Logs de Fluxo da VPC para as sub-redes que hospedam as instâncias EC2 para monitorar o fluxo de tráfego para e do bucket S3."
        },
        "Correct Answer": "Habilitar os Logs de Fluxo da VPC para as sub-redes que hospedam as instâncias EC2 para monitorar o fluxo de tráfego para e do bucket S3.",
        "Explanation": "Habilitar os Logs de Fluxo da VPC permite que a organização capture informações sobre o tráfego IP indo e vindo das instâncias EC2. Esses dados podem ajudar a identificar se os problemas de conectividade são devido a configurações de rede incorretas, regras de grupo de segurança ou outros fatores que afetam o fluxo de tráfego para o bucket S3.",
        "Other Options": [
            "Usar os Logs do Amazon CloudWatch para verificar logs de aplicação pode fornecer algumas informações, mas não oferece visibilidade sobre os problemas relacionados à rede que afetam diretamente o acesso ao S3.",
            "O AWS Trusted Advisor fornece principalmente recomendações de melhores práticas e pode não diagnosticar diretamente problemas de conectividade com recursos específicos, como buckets S3.",
            "Executar regras do AWS Config ajuda a garantir conformidade, mas não fornece análise de tráfego em tempo real ou logs que ajudariam na solução de problemas de conectividade."
        ]
    },
    {
        "Question Number": "46",
        "Situation": "Uma empresa de serviços financeiros precisa garantir que seus dados críticos sejam copiados regularmente e possam ser restaurados rapidamente em caso de desastre. Atualmente, eles utilizam o Amazon S3 para armazenamento, mas não têm certeza sobre a melhor estratégia de backup para atender aos seus objetivos de tempo de recuperação (RTO) e objetivos de ponto de recuperação (RPO).",
        "Question": "Qual estratégia de backup proporcionaria o método mais eficiente e confiável para garantir que os dados estejam protegidos e possam ser restaurados rapidamente, minimizando custos?",
        "Options": {
            "1": "Utilizar o Amazon Glacier para armazenamento de longo prazo dos dados de backup e restaurar sob demanda conforme necessário.",
            "2": "Criar um processo de backup manual que copie dados do S3 para um servidor local todas as noites.",
            "3": "Implementar o AWS Backup para automatizar cronogramas de backup e políticas de retenção para o Amazon S3.",
            "4": "Configurar replicação entre regiões para os buckets S3 para garantir disponibilidade e redundância dos dados."
        },
        "Correct Answer": "Implementar o AWS Backup para automatizar cronogramas de backup e políticas de retenção para o Amazon S3.",
        "Explanation": "O AWS Backup é projetado para gerenciar backups de forma centralizada em serviços da AWS, permitindo cronogramas de backup automatizados e políticas de retenção. Isso garante que os backups atendam efetivamente aos requisitos de RTO e RPO, minimizando a sobrecarga operacional e os custos associados a processos manuais.",
        "Other Options": [
            "Um processo de backup manual introduz o risco de erro humano, é intensivo em mão de obra e pode não garantir backups em tempo hábil, potencialmente violando os requisitos de RTO e RPO.",
            "Usar o Amazon Glacier é adequado para armazenamento de longo prazo, mas não é otimizado para restaurações rápidas, o que pode levar a atrasos inaceitáveis na recuperação de dados críticos.",
            "A replicação entre regiões é eficaz para disponibilidade e durabilidade dos dados, mas não aborda especificamente cronogramas de backup ou políticas de retenção, que são essenciais para atender aos objetivos de RTO e RPO."
        ]
    },
    {
        "Question Number": "47",
        "Situation": "Uma empresa global de comércio eletrônico está projetando uma aplicação web altamente disponível que deve atender a requisitos rigorosos de tempo de atividade, enquanto também acomoda a demanda flutuante dos usuários. A aplicação está hospedada na AWS e deve ser resiliente a falhas regionais e de zonas de disponibilidade. A empresa requer uma arquitetura que possa escalar automaticamente os recursos com base nos padrões de tráfego.",
        "Question": "Qual combinação de estratégias de design a empresa deve implementar para alcançar alta disponibilidade e escalabilidade para a aplicação? (Selecione Dois)",
        "Options": {
            "1": "Usar Elastic Load Balancing com verificações de integridade para distribuir o tráfego entre instâncias em uma única Zona de Disponibilidade.",
            "2": "Aproveitar o AWS Global Accelerator para melhorar a disponibilidade e o desempenho da aplicação globalmente.",
            "3": "Implementar o Amazon CloudFront como uma rede de entrega de conteúdo (CDN) para armazenar em cache conteúdo estático.",
            "4": "Utilizar um grupo de Auto Scaling com várias instâncias EC2 em várias Zonas de Disponibilidade.",
            "5": "Implantar a aplicação em várias regiões da AWS e usar o Amazon Route 53 para failover de DNS."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Utilizar um grupo de Auto Scaling com várias instâncias EC2 em várias Zonas de Disponibilidade.",
            "Implantar a aplicação em várias regiões da AWS e usar o Amazon Route 53 para failover de DNS."
        ],
        "Explanation": "Utilizar um grupo de Auto Scaling em várias Zonas de Disponibilidade garante que a aplicação possa escalar automaticamente com base na demanda, mantendo alta disponibilidade. Implantar em várias regiões da AWS com o Route 53 para failover de DNS proporciona resiliência adicional contra interrupções regionais, contribuindo para uma arquitetura robusta.",
        "Other Options": [
            "Implementar o Amazon CloudFront é benéfico para o desempenho, mas não aborda diretamente os requisitos de alta disponibilidade e escalabilidade para os serviços de backend da aplicação.",
            "Usar Elastic Load Balancing dentro de uma única Zona de Disponibilidade não fornece a redundância necessária; se essa zona falhar, a aplicação ficará indisponível.",
            "Embora o AWS Global Accelerator possa melhorar o desempenho e a disponibilidade, ele não fornece inerentemente uma arquitetura de alta disponibilidade sem serviços adicionais implantados em várias regiões ou zonas."
        ]
    },
    {
        "Question Number": "48",
        "Situation": "Uma empresa está projetando seu ambiente AWS para aprimorar a segurança e controlar o acesso aos seus recursos. O ambiente consiste em várias VPCs, cada uma hospedando diferentes aplicações. A empresa deseja implementar a segmentação de rede de forma eficaz para isolar cargas de trabalho, permitindo conectividade específica entre as VPCs.",
        "Question": "Qual abordagem proporcionará a MELHOR segmentação de rede enquanto permite comunicação controlada entre as VPCs?",
        "Options": {
            "1": "Implantar todas as aplicações em uma única VPC e utilizar ACLs de Rede para segmentar o tráfego com base nas necessidades da aplicação.",
            "2": "Implementar o AWS Transit Gateway para conectar várias VPCs enquanto mantém isolamento e controle sobre o fluxo de tráfego.",
            "3": "Criar VPCs separadas para cada aplicação e estabelecer conexões de peering entre VPCs para permitir tráfego específico entre elas.",
            "4": "Usar uma única VPC com várias sub-redes para todas as aplicações, configurando grupos de segurança para controlar o tráfego entre elas."
        },
        "Correct Answer": "Implementar o AWS Transit Gateway para conectar várias VPCs enquanto mantém isolamento e controle sobre o fluxo de tráfego.",
        "Explanation": "Usar o AWS Transit Gateway permite conectividade centralizada entre várias VPCs, possibilitando comunicação controlada enquanto mantém o isolamento de cada VPC. Essa abordagem simplifica a gestão e proporciona melhor escalabilidade em comparação com o peering direto de VPCs.",
        "Other Options": [
            "Usar uma única VPC com várias sub-redes carece de isolamento entre aplicações, aumentando o risco de acesso não intencional e complicando a gestão de segurança.",
            "Criar VPCs separadas com peering de VPC é uma boa abordagem, mas pode levar a configurações complexas à medida que o número de VPCs aumenta, e não escala tão eficientemente quanto o Transit Gateway.",
            "Implantar todas as aplicações em uma única VPC com ACLs de Rede não fornece isolamento adequado e pode levar a desafios de gestão à medida que o controle de tráfego se torna excessivamente complicado."
        ]
    },
    {
        "Question Number": "49",
        "Situation": "Uma corporação multinacional está utilizando o AWS Direct Connect para estabelecer uma conexão de rede dedicada de seu data center local para seus VPCs da AWS. Eles requerem alta capacidade de throughput e baixa latência para suas aplicações que operam em várias regiões. A corporação pretende se conectar a uma variedade de serviços da AWS, como EC2 e S3, e também possui requisitos de segurança para garantir que seus dados em trânsito sejam criptografados. Dadas suas necessidades arquitetônicas, eles estão avaliando suas opções para configurar as conexões do Direct Connect e interfaces virtuais.",
        "Question": "Qual configuração atenderá melhor aos requisitos da corporação para alta capacidade de throughput, baixa latência e conexões seguras aos serviços da AWS usando o Direct Connect?",
        "Options": {
            "1": "Estabelecer um gateway do Direct Connect em uma região pública. Configurar várias interfaces virtuais públicas para acessar serviços como S3 e EC2 sem criar uma VPN, que não criptografa o tráfego.",
            "2": "Configurar uma única conexão do Direct Connect com uma interface virtual privada para conectar-se a vários VPCs. Usar o AWS Transit Gateway para roteamento e confiar no AWS Shield para proteção contra DDoS sem implementar criptografia adicional.",
            "3": "Implantar duas conexões do Direct Connect no mesmo local, cada uma com uma interface virtual pública. Usar essas conexões apenas para acessar serviços da AWS como S3 e EC2 sem empregar medidas de segurança adicionais.",
            "4": "Criar duas conexões do Direct Connect em locais diferentes. Usar interfaces virtuais privadas para conectar-se ao gateway do Direct Connect, que pode rotear o tráfego para os VPCs. Implementar uma conexão VPN sobre a interface virtual pública para acesso seguro ao S3 e EC2."
        },
        "Correct Answer": "Criar duas conexões do Direct Connect em locais diferentes. Usar interfaces virtuais privadas para conectar-se ao gateway do Direct Connect, que pode rotear o tráfego para os VPCs. Implementar uma conexão VPN sobre a interface virtual pública para acesso seguro ao S3 e EC2.",
        "Explanation": "Esta opção atende a todos os requisitos ao utilizar duas conexões do Direct Connect para alta disponibilidade e baixa latência, conectando-se a vários VPCs através de um gateway do Direct Connect e garantindo que os dados em trânsito sejam criptografados via uma conexão VPN sobre a interface pública.",
        "Other Options": [
            "Esta opção fornece apenas uma única conexão do Direct Connect, que não garante alta disponibilidade e pode levar a um único ponto de falha. Embora usar uma interface virtual privada seja apropriado, confiar apenas no AWS Transit Gateway sem criptografia não atende aos requisitos de segurança.",
            "Esta opção não satisfaz o requisito de criptografia, pois utiliza interfaces virtuais públicas sem uma VPN. Além disso, não fornece a alta disponibilidade necessária para uma arquitetura robusta, já que está limitada a um gateway do Direct Connect em uma região.",
            "Usar duas conexões do Direct Connect no mesmo local não fornece redundância em diferentes áreas geográficas, o que é crítico para alta disponibilidade. Além disso, confiar apenas em interfaces virtuais públicas sem criptografia compromete a segurança dos dados."
        ]
    },
    {
        "Question Number": "50",
        "Situation": "Uma empresa de varejo está planejando lançar uma nova plataforma de e-commerce que experimentará alto tráfego durante eventos de vendas e exigirá diferentes padrões de acesso para interações com os clientes. A plataforma precisa suportar operações pesadas de leitura para navegação de produtos e operações pesadas de gravação para processamento de pedidos. Considerando escalabilidade, custo-efetividade e desempenho, você precisa projetar uma arquitetura adequada.",
        "Question": "Qual design de arquitetura melhor apoiaria os variados padrões de acesso e os altos requisitos de escalabilidade da plataforma de e-commerce?",
        "Options": {
            "1": "Configurar um banco de dados SQL tradicional em instâncias EC2 e escalar manualmente os recursos durante os períodos de pico.",
            "2": "Utilizar o Amazon RDS para todas as operações de banco de dados e implantar réplicas de leitura para lidar com alto tráfego de leitura.",
            "3": "Usar o Amazon Aurora com uma configuração multi-master para suportar operações de leitura e gravação de forma equilibrada em várias instâncias.",
            "4": "Implementar o Amazon DynamoDB com modo de capacidade sob demanda para lidar com cargas de trabalho variáveis e um bucket separado do Amazon S3 para ativos estáticos."
        },
        "Correct Answer": "Implementar o Amazon DynamoDB com modo de capacidade sob demanda para lidar com cargas de trabalho variáveis e um bucket separado do Amazon S3 para ativos estáticos.",
        "Explanation": "O Amazon DynamoDB com modo de capacidade sob demanda ajusta automaticamente seu throughput com base no tráfego, tornando-o ideal para cargas de trabalho variáveis típicas de plataformas de e-commerce. Além disso, usar o Amazon S3 para ativos estáticos ajuda a descarregar a entrega de imagens e arquivos, melhorando o desempenho e reduzindo a carga no banco de dados.",
        "Other Options": [
            "Embora o Amazon RDS com réplicas de leitura possa lidar com operações pesadas de leitura, pode não escalar efetivamente durante picos de tráfego súbitos. Também requer intervenção manual para escalar operações de gravação, o que pode levar a gargalos de desempenho.",
            "O Amazon Aurora com uma configuração multi-master fornece alta disponibilidade, mas pode ser complexo e caro de gerenciar, especialmente para uma nova plataforma de e-commerce. Esta opção pode não ser necessária, dadas as exigências de padrões de acesso variados.",
            "Usar um banco de dados SQL tradicional em instâncias EC2 carece da escalabilidade e gerenciamento automatizado que arquiteturas modernas nativas da nuvem oferecem. Requer um esforço manual significativo para escalar e pode não lidar com alto tráfego de forma eficiente."
        ]
    },
    {
        "Question Number": "51",
        "Situation": "Uma empresa implantou uma aplicação sem servidor usando funções do AWS Lambda que precisam acessar recursos dentro de um VPC privado. A aplicação está enfrentando um aumento nos erros de invocação, especificamente EC2ThrottledException, à medida que o tráfego aumentou. O arquiteto de soluções precisa garantir que a função Lambda possa escalar efetivamente sem atingir limites.",
        "Question": "O que o arquiteto de soluções deve fazer para resolver os erros de invocação enquanto mantém a escalabilidade da função Lambda?",
        "Options": {
            "1": "Mover a função Lambda para fora do VPC para melhorar a escalabilidade.",
            "2": "Criar um VPC maior com mais sub-redes para acomodar a função Lambda.",
            "3": "Aumentar o número de ENIs disponíveis e garantir endereços IP suficientes na sub-rede.",
            "4": "Usar várias funções Lambda para distribuir a carga entre diferentes VPCs."
        },
        "Correct Answer": "Aumentar o número de ENIs disponíveis e garantir endereços IP suficientes na sub-rede.",
        "Explanation": "Ao aumentar o número de Interfaces de Rede Elásticas (ENIs) disponíveis e garantir que haja endereços IP suficientes na sub-rede, a função Lambda pode escalar efetivamente dentro do VPC, reduzindo os erros de invocação relacionados à limitação.",
        "Other Options": [
            "Mover a função Lambda para fora do VPC comprometeria sua capacidade de acessar os recursos do VPC privado, que é essencial para a operação da aplicação.",
            "Usar várias funções Lambda em diferentes VPCs complicaria a arquitetura e poderia introduzir latência adicional e sobrecarga de gerenciamento sem resolver as limitações de ENI.",
            "Criar um VPC maior com mais sub-redes não aborda diretamente a questão da insuficiência de ENIs ou endereços IP dentro das sub-redes existentes e pode não ser uma solução viável."
        ]
    },
    {
        "Question Number": "52",
        "Situation": "Uma empresa está buscando otimizar seus custos na AWS enquanto garante visibilidade sobre seus padrões de gastos. A equipe financeira foi encarregada de identificar qualquer potencial excesso de gastos e garantir que os orçamentos futuros sejam respeitados. Eles querem usar ferramentas da AWS que possam ajudá-los a monitorar o uso e os custos de forma eficaz, sem incorrer em cobranças adicionais.",
        "Question": "Qual combinação de ferramentas da AWS forneceria à equipe financeira a melhor visão geral dos padrões de gastos, ajudaria a identificar excessos de gastos e permitiria que eles definissem orçamentos para o uso futuro?",
        "Options": {
            "1": "Utilizar o AWS Cost Explorer para visualizar tendências de uso e custo, e configurar o AWS Budgets para monitorar e alertar sobre limites orçamentários.",
            "2": "Aproveitar o AWS Budgets exclusivamente para rastrear limites de gastos enquanto se baseia nos logs do AWS CloudTrail para análise de uso.",
            "3": "Implementar o AWS Trusted Advisor para verificar recomendações de otimização de custos e usar o AWS Pricing Calculator para estimar custos de projetos futuros.",
            "4": "Implantar o AWS Trusted Advisor e integrá-lo ao AWS Config para monitorar continuamente a conformidade relacionada à gestão de custos."
        },
        "Correct Answer": "Utilizar o AWS Cost Explorer para visualizar tendências de uso e custo, e configurar o AWS Budgets para monitorar e alertar sobre limites orçamentários.",
        "Explanation": "Essa combinação do AWS Cost Explorer e AWS Budgets fornece uma solução abrangente para monitorar e gerenciar custos. O Cost Explorer permite uma análise visual dos padrões de gastos, enquanto o Budgets possibilita o rastreamento proativo dos gastos em relação a limites predefinidos, garantindo que a equipe financeira possa identificar excessos de gastos precocemente.",
        "Other Options": [
            "Embora o AWS Trusted Advisor forneça recomendações úteis para otimização de custos, ele não oferece o mesmo nível de análise histórica detalhada que o AWS Cost Explorer. O AWS Pricing Calculator é útil para estimar custos, mas não ajuda a monitorar custos em andamento de forma eficaz.",
            "Usar o AWS Budgets sozinho não fornece visibilidade sobre tendências de gastos. Os logs do AWS CloudTrail rastreiam chamadas de API, mas não oferecem uma visão geral de custo ou uso, tornando-o menos eficaz para a adesão ao orçamento e identificação de excessos de gastos.",
            "O AWS Trusted Advisor oferece insights, mas não fornece monitoramento contínuo para conformidade na gestão de custos. O AWS Config foca na conformidade de configuração de recursos em vez da gestão de custos, tornando essa combinação menos eficaz para os objetivos da equipe financeira."
        ]
    },
    {
        "Question Number": "53",
        "Situation": "Uma empresa de serviços financeiros está construindo um sistema de processamento de transações em tempo real usando AWS Lambda, Kinesis Data Streams e Amazon DynamoDB. Espera-se que o sistema lide com altos volumes de transações por segundo, exigindo processamento de dados eficiente e latência mínima. Os desenvolvedores querem otimizar o comportamento de agrupamento de suas funções Lambda para garantir que processem registros rapidamente, maximizando ainda o throughput. Eles estão particularmente preocupados com a configuração dos parâmetros MaximumBatchingWindowInSeconds e BatchSize para o mapeamento da fonte de eventos Kinesis.",
        "Question": "Qual das seguintes configurações otimizará melhor o comportamento de agrupamento para o processamento Lambda de fluxos de dados Kinesis neste cenário?",
        "Options": {
            "1": "Definir MaximumBatchingWindowInSeconds para 0 segundos e BatchSize para 1000 registros para garantir latência mínima e throughput máximo.",
            "2": "Definir MaximumBatchingWindowInSeconds para 500 milissegundos e BatchSize para 500 registros para equilibrar latência e throughput.",
            "3": "Definir MaximumBatchingWindowInSeconds para 300 segundos e BatchSize para 300 registros para maximizar a janela de agrupamento.",
            "4": "Definir MaximumBatchingWindowInSeconds para 100 milissegundos e BatchSize para 10 registros para reduzir o tempo de processamento."
        },
        "Correct Answer": "Definir MaximumBatchingWindowInSeconds para 0 segundos e BatchSize para 1000 registros para garantir latência mínima e throughput máximo.",
        "Explanation": "Definir MaximumBatchingWindowInSeconds para 0 segundos permite que o Lambda processe registros imediatamente à medida que chegam, o que é crucial para o processamento de transações em tempo real. Um BatchSize de 1000 registros maximiza o throughput ao permitir que a função lide com um maior número de registros em cada invocação. Essa configuração é ideal para cenários de alto volume, como o processamento de transações.",
        "Other Options": [
            "Definir MaximumBatchingWindowInSeconds para 500 milissegundos e BatchSize para 500 registros pode introduzir latência desnecessária, já que a função esperaria meio segundo antes de processar, potencialmente atrasando o processamento de registros recebidos.",
            "Definir MaximumBatchingWindowInSeconds para 300 segundos é excessivo para processamento em tempo real, pois atrasa significativamente o processamento de registros. Um BatchSize de 300 registros pode não utilizar totalmente as capacidades de throughput do fluxo Kinesis em cenários de alto volume.",
            "Definir MaximumBatchingWindowInSeconds para 100 milissegundos e BatchSize para 10 registros não aproveita o throughput disponível do Kinesis. Essa configuração provavelmente levaria à subutilização de recursos e aumento da latência."
        ]
    },
    {
        "Question Number": "54",
        "Situation": "Um aplicativo móvel enfrenta problemas de latência ao buscar dados de vários microsserviços implantados na AWS. O aplicativo utiliza o AWS API Gateway para gerenciar solicitações e respostas de API. Atualmente, a configuração do API Gateway emprega funções Lambda para processamento de backend, mas os usuários estão relatando tempos de resposta lentos. A arquitetura é projetada para lidar com uma base de usuários global com condições de rede variadas, e a equipe de desenvolvimento deseja otimizar o desempenho sem comprometer a segurança ou aumentar significativamente os custos.",
        "Question": "Qual é a maneira mais eficaz de melhorar o desempenho da configuração do API Gateway para este aplicativo móvel?",
        "Options": {
            "1": "Implantar um Elastic Load Balancer (ELB) dedicado na frente do API Gateway para distribuir as solicitações recebidas de forma mais uniforme entre os microsserviços, melhorando os tempos de resposta.",
            "2": "Usar o recurso de cache embutido do API Gateway para armazenar dados frequentemente acessados pelo aplicativo móvel, minimizando chamadas para o Lambda e reduzindo a latência geral.",
            "3": "Implementar o CloudFront na frente do API Gateway para armazenar em cache as respostas e reduzir a latência para usuários globais, enquanto usa cabeçalhos de controle de cache personalizados para conteúdo dinâmico.",
            "4": "Aumentar a configuração de tempo limite do API Gateway para permitir tempos de processamento mais longos para solicitações, garantindo que todas as respostas sejam retornadas mesmo que levem mais tempo para processar."
        },
        "Correct Answer": "Implementar o CloudFront na frente do API Gateway para armazenar em cache as respostas e reduzir a latência para usuários globais, enquanto usa cabeçalhos de controle de cache personalizados para conteúdo dinâmico.",
        "Explanation": "Implementar o CloudFront na frente do API Gateway permite o armazenamento em cache das respostas, o que reduz significativamente a latência para usuários em diferentes regiões. Isso é particularmente benéfico para uma base de usuários global, pois aproveita locais de borda para entregar conteúdo rapidamente sem precisar acessar repetidamente os serviços de backend, otimizando assim o desempenho de forma eficaz.",
        "Other Options": [
            "Aumentar a configuração de tempo limite do API Gateway não aborda a causa raiz da latência e pode levar a tempos de espera mais longos para os usuários sem garantir respostas mais rápidas.",
            "Implantar um Elastic Load Balancer (ELB) dedicado na frente do API Gateway é desnecessário e pode introduzir complexidade e custo adicionais, já que o API Gateway já é projetado para lidar com solicitações de forma eficiente.",
            "Usar o recurso de cache embutido do API Gateway é benéfico, mas pode não ser tão eficaz quanto aproveitar o CloudFront para uma base de usuários global, especialmente para conteúdo dinâmico que requer estratégias de cache sofisticadas."
        ]
    },
    {
        "Question Number": "55",
        "Situation": "Uma empresa de serviços financeiros está procurando conectar seu data center local a múltiplos VPCs da AWS em diferentes regiões usando o AWS Direct Connect. Eles precisam de uma solução que permita uma conexão privada enquanto mantém flexibilidade no roteamento de tráfego para vários VPCs em diferentes contas. O arquiteto deve garantir que a solução siga as melhores práticas da AWS para Direct Connect e conectividade VPC.",
        "Question": "Qual das seguintes configurações o Solutions Architect deve implementar para atender aos requisitos da empresa?",
        "Options": {
            "1": "Criar uma conexão Direct Connect e um gateway Direct Connect. Anexar o gateway aos gateways virtuais privados dos VPCs em diferentes contas e regiões. Criar interfaces virtuais privadas para o gateway Direct Connect para cada VPC.",
            "2": "Criar uma conexão Direct Connect com uma interface virtual pública para acessar os serviços da AWS. Configurar o emparelhamento de VPC entre os VPCs para permitir a comunicação.",
            "3": "Usar o AWS Transit Gateway para criar um hub de roteamento centralizado. Conectar o data center local ao Transit Gateway com uma conexão Direct Connect e configurar anexos de VPC para múltiplos VPCs em diferentes contas.",
            "4": "Estabelecer uma conexão Direct Connect e criar interfaces virtuais privadas diretamente para cada VPC sem usar um gateway Direct Connect, permitindo o roteamento direto."
        },
        "Correct Answer": "Criar uma conexão Direct Connect e um gateway Direct Connect. Anexar o gateway aos gateways virtuais privados dos VPCs em diferentes contas e regiões. Criar interfaces virtuais privadas para o gateway Direct Connect para cada VPC.",
        "Explanation": "Usar um gateway Direct Connect permite conectividade privada a múltiplos VPCs em diferentes contas e regiões, seguindo as melhores práticas para Direct Connect. Isso possibilita a criação de interfaces virtuais privadas adaptadas para cada VPC, garantindo roteamento seguro e eficiente.",
        "Other Options": [
            "Esta opção sugere incorretamente o uso de uma interface virtual pública, que não é adequada para conectividade privada a VPCs em diferentes contas e regiões. Os gateways Direct Connect são especificamente projetados para interfaces virtuais privadas.",
            "Embora o uso de um Transit Gateway simplifique o roteamento, esta opção não aborda diretamente a necessidade de uma interface virtual privada para conectar a múltiplos VPCs em diferentes contas. Um gateway Direct Connect ainda é necessário para conexões privadas.",
            "Esta opção está incorreta, pois contorna o uso de um gateway Direct Connect. Os gateways Direct Connect são necessários para criar interfaces virtuais privadas para múltiplos VPCs, especialmente quando estão em diferentes contas."
        ]
    },
    {
        "Question Number": "56",
        "Situation": "Uma empresa está implantando um aplicativo em múltiplas camadas na AWS que requer atualizações e patches regulares para garantir segurança e conformidade. O aplicativo é executado em uma frota de instâncias Amazon EC2 gerenciadas por grupos de Auto Scaling. A empresa está em busca de um processo robusto para automatizar a aplicação de patches em suas instâncias, minimizando o tempo de inatividade e garantindo que o aplicativo permaneça disponível durante as atualizações.",
        "Question": "Qual das seguintes opções o Solutions Architect deve implementar para projetar um processo eficaz de patch e atualização? (Selecione duas)",
        "Options": {
            "1": "Aproveitar o AWS Elastic Beanstalk para gerenciar o ambiente do aplicativo e aplicar patches como parte do processo de implantação.",
            "2": "Usar o AWS OpsWorks Stacks para definir uma receita Chef personalizada que trate especificamente da aplicação de patches e atualizações para as instâncias EC2.",
            "3": "Utilizar o AWS Systems Manager Patch Manager para automatizar a aplicação de patches nas instâncias EC2 durante janelas de manutenção especificadas.",
            "4": "Criar um alarme do Amazon CloudWatch que acione uma função Lambda para executar o processo de patch em todas as instâncias EC2 simultaneamente.",
            "5": "Implementar um gancho de ciclo de vida do Auto Scaling para pausar o processo de terminação da instância durante a fase de patch para garantir que nenhuma instância seja perdida."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Utilizar o AWS Systems Manager Patch Manager para automatizar a aplicação de patches nas instâncias EC2 durante janelas de manutenção especificadas.",
            "Aproveitar o AWS Elastic Beanstalk para gerenciar o ambiente do aplicativo e aplicar patches como parte do processo de implantação."
        ],
        "Explanation": "Usar o AWS Systems Manager Patch Manager permite a automação dos processos de aplicação de patches com base em janelas de manutenção definidas, garantindo que as instâncias sejam atualizadas de maneira controlada. Além disso, o AWS Elastic Beanstalk oferece suporte integrado para gerenciar atualizações de aplicativos, permitindo que os patches sejam integrados ao processo de implantação de forma contínua, minimizando assim o tempo de inatividade.",
        "Other Options": [
            "Criar um alarme do Amazon CloudWatch que acione uma função Lambda para aplicar patches em todas as instâncias EC2 simultaneamente pode levar a potenciais períodos de inatividade e interrupção do serviço. Essa abordagem carece de controle sobre o processo de patch e pode não garantir alta disponibilidade durante as atualizações.",
            "Implementar um gancho de ciclo de vida do Auto Scaling para pausar o processo de terminação da instância não facilita diretamente o processo de patch. Ele apenas atrasa a terminação das instâncias, mas não automatiza a aplicação de patches em si.",
            "Usar o AWS OpsWorks Stacks para definir uma receita Chef personalizada para patch é uma opção viável, mas introduz complexidade e requer manutenção contínua das receitas Chef. Pode não ser a abordagem mais eficiente ou direta em comparação ao uso do Patch Manager."
        ]
    },
    {
        "Question Number": "57",
        "Situation": "Uma plataforma de e-commerce está planejando usar o Amazon DynamoDB para armazenar dados de sessão de usuários devido à sua escalabilidade e desempenho de baixa latência. O arquiteto de soluções é encarregado de garantir que a arquitetura possa lidar com picos súbitos de tráfego durante eventos de vendas. O arquiteto precisa escolher uma configuração apropriada de capacidade de leitura e escrita para a tabela do DynamoDB para atender a esses requisitos.",
        "Question": "Qual das seguintes configurações o arquiteto de soluções deve implementar para garantir desempenho ideal durante o tráfego de pico enquanto minimiza custos durante a operação normal?",
        "Options": {
            "1": "Capacidade provisionada com autoescalonamento habilitado para ajustar com base nos padrões de tráfego.",
            "2": "Modo de capacidade sob demanda para escalar automaticamente para cima e para baixo com base no tráfego sem intervenção manual.",
            "3": "Usar uma camada de cache na frente do DynamoDB para lidar com todas as solicitações de leitura e provisionar baixa capacidade de escrita.",
            "4": "Capacidade provisionada com uma alta capacidade de leitura e escrita fixa definida para lidar com cargas de pico o tempo todo."
        },
        "Correct Answer": "Modo de capacidade sob demanda para escalar automaticamente para cima e para baixo com base no tráfego sem intervenção manual.",
        "Explanation": "O modo de capacidade sob demanda é projetado para lidar com cargas de trabalho imprevisíveis e escala automaticamente para cima e para baixo com base no tráfego real. Isso o torna ideal para lidar com picos súbitos de tráfego, permitindo economias de custo durante a operação normal.",
        "Other Options": [
            "Capacidade provisionada com autoescalonamento pode funcionar, mas requer configuração e monitoramento cuidadosos para garantir que responda rapidamente o suficiente a picos, o que pode levar a estrangulamentos se não for configurado corretamente.",
            "Capacidade provisionada com uma alta capacidade de leitura e escrita fixa incorre em custos desnecessários durante períodos de baixo tráfego, pois os recursos são reservados independentemente do uso real.",
            "Usar uma camada de cache pode reduzir a carga de leitura no DynamoDB, mas não aborda a questão da capacidade de escrita. Isso pode complicar a arquitetura sem fornecer uma solução completa para lidar com picos de tráfego."
        ]
    },
    {
        "Question Number": "58",
        "Situation": "Uma organização de saúde está executando várias aplicações na AWS que processam dados sensíveis de pacientes. Eles precisam garantir que seus dados estejam em conformidade com as regulamentações e que quaisquer incidentes de segurança sejam rapidamente remediados. A organização identificou que várias funções do IAM têm permissões excessivas e deseja implementar uma solução para corrigir esse problema sem causar interrupções nos serviços.",
        "Question": "Qual técnica de remediação o arquiteto de soluções deve implementar para abordar as permissões excessivas do IAM, garantindo ao mesmo tempo um impacto mínimo nas aplicações?",
        "Options": {
            "1": "Implementar o AWS CloudTrail para registrar todas as ações do IAM e, em seguida, revisar os registros antes de fazer quaisquer alterações nas permissões para garantir que nenhuma interrupção ocorra.",
            "2": "Agendar uma revisão das permissões do IAM a cada seis meses para identificar e reduzir permissões excessivas sem mudanças imediatas.",
            "3": "Criar novas funções do IAM com o menor privilégio e gradualmente fazer a transição das aplicações para usar essas funções, monitorando quaisquer problemas de acesso.",
            "4": "Remover imediatamente todas as permissões excessivas das funções existentes do IAM, garantindo que nenhuma função tenha mais permissões do que o necessário."
        },
        "Correct Answer": "Criar novas funções do IAM com o menor privilégio e gradualmente fazer a transição das aplicações para usar essas funções, monitorando quaisquer problemas de acesso.",
        "Explanation": "Criar novas funções do IAM com o menor privilégio permite que a organização mantenha a continuidade do serviço enquanto reduz o risco de permissões excessivas. A transição gradual garante que quaisquer problemas de acesso possam ser detectados e resolvidos sem impactar as aplicações.",
        "Other Options": [
            "Remover imediatamente permissões excessivas pode levar a falhas nas aplicações se as funções perderem acesso crítico. Essa abordagem não permite testes ou monitoramento antes que as mudanças sejam feitas.",
            "Embora o AWS CloudTrail seja útil para registro e auditoria, confiar apenas nos registros para revisar permissões atrasa o processo de remediação e não reduz ativamente o risco de permissões excessivas.",
            "Agendar uma revisão a cada seis meses não fornece remediação oportuna dos riscos de segurança. Ação imediata é necessária para abordar o problema das permissões excessivas."
        ]
    },
    {
        "Question Number": "59",
        "Situation": "Uma empresa de mídia precisa armazenar grandes arquivos de vídeo que são acessados frequentemente durante as primeiras semanas após seu lançamento, mas uma vez que o interesse inicial diminui, o acesso a esses arquivos cai significativamente. A empresa planeja manter esses arquivos de vídeo por um mínimo de três anos e visa minimizar os custos de armazenamento.",
        "Question": "Qual das seguintes classes de armazenamento do S3 proporcionaria a solução mais econômica para armazenar esses arquivos de vídeo, atendendo aos requisitos de acesso e retenção?",
        "Options": {
            "1": "Amazon S3 Intelligent-Tiering para mover automaticamente os arquivos entre as camadas de acesso com base nos padrões de uso.",
            "2": "Amazon S3 Standard durante o período de retenção, pois oferece o melhor desempenho para dados acessados frequentemente.",
            "3": "Amazon S3 One Zone-IA nos primeiros meses, depois transitar para Amazon S3 Standard-IA.",
            "4": "Amazon S3 Standard nos primeiros 30 dias, depois transitar para Amazon S3 Glacier para armazenamento a longo prazo."
        },
        "Correct Answer": "Amazon S3 Intelligent-Tiering para mover automaticamente os arquivos entre as camadas de acesso com base nos padrões de uso.",
        "Explanation": "Amazon S3 Intelligent-Tiering é ideal para este cenário, pois ajusta automaticamente a classe de armazenamento com base na frequência de acesso dos arquivos de vídeo, otimizando custos enquanto garante que eles estejam prontamente disponíveis quando necessário. Essa classe se adapta aos padrões de acesso flutuantes dos arquivos de vídeo durante o período de retenção especificado.",
        "Other Options": [
            "Amazon S3 Standard nos primeiros 30 dias, depois transitar para Amazon S3 Glacier não é ideal, pois embora o Glacier seja econômico para armazenamento a longo prazo, não é projetado para acesso frequente, o que pode levar a custos de recuperação mais altos e atrasos quando os vídeos ainda estão em demanda.",
            "Amazon S3 One Zone-IA nos primeiros meses, depois transitar para Amazon S3 Standard-IA está incorreto porque One Zone-IA é menos durável do que outras classes. Se houver uma perda de disponibilidade nessa zona, os arquivos de vídeo podem ser irrecuperáveis, tornando-o inadequado para armazenamento de mídia crítica.",
            "Amazon S3 Standard durante o período de retenção não é econômico neste caso, pois não fornece a otimização de custos necessária para os períodos de acesso infrequente após as semanas iniciais, levando a custos gerais de armazenamento mais altos."
        ]
    },
    {
        "Question Number": "60",
        "Situation": "Uma startup está buscando aproveitar os serviços gerenciados da AWS para construir uma nova aplicação que requer um backend robusto para processamento e armazenamento de dados. A equipe deseja minimizar a sobrecarga operacional e se concentrar no desenvolvimento da aplicação em vez da gestão da infraestrutura. Eles estão considerando vários serviços gerenciados da AWS para atender às suas necessidades.",
        "Question": "Qual combinação de serviços gerenciados da AWS a startup deve utilizar para atender eficientemente aos requisitos de sua aplicação? (Selecione Dois)",
        "Options": {
            "1": "Implantar o Amazon ECS para orquestração de contêineres e o Amazon RDS para serviços de banco de dados relacionais.",
            "2": "Utilizar o Amazon EC2 para toda a hospedagem da aplicação e o Amazon EBS para necessidades de armazenamento.",
            "3": "Aproveitar o AWS Elastic Beanstalk para gerenciamento de aplicações e o Amazon CloudFront para entrega de conteúdo.",
            "4": "Implementar o AWS Lambda para computação sem servidor e o Amazon DynamoDB para armazenamento de banco de dados NoSQL.",
            "5": "Usar o Amazon RDS para gerenciamento de banco de dados e o Amazon S3 para armazenamento de objetos."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Usar o Amazon RDS para gerenciamento de banco de dados e o Amazon S3 para armazenamento de objetos.",
            "Implementar o AWS Lambda para computação sem servidor e o Amazon DynamoDB para armazenamento de banco de dados NoSQL."
        ],
        "Explanation": "Usar o Amazon RDS permite que a startup se beneficie de um serviço de banco de dados relacional totalmente gerenciado, reduzindo tarefas administrativas como backups e gerenciamento de patches. O Amazon S3 fornece armazenamento de objetos escalável para dados não estruturados. O AWS Lambda facilita a computação sem servidor, permitindo que a equipe execute código sem provisionar servidores, enquanto o DynamoDB oferece um banco de dados NoSQL totalmente gerenciado que escala automaticamente com base na demanda, perfeito para aplicações modernas.",
        "Other Options": [
            "Utilizar o Amazon EC2 para toda a hospedagem da aplicação introduz uma sobrecarga operacional significativa, pois a startup precisaria gerenciar os servidores subjacentes, o que vai contra seu objetivo de minimizar a gestão da infraestrutura.",
            "Aproveitar o AWS Elastic Beanstalk é uma boa opção para gerenciamento de aplicações, mas emparelhá-lo com o Amazon CloudFront não atende efetivamente às suas necessidades de armazenamento de dados ou processamento de backend.",
            "Implantar o Amazon ECS para orquestração de contêineres é uma escolha válida, mas confiar apenas no Amazon RDS não utiliza totalmente as vantagens de uma arquitetura sem servidor que o AWS Lambda e o DynamoDB podem oferecer."
        ]
    },
    {
        "Question Number": "61",
        "Situation": "Uma empresa de serviços financeiros está migrando sua arquitetura de aplicação para a AWS. Eles têm a necessidade de armazenar grandes volumes de dados de transações de forma segura e com alta durabilidade. Além disso, precisam garantir que os dados sejam replicados em diferentes regiões para fins de recuperação de desastres. Eles estão considerando vários serviços de armazenamento da AWS para atender a esses requisitos.",
        "Question": "Qual das seguintes estratégias o Arquiteto de Soluções deve recomendar para garantir o armazenamento seguro e altamente durável dos dados de transações com replicação entre regiões?",
        "Options": {
            "1": "Usar o Amazon S3 com versionamento habilitado e configurar a replicação entre regiões (CRR) para replicar automaticamente objetos para outro bucket S3 em uma região diferente.",
            "2": "Implementar o Amazon ElastiCache com persistência de dados habilitada e configurar grupos de replicação entre regiões para garantir que os dados em cache estejam disponíveis durante uma falha.",
            "3": "Utilizar o Amazon RDS com implantações Multi-AZ para fornecer alta disponibilidade e failover automático, e habilitar réplicas de leitura em outra região para recuperação de desastres.",
            "4": "Usar o Amazon EFS para armazenamento de arquivos e habilitar a replicação entre regiões para garantir que os sistemas de arquivos sejam replicados para outra região para recuperação de desastres."
        },
        "Correct Answer": "Usar o Amazon S3 com versionamento habilitado e configurar a replicação entre regiões (CRR) para replicar automaticamente objetos para outro bucket S3 em uma região diferente.",
        "Explanation": "O Amazon S3 fornece uma solução de armazenamento altamente durável com 99.999999999% de durabilidade. Habilitar o versionamento permite que você mantenha várias versões de um objeto, e a replicação entre regiões (CRR) replica automaticamente objetos para uma região diferente, garantindo que os dados estejam seguros e disponíveis em caso de falha regional.",
        "Other Options": [
            "Embora o Amazon RDS com implantações Multi-AZ forneça alta disponibilidade e capacidades de failover, ele não suporta intrinsecamente a replicação entre regiões para recuperação de desastres. Esta opção não atenderia ao requisito de replicação entre regiões.",
            "O Amazon ElastiCache é usado principalmente para cache e não é projetado para armazenamento durável de longo prazo de dados de transações. Embora suporte replicação, não garante o mesmo nível de durabilidade exigido para dados de transações.",
            "O Amazon EFS não suporta replicação entre regiões nativamente. Embora seja uma boa escolha para armazenamento de arquivos, não pode atender ao requisito de garantir que os arquivos sejam replicados para outra região para recuperação de desastres."
        ]
    },
    {
        "Question Number": "62",
        "Situation": "Uma empresa de serviços financeiros está migrando suas aplicações de computação de alto desempenho (HPC) para a AWS. Essas aplicações requerem capacidades de rede de baixa latência e alta taxa de transferência para alcançar desempenho ideal em várias instâncias EC2. A empresa está considerando usar o Elastic Fabric Adapter (EFA) para melhorar o desempenho das comunicações entre instâncias. Eles querem garantir que sua estratégia de migração aproveite ao máximo as capacidades do EFA.",
        "Question": "O que a empresa deve fazer para garantir que o EFA seja efetivamente utilizado para suas aplicações HPC na AWS?",
        "Options": {
            "1": "Selecionar tipos de instâncias EC2 que suportem EFA, habilitar EFA durante o lançamento da instância e configurar suas aplicações para usar as capacidades de rede aprimoradas.",
            "2": "Usar o Amazon ECS para executar versões em contêiner de suas aplicações HPC sem habilitar EFA, confiando apenas na rede padrão do EC2.",
            "3": "Lançar instâncias EC2 que não são otimizadas para desempenho de rede e configurá-las para usar o Elastic Network Adapter (ENA) padrão.",
            "4": "Implantar instâncias EC2 com EFA habilitado, mas restringir as aplicações de utilizar os recursos de rede aprimorados para evitar problemas de compatibilidade."
        },
        "Correct Answer": "Selecionar tipos de instâncias EC2 que suportem EFA, habilitar EFA durante o lançamento da instância e configurar suas aplicações para usar as capacidades de rede aprimoradas.",
        "Explanation": "Ao selecionar tipos de instâncias EC2 que suportam EFA e habilitar EFA durante o lançamento da instância, a empresa pode se beneficiar das capacidades de rede de baixa latência e alta taxa de transferência que o EFA fornece, que são essenciais para o desempenho das aplicações HPC.",
        "Other Options": [
            "Lançar instâncias EC2 que não são otimizadas para desempenho de rede e usar o Elastic Network Adapter (ENA) padrão não aproveitaria as capacidades do EFA, levando a um desempenho subótimo para as aplicações HPC.",
            "Implantar instâncias EC2 com EFA habilitado, mas restringir as aplicações de utilizar recursos de rede aprimorados negaria os benefícios do EFA, pois as aplicações não poderiam aproveitar a rede de baixa latência e alta taxa de transferência.",
            "Usar o Amazon ECS para executar versões em contêiner das aplicações HPC sem habilitar EFA não maximiza o desempenho da rede, já que a rede padrão do EC2 carece das melhorias fornecidas pelo EFA."
        ]
    },
    {
        "Question Number": "63",
        "Situation": "Uma empresa de serviços financeiros está planejando migrar sua aplicação existente local para a AWS. A aplicação é construída sobre um framework .NET, utiliza um banco de dados Microsoft SQL Server e experimenta flutuações significativas de carga ao longo do mês. A empresa requer uma arquitetura escalável que possa lidar com cargas de trabalho variadas sem exigir intervenção manual significativa. Além disso, a aplicação precisa manter alta disponibilidade e capacidades de recuperação de desastres. A equipe está explorando opções que lhes permitam aproveitar serviços gerenciados sempre que possível e garantir um tempo de inatividade mínimo durante a transição.",
        "Question": "Qual dos seguintes designs arquitetônicos melhor apoiaria os requisitos da empresa durante a migração para a AWS?",
        "Options": {
            "1": "Migrar a aplicação .NET para instâncias EC2 gerenciadas por um grupo de Auto Scaling. Usar o Amazon RDS com SQL Server, mas configurá-lo sem implantação Multi-AZ. Criar um Elastic Load Balancer para distribuir o tráfego e ajustar manualmente as instâncias EC2 conforme necessário para lidar com mudanças de carga.",
            "2": "Adotar o AWS Elastic Beanstalk para gerenciar a aplicação .NET e configurar um Application Load Balancer para distribuir o tráfego. Usar o Amazon RDS com SQL Server para necessidades de banco de dados e configurar Multi-AZ para alta disponibilidade e failover automático. Implementar o AWS Auto Scaling para lidar com cargas de trabalho flutuantes.",
            "3": "Utilizar o AWS Fargate para executar a aplicação .NET como um serviço em contêiner, juntamente com o Amazon Aurora para necessidades de banco de dados SQL. Implementar um Network Load Balancer para gerenciamento de tráfego e escalonamento manual com base em padrões de carga observados.",
            "4": "Implantar a aplicação .NET no Amazon ECS com tipo de lançamento EC2 para gerenciar os contêineres. Usar o Amazon RDS com SQL Server e configurar Multi-AZ para alta disponibilidade. Implementar um Application Load Balancer para direcionar o tráfego e aproveitar o CloudWatch para monitoramento e escalonamento."
        },
        "Correct Answer": "Adotar o AWS Elastic Beanstalk para gerenciar a aplicação .NET e configurar um Application Load Balancer para distribuir o tráfego. Usar o Amazon RDS com SQL Server para necessidades de banco de dados e configurar Multi-AZ para alta disponibilidade e failover automático. Implementar o AWS Auto Scaling para lidar com cargas de trabalho flutuantes.",
        "Explanation": "Esta opção fornece um serviço totalmente gerenciado através do AWS Elastic Beanstalk, que simplifica a implantação, gerenciamento e escalonamento da aplicação .NET. Também inclui o Amazon RDS com Multi-AZ para alta disponibilidade, garantindo integridade dos dados e recuperação rápida em caso de falha, enquanto o AWS Auto Scaling garante adaptabilidade durante cargas de trabalho flutuantes.",
        "Other Options": [
            "Esta opção carece da configuração Multi-AZ para o Amazon RDS, que é crucial para alta disponibilidade e recuperação de desastres. Além disso, confiar em ajustes manuais para instâncias EC2 não atende ao requisito de intervenção manual mínima durante mudanças de carga.",
            "Executar a aplicação .NET no AWS Fargate pode não utilizar a arquitetura existente de forma eficiente, especialmente se a aplicação não for projetada para containerização. Além disso, o Amazon Aurora não é um substituto direto para o SQL Server, o que pode complicar o processo de migração.",
            "Usar o Amazon ECS com tipo de lançamento EC2 adiciona sobrecarga na gestão das instâncias EC2 subjacentes, o que vai contra a abordagem de serviço gerenciado desejada pela empresa. Embora o Multi-AZ esteja incluído para o RDS, a complexidade da orquestração de contêineres pode não atender aos requisitos para uma migração sem costura."
        ]
    },
    {
        "Question Number": "64",
        "Situation": "Uma empresa de serviços financeiros está migrando seu aplicativo para a AWS e deseja garantir que possa aproveitar tecnologias avançadas como aprendizado de máquina e análise de dados sem exigir uma extensa expertise interna. O objetivo é automatizar a implantação e tornar a tecnologia acessível para suas equipes de desenvolvimento, enquanto cumpre as normas de conformidade regulatória.",
        "Question": "Qual das seguintes soluções permitirá que a empresa delegue tarefas complexas de aprendizado de máquina e análise para a AWS, garantindo conformidade e acessibilidade para suas equipes de desenvolvimento?",
        "Options": {
            "1": "Usar o Amazon Elastic MapReduce (EMR) para análise e exigir que a equipe de desenvolvimento gerencie manualmente a infraestrutura subjacente para garantir conformidade.",
            "2": "Implementar o AWS Glue para preparação de dados e tarefas de ETL, mas exigir que os desenvolvedores lidem com o treinamento e a implantação de modelos de aprendizado de máquina de forma independente.",
            "3": "Adotar o AWS Lambda para funções sem servidor para executar inferências de aprendizado de máquina, mas fazer com que os desenvolvedores mantenham seus próprios modelos de aprendizado de máquina em instâncias EC2.",
            "4": "Utilizar o Amazon SageMaker para construir, treinar e implantar modelos de aprendizado de máquina, enquanto usa o AWS CloudFormation para gerenciar a infraestrutura como código."
        },
        "Correct Answer": "Utilizar o Amazon SageMaker para construir, treinar e implantar modelos de aprendizado de máquina, enquanto usa o AWS CloudFormation para gerenciar a infraestrutura como código.",
        "Explanation": "Esta opção fornece uma solução abrangente que abstrai a complexidade do aprendizado de máquina, permitindo que a empresa mantenha a conformidade. O Amazon SageMaker permite um desenvolvimento e implantação de modelos simplificados, enquanto o AWS CloudFormation garante que a infraestrutura possa ser gerenciada de forma eficiente e consistente.",
        "Other Options": [
            "Embora o Amazon EMR seja uma ferramenta poderosa para análise de dados, exigir que a equipe de desenvolvimento gerencie manualmente a infraestrutura subjacente contradiz o objetivo de delegar tarefas complexas e adiciona uma carga operacional desnecessária.",
            "O AWS Glue é uma excelente escolha para tarefas de ETL, mas pedir aos desenvolvedores que lidem com o treinamento e a implantação de modelos de aprendizado de máquina de forma independente cria silos de expertise e complica os esforços de conformidade.",
            "O AWS Lambda pode ser usado para inferência, mas fazer com que os desenvolvedores gerenciem seus próprios modelos de aprendizado de máquina em instâncias EC2 introduz complexidade e reduz a acessibilidade de tecnologias avançadas."
        ]
    },
    {
        "Question Number": "65",
        "Situation": "Uma empresa multinacional está buscando otimizar o desempenho de seu aplicativo web, que atende usuários globalmente. O aplicativo está hospedado na região us-east-1, e a empresa está preocupada com a latência para usuários localizados na Europa e na Ásia. O arquiteto de soluções precisa implementar uma solução que garanta baixa latência e alta disponibilidade para usuários ao redor do mundo.",
        "Question": "Qual das seguintes soluções atenderá melhor aos requisitos da empresa para otimização de desempenho global?",
        "Options": {
            "1": "Implementar o Amazon CloudFront como uma rede de entrega de conteúdo (CDN) para armazenar em cache conteúdo estático em locais de borda mais próximos dos usuários, enquanto também permite a entrega de conteúdo dinâmico.",
            "2": "Usar o AWS Global Accelerator para direcionar o tráfego do usuário para o ponto de extremidade do aplicativo mais próximo, otimizando o desempenho e melhorando a disponibilidade por meio de roteamento inteligente.",
            "3": "Utilizar o AWS Lambda@Edge para executar código personalizado em locais de borda da AWS, permitindo processamento de dados em tempo real e geração de respostas próximas ao usuário.",
            "4": "Implantar o aplicativo web em várias regiões da AWS e usar o Amazon Route 53 para geo-roteamento para direcionar os usuários à região mais próxima, garantindo latência mínima."
        },
        "Correct Answer": "Usar o AWS Global Accelerator para direcionar o tráfego do usuário para o ponto de extremidade do aplicativo mais próximo, otimizando o desempenho e melhorando a disponibilidade por meio de roteamento inteligente.",
        "Explanation": "O AWS Global Accelerator melhora o desempenho do aplicativo direcionando o tráfego do usuário para o ponto de extremidade mais otimizado com base na localização do usuário e na saúde dos pontos de extremidade. Ele melhora a disponibilidade e reduz a latência, tornando-se uma escolha adequada para otimização de desempenho global.",
        "Other Options": [
            "Embora implementar o Amazon CloudFront seja uma boa abordagem para armazenar em cache conteúdo estático e reduzir a latência, não otimiza especificamente o roteamento de conteúdo dinâmico ou garante alta disponibilidade em vários pontos de extremidade do aplicativo.",
            "Implantar o aplicativo web em várias regiões da AWS com o Amazon Route 53 para geo-roteamento é benéfico, mas pode introduzir complexidade na gestão de várias implantações e não fornece o mesmo nível de roteamento inteligente que o AWS Global Accelerator.",
            "Usar o AWS Lambda@Edge pode melhorar o desempenho para casos de uso específicos ao executar lógica personalizada em locais de borda, mas não otimiza inerentemente o roteamento do tráfego do usuário para o ponto de extremidade do aplicativo mais próximo, como faz o AWS Global Accelerator."
        ]
    },
    {
        "Question Number": "66",
        "Situation": "Uma empresa startup está lançando um novo serviço de streaming de vídeo online. Espera-se que o serviço tenha uma base de usuários flutuante, com uma média de 5.000 usuários simultâneos e picos de até 50.000 usuários simultâneos durante eventos populares. A empresa deseja garantir que pague apenas pelos recursos que precisa e quer implementar uma infraestrutura econômica enquanto mantém uma experiência de streaming de alta qualidade. Eles estão considerando diferentes soluções de armazenamento para conteúdo de vídeo e capacidades de streaming.",
        "Question": "Qual das seguintes arquiteturas fornecerá a solução mais econômica para entregar conteúdo de vídeo em streaming enquanto se ajusta dinamicamente à demanda do usuário?",
        "Options": {
            "1": "Usar o Amazon S3 para armazenar arquivos de vídeo e implementar os AWS Elemental Media Services para processar e escalar os streams de vídeo, garantindo entrega ideal durante os picos de demanda.",
            "2": "Utilizar o Amazon Elastic Transcoder para converter arquivos de vídeo e armazená-los no Amazon S3, depois usar funções do AWS Lambda para atender as solicitações diretamente do S3 sem usar uma rede de entrega de conteúdo.",
            "3": "Armazenar arquivos de vídeo diretamente no Amazon EFS e montá-los em uma frota de instâncias Amazon EC2. Usar essas instâncias para transmitir conteúdo diretamente para os usuários sem nenhuma camada de cache.",
            "4": "Usar o Amazon S3 para armazenar arquivos de vídeo, combinado com o Amazon CloudFront para entrega de conteúdo. Implementar um grupo de Auto Scaling de instâncias Amazon EC2 para atender as solicitações com um balanceador de carga à frente para gerenciar o tráfego de entrada."
        },
        "Correct Answer": "Usar o Amazon S3 para armazenar arquivos de vídeo e implementar os AWS Elemental Media Services para processar e escalar os streams de vídeo, garantindo entrega ideal durante os picos de demanda.",
        "Explanation": "Esta opção aproveita o Amazon S3 para armazenamento econômico e os AWS Elemental Media Services para processamento e escalonamento eficientes, o que garante entrega de alta qualidade durante os períodos de pico. Esta arquitetura se ajusta dinamicamente com base na demanda, tornando-se uma solução econômica para streaming de vídeo.",
        "Other Options": [
            "Esta opção depende de instâncias EC2 e de um balanceador de carga, o que pode levar a custos mais altos devido à necessidade de recursos sempre ativos, especialmente durante períodos de baixa utilização, quando pode não ser necessário ter várias instâncias EC2 em execução.",
            "Usar o Amazon EFS para armazenamento de vídeo não é ideal para streaming devido a possíveis problemas de latência, e pode ser mais caro do que o S3. Esta opção não inclui uma camada de cache que poderia melhorar o desempenho e reduzir custos.",
            "Embora o Amazon Elastic Transcoder seja útil para converter formatos de vídeo, atender solicitações diretamente do S3 sem uma CDN pode levar a um aumento de latência e custos, especialmente durante períodos de pico, quando uma CDN poderia melhorar o desempenho e reduzir a carga no bucket do S3."
        ]
    },
    {
        "Question Number": "67",
        "Situation": "Uma grande empresa de e-commerce está enfrentando um aumento no tráfego devido a um evento promocional. Eles estão preocupados com possíveis ataques de Negação de Serviço Distribuída (DDoS) que podem interromper seus serviços online. A empresa deseja implementar uma solução que ofereça proteção robusta contra vários ataques DDoS, garantindo ao mesmo tempo um impacto mínimo no desempenho de suas aplicações. Eles também precisam ser notificados sobre qualquer atividade suspeita que possa afetar seus recursos.",
        "Question": "Qual das seguintes soluções atenderá melhor aos requisitos da empresa para proteção contra DDoS e notificação?",
        "Options": {
            "1": "Implementar o AWS Shield Advanced para proteção abrangente contra DDoS e utilizar o AWS WAF para criar regras que filtram o tráfego. Ativar o registro para análise detalhada de ataques e configurar notificações através do Amazon SNS.",
            "2": "Usar o AWS Shield Standard para proteção básica contra DDoS e implementar o Route 53 para roteamento DNS. Criar uma solução de monitoramento personalizada para rastrear padrões de tráfego e alertar a equipe.",
            "3": "Ativar o AWS Shield Advanced para proteção aprimorada contra DDoS e configurar o CloudFront para armazenar em cache o conteúdo. Configurar alarmes do Amazon CloudWatch para monitoramento de atividade e notificações.",
            "4": "Ativar o AWS Shield Standard para proteção automática contra DDoS e integrar o Elastic Load Balancing para distribuição de tráfego. Confiar no AWS CloudTrail para monitoramento e resposta a incidentes."
        },
        "Correct Answer": "Implementar o AWS Shield Advanced para proteção abrangente contra DDoS e utilizar o AWS WAF para criar regras que filtram o tráfego. Ativar o registro para análise detalhada de ataques e configurar notificações através do Amazon SNS.",
        "Explanation": "O AWS Shield Advanced oferece proteção aprimorada contra ataques DDoS sofisticados e, quando combinado com o AWS WAF, permite a criação de regras personalizadas para filtrar tráfego malicioso. Além disso, ativar o registro fornece insights sobre padrões de ataque, e usar o Amazon SNS permite notificações em tempo real para a equipe, atendendo efetivamente aos requisitos da empresa.",
        "Other Options": [
            "Embora ativar o AWS Shield Advanced seja uma boa escolha, configurar o CloudFront sozinho não fornece a proteção abrangente contra DDoS necessária, e sem registro e notificação, falta capacidades críticas de monitoramento.",
            "O AWS Shield Standard oferece proteção básica, mas não fornece as notificações detalhadas ou capacidades de detecção avançada que a empresa requer. Uma solução de monitoramento personalizada pode não ser tão eficaz quanto os serviços integrados da AWS.",
            "O AWS Shield Standard fornece proteção automática, mas sem os recursos avançados do AWS Shield Advanced e do AWS WAF, a solução carece da personalização e capacidades de registro necessárias para alertar a equipe sobre ameaças potenciais."
        ]
    },
    {
        "Question Number": "68",
        "Situation": "Uma empresa global de jogos online deseja garantir alta disponibilidade e baixo tempo de recuperação para sua infraestrutura de jogos multiplayer. Atualmente, eles estão operando em uma única região da AWS, mas desejam aprimorar sua estratégia de recuperação de desastres. A empresa precisa de uma solução que lhes permita alcançar 4 9s (99,99%) de disponibilidade com um tempo de recuperação rápido, utilizando recursos em uma região secundária.",
        "Question": "Qual das seguintes arquiteturas a empresa pode implementar para alcançar 4 9s de disponibilidade e garantir um tempo de recuperação muito curto enquanto utiliza apenas uma região ativa?",
        "Options": {
            "1": "Implementar um grupo de Auto Scaling em uma região e configurar um mecanismo de failover que ativa outro grupo de Auto Scaling em uma região secundária apenas quando a região primária falha.",
            "2": "Utilizar o Amazon S3 para armazenamento de dados do jogo em uma região e replicar os dados para uma região secundária usando replicação entre regiões, mantendo os servidores de jogo ativos apenas na região primária.",
            "3": "Configurar uma instância do Amazon RDS com implantações Multi-AZ na região primária e uma réplica de leitura em outra região para garantir a disponibilidade de dados e uma rápida troca em caso de falha.",
            "4": "Implantar os servidores de jogo em uma única região da AWS e usar o Amazon Route 53 com verificações de saúde para redirecionar o tráfego para uma região de espera quando a região primária falhar."
        },
        "Correct Answer": "Utilizar o Amazon S3 para armazenamento de dados do jogo em uma região e replicar os dados para uma região secundária usando replicação entre regiões, mantendo os servidores de jogo ativos apenas na região primária.",
        "Explanation": "Ao utilizar o Amazon S3 para armazenamento de dados do jogo e habilitar a replicação entre regiões, a empresa pode garantir que os dados estejam sempre disponíveis em uma região secundária. Isso permite uma recuperação rápida em caso de falha na região primária, enquanto mantém os recursos utilizados de forma eficiente em uma região ativa.",
        "Other Options": [
            "Implantar servidores de jogo em uma única região da AWS com verificações de saúde do Route 53 não garante o tempo de recuperação necessário ou a disponibilidade de dados na região secundária, pois os servidores de jogo não estariam operacionais até que a troca ocorra.",
            "Implementar um grupo de Auto Scaling em uma região com um mecanismo de failover para outra região não forneceria a disponibilidade desejada de 4 9s, pois o grupo secundário estaria inativo até ser acionado por uma falha.",
            "Configurar uma instância do Amazon RDS com implantações Multi-AZ garante alta disponibilidade, mas não permite uma recuperação rápida usando recursos de uma região secundária, já que a réplica de leitura não é usada ativamente para gravações."
        ]
    },
    {
        "Question Number": "69",
        "Situation": "Uma empresa de serviços financeiros está buscando otimizar seus gastos na AWS e melhorar a visibilidade de custos entre vários departamentos. A empresa deseja implementar uma estratégia de etiquetagem que lhes permita alocar custos de forma eficaz e gerar relatórios com base nessas etiquetas. Eles estão considerando várias opções para etiquetar seus recursos da AWS.",
        "Question": "Qual abordagem o Arquiteto de Soluções deve recomendar para garantir alocação de custos e relatórios eficazes por meio de etiquetagem?",
        "Options": {
            "1": "Criar um script que etiqueta recursos com base na data de criação e aplica automaticamente uma etiqueta padrão para o ambiente. Usar o AWS Lambda para executar esse script regularmente para relatórios de custos.",
            "2": "Etiquetar recursos manualmente em uma base mensal antes de gerar relatórios de custos. Usar o Amazon QuickSight para visualizar custos com base nas etiquetas criadas durante esse processo manual.",
            "3": "Usar o AWS Config para impor conformidade de etiquetagem de recursos e etiquetar automaticamente recursos com base em seu tipo. Gerar relatórios de alocação de custos com base nessas etiquetas atribuídas automaticamente usando o AWS Budgets.",
            "4": "Implementar uma política de etiquetagem consistente em todas as contas da AWS, garantindo que cada recurso seja etiquetado com identificadores-chave para o departamento, projeto e ambiente. Utilizar o AWS Cost Explorer para analisar custos com base nessas etiquetas."
        },
        "Correct Answer": "Implementar uma política de etiquetagem consistente em todas as contas da AWS, garantindo que cada recurso seja etiquetado com identificadores-chave para o departamento, projeto e ambiente. Utilizar o AWS Cost Explorer para analisar custos com base nessas etiquetas.",
        "Explanation": "Uma política de etiquetagem consistente permite a categorização adequada dos custos entre departamentos, projetos e ambientes. Usar o AWS Cost Explorer permite a análise de custos com base nessas etiquetas, fornecendo insights claros sobre gastos e ajudando a otimizar orçamentos de forma eficaz.",
        "Other Options": [
            "Usar o AWS Config para impor conformidade pode não abordar totalmente a necessidade de uma estratégia de etiquetagem proativa. Etiquetas atribuídas automaticamente podem não se alinhar com as necessidades específicas de negócios para alocação de custos.",
            "Etiquetar recursos manualmente pode levar a inconsistências e erros, tornando difícil confiar nas etiquetas para relatórios de custos precisos. Além disso, essa abordagem não é escalável ou eficiente para gerenciamento contínuo.",
            "Etiquetar recursos com base na data de criação não fornece contexto significativo para alocação de custos. Etiquetas padrão podem não representar com precisão o propósito do recurso, levando a análises de custos incompletas ou enganosas."
        ]
    },
    {
        "Question Number": "70",
        "Situation": "Uma corporação multinacional opera em várias regiões e precisa estabelecer uma conexão segura e confiável entre seu data center local e seu ambiente AWS. A empresa requer baixa latência e alta largura de banda para transferência de dados, enquanto também garante que a conexão permaneça resiliente em caso de falha. Além disso, a empresa precisa evitar qualquer dependência da internet pública para essa conectividade.",
        "Question": "Qual serviço da AWS oferece a melhor solução para estabelecer uma conexão dedicada, de alta largura de banda e baixa latência entre o data center local e a AWS, ao mesmo tempo em que oferece opções de redundância em caso de falha da conexão primária?",
        "Options": {
            "1": "AWS Direct Connect com um backup de Rede Privada Virtual (VPN).",
            "2": "AWS Direct Connect com uma conexão redundante em um local diferente.",
            "3": "AWS Site-to-Site VPN com múltiplos túneis VPN para redundância.",
            "4": "AWS Transit Gateway conectado a múltiplas conexões VPN para failover."
        },
        "Correct Answer": "AWS Direct Connect com uma conexão redundante em um local diferente.",
        "Explanation": "O AWS Direct Connect fornece uma conexão de rede dedicada que oferece menor latência e maior largura de banda em comparação com soluções baseadas na internet. Ao estabelecer uma conexão redundante em um local diferente, a empresa garante alta disponibilidade e resiliência contra falhas de conexão, o que é crítico para suas operações.",
        "Other Options": [
            "O AWS Site-to-Site VPN é uma opção viável para conexões seguras; no entanto, ele depende da internet pública, o que pode introduzir latência e limitações de largura de banda. Embora múltiplos túneis VPN possam oferecer redundância, eles não correspondem à natureza dedicada do Direct Connect.",
            "O AWS Transit Gateway pode conectar múltiplas conexões VPN, mas ainda depende da internet pública para essas conexões. Essa configuração pode não fornecer a baixa latência e a alta largura de banda que a empresa requer para suas operações.",
            "O AWS Direct Connect com um backup de VPN pode aumentar a segurança, mas, em caso de falha da conexão primária, a conexão VPN ainda dependerá da internet pública, o que pode levar a problemas de latência e pode não atender aos requisitos da empresa para uma conexão dedicada."
        ]
    },
    {
        "Question Number": "71",
        "Situation": "Uma empresa de serviços financeiros passou por uma interrupção significativa em sua arquitetura multi-região hospedada na AWS. A equipe de operações agora tem a tarefa de identificar a causa raiz e garantir que os procedimentos de recuperação sejam implementados de forma eficaz. Eles querem simular um cenário de falha para validar seus processos de resposta a emergências e melhorar seu plano de recuperação de desastres. (Selecione Dois.)",
        "Question": "Quais das seguintes atividades o arquiteto de soluções deve implementar para exercitar a compreensão das ações de recuperação durante essa simulação?",
        "Options": {
            "1": "Criar um runbook para operações diárias e incluir procedimentos para lidar com falhas simuladas para orientar a equipe.",
            "2": "Configurar um processo de backup automatizado usando o AWS Backup para proteger dados críticos antes de realizar as simulações.",
            "3": "Realizar uma restauração completa da aplicação a partir do backup mais recente em um ambiente de teste para validar o processo de recuperação.",
            "4": "Conduzir um exercício de mesa com as partes interessadas chave para revisar o plano de resposta a incidentes e os passos de recuperação.",
            "5": "Implantar uma função AWS Lambda que possa reverter automaticamente as alterações feitas no ambiente de produção durante a simulação."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Conduzir um exercício de mesa com as partes interessadas chave para revisar o plano de resposta a incidentes e os passos de recuperação.",
            "Realizar uma restauração completa da aplicação a partir do backup mais recente em um ambiente de teste para validar o processo de recuperação."
        ],
        "Explanation": "Conduzir um exercício de mesa permite que a equipe discuta e refine o plano de resposta a incidentes sem o risco de interrupções reais. Realizar uma restauração completa a partir de um backup valida o processo de recuperação real, garantindo que a aplicação possa ser restaurada de forma eficaz em caso de uma falha real.",
        "Other Options": [
            "Embora configurar um processo de backup automatizado seja importante, isso não testa diretamente as ações de recuperação ou o plano de resposta a incidentes durante a simulação.",
            "Implantar uma função AWS Lambda para reverter alterações é útil para gerenciar mudanças, mas não simula efetivamente o processo de recuperação em um cenário de falha.",
            "Criar um runbook para operações diárias é valioso para orientar a equipe, mas não substitui a necessidade de exercícios práticos para testar ações de recuperação."
        ]
    },
    {
        "Question Number": "72",
        "Situation": "Uma empresa de serviços financeiros requer uma solução segura para gerenciar chaves de criptografia de dados sensíveis e certificados SSL/TLS em toda a sua infraestrutura. A empresa deseja garantir que todas as chaves de criptografia sejam gerenciadas centralmente, rotacionadas regularmente e integradas com suas aplicações para conformidade de segurança de dados. O arquiteto de soluções precisa implementar as melhores práticas para gerenciamento de chaves e implantação de certificados.",
        "Question": "Qual das seguintes soluções é a mais apropriada para gerenciar chaves de criptografia e certificados neste cenário?",
        "Options": {
            "1": "Implantar uma solução de gerenciamento de chaves local e gerenciar manualmente os certificados SSL/TLS para aplicações hospedadas na AWS.",
            "2": "Usar o AWS Key Management Service (AWS KMS) para gerenciamento de chaves e o AWS Certificate Manager (ACM) para provisionar e gerenciar certificados SSL/TLS para as aplicações.",
            "3": "Utilizar o AWS Secrets Manager para gerenciamento de chaves e o AWS CloudFormation para implantar certificados SSL/TLS automaticamente.",
            "4": "Implementar funções AWS Lambda para rotacionar chaves de criptografia e gerenciar certificados SSL/TLS diretamente no código da aplicação."
        },
        "Correct Answer": "Usar o AWS Key Management Service (AWS KMS) para gerenciamento de chaves e o AWS Certificate Manager (ACM) para provisionar e gerenciar certificados SSL/TLS para as aplicações.",
        "Explanation": "O AWS Key Management Service (AWS KMS) fornece uma maneira centralizada de criar e gerenciar chaves criptográficas, incluindo rotação automática de chaves e integração com outros serviços da AWS. O AWS Certificate Manager (ACM) simplifica o gerenciamento de certificados SSL/TLS, incluindo renovações automáticas, o que se alinha perfeitamente com os requisitos de segurança da empresa.",
        "Other Options": [
            "Esta opção introduz complexidade e risco desnecessários, uma vez que gerenciar uma solução de gerenciamento de chaves local não aproveita os recursos de segurança integrados da AWS, e o gerenciamento manual de certificados pode levar a possíveis descuidos e vulnerabilidades de segurança.",
            "O AWS Secrets Manager é projetado para gerenciar segredos como chaves de API e credenciais de banco de dados, mas não é otimizado para gerenciamento de chaves de criptografia. Além disso, usar o CloudFormation para certificados SSL/TLS não fornece o mesmo nível de automação e manutenção que o AWS Certificate Manager.",
            "Embora o AWS Lambda possa ser usado para várias tarefas de automação, não é uma solução adequada para rotação de chaves e gerenciamento de certificados. Essa abordagem adiciona sobrecarga e complexidade desnecessárias, carecendo dos recursos de gerenciamento centralizado que o AWS KMS e o ACM oferecem."
        ]
    },
    {
        "Question Number": "73",
        "Situation": "Uma empresa de serviços financeiros está desenvolvendo uma função AWS Lambda que precisa acessar um banco de dados hospedado em uma VPC privada. Espera-se que a função escale em resposta a altas cargas durante períodos de pico de transações. No entanto, a equipe está enfrentando erros frequentes de EC2ThrottledException, indicando que a função Lambda não consegue escalar adequadamente.",
        "Question": "O que o arquiteto de soluções deve recomendar para otimizar o desempenho da função Lambda e garantir que ela escale efetivamente dentro do ambiente VPC?",
        "Options": {
            "1": "Ajustar as configurações de concorrência da função Lambda e garantir que haja endereços IP e ENIs disponíveis suficientes nas sub-redes da VPC.",
            "2": "Aumentar o número de ENIs disponíveis na VPC modificando as configurações da VPC para permitir mais interfaces de rede elásticas.",
            "3": "Implantar a função Lambda fora da VPC para permitir que ela escale livremente sem as limitações impostas pelas configurações da VPC.",
            "4": "Configurar uma instância EC2 dedicada para lidar com as solicitações em vez de usar uma função Lambda dentro da VPC."
        },
        "Correct Answer": "Ajustar as configurações de concorrência da função Lambda e garantir que haja endereços IP e ENIs disponíveis suficientes nas sub-redes da VPC.",
        "Explanation": "Ajustar as configurações de concorrência da função Lambda permite que ela lide com mais solicitações simultaneamente. Garantir que haja endereços IP e ENIs disponíveis suficientes nas sub-redes da VPC evita a limitação e erros de invocação, permitindo que a função escale adequadamente à medida que a demanda aumenta.",
        "Other Options": [
            "Aumentar o número de ENIs disponíveis sozinho pode não resolver os problemas subjacentes relacionados à concorrência e limites de escalabilidade da função Lambda. É essencial gerenciar tanto os ENIs quanto as configurações de concorrência.",
            "Implantar a função Lambda fora da VPC eliminaria a necessidade de configurações relacionadas à VPC e permitiria escalabilidade, mas não permitiria o acesso ao banco de dados hospedado dentro da VPC privada, que é um requisito.",
            "Configurar uma instância EC2 dedicada exigiria gerenciar a infraestrutura do servidor, o que vai contra o modelo sem servidor que o Lambda oferece. Essa abordagem não resolve os problemas de escalabilidade da função Lambda dentro da VPC."
        ]
    },
    {
        "Question Number": "74",
        "Situation": "Uma empresa de varejo está desenvolvendo um novo aplicativo que lidará com gerenciamento de inventário, pedidos de clientes e análises em tempo real. O aplicativo requer uma arquitetura altamente escalável que possa se ajustar automaticamente a cargas variáveis e utilizar serviços específicos para tarefas específicas, como armazenamento de dados, computação e análises. O arquiteto de soluções precisa selecionar serviços da AWS que melhor se adequem a esses requisitos, garantindo desempenho e custo-efetividade ideais.",
        "Question": "Qual das seguintes abordagens o arquiteto de soluções deve adotar para garantir que o aplicativo utilize os serviços da AWS corretos para cada tarefa?",
        "Options": {
            "1": "Utilizar AWS Lambda para computação sem servidor, Amazon RDS para dados estruturados e Amazon Redshift para análises.",
            "2": "Selecionar Amazon EFS para armazenamento de arquivos, Amazon Lightsail para necessidades básicas de computação e Amazon QuickSight para inteligência de negócios.",
            "3": "Aproveitar instâncias Amazon EC2 para todos os requisitos de computação e usar Amazon S3 para armazenamento de dados.",
            "4": "Implementar Amazon ECS para gerenciamento de contêineres, usar Amazon DynamoDB para armazenamento de dados NoSQL e AWS Glue para transformação de dados."
        },
        "Correct Answer": "Utilizar AWS Lambda para computação sem servidor, Amazon RDS para dados estruturados e Amazon Redshift para análises.",
        "Explanation": "Essa abordagem utiliza efetivamente serviços específicos que se alinham com os requisitos do aplicativo. AWS Lambda permite computação sem servidor, que é altamente escalável e custo-efetiva para cargas variáveis. Amazon RDS é ideal para gerenciamento de dados estruturados, enquanto Amazon Redshift é otimizado para análises em tempo real, tornando essa combinação a melhor opção.",
        "Other Options": [
            "Usar instâncias Amazon EC2 para todos os requisitos de computação pode levar a superprovisionamento e custos mais altos, pois não aproveita as opções sem servidor que podem escalar automaticamente com a demanda.",
            "Implementar Amazon ECS e AWS Glue pode ser adequado para certos casos de uso, mas não aborda de forma ideal todos os requisitos, especialmente em relação ao gerenciamento de dados estruturados e análises em tempo real tão efetivamente quanto a resposta correta.",
            "Selecionar Amazon EFS e Amazon Lightsail não fornece a escalabilidade e as otimizações específicas necessárias para um aplicativo robusto de gerenciamento de inventário e análises, tornando-o menos adequado em comparação com a resposta correta."
        ]
    },
    {
        "Question Number": "75",
        "Situation": "Uma plataforma de e-commerce global requer sincronização de dados em tempo real em várias regiões geográficas para garantir que os clientes tenham uma experiência contínua, independentemente de sua localização. A arquitetura inclui um catálogo de produtos online e um banco de dados transacional que deve permanecer consistente. O Arquiteto de Soluções precisa configurar o banco de dados para suportar replicação de alta disponibilidade e baixa latência entre as regiões da AWS.",
        "Question": "Qual das seguintes opções o Arquiteto de Soluções deve implementar para alcançar uma replicação de dados eficaz, garantindo alta disponibilidade e baixa latência?",
        "Options": {
            "1": "Implementar Amazon RDS com implantações Multi-AZ em cada região e replicar dados manualmente entre as regiões usando AWS Data Pipeline.",
            "2": "Implantar Amazon RDS com réplicas de leitura entre regiões e habilitar backups automáticos para recuperação de desastres.",
            "3": "Usar Amazon DynamoDB com tabelas globais para fornecer dados totalmente replicados em várias regiões na plataforma.",
            "4": "Configurar Amazon Aurora com réplicas entre regiões para acesso de baixa latência e capacidades automáticas de failover."
        },
        "Correct Answer": "Usar Amazon DynamoDB com tabelas globais para fornecer dados totalmente replicados em várias regiões na plataforma.",
        "Explanation": "As tabelas globais do Amazon DynamoDB permitem dados totalmente replicados em várias regiões, proporcionando acesso de baixa latência a usuários em diferentes locais geográficos. Essa arquitetura atende ao requisito de sincronização de dados em tempo real e alta disponibilidade sem intervenção manual.",
        "Other Options": [
            "Implantar Amazon RDS com réplicas de leitura entre regiões oferece alguma capacidade de replicação, mas não alcança o mesmo acesso de baixa latência e capacidades automáticas de failover que as tabelas globais do DynamoDB.",
            "Implementar Amazon RDS com implantações Multi-AZ oferece alta disponibilidade dentro de uma região, mas não aborda a replicação entre regiões e requer sincronização manual de dados, o que pode levar a maior complexidade e latência.",
            "Configurar Amazon Aurora com réplicas entre regiões é uma solução válida para alta disponibilidade, mas pode não fornecer a mesma facilidade de uso e sincronização em tempo real que as tabelas globais do DynamoDB, especialmente para uma plataforma de e-commerce com dados dinâmicos."
        ]
    }
]