[
    {
        "Question Number": "1",
        "Situation": "한 미디어 회사가 여러 EC2 인스턴스에서 파일에 대한 공유 액세스를 요구하는 애플리케이션을 개발하고 있습니다. 이 애플리케이션은 자주 변경되는 멀티미디어 파일을 처리해야 하며, POSIX 파일 시스템 의미론에 따라 접근 가능해야 합니다. 회사는 이 목적을 위해 Amazon EFS를 사용하는 것을 고려하고 있으며, 지역 장애 발생 시 데이터 가용성과 내구성을 보장하고자 합니다.",
        "Question": "회사가 여러 AWS 리전에서 Amazon EFS 파일 시스템의 높은 가용성과 빠른 복구를 보장하기 위해 어떤 구성을 구현해야 합니까?",
        "Options": {
            "1": "Amazon EFS 파일 시스템을 생성하고 다른 AWS 리전의 다른 Amazon EFS 파일 시스템으로 복제를 활성화합니다.",
            "2": "기본 EFS 파일 시스템과 다른 리전의 보조 EFS 파일 시스템 간의 파일 전송을 관리하기 위해 EC2 인스턴스를 설정합니다.",
            "3": "파일 저장을 위해 Amazon S3를 사용하고, 오래된 멀티미디어 파일을 아카이브하기 위해 S3 수명 주기 정책을 설정합니다.",
            "4": "단일 가용 영역에 Amazon EFS 파일 시스템을 배포하고 AWS Backup을 사용하여 정기적인 백업을 생성합니다."
        },
        "Correct Answer": "Amazon EFS 파일 시스템을 생성하고 다른 AWS 리전의 다른 Amazon EFS 파일 시스템으로 복제를 활성화합니다.",
        "Explanation": "Amazon EFS 파일 시스템에 대한 복제를 활성화하면 서로 다른 리전의 기본 및 보조 파일 시스템 간에 데이터의 자동 및 지속적인 동기화가 가능합니다. 이는 높은 가용성을 제공하며 회사가 요구하는 복구 지점 및 복구 시간 목표를 충족합니다.",
        "Other Options": [
            "단일 가용 영역에 Amazon EFS 파일 시스템을 배포하는 것은 지역 장애 발생 시 필요한 내구성과 가용성을 제공하지 않으며, 하나의 영역으로 제한됩니다.",
            "Amazon S3를 사용하는 것은 멀티미디어 처리 애플리케이션에 필요한 POSIX 준수 파일 시스템 의미론을 요구하는 애플리케이션에 적합하지 않습니다.",
            "파일 전송을 관리하기 위해 EC2 인스턴스를 설정하는 것은 불필요한 복잡성을 추가하며, EFS가 제공하는 자동화된 지속적인 복제를 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "2",
        "Situation": "한 미디어 회사가 AWS 리소스를 활용하여 비디오 스트리밍 플랫폼을 운영하고 있으며, 비디오 업로드 처리를 위한 여러 EC2 인스턴스와 수신 트래픽을 분산하기 위한 Elastic Load Balancer (ELB)를 사용하고 있습니다. 사용자들은 피크 사용 시간 동안 간헐적인 버퍼링과 느린 로드 시간을 보고했습니다. 솔루션 아키텍트는 비용을 최적화하면서 애플리케이션의 성능을 향상시키기 위한 전략을 마련해야 합니다.",
        "Question": "피크 사용 시간 동안 비디오 스트리밍 플랫폼의 성능을 가장 잘 개선할 수 있는 전략은 무엇입니까?",
        "Options": {
            "1": "EC2 플릿의 인스턴스 유형을 더 큰 크기로 늘리고, 더 많은 사용자 요청을 동시에 처리하기 위해 추가 Elastic IP 주소를 할당합니다.",
            "2": "비디오 처리 작업을 AWS Lambda와 같은 관리형 서비스로 마이그레이션하고, 사용자로부터 직접 접근할 수 있도록 S3에 비디오 파일을 저장합니다.",
            "3": "CPU 사용률 메트릭을 기반으로 EC2 인스턴스에 대해 Auto Scaling을 구현하고, CloudFront 배포를 구성하여 사용자에게 더 가까운 곳에서 비디오 콘텐츠를 캐시합니다.",
            "4": "모든 비디오 처리 작업을 처리하기 위해 단일 대형 EC2 인스턴스를 배포하고, 해당 인스턴스에 프로비저닝된 IOPS가 있는 EBS 볼륨을 연결합니다."
        },
        "Correct Answer": "CPU 사용률 메트릭을 기반으로 EC2 인스턴스에 대해 Auto Scaling을 구현하고, CloudFront 배포를 구성하여 사용자에게 더 가까운 곳에서 비디오 콘텐츠를 캐시합니다.",
        "Explanation": "Auto Scaling을 구현하면 애플리케이션이 실제 수요에 따라 EC2 인스턴스 수를 동적으로 조정할 수 있어 트래픽 급증을 효과적으로 관리할 수 있습니다. 또한, CloudFront를 콘텐츠 전송 네트워크(CDN)로 사용하면 비디오 콘텐츠를 사용자에게 더 가까운 곳에서 캐시하여 지연 시간을 줄이고 로드 시간을 크게 향상시킵니다.",
        "Other Options": [
            "인스턴스 유형을 늘리는 것은 더 많은 리소스를 제공할 수 있지만, 피크 시간 동안 필요한 확장성을 해결하지 않으며 최적의 성능을 보장하지 않고 더 높은 비용으로 이어질 수 있습니다.",
            "단일 대형 EC2 인스턴스를 배포하는 것은 단일 실패 지점을 생성하며 피크 사용 시간 동안 효과적으로 확장되지 않습니다. 이 옵션은 로드 밸런싱이나 중복성의 이점을 활용하지 않습니다.",
            "AWS Lambda로 마이그레이션하는 것은 긴 실행 시간이 필요한 비디오 처리 작업에 적합하지 않을 수 있으며, Lambda에는 타임아웃 제한이 있습니다. 또한, 이 옵션은 사용자 요청과 관련된 즉각적인 성능 문제를 해결하지 않습니다."
        ]
    },
    {
        "Question Number": "3",
        "Situation": "한 회사가 동적 애플리케이션 인프라의 일부인 대규모 Amazon EC2 인스턴스 플릿을 관리하고 있습니다. 인프라는 보안 정책 및 운영 모범 사례를 준수하면서 효율적으로 유지되어야 합니다. 회사는 패치, 모니터링 및 인벤토리 관리와 같은 운영 작업을 자동화하기 위해 구성 관리 솔루션을 구현하는 것을 고려하고 있습니다.",
        "Question": "이 시나리오에서 회사의 구성 관리 요구 사항을 가장 잘 충족할 수 있는 AWS 서비스는 무엇입니까?",
        "Options": {
            "1": "AWS CloudFormation을 구현하여 인프라를 코드로 관리하고 EC2 인스턴스의 배포를 자동화합니다.",
            "2": "AWS Systems Manager를 사용하여 EC2 인스턴스 전반에 걸쳐 운영 작업을 자동화하고 보안 정책 준수를 보장합니다.",
            "3": "Amazon CloudWatch를 활용하여 애플리케이션 성능을 모니터링하고 메트릭 기반으로 경고를 생성합니다.",
            "4": "AWS Config를 활용하여 리소스 구성을 추적하고 회사의 정책 준수를 보장합니다."
        },
        "Correct Answer": "AWS Systems Manager를 사용하여 EC2 인스턴스 전반에 걸쳐 운영 작업을 자동화하고 보안 정책 준수를 보장합니다.",
        "Explanation": "AWS Systems Manager는 구성 관리를 위한 포괄적인 도구 모음을 제공하여 운영 작업, 패치 관리 및 준수 모니터링을 자동화할 수 있습니다. 이는 대규모 인스턴스 플릿을 효율적으로 관리하기 위해 특별히 설계되었습니다.",
        "Other Options": [
            "AWS CloudFormation은 AWS 리소스를 코드로 프로비저닝하고 관리하는 데 중점을 두고 있어 지속적인 운영 작업을 자동화하는 데 적합하지 않습니다.",
            "AWS Config는 주로 리소스 구성을 추적하고 준수를 보장하는 데 사용되지만, 패치나 모니터링과 같은 운영 작업을 자동화하지 않으므로 이 시나리오에서는 중요합니다.",
            "Amazon CloudWatch는 주로 메트릭과 로그를 추적하는 모니터링 서비스로, 운영 작업을 자동화하고 준수를 보장하는 데 필요한 구성 관리 기능을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "4",
        "Situation": "한 금융 서비스 회사가 AWS에서의 클라우드 지출을 분석하고 있습니다. 이들은 단기 프로젝트와 장기 운영이 혼합되어 있습니다. 회사는 비용을 최적화하면서 변화하는 비즈니스 요구에 적응할 수 있는 유연성을 보장하고자 합니다. 특히 안정적인 상태의 작업에 대한 비용을 최소화하는 데 관심이 있으며 다양한 가격 모델을 고려하고 있습니다.",
        "Question": "단기 프로젝트에 대한 유연성을 유지하면서 회사의 비용을 최적화하기 위해 솔루션 아키텍트가 추천해야 할 가격 모델은 무엇입니까?",
        "Options": {
            "1": "모든 Amazon EC2 인스턴스에 대해 예약 인스턴스를 구매하여 1년 또는 3년 기간 동안 가장 낮은 시간당 요금을 보장합니다.",
            "2": "다양한 인스턴스 패밀리와 지역에서 유연성을 제공하면서 온디맨드 가격보다 상당한 절감을 제공하는 세이빙 플랜을 활용합니다.",
            "3": "최대 유연성을 유지하고 장기 약속을 피하기 위해 온디맨드 인스턴스만 사용합니다.",
            "4": "모든 작업에 대해 스팟 인스턴스를 활용하여 어떤 형태의 약속 없이 가능한 가장 낮은 가격을 달성합니다."
        },
        "Correct Answer": "다양한 인스턴스 패밀리와 지역에서 유연성을 제공하면서 온디맨드 가격보다 상당한 절감을 제공하는 세이빙 플랜을 활용합니다.",
        "Explanation": "세이빙 플랜은 회사가 1년 또는 3년 기간 동안 특정 사용량에 약속함으로써 비용을 최적화할 수 있는 유연한 가격 모델을 제공합니다. 이 모델은 다양한 인스턴스 유형과 지역을 지원하여 안정적인 상태의 작업과 변동하는 작업 모두에 이상적입니다.",
        "Other Options": [
            "예약 인스턴스를 구매하면 더 낮은 가격을 보장하지만 유연성의 대가를 치르게 되며, 이는 단기 및 장기 프로젝트가 모두 있는 회사에는 적합하지 않습니다.",
            "온디맨드 인스턴스만 사용하는 것은 최대 유연성을 제공할 수 있지만 비용을 효과적으로 최적화하지 못해 세이빙 플랜에 비해 더 높은 비용이 발생할 수 있습니다.",
            "스팟 인스턴스를 활용하면 가장 낮은 가격을 제공하지만 중단의 위험을 초래하여 신뢰성이 필요한 안정적인 상태의 작업에는 적합하지 않습니다."
        ]
    },
    {
        "Question Number": "5",
        "Situation": "한 금융 서비스 회사가 고가용성과 자주 사용되는 데이터에 대한 빠른 접근이 필요한 온프레미스 애플리케이션을 위한 새로운 데이터 저장 솔루션을 구현할 계획입니다. 회사는 AWS Storage Gateway를 사용하고 Cached Volumes와 Stored Volumes 중에서 선택해야 합니다. 그들은 전체 데이터 세트에 대한 저지연 접근을 보장하면서 클라우드 저장소를 백업으로 활용하고자 합니다.",
        "Question": "회사가 전체 데이터 세트에 대한 저지연 접근 요구 사항을 가장 잘 충족하면서 클라우드 저장소를 백업으로 활용하기 위해 선택해야 할 구성은 무엇입니까?",
        "Options": {
            "1": "데이터가 Amazon S3에서 직접 액세스되는 하이브리드 구성에서 Volume Gateway를 배포합니다.",
            "2": "자주 액세스되는 데이터의 로컬 저장을 허용하고 Amazon S3에 백업을 유지하기 위해 Cached와 Stored Volumes의 조합을 사용합니다.",
            "3": "Volume Gateway를 Cached Volumes를 사용하도록 구성하여 데이터가 Amazon S3에 저장되고 자주 액세스되는 데이터가 로컬에 유지되도록 합니다.",
            "4": "Volume Gateway를 Stored Volumes를 사용하도록 설정하여 모든 데이터를 먼저 로컬에 저장하고 비동기적으로 Amazon S3에 백업합니다."
        },
        "Correct Answer": "Volume Gateway를 Stored Volumes를 사용하도록 설정하여 모든 데이터를 먼저 로컬에 저장하고 비동기적으로 Amazon S3에 백업합니다.",
        "Explanation": "Stored Volumes는 모든 데이터를 로컬에 저장하여 전체 데이터 세트에 대한 저지연 접근을 제공하며, 이는 빠른 성능이 필요한 애플리케이션에 중요합니다. 또한, 데이터는 비동기적으로 Amazon S3에 백업될 수 있어 클라우드 백업 요구 사항을 충족합니다.",
        "Other Options": [
            "Cached Volumes는 자주 액세스되는 데이터만 로컬에 유지하므로 전체 데이터 세트에 대한 저지연 접근 요구 사항을 충족하지 않습니다.",
            "Cached와 Stored Volumes의 조합을 사용하는 것은 불필요하며 아키텍처를 복잡하게 만들 수 있습니다. Stored Volumes만으로도 요구 사항을 효과적으로 충족합니다.",
            "로컬 저장소 없이 하이브리드 구성으로 Volume Gateway를 배포하는 것은 저지연 접근을 제공하지 않으며 즉각적인 데이터 가용성이 필요한 애플리케이션에는 적합하지 않습니다."
        ]
    },
    {
        "Question Number": "6",
        "Situation": "한 금융 서비스 회사가 여러 AWS 계정과 지역에서 구성 관리 자동화를 통해 준수를 보장하고 수동 오류를 줄이려 하고 있습니다. 그들은 기존 AWS 서비스와 잘 통합되고 Linux 및 Windows 환경을 모두 지원하는 솔루션을 원합니다. 이 솔루션은 또한 버전 관리 및 감사 기능을 제공해야 합니다.",
        "Question": "구성 관리 자동화를 가능하게 하기 위해 솔루션 아키텍트가 추천해야 할 AWS 서비스는 무엇입니까?",
        "Options": {
            "1": "교차 계정 관리를 위한 AWS CloudFormation과 StackSets",
            "2": "준수 검사를 위한 AWS Config와 AWS Systems Manager",
            "3": "구성 관리를 위한 AWS OpsWorks와 Chef",
            "4": "상태 관리자 및 자동화 기능을 갖춘 AWS Systems Manager"
        },
        "Correct Answer": "상태 관리자 및 자동화 기능을 갖춘 AWS Systems Manager",
        "Explanation": "AWS Systems Manager는 원하는 상태를 강제하는 상태 관리자와 인스턴스 간 스크립트를 실행하는 자동화 기능을 포함하여 구성 관리를 위한 포괄적인 도구 모음을 제공합니다. 이 서비스는 Linux 및 Windows 환경을 모두 지원하며 버전 관리 및 감사 기능을 제공하여 회사의 요구에 이상적입니다.",
        "Other Options": [
            "AWS CloudFormation은 주로 인프라 프로비저닝 및 관리에 사용되며, 이 경우 필요한 지속적인 구성 관리 및 자동화에는 적합하지 않습니다.",
            "AWS Config는 리소스 준수 및 모니터링에 중점을 두고 있으며 구성 관리 자동화보다는 Systems Manager와 함께 작동할 수 있지만 자동화 측면을 직접 처리하지 않습니다.",
            "AWS OpsWorks는 Chef를 사용하는 구성 관리 서비스이지만 Systems Manager에 비해 다른 AWS 서비스와의 통합이 덜 되어 있어 이 특정 요구 사항에는 최적의 선택이 아닙니다."
        ]
    },
    {
        "Question Number": "7",
        "Situation": "한 금융 서비스 회사가 여러 Amazon EC2 인스턴스가 공유 데이터에 동시에 접근할 수 있는 새로운 고가용성 애플리케이션을 배포하고 있습니다. 이 애플리케이션은 높은 I/O 작업 부하를 처리하도록 설계되었으며 Amazon EBS를 스토리지로 사용할 것입니다. 아키텍트는 EBS 볼륨이 여러 EC2 인스턴스 간에 공유될 수 있도록 하여 애플리케이션의 가동 시간과 가용성을 향상시켜야 합니다.",
        "Question": "애플리케이션의 요구 사항을 충족하기 위해 솔루션 아키텍트가 구현해야 할 구성은 무엇입니까? (두 개 선택)",
        "Options": {
            "1": "지연 문제를 최소화하기 위해 각 EC2 인스턴스에 단일 Provisioned IOPS SSD 볼륨을 연결합니다.",
            "2": "Amazon EBS Multi-Attach를 사용하여 동일한 가용 영역 내에서 단일 Provisioned IOPS SSD 볼륨을 여러 EC2 인스턴스에 연결합니다.",
            "3": "Amazon EBS Multi-Attach를 사용하여 여러 Throughput Optimized HDD 볼륨을 단일 EC2 인스턴스에 연결합니다.",
            "4": "각 EC2 인스턴스에 여러 Amazon EBS 표준 볼륨을 배포하고, 이를 수동으로 인스턴스 간에 데이터를 복제하도록 구성합니다.",
            "5": "여러 EC2 인스턴스가 동시에 접근할 수 있는 공유 파일 시스템을 제공하기 위해 Amazon EFS를 구현합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon EBS Multi-Attach를 사용하여 동일한 가용 영역 내에서 단일 Provisioned IOPS SSD 볼륨을 여러 EC2 인스턴스에 연결합니다.",
            "여러 EC2 인스턴스가 동시에 접근할 수 있는 공유 파일 시스템을 제공하기 위해 Amazon EFS를 구현합니다."
        ],
        "Explanation": "Amazon EBS Multi-Attach를 사용하면 단일 Provisioned IOPS SSD 볼륨을 여러 EC2 인스턴스에 연결할 수 있어, 동시 읽기 및 쓰기 접근이 필요한 작업 부하에 대해 높은 가용성과 성능을 제공합니다. 또한, Amazon EFS는 여러 인스턴스가 접근할 수 있는 확장 가능한 파일 저장 솔루션을 제공하여 고가용성 애플리케이션에 적합합니다.",
        "Other Options": [
            "여러 EBS 표준 볼륨을 배포하고 수동으로 데이터를 복제하는 것은 비효율적이며, 동시 접근을 위한 필요한 고가용성이나 단순성을 제공하지 않습니다.",
            "단일 EC2 인스턴스에 여러 Throughput Optimized HDD 볼륨을 연결하여 EBS Multi-Attach를 사용하는 것은 여러 인스턴스 간에 볼륨을 공유하는 요구 사항을 충족하지 않습니다.",
            "각 EC2 인스턴스에 단일 Provisioned IOPS SSD 볼륨을 연결하는 것은 공유 접근을 허용하지 않으며, 인스턴스 간의 가동 시간이나 가용성을 향상시키지 않습니다."
        ]
    },
    {
        "Question Number": "8",
        "Situation": "한 금융 서비스 회사가 온프레미스 애플리케이션을 AWS로 마이그레이션할 계획입니다. 회사는 기존 애플리케이션 포트폴리오를 평가하고 다양한 AWS 서비스에 걸쳐 마이그레이션 진행 상황을 추적하고자 합니다. 마이그레이션 상태를 시각화하고 마이그레이션 과정 중 최적의 AWS 서비스에 대한 권장 사항을 받을 수 있는 중앙 집중식 도구가 필요합니다.",
        "Question": "마이그레이션 평가 및 추적에 적합한 도구는 무엇입니까? (두 개 선택)",
        "Options": {
            "1": "AWS Cost Explorer",
            "2": "AWS CloudTrail",
            "3": "AWS Migration Hub",
            "4": "AWS Config",
            "5": "AWS Application Discovery Service"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "AWS Migration Hub",
            "AWS Application Discovery Service"
        ],
        "Explanation": "AWS Migration Hub는 AWS 및 온프레미스 환경에서 애플리케이션 마이그레이션의 진행 상황을 추적할 수 있는 중앙 위치를 제공합니다. 사용자는 마이그레이션 상태를 시각화하고 리소스를 최적화할 수 있는 통찰력을 수집할 수 있습니다. AWS Application Discovery Service는 애플리케이션 의존성과 리소스 활용도를 식별하는 데 도움을 주며, 이는 마이그레이션 중 기존 포트폴리오를 평가하는 데 필수적입니다.",
        "Other Options": [
            "AWS CloudTrail은 주로 보안 및 규정 준수를 위한 AWS 계정의 API 호출 및 변경 사항을 추적하는 데 사용되며, 마이그레이션 평가 또는 추적을 위한 것이 아닙니다.",
            "AWS Cost Explorer는 AWS 비용 분석 및 관리에 중점을 두고 있으며, 마이그레이션 과정이나 애플리케이션 포트폴리오 평가를 지원하지 않습니다.",
            "AWS Config는 주로 AWS에서 리소스 구성 관리 및 규정 준수 모니터링에 사용되며, 마이그레이션 특정 평가 또는 추적 기능을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "9",
        "Situation": "한 금융 서비스 회사가 실시간으로 거래를 처리하는 중요한 애플리케이션을 운영하고 있습니다. 이 애플리케이션은 AWS에 호스팅되어 있으며 사용자에게 높은 가용성을 유지하도록 설계되었습니다. 그러나 회사는 자연 재해나 기타 재앙적인 사건으로 인한 잠재적인 중단에 대해 우려하고 있습니다. 그들은 가동 중지 시간과 데이터 손실을 최소화하면서 규제 요구 사항을 준수하는 재해 복구 전략을 구현하고자 합니다. 회사는 다양한 재해 복구 전략 옵션을 가지고 있으며 최선의 접근 방식에 대한 지침을 찾고 있습니다.",
        "Question": "회사가 중요한 애플리케이션의 가동 중지 시간과 데이터 손실을 최소화하기 위해 구현해야 할 재해 복구 전략은 무엇입니까?",
        "Options": {
            "1": "파일럿 라이트 전략을 활용하여 다른 지역에 애플리케이션의 최소 버전을 유지하고, 장애 발생 시 신속하게 확장할 수 있도록 합니다.",
            "2": "활성-활성 구성의 다중 사이트 전략을 채택하여 애플리케이션이 여러 AWS 지역에서 동시에 실행되도록 하여 높은 가용성을 보장합니다.",
            "3": "다른 AWS 지역에서 축소된 버전의 애플리케이션이 실행되도록 하는 웜 스탠바이 전략을 구현하여 장애 발생 시 즉시 인수할 수 있도록 합니다.",
            "4": "AWS Elastic Disaster Recovery를 사용하여 애플리케이션을 지속적으로 복제하고 재해 발생 시 새로운 환경으로 신속하게 복원합니다."
        },
        "Correct Answer": "AWS Elastic Disaster Recovery를 사용하여 애플리케이션을 지속적으로 복제하고 재해 발생 시 새로운 환경으로 신속하게 복원합니다.",
        "Explanation": "AWS Elastic Disaster Recovery는 애플리케이션을 지속적으로 복제하는 효율적이고 자동화된 방법을 제공하여, 최소한의 가동 중지 시간과 데이터 손실로 새로운 환경에서 신속하게 복원할 수 있도록 합니다. 이 접근 방식은 높은 가용성과 규정 준수에 대한 회사의 요구 사항과 완벽하게 일치합니다.",
        "Other Options": [
            "웜 스탠바이 전략을 구현하는 것은 축소된 버전의 애플리케이션을 유지하는 것을 포함합니다. 이는 복구 시간을 단축할 수 있지만, 지속적인 복제와 비교할 때 최소한의 가동 중지 시간과 데이터 손실 요구 사항을 완전히 충족하지 않을 수 있습니다.",
            "활성-활성 구성의 다중 사이트 전략은 복잡하고 비용이 많이 들 수 있으며, 여러 지역에서 전체 규모의 인스턴스를 실행해야 합니다. 이는 높은 가용성을 제공하지만, 비용을 최소화하려는 회사에 가장 효율적인 솔루션이 아닐 수 있습니다.",
            "파일럿 라이트 전략을 활용하는 것은 애플리케이션의 최소 버전을 유지하는 것을 포함합니다. 이 전략은 복구 시간이 길어질 수 있으며, 이는 중요한 상황에서 최소한의 가동 중지 시간에 대한 회사의 필요와 일치하지 않을 수 있습니다."
        ]
    },
    {
        "Question Number": "10",
        "Situation": "한 금융 서비스 회사가 빠른 성장을 경험하고 있으며 웹 애플리케이션이 가변적인 트래픽 부하를 처리할 수 있도록 하면서 비용을 최소화해야 합니다. 애플리케이션은 Amazon EC2 인스턴스에서 실행되며 높은 가용성과 성능을 유지해야 합니다. 솔루션 아키텍트는 트래픽 패턴에 따라 동적으로 확장할 수 있는 아키텍처를 설계하고 여러 가용 영역에서 리소스를 최적화하여 활용해야 합니다.",
        "Question": "다음 중 솔루션 아키텍트가 회사의 요구 사항을 달성하기 위해 구현해야 할 작업은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "모든 EC2 인스턴스가 동일한 가용 영역에 위치하도록 배치 그룹을 활용하여 지연 시간을 최소화합니다.",
            "2": "Amazon EC2 스팟 인스턴스를 사용하여 비용을 줄이면서 피크 시간 동안 충분한 용량이 확보되도록 합니다.",
            "3": "성능과 비용을 최적화하기 위해 Auto Scaling 그룹 내에서 여러 EC2 인스턴스 유형으로 애플리케이션을 배포합니다.",
            "4": "평균 CPU 활용도를 기반으로 하는 목표 추적 확장 정책으로 Amazon EC2 Auto Scaling을 구현합니다.",
            "5": "사용자의 세션 정보를 유지하기 위해 스티키 세션이 있는 Amazon Elastic Load Balancer (ELB)를 구성합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "평균 CPU 활용도를 기반으로 하는 목표 추적 확장 정책으로 Amazon EC2 Auto Scaling을 구현합니다.",
            "Amazon EC2 스팟 인스턴스를 사용하여 비용을 줄이면서 피크 시간 동안 충분한 용량이 확보되도록 합니다."
        ],
        "Explanation": "Amazon EC2 Auto Scaling을 목표 추적 확장 정책으로 구현하면 현재 부하에 따라 용량을 동적으로 조정할 수 있어 높은 가용성과 성능을 보장합니다. EC2 스팟 인스턴스를 사용하면 AWS 클라우드의 여분의 용량을 활용하여 비용을 최적화할 수 있어 성능을 희생하지 않고 비용을 관리하는 좋은 방법입니다.",
        "Other Options": [
            "스티키 세션이 있는 ELB를 사용하면 트래픽의 불균형 분배가 발생할 수 있으며, 이는 가변 부하 하에서 확장 가능한 아키텍처에 이상적이지 않습니다. 일부 인스턴스가 과부하되고 다른 인스턴스는 저활용 상태가 될 수 있습니다.",
            "여러 인스턴스 유형으로 배포하는 것은 리소스 활용을 최적화하는 좋은 방법이지만, 목표 추적을 사용하는 Auto Scaling만큼 효과적으로 확장 요구 사항을 직접적으로 해결하지는 않습니다.",
            "배치 그룹을 활용하면 인스턴스 간의 지연 시간을 최소화하여 네트워크 성능을 개선할 수 있지만, 가변 부하를 관리하는 데 중요한 동적 확장이나 비용 최적화를 본질적으로 제공하지는 않습니다."
        ]
    },
    {
        "Question Number": "11",
        "Situation": "귀 조직은 다양한 팀과 프로젝트를 지원하기 위해 여러 AWS 계정을 관리하고 있습니다. 그러나 이러한 계정 간의 거버넌스, 비용 관리 및 보안에 대한 우려가 있습니다. 리더십은 모든 계정에 대한 준수, 중앙 집중식 청구 및 효과적인 접근 관리가 보장되는 거버넌스 모델을 구현할 방법을 찾고 있습니다. (두 가지 선택)",
        "Question": "다음 중 AWS에서 강력한 다중 계정 거버넌스 모델을 구축하는 데 도움이 되는 작업은 무엇입니까?",
        "Options": {
            "1": "각 계정의 청구를 수동으로 관리하여 비용 가시성을 유지합니다.",
            "2": "계정 간 연합 접근 관리를 위해 외부 신원 공급자를 사용합니다.",
            "3": "AWS Organizations를 구현하여 계정을 중앙에서 관리하고 서비스 제어 정책을 적용합니다.",
            "4": "모든 계정에서 AWS CloudTrail을 활성화하여 API 활동의 중앙 집중식 로깅을 수행합니다.",
            "5": "각 팀에 대해 별도의 AWS 계정을 생성하고 모든 AWS 서비스에 대한 무제한 접근을 허용합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "AWS Organizations를 구현하여 계정을 중앙에서 관리하고 서비스 제어 정책을 적용합니다.",
            "모든 계정에서 AWS CloudTrail을 활성화하여 API 활동의 중앙 집중식 로깅을 수행합니다."
        ],
        "Explanation": "AWS Organizations를 구현하면 여러 계정을 중앙에서 관리하고 모든 계정에 대한 거버넌스를 시행하기 위해 서비스 제어 정책을 적용할 수 있습니다. AWS CloudTrail을 활성화하면 API 활동의 중앙 집중식 로깅을 보장하여 준수 및 감사에 필수적입니다.",
        "Other Options": [
            "각 팀에 대해 별도의 AWS 계정을 생성하고 무제한 접근을 허용하는 것은 상당한 보안 위험을 초래하며, 어떤 거버넌스 모델도 시행하지 않습니다.",
            "계정 간 연합 접근 관리를 위해 외부 신원 공급자를 사용하는 것은 유용할 수 있지만, 독립적인 거버넌스 모델이 아니며 AWS Organizations가 제공하는 더 넓은 제어가 부족합니다.",
            "각 계정의 청구를 수동으로 관리하는 것은 비효율적이며 AWS Organizations가 제공할 수 있는 중앙 집중식 비용 보기 기능을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "12",
        "Situation": "의료 애플리케이션이 환자 데이터를 처리하고 분석 및 보고를 위해 다양한 제3자 서비스와 통신합니다. 현재 모든 서비스가 밀접하게 결합되어 있어 지연 문제가 발생하고 변경 사항을 구현하기 어렵습니다. 솔루션 아키텍트는 성능과 유지 관리성을 개선하기 위해 애플리케이션 구성 요소를 분리할 기회를 식별해야 합니다.",
        "Question": "다음 중 애플리케이션 구성 요소를 최적으로 분리하면서 성능과 유지 관리성을 향상시키는 솔루션은 무엇입니까?",
        "Options": {
            "1": "애플리케이션을 Amazon ECS로 마이그레이션하여 각 서비스가 HTTP 호출을 사용하여 서로 직접 통신하도록 하여 밀접하게 결합된 상태를 유지합니다.",
            "2": "애플리케이션을 AWS Lambda에서 완전히 실행되도록 리팩토링하고 모든 제3자 서비스에 대해 동기 호출을 활용하여 실시간 데이터 처리를 수행합니다.",
            "3": "애플리케이션과 제3자 서비스 간의 요청을 큐잉하기 위해 Amazon SQS를 구현하여 독립적으로 메시지를 처리할 수 있도록 합니다.",
            "4": "각 구성 요소에 대해 RESTful API를 생성하기 위해 Amazon API Gateway를 사용하여 서비스 간 독립적인 확장 및 통신을 가능하게 합니다."
        },
        "Correct Answer": "각 구성 요소에 대해 RESTful API를 생성하기 위해 Amazon API Gateway를 사용하여 서비스 간 독립적인 확장 및 통신을 가능하게 합니다.",
        "Explanation": "Amazon API Gateway를 사용하여 RESTful API를 생성하면 각 구성 요소가 독립적으로 통신하고 필요에 따라 확장할 수 있습니다. 이 접근 방식은 서비스를 효과적으로 분리하여 전체 애플리케이션에 영향을 주지 않고도 업데이트 및 유지 관리를 용이하게 합니다.",
        "Other Options": [
            "Amazon SQS를 구현하는 것은 분리에 대한 좋은 방법이지만, API Gateway만큼 독립적인 확장 및 API 관리 기능을 완전히 활용하지 못할 수 있습니다.",
            "애플리케이션을 AWS Lambda에서 완전히 실행되도록 리팩토링하고 동기 호출을 사용하는 것은 지연 및 밀접한 결합의 위험을 초래하여 구성 요소 분리의 목표에 반합니다.",
            "애플리케이션을 Amazon ECS로 마이그레이션하고 서비스 간 HTTP 호출을 사용하는 것은 밀접한 결합을 유지하며 독립적인 확장이나 개선된 유지 관리의 필요성을 해결하지 않습니다."
        ]
    },
    {
        "Question Number": "13",
        "Situation": "한 회사가 기존 파일 전송 작업을 Secure Shell File Transfer Protocol (SFTP)을 사용하여 AWS로 마이그레이션해야 합니다. 사용자가 기존 SFTP 클라이언트를 변경 없이 계속 사용할 수 있도록 보장하고 싶습니다. 또한, 회사는 서비스 관리 신원과 기업 신원 공급자의 조합을 사용하여 사용자를 인증하고자 합니다. 전송된 파일은 Amazon S3 버킷에 저장되어야 합니다. 솔루션 아키텍트는 이러한 요구 사항을 충족하면서 운영 오버헤드를 최소화하는 솔루션을 구현하는 임무를 맡고 있습니다.",
        "Question": "솔루션 아키텍트가 회사의 요구 사항을 충족하기 위해 구현해야 할 솔루션은 무엇입니까?",
        "Options": {
            "1": "SFTP 서버 애플리케이션을 실행하는 EC2 인스턴스를 배포하고 인증을 위해 IAM 역할을 사용하도록 구성합니다. 각 업로드 후 파일을 Amazon S3 버킷으로 전송하는 스크립트를 설정합니다.",
            "2": "AWS Transfer Family SFTP 서버를 생성하고 인증을 위해 서비스 관리 신원을 사용하도록 구성합니다. 도메인을 서버 엔드포인트에 매핑하고 저장을 위해 적절한 Amazon S3 버킷을 선택합니다.",
            "3": "사용자 인증을 위한 맞춤형 신원 공급자를 사용하여 AWS Transfer Family SFTP 서버를 구현합니다. 서버를 구성하여 파일을 Amazon EFS 파일 시스템으로 직접 전송하여 저장합니다.",
            "4": "SFTP 요청을 처리하기 위해 Lambda 함수를 설정하고 AWS SDK를 사용하여 사용자를 인증합니다. 전송된 파일을 Amazon RDS 데이터베이스에 저장합니다."
        },
        "Correct Answer": "AWS Transfer Family SFTP 서버를 생성하고 인증을 위해 서비스 관리 신원을 사용하도록 구성합니다. 도메인을 서버 엔드포인트에 매핑하고 저장을 위해 적절한 Amazon S3 버킷을 선택합니다.",
        "Explanation": "AWS Transfer Family를 사용하면 SFTP 작업을 최소한의 관리 오버헤드로 원활하게 통합할 수 있습니다. 인증을 위한 서비스 관리 신원을 지원하며, 파일 저장을 위해 Amazon S3와 직접 통합되어 회사의 모든 요구 사항을 충족합니다.",
        "Other Options": [
            "SFTP를 위한 EC2 인스턴스를 배포하면 추가적인 관리 복잡성이 발생하며, AWS Transfer Family의 내장 기능을 활용하지 않습니다.",
            "AWS Transfer Family와 맞춤형 신원 공급자를 사용하는 것은 불필요합니다. 서비스 관리 신원이 회사의 요구를 충족하며, EFS 파일 시스템으로 파일을 전송하는 것은 S3 사용 요구 사항과 일치하지 않습니다.",
            "SFTP 처리를 위한 Lambda 함수를 구현하는 것은 지나치게 복잡하며 고빈도 파일 전송에 적합하지 않습니다. 또한, RDS는 구조화된 데이터를 위해 설계되었으므로 파일 저장에 적합하지 않습니다."
        ]
    },
    {
        "Question Number": "14",
        "Situation": "한 의료 기관이 AWS에 저장된 환자 데이터에 대해 서로 다른 접근 수준이 필요한 직원들의 사용자 접근 및 권한을 안전하게 관리해야 합니다. 이 기관은 접근 제어가 중앙에서 관리되고 기존 온프레미스 Microsoft Active Directory와 쉽게 통합될 수 있도록 보장하고자 합니다. 솔루션 아키텍트는 연합 인증 및 세분화된 접근 제어를 모두 허용하는 솔루션을 구현해야 합니다. (두 가지 선택)",
        "Question": "요구 사항을 충족하기 위해 솔루션 아키텍트가 구현해야 할 서비스는 무엇입니까?",
        "Options": {
            "1": "온프레미스 Active Directory와 AWS 리소스를 연결하기 위해 AWS Directory Service를 구현합니다.",
            "2": "여러 AWS 계정 및 애플리케이션에 대한 원활한 접근을 위해 AWS Single Sign-On을 활용합니다.",
            "3": "애플리케이션의 접근 키를 안전하게 저장하고 관리하기 위해 AWS Secrets Manager를 설정합니다.",
            "4": "AWS 계정 전반에 걸쳐 사용자 접근 및 권한을 관리하기 위해 AWS IAM Identity Center를 사용합니다.",
            "5": "사용자 신원을 관리하고 장치 간 사용자 데이터를 동기화하기 위해 Amazon Cognito를 활용합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "AWS 계정 전반에 걸쳐 사용자 접근 및 권한을 관리하기 위해 AWS IAM Identity Center를 사용합니다.",
            "온프레미스 Active Directory와 AWS 리소스를 연결하기 위해 AWS Directory Service를 구현합니다."
        ],
        "Explanation": "AWS IAM Identity Center는 사용자 접근 관리의 복잡성을 줄이고 여러 AWS 계정에 걸쳐 사용자에 대한 권한을 중앙에서 관리할 수 있는 방법을 제공합니다. AWS Directory Service는 온프레미스 Active Directory와의 통합을 허용하여 연합 인증 및 AWS 리소스에 대한 접근 제어를 개선합니다.",
        "Other Options": [
            "Amazon Cognito는 웹 및 모바일 애플리케이션의 사용자 신원을 관리하는 데 주로 사용되며, AWS 리소스에 대한 연합 접근이 필요한 이 시나리오의 주요 관심사가 아닙니다.",
            "AWS Secrets Manager는 API 키 및 비밀번호와 같은 비밀을 관리하기 위해 설계되었지만 사용자 접근 관리 또는 권한 제어를 제공하지 않습니다.",
            "AWS Single Sign-On은 여러 AWS 계정에 대한 접근을 간소화하지만, 기존 온프레미스 Active Directory와의 통합을 직접적으로 다루지 않으며, 이는 이 시나리오에서 중요합니다."
        ]
    },
    {
        "Question Number": "15",
        "Situation": "IT 팀이 AWS CodeDeploy를 사용하여 Amazon EC2 인스턴스의 집합에 애플리케이션 배포를 자동화하려고 합니다. 배포 프로세스가 제어되고 필요할 경우 이전 버전으로 쉽게 롤백할 수 있도록 보장하고자 합니다.",
        "Question": "IT 팀이 모든 인스턴스가 업데이트될 때까지 5분마다 20%의 인스턴스에 새 버전을 점진적으로 배포하기 위해 사용해야 할 배포 구성은 무엇입니까?",
        "Options": {
            "1": "CodeDeployDefault.ECSCanary10Percent5Minutes",
            "2": "CodeDeployDefault.OneAtATime",
            "3": "CodeDeployDefault.AllAtOnce",
            "4": "CodeDeployDefault.HalfAtATime"
        },
        "Correct Answer": "CodeDeployDefault.ECSCanary10Percent5Minutes",
        "Explanation": "ECSCanary10Percent5Minutes 구성은 배포가 카나리 방식으로 진행되도록 하여 5분마다 10%의 인스턴스가 업데이트됩니다. 이 구성은 모든 인스턴스에 배포하기 전에 애플리케이션의 상태를 모니터링하면서 점진적인 배포를 가능하게 합니다.",
        "Other Options": [
            "HalfAtATime은 인스턴스의 절반을 한 번에 업데이트하므로 20%의 점진적 배포 요구 사항을 충족하지 않습니다.",
            "AllAtOnce는 새 버전을 모든 인스턴스에 동시에 배포하므로 제어된 배포 및 모니터링을 허용하지 않습니다.",
            "OneAtATime은 한 번에 하나의 인스턴스만 업데이트하므로 20%의 인스턴스에 빠르게 배포해야 하는 요구 사항에 비효율적입니다."
        ]
    },
    {
        "Question Number": "16",
        "Situation": "한 회사가 가상 사설 클라우드(VPC) 내에서 EC2 인스턴스를 배포하고 있으며, 공인 IP 주소를 가진 인스턴스가 공용 DNS 호스트 이름을 해석할 수 있도록 해야 합니다. 이 기능을 활성화하기 위해 VPC 구성에는 특정 설정이 필요합니다.",
        "Question": "VPC 내의 EC2 인스턴스가 공용 DNS 호스트 이름을 해석할 수 있도록 보장하기 위해 구성해야 하는 두 가지 설정은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "enableDnsSupport를 true로 설정합니다.",
            "2": "enableDnsHostnames를 false로 설정합니다.",
            "3": "enableDnsSupport를 false로 설정합니다.",
            "4": "사설 IP 주소에 대해 enableDnsSupport를 true로 설정합니다.",
            "5": "enableDnsHostnames를 true로 설정합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "enableDnsSupport를 true로 설정합니다.",
            "enableDnsHostnames를 true로 설정합니다."
        ],
        "Explanation": "VPC 내의 EC2 인스턴스가 공용 DNS 호스트 이름을 해석하려면 enableDnsSupport와 enableDnsHostnames 속성을 모두 true로 설정해야 합니다. enableDnsSupport는 인스턴스가 Amazon에서 제공하는 DNS 서버를 사용할 수 있도록 하고, enableDnsHostnames는 공인 IP 주소를 가진 인스턴스가 해당하는 공용 DNS 이름을 받을 수 있도록 보장합니다.",
        "Other Options": [
            "enableDnsHostnames를 false로 설정하면 인스턴스가 공용 DNS 호스트 이름을 받을 수 없게 되어 해석이 불가능해집니다.",
            "enableDnsSupport를 false로 설정하면 Amazon에서 제공하는 DNS 서버가 비활성화되어 공용 호스트 이름을 포함한 모든 DNS 해석이 불가능해집니다.",
            "사설 IP 주소에 대해 enableDnsSupport를 true로 설정하는 것은 공용 DNS 호스트 이름 해석 요구 사항을 해결하지 않으며, 공인 IP 주소 해석에 영향을 미치지 않습니다."
        ]
    },
    {
        "Question Number": "17",
        "Situation": "한 의료 기관이 환자 데이터를 AWS로 마이그레이션하고 있습니다. 이 정보의 민감한 특성으로 인해 기관은 HIPAA 규정을 준수해야 하며 데이터를 최소 6년 동안 보관해야 합니다. 기관은 규제 요구 사항에 따라 이 데이터를 저장, 관리 및 보호할 수 있는 옵션을 평가하고 있습니다.",
        "Question": "기관이 민감한 환자 데이터를 관리하기 쉽게 하면서 데이터 보존 및 민감성 요구 사항을 준수하기 위해 어떤 AWS 서비스 또는 기능을 활용해야 합니까?",
        "Options": {
            "1": "Amazon RDS를 자동 백업 및 스냅샷과 함께 구현하여 환자 데이터를 저장하고 필요한 기간 동안 보존합니다.",
            "2": "AWS Backup을 활용하여 모든 AWS 리소스에 대한 백업 정책을 관리하고 환자 데이터에 대한 보존 기간을 시행합니다.",
            "3": "Amazon S3와 Object Lock을 사용하여 보존 정책을 시행하고 환자 데이터의 삭제를 방지합니다.",
            "4": "Amazon DynamoDB에 환자 데이터를 저장하고 TTL(Time to Live)을 활성화하여 6년 후에 자동으로 레코드를 삭제합니다."
        },
        "Correct Answer": "Amazon S3와 Object Lock을 사용하여 보존 정책을 시행하고 환자 데이터의 삭제를 방지합니다.",
        "Explanation": "Amazon S3와 Object Lock은 지정된 기간 동안 객체 삭제를 방지하여 데이터 보존 요구 사항을 충족하도록 특별히 설계되어 HIPAA 규정을 준수하는 데 적합합니다. 이를 통해 의료 기관은 환자 데이터가 의무 보존 기간이 끝나기 전에 삭제되지 않도록 보장할 수 있습니다.",
        "Other Options": [
            "자동 백업 및 스냅샷과 함께 Amazon RDS를 구현하는 것은 데이터베이스 관리에 좋은 방법이지만, S3의 Object Lock과 같은 수준의 보존 시행을 제공하지 않아 규정 준수 위험을 초래할 수 있습니다.",
            "Amazon DynamoDB에 TTL을 활성화하여 환자 데이터를 저장하면 자동 삭제가 가능해지므로 최소 6년 동안 민감한 데이터를 보존해야 하는 요구 사항과 모순됩니다.",
            "AWS Backup을 활용하는 것은 AWS 서비스 전반에 걸쳐 백업을 관리하는 데 유용하지만, S3 Object Lock과 같은 방식으로 보존 정책을 본질적으로 시행하지 않으므로 데이터 민감성 규정 준수에 필수적입니다."
        ]
    },
    {
        "Question Number": "18",
        "Situation": "한 금융 서비스 회사가 월별 AWS 지출을 분석하여 비용 최적화 영역을 식별해야 합니다. 이 회사는 EC2, S3 및 RDS를 포함한 다양한 AWS 서비스를 사용하고 있으며 복잡한 청구 구조를 가지고 있습니다. 그들은 AWS 비용 및 사용 보고서(CUR)를 자세히 분석하여 사용 패턴을 이해하고 이상을 식별하며 다양한 부서에 걸쳐 비용을 정확하게 할당하고자 합니다. 팀은 CUR를 효과적으로 활용하는 방법을 잘 모르고 있습니다.",
        "Question": "회사가 AWS 비용 및 사용 보고서를 세부적으로 조사하기 위한 가장 좋은 접근 방식은 무엇입니까?",
        "Options": {
            "1": "AWS Cost Explorer를 활용하여 사용 추세를 시각화하고 서비스, 연결된 계정 및 태그별로 필터링하여 특정 비용 원인 및 이상을 식별합니다.",
            "2": "비용 및 사용 보고서를 매일 처리하여 각 부서에 대한 CSV 파일을 생성하는 예약된 Lambda 함수를 설정합니다.",
            "3": "비용 및 사용 보고서를 S3 버킷에 다운로드하고 Amazon Athena를 사용하여 데이터를 분석하여 다양한 부서에 걸쳐 비용 할당 및 즉석 쿼리를 수행합니다.",
            "4": "AWS Budgets를 사용하여 특정 서비스 사용 임계값에 따라 알림을 생성하여 팀이 비용 변화에 신속하게 대응할 수 있도록 합니다."
        },
        "Correct Answer": "비용 및 사용 보고서를 S3 버킷에 다운로드하고 Amazon Athena를 사용하여 데이터를 분석하여 다양한 부서에 걸쳐 비용 할당 및 즉석 쿼리를 수행합니다.",
        "Explanation": "비용 및 사용 보고서를 S3 버킷에 다운로드하고 Amazon Athena를 사용하면 데이터에 대한 상세 분석 및 즉석 쿼리를 수행할 수 있어 비용 및 사용 패턴을 보다 세부적으로 이해할 수 있습니다. 이 방법을 통해 회사는 특정 관심 영역을 효율적으로 조사하고 부서 간에 비용을 정확하게 할당할 수 있습니다.",
        "Other Options": [
            "AWS Cost Explorer는 추세를 시각화하고 고수준 사용 패턴을 이해하는 데 유용하지만, 비용 및 사용 보고서에 대한 심층 분석을 위한 Athena의 상세 쿼리 기능이 부족합니다.",
            "예약된 Lambda 함수를 설정하여 CSV 파일을 생성하는 것은 유용할 수 있지만, Athena에서 원시 데이터를 쿼리하는 것만큼 분석에 대한 세부 정보와 유연성을 제공하지 않을 수 있습니다.",
            "AWS Budgets는 임계값에 대한 지출 모니터링에 효과적이지만, 회사가 비용 할당 및 사용 패턴을 세부적으로 조사하는 데 필요한 상세한 통찰력을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "19",
        "Situation": "한 금융 서비스 회사가 AWS의 VPC에 웹 애플리케이션을 배포하고 있습니다. 이 애플리케이션은 규제 기준을 준수하기 위해 인바운드 및 아웃바운드 트래픽에 대한 엄격한 제어가 필요합니다. 솔루션 아키텍트는 합법적인 트래픽이 차단되지 않도록 하면서 허용된 트래픽 흐름을 정의하기 위한 보안 조치를 구현해야 합니다. 아키텍트는 이러한 흐름을 관리하기 위해 보안 그룹과 네트워크 ACL을 효과적으로 활용해야 합니다. (두 가지 선택)",
        "Question": "요구 사항을 충족하기 위해 솔루션 아키텍트가 취해야 할 행동은 무엇입니까?",
        "Options": {
            "1": "설정된 연결을 제외한 모든 인바운드 트래픽을 거부하도록 네트워크 ACL을 구성합니다.",
            "2": "특정 CIDR 블록에서 인바운드 트래픽을 허용하는 네트워크 ACL 규칙을 구현합니다.",
            "3": "모든 아웃바운드 트래픽을 모든 목적지로 허용하는 보안 그룹을 설정합니다.",
            "4": "특정 IP 주소에서 HTTP 및 HTTPS 트래픽을 허용하는 보안 그룹을 생성합니다.",
            "5": "모든 트래픽을 모니터링하고 패턴을 분석하기 위해 네트워크 ACL에서 흐름 로그를 활성화합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "특정 IP 주소에서 HTTP 및 HTTPS 트래픽을 허용하는 보안 그룹을 생성합니다.",
            "특정 CIDR 블록에서 인바운드 트래픽을 허용하는 네트워크 ACL 규칙을 구현합니다."
        ],
        "Explanation": "정답은 신뢰할 수 있는 IP 주소에서 특정 HTTP 및 HTTPS 트래픽을 허용하기 위해 보안 그룹을 사용하는 것이며, 이는 합법적인 요청만 처리되도록 보장합니다. 또한, 특정 CIDR 블록에서 인바운드 트래픽을 허용하는 네트워크 ACL 규칙을 구현함으로써 보안 준수를 유지하면서 더 넓은 트래픽 흐름에 대한 제어를 제공합니다.",
        "Other Options": [
            "설정된 연결을 제외한 모든 인바운드 트래픽을 거부하도록 네트워크 ACL을 구성하는 것은 너무 제한적이며, 설정된 연결의 일부가 아닌 합법적인 트래픽을 차단할 수 있습니다.",
            "모든 트래픽을 모니터링하고 패턴을 분석하기 위해 네트워크 ACL에서 흐름 로그를 활성화하는 것은 트래픽 흐름을 직접적으로 제어하지 않으며, 보안 조치라기보다는 모니터링 솔루션에 가깝습니다.",
            "모든 아웃바운드 트래픽을 모든 목적지로 허용하는 보안 그룹을 설정하는 것은 보안 관행으로 좋지 않으며, 애플리케이션을 불필요한 위험에 노출시킬 수 있습니다."
        ]
    },
    {
        "Question Number": "20",
        "Situation": "한 금융 서비스 회사가 애플리케이션을 AWS로 마이그레이션하고 있으며, 클라우드 인프라 전반에 걸쳐 사용자 행동 및 서비스 상호작용에 대한 포괄적인 추적 가능성을 보장해야 합니다. 보안 및 준수 목적을 위해 활동을 추적하고 분석할 수 있는 솔루션을 구현하고자 합니다. 이 회사는 Amazon S3, Amazon RDS 및 AWS Lambda를 포함한 여러 AWS 서비스를 사용하고 있으며, 모든 관련 이벤트를 캡처하는 중앙 집중식 로깅 메커니즘이 필요합니다.",
        "Question": "AWS 환경에서 사용자 및 서비스의 포괄적인 추적 가능성을 달성하기 위한 최상의 접근 방식은 무엇입니까?",
        "Options": {
            "1": "모든 계정 및 리전에서 AWS CloudTrail을 활성화하여 모든 AWS 서비스에 대한 API 호출 및 사용자 활동을 캡처하고, Amazon CloudWatch Logs를 구성하여 로그를 모니터링하고 분석합니다.",
            "2": "AWS 서비스에서 이벤트를 캡처하기 위해 Amazon CloudWatch Events를 배포하고 이러한 이벤트를 처리하기 위해 AWS Lambda를 사용하되, API 호출 추적을 위해 AWS CloudTrail을 활성화하지 않습니다.",
            "3": "Amazon GuardDuty를 구현하여 악의적인 활동 및 무단 행동을 지속적으로 모니터링하며, AWS 환경에서 보안 이벤트 로깅을 위해 그것에만 의존합니다.",
            "4": "AWS 리소스의 구성 변경을 추적하기 위해 AWS Config를 사용하고 특정 변경 사항에 대한 SNS 알림을 설정하되, 사용자 행동에 대한 중앙 집중식 로깅 솔루션은 없습니다."
        },
        "Correct Answer": "모든 계정 및 리전에서 AWS CloudTrail을 활성화하여 모든 AWS 서비스에 대한 API 호출 및 사용자 활동을 캡처하고, Amazon CloudWatch Logs를 구성하여 로그를 모니터링하고 분석합니다.",
        "Explanation": "AWS CloudTrail을 활성화하면 사용자 및 서비스가 수행한 모든 API 호출에 대한 포괄적인 뷰를 제공하여 추적 가능성에 필수적입니다. Amazon CloudWatch Logs와 결합하면 로그의 실시간 모니터링 및 분석이 가능하여 준수 및 보안을 보장합니다.",
        "Other Options": [
            "Amazon GuardDuty만 구현하는 것은 모든 사용자 행동 및 서비스 상호작용에 대한 포괄적인 추적 가능성을 제공하지 않으며, 주로 위협 탐지에 초점을 맞추고 사용자 활동에 대한 자세한 로깅을 놓칠 수 있습니다.",
            "AWS Config를 사용하는 것은 구성 변경 추적에 한정되며, 사용자 행동이나 API 호출을 캡처하지 않으므로 포괄적인 추적 가능성 및 준수 목적에 필수적입니다.",
            "AWS CloudTrail을 활성화하지 않고 Amazon CloudWatch Events를 배포하면 API 호출 및 사용자 활동을 추적할 수 있는 능력이 제한되어 AWS 환경 전반에 걸친 행동의 포괄적인 추적 가능성에 불충분합니다."
        ]
    },
    {
        "Question Number": "21",
        "Situation": "한 미디어 회사가 전 세계 사용자들이 접근하는 비디오 콘텐츠를 저장하기 위해 Amazon S3를 사용하고 있습니다. 이들은 오직 권한이 있는 사용자만 비디오에 접근할 수 있도록 하면서 URL은 그대로 유지하여 사용의 편리함을 보장하고자 합니다. 또한, 개별 URL을 생성하지 않고 여러 비디오에 대한 안전한 접근을 제공해야 합니다. 솔루션 아키텍트는 이러한 요구 사항을 충족하는 솔루션을 설계해야 합니다.",
        "Question": "솔루션 아키텍트가 미디어 회사의 비디오 콘텐츠에 대한 URL 서명을 구현하기 위한 최상의 접근 방식은 무엇입니까?",
        "Options": {
            "1": "비디오에 대한 공용 접근을 허용하지만 IP 주소에 따라 접근을 제한하는 S3 버킷 정책을 설정합니다.",
            "2": "각 비디오 요청에 대해 고유한 URL을 생성하는 사용자 정의 인증 시스템을 만들어 인증된 사용자만 접근할 수 있도록 합니다.",
            "3": "CloudFront를 구성하여 서명된 URL 및 서명된 쿠키를 사용하고, 사용자가 단일 서명된 쿠키로 여러 비디오에 접근할 수 있도록 하여 접근 제어를 유지합니다.",
            "4": "AWS Lambda를 사용하여 각 비디오에 대한 사전 서명된 URL을 생성하고 이를 사용자에게 전송하여 제한된 수명을 보장합니다."
        },
        "Correct Answer": "CloudFront를 구성하여 서명된 URL 및 서명된 쿠키를 사용하고, 사용자가 단일 서명된 쿠키로 여러 비디오에 접근할 수 있도록 하여 접근 제어를 유지합니다.",
        "Explanation": "CloudFront의 서명된 URL 및 서명된 쿠키를 사용하면 미디어 회사가 URL을 변경하지 않고도 여러 비디오 파일에 대한 접근을 효율적으로 제어할 수 있어, 보안을 보장하면서 더 사용자 친화적인 경험을 제공합니다.",
        "Other Options": [
            "AWS Lambda를 사용하여 각 비디오에 대한 사전 서명된 URL을 생성하면 생성된 URL의 수가 과도해져 여러 비디오를 보려는 사용자에게 접근을 복잡하게 만들 수 있습니다.",
            "IP 주소에 따라 공용 접근을 허용하는 S3 버킷 정책을 설정하면 IP 범위가 엄격하게 제어되지 않을 경우 콘텐츠가 무단 사용자에게 노출될 수 있습니다.",
            "사용자 정의 인증 시스템을 만드는 것은 불필요한 복잡성과 관리 오버헤드를 추가하여 CloudFront의 기존 기능을 사용하는 것보다 효율성이 떨어집니다."
        ]
    },
    {
        "Question Number": "22",
        "Situation": "한 소매 회사가 전국의 매장에 위치한 판매 시점(POS) 시스템에서 실시간 판매 데이터를 수집하고 있습니다. 이 데이터 분석을 통해 고객 구매 행동 및 트렌드에 대한 통찰력을 얻고자 합니다. 이를 위해, 그들은 데이터 레이크에 스트리밍 데이터를 신뢰성 있게 로드할 수 있는 서비스를 고려하고 있습니다.",
        "Question": "솔루션 아키텍트가 최소한의 관리 오버헤드로 Amazon S3에 스트리밍 데이터를 캡처하고 로드하기 위해 추천해야 할 AWS 서비스는 무엇입니까?",
        "Options": {
            "1": "Amazon Kinesis Data Firehose",
            "2": "Amazon SQS",
            "3": "AWS Lambda",
            "4": "Amazon Kinesis Data Streams"
        },
        "Correct Answer": "Amazon Kinesis Data Firehose",
        "Explanation": "Amazon Kinesis Data Firehose는 지속적인 관리 없이 Amazon S3와 같은 서비스에 스트리밍 데이터를 로드하도록 특별히 설계되어 이 사용 사례에 이상적입니다. 데이터 변환 및 로드를 데이터 레이크에 직접 처리할 수 있어 실시간 분석 기능을 제공합니다.",
        "Other Options": [
            "Amazon Kinesis Data Streams는 실시간 처리 기능을 제공하도록 설계되어 있어 더 많은 관리 및 구성이 필요하며, Kinesis 클라이언트를 사용하여 데이터를 읽고 처리해야 합니다.",
            "AWS Lambda는 데이터를 처리하는 데 사용할 수 있는 서버리스 컴퓨팅 서비스이지만, 데이터 레이크에 스트리밍 데이터를 로드하도록 특별히 설계되지 않아 이 시나리오에 덜 적합합니다.",
            "Amazon SQS는 분리된 마이크로서비스가 통신할 수 있도록 하는 메시지 큐잉 서비스이지만, 스트리밍 데이터를 데이터 레이크나 다른 분석 서비스에 직접 로드하는 기능을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "23",
        "Situation": "한 금융 서비스 회사가 AWS에 호스팅된 마이크로서비스 아키텍처를 위한 CI/CD 파이프라인을 구현하고 있습니다. 그들은 다운타임을 최소화하고 실패 시 빠른 롤백을 가능하게 하는 배포 전략이 필요합니다. 애플리케이션은 자동화된 테스트와 기존 모니터링 도구와의 통합을 지원해야 합니다. 회사는 배포 중 원활한 사용자 경험을 보장하는 것에 특히 신경을 쓰고 있습니다.",
        "Question": "솔루션 아키텍트가 회사의 다운타임 최소화 및 빠른 롤백을 위한 요구 사항을 충족하기 위해 추천해야 할 배포 전략은 무엇입니까?",
        "Options": {
            "1": "AWS CodeDeploy를 사용하여 롤링 배포 전략을 사용합니다. 이전 버전의 일부를 실행하면서 인스턴스를 배치로 업데이트합니다. 이는 점진적인 전환을 가능하게 하지만 롤백 프로세스를 복잡하게 만들 수 있습니다.",
            "2": "AWS Elastic Beanstalk를 사용하여 블루/그린 배포 전략을 구현합니다. 현재 버전과 새 버전을 위한 두 개의 동일한 환경을 생성합니다. 성공적인 테스트 후 새 환경으로 트래픽을 라우팅하고 문제가 발생하면 쉽게 다시 전환합니다.",
            "3": "AWS CodeDeploy를 사용하여 한 번에 모두 배포하는 전략을 활용합니다. 새 버전을 모든 인스턴스에 동시에 배포하고 문제를 모니터링합니다. 필요 시 롤백하지만 배포 중 잠재적인 다운타임이 예상됩니다.",
            "4": "AWS Lambda를 사용하여 카나리아 배포 전략을 채택합니다. 처음에 소수의 사용자에게 새 버전을 배포하고 반응을 모니터링한 후 전체 사용자 기반으로 배포합니다."
        },
        "Correct Answer": "AWS Elastic Beanstalk를 사용하여 블루/그린 배포 전략을 구현합니다. 현재 버전과 새 버전을 위한 두 개의 동일한 환경을 생성합니다. 성공적인 테스트 후 새 환경으로 트래픽을 라우팅하고 문제가 발생하면 쉽게 다시 전환합니다.",
        "Explanation": "블루/그린 배포 전략은 애플리케이션 버전 간의 원활한 전환을 가능하게 하여 다운타임을 최소화하고 배포 후 문제가 발생할 경우 쉽게 롤백할 수 있는 메커니즘을 제공합니다. 이 접근 방식은 업데이트 중 사용자 경험이 중단되지 않도록 보장합니다.",
        "Other Options": [
            "한 번에 모두 배포하는 전략은 모든 인스턴스가 동시에 업데이트되므로 상당한 다운타임을 초래할 수 있습니다. 롤백은 가능하지만 사용자 중단의 가능성 때문에 이 접근 방식은 회사의 요구에 덜 적합합니다.",
            "롤링 배포 전략은 인스턴스를 배치로 업데이트하여 다운타임을 줄이는 데 도움이 될 수 있습니다. 그러나 일부 사용자는 여전히 이전 버전을 사용하고 다른 사용자는 새 버전을 사용하게 되어 일관성 없는 동작을 초래할 수 있으므로 롤백 프로세스를 복잡하게 만듭니다.",
            "카나리아 배포 전략은 먼저 소수의 사용자와 함께 새 버전을 테스트하는 데 유용합니다. 그러나 블루/그린만큼 효과적으로 완전한 롤백 옵션을 제공하지 않으며, Lambda 함수에 대한 추가 구성 및 모니터링이 필요할 수 있습니다."
        ]
    },
    {
        "Question Number": "24",
        "Situation": "한 회사가 신뢰할 수 있는 메시지 큐잉 서비스가 필요한 마이크로서비스 애플리케이션을 개발하고 있습니다. 그들은 이 목적을 위해 Amazon SQS를 사용하는 것을 고려하고 있습니다. 그들이 고려해야 할 주요 제약 조건 중 하나는 SQS를 통해 전송할 수 있는 메시지의 최대 크기입니다.",
        "Question": "Amazon SQS를 통해 전송할 수 있는 메시지의 최대 크기는 얼마입니까?",
        "Options": {
            "1": "128,000 바이트",
            "2": "512,000 바이트",
            "3": "262,144 바이트",
            "4": "256,000 바이트"
        },
        "Correct Answer": "262,144 바이트",
        "Explanation": "Amazon SQS의 최대 메시지 크기는 262,144 바이트(256 KB)입니다. 이 제한은 SQS 큐에 전송할 수 있는 각 개별 메시지의 크기에 적용되어 메시지가 경량으로 유지되고 전송이 효율적이도록 보장합니다.",
        "Other Options": [
            "128,000 바이트는 262,144 바이트의 실제 최대 메시지 크기 제한보다 훨씬 낮기 때문에 잘못된 답변입니다.",
            "256,000 바이트는 262,144 바이트의 최대 메시지 크기 제한보다 낮기 때문에 잘못된 답변입니다.",
            "512,000 바이트는 262,144 바이트의 최대 메시지 크기 제한을 초과하므로 SQS에 대한 유효한 옵션이 아닙니다."
        ]
    },
    {
        "Question Number": "25",
        "Situation": "한 회사가 데이터 분석을 위해 Amazon Redshift를 사용하고 있으며 재해 복구 전략을 강화하고자 합니다. 그들은 데이터를 다른 AWS 리전으로 자동으로 백업해야 하는 요구 사항이 있습니다. Redshift 클러스터는 KMS로 암호화되어 있으며, 규정 준수 요구 사항을 준수하면서 스냅샷을 리전 간에 복사할 수 있도록 보장하고자 합니다.",
        "Question": "KMS로 암호화된 Amazon Redshift 클러스터에 대해 리전 간 스냅샷을 활성화하는 올바른 프로세스는 무엇입니까?",
        "Options": {
            "1": "자동 스냅샷을 활성화하고 클러스터 설정에서 대상 리전을 지정합니다.",
            "2": "스냅샷 복사를 활성화하기 전에 Redshift가 대상 리전에서 KMS 고객 마스터 키를 사용할 수 있도록 권한을 부여합니다.",
            "3": "AWS Management Console을 사용하여 스냅샷을 수동으로 대상 리전으로 복사합니다.",
            "4": "KMS 암호화 대신 S3를 백업에 사용하도록 클러스터 구성을 변경합니다."
        },
        "Correct Answer": "스냅샷 복사를 활성화하기 전에 Redshift가 대상 리전에서 KMS 고객 마스터 키를 사용할 수 있도록 권한을 부여합니다.",
        "Explanation": "KMS로 암호화된 Amazon Redshift 클러스터에 대해 리전 간 스냅샷을 활성화하려면, Amazon Redshift가 대상 리전에서 KMS 고객 마스터 키(CMK)를 사용할 수 있도록 권한을 부여해야 합니다. 이 단계는 클러스터가 다른 리전에서 스냅샷에 필요한 암호화 키에 접근할 수 있도록 보장하는 데 필수적입니다.",
        "Other Options": [
            "자동 스냅샷을 활성화하고 대상 리전을 지정하는 것만으로는 충분하지 않으며, 암호화를 위한 KMS 권한을 처리해야 합니다.",
            "스냅샷을 수동으로 복사하는 것은 지속적인 백업을 위한 실행 가능하거나 자동화된 솔루션이 아니며, 리전 간 스냅샷 기능은 자동화되도록 설계되었습니다.",
            "클러스터 구성을 S3를 백업에 사용하도록 변경하는 것은 Redshift 스냅샷 복사에 적용되지 않으며, 리전 간 자동화된 스냅샷 요구 사항을 충족하지 않습니다."
        ]
    },
    {
        "Question Number": "26",
        "Situation": "한 글로벌 회사가 AWS Organizations를 사용하여 다양한 사업 부서를 관리하기 위한 다중 계정 전략을 구현하고자 합니다. 이 회사는 또한 거버넌스 및 규정 준수를 위해 AWS Control Tower를 활용할 계획입니다. 솔루션 아키텍트는 모든 계정에서 중앙 집중식 관리, 청구 및 규정 준수를 가능하게 하면서 각 사업 부서가 자신의 리소스에 대한 자율성을 가질 수 있도록 하는 솔루션을 설계해야 합니다.",
        "Question": "솔루션 아키텍트가 요구 사항을 가장 잘 충족하기 위해 구현해야 할 솔루션은 무엇입니까?",
        "Options": {
            "1": "각 사업 부서에 대해 AWS Organization 내에 여러 OU를 생성하고, OU 수준에서 SCP를 적용하여 규정 준수 및 중앙 집중식 관리를 관리합니다.",
            "2": "모든 계정을 루트 OU에 설정하고 각 계정에 대해 서비스 제어 정책(SCP)을 활성화하여 규정 준수를 강제하는 단일 AWS Organization을 설정합니다.",
            "3": "AWS Control Tower를 구현하여 거버넌스 프레임워크를 생성하고 모든 계정을 단일 OU에 배치하며 계정 수준에서 엄격한 SCP를 적용합니다.",
            "4": "AWS Control Tower를 활용하여 사전 구성된 계정으로 랜딩 존을 설정하고 루트 OU에서 SCP를 구현하여 모든 사업 부서에서 규정 준수를 강제합니다."
        },
        "Correct Answer": "각 사업 부서에 대해 AWS Organization 내에 여러 OU를 생성하고, OU 수준에서 SCP를 적용하여 규정 준수 및 중앙 집중식 관리를 관리합니다.",
        "Explanation": "여러 OU를 생성하면 서로 다른 사업 부서에 해당하는 계정을 더 잘 조직하고 관리할 수 있으며, OU 수준에서 SCP를 적용하면 각 부서의 요구에 맞춘 규정 준수를 유연하게 강제할 수 있습니다.",
        "Other Options": [
            "모든 계정을 루트 OU에 설정하고 각 사업 부서에 대한 특정 OU 없이 관리하면 관리 복잡성이 증가하고 규정 준수 강제가 덜 효과적일 수 있습니다.",
            "AWS Control Tower를 활용하여 랜딩 존을 설정하는 것은 유익하지만, 루트 OU에서만 SCP를 적용하면 서로 다른 사업 부서 간의 규정 준수 관리의 세분성이 제한될 수 있습니다.",
            "모든 계정을 단일 OU에 배치하고 계정 수준에서 엄격한 SCP를 적용하면 개별 사업 부서의 자율성을 저해하고 거버넌스를 복잡하게 만들 수 있으며, 각 부서의 요구에 맞춘 특정 정책을 허용하지 않습니다."
        ]
    },
    {
        "Question Number": "27",
        "Situation": "한 금융 서비스 회사가 민감한 고객 데이터를 처리하는 새로운 애플리케이션을 AWS에 배포하고 있습니다. 이 회사는 애플리케이션이 엄격한 보안 규정 준수 요구 사항을 충족하면서 리소스에 대한 무단 접근 위험을 최소화해야 합니다.",
        "Question": "회사가 산업 규정을 준수하면서 AWS 환경의 보안을 강화하기 위해 구현해야 할 전략은 무엇입니까?",
        "Options": {
            "1": "AWS CloudTrail을 활성화하여 모든 API 호출을 기록하고 AWS Config를 구성하여 모든 리소스의 보안 정책 준수를 모니터링합니다.",
            "2": "민감한 데이터를 저장하기 위해 Amazon S3 버킷을 생성하고 애플리케이션의 원활한 검색을 위해 공개 액세스를 활성화합니다.",
            "3": "사용하지 않는 IAM 역할과 액세스 키를 삭제하기 위해 주기적으로 실행되는 AWS Lambda 함수를 구현하여 공격 표면을 줄입니다.",
            "4": "공용 서브넷 내에 SSH 접근을 허용하는 배스천 호스트를 설정하여 모든 다른 수신 트래픽을 비활성화합니다."
        },
        "Correct Answer": "AWS CloudTrail을 활성화하여 모든 API 호출을 기록하고 AWS Config를 구성하여 모든 리소스의 보안 정책 준수를 모니터링합니다.",
        "Explanation": "AWS CloudTrail을 활성화하면 AWS 계정에서 이루어진 모든 API 호출을 기록할 수 있어 규정 준수를 위한 포괄적인 감사 추적을 제공합니다. 또한 AWS Config는 리소스의 변경 사항을 추적하고 정의된 보안 정책에 대한 준수를 평가하는 데 도움이 되어 보안을 강화하고 규제 요구 사항을 충족하는 효과적인 전략이 됩니다.",
        "Other Options": [
            "배스천 호스트를 설정하면 SSH 접근에 대한 보안을 개선할 수 있지만, 민감한 애플리케이션에 중요한 전체 규정 준수 모니터링이나 로깅을 해결하지 않습니다.",
            "사용하지 않는 IAM 역할과 액세스 키를 삭제하기 위해 Lambda 함수를 구현하는 것은 공격 표면을 줄일 수 있지만, 민감한 데이터 처리를 위한 포괄적인 감사 및 규정 준수 모니터링을 제공하지 않습니다.",
            "공개 액세스를 가진 S3 버킷을 생성하는 것은 민감한 데이터를 노출시켜 보안을 저해하며, AWS 환경에서 보안 및 규정 준수를 강화하려는 목표에 반합니다."
        ]
    },
    {
        "Question Number": "28",
        "Situation": "한 금융 서비스 회사가 온프레미스 애플리케이션을 AWS로 마이그레이션할 계획을 세우고 있습니다. 이들은 마이그레이션 과정에서 데이터의 보안에 특히 우려하고 있습니다. 이 회사는 AWS Database Migration Service (DMS)와 AWS Application Migration Service (AWS MGN)를 조합하여 마이그레이션을 처리하고 있습니다. 이들은 민감한 데이터가 전송 중과 저장 중에 안전하게 유지되기를 원합니다.",
        "Question": "회사가 마이그레이션 과정에서 데이터의 보안을 강화하기 위해 어떤 방법을 구현해야 합니까? (두 가지 선택)",
        "Options": {
            "1": "모든 마이그레이션 인스턴스가 마이그레이션 중 더 쉽게 접근할 수 있도록 공용 서브넷에서 시작되도록 합니다.",
            "2": "AWS CloudTrail을 활성화하여 마이그레이션 서비스가 수행한 API 호출을 추적하여 준수 및 감사 목적으로 사용합니다.",
            "3": "AWS Key Management Service (KMS)를 사용하여 대상 AWS 환경에서 저장된 데이터의 암호화 키를 관리합니다.",
            "4": "S3 버킷 정책을 구성하여 마이그레이션 도구가 임시 데이터를 저장할 수 있도록 무제한 접근을 허용합니다.",
            "5": "DMS와 AWS MGN을 사용하여 TLS로 전송 중 암호화를 구현하여 마이그레이션 중 민감한 데이터를 보호합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "DMS와 AWS MGN을 사용하여 TLS로 전송 중 암호화를 구현하여 마이그레이션 중 민감한 데이터를 보호합니다.",
            "AWS Key Management Service (KMS)를 사용하여 대상 AWS 환경에서 저장된 데이터의 암호화 키를 관리합니다."
        ],
        "Explanation": "TLS를 사용하여 전송 중 암호화를 구현하면 온프레미스 환경과 AWS 간에 이동하는 데이터가 가로채기에서 보호됩니다. 또한, AWS KMS를 사용하여 저장된 데이터의 암호화 키를 관리하면 AWS에 저장된 민감한 데이터가 안전하게 유지되며 데이터 보호를 위한 모범 사례를 준수합니다.",
        "Other Options": [
            "마이그레이션 인스턴스를 공용 서브넷에서 시작하면 공용 인터넷에 노출되어 마이그레이션 중 민감한 데이터에 대한 무단 접근 위험이 증가합니다. 적절한 보안 조치를 갖춘 사설 서브넷을 사용하는 것이 좋습니다.",
            "AWS CloudTrail을 활성화하는 것은 활동을 추적하는 좋은 방법이지만, 마이그레이션 중 데이터의 보안을 직접적으로 강화하지는 않습니다. 이는 데이터 자체를 보호하기보다는 로깅에 중점을 둡니다.",
            "S3 버킷 정책에서 무제한 접근을 허용하면 무단 접근 및 데이터 유출로 이어질 수 있습니다. 마이그레이션 중 데이터에 접근할 수 있는 사람을 제한하기 위해 최소 권한 접근을 구현하는 것이 중요합니다."
        ]
    },
    {
        "Question Number": "29",
        "Situation": "한 금융 서비스 회사가 Amazon S3에 저장된 민감한 데이터를 보호하기 위해 고객 제공 키(SSE-C)를 사용한 서버 측 암호화를 구현하고 있습니다. 애플리케이션은 REST API 호출을 통해 암호화된 객체를 업로드하고 검색하며, 데이터 무결성과 보안을 유지하기 위해 각 요청에 올바른 HTTP 헤더가 포함되어야 합니다. 개발 팀은 사전 서명된 URL을 사용할 때 SSE-C 암호화를 위한 필수 헤더를 이해해야 합니다.",
        "Question": "Amazon S3에서 고객 제공 키(SSE-C)로 서버 측 암호화를 위해 사전 서명된 URL을 사용할 때 포함해야 하는 HTTP 요청 헤더는 무엇입니까?",
        "Options": {
            "1": "x-amz-server-side-encryption-customer-algorithm, x-amz-server-side-encryption-customer-key, x-amz-server-side-encryption-customer-key-MD5",
            "2": "x-amz-server-side-encryption-customer-key, x-amz-server-side-encryption-customer-key-MD5",
            "3": "x-amz-server-side-encryption-customer-algorithm, x-amz-server-side-encryption-customer-key",
            "4": "x-amz-server-side-encryption-customer-algorithm"
        },
        "Correct Answer": "x-amz-server-side-encryption-customer-algorithm",
        "Explanation": "Amazon S3에서 SSE-C를 위해 사전 서명된 URL을 사용할 때 필요한 HTTP 헤더는 'x-amz-server-side-encryption-customer-algorithm'으로 암호화 알고리즘을 지정합니다. 다른 헤더는 사전 서명된 URL을 사용할 때 필요하지 않으며, 고객 키와 그 MD5 해시는 초기 요청에 포함되지 않습니다.",
        "Other Options": [
            "이 옵션은 사전 서명된 URL에 필요하지 않은 불필요한 헤더를 포함하고 있으므로 잘못된 것입니다. 알고리즘 헤더만 필수입니다.",
            "이 옵션은 사전 서명된 URL을 사용할 때 암호화 알고리즘을 지정하기 위한 필수 헤더가 부족하므로 잘못된 것입니다.",
            "이 옵션은 사전 서명된 URL을 사용할 때 SSE-C를 위한 필수 알고리즘 헤더를 포함하지 않으므로 잘못된 것입니다."
        ]
    },
    {
        "Question Number": "30",
        "Situation": "한 금융 서비스 회사가 웹 계층, 애플리케이션 계층 및 데이터베이스 계층을 포함하는 다계층 애플리케이션을 AWS에 배포하고 있습니다. 이 회사는 규제 요구 사항을 준수하고 문제를 해결하며 성능을 최적화하기 위해 포괄적인 로깅 및 모니터링 전략이 필요합니다. 애플리케이션은 웹 및 애플리케이션 계층에 Amazon EC2 인스턴스를 사용하고 데이터베이스에 Amazon RDS를 사용할 것입니다. 이 회사는 운영 오버헤드를 최소화하면서 보안 및 접근 제어를 극대화하는 솔루션을 구현하는 것을 목표로 하고 있습니다.",
        "Question": "회사가 요구 사항을 충족하기 위해 채택해야 할 로깅 및 모니터링 전략은 무엇입니까?",
        "Options": {
            "1": "EC2 인스턴스에서 로그를 수집하고 중앙 집중화하는 오픈 소스 로깅 솔루션을 배포합니다. 기본 모니터링을 위해 Amazon CloudWatch를 사용하고, 규정 준수를 위해 로그 데이터를 S3에 정기적으로 백업하는 크론 작업을 설정합니다.",
            "2": "애플리케이션 및 인프라 모니터링을 위해 Amazon CloudWatch를 구현하고, 모든 API 호출을 기록하기 위해 AWS CloudTrail을 사용합니다. 잠재적인 문제에 대해 운영 팀에 알리기 위해 사용자 정의 메트릭 및 경고를 설정합니다. 보안 모니터링 및 위협 탐지를 위해 Amazon GuardDuty를 통합합니다.",
            "3": "Amazon CloudWatch Logs를 활용하여 EC2 인스턴스와 RDS의 애플리케이션 로그를 집계합니다. AWS Lambda를 구성하여 로그를 처리하고 중요한 이벤트에 대해 Amazon SNS를 통해 경고를 보냅니다. AWS Systems Manager를 사용하여 운영 작업을 관리하고 자동화합니다.",
            "4": "애플리케이션 전반에 걸쳐 요청을 추적하기 위해 AWS X-Ray를 활용하고, 시스템 성능 모니터링을 위해 Amazon CloudWatch를 결합합니다. 구성 변경을 추적하기 위해 AWS Config를 사용하고, API 호출 로깅을 위해 AWS CloudTrail을 사용하여 포괄적인 감사 추적을 보장합니다."
        },
        "Correct Answer": "애플리케이션 및 인프라 모니터링을 위해 Amazon CloudWatch를 구현하고, 모든 API 호출을 기록하기 위해 AWS CloudTrail을 사용합니다. 잠재적인 문제에 대해 운영 팀에 알리기 위해 사용자 정의 메트릭 및 경고를 설정합니다. 보안 모니터링 및 위협 탐지를 위해 Amazon GuardDuty를 통합합니다.",
        "Explanation": "이 옵션은 규제 준수를 충족하고 문제 해결을 가능하게 하며 성능을 최적화하는 포괄적인 로깅 및 모니터링 전략을 제공합니다. Amazon CloudWatch는 실시간 모니터링 및 경고를 가능하게 하고, AWS CloudTrail은 API 호출의 완전한 감사 추적을 보장하며, Amazon GuardDuty는 필수적인 보안 모니터링을 추가합니다.",
        "Other Options": [
            "AWS X-Ray를 사용하여 추적하고 Amazon CloudWatch를 사용하여 모니터링하는 것은 유익하지만, Amazon GuardDuty가 제공하는 포괄적인 보안 모니터링 및 위협 탐지 기능과 AWS CloudTrail이 제공하는 집중적인 API 로깅 기능이 부족합니다.",
            "Amazon CloudWatch Logs로 로그를 집계하고 AWS Lambda를 통해 처리하는 것은 일부 모니터링 기능을 제공하지만, 규제 준수를 위해 필수적인 광범위한 API 로깅 및 보안 기능을 제공하지 않습니다.",
            "오픈 소스 로깅 솔루션을 배포하면 운영 오버헤드와 유지 관리 문제를 증가시킬 수 있으며, 보안, 준수 및 사용 편의성을 보장하기 위해 설계된 AWS의 관리형 서비스의 이점을 충분히 활용하지 못합니다."
        ]
    },
    {
        "Question Number": "31",
        "Situation": "한 금융 서비스 회사가 AWS에서 호스팅되는 중요한 애플리케이션의 재해 복구 전략을 평가하고 있습니다. 그들은 재해 발생 시 최소한의 다운타임과 데이터 손실을 보장하고자 합니다. 이 회사는 애플리케이션에 대해 4시간의 복구 시간 목표(RTO)와 1시간의 복구 지점 목표(RPO)를 정의했습니다. 그들은 이러한 목표를 충족하기 위해 다양한 백업 및 복제 전략을 고려하고 있습니다.",
        "Question": "다음 전략 중 어느 것이 회사가 RTO 및 RPO 요구 사항을 충족하는 데 가장 적합합니까?",
        "Options": {
            "1": "버전 관리가 활성화된 Amazon S3를 저장소로 활용하고 Amazon RDS에 대해 다중 AZ 배포를 설정합니다.",
            "2": "모든 데이터에 대해 교차 지역 복제를 구현하고 AWS Elastic Beanstalk를 사용하여 애플리케이션을 배포합니다.",
            "3": "AWS Backup을 사용하여 모든 리소스의 일일 백업을 생성하고 단일 가용 영역의 Amazon EC2 인스턴스에 애플리케이션을 배포합니다.",
            "4": "Amazon RDS의 시간별 스냅샷을 예약하고 AWS Lambda를 사용하여 데이터베이스 장애 조치를 보조 지역으로 자동화합니다."
        },
        "Correct Answer": "버전 관리가 활성화된 Amazon S3를 저장소로 활용하고 Amazon RDS에 대해 다중 AZ 배포를 설정합니다.",
        "Explanation": "버전 관리가 활성화된 Amazon S3를 활용하면 데이터 손실을 최소화하고 1시간의 RPO를 충족하는 데 도움이 되는 신뢰할 수 있는 데이터 저장소를 제공합니다. 한편, Amazon RDS에 대한 다중 AZ 배포는 높은 가용성과 신속한 장애 조치 기능을 보장하여 4시간의 RTO와 일치합니다.",
        "Other Options": [
            "교차 지역 복제를 구현하면 지연 시간과 비용이 증가할 수 있으며, 내구성을 제공할 수 있지만 다중 AZ 배포만큼 RTO 및 RPO 요구 사항을 효과적으로 충족하지 못할 수 있습니다.",
            "시간별 스냅샷을 예약하는 것은 1시간의 RPO를 충족하기에 충분히 자주 이루어지지 않을 수 있으며, 장애 조치를 자동화하는 것은 유익하지만 RTO를 충족하기 위해 필요한 빠른 복구 시간을 보장하지 못할 수 있습니다.",
            "일일 백업을 생성하는 것은 1시간의 RPO를 충족하지 못합니다. 왜냐하면 백업이 해당 시간 내에 이루어진 데이터 변경 사항을 포착하지 못하기 때문입니다. 또한 단일 가용 영역에 애플리케이션을 배포하는 것은 RTO를 충족하기 위한 필요한 복원력을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "32",
        "Situation": "한 회사가 대규모 온프레미스 데이터베이스를 AWS로 마이그레이션할 계획을 세우고 있습니다. 데이터베이스의 크기는 약 10TB이며 마이그레이션 중 최소한의 다운타임이 필요합니다. 팀은 데이터 무결성과 보안을 보장하면서 이 마이그레이션을 용이하게 하기 위해 다양한 AWS 서비스를 고려하고 있습니다.",
        "Question": "팀이 최소한의 다운타임으로 데이터베이스를 마이그레이션하기 위해 어떤 AWS 서비스와 전략을 사용해야 합니까?",
        "Options": {
            "1": "AWS DataSync와 AWS Schema Conversion Tool (SCT)",
            "2": "AWS Snowball과 AWS Database Migration Service (DMS)",
            "3": "AWS Transfer Family와 Amazon RDS Migration Readiness Review",
            "4": "AWS Direct Connect와 수동 데이터 내보내기 및 가져오기"
        },
        "Correct Answer": "AWS Snowball과 AWS Database Migration Service (DMS)",
        "Explanation": "AWS Snowball은 대량의 데이터를 AWS로 효율적으로 전송할 수 있게 해줍니다. AWS Database Migration Service (DMS)를 함께 사용하면 데이터 전송 중 지속적인 복제를 수행할 수 있어 최소한의 다운타임을 보장하고 마이그레이션 과정에서 데이터 무결성을 유지할 수 있습니다.",
        "Other Options": [
            "AWS DataSync는 주로 파일 전송에 사용되며 데이터베이스에는 적합하지 않습니다. AWS Schema Conversion Tool (SCT)은 스키마 변환에 유용하지만 최소한의 다운타임으로 대규모 마이그레이션 요구 사항을 충족하지 않습니다.",
            "AWS Direct Connect는 전용 네트워크 연결을 설정하는 데 유용하지만 대규모 데이터베이스의 마이그레이션을 직접 지원하지 않습니다. 수동 데이터 내보내기 및 가져오기는 상당한 다운타임을 초래할 가능성이 높으며 이 상황에 적합하지 않습니다.",
            "AWS Transfer Family는 SFTP 또는 FTP와 같은 프로토콜을 사용하여 파일을 전송하기 위해 설계되었으며 데이터베이스 마이그레이션에는 적용되지 않습니다. 또한 Amazon RDS Migration Readiness Review는 마이그레이션 전략이 아니라 준비 단계입니다."
        ]
    },
    {
        "Question Number": "33",
        "Situation": "한 기술 회사가 웹 애플리케이션을 사용하여 인증하는 사용자에게 AWS 리소스에 대한 임시 액세스를 요구하는 시스템을 구현하고 있습니다. 이 애플리케이션은 영구적인 AWS IAM 사용자를 생성하지 않고 특정 AWS 서비스에 대한 제한된 시간 액세스를 사용자에게 제공해야 합니다. 아키텍처는 솔루션이 확장 가능하고 단일 실패 지점을 도입하지 않도록 해야 합니다. 보안과 관리 용이성을 고려하여 사용자 액세스를 관리하기 위한 올바른 접근 방식을 선택하는 임무를 맡고 있습니다.",
        "Question": "단일 실패 지점의 위험을 최소화하면서 AWS 리소스에 대한 임시 액세스를 제공하기 위해 어떤 접근 방식을 구현해야 합니까?",
        "Options": {
            "1": "AWS Security Token Service (STS)를 사용하여 인증 시 사용자에게 제공할 수 있는 임시 자격 증명을 생성하고, 자격 증명이 제한된 권한을 가지도록 합니다.",
            "2": "전통적인 토큰 검증 모델(TVM)을 구현하여 사용자 액세스를 관리하고 서비스별 권한 및 자격 증명 전달을 사용자에게 허용합니다.",
            "3": "Amazon Cognito를 사용하여 사용자 인증을 관리하고 AWS STS를 통해 임시 자격 증명을 발급하여 단일 실패 지점 없이 확장 가능하고 안전한 솔루션을 제공합니다.",
            "4": "사용자 인증 및 액세스를 관리하기 위해 사용자 정의 코드가 실행되는 EC2 인스턴스를 배포하여 자격 증명이 안전하게 전달되도록 합니다."
        },
        "Correct Answer": "Amazon Cognito를 사용하여 사용자 인증을 관리하고 AWS STS를 통해 임시 자격 증명을 발급하여 단일 실패 지점 없이 확장 가능하고 안전한 솔루션을 제공합니다.",
        "Explanation": "Amazon Cognito는 사용자 인증을 위한 강력한 솔루션을 제공하며 AWS STS와 원활하게 통합되어 임시 자격 증명을 발급합니다. 이 접근 방식은 사용자 정의 TVM 구현과 관련된 단일 실패 지점을 피하고 사용자 액세스를 관리하는 데 있어 확장성과 보안을 제공합니다.",
        "Other Options": [
            "AWS STS만 사용하는 것은 임시 자격 증명을 제공하지만 사용자 인증을 직접 관리하지 않습니다. 이 접근 방식은 Amazon Cognito가 제공하는 사용자 풀 관리 및 향상된 보안과 같은 추가 기능이 부족합니다.",
            "전통적인 토큰 검증 모델(TVM)을 구현하면 EC2에 호스팅될 경우 단일 실패 지점을 초래할 수 있습니다. 또한 TVM은 Amazon Cognito와 같은 현대적인 솔루션에 비해 구식으로 간주됩니다.",
            "사용자 정의 TVM을 위한 EC2 인스턴스를 배포하면 복잡성과 운영 오버헤드가 증가하여 실패 위험이 높아집니다. 이 방법은 사용자 액세스를 관리하는 데 있어 Amazon Cognito와 같은 수준의 확장성과 보안을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "34",
        "Situation": "한 소매 회사가 높은 가용성과 트래픽에 따라 자동으로 확장할 수 있는 새로운 전자상거래 애플리케이션을 출시할 계획입니다. 이 애플리케이션은 특히 프로모션과 휴일 세일 기간 동안 예측할 수 없는 트래픽 패턴을 경험할 것입니다. 회사는 배포 전략이 다운타임을 최소화하고 원활한 사용자 경험을 제공하도록 보장하고자 합니다.",
        "Question": "회사가 전자상거래 애플리케이션의 높은 가용성과 확장성을 보장하기 위해 어떤 배포 전략을 구현해야 합니까?",
        "Options": {
            "1": "단일 EC2 인스턴스에 애플리케이션을 배포하고 대용량 EBS 볼륨을 구성한 후, 스케일링 알림을 보내기 위해 CloudWatch 알람을 설정합니다.",
            "2": "로드 밸런서 뒤에 여러 EC2 인스턴스가 있는 Elastic Beanstalk 환경을 활용하고, CPU 사용량 메트릭에 따라 자동 스케일링을 구성합니다.",
            "3": "모든 수신 요청을 처리하기 위해 AWS Lambda 함수를 사용하여 EC2 인스턴스를 관리하고 자동으로 확장할 필요가 없도록 합니다.",
            "4": "여러 컨테이너 인스턴스가 있는 Amazon ECS 클러스터를 구현하고, Fargate를 사용하여 애플리케이션의 확장 및 배포를 관리합니다."
        },
        "Correct Answer": "로드 밸런서 뒤에 여러 EC2 인스턴스가 있는 Elastic Beanstalk 환경을 활용하고, CPU 사용량 메트릭에 따라 자동 스케일링을 구성합니다.",
        "Explanation": "여러 EC2 인스턴스가 있는 Elastic Beanstalk를 사용하면 애플리케이션이 다양한 트래픽 부하를 처리할 수 있습니다. 로드 밸런서는 수신 트래픽을 분산시키고, 자동 스케일링은 CPU 사용량에 따라 인스턴스 수를 조정하여 높은 가용성과 효율적인 자원 사용을 이끌어냅니다.",
        "Other Options": [
            "단일 EC2 인스턴스에 애플리케이션을 배포하는 것은 높은 가용성을 제공하지 않으며, 단일 실패 지점을 도입합니다. CloudWatch 알람은 스케일링 필요성을 알릴 수 있지만, 처음부터 여러 인스턴스가 없으면 자동으로 스케일링할 수 없습니다.",
            "AWS Lambda를 사용하면 자동 스케일링이 가능하고 서버 관리를 없앨 수 있지만, 지속적인 연결이나 상태 유지 세션이 필요한 워크로드에는 적합하지 않을 수 있습니다.",
            "Fargate를 사용하는 Amazon ECS는 컨테이너 관리를 위한 유효한 옵션이지만, Elastic Beanstalk의 더 간단한 배포 모델로 효과적으로 관리할 수 있는 새로운 애플리케이션에는 불필요한 복잡성을 초래할 수 있습니다."
        ]
    },
    {
        "Question Number": "35",
        "Situation": "한 회사가 확장성과 유지 관리를 개선하기 위해 마이크로서비스 아키텍처를 개발하고 있습니다. 이 아키텍처는 서비스가 독립적으로 유지되고 긴밀한 결합 없이 별도로 발전할 수 있어야 합니다. 개발 팀은 마이크로서비스 간 느슨한 결합 종속성을 구현하기 위해 다양한 AWS 서비스를 고려하고 있습니다.",
        "Question": "마이크로서비스 간 느슨한 결합 종속성을 가능하게 하기 위해 솔루션 아키텍트가 추천해야 할 가장 적합한 솔루션은 무엇입니까?",
        "Options": {
            "1": "각 마이크로서비스에 대해 직접 API Gateway 엔드포인트가 있는 AWS Lambda 함수를 배포하여 서로 직접 호출할 수 있도록 합니다.",
            "2": "Amazon SNS를 활용하여 한 마이크로서비스에서 이벤트를 게시하고, 다른 마이크로서비스가 이를 구독할 수 있도록 하여 느슨한 결합 이벤트 기반 아키텍처를 허용합니다.",
            "3": "서비스 간 비동기 통신을 위해 Amazon SQS를 구현하여 직접 종속성 없이 메시지를 독립적으로 처리할 수 있도록 합니다.",
            "4": "AWS AppSync를 사용하여 모든 마이크로서비스를 연결하는 GraphQL API를 구축하여 동기식 통신과 공유 데이터 접근을 보장합니다."
        },
        "Correct Answer": "Amazon SNS를 활용하여 한 마이크로서비스에서 이벤트를 게시하고, 다른 마이크로서비스가 이를 구독할 수 있도록 하여 느슨한 결합 이벤트 기반 아키텍처를 허용합니다.",
        "Explanation": "Amazon SNS를 활용하면 마이크로서비스가 게시된 이벤트를 통해 통신할 수 있도록 하여 느슨한 결합 종속성을 구현하는 강력한 메커니즘을 제공합니다. 이 접근 방식은 서비스가 독립적으로 운영되고 긴밀하게 통합되지 않고 확장할 수 있도록 하여 이벤트 기반 아키텍처를 촉진합니다.",
        "Other Options": [
            "비동기 통신을 위한 Amazon SQS 구현은 유익하지만, 주로 메시지 큐잉에 초점을 맞추고 있어 느슨한 결합 종속성에 더 적합한 이벤트 기반 모델보다는 덜 적합합니다.",
            "AWS AppSync를 사용하면 GraphQL API가 동기식 통신을 촉진하여 서비스 간 긴밀한 결합을 초래할 수 있으며, 이는 독립성을 유지하려는 목표와 반대됩니다.",
            "직접 API Gateway 엔드포인트가 있는 AWS Lambda 함수를 배포하면 서비스가 서로 직접 호출하게 되어 긴밀한 결합을 초래하고 독립적으로 발전하기 어렵게 만듭니다."
        ]
    },
    {
        "Question Number": "36",
        "Situation": "한 회사가 온프레미스 애플리케이션을 AWS로 마이그레이션할 계획입니다. 그들은 서로 긴밀하게 결합된 레거시 애플리케이션과 일부 최신 클라우드 네이티브 애플리케이션을 혼합하여 보유하고 있습니다. 이 애플리케이션은 비즈니스 운영에 필수적이며, 회사는 마이그레이션 과정에서 다운타임을 최소화하고자 합니다. 솔루션 아키텍트는 이러한 워크로드에 대한 최적의 마이그레이션 접근 방식을 결정해야 합니다.",
        "Question": "솔루션 아키텍트가 애플리케이션을 AWS로 마이그레이션하는 동안 최소한의 다운타임을 보장하기 위해 추천해야 할 마이그레이션 전략은 무엇입니까?",
        "Options": {
            "1": "레거시 애플리케이션을 폐기하고 데이터를 Amazon RDS로 마이그레이션하며, 비즈니스 기능을 클라우드 네이티브 애플리케이션으로 대체합니다.",
            "2": "AWS Application Migration Service를 사용하여 레거시 애플리케이션을 AWS로 리프트 앤 시프트하여 마이그레이션 과정에서 운영을 유지합니다.",
            "3": "레거시 애플리케이션을 Amazon EC2 인스턴스에 재호스팅하고, 최신 애플리케이션을 Amazon ECS를 사용하여 컨테이너화하도록 점진적으로 리팩토링합니다.",
            "4": "모든 애플리케이션을 마이크로서비스로 리팩토링하고 AWS Lambda 함수로 배포하여 서버리스 아키텍처의 이점을 활용합니다."
        },
        "Correct Answer": "AWS Application Migration Service를 사용하여 레거시 애플리케이션을 AWS로 리프트 앤 시프트하여 마이그레이션 과정에서 운영을 유지합니다.",
        "Explanation": "AWS Application Migration Service를 사용한 리프트 앤 시프트 접근 방식은 회사가 레거시 애플리케이션을 신속하게 마이그레이션할 수 있도록 하여 다운타임을 최소화합니다. 이 방법은 애플리케이션이 큰 변경 없이 AWS에서 실행될 수 있도록 하여 전환 중 비즈니스 연속성을 보장합니다.",
        "Other Options": [
            "레거시 애플리케이션을 재호스팅하면서 최신 애플리케이션을 점진적으로 리팩토링하는 것은 긴밀하게 결합된 레거시 시스템이 단계적 마이그레이션에 쉽게 적응할 수 없기 때문에 다운타임 위험과 복잡성을 초래할 수 있습니다.",
            "모든 애플리케이션을 마이크로서비스로 리팩토링하고 AWS Lambda 함수로 배포하는 것은 광범위한 재구성이 필요할 수 있는 야심찬 접근 방식으로, 전환 중 다운타임이 발생할 수 있습니다.",
            "레거시 애플리케이션을 폐기하고 데이터를 Amazon RDS로 마이그레이션하며 비즈니스 기능을 클라우드 네이티브 애플리케이션으로 대체하는 것은 중요한 레거시 시스템에서 벗어나는 과정에서 상당한 다운타임과 비즈니스 중단을 초래할 수 있습니다."
        ]
    },
    {
        "Question Number": "37",
        "Situation": "한 스타트업이 AWS에서 실행될 마이크로서비스 애플리케이션을 개발하고 있습니다. 이 애플리케이션은 각각 특정 비즈니스 기능을 담당하는 여러 서비스를 포함할 것입니다. 스타트업은 컨테이너 배포를 위한 다양한 옵션을 고려하고 있으며, 높은 확장성, 자동 로드 밸런싱 및 최소한의 운영 오버헤드를 제공하는 솔루션을 선택하고자 합니다.",
        "Question": "다음 옵션 중 스타트업이 비용 효율적이고 효율적인 방식으로 마이크로서비스 애플리케이션을 배포하기 위한 요구 사항을 가장 잘 충족하는 것은 무엇입니까?",
        "Options": {
            "1": "AWS Fargate와 Amazon ECS를 사용하여 마이크로서비스를 배포합니다. 이 서버리스 옵션은 스타트업이 기본 인프라를 관리하지 않고도 컨테이너를 실행할 수 있게 해줍니다. 서비스 자동 확장을 구성하고 ECS의 내장 로드 밸런싱 기능을 사용하여 트래픽을 분산시킵니다.",
            "2": "EC2 런치 타입으로 Amazon ECS에 마이크로서비스를 배포합니다. 다양한 부하를 처리하기 위해 자동 확장을 구성하고 트래픽 분산을 위해 Elastic Load Balancer를 사용합니다. 기본 EC2 인스턴스를 관리하고 적절히 유지 관리해야 합니다.",
            "3": "Amazon EKS에 마이크로서비스를 배포합니다. Kubernetes를 사용하여 서비스의 배포 및 확장을 관리합니다. 동적 확장을 위해 클러스터 자동 확장기를 구성하고 로드 밸런싱을 위해 Kubernetes 서비스를 사용합니다. 이 옵션은 Kubernetes 환경을 관리해야 합니다.",
            "4": "AWS Lambda에 마이크로서비스를 배포합니다. 각 마이크로서비스를 수요에 따라 자동으로 확장할 수 있는 서버리스 함수로 분해합니다. API Gateway를 사용하여 로드 밸런싱 및 트래픽 관리를 수행하여 컨테이너 오케스트레이션의 필요성을 없앱니다."
        },
        "Correct Answer": "AWS Fargate와 Amazon ECS를 사용하여 마이크로서비스를 배포합니다. 이 서버리스 옵션은 스타트업이 기본 인프라를 관리하지 않고도 컨테이너를 실행할 수 있게 해줍니다. 서비스 자동 확장을 구성하고 ECS의 내장 로드 밸런싱 기능을 사용하여 트래픽을 분산시킵니다.",
        "Explanation": "AWS Fargate와 Amazon ECS에 마이크로서비스를 배포하면 스타트업이 기본 EC2 인스턴스를 관리할 필요 없이 서버리스 환경에서 컨테이너를 실행할 수 있습니다. 이 옵션은 자동 확장 및 내장 로드 밸런싱을 제공하여 운영 오버헤드와 비용을 최소화하면서 그들의 요구에 이상적입니다.",
        "Other Options": [
            "Amazon ECS에 EC2 런치 타입으로 마이크로서비스를 배포하면 스타트업이 기본 EC2 인스턴스를 관리해야 하므로 운영 오버헤드와 복잡성이 증가합니다. 확장할 수는 있지만 Fargate가 제공하는 관리 용이성과는 맞지 않습니다.",
            "Amazon EKS에 마이크로서비스를 배포하면 Kubernetes 환경을 관리해야 하므로 컨테이너 오케스트레이션 경험이 없는 스타트업에게는 복잡할 수 있습니다. 확장성을 제공하지만 Fargate와 같은 수준의 운영 단순성을 제공하지 않습니다.",
            "AWS Lambda에 마이크로서비스를 배포하는 것은 애플리케이션을 개별 함수로 분해해야 하므로 적합하지 않으며, 이는 함수 관리의 복잡성을 증가시키고 스타트업이 선호하는 컨테이너화된 접근 방식과는 달리 잠재적인 콜드 스타트 문제를 초래할 수 있습니다."
        ]
    },
    {
        "Question Number": "38",
        "Situation": "한 대규모 전자상거래 회사가 다양한 클라우드 서비스의 사용 증가로 인해 AWS 비용의 예상치 못한 급증을 경험하고 있습니다. 이 상황을 관리하기 위해 회사는 포괄적인 지출 및 사용 인식 전략을 구현해야 합니다. 솔루션 아키텍트는 회사가 AWS 지출을 효과적으로 모니터링, 분석 및 제어할 수 있는 솔루션을 제안하는 임무를 맡았습니다.",
        "Question": "다음 옵션 중 AWS에서 지출 및 사용 인식 제어를 개발하기 위한 최상의 전략은 무엇입니까?",
        "Options": {
            "1": "AWS Budgets를 구현하여 사용자 정의 비용 및 사용 예산을 설정합니다. AWS CloudTrail을 사용하여 서비스 사용을 기록하고 정기적으로 로그를 검토하여 비정상적인 지출 패턴을 식별합니다.",
            "2": "AWS Trusted Advisor를 활용하여 비용 최적화 및 서비스 사용에 대한 통찰력을 얻습니다. 이를 AWS 인보이스의 수동 추적과 결합하여 포괄적인 뷰를 제공합니다.",
            "3": "AWS Organizations를 활용하여 여러 계정의 청구를 통합합니다. 미리 정의된 보고서와 함께 AWS Cost Explorer를 구현하여 팀 간의 지출에 대한 통찰력을 얻습니다.",
            "4": "Amazon CloudWatch를 배포하여 서비스 사용을 모니터링하고 특정 임계값에 대한 알람을 설정합니다. AWS Cost Explorer를 사용하여 지출 추세를 분석하고 보고서를 생성합니다."
        },
        "Correct Answer": "AWS Budgets를 구현하여 사용자 정의 비용 및 사용 예산을 설정합니다. AWS CloudTrail을 사용하여 서비스 사용을 기록하고 정기적으로 로그를 검토하여 비정상적인 지출 패턴을 식별합니다.",
        "Explanation": "이 옵션은 서비스 사용에 대한 상세한 로깅과 함께 능동적인 예산 관리를 효과적으로 결합하여 회사가 재정적 한계를 설정하고 비정상적인 지출을 조사할 수 있게 해줍니다. 이는 지출 인식을 유지하는 데 중요합니다.",
        "Other Options": [
            "Amazon CloudWatch를 배포하면 사용 모니터링에 도움이 될 수 있지만 예산 관리의 필요성을 직접적으로 해결하지 않으며, 능동적인 비용 통제보다는 반응적인 조치를 초래할 수 있습니다.",
            "AWS Trusted Advisor를 활용하면 비용 최적화에 대한 유용한 통찰력을 제공하지만, 인보이스의 수동 추적에만 의존하는 것은 비효율적이며 비용 문제에 대한 인식이 지연될 수 있습니다.",
            "AWS Organizations를 활용하면 청구 통합에 도움이 될 수 있지만, 예산 전략이나 상세한 사용 모니터링을 포함하지 않으면 지출 인식을 위한 필요한 제어를 제공하지 못할 수 있습니다."
        ]
    },
    {
        "Question Number": "39",
        "Situation": "한 금융 서비스 회사가 단일 가용 영역에서 Amazon EC2 인스턴스에서 중요한 애플리케이션을 실행하고 있습니다. 이 애플리케이션은 기본 인프라의 가용성 부족으로 인해 가끔 중단되고 있습니다. 솔루션 아키텍트는 애플리케이션 성능에 영향을 주지 않으면서 장애 조치를 처리할 수 있는 고가용성 아키텍처를 설계하는 임무를 맡았습니다.",
        "Question": "다음 옵션 중 이 아키텍처의 단일 실패 지점을 가장 잘 해결할 수 있는 솔루션은 무엇입니까?",
        "Options": {
            "1": "여러 가용 영역에 걸쳐 여러 EC2 인스턴스에 애플리케이션을 배포하고 Elastic Load Balancer를 사용하여 트래픽을 분산시킵니다.",
            "2": "장애 발생 시 애플리케이션을 다른 가용 영역에 자동으로 재생성하는 CloudFormation 스택을 설정합니다.",
            "3": "데이터베이스 계층의 장애 조치를 처리하기 위해 다른 가용 영역에 Amazon RDS 읽기 복제본을 생성합니다.",
            "4": "Amazon Route 53을 구현하여 장애 조치 라우팅 정책을 사용하여 다른 지역의 보조 애플리케이션 인스턴스로 트래픽을 유도합니다."
        },
        "Correct Answer": "여러 가용 영역에 걸쳐 여러 EC2 인스턴스에 애플리케이션을 배포하고 Elastic Load Balancer를 사용하여 트래픽을 분산시킵니다.",
        "Explanation": "여러 가용 영역에 걸쳐 여러 EC2 인스턴스에 애플리케이션을 배포하고 Elastic Load Balancer를 사용하면 하나의 가용 영역이 사용할 수 없게 되더라도 트래픽을 다른 가용 영역의 인스턴스로 유도할 수 있어 고가용성을 보장하고 다운타임을 최소화할 수 있습니다.",
        "Other Options": [
            "다른 가용 영역에 Amazon RDS 읽기 복제본을 생성하는 것은 데이터베이스 계층만 해결할 뿐 전체 애플리케이션의 고가용성을 제공하지 않으며, 기본 애플리케이션 인스턴스가 사용할 수 없게 되면 여전히 실패할 수 있습니다.",
            "Amazon Route 53을 구현하여 장애 조치 라우팅 정책을 사용하면 보조 인스턴스로 트래픽을 유도할 수 있지만, 이 접근 방식은 로드 밸런싱을 적극적으로 관리하지 않으며 애플리케이션에 대한 실시간 장애 조치를 제공하지 않아 잠재적인 애플리케이션 다운타임을 초래할 수 있습니다.",
            "CloudFormation 스택을 설정하여 애플리케이션을 다른 가용 영역에 재생성하는 것은 복잡성을 증가시키고 즉각적인 장애 조치 기능을 제공하지 않을 수 있으며, 재생성 과정에서 애플리케이션이 취약해질 수 있습니다."
        ]
    },
    {
        "Question Number": "40",
        "Situation": "한 금융 서비스 회사가 AWS에서 호스팅되는 새로운 다계층 애플리케이션을 설계하고 있습니다. 이 애플리케이션은 민감한 고객 데이터를 처리하며 엄격한 신뢰성 요구 사항을 충족해야 합니다. 아키텍처는 Amazon EC2 기반의 웹 레이어, 로드 밸런서 및 백엔드 Amazon RDS 데이터베이스로 구성됩니다. 회사는 여러 가용 영역에서 애플리케이션의 높은 가용성과 내결함성을 보장하고자 합니다. 또한 잠재적인 데이터 손실을 처리하고 애플리케이션이 중단에서 신속하게 복구할 수 있도록 하는 방법을 고려하고 있습니다. 회사가 구현해야 할 전략은 무엇입니까?",
        "Question": "다음 전략 중 신뢰성 요구 사항을 충족하는 데 도움이 되는 것은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "Elastic Load Balancer와 함께 여러 가용 영역에 Amazon EC2 인스턴스에서 웹 레이어를 배포합니다.",
            "2": "백엔드 데이터베이스에 대해 Amazon RDS Multi-AZ 배포를 사용하여 장애 조치 지원을 보장합니다.",
            "3": "비용과 복잡성을 줄이기 위해 웹 레이어에 단일 EC2 인스턴스를 구현합니다.",
            "4": "RDS 데이터베이스의 백업을 위해 S3를 활용하여 신속한 데이터 복구를 가능하게 합니다.",
            "5": "트래픽 급증을 처리하고 가용성을 보장하기 위해 웹 레이어에 Auto Scaling 그룹을 설정합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Elastic Load Balancer와 함께 여러 가용 영역에 Amazon EC2 인스턴스에서 웹 레이어를 배포합니다.",
            "백엔드 데이터베이스에 대해 Amazon RDS Multi-AZ 배포를 사용하여 장애 조치 지원을 보장합니다."
        ],
        "Explanation": "첫 번째 정답은 웹 레이어가 여러 가용 영역에 분산되어 중복성과 높은 가용성을 제공하도록 보장합니다. 두 번째 정답은 RDS 데이터베이스가 다른 가용 영역의 대기 인스턴스로 자동 장애 조치할 수 있도록 보장하여 최소한의 다운타임과 데이터 손실을 보장합니다.",
        "Other Options": [
            "이 옵션은 중복성이 부족하여 단일 실패 지점을 생성하며, 이는 신뢰성 요구 사항을 충족하지 않습니다.",
            "백업은 중요하지만, 높은 가용성 요구 사항을 충족하는 데 필수적인 즉각적인 장애 조치 기능을 제공하지 않습니다.",
            "이 옵션은 트래픽 관리에 도움이 되지만, 웹 레이어의 가용성을 보장하기 위해 가용 영역 전반에 걸쳐 높은 가용성의 필요성을 해결하지 않습니다."
        ]
    },
    {
        "Question Number": "41",
        "Situation": "한 회사가 온프레미스 데이터를 AWS로 마이그레이션하고 있으며, 마이그레이션 과정에서 데이터 전송 비용을 최적화하고자 합니다. 그들은 Amazon S3로 대량의 데이터를 전송하기 위한 다양한 옵션을 고려하고 있으며, 데이터 전송 수수료와 관련된 비용에 대해 우려하고 있습니다.",
        "Question": "대량의 데이터를 Amazon S3로 마이그레이션할 때 데이터 전송 비용을 최소화하는 데 가장 적합한 전략은 무엇입니까?",
        "Options": {
            "1": "Amazon Direct Connect를 활용하여 S3로 지속적인 데이터 전송을 합니다.",
            "2": "AWS CLI를 사용하여 인터넷을 통해 데이터를 S3에 직접 업로드합니다.",
            "3": "먼저 Amazon EC2로 데이터를 전송한 다음 S3로 복사합니다.",
            "4": "AWS Snowball을 사용하여 데이터를 물리적으로 AWS로 전송합니다."
        },
        "Correct Answer": "AWS Snowball을 사용하여 데이터를 물리적으로 AWS로 전송합니다.",
        "Explanation": "AWS Snowball을 사용하면 대량의 데이터 세트를 AWS로 물리적으로 전송할 수 있어 인터넷을 통해 대량의 데이터를 전송할 때 발생하는 데이터 전송 비용을 최소화합니다. Snowball은 대규모 마이그레이션에 특히 비용 효율적이며, 비싼 대역폭 요금을 피할 수 있습니다.",
        "Other Options": [
            "AWS CLI를 사용하여 인터넷을 통해 데이터를 S3에 직접 업로드하면 특히 대량의 데이터에 대해 상당한 데이터 전송 비용이 발생할 수 있습니다. 이는 공용 인터넷 대역폭에 의존하기 때문입니다.",
            "먼저 Amazon EC2로 데이터를 전송한 다음 S3로 복사하는 것은 데이터 전송 비용을 줄이는 주요 문제를 해결하지 않으며, EC2 인스턴스에서 데이터 전송 시 추가 요금이 발생할 수 있습니다.",
            "Amazon Direct Connect를 활용하면 일관된 대량 데이터 전송에 대한 지속적인 데이터 전송 비용을 줄일 수 있지만, 설정이 비용이 많이 들고 시간이 소요될 수 있어 초기 대량 마이그레이션에는 덜 이상적입니다."
        ]
    },
    {
        "Question Number": "42",
        "Situation": "한 금융 서비스 회사가 고빈도 거래 애플리케이션을 위한 캐싱 레이어를 설계하고 있습니다. 그들은 대량의 데이터 세트를 효율적으로 처리할 수 있는 캐싱 솔루션과 수요 변동에 따라 신속하게 확장할 수 있는 솔루션을 요구합니다. 팀은 또한 암호화나 데이터 지속성과 같은 복잡성이 없는 간단한 아키텍처를 선호합니다. 이러한 요구 사항을 고려할 때 솔루션 아키텍트는 적절한 캐싱 솔루션을 선택해야 합니다.",
        "Question": "회사의 요구 사항을 충족하기 위해 솔루션 아키텍트가 선택해야 할 캐싱 솔루션은 무엇입니까?",
        "Options": {
            "1": "Memcached를 선택합니다. Memcached는 간단한 아키텍처를 제공하며 대형 노드에 대한 다중 코어 사용을 지원합니다.",
            "2": "데이터를 지속할 수 있고 암호화를 제공하는 디스크 기반 캐싱 솔루션을 선택합니다.",
            "3": "필요하지 않더라도 Redis의 고급 데이터 구조와 지속성 기능을 사용합니다.",
            "4": "Amazon ElastiCache를 Redis와 함께 구현하고 높은 가용성을 위해 구성합니다."
        },
        "Correct Answer": "Memcached를 선택합니다. Memcached는 간단한 아키텍처를 제공하며 대형 노드에 대한 다중 코어 사용을 지원합니다.",
        "Explanation": "Memcached는 이 시나리오에 이상적인 선택으로, 간단한 캐싱 모델을 제공하고 암호화가 필요하지 않으며, 여러 코어를 효과적으로 활용하여 대형 노드를 처리하는 데 최적의 성능을 발휘합니다. 또한 수요에 따라 확장 및 축소를 지원합니다.",
        "Other Options": [
            "Redis는 강력하지만, 회사의 단순성 요구 사항과 고급 기능의 필요성이 없음을 고려할 때 불필요한 복잡성을 초래합니다.",
            "높은 가용성을 위해 Redis를 구현하는 것은 불필요한 복잡성과 잠재적인 비용을 추가할 수 있으며, 회사는 지속성이나 고급 구성 없이 간단한 솔루션을 찾고 있습니다.",
            "디스크 기반 캐싱 솔루션은 단순성과 신속한 확장 요구 사항에 반하므로 적합하지 않으며, 회사는 데이터 지속성이 필요하지 않다고 명시했습니다."
        ]
    },
    {
        "Question Number": "43",
        "Situation": "한 금융 서비스 회사는 민감한 고객 데이터를 처리하며 데이터 보호와 관련된 엄격한 규제 요구 사항을 준수해야 합니다. 이들은 데이터가 저장된 상태와 전송 중 모두에 대해 암호화를 구현해야 합니다. 회사는 데이터의 전체 생애 주기 동안 기밀성과 무결성을 보장하는 효과적인 솔루션을 찾고 있습니다.",
        "Question": "회사가 데이터가 저장된 상태와 전송 중 요구 사항을 모두 충족하기 위해 어떤 암호화 솔루션을 구현해야 합니까?",
        "Options": {
            "1": "AWS Secrets Manager를 사용하여 민감한 정보를 암호화하고 AWS Direct Connect를 사용하여 온프레미스와 AWS 간의 안전한 데이터 전송을 수행합니다.",
            "2": "AWS Key Management Service (KMS)를 사용하여 Amazon S3 객체에 대한 암호화 키를 생성하고 관리하며, 인터넷을 통해 전송되는 데이터에 대해 SSL/TLS를 활성화합니다.",
            "3": "Amazon S3 서버 측 암호화를 사용자 정의 키 관리 솔루션으로 구성하고 안전한 데이터 전송을 위해 VPN을 설정합니다.",
            "4": "암호화된 스토리지를 사용하는 Amazon RDS를 활용하고 애플리케이션과 데이터베이스 간에 전송되는 데이터에 대해 IAM 인증을 사용하여 암호화된 연결을 활성화합니다."
        },
        "Correct Answer": "AWS Key Management Service (KMS)를 사용하여 Amazon S3 객체에 대한 암호화 키를 생성하고 관리하며, 인터넷을 통해 전송되는 데이터에 대해 SSL/TLS를 활성화합니다.",
        "Explanation": "AWS Key Management Service (KMS)를 사용하면 회사가 암호화 키를 효과적으로 관리하면서 Amazon S3에 저장된 데이터가 암호화되도록 보장할 수 있습니다. 또한 SSL/TLS를 활성화하면 전송 중인 데이터가 암호화되어 데이터 보호에 대한 규제 요구 사항을 충족합니다.",
        "Other Options": [
            "암호화된 스토리지를 사용하는 Amazon RDS는 데이터가 저장된 상태에서 암호화를 제공하지만, IAM 인증은 전송 중인 데이터를 직접 암호화하지 않으며 단순히 접근을 승인하므로 이 옵션은 회사의 요구를 완전히 충족하지 않습니다.",
            "AWS Secrets Manager는 비밀 관리를 위해 설계되었으며, 데이터가 저장된 상태 또는 전송 중인 데이터를 포괄적으로 암호화하는 데 적합하지 않습니다. AWS Direct Connect는 안전하지만 자체적으로 암호화를 제공하지 않으므로 요구 사항을 완전히 충족하지 않습니다.",
            "Amazon S3 서버 측 암호화는 데이터가 저장된 상태에서 보안을 제공할 수 있지만, 사용자 정의 키 관리 솔루션을 사용하는 것은 복잡성을 초래하고 잠재적인 규정 준수 문제를 일으킬 수 있습니다. VPN은 전송 중인 데이터를 보호할 수 있지만 인터넷을 통한 전송 중인 데이터의 암호화를 보장하지 않습니다."
        ]
    },
    {
        "Question Number": "44",
        "Situation": "한 금융 서비스 회사는 AWS Application Migration Service (AWS MGN)를 사용하여 온프레미스 데이터 센터에서 AWS로 애플리케이션을 마이그레이션할 계획입니다. 이 회사는 전환 중 최소한의 다운타임을 요구하는 여러 레거시 애플리케이션을 보유하고 있습니다. 그들은 마이그레이션 프로세스를 자동화하고 수동 마이그레이션과 관련된 오류의 위험을 줄이는 접근 방식을 원한다고 명시했습니다.",
        "Question": "이 시나리오에서 AWS Application Migration Service (AWS MGN)를 최적으로 활용하여 원활한 리프트 앤 시프트 마이그레이션을 보장하고 클라우드에 맞게 애플리케이션을 최적화하기 위해 어떤 전략이 가장 적합합니까?",
        "Options": {
            "1": "회사는 AWS MGN을 사용하기 전에 애플리케이션을 클라우드 네이티브로 리팩토링해야 하며, 이는 보다 원활한 마이그레이션과 AWS 환경에서의 더 나은 최적화를 가능하게 합니다.",
            "2": "회사는 AWS MGN의 에이전트 없는 스냅샷 접근 방식을 사용하여 각 서버의 일회성 스냅샷을 생성한 후, 애플리케이션을 AWS로 수동 전송하여 빠른 리프트 앤 시프트 마이그레이션을 허용해야 합니다.",
            "3": "회사는 각 소스 서버에 AWS MGN 에이전트를 설치하여 데이터를 지속적으로 복제해야 하며, 이는 전환 중 최소한의 다운타임을 허용하고 애플리케이션이 원래 상태로 마이그레이션되도록 보장합니다.",
            "4": "회사는 온프레미스 서버와 AWS 환경을 함께 실행하여 애플리케이션이 최종 전환 전에 동기화되도록 보장하는 AWS MGN의 하이브리드 마이그레이션 접근 방식을 활용해야 합니다."
        },
        "Correct Answer": "회사는 각 소스 서버에 AWS MGN 에이전트를 설치하여 데이터를 지속적으로 복제해야 하며, 이는 전환 중 최소한의 다운타임을 허용하고 애플리케이션이 원래 상태로 마이그레이션되도록 보장합니다.",
        "Explanation": "각 소스 서버에 AWS MGN 에이전트를 사용하면 데이터의 지속적인 복제가 가능해져 다운타임을 줄이고 수동 마이그레이션 프로세스와 관련된 위험을 최소화할 수 있습니다. 이는 애플리케이션이 원래 상태로 마이그레이션될 수 있도록 보장하며, 마이그레이션 중 비즈니스 연속성을 유지하는 데 도움이 됩니다.",
        "Other Options": [
            "에이전트 없는 스냅샷 접근 방식은 일회성 스냅샷만 생성하므로 진행 중인 변경 사항을 포착하지 못하고 마이그레이션 과정에서 데이터 손실이나 불일치를 초래할 수 있습니다.",
            "AWS MGN을 사용하기 전에 애플리케이션을 리팩토링하는 것은 리프트 앤 시프트 마이그레이션에 필요하지 않습니다. AWS MGN은 애플리케이션 자체에 대한 변경 없이 마이그레이션을 용이하게 하기 위해 특별히 설계되었습니다.",
            "하이브리드 마이그레이션 접근 방식을 활용하면 마이그레이션 프로세스가 복잡해지고 두 환경이 동시에 실행되는 기간이 길어져 리프트 앤 시프트 마이그레이션 중 다운타임을 최소화하는 데 이상적이지 않습니다."
        ]
    },
    {
        "Question Number": "45",
        "Situation": "한 조직은 여러 가용 영역에 걸쳐 EC2 인스턴스에서 실행되는 다양한 애플리케이션이 Amazon S3 버킷에 간헐적인 연결 문제를 겪고 있습니다. 애플리케이션은 가상 사설 클라우드(VPC)에 배포되어 있으며 S3 버킷에 직접 접근하기 위해 VPC 엔드포인트를 사용하고 있습니다. 조직은 연결 문제의 근본 원인을 파악하고자 합니다.",
        "Question": "조직이 AWS 도구를 사용하여 S3 버킷에 대한 연결 문제를 해결하는 데 도움이 되는 접근 방식은 무엇입니까?",
        "Options": {
            "1": "AWS Trusted Advisor를 활용하여 S3 버킷 구성을 분석하고 잘못 구성된 설정을 식별합니다.",
            "2": "AWS Config 규칙을 실행하여 EC2 인스턴스가 S3 접근을 위한 모범 사례를 준수하는지 확인합니다.",
            "3": "Amazon CloudWatch Logs를 사용하여 S3 접근과 관련된 타임아웃 또는 연결 오류 메시지에 대한 애플리케이션 로그를 확인합니다.",
            "4": "EC2 인스턴스를 호스팅하는 서브넷에 대해 VPC 흐름 로그를 활성화하여 S3 버킷으로의 트래픽 흐름을 모니터링합니다."
        },
        "Correct Answer": "EC2 인스턴스를 호스팅하는 서브넷에 대해 VPC 흐름 로그를 활성화하여 S3 버킷으로의 트래픽 흐름을 모니터링합니다.",
        "Explanation": "VPC 흐름 로그를 활성화하면 조직이 EC2 인스턴스 간의 IP 트래픽에 대한 정보를 캡처할 수 있습니다. 이 데이터는 연결 문제가 네트워크 잘못 구성, 보안 그룹 규칙 또는 S3 버킷으로의 트래픽 흐름에 영향을 미치는 기타 요인으로 인한 것인지 식별하는 데 도움이 될 수 있습니다.",
        "Other Options": [
            "Amazon CloudWatch Logs를 사용하여 애플리케이션 로그를 확인하는 것은 일부 통찰력을 제공할 수 있지만, S3 접근에 직접 영향을 미치는 네트워크 관련 문제에 대한 가시성을 제공하지 않습니다.",
            "AWS Trusted Advisor는 주로 모범 사례 권장 사항을 제공하며 S3 버킷과 같은 특정 리소스의 연결 문제를 직접 진단하지 않을 수 있습니다.",
            "AWS Config 규칙을 실행하면 준수를 보장하지만 연결 문제를 해결하는 데 도움이 되는 실시간 트래픽 분석이나 로그를 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "46",
        "Situation": "금융 서비스 회사는 중요한 데이터가 정기적으로 백업되고 재해 발생 시 신속하게 복구될 수 있도록 해야 합니다. 현재 Amazon S3를 저장소로 사용하고 있지만, 복구 시간 목표(RTO)와 복구 지점 목표(RPO)를 충족하기 위한 최상의 백업 전략에 대해 확신이 없습니다.",
        "Question": "데이터를 보호하고 신속하게 복구할 수 있도록 하면서 비용을 최소화하는 가장 효율적이고 신뢰할 수 있는 백업 전략은 무엇입니까?",
        "Options": {
            "1": "장기 백업 데이터 저장을 위해 Amazon Glacier를 활용하고 필요에 따라 온디맨드로 복구합니다.",
            "2": "매일 밤 S3에서 온프레미스 서버로 데이터를 복사하는 수동 백업 프로세스를 생성합니다.",
            "3": "Amazon S3의 백업 일정 및 보존 정책을 자동화하기 위해 AWS Backup을 구현합니다.",
            "4": "S3 버킷에 대한 교차 지역 복제를 설정하여 데이터 가용성과 중복성을 보장합니다."
        },
        "Correct Answer": "Amazon S3의 백업 일정 및 보존 정책을 자동화하기 위해 AWS Backup을 구현합니다.",
        "Explanation": "AWS Backup은 AWS 서비스 전반에 걸쳐 백업을 중앙에서 관리하도록 설계되어 자동화된 백업 일정 및 보존 정책을 제공합니다. 이를 통해 백업이 RTO 및 RPO 요구 사항을 효과적으로 충족하면서 수동 프로세스와 관련된 운영 오버헤드 및 비용을 최소화할 수 있습니다.",
        "Other Options": [
            "수동 백업 프로세스는 인적 오류의 위험을 초래하고, 노동 집약적이며, 적시에 백업을 보장하지 못할 수 있어 RTO 및 RPO 요구 사항을 위반할 수 있습니다.",
            "Amazon Glacier를 사용하는 것은 장기 저장에 적합하지만 신속한 복구를 위해 최적화되어 있지 않아 중요한 데이터의 복구에 있어 용납할 수 없는 지연을 초래할 수 있습니다.",
            "교차 지역 복제는 데이터 가용성과 내구성에 효과적이지만, RTO 및 RPO 목표를 충족하는 데 필수적인 백업 일정이나 보존 정책을 구체적으로 다루지 않습니다."
        ]
    },
    {
        "Question Number": "47",
        "Situation": "글로벌 전자상거래 회사는 엄격한 가동 시간 요구 사항을 충족하면서 변동하는 사용자 수요를 수용해야 하는 고가용성 웹 애플리케이션을 설계하고 있습니다. 이 애플리케이션은 AWS에 호스팅되며 지역 및 가용성 영역의 장애에 대해 복원력이 있어야 합니다. 회사는 트래픽 패턴에 따라 리소스를 자동으로 확장할 수 있는 아키텍처가 필요합니다.",
        "Question": "회사가 애플리케이션의 고가용성과 확장성을 달성하기 위해 구현해야 할 설계 전략의 조합은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "Elastic Load Balancing을 사용하여 단일 가용성 영역의 인스턴스 간에 트래픽을 분산시키기 위해 상태 검사를 수행합니다.",
            "2": "AWS Global Accelerator를 활용하여 애플리케이션의 글로벌 가용성과 성능을 개선합니다.",
            "3": "정적 콘텐츠를 캐시하기 위해 Amazon CloudFront를 콘텐츠 전송 네트워크(CDN)로 구현합니다.",
            "4": "여러 가용성 영역에 걸쳐 여러 EC2 인스턴스를 사용하는 Auto Scaling 그룹을 활용합니다.",
            "5": "여러 AWS 리전에서 애플리케이션을 배포하고 Amazon Route 53을 사용하여 DNS 장애 조치를 수행합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "여러 가용성 영역에 걸쳐 여러 EC2 인스턴스를 사용하는 Auto Scaling 그룹을 활용합니다.",
            "여러 AWS 리전에서 애플리케이션을 배포하고 Amazon Route 53을 사용하여 DNS 장애 조치를 수행합니다."
        ],
        "Explanation": "여러 가용성 영역에 걸쳐 Auto Scaling 그룹을 활용하면 수요에 따라 애플리케이션이 자동으로 확장되면서 고가용성을 유지할 수 있습니다. Route 53을 사용하여 여러 AWS 리전에서 배포하면 지역 장애에 대한 추가적인 복원력을 제공하여 강력한 아키텍처에 기여합니다.",
        "Other Options": [
            "Amazon CloudFront를 구현하는 것은 성능에 유익하지만 애플리케이션의 백엔드 서비스에 대한 고가용성 및 확장성 요구 사항을 직접적으로 해결하지 않습니다.",
            "단일 가용성 영역 내에서 Elastic Load Balancing을 사용하는 것은 필요한 중복성을 제공하지 않으며, 해당 영역이 실패하면 애플리케이션이 사용할 수 없게 됩니다.",
            "AWS Global Accelerator는 성능과 가용성을 향상시킬 수 있지만, 여러 리전이나 영역에 추가 서비스를 배포하지 않으면 본질적으로 고가용성 아키텍처를 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "48",
        "Situation": "회사는 보안을 강화하고 리소스에 대한 접근을 제어하기 위해 AWS 환경을 설계하고 있습니다. 이 환경은 서로 다른 애플리케이션을 호스팅하는 여러 VPC로 구성되어 있습니다. 회사는 특정 VPC 간의 연결성을 허용하면서 워크로드를 격리하기 위해 네트워크 세분화를 효과적으로 구현하고자 합니다.",
        "Question": "VPC 간의 제어된 통신을 가능하게 하면서 가장 좋은 네트워크 세분화를 제공하는 접근 방식은 무엇입니까?",
        "Options": {
            "1": "모든 애플리케이션을 단일 VPC에 배포하고 애플리케이션 요구 사항에 따라 트래픽을 세분화하기 위해 네트워크 ACL을 활용합니다.",
            "2": "여러 VPC를 연결하면서 트래픽 흐름에 대한 격리 및 제어를 유지하기 위해 AWS Transit Gateway를 구현합니다.",
            "3": "각 애플리케이션에 대해 별도의 VPC를 생성하고 특정 트래픽을 허용하기 위해 VPC 피어링 연결을 설정합니다.",
            "4": "모든 애플리케이션에 대해 여러 서브넷을 사용하는 단일 VPC를 사용하고, 이들 간의 트래픽을 제어하기 위해 보안 그룹을 구성합니다."
        },
        "Correct Answer": "여러 VPC를 연결하면서 트래픽 흐름에 대한 격리 및 제어를 유지하기 위해 AWS Transit Gateway를 구현합니다.",
        "Explanation": "AWS Transit Gateway를 사용하면 여러 VPC 간의 중앙 집중식 연결이 가능하여 각 VPC의 격리를 유지하면서 제어된 통신을 가능하게 합니다. 이 접근 방식은 관리가 간소화되고 직접 VPC 피어링에 비해 더 나은 확장성을 제공합니다.",
        "Other Options": [
            "여러 서브넷을 사용하는 단일 VPC를 사용하는 것은 애플리케이션 간의 격리가 부족하여 의도하지 않은 접근의 위험을 증가시키고 보안 관리가 복잡해집니다.",
            "VPC 피어링을 통해 별도의 VPC를 생성하는 것은 좋은 접근 방식이지만, VPC 수가 증가함에 따라 복잡한 구성이 발생할 수 있으며 Transit Gateway만큼 효율적으로 확장되지 않습니다.",
            "모든 애플리케이션을 단일 VPC에 배포하고 네트워크 ACL을 사용하는 것은 적절한 격리를 제공하지 않으며, 트래픽 제어가 지나치게 복잡해짐에 따라 관리 문제를 초래할 수 있습니다."
        ]
    },
    {
        "Question Number": "49",
        "Situation": "다국적 기업이 AWS Direct Connect를 활용하여 온프레미스 데이터 센터에서 AWS VPC로 전용 네트워크 연결을 설정하고 있습니다. 이들은 여러 지역에서 실행되는 애플리케이션에 대해 높은 처리량과 낮은 대기 시간이 필요합니다. 이 기업은 EC2 및 S3와 같은 다양한 AWS 서비스에 연결할 계획이며, 전송 중인 데이터가 암호화되도록 보안 요구 사항도 가지고 있습니다. 이러한 아키텍처 요구 사항에 따라 Direct Connect 연결 및 가상 인터페이스 설정 옵션을 평가하고 있습니다.",
        "Question": "Direct Connect를 사용하여 AWS 서비스에 대한 높은 처리량, 낮은 대기 시간 및 안전한 연결 요구 사항을 가장 잘 충족하는 구성은 무엇입니까?",
        "Options": {
            "1": "하나의 공용 지역에 Direct Connect 게이트웨이를 설정합니다. S3 및 EC2와 같은 서비스에 접근하기 위해 여러 개의 공용 가상 인터페이스를 설정하되, 트래픽을 암호화하지 않는 VPN을 생성하지 않습니다.",
            "2": "여러 VPC에 연결하기 위해 개인 가상 인터페이스가 있는 단일 Direct Connect 연결을 설정합니다. 라우팅을 위해 AWS Transit Gateway를 사용하고 추가 암호화를 구현하지 않고 AWS Shield에 의존합니다.",
            "3": "같은 위치에 두 개의 Direct Connect 연결을 배포하고 각각 공용 가상 인터페이스를 사용합니다. 이러한 연결은 S3 및 EC2와 같은 AWS 서비스에 접근하는 데만 사용되며 추가 보안 조치를 취하지 않습니다.",
            "4": "서로 다른 위치에 두 개의 Direct Connect 연결을 생성합니다. 개인 가상 인터페이스를 사용하여 Direct Connect 게이트웨이에 연결하고, S3 및 EC2에 대한 안전한 접근을 위해 공용 가상 인터페이스 위에 VPN 연결을 구현합니다."
        },
        "Correct Answer": "서로 다른 위치에 두 개의 Direct Connect 연결을 생성합니다. 개인 가상 인터페이스를 사용하여 Direct Connect 게이트웨이에 연결하고, S3 및 EC2에 대한 안전한 접근을 위해 공용 가상 인터페이스 위에 VPN 연결을 구현합니다.",
        "Explanation": "이 옵션은 두 개의 Direct Connect 연결을 활용하여 높은 가용성과 낮은 대기 시간을 보장하고, Direct Connect 게이트웨이를 통해 여러 VPC에 연결하며, 공용 인터페이스 위의 VPN 연결을 통해 전송 중인 데이터가 암호화되도록 보장하여 모든 요구 사항을 충족합니다.",
        "Other Options": [
            "이 옵션은 단일 Direct Connect 연결만 제공하므로 높은 가용성을 보장하지 않으며 단일 실패 지점으로 이어질 수 있습니다. 개인 가상 인터페이스를 사용하는 것은 적절하지만, 암호화 없이 AWS Transit Gateway에만 의존하는 것은 보안 요구 사항을 충족하지 않습니다.",
            "이 옵션은 VPN 없이 공용 가상 인터페이스를 사용하므로 암호화 요구 사항을 충족하지 않습니다. 또한, 하나의 지역에 있는 하나의 Direct Connect 게이트웨이에 제한되어 있어 강력한 아키텍처에 필요한 높은 가용성을 제공하지 않습니다.",
            "같은 위치에 두 개의 Direct Connect 연결을 사용하는 것은 서로 다른 지리적 영역에서의 중복성을 제공하지 않으므로 높은 가용성에 필수적입니다. 또한, 암호화 없이 공용 가상 인터페이스에만 의존하는 것은 데이터 보안을 저해합니다."
        ]
    },
    {
        "Question Number": "50",
        "Situation": "소매 회사가 세일 이벤트 동안 높은 트래픽을 경험하고 고객 상호작용을 위한 다양한 접근 패턴이 필요한 새로운 전자상거래 플랫폼을 출시할 계획입니다. 이 플랫폼은 제품 탐색을 위한 읽기 중심 작업과 주문 처리를 위한 쓰기 중심 작업을 모두 지원해야 합니다. 확장성, 비용 효율성 및 성능을 고려하여 적절한 아키텍처를 설계해야 합니다.",
        "Question": "전자상거래 플랫폼의 다양한 접근 패턴과 높은 확장성 요구 사항을 가장 잘 지원하는 아키텍처 설계는 무엇입니까?",
        "Options": {
            "1": "EC2 인스턴스에 전통적인 SQL 데이터베이스를 설정하고 피크 시간 동안 수동으로 리소스를 확장합니다.",
            "2": "모든 데이터베이스 작업에 Amazon RDS를 활용하고 높은 읽기 트래픽을 처리하기 위해 읽기 복제본을 배포합니다.",
            "3": "여러 인스턴스에서 읽기 및 쓰기 작업을 고르게 지원하기 위해 다중 마스터 구성의 Amazon Aurora를 사용합니다.",
            "4": "변동하는 작업 부하를 처리하기 위해 온디맨드 용량 모드로 Amazon DynamoDB를 구현하고 정적 자산을 위한 별도의 Amazon S3 버킷을 사용합니다."
        },
        "Correct Answer": "변동하는 작업 부하를 처리하기 위해 온디맨드 용량 모드로 Amazon DynamoDB를 구현하고 정적 자산을 위한 별도의 Amazon S3 버킷을 사용합니다.",
        "Explanation": "온디맨드 용량 모드의 Amazon DynamoDB는 트래픽에 따라 처리량을 자동으로 조정하여 전자상거래 플랫폼의 전형적인 변동 작업 부하에 이상적입니다. 또한, 정적 자산을 위해 Amazon S3를 사용하면 이미지 및 파일의 전달을 분산시켜 성능을 개선하고 데이터베이스의 부하를 줄입니다.",
        "Other Options": [
            "읽기 복제본이 있는 Amazon RDS는 읽기 중심 작업을 처리할 수 있지만, 갑작스러운 트래픽 급증 시 효과적으로 확장되지 않을 수 있습니다. 또한, 쓰기 작업을 확장하기 위해 수동 개입이 필요하여 성능 병목 현상이 발생할 수 있습니다.",
            "다중 마스터 구성의 Amazon Aurora는 높은 가용성을 제공하지만, 특히 새로운 전자상거래 플랫폼의 경우 관리가 복잡하고 비용이 많이 들 수 있습니다. 다양한 접근 패턴에 대한 요구 사항을 고려할 때 이 옵션은 필요하지 않을 수 있습니다.",
            "EC2 인스턴스에 전통적인 SQL 데이터베이스를 사용하는 것은 현대 클라우드 네이티브 아키텍처가 제공하는 확장성과 자동 관리 기능이 부족합니다. 확장을 위해 상당한 수동 노력이 필요하며 높은 트래픽을 효율적으로 처리하지 못할 수 있습니다."
        ]
    },
    {
        "Question Number": "51",
        "Situation": "한 회사가 AWS Lambda 함수를 사용하여 서버리스 애플리케이션을 배포했으며, 이 함수는 개인 VPC 내의 리소스에 접근해야 합니다. 트래픽이 급증함에 따라 애플리케이션은 EC2ThrottledException과 같은 호출 오류가 증가하고 있습니다. 솔루션 아키텍트는 Lambda 함수가 한계에 도달하지 않고 효과적으로 확장될 수 있도록 해야 합니다.",
        "Question": "솔루션 아키텍트는 Lambda 함수의 확장성을 유지하면서 호출 오류를 해결하기 위해 무엇을 해야 합니까?",
        "Options": {
            "1": "Lambda 함수를 VPC 외부로 이동하여 확장성을 개선합니다.",
            "2": "Lambda 함수를 수용하기 위해 더 큰 VPC를 만들고 더 많은 서브넷을 설정합니다.",
            "3": "사용 가능한 ENI 수를 늘리고 서브넷에 충분한 IP 주소가 있는지 확인합니다.",
            "4": "여러 Lambda 함수를 사용하여 서로 다른 VPC에 부하를 분산시킵니다."
        },
        "Correct Answer": "사용 가능한 ENI 수를 늘리고 서브넷에 충분한 IP 주소가 있는지 확인합니다.",
        "Explanation": "사용 가능한 Elastic Network Interface(ENI) 수를 늘리고 서브넷에 충분한 IP 주소가 있도록 함으로써 Lambda 함수는 VPC 내에서 효과적으로 확장할 수 있어 스로틀링과 관련된 호출 오류를 줄일 수 있습니다.",
        "Other Options": [
            "Lambda 함수를 VPC 외부로 이동하면 애플리케이션의 작동에 필수적인 개인 VPC 리소스에 접근할 수 있는 능력이 손상됩니다.",
            "서로 다른 VPC에 여러 Lambda 함수를 사용하는 것은 아키텍처를 복잡하게 만들고 ENI 제한 문제를 해결하지 않으면서 추가 지연 및 관리 오버헤드를 초래할 수 있습니다.",
            "더 큰 VPC를 만들고 더 많은 서브넷을 설정하는 것은 기존 서브넷 내에서 ENI 또는 IP 주소 부족 문제를 직접 해결하지 않으며, 실현 가능한 솔루션이 아닐 수 있습니다."
        ]
    },
    {
        "Question Number": "52",
        "Situation": "한 회사가 AWS 비용을 최적화하면서 지출 패턴에 대한 가시성을 확보하려고 합니다. 재무 팀은 잠재적인 과다 지출을 식별하고 향후 예산을 준수하도록 하는 임무를 맡았습니다. 그들은 추가 비용을 발생시키지 않으면서 사용량과 비용을 효과적으로 모니터링할 수 있는 AWS 도구를 사용하고 싶어합니다.",
        "Question": "재무 팀이 지출 패턴에 대한 최상의 개요를 제공하고 과다 지출을 식별하며 향후 사용을 위한 예산을 설정할 수 있도록 하는 AWS 도구의 조합은 무엇입니까?",
        "Options": {
            "1": "AWS Cost Explorer를 활용하여 사용량 및 비용 추세를 시각화하고, AWS Budgets를 설정하여 예산 한도에 대한 모니터링 및 알림을 설정합니다.",
            "2": "AWS Budgets를 독점적으로 사용하여 지출 한도를 추적하고, AWS CloudTrail 로그를 사용하여 사용량 분석을 수행합니다.",
            "3": "AWS Trusted Advisor를 구현하여 비용 최적화 권장 사항을 확인하고, AWS Pricing Calculator를 사용하여 향후 프로젝트의 비용을 추정합니다.",
            "4": "AWS Trusted Advisor를 배포하고 AWS Config와 통합하여 비용 관리와 관련된 준수를 지속적으로 모니터링합니다."
        },
        "Correct Answer": "AWS Cost Explorer를 활용하여 사용량 및 비용 추세를 시각화하고, AWS Budgets를 설정하여 예산 한도에 대한 모니터링 및 알림을 설정합니다.",
        "Explanation": "AWS Cost Explorer와 AWS Budgets의 조합은 비용 모니터링 및 관리에 대한 포괄적인 솔루션을 제공합니다. Cost Explorer는 지출 패턴의 시각적 분석을 가능하게 하고, Budgets는 미리 정의된 한도에 대한 지출을 능동적으로 추적하여 재무 팀이 과다 지출을 조기에 식별할 수 있도록 합니다.",
        "Other Options": [
            "AWS Trusted Advisor는 비용 최적화에 대한 유용한 권장 사항을 제공하지만, AWS Cost Explorer와 같은 수준의 상세한 역사적 분석을 제공하지 않습니다. AWS Pricing Calculator는 비용 추정에 유용하지만, 지속적인 비용 모니터링에는 효과적이지 않습니다.",
            "AWS Budgets만 사용하는 것은 지출 추세에 대한 가시성을 제공하지 않습니다. AWS CloudTrail 로그는 API 호출을 추적하지만, 비용이나 사용량에 대한 고수준의 뷰를 제공하지 않아 예산 준수 및 과다 지출 식별에 덜 효과적입니다.",
            "AWS Trusted Advisor는 통찰력을 제공하지만, 비용 관리 준수에 대한 지속적인 모니터링을 제공하지 않습니다. AWS Config는 비용 관리보다는 리소스 구성 준수에 중점을 두어 이 조합이 재무 팀의 목표에 덜 효과적입니다."
        ]
    },
    {
        "Question Number": "53",
        "Situation": "한 금융 서비스 회사가 AWS Lambda, Kinesis Data Streams 및 Amazon DynamoDB를 사용하여 실시간 거래 처리 시스템을 구축하고 있습니다. 이 시스템은 초당 높은 거래량을 처리할 것으로 예상되며, 효율적인 데이터 처리와 최소한의 지연이 필요합니다. 개발자들은 Lambda 함수의 배치 동작을 최적화하여 레코드를 신속하게 처리하면서도 처리량을 극대화하고자 합니다. 그들은 Kinesis 이벤트 소스 매핑의 MaximumBatchingWindowInSeconds 및 BatchSize 매개변수 구성에 특히 신경 쓰고 있습니다.",
        "Question": "이 시나리오에서 Kinesis 데이터 스트림의 Lambda 처리를 위한 배치 동작을 최적화하는 가장 좋은 구성은 무엇입니까?",
        "Options": {
            "1": "MaximumBatchingWindowInSeconds를 0초로 설정하고 BatchSize를 1000 레코드로 설정하여 최소한의 지연과 최대 처리량을 보장합니다.",
            "2": "MaximumBatchingWindowInSeconds를 500밀리초로 설정하고 BatchSize를 500 레코드로 설정하여 지연과 처리량의 균형을 맞춥니다.",
            "3": "MaximumBatchingWindowInSeconds를 300초로 설정하고 BatchSize를 300 레코드로 설정하여 배치 창을 극대화합니다.",
            "4": "MaximumBatchingWindowInSeconds를 100밀리초로 설정하고 BatchSize를 10 레코드로 설정하여 처리 시간을 줄입니다."
        },
        "Correct Answer": "MaximumBatchingWindowInSeconds를 0초로 설정하고 BatchSize를 1000 레코드로 설정하여 최소한의 지연과 최대 처리량을 보장합니다.",
        "Explanation": "MaximumBatchingWindowInSeconds를 0초로 설정하면 Lambda가 레코드를 즉시 처리할 수 있어 실시간 거래 처리에 매우 중요합니다. BatchSize를 1000 레코드로 설정하면 각 호출에서 더 많은 레코드를 처리할 수 있어 처리량을 극대화합니다. 이 구성은 거래 처리와 같은 고용량 시나리오에 최적입니다.",
        "Other Options": [
            "MaximumBatchingWindowInSeconds를 500밀리초로 설정하고 BatchSize를 500 레코드로 설정하면 불필요한 지연이 발생할 수 있습니다. 함수가 처리하기 전에 반초를 기다리게 되어 들어오는 레코드의 처리가 지연될 수 있습니다.",
            "MaximumBatchingWindowInSeconds를 300초로 설정하는 것은 실시간 처리에는 과도하며, 레코드 처리를 상당히 지연시킵니다. BatchSize를 300 레코드로 설정하면 고용량 시나리오에서 Kinesis 스트림의 처리량 기능을 충분히 활용하지 못할 수 있습니다.",
            "MaximumBatchingWindowInSeconds를 100밀리초로 설정하고 BatchSize를 10 레코드로 설정하면 Kinesis의 가용 처리량을 활용하지 못합니다. 이 구성은 자원의 활용도를 저하시켜 지연을 증가시킬 가능성이 높습니다."
        ]
    },
    {
        "Question Number": "54",
        "Situation": "모바일 애플리케이션이 AWS에 배포된 다양한 마이크로서비스에서 데이터를 가져올 때 지연 문제를 겪고 있습니다. 이 애플리케이션은 API 요청 및 응답을 관리하기 위해 AWS API Gateway를 활용하고 있습니다. 현재 API Gateway 설정은 백엔드 처리를 위해 Lambda 함수를 사용하고 있지만, 사용자들은 느린 응답 시간을 보고하고 있습니다. 이 아키텍처는 다양한 네트워크 조건을 가진 글로벌 사용자 기반을 처리하도록 설계되었으며, 개발 팀은 보안을 저해하거나 비용을 크게 증가시키지 않으면서 성능을 최적화하고자 합니다.",
        "Question": "이 모바일 애플리케이션의 API Gateway 설정 성능을 개선하는 가장 효과적인 방법은 무엇입니까?",
        "Options": {
            "1": "API Gateway 앞에 전용 Elastic Load Balancer (ELB)를 배포하여 들어오는 요청을 마이크로서비스 간에 보다 고르게 분산시켜 응답 시간을 개선합니다.",
            "2": "API Gateway의 내장 캐싱 기능을 사용하여 모바일 애플리케이션에서 자주 접근하는 데이터를 저장하여 Lambda 호출을 최소화하고 전체 지연을 줄입니다.",
            "3": "API Gateway 앞에 CloudFront를 구현하여 응답을 캐시하고 글로벌 사용자에 대한 지연을 줄이며, 동적 콘텐츠에 대해 사용자 정의 캐시 제어 헤더를 사용합니다.",
            "4": "API Gateway의 타임아웃 설정을 늘려 요청 처리 시간을 길게 하여 모든 응답이 반환되도록 합니다."
        },
        "Correct Answer": "API Gateway 앞에 CloudFront를 구현하여 응답을 캐시하고 글로벌 사용자에 대한 지연을 줄이며, 동적 콘텐츠에 대해 사용자 정의 캐시 제어 헤더를 사용합니다.",
        "Explanation": "API Gateway 앞에 CloudFront를 구현하면 응답을 캐시할 수 있어 다양한 지역의 사용자에 대한 지연을 크게 줄일 수 있습니다. 이는 글로벌 사용자 기반에 특히 유리하며, 엣지 위치를 활용하여 백엔드 서비스를 반복적으로 호출하지 않고도 콘텐츠를 신속하게 제공하여 성능을 효과적으로 최적화합니다.",
        "Other Options": [
            "API Gateway의 타임아웃 설정을 늘리는 것은 지연의 근본 원인을 해결하지 않으며, 사용자에게 더 긴 대기 시간을 초래할 수 있지만 더 빠른 응답을 보장하지 않습니다.",
            "API Gateway 앞에 전용 Elastic Load Balancer (ELB)를 배포하는 것은 불필요하며, API Gateway는 이미 요청을 효율적으로 처리하도록 설계되어 있어 추가적인 복잡성과 비용을 초래할 수 있습니다.",
            "API Gateway의 내장 캐싱 기능을 사용하는 것은 유용하지만, 특히 동적 콘텐츠에 대해 복잡한 캐싱 전략이 필요한 글로벌 사용자 기반에 대해 CloudFront를 활용하는 것만큼 효과적이지 않을 수 있습니다."
        ]
    },
    {
        "Question Number": "55",
        "Situation": "한 금융 서비스 회사가 AWS Direct Connect를 사용하여 여러 지역의 여러 AWS VPC에 온프레미스 데이터 센터를 연결하려고 합니다. 그들은 다양한 계정의 여러 VPC로 트래픽을 라우팅하는 유연성을 유지하면서 개인 연결을 허용하는 솔루션이 필요합니다. 아키텍트는 솔루션이 AWS Direct Connect 및 VPC 연결에 대한 모범 사례를 준수하는지 확인해야 합니다.",
        "Question": "다음 구성 중 솔루션 아키텍트가 회사의 요구 사항을 충족하기 위해 구현해야 할 것은 무엇입니까?",
        "Options": {
            "1": "Direct Connect 연결과 Direct Connect 게이트웨이를 생성합니다. 게이트웨이를 다른 계정 및 지역의 VPC의 가상 프라이빗 게이트웨이에 연결합니다. 각 VPC에 대해 Direct Connect 게이트웨이에 개인 가상 인터페이스를 생성합니다.",
            "2": "AWS 서비스에 접근하기 위해 공용 가상 인터페이스가 있는 Direct Connect 연결을 생성합니다. VPC 간의 통신을 가능하게 하기 위해 VPC 피어링을 구성합니다.",
            "3": "AWS Transit Gateway를 사용하여 중앙 집중식 라우팅 허브를 생성합니다. 온프레미스 데이터 센터를 Direct Connect 연결로 Transit Gateway에 연결하고 여러 계정의 여러 VPC에 대한 VPC 첨부를 설정합니다.",
            "4": "Direct Connect 게이트웨이를 사용하지 않고 각 VPC에 대해 개인 가상 인터페이스를 직접 생성하여 Direct Connect 연결을 설정하여 직접 라우팅을 허용합니다."
        },
        "Correct Answer": "Direct Connect 연결과 Direct Connect 게이트웨이를 생성합니다. 게이트웨이를 다른 계정 및 지역의 VPC의 가상 프라이빗 게이트웨이에 연결합니다. 각 VPC에 대해 Direct Connect 게이트웨이에 개인 가상 인터페이스를 생성합니다.",
        "Explanation": "Direct Connect 게이트웨이를 사용하면 다양한 계정 및 지역의 여러 VPC에 대한 개인 연결이 가능하며, Direct Connect에 대한 모범 사례를 준수합니다. 각 VPC에 맞춤화된 개인 가상 인터페이스를 생성할 수 있어 안전하고 효율적인 라우팅을 보장합니다.",
        "Other Options": [
            "이 옵션은 공용 가상 인터페이스를 사용하는 것을 잘못 제안하고 있으며, 이는 다양한 계정 및 지역의 VPC에 대한 개인 연결에 적합하지 않습니다. Direct Connect 게이트웨이는 개인 가상 인터페이스를 위해 특별히 설계되었습니다.",
            "Transit Gateway를 사용하면 라우팅이 간소화되지만, 이 옵션은 다양한 계정의 여러 VPC에 연결하기 위한 개인 가상 인터페이스 요구 사항을 직접적으로 해결하지 않습니다. 개인 연결을 위해서는 여전히 Direct Connect 게이트웨이가 필요합니다.",
            "이 옵션은 Direct Connect 게이트웨이를 사용하지 않으므로 잘못된 것입니다. Direct Connect 게이트웨이는 특히 서로 다른 계정에 있는 여러 VPC에 대한 개인 가상 인터페이스를 생성하는 데 필요합니다."
        ]
    },
    {
        "Question Number": "56",
        "Situation": "한 회사가 보안 및 규정 준수를 보장하기 위해 정기적인 업데이트 및 패치가 필요한 다계층 애플리케이션을 AWS에 배포하고 있습니다. 이 애플리케이션은 Auto Scaling 그룹에 의해 관리되는 Amazon EC2 인스턴스의 집합에서 실행됩니다. 이 회사는 다운타임을 최소화하고 업데이트 중에 애플리케이션이 계속 사용 가능하도록 하면서 인스턴스의 패치를 자동화하는 강력한 프로세스를 찾고 있습니다.",
        "Question": "솔루션 아키텍트가 효과적인 패치 및 업데이트 프로세스를 설계하기 위해 구현해야 할 옵션은 무엇입니까? (두 개 선택)",
        "Options": {
            "1": "AWS Elastic Beanstalk를 활용하여 애플리케이션 환경을 관리하고 배포 프로세스의 일환으로 패치를 적용합니다.",
            "2": "AWS OpsWorks Stacks를 사용하여 EC2 인스턴스의 패치 및 업데이트를 처리하는 사용자 정의 Chef 레시피를 정의합니다.",
            "3": "AWS Systems Manager Patch Manager를 활용하여 지정된 유지 관리 창 동안 EC2 인스턴스의 패치를 자동화합니다.",
            "4": "모든 EC2 인스턴스에서 동시에 패치 프로세스를 실행하는 Lambda 함수를 트리거하는 Amazon CloudWatch 경고를 생성합니다.",
            "5": "패치 단계 동안 인스턴스 종료 프로세스를 일시 중지하기 위해 Auto Scaling 생명 주기 훅을 구현하여 인스턴스가 손실되지 않도록 합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "AWS Systems Manager Patch Manager를 활용하여 지정된 유지 관리 창 동안 EC2 인스턴스의 패치를 자동화합니다.",
            "AWS Elastic Beanstalk를 활용하여 애플리케이션 환경을 관리하고 배포 프로세스의 일환으로 패치를 적용합니다."
        ],
        "Explanation": "AWS Systems Manager Patch Manager를 사용하면 정의된 유지 관리 창에 따라 패치 프로세스를 자동화할 수 있어 인스턴스가 통제된 방식으로 패치됩니다. 또한 AWS Elastic Beanstalk는 애플리케이션 업데이트 관리를 위한 내장 지원을 제공하여 패치를 배포 프로세스에 원활하게 통합할 수 있어 다운타임을 최소화합니다.",
        "Other Options": [
            "모든 EC2 인스턴스에서 동시에 패치하는 Lambda 함수를 트리거하는 Amazon CloudWatch 경고를 생성하면 잠재적인 다운타임 및 서비스 중단이 발생할 수 있습니다. 이 접근 방식은 패치 프로세스에 대한 제어가 부족하며 업데이트 중 높은 가용성을 보장하지 않을 수 있습니다.",
            "Auto Scaling 생명 주기 훅을 구현하여 인스턴스 종료 프로세스를 일시 중지하는 것은 패치 프로세스를 직접적으로 촉진하지 않습니다. 이는 단순히 인스턴스 종료를 지연시킬 뿐 패치 자체를 자동화하지 않습니다.",
            "AWS OpsWorks Stacks를 사용하여 패치를 위한 사용자 정의 Chef 레시피를 정의하는 것은 실행 가능한 옵션이지만 복잡성을 도입하고 Chef 레시피의 지속적인 유지 관리가 필요합니다. Patch Manager를 사용하는 것에 비해 가장 효율적이거나 간단한 접근 방식이 아닐 수 있습니다."
        ]
    },
    {
        "Question Number": "57",
        "Situation": "한 전자상거래 플랫폼이 확장성과 낮은 대기 시간 성능으로 인해 사용자 세션 데이터를 저장하기 위해 Amazon DynamoDB를 사용하려고 계획하고 있습니다. 솔루션 아키텍트는 세일 이벤트 중 갑작스러운 트래픽 급증을 처리할 수 있는 아키텍처를 보장하는 임무를 맡고 있습니다. 아키텍트는 이러한 요구 사항을 충족하기 위해 DynamoDB 테이블의 적절한 읽기 및 쓰기 용량 구성을 선택해야 합니다.",
        "Question": "최적의 성능을 보장하면서 정상 운영 중 비용을 최소화하기 위해 솔루션 아키텍트가 구현해야 할 구성은 무엇입니까?",
        "Options": {
            "1": "트래픽 패턴에 따라 조정할 수 있도록 자동 스케일링이 활성화된 프로비저닝 용량을 사용합니다.",
            "2": "트래픽에 따라 수동 개입 없이 자동으로 확장 및 축소할 수 있는 온디맨드 용량 모드를 사용합니다.",
            "3": "DynamoDB 앞에 캐싱 레이어를 사용하여 모든 읽기 요청을 처리하고 낮은 쓰기 용량을 프로비저닝합니다.",
            "4": "항상 피크 부하를 처리할 수 있도록 고정된 높은 읽기 및 쓰기 용량으로 프로비저닝된 용량을 설정합니다."
        },
        "Correct Answer": "트래픽에 따라 수동 개입 없이 자동으로 확장 및 축소할 수 있는 온디맨드 용량 모드를 사용합니다.",
        "Explanation": "온디맨드 용량 모드는 예측할 수 없는 작업 부하를 처리하도록 설계되었으며 실제 트래픽에 따라 자동으로 확장 및 축소됩니다. 이는 갑작스러운 트래픽 급증을 처리하는 데 이상적이며 정상 운영 중 비용 절감이 가능합니다.",
        "Other Options": [
            "자동 스케일링이 활성화된 프로비저닝 용량은 작동할 수 있지만 급증에 신속하게 대응하기 위해 신중한 구성 및 모니터링이 필요하며, 올바르게 설정되지 않으면 제한이 발생할 수 있습니다.",
            "고정된 높은 읽기 및 쓰기 용량으로 프로비저닝된 용량은 낮은 트래픽 기간 동안 불필요한 비용이 발생하며, 실제 사용량에 관계없이 리소스가 예약됩니다.",
            "캐싱 레이어를 사용하면 DynamoDB의 읽기 부하를 줄일 수 있지만 쓰기 용량 문제를 해결하지는 않습니다. 이는 아키텍처를 복잡하게 만들 수 있으며 트래픽 급증을 처리하기 위한 완전한 솔루션을 제공하지 않을 수 있습니다."
        ]
    },
    {
        "Question Number": "58",
        "Situation": "한 의료 기관이 AWS에서 민감한 환자 데이터를 처리하는 여러 애플리케이션을 운영하고 있습니다. 그들은 데이터가 규정을 준수하고 보안 사고가 신속하게 해결되도록 해야 합니다. 이 기관은 여러 IAM 역할이 과도한 권한을 가지고 있음을 확인했으며, 서비스 중단 없이 이 문제를 해결할 수 있는 솔루션을 구현하고자 합니다.",
        "Question": "솔루션 아키텍트가 애플리케이션에 미치는 영향을 최소화하면서 과도한 IAM 권한을 해결하기 위해 어떤 수정 기술을 구현해야 합니까?",
        "Options": {
            "1": "AWS CloudTrail을 구현하여 모든 IAM 작업을 기록한 다음, 권한 변경을 하기 전에 로그를 검토하여 중단이 발생하지 않도록 합니다.",
            "2": "IAM 권한을 매 6개월마다 검토하여 즉각적인 변경 없이 과도한 권한을 식별하고 줄입니다.",
            "3": "최소 권한을 가진 새로운 IAM 역할을 생성하고, 이러한 역할을 사용하도록 애플리케이션을 점진적으로 전환하면서 접근 문제를 모니터링합니다.",
            "4": "기존 IAM 역할에서 모든 과도한 권한을 즉시 제거하여 어떤 역할도 필요 이상의 권한을 가지지 않도록 합니다."
        },
        "Correct Answer": "최소 권한을 가진 새로운 IAM 역할을 생성하고, 이러한 역할을 사용하도록 애플리케이션을 점진적으로 전환하면서 접근 문제를 모니터링합니다.",
        "Explanation": "최소 권한을 가진 새로운 IAM 역할을 생성하면 기관이 서비스 연속성을 유지하면서 과도한 권한의 위험을 줄일 수 있습니다. 점진적인 전환은 접근 문제를 발견하고 해결할 수 있도록 하여 애플리케이션에 영향을 미치지 않도록 합니다.",
        "Other Options": [
            "즉시 과도한 권한을 제거하면 역할이 중요한 접근 권한을 잃게 되어 애플리케이션 실패로 이어질 수 있습니다. 이 접근 방식은 변경 전에 테스트나 모니터링을 허용하지 않습니다.",
            "AWS CloudTrail은 기록 및 감사에 유용하지만, 로그만으로 권한을 검토하는 것은 수정 프로세스를 지연시키고 과도한 권한의 위험을 적극적으로 줄이지 않습니다.",
            "매 6개월마다 검토를 예약하는 것은 보안 위험의 시기적절한 수정을 제공하지 않습니다. 과도한 권한 문제를 해결하기 위해 즉각적인 조치가 필요합니다."
        ]
    },
    {
        "Question Number": "59",
        "Situation": "한 미디어 회사는 출시 초기 몇 주 동안 자주 접근되는 대용량 비디오 파일을 저장해야 하지만, 초기 관심이 사라지면 이러한 파일에 대한 접근이 크게 줄어듭니다. 이 회사는 이러한 비디오 파일을 최소 3년 동안 보관할 계획이며, 저장 비용을 최소화하는 것을 목표로 하고 있습니다.",
        "Question": "다음 S3 저장 클래스 중에서 접근 및 보존 요구 사항을 충족하면서 이러한 비디오 파일을 저장하는 데 가장 비용 효율적인 솔루션은 무엇입니까?",
        "Options": {
            "1": "사용 패턴에 따라 파일을 자동으로 접근 계층 간에 이동하는 Amazon S3 Intelligent-Tiering.",
            "2": "보존 기간 동안 자주 접근되는 데이터에 대해 최상의 성능을 제공하는 Amazon S3 Standard.",
            "3": "처음 몇 개월 동안 Amazon S3 One Zone-IA를 사용한 후 Amazon S3 Standard-IA로 전환합니다.",
            "4": "처음 30일 동안 Amazon S3 Standard를 사용한 후 장기 저장을 위해 Amazon S3 Glacier로 전환합니다."
        },
        "Correct Answer": "사용 패턴에 따라 파일을 자동으로 접근 계층 간에 이동하는 Amazon S3 Intelligent-Tiering.",
        "Explanation": "Amazon S3 Intelligent-Tiering은 비디오 파일의 접근 빈도에 따라 저장 클래스를 자동으로 조정하여 비용을 최적화하면서 필요할 때 쉽게 접근할 수 있도록 합니다. 이 클래스는 지정된 보존 기간 동안 비디오 파일의 변동하는 접근 패턴에 적합합니다.",
        "Other Options": [
            "처음 30일 동안 Amazon S3 Standard를 사용한 후 Amazon S3 Glacier로 전환하는 것은 최적이 아닙니다. Glacier는 장기 저장에 비용 효율적이지만, 자주 접근하는 데는 적합하지 않아 높은 검색 비용과 지연이 발생할 수 있습니다.",
            "처음 몇 개월 동안 Amazon S3 One Zone-IA를 사용한 후 Amazon S3 Standard-IA로 전환하는 것은 잘못된 선택입니다. One Zone-IA는 다른 클래스보다 내구성이 낮아 해당 영역에서 가용성이 손실되면 비디오 파일이 복구 불가능할 수 있어 중요한 미디어 저장에 적합하지 않습니다.",
            "보존 기간 동안 Amazon S3 Standard를 사용하는 것은 이 경우 비용 효율적이지 않습니다. 초기 몇 주 이후의 드문 접근 기간에 대한 비용 최적화를 제공하지 않아 전체 저장 비용이 증가합니다."
        ]
    },
    {
        "Question Number": "60",
        "Situation": "한 스타트업이 데이터 처리 및 저장을 위한 강력한 백엔드를 요구하는 새로운 애플리케이션을 구축하기 위해 AWS 관리 서비스를 활용하고자 합니다. 팀은 운영 오버헤드를 최소화하고 인프라 관리보다는 애플리케이션 개발에 집중하고자 합니다. 그들은 필요를 충족하기 위해 다양한 AWS 관리 서비스를 고려하고 있습니다.",
        "Question": "스타트업이 애플리케이션 요구 사항을 효율적으로 충족하기 위해 어떤 AWS 관리 서비스 조합을 활용해야 합니까? (두 가지 선택)",
        "Options": {
            "1": "컨테이너 오케스트레이션을 위해 Amazon ECS를 배포하고 관계형 데이터베이스 서비스를 위해 Amazon RDS를 사용합니다.",
            "2": "모든 애플리케이션 호스팅을 위해 Amazon EC2를 사용하고 저장 요구를 위해 Amazon EBS를 사용합니다.",
            "3": "애플리케이션 관리를 위해 AWS Elastic Beanstalk를 활용하고 콘텐츠 전송을 위해 Amazon CloudFront를 사용합니다.",
            "4": "서버리스 컴퓨팅을 위해 AWS Lambda를 구현하고 NoSQL 데이터베이스 저장을 위해 Amazon DynamoDB를 사용합니다.",
            "5": "데이터베이스 관리를 위해 Amazon RDS를 사용하고 객체 저장을 위해 Amazon S3를 사용합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "데이터베이스 관리를 위해 Amazon RDS를 사용하고 객체 저장을 위해 Amazon S3를 사용합니다.",
            "서버리스 컴퓨팅을 위해 AWS Lambda를 구현하고 NoSQL 데이터베이스 저장을 위해 Amazon DynamoDB를 사용합니다."
        ],
        "Explanation": "Amazon RDS를 사용하면 스타트업이 완전 관리형 관계형 데이터베이스 서비스의 이점을 누릴 수 있어 백업 및 패치 관리와 같은 관리 작업을 줄일 수 있습니다. Amazon S3는 비구조적 데이터에 대한 확장 가능한 객체 저장소를 제공합니다. AWS Lambda는 서버리스 컴퓨팅을 가능하게 하여 팀이 서버를 프로비저닝하지 않고도 코드를 실행할 수 있게 하며, DynamoDB는 수요에 따라 자동으로 확장되는 완전 관리형 NoSQL 데이터베이스를 제공하여 현대 애플리케이션에 적합합니다.",
        "Other Options": [
            "모든 애플리케이션 호스팅을 위해 Amazon EC2를 사용하는 것은 상당한 운영 오버헤드를 초래합니다. 스타트업은 기본 서버를 관리해야 하므로 인프라 관리 최소화 목표에 반합니다.",
            "AWS Elastic Beanstalk를 활용하는 것은 애플리케이션 관리에 좋은 선택이지만, Amazon CloudFront와 함께 사용하는 것은 데이터 저장 또는 백엔드 처리 요구를 효과적으로 해결하지 못합니다.",
            "컨테이너 오케스트레이션을 위해 Amazon ECS를 배포하는 것은 유효한 선택이지만, Amazon RDS만 의존하는 것은 AWS Lambda와 DynamoDB가 제공할 수 있는 서버리스 아키텍처의 이점을 완전히 활용하지 못합니다."
        ]
    },
    {
        "Question Number": "61",
        "Situation": "한 금융 서비스 회사가 애플리케이션 아키텍처를 AWS로 마이그레이션하고 있습니다. 그들은 대량의 거래 데이터를 안전하게 저장하고 높은 내구성을 유지해야 합니다. 또한, 재해 복구를 위해 데이터가 서로 다른 지역에 복제되도록 보장해야 합니다. 이들은 이러한 요구 사항을 충족하기 위해 다양한 AWS 스토리지 서비스를 고려하고 있습니다.",
        "Question": "Solutions Architect가 거래 데이터의 안전하고 높은 내구성을 보장하며 교차 지역 복제를 위한 전략으로 무엇을 추천해야 합니까?",
        "Options": {
            "1": "버전 관리가 활성화된 Amazon S3를 사용하고 교차 지역 복제(CRR)를 구성하여 객체를 다른 지역의 S3 버킷으로 자동 복제합니다.",
            "2": "데이터 지속성이 활성화된 Amazon ElastiCache를 구현하고 지역 간 복제 그룹을 설정하여 장애 발생 시 캐시 데이터가 사용 가능하도록 합니다.",
            "3": "고가용성과 자동 장애 조치를 제공하기 위해 Multi-AZ 배포가 있는 Amazon RDS를 활용하고, 재해 복구를 위해 다른 지역에 읽기 복제를 활성화합니다.",
            "4": "파일 저장을 위해 Amazon EFS를 사용하고 교차 지역 복제를 활성화하여 파일 시스템이 재해 복구를 위해 다른 지역으로 복제되도록 합니다."
        },
        "Correct Answer": "버전 관리가 활성화된 Amazon S3를 사용하고 교차 지역 복제(CRR)를 구성하여 객체를 다른 지역의 S3 버킷으로 자동 복제합니다.",
        "Explanation": "Amazon S3는 99.999999999%의 내구성을 제공하는 매우 내구성 있는 저장 솔루션입니다. 버전 관리를 활성화하면 객체의 여러 버전을 유지할 수 있으며, 교차 지역 복제(CRR)는 객체를 다른 지역으로 자동 복제하여 지역 장애 발생 시 데이터가 안전하고 사용 가능하도록 보장합니다.",
        "Other Options": [
            "Multi-AZ 배포가 있는 Amazon RDS는 고가용성과 장애 조치 기능을 제공하지만, 재해 복구를 위한 교차 지역 복제를 본질적으로 지원하지 않습니다. 이 옵션은 지역 간 복제 요구 사항을 충족하지 않습니다.",
            "Amazon ElastiCache는 주로 캐싱에 사용되며 거래 데이터의 장기 내구성 저장을 위해 설계되지 않았습니다. 복제를 지원하지만 거래 데이터에 필요한 동일한 수준의 내구성을 보장하지 않습니다.",
            "Amazon EFS는 본래 교차 지역 복제를 지원하지 않습니다. 파일 저장에 좋은 선택이지만, 재해 복구를 위해 파일이 다른 지역으로 복제되도록 보장하는 요구 사항을 충족할 수 없습니다."
        ]
    },
    {
        "Question Number": "62",
        "Situation": "한 금융 서비스 회사가 고성능 컴퓨팅(HPC) 애플리케이션을 AWS로 마이그레이션할 계획입니다. 이 애플리케이션은 여러 EC2 인스턴스에서 최적의 성능을 달성하기 위해 저지연, 고처리량 네트워킹 기능이 필요합니다. 회사는 인스턴스 간 통신 성능을 향상시키기 위해 Elastic Fabric Adapter(EFA)를 사용하는 것을 고려하고 있습니다. 그들은 마이그레이션 전략이 EFA의 기능을 최대한 활용하도록 보장하고 싶어합니다.",
        "Question": "회사가 AWS에서 HPC 애플리케이션에 EFA를 효과적으로 활용하기 위해 무엇을 해야 합니까?",
        "Options": {
            "1": "EFA를 지원하는 EC2 인스턴스 유형을 선택하고 인스턴스 시작 시 EFA를 활성화하며, 애플리케이션을 향상된 네트워킹 기능을 사용하도록 구성합니다.",
            "2": "Amazon ECS를 사용하여 EFA를 활성화하지 않고 HPC 애플리케이션의 컨테이너화된 버전을 실행하며, 표준 EC2 네트워킹에만 의존합니다.",
            "3": "네트워크 성능에 최적화되지 않은 EC2 인스턴스를 시작하고 기본 Elastic Network Adapter(ENA)를 사용하도록 구성합니다.",
            "4": "EFA가 활성화된 EC2 인스턴스를 배포하되, 호환성 문제를 피하기 위해 애플리케이션이 향상된 네트워킹 기능을 활용하지 못하도록 제한합니다."
        },
        "Correct Answer": "EFA를 지원하는 EC2 인스턴스 유형을 선택하고 인스턴스 시작 시 EFA를 활성화하며, 애플리케이션을 향상된 네트워킹 기능을 사용하도록 구성합니다.",
        "Explanation": "EFA를 지원하는 EC2 인스턴스 유형을 선택하고 인스턴스 시작 시 EFA를 활성화함으로써, 회사는 HPC 애플리케이션의 성능에 필수적인 저지연 및 고처리량 네트워킹 기능의 이점을 누릴 수 있습니다.",
        "Other Options": [
            "네트워크 성능에 최적화되지 않은 EC2 인스턴스를 시작하고 기본 Elastic Network Adapter(ENA)를 사용하는 것은 EFA의 기능을 활용하지 못하게 하여 HPC 애플리케이션의 성능을 저하시킬 것입니다.",
            "EFA가 활성화된 EC2 인스턴스를 배포하되 애플리케이션이 향상된 네트워킹 기능을 활용하지 못하도록 제한하는 것은 EFA의 이점을 무효화하여 애플리케이션이 저지연 및 고처리량 네트워킹을 활용할 수 없게 됩니다.",
            "EFA를 활성화하지 않고 Amazon ECS를 사용하여 HPC 애플리케이션의 컨테이너화된 버전을 실행하는 것은 네트워크 성능을 극대화하지 못하게 되며, 표준 EC2 네트워킹은 EFA가 제공하는 향상을 결여하고 있습니다."
        ]
    },
    {
        "Question Number": "63",
        "Situation": "한 금융 서비스 회사가 기존의 온프레미스 애플리케이션을 AWS로 마이그레이션할 계획입니다. 이 애플리케이션은 .NET 프레임워크로 구축되었으며, Microsoft SQL Server 데이터베이스를 사용하고 있으며, 한 달 동안 상당한 부하 변동을 경험합니다. 회사는 상당한 수동 개입 없이 다양한 작업 부하를 처리할 수 있는 확장 가능한 아키텍처가 필요합니다. 또한, 애플리케이션은 높은 가용성과 재해 복구 기능을 유지해야 합니다. 팀은 가능한 경우 관리형 서비스를 활용하고 전환 중 최소한의 다운타임을 보장하는 옵션을 탐색하고 있습니다.",
        "Question": "AWS로의 마이그레이션 중 회사의 요구 사항을 가장 잘 지원하는 아키텍처 설계는 무엇입니까?",
        "Options": {
            "1": ".NET 애플리케이션을 Auto Scaling 그룹에서 관리하는 Amazon EC2 인스턴스로 마이그레이션합니다. Amazon RDS를 SQL Server와 함께 사용하되 Multi-AZ 배포 없이 구성합니다. 트래픽을 분산시키기 위해 Elastic Load Balancer를 생성하고, 부하 변화에 따라 EC2 인스턴스를 수동으로 조정합니다.",
            "2": "AWS Elastic Beanstalk를 사용하여 .NET 애플리케이션을 관리하고, 트래픽 분산을 위해 Application Load Balancer를 구성합니다. 데이터베이스 요구 사항을 위해 Amazon RDS를 SQL Server와 함께 사용하고, 고가용성과 자동 장애 조치를 위해 Multi-AZ를 설정합니다. 변동하는 작업 부하를 처리하기 위해 AWS Auto Scaling을 구현합니다.",
            "3": "AWS Fargate를 사용하여 .NET 애플리케이션을 컨테이너화된 서비스로 실행하고, SQL 데이터베이스 요구 사항을 위해 Amazon Aurora를 사용합니다. 트래픽 관리를 위해 Network Load Balancer를 구현하고, 관찰된 부하 패턴에 따라 수동으로 스케일링합니다.",
            "4": "Amazon ECS에서 EC2 시작 유형으로 .NET 애플리케이션을 배포하여 컨테이너를 관리합니다. Amazon RDS를 SQL Server와 함께 사용하고, 고가용성을 위해 Multi-AZ를 구성합니다. 트래픽을 라우팅하기 위해 Application Load Balancer를 구현하고, 모니터링 및 스케일링을 위해 CloudWatch를 활용합니다."
        },
        "Correct Answer": "AWS Elastic Beanstalk를 사용하여 .NET 애플리케이션을 관리하고, 트래픽 분산을 위해 Application Load Balancer를 구성합니다. 데이터베이스 요구 사항을 위해 Amazon RDS를 SQL Server와 함께 사용하고, 고가용성과 자동 장애 조치를 위해 Multi-AZ를 설정합니다. 변동하는 작업 부하를 처리하기 위해 AWS Auto Scaling을 구현합니다.",
        "Explanation": "이 옵션은 AWS Elastic Beanstalk를 통해 완전 관리형 서비스를 제공하여 .NET 애플리케이션의 배포, 관리 및 스케일링을 간소화합니다. 또한, Amazon RDS와 Multi-AZ를 포함하여 고가용성을 보장하고, 장애 발생 시 데이터 무결성과 신속한 복구를 보장하며, AWS Auto Scaling은 변동하는 작업 부하에 적응할 수 있도록 합니다.",
        "Other Options": [
            "이 옵션은 Amazon RDS에 대한 Multi-AZ 구성이 부족하여 고가용성과 재해 복구에 중요합니다. 또한, EC2 인스턴스에 대한 수동 조정에 의존하는 것은 부하 변화 동안 최소한의 수동 개입 요구 사항을 충족하지 않습니다.",
            "AWS Fargate에서 .NET 애플리케이션을 실행하는 것은 기존 아키텍처를 효율적으로 활용하지 못할 수 있으며, 특히 애플리케이션이 컨테이너화에 맞게 설계되지 않은 경우 더욱 그렇습니다. 또한, Amazon Aurora는 직접적인 SQL Server 대체가 아니므로 마이그레이션 과정을 복잡하게 만들 수 있습니다.",
            "Amazon ECS에서 EC2 시작 유형을 사용하는 것은 기본 EC2 인스턴스를 관리하는 데 추가적인 부담을 주며, 이는 회사가 원하는 관리형 서비스 접근 방식에 반합니다. Multi-AZ가 RDS에 포함되어 있지만, 컨테이너 오케스트레이션의 복잡성은 원활한 마이그레이션 요구 사항을 충족하지 못할 수 있습니다."
        ]
    },
    {
        "Question Number": "64",
        "Situation": "한 금융 서비스 회사가 애플리케이션을 AWS로 마이그레이션하고 있으며, 광범위한 내부 전문 지식 없이 기계 학습 및 데이터 분석과 같은 고급 기술을 활용할 수 있도록 보장하고자 합니다. 목표는 배포를 자동화하고 기술을 개발 팀이 접근할 수 있도록 하면서 규제 준수를 준수하는 것입니다.",
        "Question": "다음 솔루션 중 어떤 것이 회사가 복잡한 기계 학습 및 분석 작업을 AWS에 위임하면서 개발 팀의 규정 준수 및 접근성을 보장하는 데 가장 적합합니까?",
        "Options": {
            "1": "Amazon Elastic MapReduce (EMR)를 사용하여 분석을 수행하고 개발 팀이 규정 준수를 보장하기 위해 기본 인프라를 수동으로 관리하도록 요구합니다.",
            "2": "데이터 준비 및 ETL 작업을 위해 AWS Glue를 구현하지만 개발자가 기계 학습 모델 교육 및 배포를 독립적으로 처리하도록 요구합니다.",
            "3": "서버리스 기능을 위해 AWS Lambda를 채택하여 기계 학습 추론을 실행하지만 개발자가 EC2 인스턴스에서 자신의 기계 학습 모델을 유지하도록 합니다.",
            "4": "Amazon SageMaker를 활용하여 기계 학습 모델을 구축, 교육 및 배포하고 AWS CloudFormation을 사용하여 인프라를 코드로 관리합니다."
        },
        "Correct Answer": "Amazon SageMaker를 활용하여 기계 학습 모델을 구축, 교육 및 배포하고 AWS CloudFormation을 사용하여 인프라를 코드로 관리합니다.",
        "Explanation": "이 옵션은 기계 학습의 복잡성을 추상화하면서 회사가 규정 준수를 유지할 수 있도록 하는 포괄적인 솔루션을 제공합니다. Amazon SageMaker는 모델 개발 및 배포를 간소화하며, AWS CloudFormation은 인프라를 효율적이고 일관되게 관리할 수 있도록 보장합니다.",
        "Other Options": [
            "Amazon EMR은 데이터 분석을 위한 강력한 도구이지만, 개발 팀이 기본 인프라를 수동으로 관리하도록 요구하는 것은 복잡한 작업을 위임하려는 목표와 모순되며 불필요한 운영 부담을 추가합니다.",
            "AWS Glue는 ETL 작업에 훌륭한 선택이지만, 개발자가 기계 학습 모델 교육 및 배포를 독립적으로 처리하도록 요구하는 것은 전문 지식의 사일로를 만들고 규정 준수 노력을 복잡하게 만듭니다.",
            "AWS Lambda는 추론에 사용할 수 있지만, 개발자가 EC2 인스턴스에서 자신의 기계 학습 모델을 관리하도록 하는 것은 복잡성을 도입하고 고급 기술의 접근성을 감소시킵니다."
        ]
    },
    {
        "Question Number": "65",
        "Situation": "한 다국적 회사가 전 세계 사용자에게 서비스를 제공하는 웹 애플리케이션의 성능을 최적화하려고 합니다. 애플리케이션은 us-east-1 리전에서 호스팅되고 있으며, 회사는 유럽 및 아시아에 위치한 사용자에 대한 지연 시간에 대해 우려하고 있습니다. 솔루션 아키텍트는 전 세계 사용자에게 낮은 지연 시간과 높은 가용성을 보장하는 솔루션을 구현해야 합니다.",
        "Question": "다음 솔루션 중 어떤 것이 회사의 글로벌 성능 최적화 요구 사항을 가장 잘 충족합니까?",
        "Options": {
            "1": "Amazon CloudFront를 콘텐츠 전송 네트워크(CDN)로 구현하여 사용자와 가까운 엣지 위치에서 정적 콘텐츠를 캐시하고 동적 콘텐츠 전송도 가능하게 합니다.",
            "2": "AWS Global Accelerator를 사용하여 사용자 트래픽을 가장 가까운 애플리케이션 엔드포인트로 라우팅하여 성능을 최적화하고 지능형 라우팅을 통해 가용성을 향상시킵니다.",
            "3": "AWS Lambda@Edge를 활용하여 AWS 엣지 위치에서 사용자 정의 코드를 실행하여 사용자 근처에서 실시간 데이터 처리 및 응답 생성을 가능하게 합니다.",
            "4": "여러 AWS 리전에 웹 애플리케이션을 배포하고 Amazon Route 53을 사용하여 지리적 라우팅을 통해 사용자를 가장 가까운 리전으로 안내하여 최소한의 지연 시간을 보장합니다."
        },
        "Correct Answer": "AWS Global Accelerator를 사용하여 사용자 트래픽을 가장 가까운 애플리케이션 엔드포인트로 라우팅하여 성능을 최적화하고 지능형 라우팅을 통해 가용성을 향상시킵니다.",
        "Explanation": "AWS Global Accelerator는 사용자의 위치와 엔드포인트의 상태에 따라 사용자 트래픽을 가장 최적의 엔드포인트로 유도하여 애플리케이션 성능을 향상시킵니다. 이는 가용성을 높이고 지연 시간을 줄여 글로벌 성능 최적화에 적합한 선택입니다.",
        "Other Options": [
            "Amazon CloudFront를 구현하는 것은 정적 콘텐츠를 캐시하고 지연 시간을 줄이는 좋은 접근 방식이지만, 동적 콘텐츠의 라우팅을 최적화하거나 여러 애플리케이션 엔드포인트에서 높은 가용성을 보장하지는 않습니다.",
            "여러 AWS 리전에 웹 애플리케이션을 배포하고 Amazon Route 53을 사용하여 지리적 라우팅을 하는 것은 유익하지만, 여러 배포를 관리하는 데 복잡성을 도입할 수 있으며 AWS Global Accelerator와 같은 수준의 지능형 라우팅을 제공하지 않습니다.",
            "AWS Lambda@Edge를 사용하면 엣지 위치에서 사용자 정의 로직을 실행하여 특정 사용 사례의 성능을 향상시킬 수 있지만, AWS Global Accelerator처럼 사용자 트래픽을 가장 가까운 애플리케이션 엔드포인트로 라우팅하는 것을 본질적으로 최적화하지는 않습니다."
        ]
    },
    {
        "Question Number": "66",
        "Situation": "한 스타트업 회사가 새로운 온라인 비디오 스트리밍 서비스를 출시하고 있습니다. 이 서비스는 평균 5,000명의 동시 사용자와 인기 있는 이벤트 동안 50,000명의 동시 사용자에 도달하는 변동하는 사용자 기반을 가질 것으로 예상됩니다. 회사는 필요한 리소스에 대해서만 비용을 지불하고 고품질 스트리밍 경험을 유지하면서 비용 효율적인 인프라를 구현하고자 합니다. 그들은 비디오 콘텐츠 및 스트리밍 기능을 위한 다양한 저장 솔루션을 고려하고 있습니다.",
        "Question": "다음 아키텍처 디자인 중 어떤 것이 사용자 수요에 따라 동적으로 조정하면서 스트리밍 비디오 콘텐츠를 제공하는 가장 비용 효율적인 솔루션을 제공합니까?",
        "Options": {
            "1": "Amazon S3를 사용하여 비디오 파일을 저장하고 AWS Elemental Media Services를 구현하여 비디오 스트림을 처리하고 확장하여 피크 시간 동안 최적의 전송을 보장합니다.",
            "2": "Amazon Elastic Transcoder를 사용하여 비디오 파일을 변환하고 Amazon S3에 저장한 다음, AWS Lambda 함수를 사용하여 CDN을 사용하지 않고 S3에서 직접 요청을 처리합니다.",
            "3": "비디오 파일을 Amazon EFS에 직접 저장하고 이를 Amazon EC2 인스턴스의 플릿에 마운트합니다. 이러한 인스턴스를 사용하여 캐시 레이어 없이 사용자에게 직접 콘텐츠를 스트리밍합니다.",
            "4": "Amazon S3를 사용하여 비디오 파일을 저장하고 Amazon CloudFront와 함께 콘텐츠 전송을 위해 사용합니다. 요청을 처리하기 위해 로드 밸런서가 있는 Amazon EC2 인스턴스의 Auto Scaling 그룹을 구현합니다."
        },
        "Correct Answer": "Amazon S3를 사용하여 비디오 파일을 저장하고 AWS Elemental Media Services를 구현하여 비디오 스트림을 처리하고 확장하여 피크 시간 동안 최적의 전송을 보장합니다.",
        "Explanation": "이 옵션은 비용 효율적인 저장을 위해 Amazon S3를 활용하고, 효율적인 처리 및 확장을 위해 AWS Elemental Media Services를 활용하여 피크 사용 시 고품질 전송을 보장합니다. 이 아키텍처는 수요에 따라 동적으로 조정되어 비디오 스트리밍을 위한 비용 효율적인 솔루션이 됩니다.",
        "Other Options": [
            "이 옵션은 EC2 인스턴스와 로드 밸런서에 의존하므로, 특히 사용량이 적은 기간 동안 여러 EC2 인스턴스를 실행할 필요가 없을 때 항상 켜져 있는 리소스 때문에 더 높은 비용이 발생할 수 있습니다.",
            "비디오 저장을 위해 Amazon EFS를 사용하는 것은 잠재적인 지연 문제로 인해 스트리밍에 이상적이지 않으며, S3보다 더 비쌀 수 있습니다. 이 옵션은 성능을 개선하고 비용을 줄일 수 있는 캐시 레이어를 포함하지 않습니다.",
            "Amazon Elastic Transcoder는 비디오 형식 변환에 유용하지만, CDN 없이 S3에서 직접 요청을 처리하면 피크 시간 동안 지연 시간과 비용이 증가할 수 있으며, CDN이 성능을 개선하고 S3 버킷의 부하를 줄일 수 있는 경우에는 더욱 그렇습니다."
        ]
    },
    {
        "Question Number": "67",
        "Situation": "대규모 전자상거래 회사가 프로모션 이벤트로 인해 트래픽이 급증하고 있습니다. 그들은 온라인 서비스에 방해가 될 수 있는 분산 서비스 거부(DDoS) 공격에 대해 우려하고 있습니다. 이 회사는 다양한 DDoS 공격에 대해 강력한 보호를 제공하면서 애플리케이션 성능에 미치는 영향을 최소화하는 솔루션을 구현하고자 합니다. 또한 자원에 영향을 미칠 수 있는 의심스러운 활동에 대한 알림이 필요합니다.",
        "Question": "다음 솔루션 중 어떤 것이 회사의 DDoS 보호 및 알림 요구 사항을 가장 잘 충족합니까?",
        "Options": {
            "1": "AWS Shield Advanced를 구현하여 포괄적인 DDoS 보호를 제공하고 AWS WAF를 활용하여 트래픽을 필터링하는 규칙을 생성합니다. 자세한 공격 분석을 위해 로깅을 활성화하고 Amazon SNS를 통해 알림을 설정합니다.",
            "2": "기본 DDoS 보호를 위해 AWS Shield Standard를 사용하고 Route 53을 구현하여 DNS 라우팅을 설정합니다. 트래픽 패턴을 추적하고 팀에 경고하는 맞춤형 모니터링 솔루션을 만듭니다.",
            "3": "강화된 DDoS 보호를 위해 AWS Shield Advanced를 활성화하고 CloudFront를 구성하여 콘텐츠를 캐시합니다. 활동 모니터링 및 알림을 위해 Amazon CloudWatch 경고를 설정합니다.",
            "4": "자동 DDoS 보호를 위해 AWS Shield Standard를 활성화하고 트래픽 분배를 위해 Elastic Load Balancing을 통합합니다. 모니터링 및 사고 대응을 위해 AWS CloudTrail에 의존합니다."
        },
        "Correct Answer": "AWS Shield Advanced를 구현하여 포괄적인 DDoS 보호를 제공하고 AWS WAF를 활용하여 트래픽을 필터링하는 규칙을 생성합니다. 자세한 공격 분석을 위해 로깅을 활성화하고 Amazon SNS를 통해 알림을 설정합니다.",
        "Explanation": "AWS Shield Advanced는 정교한 DDoS 공격에 대한 강화된 보호를 제공하며, AWS WAF와 함께 사용할 경우 악의적인 트래픽을 필터링하는 맞춤형 규칙을 생성할 수 있습니다. 또한 로깅을 활성화하면 공격 패턴에 대한 통찰력을 제공하고, Amazon SNS를 사용하면 팀에 실시간 알림을 제공하여 회사의 요구 사항을 효과적으로 충족합니다.",
        "Other Options": [
            "AWS Shield Advanced를 활성화하는 것은 좋은 선택이지만, CloudFront만 구성하는 것은 필요한 포괄적인 DDoS 보호를 제공하지 않으며, 로깅 및 알림이 없으면 중요한 모니터링 기능이 부족합니다.",
            "AWS Shield Standard는 기본 보호를 제공하지만, 회사가 요구하는 자세한 알림이나 고급 탐지 기능을 제공하지 않습니다. 맞춤형 모니터링 솔루션은 AWS의 내장 서비스만큼 효과적이지 않을 수 있습니다.",
            "AWS Shield Standard는 자동 보호를 제공하지만, AWS Shield Advanced 및 AWS WAF의 고급 기능이 없으면 잠재적인 위협에 대해 팀에 경고할 수 있는 필요한 맞춤화 및 로깅 기능이 부족합니다."
        ]
    },
    {
        "Question Number": "68",
        "Situation": "글로벌 온라인 게임 회사는 멀티플레이어 게임 인프라의 높은 가용성과 짧은 복구 시간을 보장하고자 합니다. 현재 단일 AWS 리전에서 운영 중이지만 재해 복구 전략을 강화하고 싶어합니다. 이 회사는 보조 리소스를 활용하여 4 9s(99.99%) 가용성을 달성하고 빠른 복구 시간을 확보할 수 있는 솔루션이 필요합니다.",
        "Question": "회사가 4 9s 가용성을 달성하고 매우 짧은 복구 시간을 보장하기 위해 단일 활성 리전만을 활용하여 구현할 수 있는 아키텍처는 무엇입니까?",
        "Options": {
            "1": "한 리전에서 Auto Scaling 그룹을 구현하고 기본 리전이 실패할 때만 보조 리전에서 다른 Auto Scaling 그룹을 활성화하는 장애 조치 메커니즘을 구성합니다.",
            "2": "한 리전에서 게임 데이터 저장을 위해 Amazon S3를 활용하고 교차 리전 복제를 사용하여 데이터를 보조 리전으로 복제하며, 게임 서버는 기본 리전에서만 활성 상태로 유지합니다.",
            "3": "기본 리전에서 Multi-AZ 배포로 Amazon RDS 인스턴스를 설정하고 다른 리전에서 읽기 복제본을 만들어 데이터 가용성과 빠른 장애 조치를 보장합니다.",
            "4": "게임 서버를 단일 AWS 리전에 배포하고 Amazon Route 53과 헬스 체크를 사용하여 기본 리전이 실패할 때 대기 리전으로 트래픽을 리디렉션합니다."
        },
        "Correct Answer": "한 리전에서 게임 데이터 저장을 위해 Amazon S3를 활용하고 교차 리전 복제를 사용하여 데이터를 보조 리전으로 복제하며, 게임 서버는 기본 리전에서만 활성 상태로 유지합니다.",
        "Explanation": "Amazon S3를 게임 데이터 저장에 활용하고 교차 리전 복제를 활성화함으로써 회사는 데이터가 항상 보조 리전에서 사용 가능하도록 보장할 수 있습니다. 이는 기본 리전에서 실패가 발생할 경우 신속한 복구를 가능하게 하며, 자원을 효율적으로 활용할 수 있습니다.",
        "Other Options": [
            "단일 AWS 리전에서 게임 서버를 배포하고 Route 53 헬스 체크를 사용하는 것은 보조 리전에서 필요한 복구 시간이나 데이터 가용성을 보장하지 않으며, 게임 서버는 장애 조치가 발생할 때까지 작동하지 않습니다.",
            "한 리전에서 Auto Scaling 그룹을 구현하고 다른 리전으로의 장애 조치 메커니즘을 설정하는 것은 보조 그룹이 실패로 인해 트리거될 때까지 비활성 상태이므로 원하는 4 9s 가용성을 제공하지 않습니다.",
            "Amazon RDS 인스턴스를 Multi-AZ 배포로 설정하면 높은 가용성을 보장하지만, 읽기 복제본이 쓰기에 적극적으로 사용되지 않기 때문에 보조 리전의 자원을 사용하여 신속한 복구를 허용하지 않습니다."
        ]
    },
    {
        "Question Number": "69",
        "Situation": "금융 서비스 회사는 AWS 지출을 최적화하고 여러 부서 간의 비용 가시성을 개선하고자 합니다. 이 회사는 비용을 효과적으로 할당하고 해당 태그를 기반으로 보고서를 생성할 수 있는 태깅 전략을 구현하고자 합니다. 그들은 AWS 리소스에 태그를 지정하기 위한 다양한 옵션을 고려하고 있습니다.",
        "Question": "효과적인 비용 할당 및 보고를 보장하기 위해 솔루션 아키텍트가 추천해야 할 접근 방식은 무엇입니까?",
        "Options": {
            "1": "리소스의 생성 날짜에 따라 태그를 지정하고 환경에 대한 기본 태그를 자동으로 적용하는 스크립트를 생성합니다. 이 스크립트를 정기적으로 실행하여 비용 보고를 위해 AWS Lambda를 사용합니다.",
            "2": "비용 보고서를 생성하기 전에 매월 리소스에 수동으로 태그를 지정합니다. 이 수동 프로세스에서 생성된 태그를 기반으로 Amazon QuickSight를 사용하여 비용을 시각화합니다.",
            "3": "AWS Config를 사용하여 리소스 태깅 준수를 강제하고 리소스 유형에 따라 자동으로 태그를 지정합니다. 이러한 자동으로 할당된 태그를 사용하여 AWS Budgets를 통해 비용 할당 보고서를 생성합니다.",
            "4": "모든 AWS 계정에 걸쳐 일관된 태깅 정책을 구현하여 각 리소스가 부서, 프로젝트 및 환경에 대한 주요 식별자로 태그가 지정되도록 합니다. 이러한 태그를 기반으로 비용을 분석하기 위해 AWS Cost Explorer를 활용합니다."
        },
        "Correct Answer": "모든 AWS 계정에 걸쳐 일관된 태깅 정책을 구현하여 각 리소스가 부서, 프로젝트 및 환경에 대한 주요 식별자로 태그가 지정되도록 합니다. 이러한 태그를 기반으로 비용을 분석하기 위해 AWS Cost Explorer를 활용합니다.",
        "Explanation": "일관된 태깅 정책은 부서, 프로젝트 및 환경에 걸쳐 비용을 적절하게 분류할 수 있도록 합니다. AWS Cost Explorer를 사용하면 이러한 태그를 기반으로 비용 분석이 가능하여 지출에 대한 명확한 통찰력을 제공하고 예산을 효과적으로 최적화하는 데 도움이 됩니다.",
        "Other Options": [
            "AWS Config를 사용하여 준수를 강제하는 것은 능동적인 태깅 전략의 필요성을 완전히 해결하지 못할 수 있습니다. 자동으로 할당된 태그는 비용 할당을 위한 특정 비즈니스 요구와 일치하지 않을 수 있습니다.",
            "리소스에 수동으로 태그를 지정하면 불일치와 오류가 발생할 수 있어 정확한 비용 보고를 위해 태그에 의존하기 어렵습니다. 또한 이 접근 방식은 지속적인 관리에 대해 확장 가능하거나 효율적이지 않습니다.",
            "리소스의 생성 날짜에 따라 태그를 지정하는 것은 비용 할당에 대한 의미 있는 맥락을 제공하지 않습니다. 기본 태그는 리소스의 목적을 정확하게 나타내지 않을 수 있어 불완전하거나 오해의 소지가 있는 비용 분석으로 이어질 수 있습니다."
        ]
    },
    {
        "Question Number": "70",
        "Situation": "다국적 기업이 여러 지역에서 운영되고 있으며, 온프레미스 데이터 센터와 AWS 환경 간에 안전하고 신뢰할 수 있는 연결을 구축해야 합니다. 이 회사는 데이터 전송을 위해 낮은 대기 시간과 높은 대역폭이 필요하며, 연결이 실패할 경우에도 복원력이 유지되어야 합니다. 또한, 이 회사는 이러한 연결을 위해 공용 인터넷에 의존하지 않도록 해야 합니다.",
        "Question": "온프레미스 데이터 센터와 AWS 간에 전용, 고대역폭, 저대기 시간 연결을 구축하면서 기본 연결 실패 시 중복 옵션도 제공하는 AWS 서비스는 무엇입니까?",
        "Options": {
            "1": "AWS Direct Connect와 가상 사설망(VPN) 백업.",
            "2": "다른 위치에 중복 연결이 있는 AWS Direct Connect.",
            "3": "중복성을 위한 여러 VPN 터널이 있는 AWS Site-to-Site VPN.",
            "4": "페일오버를 위한 여러 VPN 연결에 연결된 AWS Transit Gateway."
        },
        "Correct Answer": "다른 위치에 중복 연결이 있는 AWS Direct Connect.",
        "Explanation": "AWS Direct Connect는 인터넷 기반 솔루션에 비해 낮은 대기 시간과 높은 대역폭을 제공하는 전용 네트워크 연결을 제공합니다. 다른 위치에 중복 연결을 설정함으로써 회사는 높은 가용성과 연결 실패에 대한 복원력을 보장하여 운영에 필수적입니다.",
        "Other Options": [
            "AWS Site-to-Site VPN은 안전한 연결을 위한 실행 가능한 옵션이지만, 공용 인터넷에 의존하므로 대기 시간과 대역폭 제한이 발생할 수 있습니다. 여러 VPN 터널이 중복성을 제공할 수 있지만, Direct Connect의 전용 특성과는 일치하지 않습니다.",
            "AWS Transit Gateway는 여러 VPN 연결을 연결할 수 있지만, 여전히 이러한 연결에 대해 공용 인터넷에 의존합니다. 이 설정은 회사의 운영에 필요한 낮은 대기 시간과 높은 대역폭을 제공하지 않을 수 있습니다.",
            "VPN 백업이 있는 AWS Direct Connect는 보안을 강화할 수 있지만, 기본 연결 실패 시 VPN 연결은 여전히 공용 인터넷에 의존하므로 대기 시간 문제를 일으킬 수 있으며, 회사의 전용 연결 요구 사항을 충족하지 못할 수 있습니다."
        ]
    },
    {
        "Question Number": "71",
        "Situation": "한 금융 서비스 회사가 AWS에 호스팅된 다중 지역 아키텍처에서 심각한 중단을 경험했습니다. 운영 팀은 이제 근본 원인을 파악하고 복구 절차가 효과적으로 구현되도록 해야 합니다. 그들은 비상 대응 프로세스를 검증하고 재해 복구 계획을 개선하기 위해 실패 시나리오를 시뮬레이션하고자 합니다. (두 가지 선택.)",
        "Question": "이 시뮬레이션 동안 복구 작업에 대한 이해를 연습하기 위해 솔루션 아키텍트가 구현해야 할 활동은 무엇입니까?",
        "Options": {
            "1": "일일 운영을 위한 실행 매뉴얼을 작성하고 팀을 안내하기 위해 시뮬레이션된 실패 처리 절차를 포함합니다.",
            "2": "AWS Backup을 사용하여 중요한 데이터를 보호하기 위해 자동 백업 프로세스를 설정합니다.",
            "3": "테스트 환경에서 최신 백업에서 애플리케이션을 완전히 복원하여 복구 프로세스를 검증합니다.",
            "4": "주요 이해관계자와 함께 테이블탑 연습을 실시하여 사고 대응 계획 및 복구 단계를 검토합니다.",
            "5": "시뮬레이션 중에 프로덕션 환경에서 변경 사항을 자동으로 롤백할 수 있는 AWS Lambda 함수를 배포합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "주요 이해관계자와 함께 테이블탑 연습을 실시하여 사고 대응 계획 및 복구 단계를 검토합니다.",
            "테스트 환경에서 최신 백업에서 애플리케이션을 완전히 복원하여 복구 프로세스를 검증합니다."
        ],
        "Explanation": "테이블탑 연습을 실시하면 팀이 실제 중단의 위험 없이 사고 대응 계획을 논의하고 개선할 수 있습니다. 백업에서 완전 복원을 수행하면 실제 복구 프로세스를 검증하여 실제 실패 시 애플리케이션을 효과적으로 복원할 수 있도록 보장합니다.",
        "Other Options": [
            "자동 백업 프로세스를 설정하는 것은 중요하지만, 시뮬레이션 동안 복구 작업이나 사고 대응 계획을 직접 테스트하지는 않습니다.",
            "AWS Lambda 함수를 배포하여 변경 사항을 롤백하는 것은 변경 사항 관리를 위해 유용하지만, 실패 시나리오에서 복구 프로세스를 효과적으로 시뮬레이션하지는 않습니다.",
            "일일 운영을 위한 실행 매뉴얼을 작성하는 것은 팀을 안내하는 데 유용하지만, 복구 작업을 테스트하기 위한 실용적인 연습의 필요성을 대체하지는 않습니다."
        ]
    },
    {
        "Question Number": "72",
        "Situation": "한 금융 서비스 회사는 인프라 전반에 걸쳐 민감한 데이터 암호화 키와 SSL/TLS 인증서를 관리하기 위한 안전한 솔루션이 필요합니다. 이 회사는 모든 암호화 키가 중앙에서 관리되고 정기적으로 교체되며, 데이터 보안 준수를 위해 애플리케이션과 통합되도록 하기를 원합니다. 솔루션 아키텍트는 키 관리 및 인증서 배포를 위한 모범 사례를 구현해야 합니다.",
        "Question": "이 시나리오에서 암호화 키와 인증서를 관리하기에 가장 적합한 솔루션은 무엇입니까?",
        "Options": {
            "1": "온프레미스 키 관리 솔루션을 배포하고 AWS에 호스팅된 애플리케이션의 SSL/TLS 인증서를 수동으로 관리합니다.",
            "2": "키 관리를 위해 AWS Key Management Service(AWS KMS)를 사용하고, 애플리케이션의 SSL/TLS 인증서를 프로비저닝하고 관리하기 위해 AWS Certificate Manager(ACM)를 사용합니다.",
            "3": "키 관리를 위해 AWS Secrets Manager를 활용하고, SSL/TLS 인증서를 자동으로 배포하기 위해 AWS CloudFormation을 사용합니다.",
            "4": "AWS Lambda 함수를 구현하여 암호화 키를 교체하고 애플리케이션 코드에서 SSL/TLS 인증서를 직접 관리합니다."
        },
        "Correct Answer": "키 관리를 위해 AWS Key Management Service(AWS KMS)를 사용하고, 애플리케이션의 SSL/TLS 인증서를 프로비저닝하고 관리하기 위해 AWS Certificate Manager(ACM)를 사용합니다.",
        "Explanation": "AWS Key Management Service(AWS KMS)는 암호화 키를 생성하고 관리하는 중앙 집중식 방법을 제공하며, 자동 키 교체 및 다른 AWS 서비스와의 통합을 포함합니다. AWS Certificate Manager(ACM)는 SSL/TLS 인증서 관리를 간소화하며, 자동 갱신을 포함하여 회사의 보안 요구 사항과 완벽하게 일치합니다.",
        "Other Options": [
            "이 옵션은 불필요한 복잡성과 위험을 초래합니다. 온프레미스 키 관리 솔루션을 관리하는 것은 AWS의 내장 보안 기능을 활용하지 않으며, 인증서를 수동으로 관리하면 잠재적인 간과 및 보안 취약점이 발생할 수 있습니다.",
            "AWS Secrets Manager는 API 키 및 데이터베이스 자격 증명과 같은 비밀을 관리하기 위해 설계되었지만, 암호화 키 관리에 최적화되어 있지 않습니다. 또한, SSL/TLS 인증서를 위한 CloudFormation 사용은 AWS Certificate Manager와 같은 수준의 자동화 및 유지 관리를 제공하지 않습니다.",
            "AWS Lambda는 다양한 자동화 작업에 사용될 수 있지만, 키 교체 및 인증서 관리에 적합한 솔루션이 아닙니다. 이 접근 방식은 불필요한 오버헤드와 복잡성을 추가하며, AWS KMS와 ACM이 제공하는 중앙 집중식 관리 기능이 부족합니다."
        ]
    },
    {
        "Question Number": "73",
        "Situation": "한 금융 서비스 회사가 프라이빗 VPC에 호스팅된 데이터베이스에 접근해야 하는 AWS Lambda 함수를 개발하고 있습니다. 이 함수는 피크 거래 기간 동안 높은 부하에 대응하여 확장할 것으로 예상됩니다. 그러나 팀은 Lambda 함수가 제대로 확장할 수 없음을 나타내는 빈번한 EC2ThrottledException 오류를 겪고 있습니다.",
        "Question": "솔루션 아키텍트는 Lambda 함수의 성능을 최적화하고 VPC 환경 내에서 효과적으로 확장되도록 하기 위해 무엇을 추천해야 합니까?",
        "Options": {
            "1": "Lambda 함수의 동시성 설정을 조정하고 VPC 서브넷에 충분한 사용 가능한 IP 주소와 ENI가 있는지 확인합니다.",
            "2": "VPC 설정을 수정하여 더 많은 탄력적 네트워크 인터페이스를 허용함으로써 VPC에서 사용 가능한 ENI의 수를 증가시킵니다.",
            "3": "VPC 외부에 Lambda 함수를 배포하여 VPC 구성의 제한 없이 자유롭게 확장할 수 있도록 합니다.",
            "4": "VPC 내에서 Lambda 함수 대신 요청을 처리할 전용 EC2 인스턴스를 설정합니다."
        },
        "Correct Answer": "Lambda 함수의 동시성 설정을 조정하고 VPC 서브넷에 충분한 사용 가능한 IP 주소와 ENI가 있는지 확인합니다.",
        "Explanation": "Lambda 함수의 동시성 설정을 조정하면 동시에 더 많은 요청을 처리할 수 있습니다. VPC 서브넷에 충분한 사용 가능한 IP 주소와 ENI가 있는지 확인하면 스로틀링 및 호출 오류를 방지하여 수요가 증가할 때 함수가 제대로 확장될 수 있습니다.",
        "Other Options": [
            "사용 가능한 ENI의 수를 증가시키는 것만으로는 Lambda 함수의 동시성 및 확장 한계와 관련된 근본적인 문제를 해결하지 못할 수 있습니다. ENI와 동시성 설정을 모두 관리하는 것이 필수적입니다.",
            "Lambda 함수를 VPC 외부에 배포하면 VPC 관련 구성이 필요 없어지고 확장성이 가능해지지만, 이는 프라이빗 VPC 내에 호스팅된 데이터베이스에 접근할 수 없게 되어 요구 사항을 충족하지 못합니다.",
            "전용 EC2 인스턴스를 설정하면 서버 인프라를 관리해야 하며, 이는 Lambda가 제공하는 서버리스 모델에 반하는 것입니다. 이 접근 방식은 VPC 내에서 Lambda 함수의 확장성 문제를 해결하지 않습니다."
        ]
    },
    {
        "Question Number": "74",
        "Situation": "한 소매 회사가 재고 관리, 고객 주문 및 실시간 분석을 처리할 새로운 애플리케이션을 개발하고 있습니다. 이 애플리케이션은 다양한 부하에 자동으로 조정할 수 있는 고도로 확장 가능한 아키텍처가 필요하며, 데이터 저장, 컴퓨팅 및 분석과 같은 특정 작업을 위한 목적에 맞는 서비스를 활용해야 합니다. 솔루션 아키텍트는 최적의 성능과 비용 효율성을 보장하면서 이러한 요구 사항에 가장 적합한 AWS 서비스를 선택해야 합니다.",
        "Question": "솔루션 아키텍트가 각 작업에 적합한 AWS 서비스를 사용하도록 애플리케이션을 보장하기 위해 어떤 접근 방식을 취해야 합니까?",
        "Options": {
            "1": "서버리스 컴퓨팅을 위해 AWS Lambda를 사용하고, 구조화된 데이터에 Amazon RDS를, 분석을 위해 Amazon Redshift를 사용합니다.",
            "2": "파일 저장을 위해 Amazon EFS를 선택하고, 기본 컴퓨팅 요구를 위해 Amazon Lightsail을, 비즈니스 인텔리전스를 위해 Amazon QuickSight를 사용합니다.",
            "3": "모든 컴퓨팅 요구를 위해 Amazon EC2 인스턴스를 활용하고, 데이터 저장을 위해 Amazon S3를 사용합니다.",
            "4": "컨테이너 관리를 위해 Amazon ECS를 구현하고, NoSQL 데이터 저장을 위해 Amazon DynamoDB를, 데이터 변환을 위해 AWS Glue를 사용합니다."
        },
        "Correct Answer": "서버리스 컴퓨팅을 위해 AWS Lambda를 사용하고, 구조화된 데이터에 Amazon RDS를, 분석을 위해 Amazon Redshift를 사용합니다.",
        "Explanation": "이 접근 방식은 애플리케이션의 요구 사항에 맞는 목적에 맞는 서비스를 효과적으로 활용합니다. AWS Lambda는 서버리스 컴퓨팅을 가능하게 하여 다양한 부하에 대해 매우 확장 가능하고 비용 효율적입니다. Amazon RDS는 구조화된 데이터 관리에 이상적이며, Amazon Redshift는 실시간 분석에 최적화되어 있어 이 조합이 가장 적합합니다.",
        "Other Options": [
            "모든 컴퓨팅 요구를 위해 Amazon EC2 인스턴스를 사용하는 것은 과잉 프로비저닝 및 높은 비용으로 이어질 수 있으며, 수요에 따라 자동으로 확장할 수 있는 서버리스 옵션을 활용하지 않습니다.",
            "Amazon ECS 및 AWS Glue를 구현하는 것은 특정 사용 사례에 적합할 수 있지만, 구조화된 데이터 관리 및 실시간 분석과 같은 모든 요구 사항을 최적으로 해결하지는 못합니다.",
            "Amazon EFS 및 Amazon Lightsail을 선택하는 것은 강력한 재고 관리 및 분석 애플리케이션에 필요한 확장성과 특정 최적화를 제공하지 않으므로 정답에 비해 덜 적합합니다."
        ]
    },
    {
        "Question Number": "75",
        "Situation": "글로벌 전자상거래 플랫폼은 고객이 위치에 관계없이 원활한 경험을 제공하기 위해 여러 지리적 지역 간의 실시간 데이터 동기화가 필요합니다. 아키텍처에는 온라인 제품 카탈로그와 일관성을 유지해야 하는 트랜잭션 데이터베이스가 포함됩니다. 솔루션 아키텍트는 AWS 리전 간의 저지연, 고가용성 복제를 지원하도록 데이터베이스를 구성해야 합니다.",
        "Question": "솔루션 아키텍트가 고가용성과 저지연을 보장하면서 효과적인 데이터 복제를 달성하기 위해 어떤 옵션을 구현해야 합니까?",
        "Options": {
            "1": "각 리전에서 Multi-AZ 배포로 Amazon RDS를 구현하고 AWS Data Pipeline을 사용하여 리전 간에 데이터를 수동으로 복제합니다.",
            "2": "교차 리전 읽기 복제를 사용하여 Amazon RDS를 배포하고 재해 복구를 위해 자동 백업을 활성화합니다.",
            "3": "Amazon DynamoDB를 사용하여 글로벌 테이블을 제공하여 플랫폼 전반에 걸쳐 다중 리전, 완전 복제된 데이터를 제공합니다.",
            "4": "저지연 액세스 및 자동 장애 조치 기능을 위해 교차 리전 복제를 설정한 Amazon Aurora를 구성합니다."
        },
        "Correct Answer": "Amazon DynamoDB를 사용하여 글로벌 테이블을 제공하여 플랫폼 전반에 걸쳐 다중 리전, 완전 복제된 데이터를 제공합니다.",
        "Explanation": "Amazon DynamoDB 글로벌 테이블은 여러 리전 간에 완전 복제된 데이터를 허용하여 서로 다른 지리적 위치의 사용자에게 저지연 액세스를 제공합니다. 이 아키텍처는 실시간 데이터 동기화 및 고가용성 요구 사항을 수동 개입 없이 충족합니다.",
        "Other Options": [
            "교차 리전 읽기 복제를 사용하여 Amazon RDS를 배포하면 일부 복제 기능을 제공하지만, DynamoDB 글로벌 테이블과 같은 저지연 액세스 및 자동 장애 조치 기능을 달성하지는 못합니다.",
            "Multi-AZ 배포로 Amazon RDS를 구현하면 리전 내에서 고가용성을 제공하지만, 교차 리전 복제를 해결하지 않으며 수동 데이터 동기화가 필요하여 복잡성과 지연이 증가할 수 있습니다.",
            "교차 리전 복제를 설정한 Amazon Aurora는 고가용성을 위한 유효한 솔루션이지만, 특히 동적 데이터가 있는 전자상거래 플랫폼에 대해 DynamoDB 글로벌 테이블과 같은 사용 편의성과 실시간 동기화를 제공하지 않을 수 있습니다."
        ]
    }
]