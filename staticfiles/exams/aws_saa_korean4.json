[
    {
        "Question Number": "1",
        "Situation": "회사가 특정 팀 구성원에게 Amazon S3 버킷에 대한 접근 권한을 부여해야 하지만, 버킷 내의 특정 객체에만 접근을 제한해야 합니다. IAM 관리자는 팀 구성원이 필요한 권한만 가지도록 하면서 관리 오버헤드를 낮추고 싶어합니다.",
        "Question": "관리자가 어떤 유형의 정책을 사용해야 하며, 버킷 내 객체에 대한 접근을 제한하기 위해 어떤 리소스 ARN 형식을 지정해야 합니까? (두 가지 선택)",
        "Options": {
            "1": "인라인 정책을 사용하고 ARN을 arn:aws:s3:::bucket-name/*로 지정합니다.",
            "2": "고객 관리 정책을 사용하고 ARN을 arn:aws:s3:::bucket-name로 지정합니다.",
            "3": "AWS 관리 정책을 사용하고 ARN을 arn:aws:s3:::bucket-name/*로 지정합니다.",
            "4": "인라인 정책을 사용하고 ARN을 arn:aws:s3:::bucket-name로 지정합니다.",
            "5": "버킷 정책을 사용하고 ARN을 arn:aws:s3:::bucket-name/specific-object-key로 지정합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "인라인 정책을 사용하고 ARN을 arn:aws:s3:::bucket-name/*로 지정합니다.",
            "버킷 정책을 사용하고 ARN을 arn:aws:s3:::bucket-name/specific-object-key로 지정합니다."
        ],
        "Explanation": "인라인 정책은 단일 IAM 아이덴티티(사용자, 그룹 또는 역할)에 내장된 정책입니다. 이는 관리자가 특정 사용자에게 특정 권한을 부여할 수 있게 해주며, 이 경우의 요구 사항에 부합합니다. ARN 'arn:aws:s3:::bucket-name/*'는 버킷 내의 모든 객체에 대한 접근을 허용합니다. 버킷 정책은 리소스 기반 정책으로, 정책을 생성하고 이를 S3 버킷에 직접 연결할 수 있게 해줍니다. ARN 'arn:aws:s3:::bucket-name/specific-object-key'는 버킷 내의 특정 객체에 대한 접근을 제한합니다.",
        "Other Options": [
            "고객 관리 정책을 사용하고 ARN을 'arn:aws:s3:::bucket-name'로 지정하는 것은 버킷 내의 특정 객체에 대한 접근을 제한하지 않습니다. 대신, 전체 버킷에 대한 접근을 허용합니다.",
            "AWS 관리 정책을 사용하고 ARN을 'arn:aws:s3:::bucket-name/*'로 지정하는 것은 이상적이지 않습니다. AWS 관리 정책은 일반적인 사용 사례에 대한 권한을 제공하도록 설계되었으며, AWS에 의해 관리됩니다. 이는 이 시나리오에서 필요한 세부적인 제어를 제공하지 않을 수 있습니다.",
            "인라인 정책을 사용하고 ARN을 'arn:aws:s3:::bucket-name'로 지정하는 것은 버킷 내의 특정 객체에 대한 접근을 제한하지 않습니다. 대신, 전체 버킷에 대한 접근을 허용합니다."
        ]
    },
    {
        "Question Number": "2",
        "Situation": "회사는 조직 내 다양한 팀의 많은 IAM 사용자에 대한 권한을 관리하고자 합니다. 각 팀에 대한 권한을 쉽게 할당할 수 있는 구조가 필요하며, 모든 사용자에게 개별 정책을 할당할 필요가 없습니다. 또한, 개별 사용자가 리소스 정책에서 직접 참조되는 것을 방지하고자 합니다.",
        "Question": "이러한 요구 사항을 충족하기 위해 가장 효과적인 IAM 기능은 무엇입니까?",
        "Options": {
            "1": "각 사용자에 대해 팀별 정책이 부착된 개별 IAM 역할을 생성합니다.",
            "2": "IAM 그룹을 사용하여 사용자를 팀별로 조직하고 각 그룹에 팀별 정책을 부착합니다.",
            "3": "모든 사용자에 대해 단일 IAM 역할을 설정하고 AWS Organizations를 사용하여 권한을 관리합니다.",
            "4": "각 사용자에게 특정 팀 권한에 따라 인라인 정책을 할당합니다."
        },
        "Correct Answer": "IAM 그룹을 사용하여 사용자를 팀별로 조직하고 각 그룹에 팀별 정책을 부착합니다.",
        "Explanation": "IAM 그룹을 사용하는 것이 가장 효과적인 솔루션입니다. 이는 회사가 개별적으로가 아니라 팀 수준에서 권한을 관리할 수 있게 해줍니다. 각 팀에 대한 그룹을 생성함으로써, 회사는 해당 그룹의 모든 사용자에 대한 권한을 정의하는 정책을 부착할 수 있습니다. 이는 정책에 대한 변경 사항이 그룹 내 모든 사용자에게 자동으로 적용되므로 권한 관리가 간소화됩니다. 또한, IAM 그룹은 개별 사용자가 리소스 정책에서 직접 참조되는 것을 방지하여 회사의 요구 사항에 부합합니다.",
        "Other Options": [
            "각 사용자에 대해 팀별 정책이 부착된 개별 IAM 역할을 생성하는 것은 복잡하고 관리하기 어려운 구조로 이어지며, 특히 많은 수의 사용자가 있을 경우 더욱 그렇습니다. 이 접근 방식은 각 역할을 지속적으로 업데이트하고 관리해야 하므로 비효율적입니다.",
            "모든 사용자에 대해 단일 IAM 역할을 설정하고 AWS Organizations를 사용하여 권한을 관리하는 것은 팀별 권한에 필요한 세부 사항을 제공하지 않습니다. 이 경우 모든 사용자가 동일한 권한을 가지게 되어 팀별 권한 관리 요구 사항을 충족하지 않습니다.",
            "각 사용자에게 특정 팀 권한에 따라 인라인 정책을 할당하는 것은 확장성이 없습니다. 인라인 정책은 사용자에게 직접 부착되므로 팀의 권한을 집합적으로 관리하기 어렵습니다. 이 접근 방식은 중복성과 관리 오버헤드 증가로 이어질 수 있습니다."
        ]
    },
    {
        "Question Number": "3",
        "Situation": "회사가 AWS에서 프라이빗 및 퍼블릭 서브넷을 구성하고 있습니다. 퍼블릭 서브넷의 인스턴스에 인터넷 접근을 가능하게 하면서 프라이빗 서브넷의 인스턴스는 직접 인터넷 접근으로부터 격리해야 합니다.",
        "Question": "회사가 퍼블릭 서브넷에 대한 인터넷 접근을 구성하고 VPC 내에서 안전한 라우팅을 보장하기 위해 어떤 단계를 취해야 합니까?",
        "Options": {
            "1": "VPC에 인터넷 게이트웨이(IGW)를 연결하고, 퍼블릭 서브넷과 연결된 라우트 테이블을 설정하여 0.0.0.0/0 트래픽을 IGW로 전송합니다. 그리고 퍼블릭 서브넷의 인스턴스에 퍼블릭 IPv4 주소를 할당합니다.",
            "2": "프라이빗 서브넷에 NAT 게이트웨이를 구성하고 VPC에 연결한 후, 퍼블릭 서브넷에서 NAT 게이트웨이로 0.0.0.0/0 트래픽을 전송하는 라우트 테이블을 생성합니다.",
            "3": "인터넷 게이트웨이(IGW)를 생성하고 퍼블릭 서브넷의 각 인스턴스에 개별적으로 연결하여 인터넷 접근을 제공하며, 기본 라우트 테이블을 사용하여 라우팅합니다.",
            "4": "프라이빗 서브넷과 퍼블릭 서브넷 간에 VPC 피어링 연결을 사용하여 인터넷 트래픽을 라우팅하고, 두 서브넷의 모든 인스턴스에 퍼블릭 IPv4 주소를 할당하여 연결성을 보장합니다."
        },
        "Correct Answer": "VPC에 인터넷 게이트웨이(IGW)를 연결하고, 퍼블릭 서브넷과 연결된 라우트 테이블을 설정하여 0.0.0.0/0 트래픽을 IGW로 전송합니다. 그리고 퍼블릭 서브넷의 인스턴스에 퍼블릭 IPv4 주소를 할당합니다.",
        "Explanation": "퍼블릭 서브넷의 인스턴스에 인터넷 접근을 가능하게 하려면, 회사는 VPC에 인터넷 게이트웨이(IGW)를 연결해야 합니다. IGW는 퍼블릭 서브넷의 인스턴스와 인터넷 간의 통신을 허용합니다. 또한, 퍼블릭 서브넷과 연결된 라우트 테이블은 모든 아웃바운드 트래픽(0.0.0.0/0)을 IGW로 전송하도록 설정해야 합니다. 마지막으로, 퍼블릭 서브넷의 인스턴스는 인터넷에서 접근 가능하도록 퍼블릭 IPv4 주소를 가져야 합니다. 이 구성은 인스턴스가 인터넷과 트래픽을 주고받을 수 있도록 하면서 프라이빗 서브넷은 격리된 상태를 유지합니다.",
        "Other Options": [
            "프라이빗 서브넷에 NAT 게이트웨이를 구성하는 것은 퍼블릭 서브넷에 인터넷 접근을 제공하는 데 잘못된 방법입니다. NAT 게이트웨이는 프라이빗 서브넷의 인스턴스가 인터넷으로 아웃바운드 트래픽을 시작할 수 있도록 허용하지만, 인터넷으로부터의 인바운드 트래픽을 차단합니다. 이는 퍼블릭 서브넷에는 적용되지 않습니다.",
            "인터넷 게이트웨이(IGW)를 생성하고 퍼블릭 서브넷의 각 인스턴스에 개별적으로 연결하는 것은 잘못된 방법입니다. IGW는 전체 VPC에 연결되어야 하며, 개별 인스턴스에 연결할 수 없습니다. 또한, 라우트 테이블은 IGW로 트래픽을 전송하도록 구성해야 하며, 기본 라우트 테이블에 의존해서는 안 됩니다.",
            "프라이빗 서브넷과 퍼블릭 서브넷 간에 VPC 피어링 연결을 사용하는 것은 인터넷 트래픽을 라우팅하는 유효한 방법이 아닙니다. VPC 피어링은 두 VPC를 연결하는 데 사용되며, 인터넷 접근을 가능하게 하는 데 사용되지 않습니다. 또한, 프라이빗 서브넷의 인스턴스는 직접 인터넷 접근으로부터 격리되기 위해 퍼블릭 IPv4 주소를 가져서는 안 됩니다."
        ]
    },
    {
        "Question Number": "4",
        "Situation": "다국적 소매 회사가 유럽과 아시아로 온라인 존재를 확장하고 있습니다. 이들은 새로운 지역의 사용자에게 고객 데이터베이스에 대한 저지연 접근을 보장하면서 데이터 주권 요구 사항을 유지하고자 합니다.",
        "Question": "이러한 요구 사항을 충족하기 위해 솔루션 아키텍트가 추천해야 할 AWS 아키텍처 전략은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "주 AWS 리전에서 단일 Amazon RDS 인스턴스를 배포하고 Amazon CloudFront를 사용하여 전 세계적으로 데이터베이스 쿼리를 캐시합니다.",
            "2": "유럽 및 아시아 리전에 보조 읽기 복제본이 있는 Amazon Aurora Global Database를 설정합니다.",
            "3": "Amazon DynamoDB를 사용하고 글로벌 테이블을 활성화하여 지역 간 자동 복제를 수행합니다.",
            "4": "각 새로운 지역의 온프레미스 데이터 센터에 VPN 연결을 구현하고 데이터베이스를 수동으로 복제합니다.",
            "5": "AWS DataSync를 사용하여 지역 간 데이터 복제를 자동화합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "유럽 및 아시아 리전에 보조 읽기 복제본이 있는 Amazon Aurora Global Database를 설정합니다.",
            "Amazon DynamoDB를 사용하고 글로벌 테이블을 활성화하여 지역 간 자동 복제를 수행합니다."
        ],
        "Explanation": "유럽 및 아시아 리전에 보조 읽기 복제본이 있는 Amazon Aurora Global Database를 설정하는 것은 저지연 읽기 및 재해 복구를 가능하게 하므로 올바른 답변입니다. 데이터는 여러 리전 간에 복제되어 데이터 주권과 저지연 접근을 보장합니다. Amazon DynamoDB를 사용하고 글로벌 테이블을 활성화하여 지역 간 자동 복제를 수행하는 것도 올바른 답변입니다. 글로벌 테이블은 여러 AWS 리전 간에 데이터를 복제하여 전 세계적으로 분산된 애플리케이션에 대한 빠르고 로컬한 데이터 접근을 제공합니다. 이는 저지연 접근과 데이터 주권을 보장합니다.",
        "Other Options": [
            "주 AWS 리전에서 단일 Amazon RDS 인스턴스를 배포하고 Amazon CloudFront를 사용하여 전 세계적으로 데이터베이스 쿼리를 캐시하는 것은 실행 가능한 솔루션이 아닙니다. CloudFront는 콘텐츠 전송 네트워크이지 데이터베이스 캐싱 서비스가 아니며, 데이터베이스 쿼리를 캐시하도록 설계되지 않았습니다.",
            "각 새로운 지역의 온프레미스 데이터 센터에 VPN 연결을 구현하고 데이터베이스를 수동으로 복제하는 것은 효율적인 솔루션이 아닙니다. 이는 상당한 수동 노력이 필요하며, 새로운 지역의 사용자에게 필요한 저지연 접근을 제공하지 않습니다.",
            "AWS DataSync를 사용하여 지역 간 데이터 복제를 자동화하는 것은 최선의 솔루션이 아닙니다. DataSync는 주로 온프레미스 스토리지와 AWS 간 또는 AWS 스토리지 서비스 간의 데이터 전송에 사용됩니다. 이는 새로운 지역의 사용자에게 필요한 저지연 접근을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "5",
        "Situation": "글로벌 전자상거래 플랫폼은 세일 이벤트 동안 수백만 명의 사용자가 동시에 플랫폼에 접근하여 트래픽 급증을 경험합니다. 모든 사용자에게 원활한 경험을 보장하기 위해 플랫폼은 지연이나 가용성을 저하시키지 않고 높은 트래픽을 처리해야 합니다.",
        "Question": "다음 중 이러한 요구 사항을 가장 잘 해결할 수 있는 전략은 무엇입니까?",
        "Options": {
            "1": "강력한 서버가 있는 단일 데이터 센터 사용",
            "2": "사용자에게 가장 가까운 위치에서 서비스를 제공하기 위해 다중 리전 분산 아키텍처 구현",
            "3": "데이터베이스 수준에서 데이터 캐싱만 의존",
            "4": "주 애플리케이션 서버에 CPU와 메모리를 추가"
        },
        "Correct Answer": "사용자에게 가장 가까운 위치에서 서비스를 제공하기 위해 다중 리전 분산 아키텍처 구현",
        "Explanation": "다중 리전 분산 아키텍처를 구현하면 전자상거래 플랫폼이 여러 지리적 지역에 위치한 여러 서버에 부하를 분산시켜 높은 트래픽을 처리할 수 있습니다. 이 접근 방식은 사용자에게 가장 가까운 데이터 센터에서 서비스를 제공하여 지연을 최소화하고 응답 시간을 개선하며 높은 가용성을 보장합니다. 또한, 중복성을 제공하므로 한 지역에서 문제가 발생하더라도 다른 지역이 계속해서 사용자에게 서비스를 제공할 수 있어 트래픽 급증 동안 플랫폼의 전반적인 성능을 유지합니다.",
        "Other Options": [
            "강력한 서버가 있는 단일 데이터 센터를 사용하는 것은 높은 트래픽 급증을 효과적으로 처리하지 못합니다. 이는 단일 실패 지점을 생성하고 해당 데이터 센터에서 멀리 떨어진 사용자에게 지연을 증가시킬 수 있습니다. 이 접근 방식은 확장성을 제한하고 중복성을 제공하지 않습니다.",
            "데이터베이스 수준에서 데이터 캐싱만 의존하는 것은 성능을 개선할 수 있지만, 서로 다른 지역에서의 높은 트래픽 볼륨 문제를 해결하지 못합니다. 캐싱은 데이터베이스의 부하를 줄일 수 있지만, 애플리케이션 서버나 네트워크 인프라가 들어오는 트래픽을 처리할 수 없다면 사용자들은 여전히 지연이나 중단을 경험할 수 있습니다.",
            "주 애플리케이션 서버에 CPU와 메모리를 추가하는 것은 일시적인 성능 향상을 제공할 수 있지만, 서버에서 멀리 떨어진 사용자에 대한 확장성과 지연 문제의 근본적인 해결책이 되지 않습니다. 이 접근 방식은 수익 감소로 이어질 수 있으며, 글로벌 트래픽 급증을 효과적으로 관리하기 위해 필요한 지리적 분산을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "6",
        "Situation": "한 회사가 AWS에서 미션 크리티컬 애플리케이션을 배포하고 있으며, 인프라 장애 발생 시 높은 가용성과 빠른 복구를 보장하고자 합니다. 이들은 다운타임을 최소화하기 위해 다양한 장애 조치 전략을 고려하고 있습니다.",
        "Question": "다음 중 서비스 가용성을 최소한의 다운타임으로 유지하는 데 가장 적합한 장애 조치 전략은 무엇입니까? (두 가지 선택하십시오.)",
        "Options": {
            "1": "여러 가용 영역에서 활성-활성 장애 조치 전략을 사용하여 트래픽이 자동으로 건강한 리소스로 라우팅되도록 합니다.",
            "2": "주기적으로 애플리케이션 상태를 백업하고 장애 발생 시 이를 복원하는 백업 및 복원 전략을 사용합니다.",
            "3": "소규모 리소스만 백업 지역에서 실행되는 웜 스탠바이 장애 조치 전략을 사용하며, 필요할 때 전체 용량을 확장합니다.",
            "4": "최소한의 인프라가 보조 지역에서 실행되는 파일럿 라이트 장애 조치 전략을 사용하며, 장애가 발생할 때만 리소스를 확장합니다.",
            "5": "장애가 발생할 때까지 백업 지역에서 아무 리소스도 실행되지 않는 콜드 스탠바이 장애 조치 전략을 구현한 후, 리소스를 완전히 배포합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "여러 가용 영역에서 활성-활성 장애 조치 전략을 사용하여 트래픽이 자동으로 건강한 리소스로 라우팅되도록 합니다.",
            "소규모 리소스만 백업 지역에서 실행되는 웜 스탠바이 장애 조치 전략을 사용하며, 필요할 때 전체 용량을 확장합니다."
        ],
        "Explanation": "활성-활성 장애 조치 전략은 최소한의 다운타임으로 서비스 가용성을 유지하는 데 매우 효과적인 방법입니다. 이 전략은 여러 가용 영역에서 애플리케이션 인스턴스를 동시에 실행하는 것을 포함합니다. 하나의 인스턴스가 실패하면 트래픽이 자동으로 다른 활성 인스턴스로 라우팅되어 지속적인 서비스 가용성을 보장합니다. 웜 스탠바이 장애 조치 전략 또한 다운타임을 최소화하는 데 도움이 됩니다. 이 전략에서는 항상 백업 지역에서 축소된 버전의 애플리케이션이 실행됩니다. 장애가 발생할 경우 시스템은 신속하게 전체 부하를 처리할 수 있도록 확장하여 사용자에게 경험하는 다운타임을 줄입니다.",
        "Other Options": [
            "백업 및 복원 전략은 데이터 복구에 유용하지만, 최소한의 다운타임으로 서비스 가용성을 유지하는 데 최선의 선택이 아닙니다. 백업에서 복원하는 과정은 시간이 많이 소요될 수 있어 긴 다운타임을 초래할 수 있습니다.",
            "파일럿 라이트 장애 조치 전략은 보조 지역에서 환경의 최소 버전을 유지하는 것입니다. 이 전략은 효과적일 수 있지만, 웜 스탠바이 전략만큼 신속하게 전체 용량으로 확장되지 않을 수 있어 더 긴 다운타임을 초래할 수 있습니다.",
            "콜드 스탠바이 전략은 장애가 발생할 때까지 백업 지역에서 아무 리소스도 실행되지 않는 것입니다. 이 전략은 장애가 발생한 후 리소스를 완전히 배포해야 하므로 가장 긴 다운타임을 초래할 수 있으며, 이는 상당한 시간이 소요될 수 있습니다."
        ]
    },
    {
        "Question Number": "7",
        "Situation": "한 스타트업이 온라인 광고를 위한 실시간 입찰 시스템을 개발하고 있으며, 입찰 처리를 위한 매우 낮은 지연 시간과 높은 처리량이 필요합니다. 이 시스템은 수동 개입 없이도 높은 가용성과 확장성을 가져야 합니다.",
        "Question": "이러한 요구 사항을 충족하기 위해 솔루션 아키텍트가 추천해야 할 AWS 데이터베이스 솔루션은 무엇입니까?",
        "Options": {
            "1": "Amazon RDS for MySQL with provisioned IOPS",
            "2": "Amazon DynamoDB with on-demand capacity mode",
            "3": "Amazon ElastiCache for Redis in a clustered configuration",
            "4": "Amazon Aurora Serverless with in-memory optimization"
        },
        "Correct Answer": "Amazon DynamoDB with on-demand capacity mode",
        "Explanation": "Amazon DynamoDB는 단일 밀리초 응답 시간을 제공하는 완전 관리형 NoSQL 데이터베이스 서비스로, 매우 낮은 지연 시간이 필요한 애플리케이션에 적합합니다. 온디맨드 용량 모드는 데이터베이스가 트래픽에 따라 자동으로 확장 및 축소되도록 하여 수동 개입 없이 높은 처리량을 보장합니다. 이는 입찰 수가 크게 변동할 수 있는 실시간 입찰 시스템에 특히 유리합니다. 또한, DynamoDB는 높은 가용성과 내구성을 위해 설계되어 스타트업 시스템의 요구 사항과 완벽하게 일치합니다.",
        "Other Options": [
            "Amazon RDS for MySQL with provisioned IOPS는 높은 성능을 제공할 수 있는 관계형 데이터베이스 서비스이지만, 고속 워크로드에 대해 DynamoDB와 같은 낮은 지연 시간을 달성하지 못할 수 있습니다. 또한, RDS는 DynamoDB에 비해 확장성과 가용성을 위한 관리가 더 많이 필요합니다.",
            "Amazon ElastiCache for Redis in a clustered configuration은 낮은 지연 시간을 제공할 수 있는 인메모리 데이터 저장소이지만, 주로 캐싱 용도로 사용되며 기본 데이터베이스로는 적합하지 않습니다. 입찰 시스템에 필요한 내구성과 지속성 기능을 본질적으로 제공하지 않습니다.",
            "Amazon Aurora Serverless with in-memory optimization은 자동으로 확장할 수 있는 관계형 데이터베이스이지만, 특히 실시간 입찰 시나리오에서 예측할 수 없는 워크로드 하에서 DynamoDB와 같은 수준의 낮은 지연 시간과 높은 처리량을 제공하지 못할 수 있습니다."
        ]
    },
    {
        "Question Number": "8",
        "Situation": "한 회사가 AWS Lambda 함수를 사용하여 서버리스 애플리케이션을 개발하고 있습니다. 이 애플리케이션은 사용자가 업로드한 이미지를 처리하고 결과를 데이터베이스에 저장해야 합니다. 아키텍처는 동일한 이미지가 여러 번 업로드되더라도 각 이미지가 정확히 한 번만 처리되도록 보장해야 합니다.",
        "Question": "이 요구 사항을 달성하기 위해 솔루션 아키텍트가 사용해야 할 AWS 서비스 조합은 무엇입니까? (두 가지 선택하십시오.)",
        "Options": {
            "1": "Amazon S3",
            "2": "Amazon DynamoDB with conditional writes",
            "3": "Amazon Simple Queue Service (SQS)",
            "4": "Amazon Simple Notification Service (SNS)",
            "5": "AWS Step Functions"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon S3",
            "Amazon DynamoDB with conditional writes"
        ],
        "Explanation": "Amazon S3는 사용자가 업로드한 이미지를 저장하는 데 사용할 수 있습니다. 새로운 이미지가 업로드될 때 AWS Lambda 함수를 트리거하여 이미지를 처리할 수 있습니다. Amazon DynamoDB with conditional writes는 이미지 처리 결과를 저장하는 데 사용할 수 있습니다. 조건부 쓰기는 지정된 조건이 충족될 때만 항목이 테이블에 기록되도록 보장합니다. 이 경우 조건은 이미지가 이전에 처리되지 않았다는 것이며, 이를 통해 각 이미지가 정확히 한 번만 처리되도록 합니다.",
        "Other Options": [
            "Amazon Simple Queue Service (SQS)는 마이크로서비스, 분산 시스템 및 서버리스 애플리케이션을 분리하고 확장할 수 있도록 하는 완전 관리형 메시지 큐 서비스입니다. 그러나 동일한 메시지가 여러 번 처리되는 것을 본질적으로 방지하지는 않습니다.",
            "Amazon Simple Notification Service (SNS)는 애플리케이션 간(A2A) 및 애플리케이션-사람(A2P) 통신을 위한 완전 관리형 메시징 서비스입니다. 그러나 동일한 메시지가 여러 번 처리되는 것을 본질적으로 방지하지는 않습니다.",
            "AWS Step Functions는 여러 AWS 서비스를 서버리스 워크플로로 조정할 수 있는 서버리스 워크플로 서비스입니다. AWS Lambda 함수를 조정하는 데 사용할 수 있지만, 동일한 입력에 대해 동일한 함수가 여러 번 실행되는 것을 본질적으로 방지하지는 않습니다."
        ]
    },
    {
        "Question Number": "9",
        "Situation": "한 회사가 EC2 인스턴스를 위한 Auto Scaling 그룹을 설정하고 있으며, 전체 설정을 재생성하지 않고도 구성을 업데이트할 수 있도록 하기를 원합니다.",
        "Question": "어떤 옵션을 선택해야 하며, 그 이유는 무엇입니까?",
        "Options": {
            "1": "버전 관리를 지원하고 재생성 없이 업데이트를 허용하므로 Launch Configurations를 사용합니다.",
            "2": "버전 관리를 지원하여 새 템플릿을 만들지 않고도 구성 업데이트를 허용하므로 Launch Templates를 사용합니다.",
            "3": "관리하기 쉽고 내장된 버전 관리 기능이 있으므로 Launch Configurations를 사용합니다.",
            "4": "버전 관리 없이 Auto Scaling 그룹 내에서 직접 라이브 업데이트를 지원하므로 Launch Templates를 사용합니다."
        },
        "Correct Answer": "버전 관리를 지원하여 새 템플릿을 만들지 않고도 구성 업데이트를 허용하므로 Launch Templates를 사용합니다.",
        "Explanation": "Launch Templates는 AWS에서 Auto Scaling 그룹을 설정하는 데 권장되는 옵션입니다. 버전 관리를 지원하므로 구성을 업데이트해야 할 때 전체 설정을 재생성하지 않고도 Launch Template의 새 버전을 만들 수 있습니다. 이 기능은 시간이 지남에 따라 구성을 더 유연하고 쉽게 관리할 수 있게 하여 빈번한 업데이트나 변경이 필요한 환경에 이상적입니다.",
        "Other Options": [
            "버전 관리를 지원하고 재생성 없이 업데이트를 허용하므로 Launch Configurations를 사용합니다. - 이 옵션은 Launch Configurations가 버전 관리를 지원하지 않기 때문에 잘못된 것입니다. Launch Configuration이 생성되면 수정할 수 없으며, 업데이트하려면 새 Launch Configuration을 생성해야 합니다.",
            "관리하기 쉽고 내장된 버전 관리 기능이 있으므로 Launch Configurations를 사용합니다. - 이 옵션은 Launch Configurations가 내장된 버전 관리 기능이 없기 때문에 잘못된 것입니다. 이들은 Launch Templates보다 유연성이 떨어져 업데이트가 필요할 때 관리 오버헤드가 더 많을 수 있습니다.",
            "버전 관리 없이 Auto Scaling 그룹 내에서 직접 라이브 업데이트를 지원하므로 Launch Templates를 사용합니다. - 이 옵션은 오해의 소지가 있습니다. Launch Templates는 버전 관리를 지원하지만, Auto Scaling 그룹 내에서 직접 라이브 업데이트를 지원하지 않습니다. 업데이트는 새 버전을 생성해야 하며, 이는 새 인스턴스에 사용됩니다."
        ]
    },
    {
        "Question Number": "10",
        "Situation": "한 의료 애플리케이션은 초당 수백만 개의 요청을 처리해야 하며, 효율적인 처리를 위해 여러 Amazon EC2 인스턴스에 수신 트래픽을 분산해야 합니다. 규정 준수 요구 사항으로 인해 애플리케이션은 안전한 데이터 전송을 위해 종단 간 암호화를 지원해야 합니다. 또한, 애플리케이션은 시간에 민감한 의료 데이터를 처리할 때 초저 지연으로 작동해야 합니다.",
        "Question": "이러한 요구 사항을 가장 잘 충족하는 AWS 로드 밸런싱 솔루션은 무엇입니까?",
        "Options": {
            "1": "SSL 종료가 있는 Application Load Balancer (ALB)",
            "2": "TCP 및 TLS 리스너가 있는 Network Load Balancer (NLB)",
            "3": "HTTP 및 HTTPS 리스너가 있는 Classic Load Balancer",
            "4": "HTTPS 캐싱이 있는 Amazon CloudFront"
        },
        "Correct Answer": "TCP 및 TLS 리스너가 있는 Network Load Balancer (NLB)",
        "Explanation": "Network Load Balancer (NLB)는 초당 수백만 개의 요청을 처리하면서 초저 지연을 유지하도록 설계되어 있어 시간에 민감한 의료 데이터 처리에 적합합니다. NLB는 전송 계층(계층 4)에서 작동하며 여러 EC2 인스턴스에 TCP 트래픽을 효율적으로 분산할 수 있습니다. 또한, NLB는 TLS 리스너를 지원하여 종단 간 암호화를 가능하게 하여 안전한 데이터 전송을 위한 규정 준수 요구 사항을 충족합니다. 높은 처리량, 낮은 지연 시간 및 암호화 지원의 조합은 이 의료 애플리케이션에 가장 적합한 선택입니다.",
        "Other Options": [
            "SSL 종료가 있는 Application Load Balancer (ALB)는 주로 HTTP/HTTPS 트래픽을 위해 설계되었으며, 계층 7에서 작동합니다. SSL 종료를 지원하지만, 애플리케이션 계층에서 처리되기 때문에 추가적인 지연을 초래할 수 있어 초저 지연 요구 사항에는 적합하지 않습니다.",
            "HTTP 및 HTTPS 리스너가 있는 Classic Load Balancer는 NLB와 같은 성능 및 확장성을 제공하지 않는 오래된 옵션입니다. 계층 4와 계층 7 모두에서 작동하지만, NLB에서 제공하는 고급 기능과 최적화가 부족하여 초당 수백만 개의 요청을 효율적으로 처리하는 데 적합하지 않습니다.",
            "HTTPS 캐싱이 있는 Amazon CloudFront는 엣지 위치에서 콘텐츠를 캐시할 수 있는 콘텐츠 전송 네트워크(CDN)로, 정적 콘텐츠 전송에 유리합니다. 그러나 이는 로드 밸런서가 아니며 EC2 인스턴스 간에 트래픽을 직접 분산하지 않으므로 의료 데이터 처리를 위한 수신 트래픽 분산 요구 사항에 적합하지 않습니다."
        ]
    },
    {
        "Question Number": "11",
        "Situation": "글로벌 전자상거래 회사는 웹사이트의 높은 가용성과 내결함성을 보장하기 위해 트래픽을 여러 지역으로 분산시키고자 합니다. 기본 지역이 사용할 수 없게 될 경우 자동으로 백업 지역으로 장애 조치를 원합니다.",
        "Question": "회사가 탄력적인 DNS 장애 조치를 달성하기 위해 어떤 Amazon Route 53 구성을 사용해야 하며, 이 기능을 가능하게 하는 기능은 무엇입니까?",
        "Options": {
            "1": "Route 53 가중 라우팅을 사용하여 정의된 가중치에 따라 지역 간 트래픽을 분산시키고 장애 조치를 위한 상태 검사를 설정합니다.",
            "2": "Route 53 지연 기반 라우팅을 사용하여 사용자들을 가장 낮은 지연 시간을 가진 지역으로 라우팅하고, 필요 시 다른 지역으로 장애 조치를 위한 상태 검사를 설정합니다.",
            "3": "Route 53 지리적 라우팅을 사용하여 사용자 위치에 따라 트래픽을 유도하고, 지역이 실패할 경우 사용자를 리디렉션하기 위한 상태 검사를 설정합니다.",
            "4": "Route 53 장애 조치 라우팅을 사용하여 기본 지역으로 트래픽을 라우팅하고 실패 시 자동으로 보조 지역으로 리디렉션하며, 기본 지역의 가용성을 모니터링하기 위해 상태 검사를 사용합니다."
        },
        "Correct Answer": "Route 53 장애 조치 라우팅을 사용하여 기본 지역으로 트래픽을 라우팅하고 실패 시 자동으로 보조 지역으로 리디렉션하며, 기본 지역의 가용성을 모니터링하기 위해 상태 검사를 사용합니다.",
        "Explanation": "Route 53 장애 조치 라우팅은 높은 가용성이 중요한 시나리오를 위해 특별히 설계되었습니다. 이를 통해 기본 리소스(이 경우 기본 지역)와 보조 리소스(백업 지역)를 지정할 수 있습니다. 상태 검사가 기본 지역이 사용할 수 없다고 판단하면 Route 53은 자동으로 트래픽을 보조 지역으로 리디렉션합니다. 이 설정은 사용자가 최소한의 중단을 경험하고 웹사이트가 한 지역이 실패하더라도 계속 접근 가능하도록 보장합니다.",
        "Other Options": [
            "Route 53 가중 라우팅을 사용하면 정의된 가중치에 따라 트래픽을 분산시킬 수 있지만, 본질적으로 자동 장애 조치를 제공하지 않습니다. 상태 검사를 설정할 수 있지만, 이 옵션은 장애 조치 시나리오를 위해 특별히 설계되지 않았으므로 회사의 요구에 덜 적합합니다.",
            "Route 53 지연 기반 라우팅은 사용자들을 가장 낮은 지연 시간을 가진 지역으로 유도하지만, 간단한 장애 조치 메커니즘을 제공하지 않습니다. 상태 검사를 구현할 수 있지만, 이 옵션은 장애 발생 시 가용성을 보장하기보다는 사용자 경험 최적화에 주로 초점을 맞추고 있습니다.",
            "Route 53 지리적 라우팅은 사용자 위치에 따라 트래픽을 유도하지만, 자동 장애 조치 기능을 제공하지 않습니다. 상태 검사를 설정할 수 있지만, 이 라우팅 방법은 장애 조치 라우팅이 제공하는 것과 같은 방식으로 가용성을 우선시하지 않습니다."
        ]
    },
    {
        "Question Number": "12",
        "Situation": "한 회사가 사용자 업로드를 처리하고 이를 특정 형식으로 변환하는 서버리스 애플리케이션을 설계하고 있습니다. 이 애플리케이션은 변동하는 트래픽에 맞춰 자동으로 확장되어야 하며, 여러 파일 업로드를 동시에 처리해야 합니다. 회사는 서버와 인프라 관리를 피하면서 변환 프로세스가 빠르고 신뢰성 있게 완료되기를 원합니다.",
        "Question": "회사가 이 솔루션을 구현하기 위해 어떤 AWS 서비스를 사용해야 합니까? (두 가지 선택)",
        "Options": {
            "1": "AWS Lambda를 사용하여 파일이 Amazon S3에 업로드될 때 처리 기능을 트리거하고, Amazon SQS를 사용하여 변환 작업을 큐에 추가합니다.",
            "2": "AWS Fargate를 사용하여 컨테이너화된 처리 작업을 실행하고, 업로드 수에 따라 자동으로 확장합니다.",
            "3": "Amazon EC2를 사용하여 인프라를 관리하고 파일을 수동으로 처리합니다.",
            "4": "Amazon S3 이벤트 알림을 사용하여 업로드된 각 파일을 처리하기 위해 AWS Lambda 함수를 트리거합니다.",
            "5": "Amazon S3를 사용하여 업로드를 직접 처리하고 추가 기능이나 서비스를 트리거할 필요가 없습니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "AWS Lambda를 사용하여 파일이 Amazon S3에 업로드될 때 처리 기능을 트리거하고, Amazon SQS를 사용하여 변환 작업을 큐에 추가합니다.",
            "Amazon S3 이벤트 알림을 사용하여 업로드된 각 파일을 처리하기 위해 AWS Lambda 함수를 트리거합니다."
        ],
        "Explanation": "AWS Lambda는 Amazon S3 버킷의 데이터 변경과 같은 이벤트에 응답하여 코드를 실행하는 서버리스 컴퓨팅 서비스입니다. 이를 통해 회사는 서버를 관리하지 않고 사용자 업로드를 처리하고 특정 형식으로 변환할 수 있는 요구 사항을 충족할 수 있습니다. Amazon SQS는 마이크로서비스, 분산 시스템 및 서버리스 애플리케이션을 분리하고 확장할 수 있게 해주는 완전 관리형 메시지 큐 서비스입니다. SQS는 메시지 지향 미들웨어 관리 및 운영과 관련된 복잡성과 오버헤드를 제거하고 개발자가 차별화된 작업에 집중할 수 있도록 합니다. AWS Lambda와 함께 Amazon S3 이벤트 알림을 사용하면 파일이 업로드된 직후 처리 기능을 즉시 트리거할 수 있어 빠르고 신뢰성 있는 변환 요구 사항을 충족합니다.",
        "Other Options": [
            "AWS Fargate는 컨테이너를 위한 서버리스 컴퓨팅 엔진입니다. 자동 확장을 허용하지만, 이 특정 사용 사례에 대해 AWS Lambda를 사용하는 것보다 더 복잡하고 덜 직접적입니다. 또한 회사가 피하고자 하는 컨테이너화된 애플리케이션 관리를 요구합니다.",
            "Amazon EC2는 클라우드에서 크기를 조정할 수 있는 컴퓨팅 용량을 제공하는 웹 서비스입니다. 웹 규모의 클라우드 컴퓨팅을 쉽게 만들기 위해 설계되었지만, 회사가 피하고자 하는 인프라의 수동 관리가 필요합니다.",
            "Amazon S3는 저장 서비스로, 업로드를 직접 처리하거나 특정 형식으로 변환할 수 있는 기능이 없습니다. 데이터를 저장하고 검색할 수 있지만, 해당 데이터에 대한 계산이나 변환을 수행할 수 없습니다."
        ]
    },
    {
        "Question Number": "13",
        "Situation": "한 회사가 전자상거래 애플리케이션을 개발하고 있으며, 고객 주문, 결제 처리 및 재고 업데이트를 처리하기 위해 이벤트 기반 아키텍처를 구현해야 합니다. 시스템이 높은 가용성, 확장성 및 분리성을 보장하기를 원합니다.",
        "Question": "회사가 이러한 목표를 달성하기 위해 어떤 아키텍처를 사용해야 합니까?",
        "Options": {
            "1": "Amazon SQS를 사용하여 서비스를 분리하고 이벤트의 비동기 처리를 보장합니다. AWS Lambda를 사용하여 이벤트를 처리하고, Amazon SNS를 사용하여 여러 구독자에게 효율적인 알림을 위해 이벤트를 방송합니다.",
            "2": "메시지 큐가 있는 Amazon EC2 인스턴스를 사용하여 각 EC2 인스턴스가 이벤트를 처리하고 Amazon RDS 데이터베이스에 업데이트를 보냅니다.",
            "3": "Amazon DynamoDB Streams를 사용하여 이벤트 데이터를 캡처하고, AWS Step Functions를 구성하여 이벤트 처리를 위한 워크플로를 조정합니다.",
            "4": "Amazon S3를 사용하여 이벤트 데이터를 저장하고, EC2 인스턴스를 설정하여 새로운 이벤트를 처리하기 위해 S3 버킷을 폴링합니다."
        },
        "Correct Answer": "Amazon SQS를 사용하여 서비스를 분리하고 이벤트의 비동기 처리를 보장합니다. AWS Lambda를 사용하여 이벤트를 처리하고, Amazon SNS를 사용하여 여러 구독자에게 효율적인 알림을 위해 이벤트를 방송합니다.",
        "Explanation": "이 옵션은 높은 가용성, 확장성 및 분리성을 갖춘 이벤트 기반 아키텍처를 효과적으로 구현합니다. Amazon SQS(단순 큐 서비스)는 서비스 간 비동기 통신을 허용하여 서비스를 분리하는 데 도움을 줍니다. AWS Lambda는 서버를 관리할 필요 없이 이벤트를 처리할 수 있어, 들어오는 이벤트 수에 따라 자동으로 확장할 수 있습니다. 또한, Amazon SNS(단순 알림 서비스)는 여러 구독자에게 메시지를 방송할 수 있어 애플리케이션의 다양한 구성 요소가 이벤트에 효율적으로 반응할 수 있도록 합니다. 이 조합은 고객 주문, 결제 처리 및 재고 업데이트를 확장 가능한 방식으로 처리하기 위한 강력한 솔루션을 제공합니다.",
        "Other Options": [
            "메시지 큐가 있는 Amazon EC2 인스턴스를 사용하는 것은 더 많은 복잡성과 관리 오버헤드를 도입합니다. EC2 인스턴스는 프로비저닝, 확장 및 유지 관리가 필요하여 높은 가용성과 확장 가능한 아키텍처를 목표로 하는 것과 모순됩니다. 또한, 이 옵션은 서버리스 기능을 활용하지 않으므로 자원 활용의 비효율성을 초래할 수 있습니다.",
            "Amazon DynamoDB Streams와 AWS Step Functions를 사용하는 것은 실행 가능한 옵션이지만 첫 번째 옵션만큼 간단하지 않을 수 있습니다. DynamoDB Streams는 데이터베이스의 변경 사항을 캡처할 수 있지만 추가 구성 및 관리가 필요합니다. AWS Step Functions는 워크플로 조정에 유용하지만, SQS와 Lambda를 사용하는 직접적인 이벤트 기반 접근 방식에 비해 간단한 이벤트 처리 작업에 불필요한 복잡성을 더할 수 있습니다.",
            "Amazon S3를 사용하여 이벤트 데이터를 저장하고 EC2 인스턴스를 폴링하여 새로운 이벤트를 처리하는 것은 이벤트 기반 아키텍처에 이상적인 솔루션이 아닙니다. 폴링은 지연을 초래하고 비효율성을 유발할 수 있으며, 시스템이 이벤트를 처리하기 위해 대기하게 되어 실시간으로 반응하지 못하게 됩니다. 이 접근 방식은 메시지 큐와 서버리스 기능이 제공하는 분리 및 확장성 이점을 결여하고 있습니다."
        ]
    },
    {
        "Question Number": "14",
        "Situation": "대규모 전자상거래 플랫폼은 특히 세일 이벤트 동안 높은 트래픽을 경험하여 데이터베이스 연결 수가 크게 증가합니다. 데이터베이스 성능을 최적화하고 과부하를 방지하기 위해, 이들은 프록시 서비스를 사용하여 이러한 연결을 효율적으로 관리하기로 결정했습니다.",
        "Question": "데이터베이스 연결을 효율적으로 처리하기 위해 어떤 AWS 서비스를 구현해야 하며, 확장성과 장애 조치 측면에서 어떤 이점을 제공합니까?",
        "Options": {
            "1": "Amazon RDS Proxy를 사용하여 데이터베이스 연결을 풀링하고 공유하여 데이터베이스의 오버헤드를 줄이고 애플리케이션 확장성을 개선합니다.",
            "2": "AWS App Mesh는 서비스 간 통신을 관리하지만 데이터베이스 연결 처리에 전문화되어 있지 않습니다.",
            "3": "Amazon API Gateway는 API 요청을 위한 프록시를 제공하지만, 주로 RESTful API를 위해 설계되었으며 데이터베이스 연결을 위한 것이 아닙니다.",
            "4": "AWS Direct Connect는 전용 네트워크 연결을 제공하지만 데이터베이스 연결을 관리하거나 풀링하지 않습니다."
        },
        "Correct Answer": "Amazon RDS Proxy를 사용하여 데이터베이스 연결을 풀링하고 공유하여 데이터베이스의 오버헤드를 줄이고 애플리케이션 확장성을 개선합니다.",
        "Explanation": "Amazon RDS Proxy는 데이터베이스 연결을 효율적으로 관리하기 위해 특별히 설계되었습니다. 데이터베이스에 대한 연결을 풀링하고 공유하여 열린 연결 수와 데이터베이스 서버에 대한 오버헤드를 줄입니다. 이는 세일 이벤트와 같은 높은 트래픽 기간 동안 특히 유용하며, 애플리케이션이 데이터베이스를 압도하지 않고 더 효과적으로 확장할 수 있게 합니다. 또한, RDS Proxy는 장애 조치 기능을 제공하여 애플리케이션이 장애 발생 시 자동으로 대기 데이터베이스에 재연결할 수 있도록 하여 가용성과 신뢰성을 향상시킵니다.",
        "Other Options": [
            "AWS App Mesh는 서비스 간 통신을 관리하는 서비스 메쉬이지만 데이터베이스 연결 처리에 전문화되어 있지 않습니다. 마이크로서비스 간 통신에 초점을 맞추고 있습니다.",
            "Amazon API Gateway는 모든 규모의 API를 생성, 게시, 유지 관리, 모니터링 및 보호하기 위해 설계되었습니다. API 요청을 위한 프록시 역할을 하지만 데이터베이스 연결을 관리하기 위한 것이 아닙니다. 이는 이 시나리오의 주요 요구 사항입니다.",
            "AWS Direct Connect는 귀하의 시설에서 AWS로의 전용 네트워크 연결을 제공하여 대역폭을 개선하고 지연을 줄일 수 있습니다. 그러나 데이터베이스 연결을 관리하거나 풀링하지 않으므로 높은 트래픽 동안 데이터베이스 성능을 최적화하기 위한 특정 요구 사항에는 적합하지 않습니다."
        ]
    },
    {
        "Question Number": "15",
        "Situation": "한 생명공학 회사는 DNA 시퀀싱을 위한 컴퓨팅 집약적인 작업을 수행하며, 하루에 몇 시간만 컴퓨팅 리소스가 필요합니다. 이들은 비용을 최소화하면서 작업이 이러한 시간 창 내에 완료될 수 있도록 하기를 원합니다.",
        "Question": "이 작업 부하에 대한 비용을 최적화하기 위해 어떤 구매 옵션이 가장 적합합니까?",
        "Options": {
            "1": "1년 약정의 예약 인스턴스",
            "2": "3년 약정의 절약 계획",
            "3": "용량 최적화 할당의 스팟 인스턴스",
            "4": "예약된 자동 확장을 가진 온디맨드 인스턴스"
        },
        "Correct Answer": "용량 최적화 할당의 스팟 인스턴스",
        "Explanation": "스팟 인스턴스는 사용자가 온디맨드 또는 예약 인스턴스에 비해 상당히 낮은 가격으로 사용하지 않는 컴퓨팅 용량을 활용할 수 있게 해줍니다. 생명공학 회사는 하루에 몇 시간만 컴퓨팅 리소스가 필요하므로, 스팟 인스턴스를 사용하면 비용을 크게 줄일 수 있습니다. 특히 중단을 감내할 수 있다면 더욱 그렇습니다. 용량 최적화 할당은 스팟 인스턴스가 필요할 때 더 많이 사용 가능하도록 보장하므로, 특정 시간 창 내에 수행해야 하는 컴퓨팅 집약적인 작업에 적합한 선택입니다.",
        "Other Options": [
            "1년 약정의 예약 인스턴스는 하루에 몇 시간만 필요한 작업 부하에 대해 비용 효율적이지 않습니다. 사용량에 관계없이 용량에 대한 비용을 지불해야 하는 약정이 필요합니다.",
            "3년 약정의 절약 계획도 작업 부하의 간헐적인 특성과 일치하지 않는 장기 재정 약정을 포함하므로 자원과 비용이 낭비될 수 있습니다.",
            "예약된 자동 확장을 가진 온디맨드 인스턴스는 유연성을 제공하지만 일반적으로 스팟 인스턴스보다 더 비쌉니다. 특히 간헐적으로 실행할 수 있는 작업 부하에 대해 동일한 수준의 비용 절감을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "16",
        "Situation": "한 금융 서비스 회사가 클라이언트 장치와 백엔드 서버 간의 원활하고 지속적인 암호화를 요구하는 새로운 애플리케이션을 구현하고 있습니다. 또한, 애플리케이션은 보안을 강화하기 위해 IP 화이트리스트를 용이하게 하기 위해 정적 IP 주소를 사용해야 합니다.",
        "Question": "회사가 이러한 요구 사항을 충족하기 위해 배포해야 하는 AWS 로드 밸런서의 유형은 무엇이며, 이 선택의 주요 이유는 무엇인가요?",
        "Options": {
            "1": "Application Load Balancer (ALB)는 콘텐츠 기반 라우팅을 수행하고 SSL 종료를 처리할 수 있습니다.",
            "2": "Network Load Balancer (NLB)는 Layer 4에서 작동하며 정적 IP 주소를 지원하고 TCP 포워딩을 통해 종단 간 암호화를 유지할 수 있습니다.",
            "3": "Classic Load Balancer (CLB)는 HTTPS를 지원하고 안전한 연결을 위한 스티키 세션을 관리할 수 있습니다.",
            "4": "Application Load Balancer (ALB)는 정적 IP 주소를 제공하고 높은 처리량을 보장합니다."
        },
        "Correct Answer": "Network Load Balancer (NLB)는 Layer 4에서 작동하며 정적 IP 주소를 지원하고 TCP 포워딩을 통해 종단 간 암호화를 유지할 수 있습니다.",
        "Explanation": "Network Load Balancer (NLB)는 OSI 모델의 Layer 4에서 작동하여 TCP 트래픽을 효율적으로 처리할 수 있도록 설계되었습니다. 정적 IP 주소를 지원하여 IP 화이트리스트 요구 사항을 충족합니다. 또한, NLB는 TCP 트래픽을 복호화하지 않고 포워딩하여 종단 간 암호화를 유지할 수 있어 클라이언트 장치와 백엔드 서버 간의 데이터가 안전하게 유지됩니다. 이는 원활하고 지속적인 암호화의 필요성과 완벽하게 일치합니다.",
        "Other Options": [
            "Application Load Balancer (ALB)는 주로 Layer 7 (애플리케이션 레이어) 트래픽을 위해 설계되었으며 콘텐츠 기반 라우팅과 SSL 종료에 뛰어납니다. 그러나 이 경우에는 정적 IP 주소를 기본적으로 지원하지 않으므로 중요한 요구 사항을 충족하지 못합니다.",
            "Classic Load Balancer (CLB)는 HTTPS를 지원하고 스티키 세션을 관리할 수 있지만 Layer 4와 Layer 7 모두에서 작동합니다. 정적 IP 주소를 제공할 수 없으며, 일반적으로 높은 처리량 시나리오에서 NLB보다 효율성이 떨어져 요구 사항에 적합하지 않습니다.",
            "Application Load Balancer (ALB)는 IP 화이트리스트를 위한 주요 요구 사항인 정적 IP 주소를 직접 제공하지 않습니다. 높은 처리량과 고급 라우팅 기능을 제공하지만 NLB만큼 효과적으로 종단 간 암호화를 유지할 수 없습니다."
        ]
    },
    {
        "Question Number": "17",
        "Situation": "한 의료 제공자가 중단 없는 서비스를 보장하고 중요한 환자 데이터를 보호하기 위해 애플리케이션을 설계하고 있습니다. 애플리케이션은 구성 요소 실패에도 불구하고 작동해야 하며, 재해 발생 시 중요한 데이터를 복구할 수 있는 전략도 필요합니다.",
        "Question": "다음 중 이러한 요구 사항을 가장 잘 충족하는 접근 방식은 무엇인가요? (두 가지 선택)",
        "Options": {
            "1": "여러 가용 영역에 리소스를 배포하여 고가용성을 구현하여 구성 요소 실패 시 최소한의 다운타임과 빠른 복구를 보장합니다.",
            "2": "여러 서버에 활성-활성 모드로 리소스를 구성하여 하나의 구성 요소가 실패하더라도 애플리케이션이 중단 없이 계속 작동하도록 하는 내결함성을 중점적으로 둡니다.",
            "3": "정기적인 백업을 예약하고 별도의 지역에 대기 서버를 설정하여 재해 발생 시 애플리케이션을 복원할 수 있도록 재해 복구(DR) 계획을 개발합니다.",
            "4": "여러 가용 영역에 배포하고 정기적인 백업을 예약하여 고가용성과 재해 복구를 결합하여 모든 실패나 재해 동안 가동 시간을 유지하고 데이터를 보호합니다.",
            "5": "서버 실패 시 데이터 복구를 보장하기 위해 자동화된 스냅샷을 사용하여 단일 가용 영역 배포를 사용합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "여러 가용 영역에 리소스를 배포하여 고가용성을 구현하여 구성 요소 실패 시 최소한의 다운타임과 빠른 복구를 보장합니다.",
            "여러 가용 영역에 배포하고 정기적인 백업을 예약하여 고가용성과 재해 복구를 결합하여 모든 실패나 재해 동안 가동 시간을 유지하고 데이터를 보호합니다."
        ],
        "Explanation": "첫 번째 정답은 고가용성을 구현하는 것입니다. 이 접근 방식은 하나 이상의 구성 요소가 실패하더라도 애플리케이션이 계속 작동하도록 보장합니다. 여러 가용 영역에 리소스를 배포함으로써 구성 요소 실패 시 최소한의 다운타임으로 애플리케이션이 계속 작동하고 더 빠르게 복구할 수 있습니다. 두 번째 정답은 고가용성과 재해 복구를 결합하는 것입니다. 이 접근 방식은 구성 요소 실패 시 애플리케이션의 가동 시간을 보장할 뿐만 아니라 정기적인 백업을 예약하여 중요한 환자 데이터를 보호합니다. 재해 발생 시 데이터 복구가 가능하여 애플리케이션의 연속성을 보장합니다.",
        "Other Options": [
            "여러 서버에 활성-활성 모드로 리소스를 구성하여 내결함성을 중점적으로 두는 것은 충분하지 않습니다. 하나의 구성 요소가 실패하더라도 애플리케이션이 중단 없이 계속 작동하도록 보장하지만, 재해 발생 시 데이터 복구 전략을 제공하지 않습니다.",
            "정기적인 백업을 예약하고 별도의 지역에 대기 서버를 설정하여 재해 복구(DR) 계획을 개발하는 것은 데이터 복구를 위한 좋은 전략입니다. 그러나 구성 요소 실패 시 애플리케이션의 중단 없는 서비스를 보장하지는 않습니다.",
            "서버 실패 시 데이터 복구를 보장하기 위해 자동화된 스냅샷을 사용하여 단일 가용 영역 배포를 사용하는 것은 데이터 복구를 보장할 수 있지만, 단일 가용 영역의 실패는 애플리케이션 다운타임으로 이어질 수 있어 고가용성이나 내결함성을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "18",
        "Situation": "한 금융 거래 플랫폼이 Amazon EC2 인스턴스에서 호스팅되고 있으며 지연에 민감한 고빈도 데이터베이스를 위해 매우 높은 IOPS(초당 입출력 작업)를 지원할 수 있는 EBS 볼륨이 필요합니다. 이 플랫폼은 최적의 성능을 위해 최대 250,000 IOPS와 높은 처리량이 필요합니다.",
        "Question": "어떤 EBS 볼륨 유형이 이러한 요구 사항을 가장 잘 충족할까요?",
        "Options": {
            "1": "General Purpose SSD (gp3)",
            "2": "Provisioned IOPS SSD (io2)",
            "3": "Throughput Optimized HDD (st1)",
            "4": "Cold HDD (sc1)"
        },
        "Correct Answer": "Provisioned IOPS SSD (io2)",
        "Explanation": "Provisioned IOPS SSD (io2) 볼륨 유형은 높은 성능과 낮은 지연이 필요한 I/O 집약적인 애플리케이션을 위해 특별히 설계되었습니다. 이 볼륨은 최대 256,000 IOPS를 지원할 수 있어 금융 거래 플랫폼의 최대 250,000 IOPS 요구 사항에 적합합니다. 또한, io2 볼륨은 높은 처리량을 제공하며 지연에 민감한 작업에 최적화되어 있어 고빈도 데이터베이스에 가장 적합한 선택입니다.",
        "Other Options": [
            "General Purpose SSD (gp3) 볼륨은 최대 16,000 IOPS를 제공할 수 있으며 다양한 작업에 적합하지만, 이 특정 애플리케이션에 필요한 250,000 IOPS 요구 사항을 충족하지 않습니다.",
            "Throughput Optimized HDD (st1) 볼륨은 높은 IOPS보다 높은 처리량이 필요한 작업을 위해 설계되었습니다. 이 볼륨은 최대 500 IOPS만 제공할 수 있어 고빈도 데이터베이스와 같은 지연에 민감한 애플리케이션에는 적합하지 않습니다.",
            "Cold HDD (sc1) 볼륨은 자주 접근하지 않는 데이터를 위해 설계되었으며 EBS 볼륨 유형 중 가장 낮은 성능을 제공하며 최대 250 IOPS를 지원합니다. 이는 고성능 및 지연에 민감한 애플리케이션에는 적합하지 않습니다."
        ]
    },
    {
        "Question Number": "19",
        "Situation": "한 금융 기관이 실시간 데이터 처리 및 거래 활동을 지원하기 위해 온프레미스 데이터 센터와 AWS 간의 안정적이고 고대역폭, 저지연 연결이 필요한 미션 크리티컬 애플리케이션을 운영하고 있습니다. 이들은 모든 데이터 전송이 공용 인터넷을 우회하여 안전하고 개인적인 연결을 통해 이루어지도록 하여 잠재적인 보안 위험과 성능 변동성을 방지하고자 합니다.",
        "Question": "어떤 옵션이 이들의 요구 사항을 가장 잘 충족할까요? (두 가지 선택)",
        "Options": {
            "1": "통신 제공업체로부터 AWS로 직접 고속 전용 회선을 사용합니다.",
            "2": "공용 인터넷을 통해 AWS Site-to-Site VPN을 설정합니다.",
            "3": "개인 전용 네트워크 연결을 위해 AWS Direct Connect를 배포합니다.",
            "4": "정기적인 데이터 동기화를 위해 암호화된 파일 전송 프로토콜(FTP)을 설정합니다.",
            "5": "다중 지역 연결을 위해 Direct Connect Gateway와 함께 AWS Transit Gateway를 구현합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "통신 제공업체로부터 AWS로 직접 고속 전용 회선을 사용합니다.",
            "개인 전용 네트워크 연결을 위해 AWS Direct Connect를 배포합니다."
        ],
        "Explanation": "통신 제공업체로부터 AWS로 직접 고속 전용 회선을 사용하고 AWS Direct Connect를 배포하여 개인 전용 네트워크 연결을 제공하는 것은 이 금융 기관에 가장 좋은 옵션입니다. 이러한 옵션은 공용 인터넷을 우회하여 안정적이고 고대역폭, 저지연 연결을 제공하여 기관의 실시간 데이터 처리 및 거래 활동에 필수적입니다. 특히 AWS Direct Connect는 기관의 온프레미스 데이터 센터에서 AWS로의 전용 네트워크 연결을 제공하여 안전하고 신뢰할 수 있는 연결을 보장합니다.",
        "Other Options": [
            "공용 인터넷을 통해 AWS Site-to-Site VPN을 설정하는 것은 최선의 옵션이 아닙니다. 여전히 공용 인터넷을 사용하므로 성능 변동성과 잠재적인 보안 위험이 발생할 수 있습니다.",
            "정기적인 데이터 동기화를 위해 암호화된 파일 전송 프로토콜(FTP)을 설정하는 것은 실시간 데이터 처리 및 거래 활동의 요구 사항을 충족하지 않습니다. 이는 주기적인 데이터 전송을 위해 설계되었습니다.",
            "다중 지역 연결을 위해 Direct Connect Gateway와 함께 AWS Transit Gateway를 구현하는 것은 기관의 요구 사항에 반드시 필요하지 않습니다. 다중 지역 연결을 제공하지만, 실시간 데이터 처리 및 거래 활동에 필요한 고대역폭, 저지연 연결을 본질적으로 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "20",
        "Situation": "비디오 파일을 트랜스코딩하기 위해 처리하는 애플리케이션을 관리하고 있으며 수요가 변동합니다. 탄력적이고 효율적인 처리를 보장하기 위해 Amazon SQS를 메시지 큐잉에 사용하고 Auto Scaling Groups (ASGs)를 작업자 풀에 사용합니다. 그러나 일부 메시지는 가끔 실패하여 시스템 과부하를 피하기 위해 특별한 처리가 필요합니다.",
        "Question": "탄력성을 개선하고 실패한 메시지가 효과적으로 처리되도록 하기 위해 어떤 접근 방식을 구현해야 할까요?",
        "Options": {
            "1": "SQS 내에서 처리에 여러 번 실패한 문제 메시지를 캡처하기 위해 Dead-Letter Queue (DLQ)를 사용합니다.",
            "2": "CPU 사용률이 80%를 초과할 때만 인스턴스를 추가하도록 ASG 스케일링 정책을 구성합니다.",
            "3": "Amazon RDS를 사용하여 실패한 메시지를 저장하고 성공적으로 처리될 때까지 재시도합니다.",
            "4": "메시지가 실패할 때마다 알림을 받기 위해 CloudWatch 경고를 설정하여 수동으로 재처리할 수 있도록 합니다."
        },
        "Correct Answer": "SQS 내에서 처리에 여러 번 실패한 문제 메시지를 캡처하기 위해 Dead-Letter Queue (DLQ)를 사용합니다.",
        "Explanation": "Dead-Letter Queue (DLQ)는 지정된 시도 횟수 이후에도 성공적으로 처리할 수 없는 메시지를 처리하도록 특별히 설계되었습니다. DLQ를 사용하면 이러한 문제 메시지를 격리하여 다른 메시지의 처리를 방해하지 않고 추가 조사를 수행할 수 있습니다. 이 접근 방식은 메시지 처리 실패가 시스템을 압도하는 것을 방지하여 애플리케이션의 탄력성을 개선하고 실패한 메시지를 보다 쉽게 디버깅하고 처리할 수 있게 합니다.",
        "Other Options": [
            "CPU 사용률이 80%를 초과할 때만 인스턴스를 추가하도록 ASG 스케일링 정책을 구성하는 것은 실패한 메시지 처리 문제를 직접적으로 해결하지 않습니다. 리소스 할당 관리는 도와줄 수 있지만, 처리에 실패한 메시지를 처리하는 메커니즘을 제공하지 않으므로 이 시나리오의 핵심 문제를 해결하지 않습니다.",
            "Amazon RDS를 사용하여 실패한 메시지를 저장하고 성공적으로 처리될 때까지 재시도하는 것은 최적의 솔루션이 아닙니다. RDS는 관계형 데이터베이스 서비스이며 메시지 큐잉을 위해 설계되지 않았습니다. 이 접근 방식은 메시지의 상태와 재시도를 관리하기 위한 추가 로직이 필요하므로 불필요한 복잡성과 지연을 초래합니다.",
            "메시지가 실패할 때마다 알림을 받기 위해 CloudWatch 경고를 설정하는 것은 반응적인 접근 방식이 될 것입니다. 실패를 모니터링하는 데 도움이 될 수 있지만, 실패한 메시지를 처리하는 자동화된 방법을 제공하지 않으므로 시스템의 탄력성과 효율성을 유지하는 데 필수적입니다."
        ]
    },
    {
        "Question Number": "21",
        "Situation": "금융 서비스 회사가 클라이언트와 백엔드 인스턴스 간에 빠르고 끊김 없는 암호화가 필요하며, 화이트리스트를 위한 정적 IP를 사용할 수 있는 애플리케이션을 배포하고 있습니다.",
        "Question": "이 시나리오에 가장 적합한 AWS 로드 밸런서 유형은 무엇이며, 그 이유는 무엇인가요?",
        "Options": {
            "1": "Application Load Balancer (ALB), 콘텐츠 기반 라우팅을 허용하고 SSL 종료를 제공하기 때문입니다.",
            "2": "Network Load Balancer (NLB), Layer 4에서 작동하며 정적 IP를 지원하고 TCP 포워딩을 통해 끊김 없는 암호화를 허용하기 때문입니다.",
            "3": "Classic Load Balancer (CLB), HTTPS와 호환되며 안전한 연결을 위한 스티키 세션을 지원하기 때문입니다.",
            "4": "Application Load Balancer (ALB), 정적 IP 주소를 지원하고 높은 처리량을 제공하기 때문입니다."
        },
        "Correct Answer": "Network Load Balancer (NLB), Layer 4에서 작동하며 정적 IP를 지원하고 TCP 포워딩을 통해 끊김 없는 암호화를 허용하기 때문입니다.",
        "Explanation": "Network Load Balancer (NLB)는 OSI 모델의 Layer 4(전송 계층)에서 작동하므로 TCP 트래픽을 직접 처리할 수 있습니다. 이 기능은 클라이언트와 백엔드 인스턴스 간의 끊김 없는 암호화를 유지할 수 있게 해주며, TCP 패킷을 복호화하지 않고 포워딩할 수 있습니다. 또한, NLB는 정적 IP 주소를 지원하여 화이트리스트 용도로 필수적입니다. 이러한 기능의 조합은 정적 IP와 빠르고 안전한 연결이 필요한 애플리케이션에 NLB를 이상적으로 만듭니다.",
        "Other Options": [
            "Application Load Balancer (ALB)는 SSL 종료와 콘텐츠 기반 라우팅을 제공하지만 Layer 7(애플리케이션 계층)에서 작동하므로 트래픽을 복호화하여 끊김 없는 암호화 요구 사항을 깨뜨릴 수 있습니다.",
            "Classic Load Balancer (CLB)는 HTTPS를 지원하지만, NLB와 같은 성능과 기능을 제공하지 않는 구식 기술입니다. 또한 NLB와 같은 방식으로 정적 IP를 지원하지 않습니다.",
            "Application Load Balancer (ALB)는 정적 IP 주소를 지원한다고 잘못 언급되었습니다. ALB는 정적 IP를 직접 제공하지 않으며, 대신 동적 IP를 사용하고 정적 IP 기능을 달성하기 위해 추가 구성이 필요합니다(NLB를 앞에 두는 것과 같은)."
        ]
    },
    {
        "Question Number": "22",
        "Situation": "회사는 \"secretcatproject\"라는 이름의 S3 버킷을 보유하고 있으며, 이 버킷에는 민감한 데이터가 포함되어 있습니다. 회사는 파트너 계정의 특정 사용자에게 이 버킷에 대한 액세스를 허용하면서 데이터가 공개 액세스로부터 안전하게 유지되도록 해야 합니다.",
        "Question": "회사가 필요한 액세스를 부여하면서 익명의 사용자가 무단으로 접근하지 못하도록 하려면 어떤 방법을 사용해야 하나요?",
        "Options": {
            "1": "버킷 정책을 설정하여 모든 사용자가 공개 액세스를 허용하여 액세스 관리를 간소화합니다.",
            "2": "파트너 계정의 IAM 역할을 주체로 지정하고 버킷에 대한 액세스 권한을 부여하는 S3 버킷 정책을 사용합니다.",
            "3": "\"Block Public Access\"를 버킷에서 활성화하고 액세스 제어 목록(ACL)을 사용하여 파트너 계정의 액세스를 관리합니다.",
            "4": "IAM 정책을 버킷에 직접 연결하여 파트너 계정의 사용자에 대한 액세스를 제어합니다."
        },
        "Correct Answer": "파트너 계정의 IAM 역할을 주체로 지정하고 버킷에 대한 액세스 권한을 부여하는 S3 버킷 정책을 사용합니다.",
        "Explanation": "파트너 계정의 IAM 역할을 주체로 지정하는 S3 버킷 정책을 사용하면 버킷에 대한 액세스를 세밀하게 제어할 수 있습니다. 이 방법은 지정된 파트너 계정의 사용자만 민감한 데이터에 접근할 수 있도록 보장하며, 공개 액세스를 방지합니다. 버킷 정책은 권한 관리를 위한 강력한 도구이며 특정 보안 요구 사항을 충족하도록 조정할 수 있어 이 상황에 가장 안전하고 적합한 방법입니다.",
        "Other Options": [
            "버킷 정책을 설정하여 모든 사용자가 공개 액세스를 허용하면 민감한 데이터가 인터넷의 누구에게나 노출되어 데이터 보안을 유지해야 하는 요구 사항에 반합니다.",
            "버킷에서 'Block Public Access'를 활성화하고 액세스 제어 목록(ACL)을 사용하는 것은 액세스를 관리하는 최선의 방법이 아닙니다. 공개 액세스를 방지할 수는 있지만, ACL은 복잡할 수 있으며 특히 크로스 계정 액세스를 처리할 때 버킷 정책보다 관리하기 어려울 수 있습니다. 이 목적을 위해서는 일반적으로 버킷 정책이 선호됩니다.",
            "IAM 정책을 버킷에 직접 연결하는 것은 불가능합니다. IAM 정책은 IAM 사용자, 그룹 또는 역할에 연결되며 S3 버킷에 직접 연결되지 않습니다. S3 버킷에 대한 액세스 제어는 버킷 정책이나 ACL을 통해 관리되므로 이 옵션은 잘못된 것입니다."
        ]
    },
    {
        "Question Number": "23",
        "Situation": "한 의료 회사가 재해 복구를 위해 환자 데이터를 AWS에 백업해야 합니다. 비용을 줄이기 위해, 이들은 백업의 장기 보존을 보장하면서 저장 비용을 최소화하는 솔루션이 필요합니다. 또한 필요할 경우 몇 시간 내에 데이터를 검색할 수 있는 옵션을 원합니다.",
        "Question": "이 요구 사항을 가장 잘 충족하는 백업 전략은 무엇인가요? (두 가지 선택)",
        "Options": {
            "1": "Amazon S3 Standard에 백업 저장",
            "2": "아카이브 저장을 위해 Amazon S3 Glacier Flexible Retrieval 사용",
            "3": "Amazon S3 Standard-IA에 백업 저장",
            "4": "같은 지역에 저장된 Amazon EBS 스냅샷 사용",
            "5": "AWS Backup을 구현하여 백업을 저비용 저장 클래스으로 전환하는 라이프사이클 정책 설정"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "아카이브 저장을 위해 Amazon S3 Glacier Flexible Retrieval 사용",
            "AWS Backup을 구현하여 백업을 저비용 저장 클래스으로 전환하는 라이프사이클 정책 설정"
        ],
        "Explanation": "Amazon S3 Glacier Flexible Retrieval은 장기 데이터 저장을 위한 비용 효율적인 솔루션으로, 몇 시간 내에 데이터 검색이 가능하여 회사의 요구 사항에 부합합니다. AWS Backup과 라이프사이클 정책을 사용하면 일정 기간 후에 백업을 저비용 저장 클래스로 자동 전환할 수 있어 시간이 지남에 따라 저장 비용을 크게 줄일 수 있습니다.",
        "Other Options": [
            "Amazon S3 Standard에 백업을 저장하는 것은 장기 데이터 보존을 위한 가장 비용 효율적인 솔루션이 아닙니다. 높은 내구성, 가용성 및 성능을 제공하지만, S3 Glacier나 S3 Standard-IA와 같은 다른 저장 클래스에 비해 비용이 더 높습니다.",
            "Amazon S3 Standard-IA(비정기 액세스)에 백업을 저장하는 것은 덜 자주 접근되는 데이터에 대한 비용 효율적인 솔루션이 될 수 있지만, S3 Glacier나 AWS Backup과 라이프사이클 정책에 비해 장기 저장에 대한 동일한 수준의 비용 절감을 제공하지 않을 수 있습니다.",
            "같은 지역에 저장된 Amazon EBS 스냅샷을 사용하는 것은 장기 보존을 위해 저장 비용을 최소화하지 않을 수 있습니다. 또한, 같은 지역에 백업을 저장하는 것은 재해 복구 목적으로 자주 원하는 지리적 중복성을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "24",
        "Situation": "뉴스 웹사이트가 Amazon S3에 멀티미디어 파일을 저장하고 있습니다. 이 파일들은 업로드 후 처음 7일 동안 자주 접근되지만, 그 이후에는 거의 접근되지 않습니다. 웹사이트는 이러한 접근 패턴에 따라 저장 비용을 줄이고자 합니다.",
        "Question": "어떤 저장 구성이 비용 최적화에 가장 적합할까요?",
        "Options": {
            "1": "모든 파일을 S3 Standard에 저장",
            "2": "S3 Intelligent-Tiering에 파일 저장",
            "3": "7일 후 파일을 S3 Standard-IA로 이동",
            "4": "모든 멀티미디어 파일에 S3 Glacier 사용"
        },
        "Correct Answer": "7일 후 파일을 S3 Standard-IA로 이동",
        "Explanation": "파일을 7일 후 S3 Standard-IA(비정기 액세스)로 이동하는 것은 최선의 선택입니다. 이는 덜 자주 접근되지만 필요할 때 빠른 접근이 필요한 데이터에 적합하게 설계되었습니다. 멀티미디어 파일은 처음 7일 동안 자주 접근되고 그 이후에는 거의 접근되지 않으므로, 이 기간이 지나면 Standard-IA로 전환하면 저장 비용을 크게 줄이면서도 필요할 때 빠른 접근이 가능합니다. S3 Standard-IA는 S3 Standard에 비해 낮은 저장 비용을 제공하여 설명된 접근 패턴에 대한 비용 효율적인 솔루션입니다.",
        "Other Options": [
            "모든 파일을 S3 Standard에 저장하는 것은 비용을 최적화하지 못합니다. S3 Standard는 비정기적으로 접근되는 데이터에 비해 S3 Standard-IA보다 더 비쌉니다. 이 옵션은 초기 7일 이후 자주 접근되지 않는 데이터에 대해 낮은 비용을 활용하지 않습니다.",
            "S3 Intelligent-Tiering에 파일을 저장하는 것은 실행 가능한 옵션일 수 있지만, 모니터링 및 자동 계층화로 인해 추가 비용이 발생합니다. 접근 패턴이 예측 가능하므로(처음 7일 동안 자주 접근되고 그 이후에는 드물게 접근됨), 파일을 7일 후 Standard-IA로 수동으로 이동하는 것이 Intelligent-Tiering을 사용하는 것보다 비용 효율적입니다.",
            "모든 멀티미디어 파일에 S3 Glacier를 사용하는 것은 적합하지 않습니다. Glacier는 아카이브 저장을 위해 설계되었으며, 검색 시간이 몇 분에서 몇 시간까지 걸릴 수 있습니다. 이는 초기 업로드 후 빠른 접근이 필요한 파일의 요구 사항을 충족하지 못합니다."
        ]
    },
    {
        "Question Number": "25",
        "Situation": "회사가 최근에 새로운 AWS 계정을 생성했으며, 창립자는 현재 루트 사용자를 사용하여 계정 내 리소스를 관리하고 있습니다. 루트 사용자는 계정 내 모든 리소스에 대해 완전하고 무제한적인 제어 권한을 가지며, 기본적으로 다른 사용자는 명시적으로 권한이 부여될 때까지 아무런 권한도 없습니다. 더 나은 보안을 위해, 창립자는 루트 계정을 일상적인 작업에 사용하는 대신 특정 권한을 가진 IAM 사용자를 생성하여 다른 팀원에게 책임을 위임하고자 합니다.",
        "Question": "창립자가 AWS 계정을 안전하게 유지하면서 액세스를 효과적으로 관리하기 위해 어떤 조치를 취해야 하나요? (두 가지 선택)",
        "Options": {
            "1": "모든 일상적인 관리 작업에 루트 사용자를 계속 사용하고 팀원에게 읽기 전용 액세스 권한을 가진 IAM 사용자를 생성합니다.",
            "2": "루트 계정에 다중 인증(MFA)을 활성화하고, 각 팀원에게 필요한 권한을 가진 IAM 사용자를 생성하며, 정기적인 활동에 루트 계정을 사용하지 않도록 합니다.",
            "3": "루트 계정 자격 증명을 팀원과 공유하고 IAM 그룹을 설정하여 권한을 조직합니다.",
            "4": "각 팀원에게 직접 AWS 계정에 접근할 수 있도록 별도의 루트 사용자를 생성합니다.",
            "5": "루트 액세스 키를 정기적으로 교체하고 루트 계정 사용을 필수 작업으로 제한합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "루트 계정에 다중 인증(MFA)을 활성화하고, 각 팀원에게 필요한 권한을 가진 IAM 사용자를 생성하며, 정기적인 활동에 루트 계정을 사용하지 않도록 합니다.",
            "루트 액세스 키를 정기적으로 교체하고 루트 계정 사용을 필수 작업으로 제한합니다."
        ],
        "Explanation": "루트 계정에 다중 인증(MFA)을 활성화하면 로그인 시 두 가지 형태의 신원을 요구하여 보안이 강화됩니다. 각 팀원에게 IAM 사용자를 생성하면 창립자가 책임을 위임하고 각 사용자에게 특정 권한을 부여하여 액세스를 효과적으로 관리할 수 있습니다. 이렇게 하면 모든 리소스에 대한 완전한 제어 권한을 가진 루트 계정이 정기적인 활동에 사용되지 않아 우발적인 변경이나 보안 위반의 위험이 줄어듭니다. 루트 액세스 키를 정기적으로 교체하는 것도 보안을 유지하기 위한 최선의 관행입니다. 키가 손상되더라도 제한된 기간 동안만 유효하도록 보장합니다. 루트 계정 사용을 필수 작업으로 제한하는 것도 우발적인 변경이나 보안 위반의 위험을 최소화합니다.",
        "Other Options": [
            "모든 일상적인 관리 작업에 루트 사용자를 계속 사용하는 것은 우발적인 변경이나 보안 위반의 위험을 증가시키므로 좋은 관행이 아닙니다. 팀원에게 읽기 전용 액세스 권한을 가진 IAM 사용자를 생성하는 것은 그들이 필요한 작업을 수행하는 능력을 제한합니다.",
            "루트 계정 자격 증명을 팀원과 공유하는 것은 심각한 보안 위험입니다. 이는 팀원에게 계정 내 모든 리소스에 대한 완전하고 무제한적인 제어 권한을 부여합니다. 권한을 조직하기 위해 IAM 그룹을 설정하는 것은 좋은 관행이지만, 루트 계정이 아닌 IAM 사용자와 함께 수행해야 합니다.",
            "각 팀원에게 직접 AWS 계정에 접근할 수 있도록 별도의 루트 사용자를 생성하는 것은 불가능합니다. AWS는 계정당 하나의 루트 사용자만 허용합니다. 또한, 팀원에게 AWS 계정에 직접 접근할 수 있도록 하는 것은 심각한 보안 위험입니다."
        ]
    },
    {
        "Question Number": "26",
        "Situation": "한 회사가 고객 피드백을 분석하여 주요 주제와 감정을 식별하고, 이를 접근성을 위해 오디오 요약으로 변환할 수 있는 고객 서비스 애플리케이션을 구축하고자 합니다.",
        "Question": "이 작업에 가장 적합한 AWS 관리 서비스 조합은 무엇이며, 그 이유는 무엇인가요? (두 가지 선택)",
        "Options": {
            "1": "Amazon SageMaker와 Amazon Rekognition, 고급 기계 학습 모델링 및 이미지 인식 기능을 제공하기 때문입니다.",
            "2": "Amazon Comprehend와 Amazon Polly, Comprehend는 주제와 감정을 분석할 수 있고, Polly는 텍스트를 자연스러운 음성으로 변환할 수 있기 때문입니다.",
            "3": "AWS Glue와 Amazon Athena, 피드백 데이터를 처리하고 구조화된 데이터에 대한 복잡한 쿼리를 수행하기 위해서입니다.",
            "4": "Amazon Translate와 Amazon Lex, 고객 피드백을 다양한 언어로 번역하고 대화형 인터페이스를 구축하기 위해서입니다.",
            "5": "Amazon Transcribe와 Amazon Translate, 음성 피드백을 필기하고 여러 언어로 번역하기 위해서입니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon SageMaker와 Amazon Rekognition, 고급 기계 학습 모델링 및 이미지 인식 기능을 제공하기 때문입니다.",
            "Amazon Comprehend와 Amazon Polly, Comprehend는 주제와 감정을 분석할 수 있고, Polly는 텍스트를 자연스러운 음성으로 변환할 수 있기 때문입니다."
        ],
        "Explanation": "Amazon SageMaker는 모든 개발자와 데이터 과학자가 기계 학습(ML) 모델을 신속하게 구축, 훈련 및 배포할 수 있도록 하는 완전 관리형 서비스입니다. SageMaker는 기계 학습 프로세스의 각 단계에서 무거운 작업을 제거하여 고품질 모델을 개발하기 쉽게 만듭니다. Amazon Rekognition은 입증된 고도로 확장 가능한 딥 러닝 기술을 사용하여 애플리케이션에 이미지 및 비디오 분석을 쉽게 추가할 수 있게 해주며, 기계 학습 전문 지식 없이도 사용할 수 있습니다. Amazon Comprehend는 기계 학습을 사용하여 텍스트에서 통찰력과 관계를 찾습니다. 텍스트의 언어를 식별하고, 주요 구문, 장소, 사람, 브랜드 또는 사건을 추출하며, 텍스트가 긍정적인지 부정적인지를 이해하고, 토큰화 및 품사 분석을 사용하여 텍스트를 분석하고, 주제별로 텍스트 파일 모음을 자동으로 정리할 수 있습니다. Amazon Polly는 텍스트를 생생한 음성으로 변환하는 서비스로, 대화하는 애플리케이션을 만들고 완전히 새로운 음성 지원 제품 카테고리를 구축할 수 있게 해줍니다.",
        "Other Options": [
            "AWS Glue와 Amazon Athena는 ETL(추출, 변환, 적재) 작업 및 데이터 쿼리에 사용되며, 감정 분석이나 텍스트-음성 변환에는 사용되지 않습니다.",
            "Amazon Translate와 Amazon Lex는 언어 번역 및 대화형 인터페이스 구축에 사용되며, 감정 분석이나 텍스트-음성 변환에는 사용되지 않습니다.",
            "Amazon Transcribe와 Amazon Translate는 음성 피드백을 필기하고 여러 언어로 번역하는 데 사용되며, 감정 분석이나 텍스트-음성 변환에는 사용되지 않습니다."
        ]
    },
    {
        "Question Number": "27",
        "Situation": "귀하의 팀은 빠른 데이터 검색과 내구성을 위해 백엔드 데이터베이스에 의존하는 고도로 복원력 있는 애플리케이션을 설계하고 있습니다.",
        "Question": "Amazon DynamoDB의 어떤 기능이 지역 장애 발생 시 복원력을 향상시키고 데이터 가용성을 보장하는 데 가장 좋습니까?",
        "Options": {
            "1": "DynamoDB Streams, 변경 사항을 다른 AWS 서비스에 실시간으로 복제할 수 있습니다.",
            "2": "DynamoDB Global Tables, 자동 장애 조치 및 지역 간 복원력을 위한 다중 지역 복제를 가능하게 합니다.",
            "3": "DynamoDB Accelerator (DAX), 피크 부하 동안 읽기 시간을 단축하기 위한 인메모리 캐싱을 제공합니다.",
            "4": "DynamoDB Auto Scaling, 수요 급증에 맞춰 읽기 및 쓰기 처리량을 동적으로 조정합니다."
        },
        "Correct Answer": "DynamoDB Global Tables, 자동 장애 조치 및 지역 간 복원력을 위한 다중 지역 복제를 가능하게 합니다.",
        "Explanation": "DynamoDB Global Tables는 다중 지역, 완전 복제된 데이터베이스를 배포하기 위한 완전 관리형 솔루션을 제공합니다. 이 기능은 지역 장애가 발생하더라도 애플리케이션이 계속 작동할 수 있도록 하며, 데이터를 여러 AWS 지역에 자동으로 복제합니다. 이 복제는 자동 장애 조치를 가능하게 하여, 한 지역이 사용할 수 없게 되면 애플리케이션이 데이터에 여전히 접근할 수 있는 다른 지역으로 원활하게 전환할 수 있게 하여 복원력을 향상시키고 데이터 가용성을 보장합니다.",
        "Other Options": [
            "DynamoDB Streams는 변경 사항을 다른 AWS 서비스에 실시간으로 복제할 수 있지만, 다중 지역 복제나 자동 장애 조치 기능을 제공하지 않습니다. 이는 지역 장애에 대한 복원력을 보장하기보다는 이벤트 기반 아키텍처에 더 적합합니다.",
            "DynamoDB Accelerator (DAX)는 인메모리 캐싱을 제공하여 읽기 성능을 개선하도록 설계되었지만, 지역 장애 발생 시 데이터 가용성 문제를 해결하지는 않습니다.",
            "DynamoDB Auto Scaling은 수요 급증에 따라 읽기 및 쓰기 처리량을 조정하여 성능 및 비용 관리를 개선하지만, 장애 발생 시 지역 간 복원력이나 데이터 가용성을 보장하지는 않습니다."
        ]
    },
    {
        "Question Number": "28",
        "Situation": "한 회사가 Amazon S3에 저장된 민감한 데이터가 고객 관리 키를 사용하여 저장 시 암호화되도록 해야 합니다.",
        "Question": "회사가 암호화 키를 관리하기 위해 어떤 서비스를 사용해야 합니까?",
        "Options": {
            "1": "AWS Certificate Manager (ACM)",
            "2": "AWS Key Management Service (AWS KMS)",
            "3": "Amazon S3 서버 측 암호화(AES-256 사용)",
            "4": "AWS Secrets Manager"
        },
        "Correct Answer": "AWS Key Management Service (AWS KMS)",
        "Explanation": "AWS Key Management Service (AWS KMS)는 암호화 키를 관리하기 위해 특별히 설계된 서비스로, AWS 서비스 전반에 걸쳐 암호화 키를 생성, 관리 및 제어하는 중앙 집중식 방법을 제공합니다. AWS KMS를 사용할 때, Amazon S3에 저장된 데이터를 암호화하는 데 사용할 수 있는 고객 관리 키(CMK)를 생성할 수 있습니다. 이를 통해 키를 사용할 수 있는 사람과 사용 방법에 대한 세밀한 제어가 가능하여, 민감한 데이터가 회사의 보안 요구 사항에 따라 저장 시 암호화됩니다.",
        "Other Options": [
            "AWS Certificate Manager (ACM)는 웹사이트 및 애플리케이션의 SSL/TLS 인증서를 관리하는 데 주로 사용됩니다. 이는 Amazon S3와 같은 서비스에서 데이터 저장 시 암호화 키를 관리하는 기능을 제공하지 않습니다.",
            "Amazon S3 서버 측 암호화(AES-256 사용)는 저장 시 암호화를 제공하지만 기본적으로 AWS 관리 키를 사용합니다. 고객 관리 키를 사용할 수도 있지만, AWS KMS가 제공하는 키 관리 기능을 제공하지 않으므로 AWS KMS가 암호화 키 관리에 더 적합한 선택입니다.",
            "AWS Secrets Manager는 API 키, 데이터베이스 자격 증명 및 기타 민감한 정보를 관리하기 위해 설계되었습니다. 이는 Amazon S3에서 데이터 저장 시 암호화 키를 관리하기 위한 것이 아닙니다."
        ]
    },
    {
        "Question Number": "29",
        "Situation": "한 소셜 미디어 앱이 인기 있는 콘텐츠에 대한 빈번한 읽기 요청을 받는 MySQL 데이터베이스를 보유하고 있습니다. 데이터베이스 비용을 줄이고 응답 시간을 개선하기 위해, 데이터베이스에서 읽기를 오프로드하기 위한 캐싱 레이어를 구현하고자 합니다.",
        "Question": "이 시나리오에 가장 비용 효율적인 캐싱 전략은 무엇입니까?",
        "Options": {
            "1": "Amazon S3를 사용하여 자주 접근되는 콘텐츠를 캐싱합니다.",
            "2": "Amazon ElastiCache와 같은 관리형 캐시로 인메모리 캐싱을 구현합니다.",
            "3": "MySQL 데이터베이스의 여러 읽기 복제본을 생성합니다.",
            "4": "배치 처리 시스템을 사용하여 인기 있는 쿼리를 미리 계산합니다."
        },
        "Correct Answer": "Amazon ElastiCache와 같은 관리형 캐시로 인메모리 캐싱을 구현합니다.",
        "Explanation": "Amazon ElastiCache와 같은 관리형 서비스로 인메모리 캐싱을 구현하는 것은 이 시나리오에 가장 비용 효율적인 전략입니다. 이는 자주 요청되는 데이터에 빠르게 접근할 수 있게 하여 MySQL 데이터베이스의 부하를 크게 줄입니다. 인메모리 캐시는 데이터를 RAM에 저장하므로 디스크 기반 저장 솔루션에 비해 훨씬 빠른 읽기 시간을 제공합니다. 이 접근 방식은 높은 읽기 트래픽을 효율적으로 처리할 수 있으며 필요에 따라 확장할 수 있어, 인기 있는 콘텐츠에 대한 빈번한 읽기 요청이 있는 애플리케이션에 이상적입니다.",
        "Other Options": [
            "Amazon S3를 사용하여 자주 접근되는 콘텐츠를 캐싱하는 것은 적합하지 않습니다. S3는 주로 내구성과 가용성을 최적화한 객체 저장 서비스이기 때문입니다. S3에서 데이터를 접근하는 것은 인메모리 캐싱에 비해 지연 시간이 더 길어, 높은 읽기 시나리오에서 응답 시간을 줄이는 데 덜 효과적입니다.",
            "MySQL 데이터베이스의 여러 읽기 복제본을 생성하면 여러 복제본에 부하를 분산시켜 읽기 성능을 개선할 수 있지만, 캐싱만큼 비용 효율적이지는 않습니다. 각 복제본은 저장 및 유지 관리에 추가 비용이 발생하며, 읽기 확장성에는 도움이 되지만 인메모리 캐시만큼의 속도 이점을 제공하지는 않습니다.",
            "배치 처리 시스템을 사용하여 인기 있는 쿼리를 미리 계산하는 것은 직접적인 캐싱 솔루션이 아니며, 자주 접근되는 콘텐츠에 대한 실시간 접근을 제공하지 않을 수 있습니다. 결과를 미리 계산하여 데이터베이스의 부하를 줄일 수 있지만, 동적 콘텐츠 요청에 대해 인메모리 캐시가 제공하는 즉각적인 응답 시간을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "30",
        "Situation": "한 회사가 고객 지원 플랫폼을 구축하고 AWS 서비스를 사용하여 고객 피드백을 분석하고 자동 음성 응답을 생성하고자 합니다. 그들은 텍스트 데이터에서 주요 통찰력을 추출하고 텍스트 응답을 음성으로 변환하고자 합니다.",
        "Question": "회사가 이러한 목표를 달성하기 위해 어떤 AWS 서비스를 사용해야 합니까?",
        "Options": {
            "1": "Amazon Polly를 사용하여 텍스트를 음성으로 변환하고 Amazon Comprehend를 사용하여 고객 감정을 분석하고 피드백에서 주요 구문을 추출합니다.",
            "2": "Amazon Lex를 사용하여 대화형 챗봇을 구축하고 Amazon Polly를 음성-텍스트 변환에 사용합니다.",
            "3": "Amazon S3를 사용하여 피드백을 저장하고 AWS Lambda를 사용하여 텍스트를 분석하고 음성을 생성합니다.",
            "4": "Amazon Transcribe를 사용하여 음성을 텍스트로 변환하고 Amazon Rekognition을 감정 분석에 사용합니다."
        },
        "Correct Answer": "Amazon Polly를 사용하여 텍스트를 음성으로 변환하고 Amazon Comprehend를 사용하여 고객 감정을 분석하고 피드백에서 주요 구문을 추출합니다.",
        "Explanation": "이 옵션은 Amazon Polly가 텍스트를 생생한 음성으로 변환하도록 특별히 설계되었기 때문에 회사의 자동 음성 응답 생성 목표와 일치합니다. 또한 Amazon Comprehend는 텍스트 데이터를 분석하여 감정 및 주요 구문과 같은 통찰력을 추출할 수 있는 자연어 처리(NLP) 서비스로, 고객 피드백 분석에 이상적입니다.",
        "Other Options": [
            "이 옵션은 Amazon Lex가 대화형 인터페이스(챗봇)를 구축하는 데 사용되며, 감정 분석이나 주요 구문 추출을 위한 텍스트 데이터 분석에 주로 초점을 맞추지 않기 때문에 잘못된 것입니다. Amazon Polly는 음성 변환을 위해 포함되어 있지만 고객 피드백 분석을 다루지 않습니다.",
            "이 옵션은 Amazon S3가 저장 서비스이며 분석 기능을 제공하지 않기 때문에 잘못된 것입니다. AWS Lambda는 서버리스 컴퓨팅에 사용할 수 있지만 텍스트 분석 및 음성 생성을 위해 추가 서비스가 필요하므로 올바른 답변보다 효율적이지 않습니다.",
            "이 옵션은 Amazon Transcribe가 음성을 텍스트로 변환하는 데 사용되므로 회사의 텍스트 피드백 분석 목표와 관련이 없기 때문에 잘못된 것입니다. 또한 Amazon Rekognition은 이미지 및 비디오 분석 서비스로, 텍스트 데이터의 감정 분석에 적합하지 않습니다."
        ]
    },
    {
        "Question Number": "31",
        "Situation": "한 회사가 Amazon S3에 민감한 데이터를 저장하고 AWS가 평문 데이터에 접근하지 않도록 보장해야 합니다. 또한 키 관리 및 암호화 처리에 대한 완전한 제어를 원합니다.",
        "Question": "회사가 이러한 요구 사항을 충족하기 위해 어떤 암호화 방법을 사용해야 합니까?",
        "Options": {
            "1": "S3-관리 키를 사용하는 서버 측 암호화 (SSE-S3)",
            "2": "AWS KMS-관리 키를 사용하는 서버 측 암호화 (SSE-KMS)",
            "3": "클라이언트 측 암호화",
            "4": "고객 제공 키를 사용하는 서버 측 암호화 (SSE-C)"
        },
        "Correct Answer": "클라이언트 측 암호화",
        "Explanation": "클라이언트 측 암호화는 회사가 데이터를 Amazon S3에 전송하기 전에 암호화할 수 있도록 하여 AWS가 평문 데이터에 접근하지 못하도록 보장합니다. 이 방법은 회사가 자신의 암호화 키와 알고리즘을 사용하여 데이터를 S3에 업로드하기 전에 보호할 수 있도록 하여 암호화 프로세스와 키 관리에 대한 완전한 제어를 제공합니다. 이는 AWS가 평문 데이터에 접근하지 않도록 보장하는 요구 사항을 충족합니다.",
        "Other Options": [
            "S3-관리 키를 사용하는 서버 측 암호화 (SSE-S3)는 Amazon의 자체 키를 사용하여 암호화를 관리하므로 AWS가 평문 데이터에 접근할 수 있어 회사의 요구 사항을 충족하지 않습니다.",
            "AWS KMS-관리 키를 사용하는 서버 측 암호화 (SSE-KMS)는 SSE-S3에 비해 키 관리에 대한 더 많은 제어를 허용하지만, 암호화 및 복호화 프로세스가 서버 측에서 발생하기 때문에 AWS는 여전히 평문 데이터에 접근할 수 있습니다.",
            "고객 제공 키를 사용하는 서버 측 암호화 (SSE-C)는 고객이 암호화를 위해 자신의 키를 제공할 수 있도록 하지만, AWS가 여전히 암호화 및 복호화 프로세스를 처리하므로 AWS가 평문 데이터에 접근할 수 있는 가능성이 있어 회사의 요구 사항을 충족하지 않습니다."
        ]
    },
    {
        "Question Number": "32",
        "Situation": "전 세계 수백만 독자가 있는 글로벌 뉴스 웹사이트가 Amazon CloudFront를 사용하여 콘텐츠를 효율적으로 전달하고 있습니다. 웹사이트 팀은 지역 뉴스 하이라이트와 같은 콘텐츠를 시청자의 국가에 따라 개인화하는 기능을 추가하고, 기사에 대한 다양한 레이아웃을 테스트하기 위해 A/B 테스트를 구현해야 합니다. 이 솔루션은 전 세계 시청자에게 원활하고 낮은 대기 시간의 경험을 보장하기 위해 엣지 위치에서 작동해야 합니다.",
        "Question": "솔루션 아키텍트가 추천해야 할 AWS 서비스 및 구성은 무엇입니까?",
        "Options": {
            "1": "국가 기반 라우팅 규칙을 사용하여 콘텐츠 개인화를 위한 VPC에 AWS Lambda 배포",
            "2": "CloudFront Viewer Request 및 Origin Request 이벤트에 의해 트리거되는 Lambda@Edge 함수를 사용하여 국가에 따라 콘텐츠를 사용자 정의하고 엣지 위치에서 A/B 테스트 수행",
            "3": "여러 지역에 Amazon EC2 인스턴스를 배포하고 각 인스턴스에 국가별 콘텐츠를 로컬로 저장",
            "4": "각 국가에 특정한 캐시 동작으로 Amazon CloudFront 구성하여 국가 맞춤형 콘텐츠 제공"
        },
        "Correct Answer": "CloudFront Viewer Request 및 Origin Request 이벤트에 의해 트리거되는 Lambda@Edge 함수를 사용하여 국가에 따라 콘텐츠를 사용자 정의하고 엣지 위치에서 A/B 테스트 수행",
        "Explanation": "Lambda@Edge를 사용하면 웹사이트가 CloudFront 엣지 위치에서 사용자에게 더 가까운 곳에서 코드를 실행할 수 있어 대기 시간이 최소화되고 사용자 경험이 향상됩니다. Viewer Request 및 Origin Request 이벤트에서 함수를 트리거함으로써 웹사이트는 사용자의 국가에 따라 콘텐츠를 동적으로 사용자 정의하고 다양한 레이아웃에 대한 A/B 테스트를 구현할 수 있습니다. 이 솔루션은 효율적이며 CloudFront의 기능을 활용하여 개인화된 콘텐츠를 신속하고 효과적으로 전달합니다.",
        "Other Options": [
            "국가 기반 라우팅 규칙을 사용하여 VPC에 AWS Lambda를 배포하는 것은 최적의 방법이 아닙니다. 이는 트래픽이 엣지 위치가 아닌 VPC를 통해 라우팅되어야 하므로 대기 시간이 발생합니다. 이 설정은 CloudFront의 낮은 대기 시간 이점을 효과적으로 활용하지 않습니다.",
            "Lambda@Edge 함수를 사용하는 것이 올바른 접근 방식이지만, 이 옵션은 함수가 적절한 시점에 트리거되기 위해 필수적인 CloudFront 이벤트 사용을 명시하지 않습니다. 따라서 완전한 솔루션에 필요한 세부 사항이 부족합니다.",
            "여러 지역에 Amazon EC2 인스턴스를 배포하는 것은 비효율적이고 비용이 많이 듭니다. 이는 여러 인스턴스를 관리하고 콘텐츠를 동기화해야 하므로 아키텍처가 복잡해지고 낮은 대기 시간 콘텐츠 전달을 위한 엣지 컴퓨팅의 이점을 활용하지 않습니다."
        ]
    },
    {
        "Question Number": "33",
        "Situation": "비디오 스트리밍 회사가 AWS에 호스팅된 콘텐츠 전달 서비스를 본사 네트워크와 연결해야 합니다. 이 회사는 대용량 비디오 파일을 전송하기 위한 높은 처리량 연결과 비디오 재생 중 버퍼링 문제를 방지하기 위한 낮은 대기 시간이 필요합니다. 또한 민감한 비디오 콘텐츠가 공용 인터넷에 노출되지 않도록 연결이 비공개이기를 원하며 이러한 목표를 달성하기 위한 비용 효율적인 솔루션을 찾고 있습니다.",
        "Question": "어떤 접근 방식이 그들의 요구를 가장 잘 충족할까요?",
        "Options": {
            "1": "비디오 콘텐츠를 본사에 직접 연결하기 위한 AWS PrivateLink",
            "2": "AWS와 온프레미스 네트워크 간의 고대역폭 비공식 연결을 설정하기 위한 AWS Direct Connect",
            "3": "통신 제공업체의 포인트 투 포인트 MPLS 회선을 사용하여 AWS에 대한 비공식 연결 생성",
            "4": "안전한 데이터 전송을 위한 전용 VPN을 갖춘 관리형 인터넷 서비스 사용"
        },
        "Correct Answer": "AWS와 온프레미스 네트워크 간의 고대역폭 비공식 연결을 설정하기 위한 AWS Direct Connect",
        "Explanation": "AWS Direct Connect는 회사 본사와 AWS 간의 전용 네트워크 연결을 제공하여 높은 처리량 요구 사항과 낮은 대기 시간에 이상적입니다. 이 서비스는 공용 인터넷을 통과하지 않는 비공식 연결을 허용하여 민감한 비디오 콘텐츠의 보안을 보장합니다. Direct Connect는 대량 데이터 전송을 효율적으로 처리할 수 있어 비디오 재생 중 버퍼링 위험 없이 대용량 비디오 파일을 전송하기 위한 비용 효율적인 솔루션입니다.",
        "Other Options": [
            "AWS PrivateLink는 AWS 내에서 서비스를 안전하게 연결하기 위해 설계되었으며 온프레미스 네트워크에 대한 직접 연결을 제공하지 않습니다. 이는 AWS 서비스에 비공식적으로 접근하는 데 더 적합하며 AWS와 외부 네트워크 간의 대용량 파일 전송에는 적합하지 않습니다.",
            "통신 제공업체의 포인트 투 포인트 MPLS 회선은 비공식 연결을 제공할 수 있지만, AWS Direct Connect만큼 비용 효율적이거나 유연하지 않을 수 있습니다. 또한 MPLS 회선의 설정 및 관리는 더 복잡할 수 있으며 Direct Connect와 동일한 수준의 성능을 보장하지 않을 수 있습니다.",
            "전용 VPN을 갖춘 관리형 인터넷 서비스를 사용하면 안전한 연결을 제공할 수 있지만, 일반적으로 AWS Direct Connect만큼 높은 처리량과 낮은 대기 시간을 제공하지 않습니다. 인터넷을 통한 VPN은 성능 변동성을 초래할 수 있어 비디오 재생 중 버퍼링 문제를 일으킬 수 있습니다."
        ]
    },
    {
        "Question Number": "34",
        "Situation": "한 제조 회사가 온프레미스 시설에서 센서 데이터를 수집하고 AWS에 데이터를 장기 저장 및 분석을 위해 아카이브해야 합니다. 비용을 최소화하고 최소한의 수동 노력으로 클라우드로 데이터를 전송할 수 있는 원활한 방법을 원합니다.",
        "Question": "어떤 하이브리드 스토리지 옵션이 이러한 요구 사항을 가장 잘 충족할까요?",
        "Options": {
            "1": "AWS Direct Connect",
            "2": "AWS Storage Gateway",
            "3": "Transfer Acceleration을 사용하는 Amazon S3",
            "4": "AWS DataSync"
        },
        "Correct Answer": "AWS Storage Gateway",
        "Explanation": "AWS Storage Gateway는 하이브리드 클라우드 스토리지 솔루션을 위해 특별히 설계되어 온프레미스 애플리케이션이 클라우드 스토리지를 원활하게 사용할 수 있도록 합니다. 이는 최소한의 수동 노력으로 AWS에 데이터를 전송할 수 있는 방법을 제공하여 센서 데이터를 아카이브하는 데 이상적입니다. 파일, 볼륨 및 테이프 게이트웨이와 같은 다양한 구성을 지원하여 비용을 최소화하면서 클라우드에서 분석을 위해 데이터를 쉽게 사용할 수 있도록 합니다.",
        "Other Options": [
            "AWS Direct Connect는 온프레미스에서 AWS로의 전용 네트워크 연결을 제공하여 대역폭을 개선하고 데이터 전송 비용을 줄일 수 있습니다. 그러나 자동으로 데이터를 관리하고 전송하는 원활한 방법을 제공하지 않으며 추가 설정 및 관리가 필요합니다.",
            "Transfer Acceleration을 사용하는 Amazon S3는 장거리에서 S3로 파일 전송 속도를 높이지만 하이브리드 스토리지 솔루션을 제공하지 않습니다. 이는 파일 전송에 더 적합하며 온프레미스 데이터를 클라우드 스토리지와 원활하게 통합하는 데는 적합하지 않습니다.",
            "AWS DataSync는 온프레미스 스토리지와 AWS 스토리지 서비스 간의 데이터 이동을 자동화하는 서비스입니다. 대량의 데이터를 전송하는 데 효과적이지만 AWS Storage Gateway에 비해 더 많은 수동 설정 및 관리가 필요할 수 있습니다."
        ]
    },
    {
        "Question Number": "35",
        "Situation": "한 미디어 회사가 Amazon S3에 대용량 비디오 파일을 저장하고 있습니다. 비디오는 업로드 직후 자주 접근되지만 한 달 후에는 거의 접근되지 않습니다. 회사는 최근에 업로드된 비디오에 대한 접근 성능을 저하시키지 않으면서 저장 비용을 최적화하고자 합니다.",
        "Question": "솔루션 아키텍트가 추천해야 할 S3 스토리지 클래스는 무엇입니까?",
        "Options": {
            "1": "S3 Standard",
            "2": "S3 Intelligent-Tiering",
            "3": "S3 Standard-비정기적 접근 (S3 Standard-IA)",
            "4": "S3 One Zone-비정기적 접근 (S3 One Zone-IA)"
        },
        "Correct Answer": "S3 Intelligent-Tiering",
        "Explanation": "S3 Intelligent-Tiering은 이 시나리오에 가장 적합한 옵션입니다. 이 스토리지 클래스는 변경되는 접근 패턴에 따라 데이터를 두 개의 접근 계층(자주 접근 및 비정기적 접근) 간에 자동으로 이동합니다. 비디오는 업로드 직후 자주 접근되지만 한 달 후에는 거의 접근되지 않기 때문에, 이 스토리지 클래스는 초기 접근 기간 후에 데이터를 비정기적 접근 계층으로 이동시켜 최근에 업로드된 비디오에 대한 접근 성능을 저하시키지 않으면서 비용을 최적화합니다.",
        "Other Options": [
            "S3 Standard는 이 사용 사례에 가장 비용 효율적인 옵션이 아닙니다. 이는 자주 접근되는 데이터에 맞춰 설계되었으며, 짧은 기간 후에 비정기적으로 접근되는 데이터에 대한 비용 절감을 제공하지 않습니다.",
            "S3 Standard-비정기적 접근 (S3 Standard-IA)은 비정기적으로 접근되는 데이터에 대해 더 저렴하지만, 검색 수수료가 발생하며 업로드 직후 자주 접근되는 데이터에 최적화되어 있지 않습니다.",
            "S3 One Zone-비정기적 접근 (S3 One Zone-IA)도 적합하지 않습니다. 이는 데이터를 단일 가용 영역에 저장하므로 가용 영역 장애 시 데이터 손실 위험이 있습니다. 또한 이는 비정기적으로 접근되는 데이터에 맞춰 설계되어 있어 업로드 직후 빠른 접근이 필요한 요구와 일치하지 않습니다."
        ]
    },
    {
        "Question Number": "36",
        "Situation": "소프트웨어 개발 회사가 Docker 컨테이너를 사용하여 마이크로서비스 기반 애플리케이션을 배포하고 있습니다. 이 애플리케이션은 EC2 인스턴스 클러스터 전반에 걸쳐 컨테이너의 자동 배포, 확장 및 관리를 요구합니다.",
        "Question": "컨테이너화된 애플리케이션을 오케스트레이션하기 위해 솔루션 아키텍트가 추천해야 할 AWS 서비스는 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "Amazon Elastic Container Service (ECS)",
            "2": "AWS Lambda",
            "3": "Amazon EC2 Auto Scaling",
            "4": "AWS Batch",
            "5": "Amazon Elastic Kubernetes Service (EKS)"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon Elastic Container Service (ECS)",
            "Amazon Elastic Kubernetes Service (EKS)"
        ],
        "Explanation": "Amazon Elastic Container Service (ECS)와 Amazon Elastic Kubernetes Service (EKS)는 모두 컨테이너화된 애플리케이션을 오케스트레이션하기 위해 특별히 설계된 AWS 서비스입니다. ECS는 Amazon EC2 인스턴스 클러스터 전반에 걸쳐 Docker 지원 애플리케이션을 실행하고 관리할 수 있는 고성능, 고확장성 서비스입니다. 반면 EKS는 Kubernetes 제어 플레인이나 노드를 설치, 운영 및 유지 관리할 필요 없이 AWS에서 Kubernetes를 쉽게 실행할 수 있도록 하는 관리형 서비스입니다. 두 서비스 모두 자동 배포, 확장 및 컨테이너 관리를 제공하여 질문 시나리오에서 요구하는 사항을 충족합니다.",
        "Other Options": [
            "AWS Lambda는 서버를 프로비저닝하거나 관리하지 않고 코드를 실행할 수 있게 해주는 서버리스 컴퓨팅 서비스입니다. 컨테이너화된 애플리케이션과 함께 사용할 수 있지만, 컨테이너 오케스트레이션을 위해 특별히 설계된 서비스는 아닙니다.",
            "Amazon EC2 Auto Scaling은 애플리케이션 가용성을 유지하고 정의한 조건에 따라 EC2 인스턴스를 자동으로 추가하거나 제거할 수 있도록 도와주는 서비스입니다. 기본 EC2 인스턴스를 확장하는 데 사용할 수 있지만, 컨테이너 오케스트레이션 기능은 제공하지 않습니다.",
            "AWS Batch는 IT 전문가가 배치 처리 작업을 예약하고 실행할 수 있도록 하는 서비스입니다. 컨테이너화된 작업을 실행할 수 있지만, 컨테이너화된 애플리케이션을 오케스트레이션하기 위해 특별히 설계된 것은 아닙니다."
        ]
    },
    {
        "Question Number": "37",
        "Situation": "전자상거래 웹사이트는 도메인 이름에 따라 다양한 애플리케이션으로 트래픽을 라우팅할 수 있는 비용 효율적인 방법이 필요하며, 복잡한 라우팅으로 인한 추가 비용을 피하고자 합니다.",
        "Question": "이 요구 사항을 가장 잘 충족하는 AWS 네트워크 서비스는 무엇입니까?",
        "Options": {
            "1": "AWS Global Accelerator를 사용하여 글로벌 라우팅",
            "2": "DNS 기반 라우팅을 위해 Amazon Route 53 배포",
            "3": "경로 기반 라우팅을 사용하는 Application Load Balancer",
            "4": "직접 트래픽 라우팅을 위해 VPC Peering 구성"
        },
        "Correct Answer": "DNS 기반 라우팅을 위해 Amazon Route 53 배포",
        "Explanation": "Amazon Route 53은 도메인 이름에 따라 트래픽을 라우팅할 수 있는 확장 가능하고 고가용성의 도메인 이름 시스템(DNS) 웹 서비스입니다. 이는 도메인에 따라 사용자를 다양한 애플리케이션으로 안내하는 데 이상적인 비용 효율적인 DNS 기반 라우팅을 허용합니다. 이 서비스는 간단한 라우팅, 가중치 기반 라우팅, 지연 시간 기반 라우팅 등과 같은 라우팅 정책을 처리할 수 있으며, 복잡한 라우팅 설정으로 인한 추가 비용이 발생하지 않습니다. 이 목적을 위해 특별히 설계되어 있어 전자상거래 웹사이트의 요구에 가장 적합한 선택입니다.",
        "Other Options": [
            "AWS Global Accelerator는 애플리케이션의 가용성과 성능을 개선하기 위해 트래픽을 최적의 엔드포인트로 유도하도록 설계되었지만, 콘텐츠를 캐시하지는 않습니다. 이는 단순한 도메인 기반 라우팅보다는 TCP 및 UDP 애플리케이션의 성능 개선에 더 적합합니다.",
            "경로 기반 라우팅을 사용하는 Application Load Balancer는 요청 경로에 따라 여러 대상(예: EC2 인스턴스) 간에 들어오는 애플리케이션 트래픽을 분산하는 데 주로 사용됩니다. 효과적으로 트래픽을 라우팅할 수 있지만, 도메인 이름에 따라 라우팅하는 데 가장 비용 효율적인 솔루션은 아닙니다. 추가 설정 및 잠재적 비용이 발생할 수 있습니다.",
            "VPC Peering은 두 VPC(가상 사설 클라우드) 간의 직접 네트워크 트래픽 라우팅을 허용하지만, 도메인 이름 기반 라우팅을 처리하지 않습니다. 이는 외부 트래픽을 도메인 이름에 따라 유도하기보다는 내부 네트워크 통신에 더 적합하여 전자상거래 웹사이트의 요구 사항에 부적합합니다."
        ]
    },
    {
        "Question Number": "38",
        "Situation": "스타트업은 데이터베이스 비용에 대해 우려하고 있으며, 시간에 따라 비용을 모니터링하고 싶어합니다. 예산 내에서 유지하기 위해 비용 알림을 설정하고, 잠재적인 절감을 식별하기 위해 지출 추세를 분석하고자 합니다.",
        "Question": "어떤 AWS 비용 관리 도구 조합을 사용해야 합니까? (두 가지 선택)",
        "Options": {
            "1": "AWS Trusted Advisor 및 AWS Cost Explorer",
            "2": "AWS Budgets 및 AWS Cost Explorer",
            "3": "AWS Cost and Usage Report 및 AWS Support",
            "4": "AWS Trusted Advisor 및 AWS Budgets",
            "5": "AWS Cost Anomaly Detection 및 AWS Budgets"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "AWS Budgets 및 AWS Cost Explorer",
            "AWS Cost Anomaly Detection 및 AWS Budgets"
        ],
        "Explanation": "AWS Budgets는 사용자가 비용 또는 사용량이 예산 금액을 초과(또는 초과할 것으로 예측)할 때 알림을 받을 수 있도록 사용자 정의 비용 및 사용량 예산을 설정할 수 있게 해줍니다. 이는 스타트업이 비용을 모니터링하고 예산 내에서 유지하는 데 도움이 됩니다. AWS Cost Explorer는 사용자가 AWS 비용 및 사용량을 시각화하고 이해하며 관리할 수 있도록 도와줍니다. 이는 스타트업이 지출 추세를 분석하고 잠재적인 절감을 식별하는 데 도움이 됩니다. AWS Cost Anomaly Detection은 비용 및 사용량 데이터를 자동으로 분석하여 비정상적인 지출 패턴을 감지하여 추가적인 비용 관리 레이어를 제공합니다.",
        "Other Options": [
            "AWS Trusted Advisor 및 AWS Cost Explorer: AWS Cost Explorer는 올바른 도구이지만, AWS Trusted Advisor는 주로 AWS 모범 사례에 따라 리소스를 프로비저닝하는 데 도움을 주는 실시간 가이드를 제공합니다. 비용 관리에 특별히 초점을 맞추고 있지는 않습니다.",
            "AWS Cost and Usage Report 및 AWS Support: AWS Cost and Usage Report는 비용에 대한 포괄적인 데이터를 제공하지만, 스타트업이 필요로 하는 알림 기능은 제공하지 않습니다. AWS Support는 기술 지원 서비스로, 비용 관리에 직접적인 도움을 주지 않습니다.",
            "AWS Trusted Advisor 및 AWS Budgets: AWS Budgets는 올바른 도구이지만, AWS Trusted Advisor는 주로 AWS 모범 사례에 따라 리소스를 프로비저닝하는 데 도움을 주는 실시간 가이드를 제공합니다. 비용 관리에 특별히 초점을 맞추고 있지는 않습니다."
        ]
    },
    {
        "Question Number": "39",
        "Situation": "기업 애플리케이션은 Amazon S3에 저장된 데이터에 대한 저지연 액세스가 필요합니다. 이 데이터는 전 세계의 다양한 지리적 위치에서 사용자에 의해 액세스됩니다. 회사는 자주 액세스되는 데이터를 사용자에게 더 가까운 곳에 캐시하여 데이터 액세스 속도를 개선하고자 합니다.",
        "Question": "이 요구 사항을 충족하기 위해 솔루션 아키텍트가 사용해야 할 AWS 서비스는 무엇입니까?",
        "Options": {
            "1": "Amazon CloudFront",
            "2": "AWS Global Accelerator",
            "3": "Amazon Route 53",
            "4": "AWS Direct Connect"
        },
        "Correct Answer": "Amazon CloudFront",
        "Explanation": "Amazon CloudFront는 전 세계의 엣지 위치에서 콘텐츠를 캐시하는 콘텐츠 전송 네트워크(CDN) 서비스입니다. CloudFront를 사용하면 Amazon S3에 저장된 자주 액세스되는 데이터를 사용자에게 더 가까운 곳에 캐시하여 지연 시간을 크게 줄이고 액세스 속도를 개선할 수 있습니다. 사용자가 데이터를 요청하면 CloudFront는 가장 가까운 엣지 위치에서 데이터를 제공하여 다양한 지리적 지역에 위치한 사용자에게 성능을 향상시킵니다.",
        "Other Options": [
            "AWS Global Accelerator는 최적의 엔드포인트로 트래픽을 유도하여 애플리케이션의 가용성과 성능을 개선하지만, 콘텐츠를 캐시하지는 않습니다. 이는 S3의 정적 콘텐츠를 캐시하기보다는 TCP 및 UDP 애플리케이션의 성능 개선에 더 적합합니다.",
            "Amazon Route 53은 도메인 등록, DNS 라우팅 및 상태 확인을 제공하는 확장 가능한 도메인 이름 시스템(DNS) 웹 서비스입니다. 사용자를 가장 가까운 리소스로 안내하는 데 도움을 주지만, 데이터를 캐시하거나 데이터 액세스 속도를 직접적으로 개선하지는 않습니다.",
            "AWS Direct Connect는 귀하의 시설에서 AWS로의 전용 네트워크 연결을 제공하여 데이터 전송의 대역폭을 개선하고 지연 시간을 줄일 수 있습니다. 그러나 데이터를 캐시하거나 콘텐츠 전송 메커니즘을 제공하지 않으므로 자주 액세스되는 데이터를 캐시하는 요구 사항에는 적합하지 않습니다."
        ]
    },
    {
        "Question Number": "40",
        "Situation": "회사는 AWS에서 실행될 다계층 웹 애플리케이션을 설계하고 있습니다. 이 애플리케이션은 프론트엔드 웹 계층, 비즈니스 로직 계층 및 데이터베이스 계층으로 구성됩니다. 회사는 애플리케이션의 고가용성과 내결함성을 요구합니다.",
        "Question": "솔루션 아키텍트가 추천해야 할 아키텍처는 무엇입니까?",
        "Options": {
            "1": "Auto Scaling 및 로드 밸런싱을 사용하여 모든 계층을 단일 가용 영역에 배포합니다.",
            "2": "웹 및 비즈니스 로직 계층을 여러 가용 영역에 배포하고 데이터베이스 계층을 Multi-AZ RDS가 있는 단일 가용 영역에 배포합니다.",
            "3": "웹 계층을 여러 가용 영역에 배포하고 비즈니스 로직 계층을 단일 가용 영역에 배포하며 데이터베이스 계층을 Amazon DynamoDB를 사용하여 배포합니다.",
            "4": "글로벌 가용성을 보장하기 위해 모든 계층을 여러 AWS 리전으로 배포합니다."
        },
        "Correct Answer": "웹 및 비즈니스 로직 계층을 여러 가용 영역에 배포하고 데이터베이스 계층을 Multi-AZ RDS가 있는 단일 가용 영역에 배포합니다.",
        "Explanation": "이 옵션은 웹 및 비즈니스 로직 계층을 여러 가용 영역(AZ)에 배포하여 고가용성과 내결함성을 제공합니다. 이는 하나의 AZ가 다운되더라도 다른 AZ의 리소스를 사용하여 애플리케이션이 계속 작동할 수 있도록 보장합니다. 또한 Amazon RDS의 Multi-AZ를 사용하여 데이터베이스 계층의 가용성과 내구성을 향상시킴으로써 다른 AZ에 대기 인스턴스로 데이터베이스를 자동으로 복제하여 중단 시 장애 조치를 허용합니다. 이 아키텍처는 고가용성의 필요성을 충족하면서 비용과 복잡성을 관리하는 데 효과적입니다.",
        "Other Options": [
            "모든 계층을 단일 가용 영역에 Auto Scaling 및 로드 밸런싱을 사용하여 배포하는 것은 고가용성이나 내결함성을 제공하지 않으며, 해당 AZ에서의 장애가 전체 애플리케이션을 중단시킬 수 있습니다.",
            "웹 및 비즈니스 로직 계층을 여러 가용 영역에 배포하고 데이터베이스 계층을 Multi-AZ RDS가 있는 단일 가용 영역에 배포하는 것은 부분적으로 맞지만, 데이터베이스 계층의 고가용성 이점을 완전히 활용하지 못합니다. 데이터베이스는 완전한 내결함성을 위해 여러 AZ에 있어야 합니다.",
            "웹 계층을 여러 가용 영역에 배포하고 비즈니스 로직 계층을 단일 가용 영역에 배포하며 데이터베이스 계층을 Amazon DynamoDB를 사용하여 배포하는 것은 비즈니스 로직 계층에 대한 내결함성을 제공하지 않으며, 이는 애플리케이션에 중요합니다. DynamoDB는 고가용성이지만, 전체 아키텍처는 비즈니스 로직 계층의 중복성이 부족합니다."
        ]
    },
    {
        "Question Number": "41",
        "Situation": "개발 팀이 새로운 버전의 API를 배포하고 있으며, 최종 사용자에게 미치는 영향을 최소화하면서 프로덕션에서 테스트하고자 합니다. 그들은 전체 릴리스 전에 프로덕션 트래픽의 소규모 비율을 새로운 버전으로 라우팅하기 위해 카나리 배포를 사용하기로 결정했습니다.",
        "Question": "이 테스트 접근 방식을 가장 잘 지원하는 배포 전략은 무엇이며, 어떻게 지원합니까?",
        "Options": {
            "1": "Edge-Optimized Endpoint, 이는 CloudFront를 통해 트래픽을 라우팅하고 글로벌 사용자에게 낮은 대기 시간을 제공합니다.",
            "2": "Regional Endpoint, 이는 트래픽이 특정 AWS 리전 내에 유지되도록 하여 지역별 애플리케이션에 적합합니다.",
            "3": "Private Endpoint, 이는 API가 내부 테스트를 위해 VPC 내에서만 접근 가능하도록 보장합니다.",
            "4": "Stage Deployment with Canary Release, 이는 새로운 API 버전의 통제된 롤아웃을 가능하게 하며 점진적으로 트래픽을 증가시킵니다."
        },
        "Correct Answer": "Stage Deployment with Canary Release, 이는 새로운 API 버전의 통제된 롤아웃을 가능하게 하며 점진적으로 트래픽을 증가시킵니다.",
        "Explanation": "Stage Deployment with Canary Release는 애플리케이션 또는 API의 새로운 버전을 프로덕션에서 최소한의 위험으로 테스트해야 하는 시나리오를 위해 특별히 설계되었습니다. 이 전략은 개발 팀이 새로운 버전으로 트래픽의 소규모 비율을 라우팅하고 성능을 모니터링하며 새로운 버전이 잘 작동할 경우 점진적으로 트래픽을 증가시킬 수 있도록 합니다. 이 통제된 롤아웃은 최종 사용자에게 미치는 영향을 최소화하고 문제가 발생할 경우 신속한 롤백을 가능하게 합니다.",
        "Other Options": [
            "Edge-Optimized Endpoint는 주로 글로벌 사용자를 위한 대기 시간 감소에 초점을 맞추고 있으며, CloudFront를 통해 트래픽을 라우팅합니다. 성능을 개선하지만, 버전 간 트래픽 분배를 제어할 수 있는 메커니즘이 필요한 카나리 배포 전략을 본질적으로 지원하지는 않습니다.",
            "Regional Endpoint는 특정 AWS 리전 내에서 트래픽을 유지해야 하는 애플리케이션에 적합합니다. 그러나 카나리 배포에 필요한 기능을 제공하지 않으며, 이는 API의 서로 다른 버전 간에 점진적으로 트래픽을 전환할 수 있는 능력이 필요합니다.",
            "Private Endpoint는 API 접근을 Virtual Private Cloud (VPC) 내로 제한하여 내부 테스트에 적합하지만, 새로운 버전을 외부 사용자 집합에 노출하여 피드백을 수집하고 성능을 모니터링하는 카나리 배포 전략을 촉진하지 않습니다."
        ]
    },
    {
        "Question Number": "42",
        "Situation": "유전체 연구 기관이 AWS에서 대규모 DNA 서열 분석을 수행하고 있습니다. 이 작업은 높은 컴퓨팅 파워를 요구하며, 강도 높은 처리 요구를 처리하기 위해 신속하게 확장해야 합니다. 팀은 애플리케이션이 피크 성능 요구를 충족할 수 있도록 동적으로 확장할 수 있도록 하면서, 낮은 수요 기간 동안 운영 비용을 최적화해야 합니다.",
        "Question": "이러한 높은 성능 및 비용 효율성 요구를 가장 잘 충족하는 접근 방식은 무엇입니까?",
        "Options": {
            "1": "피크 작업 부하를 위해 최대 vCPU 및 메모리를 가진 EC2 인스턴스를 프로비저닝하고 수동으로 축소합니다.",
            "2": "컴퓨팅 최적화된 EC2 인스턴스를 사용하는 Auto Scaling 그룹을 사용하고 CPU 사용률에 기반한 스케일링 정책을 구성합니다.",
            "3": "모든 계산 작업을 서버리스 방식으로 처리하기 위해 Amazon Lambda 함수를 설정합니다.",
            "4": "많은 저장 용량을 가진 단일 EC2 인스턴스를 실행하고 필요에 따라 수동으로 리소스를 할당합니다."
        },
        "Correct Answer": "컴퓨팅 최적화된 EC2 인스턴스를 사용하는 Auto Scaling 그룹을 사용하고 CPU 사용률에 기반한 스케일링 정책을 구성합니다.",
        "Explanation": "컴퓨팅 최적화된 EC2 인스턴스를 사용하는 Auto Scaling 그룹을 사용하면 조직이 작업 부하에 따라 인스턴스 수를 자동으로 조정할 수 있습니다. 이 접근 방식은 피크 성능 요구 시 추가 인스턴스를 프로비저닝하여 증가된 컴퓨팅 요구를 처리할 수 있도록 보장하며, 낮은 수요 기간 동안 인스턴스를 종료하여 비용을 최적화할 수 있습니다. CPU 사용률에 기반한 스케일링 정책은 실제 리소스 사용량과 스케일링 작업을 직접 연관시키기 때문에 애플리케이션이 작업 부하의 변화에 효율적으로 동적으로 대응할 수 있도록 합니다.",
        "Other Options": [
            "피크 작업 부하를 위해 최대 vCPU 및 메모리를 가진 EC2 인스턴스를 프로비저닝하고 수동으로 축소하는 것은 효율적이지 않습니다. 이 접근 방식은 낮은 수요 기간 동안 과잉 프로비저닝으로 이어져 불필요한 비용을 초래합니다. 수동 스케일링은 인간 오류에 취약하며 작업 부하 변화에 신속하게 대응하지 못할 수 있습니다.",
            "모든 계산 작업을 서버리스 방식으로 처리하기 위해 Amazon Lambda 함수를 설정하는 것은 상당한 컴퓨팅 파워와 메모리를 요구하는 고성능 DNA 서열 분석에는 적합하지 않을 수 있습니다. Lambda는 실행 시간 및 리소스 할당에 제한이 있어 집약적인 유전체 작업의 요구를 충족하지 못할 수 있습니다.",
            "많은 저장 용량을 가진 단일 EC2 인스턴스를 실행하고 필요에 따라 수동으로 리소스를 할당하는 것은 확장 가능한 솔루션이 아닙니다. 이 접근 방식은 동적 확장을 허용하지 않으며, 이는 다양한 작업 부하를 효율적으로 처리하는 데 중요합니다. 또한 단일 인스턴스에 의존하는 것은 단일 실패 지점을 생성하고 성능 병목 현상을 초래할 수 있습니다."
        ]
    },
    {
        "Question Number": "43",
        "Situation": "한 금융 서비스 회사가 매일 온프레미스에서 대량의 고객 데이터를 생성하고 저장하고 있습니다. 엄격한 규제 및 준수 요구 사항으로 인해 이 데이터를 로컬에 보관해야 하지만, 저장 비용을 절감하기 위해 오래된, 자주 접근하지 않는 데이터를 AWS로 오프로드하고자 합니다. 그들은 기존 애플리케이션이나 워크플로를 방해하지 않고 아카이브된 데이터에 접근할 수 있도록 현재의 저장 인프라를 AWS로 원활하게 확장할 수 있는 솔루션이 필요합니다.",
        "Question": "어떤 AWS 서비스가 회사의 요구 사항을 가장 잘 충족합니까?",
        "Options": {
            "1": "Amazon S3와 라이프사이클 정책",
            "2": "AWS Direct Connect",
            "3": "AWS Storage Gateway",
            "4": "Amazon EBS 스냅샷 내보내기"
        },
        "Correct Answer": "AWS Storage Gateway",
        "Explanation": "AWS Storage Gateway는 온프레미스 환경과 클라우드 저장소를 원활하게 통합하도록 설계되었습니다. 이는 기업이 데이터를 로컬에 유지하면서 AWS로 저장 용량을 확장할 수 있는 하이브리드 클라우드 저장 솔루션을 제공합니다. 이 시나리오에서 금융 서비스 회사는 Storage Gateway를 사용하여 오래된, 자주 접근하지 않는 데이터를 AWS로 오프로드하여 규제 요구 사항을 준수하면서 저장 비용을 절감할 수 있습니다. 이 서비스는 기존 애플리케이션이나 워크플로를 방해하지 않고 아카이브된 데이터에 쉽게 접근할 수 있도록 하여 회사의 요구에 가장 적합합니다.",
        "Other Options": [
            "Amazon S3와 라이프사이클 정책은 사용자가 데이터 라이프사이클을 관리할 수 있는 저장 서비스이지만, 회사가 요구하는 온프레미스 인프라와의 원활한 통합을 제공하지 않습니다. 이는 온프레미스에서 S3로 데이터를 이동하기 위한 추가 단계를 요구하여 기존 워크플로를 방해할 수 있습니다.",
            "AWS Direct Connect는 온프레미스에서 AWS로의 전용 네트워크 연결을 제공하는 서비스입니다. 데이터 전송을 위한 대역폭을 개선하고 대기 시간을 줄일 수 있지만, 아카이브된 데이터에 대한 원활한 접근을 허용하는 하이브리드 저장 솔루션의 필요성을 직접적으로 해결하지는 않습니다.",
            "Amazon EBS 스냅샷 내보내기는 사용자가 EBS 스냅샷을 S3로 내보낼 수 있도록 하지만, 이는 EBS 볼륨의 백업 및 복구에 주로 초점을 맞추고 있으며 하이브리드 저장 솔루션을 제공하지 않습니다. 이는 AWS Storage Gateway가 제공하는 방식으로 아카이브된 데이터에 대한 지속적인 접근을 촉진하지 않습니다."
        ]
    },
    {
        "Question Number": "44",
        "Situation": "한 회사가 온프레미스 환경과 AWS VPC 간에 VPN 연결과 AWS Direct Connect 링크를 모두 설정했습니다. 매우 안전한 데이터 전송을 위해 모든 트래픽이 네트워크를 통과할 때 암호화되도록 하고자 합니다.",
        "Question": "데이터 센터와 AWS 간에 교환되는 모든 데이터의 암호화된 통신을 보장하기 위해 어떤 접근 방식이 가장 좋습니까?",
        "Options": {
            "1": "AWS Direct Connect에만 의존하여 추가 암호화의 필요성을 없앱니다.",
            "2": "AWS Direct Connect 위에 VPN을 구성하여 개인 연결에서 데이터를 암호화하여 종단 간 암호화를 보장합니다.",
            "3": "인터넷 게이트웨이(IGW)와 HTTPS를 사용하여 데이터가 인터넷을 통해 이동할 때 보안을 유지합니다.",
            "4": "Direct Connect에서 AWS Shield를 활성화하여 트래픽을 암호화하고 무단 접근을 방지합니다."
        },
        "Correct Answer": "AWS Direct Connect 위에 VPN을 구성하여 개인 연결에서 데이터를 암호화하여 종단 간 암호화를 보장합니다.",
        "Explanation": "AWS Direct Connect는 온프레미스 환경과 AWS 간의 전용 링크를 제공하지만, 전송되는 데이터를 본질적으로 암호화하지는 않습니다. 모든 교환되는 데이터가 암호화되도록 보장하기 위해 AWS Direct Connect 링크 위에 VPN을 구성하는 것이 최선의 접근 방식입니다. 이 설정은 전용 대역폭과 낮은 대기 시간을 활용하면서 안전하고 암호화된 통신을 가능하게 합니다. VPN은 데이터 패킷을 암호화하여 추가적인 보안 계층을 추가하며, 개인 링크가 손상되더라도 데이터는 안전하게 유지됩니다.",
        "Other Options": [
            "AWS Direct Connect에만 의존하는 것은 암호화를 보장하기에 충분하지 않습니다. 비록 전용 연결을 제공하지만, 전송 중인 데이터를 암호화하지 않으므로 가로채기에 취약합니다.",
            "이 옵션은 실제로 올바른 답변입니다. AWS Direct Connect 위에 VPN을 구성하는 것은 암호화된 통신을 보장하는 최선의 접근 방식입니다.",
            "인터넷 게이트웨이(IGW)와 HTTPS를 사용하는 것은 이 시나리오에 적용되지 않습니다. 질문에서는 데이터 센터와 AWS 간의 개인 연결을 원한다고 명시하고 있습니다. IGW는 공용 인터넷 접근을 위해 사용되며, HTTPS는 암호화를 제공하지만 개인적이고 안전한 연결의 요구를 충족하지 않습니다."
        ]
    },
    {
        "Question Number": "45",
        "Situation": "한 회사가 여러 계정에서 비정상적이고 무단 활동을 탐지하여 AWS 환경의 보안을 개선하고자 합니다. 그들은 Amazon GuardDuty를 고려하여 AI/ML 및 위협 인텔리전스를 사용하여 잠재적인 위협을 모니터링하고 식별하고자 합니다.",
        "Question": "Amazon GuardDuty는 보안 위협을 어떻게 탐지하며, 발견된 사항은 어떻게 처리됩니까?",
        "Options": {
            "1": "GuardDuty는 DNS, VPC 흐름 및 CloudTrail 로그를 분석하여 발견된 사항을 루트 사용자에게 수동 검토를 위해 직접 전송합니다.",
            "2": "GuardDuty는 DNS, VPC 흐름 및 CloudTrail 로그에서 AI/ML을 사용하여 발견된 사항을 생성하고, CloudWatch Events를 통해 SNS 알림이나 Lambda 호출과 같은 자동화된 응답을 트리거할 수 있습니다.",
            "3": "GuardDuty는 단일 계정의 트래픽만 모니터링하며, 사용자가 교차 계정 위협에 대해 로그를 수동으로 검토해야 합니다.",
            "4": "GuardDuty는 정적 규칙을 사용하여 활동을 탐지하고 VPC 흐름 로그에서 네트워크 이상에 대해서만 알림을 보냅니다."
        },
        "Correct Answer": "GuardDuty는 DNS, VPC 흐름 및 CloudTrail 로그에서 AI/ML을 사용하여 발견된 사항을 생성하고, CloudWatch Events를 통해 SNS 알림이나 Lambda 호출과 같은 자동화된 응답을 트리거할 수 있습니다.",
        "Explanation": "Amazon GuardDuty는 인공지능(AI) 및 머신러닝(ML)을 활용하여 DNS 로그, VPC 흐름 로그 및 CloudTrail 로그를 포함한 다양한 데이터 소스를 분석합니다. 이 분석은 비정상적인 패턴과 잠재적인 보안 위협을 식별하는 데 도움을 줍니다. GuardDuty가 위협을 탐지하면, 발견된 사항이 생성되어 AWS 서비스인 CloudWatch Events와 통합될 수 있습니다. 이 통합은 Amazon SNS를 통한 알림 전송이나 AWS Lambda 함수를 호출하여 수정 작업을 수행하는 등의 자동화된 응답을 가능하게 하여 AWS 환경의 보안 태세를 강화합니다.",
        "Other Options": [
            "옵션 1은 잘못된 것입니다. GuardDuty는 DNS, VPC 흐름 및 CloudTrail 로그를 분석하지만, 발견된 사항을 루트 사용자에게 직접 전송하지 않습니다. 대신, 발견된 사항은 자동으로 생성되며, 다른 AWS 서비스와 통합되어 자동화된 응답을 가능하게 합니다.",
            "옵션 3은 잘못된 것입니다. GuardDuty는 AWS Organizations를 통해 여러 계정을 모니터링할 수 있어, 단일 계정만이 아니라 전체 조직에 걸쳐 중앙 집중식 위협 탐지가 가능합니다. 교차 계정 위협에 대해 로그를 수동으로 검토할 필요가 없습니다.",
            "옵션 4는 잘못된 것입니다. GuardDuty는 정적 규칙에만 의존하지 않으며, 다양한 활동을 탐지하기 위해 AI와 ML을 활용합니다. VPC 흐름 로그의 네트워크 이상만 탐지하는 것이 아니라, 잠재적인 위협을 포괄적으로 식별하기 위해 다양한 유형의 로그를 분석합니다."
        ]
    },
    {
        "Question Number": "46",
        "Situation": "금융 서비스 회사가 고객 거래를 더 잘 처리하기 위해 단일 아키텍처에서 마이크로서비스로 전환하고 있습니다. 이 회사는 높은 가용성, 확장성 및 내결함성을 보장하기 위해 상태 비저장 마이크로서비스를 구현하고자 합니다.",
        "Question": "회사가 탄력적이고 느슨하게 결합된 마이크로서비스를 보장하기 위해 어떤 설계 접근 방식을 채택해야 합니까?",
        "Options": {
            "1": "각 마이크로서비스를 상태 비저장으로 설계하여 요청 간에 세션 정보를 유지하지 않도록 하고, 성능과 내구성을 위해 Amazon ElastiCache와 같은 분산 캐시에 상태를 저장합니다.",
            "2": "각 마이크로서비스가 서비스 자체 내에서 세션 상태를 유지하도록 설계하여 다른 서비스가 외부 시스템 없이 쉽게 상태에 접근할 수 있도록 합니다.",
            "3": "모든 마이크로서비스의 세션 데이터를 저장하는 단일 데이터베이스를 구현하여 시스템이 중앙에서 이를 접근하여 서비스 간 상태를 유지하도록 합니다.",
            "4": "Amazon RDS를 사용하여 각 마이크로서비스의 세션 상태를 처리하고 데이터 일관성과 가용성을 보장합니다."
        },
        "Correct Answer": "각 마이크로서비스를 상태 비저장으로 설계하여 요청 간에 세션 정보를 유지하지 않도록 하고, 성능과 내구성을 위해 Amazon ElastiCache와 같은 분산 캐시에 상태를 저장합니다.",
        "Explanation": "각 마이크로서비스를 상태 비저장으로 설계하는 것은 높은 가용성, 확장성 및 내결함성을 달성하는 데 중요합니다. 상태 비저장 마이크로서비스는 세션 정보를 유지하지 않으므로 쉽게 복제되고 수평으로 확장될 수 있습니다. Amazon ElastiCache와 같은 분산 캐시에 상태를 저장함으로써 회사는 특정 상태 관리 시스템에 서비스를 결합하지 않고도 데이터에 접근 가능하고 내구성을 보장할 수 있습니다. 이 접근 방식은 서비스 간 느슨한 결합을 촉진하여 독립적으로 운영할 수 있게 합니다.",
        "Other Options": [
            "각 마이크로서비스가 서비스 자체 내에서 세션 상태를 유지하도록 설계하는 것은 상태 비저장 원칙에 모순됩니다. 이 접근 방식은 서비스 간의 긴 결합을 초래하여 독립적으로 확장하고 관리하기 어렵게 만들며, 내결함성과 복구에 어려움을 초래할 수 있습니다.",
            "모든 세션 데이터를 저장하는 단일 데이터베이스를 구현하는 것은 상태 관리를 중앙 집중화하여 마이크로서비스 아키텍처의 분산화 목표에 반합니다. 이는 단일 실패 지점을 생성하고 시스템의 확장성과 탄력성을 제한할 수 있습니다.",
            "Amazon RDS를 사용하여 세션 상태 관리를 수행하는 것은 관계형 데이터베이스에 대한 의존성을 도입하여 병목 현상과 성능 저하를 초래할 수 있습니다. 데이터 일관성과 가용성을 제공하지만, 마이크로서비스가 따라야 할 상태 비저장 설계 원칙과 일치하지 않아 서비스 간 결합을 증가시킵니다."
        ]
    },
    {
        "Question Number": "47",
        "Situation": "조직은 민감한 데이터를 보호하는 데 사용되는 암호화 키가 매년 자동으로 회전되도록 요구합니다.",
        "Question": "조직이 이 요구 사항을 충족하기 위해 사용할 수 있는 AWS 기능은 무엇입니까?",
        "Options": {
            "1": "Amazon S3에서 수명 주기 정책을 구성합니다.",
            "2": "AWS KMS에서 자동 키 회전을 활성화합니다.",
            "3": "Amazon GuardDuty를 사용하여 키 사용을 모니터링합니다.",
            "4": "AWS Certificate Manager (ACM)를 사용하여 전송 중 암호화를 활성화합니다."
        },
        "Correct Answer": "AWS KMS에서 자동 키 회전을 활성화합니다.",
        "Explanation": "AWS Key Management Service (KMS)는 암호화 키를 자동으로 회전할 수 있는 기능을 제공합니다. 자동 키 회전을 활성화함으로써 조직은 민감한 데이터를 암호화하는 데 사용되는 키가 매년 수동 개입 없이 회전되도록 할 수 있습니다. 이 기능은 암호화 키를 정기적으로 변경하여 보안 모범 사례를 유지하는 데 도움을 주어 키 손상 위험을 줄입니다.",
        "Other Options": [
            "Amazon S3에서 수명 주기 정책을 구성하는 것은 S3의 객체 저장 수명 주기를 관리하는 것과 관련이 있으며, 암호화 키의 자동 회전과는 관련이 없습니다.",
            "Amazon GuardDuty를 사용하여 키 사용을 모니터링하는 것은 AWS 계정에서 악의적인 활동에 대한 위협 탐지 및 모니터링에 중점을 둡니다. 이는 무단 접근이나 키 사용의 이상을 식별하는 데 도움이 될 수 있지만, 키 회전을 위한 메커니즘을 제공하지 않습니다.",
            "AWS Certificate Manager (ACM)를 사용하여 전송 중 암호화를 활성화하는 것은 네트워크를 통해 데이터가 이동하는 동안 보안을 유지하는 것과 관련이 있습니다. 이는 전송 중 데이터 보호에 중요하지만, 암호화 키의 자동 회전 요구 사항을 해결하지 않습니다."
        ]
    },
    {
        "Question Number": "48",
        "Situation": "회사가 us-east-1 지역에서 웹 계층, 애플리케이션 계층 및 데이터베이스 계층을 포함하는 3계층 아키텍처의 사용자 지정 VPC를 설계하고 있습니다. 각 계층은 세 개의 가용 영역(AZ)에서 격리되어야 하며, 공용 및 개인 리소스에 대한 제어된 접근이 필요합니다. 회사는 또한 VPC 내에서 내부 호스트 이름 해석을 위한 DNS 지원을 활성화하고자 합니다.",
        "Question": "회사가 이러한 요구 사항을 충족하면서 제어된 공용 접근 및 내부 DNS 기능을 보장하기 위해 어떤 구성을 구현해야 합니까?",
        "Options": {
            "1": "/16 CIDR 블록을 VPC에 할당하고, 각 AZ의 각 계층에 대해 개인 서브넷을 사용하며, 개인 서브넷에서의 아웃바운드 인터넷 접근을 위해 각 AZ에 NAT 게이트웨이를 설정하고, DNS 기능을 위해 enableDnsHostnames 및 enableDnsSupport를 활성화합니다.",
            "2": "/24 CIDR 블록을 VPC에 사용하고, 웹 계층을 위해 각 AZ에 공용 서브넷을 생성하며, 직접 공용 접근을 위해 인터넷 게이트웨이를 배포하고, 내부 호스트 이름 해석을 방지하기 위해 enableDnsSupport를 비활성화합니다.",
            "3": "/28 CIDR 블록을 VPC에 할당하고, 모든 계층에 대해 공용 서브넷만 설정하며, 인터넷 접근을 위해 Bastion Host를 사용하고, DNS 기능을 개인 IP에만 제한하기 위해 enableDnsHostnames를 비활성화합니다.",
            "4": "/20 CIDR 블록으로 VPC를 구성하고, 웹 계층을 위해 각 AZ에 개인 서브넷을 설정하며, 아웃바운드 트래픽을 위해 NAT 인스턴스를 사용하고, 추가 보안을 위해 enableDnsHostnames를 비활성화합니다."
        },
        "Correct Answer": "/16 CIDR 블록을 VPC에 할당하고, 각 AZ의 각 계층에 대해 개인 서브넷을 사용하며, 개인 서브넷에서의 아웃바운드 인터넷 접근을 위해 각 AZ에 NAT 게이트웨이를 설정하고, DNS 기능을 위해 enableDnsHostnames 및 enableDnsSupport를 활성화합니다.",
        "Explanation": "이 옵션은 시나리오에 명시된 모든 요구 사항을 충족합니다. /16 CIDR 블록을 할당함으로써 회사는 3계층 아키텍처에 충분한 IP 주소 공간을 확보합니다. 각 AZ의 각 계층에 대해 개인 서브넷을 사용하면 필요한 격리와 보안을 제공합니다. NAT 게이트웨이는 개인 서브넷의 인스턴스가 업데이트나 외부 서비스에 접근할 수 있도록 하면서 공용 인터넷에서 접근할 수 없도록 합니다. enableDnsHostnames 및 enableDnsSupport를 모두 활성화하면 내부 리소스가 호스트 이름을 해석할 수 있어 VPC 내에서의 통신이 용이해집니다.",
        "Other Options": [
            "/24 CIDR 블록을 VPC에 사용하는 것은 여러 AZ에 걸쳐 있는 3계층 아키텍처에 대해 충분하지 않으며, 사용 가능한 IP 주소 수를 제한합니다. 웹 계층을 위해 공용 서브넷을 생성하는 것은 인터넷에 직접 노출되므로 제어된 접근 요구 사항과 일치하지 않습니다. enableDnsSupport를 비활성화하면 내부 호스트 이름 해석이 불가능해지며, 이는 중요한 요구 사항입니다.",
            "/28 CIDR 블록을 할당하는 것은 세 개의 AZ에 걸쳐 여러 계층을 지원해야 하는 VPC에는 너무 작아 IP 고갈을 초래할 것입니다. 모든 계층에 대해 공용 서브넷을 설정하는 것은 격리 및 제어된 접근 요구 사항에 모순됩니다. 또한 enableDnsHostnames를 비활성화하면 DNS 기능이 제한되어 내부 호스트 이름 해석이 불가능해집니다.",
            "/20 CIDR 블록으로 VPC를 구성하는 것은 /28보다 더 많은 IP 주소를 제공하지만, 여전히 3계층 아키텍처에 최적화되어 있지 않습니다. 웹 계층에 대해서만 개인 서브넷을 설정하는 것은 애플리케이션 및 데이터베이스 계층에 필요한 격리를 제공하지 않습니다. NAT 인스턴스 대신 NAT 게이트웨이를 사용하는 것은 성능 문제와 관리 오버헤드를 초래할 수 있습니다. enableDnsHostnames를 비활성화하면 DNS 기능이 제한되어 요구 사항을 충족하지 못합니다."
        ]
    },
    {
        "Question Number": "49",
        "Situation": "스타트업이 월간 AWS 비용을 면밀히 모니터링하여 예산 초과를 피하고 지출이 예측 한도를 초과할 경우 알림을 설정하고자 합니다. 또한 스타트업은 시간에 따른 지출 패턴의 추세를 분석하여 잠재적인 비용 절감 기회를 식별하고 AWS 사용을 최적화하고자 합니다.",
        "Question": "이러한 요구 사항을 가장 잘 충족하는 AWS 비용 관리 도구의 조합은 무엇입니까?",
        "Options": {
            "1": "AWS Budgets를 사용하여 지출 알림을 설정하고 AWS Cost Explorer를 사용하여 시간에 따른 지출 패턴과 추세를 분석합니다.",
            "2": "AWS Trusted Advisor를 구현하여 비용 절감 권장 사항을 식별하고 AWS Cost and Usage Report를 사용하여 상세한 비용 추적을 합니다.",
            "3": "AWS Cost and Usage Report를 활성화하여 포괄적인 추적을 수행하고 AWS Support에 가입하여 추가 비용 관리 통찰력을 얻습니다.",
            "4": "AWS Cost Explorer를 사용하여 비용 추세를 시각화하고 AWS Trusted Advisor를 사용하여 비용 최적화에 대한 정기적인 권장 사항을 받습니다."
        },
        "Correct Answer": "AWS Budgets를 사용하여 지출 알림을 설정하고 AWS Cost Explorer를 사용하여 시간에 따른 지출 패턴과 추세를 분석합니다.",
        "Explanation": "이 옵션은 스타트업의 요구 사항을 직접적으로 해결합니다. AWS Budgets를 사용하여 지출 한도에 대한 알림을 설정할 수 있어 예산 초과를 방지하는 데 도움이 됩니다. 또한 AWS Cost Explorer는 시간에 따른 지출 패턴과 추세를 분석할 수 있는 강력한 도구를 제공하여 스타트업이 비용 절감 기회를 식별하고 AWS 사용을 효과적으로 최적화할 수 있도록 합니다.",
        "Other Options": [
            "AWS Trusted Advisor를 비용 절감 권장 사항을 위해 구현하는 것은 유용하지만, 지출 알림을 설정할 수 있는 기능은 제공하지 않습니다. AWS Cost and Usage Report는 상세하지만 원시 데이터에 더 중점을 두어 추세 분석에는 덜 효과적입니다.",
            "AWS Cost and Usage Report를 활성화하는 것은 비용을 포괄적으로 추적하는 데 유익하지만, AWS Support에 가입하는 것은 직접적으로 비용 관리 통찰력을 제공하지 않습니다. 이 옵션은 AWS Budgets가 제공하는 능동적인 알림 기능이 부족하여 비용 모니터링에 중요합니다.",
            "AWS Cost Explorer를 사용하여 추세를 시각화하는 것은 좋은 선택이지만, AWS Trusted Advisor에만 의존하여 권장 사항을 받는 것은 예산 관리에 필요한 알림 메커니즘을 제공하지 않습니다. 이 조합은 스타트업의 지출 한도 모니터링 및 알림 요구 사항을 완전히 충족하지 않습니다."
        ]
    },
    {
        "Question Number": "50",
        "Situation": "회사가 AWS에서 안전한 VPC를 설정하고 개인 서브넷의 인스턴스에 대한 아웃바운드 인터넷 접근을 활성화해야 합니다. NAT 인스턴스 또는 NAT 게이트웨이를 사용하는 것을 고려하고 있습니다.",
        "Question": "NAT 인스턴스와 NAT 게이트웨이 간의 주요 차이점을 특히 보안 구성 및 유지 관리와 관련하여 올바르게 설명하는 것은 무엇입니까?",
        "Options": {
            "1": "NAT 인스턴스는 보안 그룹 사용을 지원하며 고가용성을 제공하는 반면, NAT 게이트웨이는 보안 그룹을 지원하지 않고 트래픽 필터링을 위해 네트워크 ACL에 의존합니다.",
            "2": "NAT 게이트웨이는 NAT 인스턴스보다 더 높은 가용성과 대역폭을 제공하며 유지 관리가 적게 필요하지만, 트래픽 필터링을 위해 보안 그룹이 아닌 네트워크 ACL만 지원합니다.",
            "3": "NAT 인스턴스는 가용 영역 내에서 자동 확장 및 고가용성을 제공하여 생산 작업에 이상적입니다.",
            "4": "NAT 게이트웨이는 다목적 사용을 허용하며, NAT 인스턴스는 AWS 관리 제한으로 인해 이를 수행할 수 없습니다."
        },
        "Correct Answer": "NAT 게이트웨이는 NAT 인스턴스보다 더 높은 가용성과 대역폭을 제공하며 유지 관리가 적게 필요하지만, 트래픽 필터링을 위해 보안 그룹이 아닌 네트워크 ACL만 지원합니다.",
        "Explanation": "NAT 게이트웨이는 개인 서브넷의 인스턴스에 대한 아웃바운드 인터넷 접근을 활성화하기 위해 관리되고 고가용성 솔루션을 제공하도록 설계되었습니다. NAT 게이트웨이는 트래픽의 대역폭 요구를 수용하기 위해 자동으로 확장되므로 생산 작업에 적합합니다. 또한 NAT 게이트웨이는 AWS에서 관리되므로 최소한의 유지 관리가 필요하지만, NAT 인스턴스는 수동 설정, 확장 및 유지 관리가 필요합니다. NAT 게이트웨이는 보안 그룹을 지원하지 않지만, 네트워크 ACL을 사용하여 제어할 수 있으며, 이는 보안 그룹을 지원하는 NAT 인스턴스와의 주요 차이점입니다.",
        "Other Options": [
            "NAT 인스턴스는 보안 그룹 사용을 지원하며 고가용성을 제공하는 반면, NAT 게이트웨이는 보안 그룹을 지원하지 않고 트래픽 필터링을 위해 네트워크 ACL에 의존합니다. 이 설명은 잘못된 것입니다. NAT 인스턴스는 보안 그룹을 지원하지만, NAT 게이트웨이는 보안 그룹을 전혀 지원하지 않고 오직 네트워크 ACL에만 의존합니다. 또한 NAT 게이트웨이는 고가용성을 위해 설계되었습니다.",
            "NAT 인스턴스는 가용 영역 내에서 자동 확장 및 고가용성을 제공하여 생산 작업에 이상적입니다. 이 설명은 잘못된 것입니다. NAT 인스턴스는 자동 확장을 제공하지 않으며, 확장을 위해 수동 개입이 필요하고, 여러 가용 영역에 걸쳐 구성되지 않는 한 본질적으로 고가용성을 제공하지 않습니다.",
            "NAT 게이트웨이는 다목적 사용을 허용하며, NAT 인스턴스는 AWS 관리 제한으로 인해 이를 수행할 수 없습니다. 이 설명은 잘못된 것입니다. NAT 게이트웨이는 NAT 기능을 위해 설계되었으며, Bastion Host로 작동할 수 없습니다. Bastion Host는 일반적으로 개인 서브넷의 인스턴스에 대한 안전한 접근을 허용하도록 구성된 EC2 인스턴스입니다."
        ]
    },
    {
        "Question Number": "51",
        "Situation": "소매 회사인 ShopSmart는 고객 데이터를 포함한 PII를 Amazon S3 버킷에 저장합니다. 데이터 프라이버시 규정을 준수하기 위해, 그들은 민감한 정보를 자동으로 식별하고 분류할 수 있는 솔루션이 필요합니다. 또한, 그들은 비즈니스에 특정한 고유 데이터 패턴을 감지하기 위한 사용자 정의 규칙을 만들 수 있는 옵션을 원합니다. ShopSmart는 이러한 요구를 해결하기 위해 Amazon Macie를 고려하고 있습니다.",
        "Question": "Amazon Macie는 S3 버킷에 있는 민감한 정보의 데이터 보안과 프라이버시를 어떻게 보장하며, 데이터 식별자를 생성하기 위한 어떤 옵션이 있습니까?",
        "Options": {
            "1": "Amazon Macie는 미리 정의된 데이터 식별자만 제공하여, 재무 정보 및 의료 기록과 같은 특정 데이터 유형에만 제한되며, 다른 민감한 데이터 패턴에 대한 사용자 정의 옵션이 없습니다.",
            "2": "Amazon Macie는 기계 학습과 관리되는 데이터 식별자를 사용하여 PII 및 재무 정보를 포함한 민감한 데이터를 자동으로 발견하고 분류합니다. 또한, 정규 표현식과 키워드 근접성을 사용하여 사용자 정의 데이터 식별자를 생성할 수 있어, 고유한 조직의 요구에 따라 더 세분화된 데이터 식별이 가능합니다.",
            "3": "Amazon Macie는 주로 비정상적인 패턴에 대한 네트워크 트래픽 모니터링에 중점을 두며, 데이터 이동에 대한 경고를 제공하지만 S3 버킷에 저장된 민감한 정보를 직접 식별하지는 않습니다.",
            "4": "Amazon Macie는 데이터 발견 및 분류를 위해 AWS Security Hub에만 의존하며, 사용자가 미리 정의된 기준에 따라 데이터를 감지하고 분류하기 위해 사용자 정의 EventBridge 규칙을 설정해야 합니다."
        },
        "Correct Answer": "Amazon Macie는 기계 학습과 관리되는 데이터 식별자를 사용하여 PII 및 재무 정보를 포함한 민감한 데이터를 자동으로 발견하고 분류합니다. 또한, 정규 표현식과 키워드 근접성을 사용하여 사용자 정의 데이터 식별자를 생성할 수 있어, 고유한 조직의 요구에 따라 더 세분화된 데이터 식별이 가능합니다.",
        "Explanation": "Amazon Macie는 조직이 Amazon S3에 저장된 민감한 데이터를 자동으로 발견하고 분류하며 보호할 수 있도록 설계되었습니다. 이는 기계 학습 알고리즘을 활용하여 개인 식별 정보(PII) 및 재무 데이터를 포함한 민감한 정보를 식별하고 분류합니다. 또한, Macie는 특정 비즈니스 요구를 충족하기 위해 맞춤형 데이터 식별자를 생성할 수 있는 유연성을 제공합니다. 이는 정규 표현식과 키워드 근접성을 사용하여 조직의 운영과 관련된 고유한 패턴을 정의할 수 있게 하여 데이터 보안 및 규정 준수 노력을 강화합니다.",
        "Other Options": [
            "옵션 1은 Amazon Macie가 미리 정의된 데이터 식별자에만 기능을 제한하지 않기 때문에 잘못되었습니다. 관리되는 데이터 식별자와 사용자 정의 식별자를 생성할 수 있는 기능을 제공하여 민감한 데이터 감지 범위를 넓힙니다.",
            "옵션 3은 Amazon Macie가 주로 네트워크 트래픽 모니터링에 중점을 두지 않기 때문에 잘못되었습니다. 대신, S3 버킷 내의 민감한 데이터를 식별하고 분류하는 것이 주요 기능으로, 데이터 프라이버시 및 보안을 위한 핵심 도구입니다.",
            "옵션 4는 Amazon Macie가 데이터 발견 및 분류에서 독립적으로 작동하기 때문에 잘못되었습니다. AWS Security Hub와 통합하여 더 넓은 보안 관리를 할 수 있지만, 핵심 기능을 위해 그것에만 의존하지 않습니다."
        ]
    },
    {
        "Question Number": "52",
        "Situation": "온라인 게임 회사는 전 세계에 사용자가 있으며, 애플리케이션을 최종 사용자에 더 가깝게 배포하여 지연 시간을 최소화하고 싶어합니다. 또한, 서로 다른 지역의 사용자가 애플리케이션에 접근할 때 지역 간 데이터 전송 요금을 피하여 비용을 최적화하고자 합니다.",
        "Question": "이 요구 사항을 충족하는 데 가장 적합한 접근 방식은 무엇입니까?",
        "Options": {
            "1": "모든 리소스를 단일 AWS 리전에서 배포하고 CloudFront를 사용하여 캐싱합니다.",
            "2": "하나의 AWS 리전 내 여러 가용 영역에 리소스를 배포합니다.",
            "3": "사용자 위치에 따라 여러 AWS 리전에서 애플리케이션을 배포합니다.",
            "4": "단일 가용 영역을 사용하고 글로벌 DNS 라우팅에 의존합니다."
        },
        "Correct Answer": "사용자 위치에 따라 여러 AWS 리전에서 애플리케이션을 배포합니다.",
        "Explanation": "여러 AWS 리전에서 애플리케이션을 배포하면 게임 회사가 리소스를 최종 사용자에 더 가깝게 배치할 수 있어 지연 시간이 크게 줄어듭니다. 다양한 리전에 인스턴스를 두면 사용자가 가장 가까운 서버에 연결할 수 있어 데이터 전송 시간을 최소화할 수 있습니다. 또한, 이 접근 방식은 지역 간 데이터 전송 요금을 피하는 데 도움이 됩니다. 사용자가 자신의 지역에서 애플리케이션에 접근할 때 지역 간 데이터 전송과 관련된 비용이 발생하지 않습니다.",
        "Other Options": [
            "모든 리소스를 단일 AWS 리전에서 배포하고 CloudFront를 사용하여 캐싱하는 것은 어느 정도 지연 시간을 줄일 수 있지만, 서로 다른 지역의 사용자가 애플리케이션에 접근할 때 지역 간 데이터 전송 요금 문제를 해결하지는 않습니다. CloudFront는 콘텐츠를 캐시할 수 있지만, 전 세계 모든 사용자에 대한 지연 시간을 완전히 완화하지는 못할 수 있습니다.",
            "하나의 AWS 리전 내 여러 가용 영역에 리소스를 배포하면 가용성과 장애 내성이 향상되지만, 해당 리전에서 멀리 떨어진 사용자에 대한 지연 시간을 크게 줄이지는 않습니다. 또한, 모든 사용자가 여전히 동일한 리전에 접근하므로 지역 간 데이터 전송 비용에도 도움이 되지 않습니다.",
            "단일 가용 영역을 사용하고 글로벌 DNS 라우팅에 의존하는 것은 해당 영역에서 멀리 떨어진 사용자에 대한 지연 시간을 효과적으로 최소화하지 못합니다. DNS 라우팅은 사용자를 가장 가까운 엔드포인트로 안내할 수 있지만, 단일 가용 영역에서 지리적으로 먼 사용자에 대한 높은 지연 시간 문제를 해결하지 못하며, 지역 간 데이터 전송 요금 문제도 해결하지 않습니다."
        ]
    },
    {
        "Question Number": "53",
        "Situation": "데이터 분석 회사는 고객을 위해 대규모 처리 작업을 수행하지만, 수요가 주중에 크게 변동합니다. 이 회사는 이러한 작업을 처리하면서 저수요 기간 동안 비용을 최소화할 수 있는 비용 효율적인 컴퓨팅 솔루션을 원합니다.",
        "Question": "이 작업의 비용을 최적화하는 데 가장 적합한 접근 방식은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "온디맨드 EC2 인스턴스를 사용하고 필요에 따라 수동으로 인스턴스를 시작합니다.",
            "2": "고정 수의 EC2 인스턴스에 대해 예약 인스턴스를 사용합니다.",
            "3": "처리 작업을 위해 스팟 인스턴스를 사용하는 오토 스케일링 그룹을 배포합니다.",
            "4": "AWS Lambda를 사용하여 모든 처리 작업을 온디맨드로 실행합니다.",
            "5": "예측 가능한 작업에 대한 비용을 줄이기 위해 EC2 세이빙스 플랜을 구현합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "처리 작업을 위해 스팟 인스턴스를 사용하는 오토 스케일링 그룹을 배포합니다.",
            "AWS Lambda를 사용하여 모든 처리 작업을 온디맨드로 실행합니다."
        ],
        "Explanation": "처리 작업을 위해 스팟 인스턴스를 사용하는 오토 스케일링 그룹을 배포하는 것은 변동 작업에 대한 비용 효율적인 솔루션입니다. 스팟 인스턴스는 온디맨드 가격에 비해 최대 90% 할인된 가격으로 제공되며, 시작 및 종료 시간이 유연한 애플리케이션이나 중단을 견딜 수 있는 애플리케이션에 적합합니다. 오토 스케일링은 회사가 주어진 시간에 적절한 용량을 유지하도록 보장하여 비용을 최적화합니다. AWS Lambda를 사용하여 모든 처리 작업을 온디맨드로 실행하는 것도 좋은 옵션입니다. 이는 회사가 서버를 프로비저닝하거나 관리하지 않고 코드를 실행할 수 있게 하며, 소비한 컴퓨팅 시간에 대해서만 비용을 지불하므로 간헐적인 작업에 대해 매우 비용 효율적일 수 있습니다.",
        "Other Options": [
            "온디맨드 EC2 인스턴스를 사용하고 필요에 따라 수동으로 인스턴스를 시작하는 것은 변동 작업에 대한 가장 비용 효율적인 솔루션이 아닙니다. 유연성을 제공하지만, 스팟 인스턴스나 AWS Lambda의 비용 절감 효과를 활용하지 못합니다.",
            "고정 수의 EC2 인스턴스에 대해 예약 인스턴스를 사용하는 것은 변동 작업에 적합하지 않습니다. 이는 수요에 따라 확장하거나 축소할 수 있는 유연성을 제공하지 않습니다. 예약 인스턴스는 온디맨드 가격에 비해 상당한 할인을 제공하지만, 1년 또는 3년의 약정이 필요하여 변동 작업에 적합하지 않을 수 있습니다.",
            "예측 가능한 작업에 대한 비용을 줄이기 위해 EC2 세이빙스 플랜을 구현하는 것은 이 시나리오에 가장 좋은 옵션이 아닙니다. 세이빙스 플랜은 AWS 컴퓨팅 사용에 대한 할인을 제공하지만, 1년 또는 3년 동안 일관된 사용량(시간당 $로 측정)에 대한 약정이 필요하여 변동 작업에 적합하지 않을 수 있습니다."
        ]
    },
    {
        "Question Number": "54",
        "Situation": "분석 팀에서 사용하는 보고 애플리케이션은 인사이트를 빠르고 효율적으로 생성하기 위해 높은 볼륨의 읽기 쿼리를 처리해야 합니다. 데이터베이스는 쓰기 작업에 대한 단일 소스를 가지고 있지만, 기본 인스턴스가 무거운 작업을 처리할 때에도 낮은 지연 시간으로 높은 읽기 트래픽을 지원해야 합니다. 팀은 읽기 부하를 분산하고 분석 쿼리에 대한 데이터베이스에 대한 중단 없는 접근을 제공할 수 있는 설정을 원합니다.",
        "Question": "이것을 가장 잘 달성할 수 있는 데이터베이스 복제 전략은 무엇입니까?",
        "Options": {
            "1": "기본 데이터베이스에 대해 Multi-AZ 배포를 활성화하여 가용성을 높이기 위해 대기 인스턴스로 자동 장애 조치를 허용합니다.",
            "2": "읽기 트래픽을 기본 데이터베이스에서 오프로드하기 위해 읽기 복제본을 사용하여 작업을 분산하고 읽기 요청의 지연 시간을 줄입니다.",
            "3": "고가용성을 지원하고 서로 다른 리전 간의 읽기 및 쓰기 트래픽을 분산하기 위해 다중 리전 활성-활성 설정을 배포합니다.",
            "4": "높은 읽기 트래픽 기간 동안 데이터 일관성을 보장하기 위해 데이터베이스를 동기식 복제만으로 구성합니다."
        },
        "Correct Answer": "읽기 트래픽을 기본 데이터베이스에서 오프로드하기 위해 읽기 복제본을 사용하여 작업을 분산하고 읽기 요청의 지연 시간을 줄입니다.",
        "Explanation": "읽기 복제본을 사용하는 것은 이 시나리오에서 높은 볼륨의 읽기 쿼리를 처리하는 가장 효과적인 전략입니다. 읽기 복제본은 기본 데이터베이스가 쓰기 작업에 집중할 수 있도록 하여 여러 복제본에 읽기 요청을 분산합니다. 이 설정은 읽기 부하를 분산할 뿐만 아니라, 읽기 쿼리를 읽기 작업에 최적화된 복제본이 처리할 수 있어 지연 시간을 줄입니다. 또한, 기본 인스턴스가 무거운 작업을 처리하고 있는 경우에도 읽기 복제본은 데이터에 대한 중단 없는 접근을 제공하여 분석 쿼리를 신속하고 효율적으로 실행할 수 있도록 보장합니다.",
        "Other Options": [
            "Multi-AZ 배포를 활성화하면 주로 가용성과 장애 조치 기능이 향상되지만, 높은 읽기 트래픽을 처리해야 하는 필요를 구체적으로 해결하지는 않습니다. 이는 장애 조치를 위한 대기 인스턴스를 제공하지만, 읽기 작업을 분산하지 않으므로 분석 팀의 요구에 필수적인 요소입니다.",
            "다중 리전 활성-활성 설정을 배포하면 고가용성과 부하 분산을 제공할 수 있지만, 더 복잡하고 리전 간 데이터 동기화로 인해 지연 시간이 발생할 수 있습니다. 이 옵션은 읽기 트래픽을 효율적으로 관리하는 데 중점을 두는 주어진 시나리오에 필요하지 않습니다.",
            "데이터베이스를 동기식 복제만으로 구성하면 데이터 일관성을 보장하지만, 높은 읽기 트래픽 기간 동안 지연 시간을 초래할 수 있습니다. 동기식 복제는 모든 복제본이 데이터를 수신했음을 확인해야 기본이 진행될 수 있으므로, 읽기 작업이 느려지고 낮은 지연 시간의 읽기 접근 필요를 효과적으로 해결하지 못합니다."
        ]
    },
    {
        "Question Number": "55",
        "Situation": "스타트업은 Amazon S3에 사용자 데이터를 저장하고 데이터 수명 주기 정책을 구현하여 저장 비용을 최적화하고자 합니다. 데이터는 처음 30일 동안 자주 접근되며 그 이후에는 거의 접근되지 않지만, 규정 준수를 위해 5년 동안 보존해야 합니다.",
        "Question": "가장 비용 효율적인 데이터 수명 주기 정책은 무엇입니까?",
        "Options": {
            "1": "데이터를 S3 Standard에 저장하고 30일 후에 Glacier로 이동합니다.",
            "2": "데이터 수명 주기 전반에 걸쳐 S3 Intelligent-Tiering에 저장합니다.",
            "3": "30일 후에 데이터를 S3 Standard-IA로 이동한 다음 1년 후에 Glacier Deep Archive로 이동합니다.",
            "4": "모든 데이터를 S3 Standard에 저장하고 5년 후에 삭제합니다."
        },
        "Correct Answer": "30일 후에 데이터를 S3 Standard-IA로 이동한 다음 1년 후에 Glacier Deep Archive로 이동합니다.",
        "Explanation": "이 옵션은 데이터가 자주 접근되는 첫 30일 동안 S3 Standard를 활용하여 최적의 성능과 비용을 보장하므로 가장 비용 효율적입니다. 30일 후, 데이터를 S3 Standard-IA(비정기적 접근)로 이동하면 드물게 접근되는 데이터의 저장 비용을 줄일 수 있습니다. 마지막으로, 1년 후 Glacier Deep Archive로 전환하면 장기 보존을 위한 가장 낮은 저장 비용을 제공하여 5년 동안 데이터를 보존해야 하는 규정 준수 요구 사항과 일치합니다. 이 전략은 데이터의 수명 주기 전반에 걸쳐 비용과 접근 요구를 효과적으로 균형 있게 관리합니다.",
        "Other Options": [
            "데이터를 S3 Standard에 저장하고 30일 후에 Glacier로 이동하는 것은 첫 30일 동안 더 높은 비용이 발생합니다. 이는 데이터를 S3 Standard에 유지하기 때문이며, Standard-IA보다 더 비쌉니다. 또한, 30일 후 Glacier로 이동하는 것은 최적이 아닐 수 있습니다. 데이터는 여전히 5년 동안 보존해야 하며, Glacier는 자주 접근하는 데이터에 적합하지 않습니다.",
            "데이터를 S3 Intelligent-Tiering에 저장하는 것은 데이터 접근 패턴이 변경될 때 자동으로 두 개의 접근 계층 간에 데이터를 이동하지만, 이 특정 사용 사례에 대해 가장 비용 효율적인 솔루션이 아닐 수 있습니다. 데이터가 처음 30일 동안 자주 접근되고 그 이후에는 드물게 접근되므로, Standard-IA로 이동하는 것과 같은 보다 맞춤형 접근 방식이 Intelligent-Tiering의 수수료보다 더 많은 비용을 절감할 수 있을 것입니다.",
            "모든 데이터를 S3 Standard에 저장하고 5년 후에 삭제하는 것은 가장 비용 효율적이지 않습니다. 이는 전체 기간 동안 모든 데이터를 S3 Standard에 유지하므로 가장 비싼 저장 클래스입니다. 또한, 첫 30일 이후 드물게 접근되는 데이터에 대한 저비용 저장 옵션을 활용하지 않습니다."
        ]
    },
    {
        "Question Number": "56",
        "Situation": "한 전자상거래 회사가 시스템 장애 발생 시 거래 데이터를 보호하고자 합니다. 잠재적인 데이터 손실을 제한하기 위해, 그들은 5분의 엄격한 복구 지점 목표(RPO)를 설정했습니다. 이는 장애 발생 시 최대 5분 분량의 데이터만 손실을 감당할 수 있음을 의미합니다. 이 최소 RPO를 달성하기 위해 데이터 복제를 최신 상태로 유지하는 솔루션이 필요합니다.",
        "Question": "다음 중 어떤 접근 방식이 이 RPO 요구 사항을 가장 잘 충족할 수 있습니까?",
        "Options": {
            "1": "데이터베이스의 시간별 스냅샷을 찍어 정기적인 데이터 복구 지점을 제공하고, 마지막 시간별 백업까지 복원할 수 있도록 합니다.",
            "2": "두 번째 데이터베이스로의 지속적인 데이터 복제를 구현하여 거의 실시간 업데이트를 보장하고 잠재적인 데이터 손실을 최소화합니다.",
            "3": "10분마다 Amazon S3에 데이터를 백업하여 필요에 따라 복원할 수 있는 정기적인 복구 지점을 생성합니다.",
            "4": "비용 효율적으로 데이터 변경 사항을 캡처하기 위해 주간 전체 백업과 일일 증분 백업을 사용합니다."
        },
        "Correct Answer": "두 번째 데이터베이스로의 지속적인 데이터 복제를 구현하여 거의 실시간 업데이트를 보장하고 잠재적인 데이터 손실을 최소화합니다.",
        "Explanation": "지속적인 데이터 복제는 기본 데이터베이스의 실시간 또는 거의 실시간 업데이트를 두 번째 데이터베이스로 수행할 수 있게 합니다. 이 접근 방식은 기본 데이터베이스에서 이루어진 모든 변경 사항이 즉시 두 번째 데이터베이스에 반영되도록 하여, 잠재적인 데이터 손실을 몇 초 또는 몇 분으로 최소화합니다. 이는 전자상거래 회사가 설정한 5분의 엄격한 복구 지점 목표(RPO)와 완벽하게 일치합니다. 이 방법은 데이터 복제를 최신 상태로 유지하는 요구 사항을 충족하는 가장 효과적인 방법입니다.",
        "Other Options": [
            "데이터베이스의 시간별 스냅샷을 찍는 것은 RPO 요구 사항인 5분을 충족하지 못합니다. 마지막 스냅샷이 찍힌 직후에 장애가 발생하면 최대 59분의 데이터 손실이 발생할 수 있습니다.",
            "10분마다 Amazon S3에 데이터를 백업하는 것은 5분의 RPO를 충분히 충족하지 못합니다. 다음 백업 직전에 장애가 발생하면 최대 9분의 데이터 손실이 발생할 수 있습니다.",
            "주간 전체 백업과 일일 증분 백업을 사용하는 것은 5분의 RPO에 적합하지 않습니다. 이 방법은 마지막 증분 백업이 찍힌 시점에 따라 최대 24시간까지 상당한 데이터 손실을 초래할 수 있습니다."
        ]
    },
    {
        "Question Number": "57",
        "Situation": "대규모 전자상거래 플랫폼이 재고 업데이트, 주문 처리 및 고객 알림을 관리하기 위해 이벤트 기반 아키텍처를 구현해야 합니다. 플랫폼은 시스템의 고가용성, 장애에 대한 복원력 및 트래픽에 따라 자동으로 확장할 수 있는 기능을 보장해야 합니다.",
        "Question": "이러한 목표를 달성하기 위해 어떤 아키텍처 설계를 구현해야 합니까? (두 가지 선택)",
        "Options": {
            "1": "Amazon SQS를 사용하여 서비스를 분리하고 비동기 메시지 처리를 보장하며, Amazon SNS를 사용하여 여러 구독자에게 이벤트를 방송합니다. AWS Lambda를 구현하여 이벤트를 처리하고 자동으로 확장합니다.",
            "2": "이벤트 소스에서 메시지를 처리하기 위해 사용자 지정 애플리케이션을 실행하는 Amazon EC2 인스턴스를 사용하고, Amazon Route 53을 구성하여 부하에 따라 트래픽을 라우팅합니다.",
            "3": "이벤트 처리를 위해 다중 가용 영역 배포가 있는 Amazon RDS를 사용하고, 확장을 위해 Amazon DynamoDB에 메시지를 저장합니다.",
            "4": "실시간으로 이벤트 데이터를 처리하기 위해 Amazon Kinesis Data Streams를 사용하고, 데이터를 쿼리하기 위해 Amazon Elasticsearch Service와 통합합니다.",
            "5": "이벤트 처리 워크플로를 조정하기 위해 AWS Step Functions를 구현하고, 메시지 브로커링을 위해 Amazon MQ를 사용합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon SQS를 사용하여 서비스를 분리하고 비동기 메시지 처리를 보장하며, Amazon SNS를 사용하여 여러 구독자에게 이벤트를 방송합니다. AWS Lambda를 구현하여 이벤트를 처리하고 자동으로 확장합니다.",
            "Amazon Kinesis Data Streams를 사용하여 실시간으로 이벤트 데이터를 처리하고, 데이터를 쿼리하기 위해 Amazon Elasticsearch Service와 통합합니다."
        ],
        "Explanation": "Amazon SQS와 SNS는 각각 서비스를 분리하고 여러 구독자에게 이벤트를 방송하는 데 사용됩니다. 이는 고가용성과 장애에 대한 복원력을 보장합니다. AWS Lambda는 서버리스이며, 작업 부하에 따라 자동으로 확장되므로 이벤트 처리에 적합합니다. 반면, Amazon Kinesis Data Streams는 실시간 이벤트 데이터를 처리하도록 설계되어 있어 전자상거래 플랫폼에 매우 중요합니다. Amazon Elasticsearch Service는 이 데이터를 효율적으로 쿼리할 수 있게 합니다.",
        "Other Options": [
            "사용자 지정 애플리케이션을 실행하는 Amazon EC2 인스턴스를 사용하여 이벤트 소스에서 메시지를 처리하고 Amazon Route 53을 구성하여 부하에 따라 트래픽을 라우팅하는 것은 최선의 선택이 아닙니다. EC2 인스턴스는 애플리케이션을 실행하는 데 사용할 수 있지만, 이 접근 방식은 본질적으로 이벤트 기반 아키텍처, 고가용성, 장애에 대한 복원력 및 자동 확장을 제공하지 않습니다.",
            "이벤트 처리를 위해 다중 가용 영역 배포가 있는 Amazon RDS를 사용하고 Amazon DynamoDB에 메시지를 저장하는 것은 이상적이지 않습니다. RDS와 DynamoDB는 강력한 AWS 서비스이지만 이벤트 기반 아키텍처를 위해 설계되지 않았습니다. RDS는 관계형 데이터베이스 서비스이며, 이벤트 처리 서비스가 아니고, DynamoDB는 확장 가능하지만 이벤트 메시징을 위해 설계되지 않았습니다.",
            "이벤트 처리 워크플로를 조정하기 위해 AWS Step Functions를 구현하고 Amazon MQ를 메시지 브로커로 사용하는 것은 최선의 선택이 아닙니다. Step Functions는 워크플로를 조정할 수 있지만, 이 시나리오에 필요한 고가용성, 장애에 대한 복원력 및 자동 확장을 본질적으로 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "58",
        "Situation": "한 회사가 Amazon EC2에서 고성능 컴퓨팅 애플리케이션을 배포하고 있으며, 인스턴스 간의 네트워크 지연 시간을 최소화하고 패킷당 초 성능을 극대화하고자 합니다. 동시에, 각 인스턴스를 서로 다른 랙에 격리하여 최대 가용성과 복원력을 요구하는 또 다른 애플리케이션이 있습니다.",
        "Question": "회사가 이러한 애플리케이션에 대해 어떤 배치 그룹 유형을 사용해야 하며, 그 이유는 무엇입니까?",
        "Options": {
            "1": "고성능 애플리케이션을 위해 클러스터 배치 그룹을 사용하여 낮은 지연 시간과 높은 처리량을 달성하고, 높은 가용성과 랙 간 격리를 요구하는 애플리케이션을 위해 스프레드 배치 그룹을 사용합니다.",
            "2": "두 애플리케이션 모두에 대해 스프레드 배치 그룹을 사용하여 복원력을 보장하고 여러 랙에 인스턴스를 격리합니다.",
            "3": "고성능 애플리케이션을 위해 파티션 배치 그룹을 사용하여 높은 처리량을 제공하고, 격리된 애플리케이션을 위해 클러스터 배치 그룹을 사용하여 지연 시간을 줄입니다.",
            "4": "두 애플리케이션 모두에 대해 클러스터 배치 그룹을 사용하여 지연 시간을 최소화하고 인스턴스 간 성능을 증가시킵니다."
        },
        "Correct Answer": "고성능 애플리케이션을 위해 클러스터 배치 그룹을 사용하여 낮은 지연 시간과 높은 처리량을 달성하고, 높은 가용성과 랙 간 격리를 요구하는 애플리케이션을 위해 스프레드 배치 그룹을 사용합니다.",
        "Explanation": "클러스터 배치 그룹은 인스턴스를 단일 가용 영역 내에서 가깝게 배치하여 낮은 지연 시간과 높은 처리량을 제공하도록 설계되었습니다. 이는 빠른 인스턴스 간 통신이 필요한 고성능 컴퓨팅 애플리케이션에 이상적입니다. 반면, 스프레드 배치 그룹은 인스턴스가 서로 다른 랙에 배치되도록 하여 동시에 발생할 수 있는 장애의 위험을 줄여 가용성과 복원력을 향상시킵니다. 이는 서로 격리되어야 하는 애플리케이션에 적합합니다.",
        "Other Options": [
            "두 애플리케이션 모두에 대해 스프레드 배치 그룹을 사용하는 것은 복원력과 격리를 보장하지만, 고성능 애플리케이션의 낮은 지연 시간과 높은 처리량을 최적화하지 못합니다. 이는 중요한 요구 사항입니다.",
            "고성능 애플리케이션에 파티션 배치 그룹을 사용하는 것은 잘못된 선택입니다. 파티션 배치 그룹은 높은 가용성과 내결함성을 요구하는 애플리케이션을 위해 설계되었으며, 낮은 지연 시간과 높은 처리량을 위해 특별히 설계되지 않았습니다. 또한, 격리된 애플리케이션에 클러스터 배치 그룹을 사용하는 것은 랙 간의 필요한 복원력을 제공하지 않습니다.",
            "두 애플리케이션 모두에 대해 클러스터 배치 그룹을 사용하는 것은 낮은 지연 시간과 성능을 최적화하지만, 높은 가용성을 요구하는 애플리케이션에 필요한 격리와 복원력을 제공하지 않습니다. 모든 인스턴스가 동일한 랙에 배치되기 때문입니다."
        ]
    },
    {
        "Question Number": "59",
        "Situation": "한 회사가 고객에게 웹 인터페이스를 통해 API를 노출하는 애플리케이션을 개발하고 있습니다. 회사는 API가 수요에 따라 자동으로 확장되고, 트래픽 급증을 처리하며, 효율적인 API 관리를 제공할 수 있도록 해야 합니다.",
        "Question": "회사가 이를 달성하기 위해 어떤 AWS 서비스를 사용해야 하며, 확장성과 복원력을 보장하기 위해 어떤 설계 원칙을 따라야 합니까?",
        "Options": {
            "1": "Amazon API Gateway를 사용하여 API를 생성하고 관리하며, AWS Lambda와 결합하여 예측할 수 없는 작업 부하를 처리하는 무상태 계산을 수행합니다. 지연 시간을 줄이고 성능을 개선하기 위해 캐싱 전략을 구현합니다.",
            "2": "Amazon EC2를 사용하여 API를 호스팅하고 Auto Scaling 그룹으로 트래픽을 관리하며, Amazon RDS에 데이터를 저장하여 높은 가용성을 유지합니다.",
            "3": "AWS Fargate를 사용하여 API를 실행하는 Docker 컨테이너를 관리하고, 애플리케이션 데이터를 저장하기 위해 Amazon DynamoDB에 직접 API 호출을 구현합니다.",
            "4": "AWS Elastic Load Balancer를 사용하여 API 트래픽을 EC2 인스턴스로 라우팅하고, API 데이터를 Amazon S3에 저장하여 높은 확장성을 제공합니다."
        },
        "Correct Answer": "Amazon API Gateway를 사용하여 API를 생성하고 관리하며, AWS Lambda와 결합하여 예측할 수 없는 작업 부하를 처리하는 무상태 계산을 수행합니다. 지연 시간을 줄이고 성능을 개선하기 위해 캐싱 전략을 구현합니다.",
        "Explanation": "Amazon API Gateway는 대규모로 API를 생성, 게시 및 관리하기 위해 특별히 설계되었습니다. 이는 자동으로 트래픽 급증을 처리할 수 있으며, 캐싱, 스로틀링 및 모니터링을 위한 내장 기능을 제공합니다. AWS Lambda와 결합하면 서버리스 코드 실행이 가능하여, 서버를 프로비저닝할 필요 없이 수요에 따라 자동으로 확장할 수 있습니다. 이 조합은 예측할 수 없는 작업 부하를 처리하는 데 이상적인 무상태 계산을 지원합니다. 캐싱 전략은 백엔드 서비스에 대한 호출 수를 줄여 성능을 더욱 향상시켜 응답 시간을 개선하고 비용을 절감합니다.",
        "Other Options": [
            "Amazon EC2를 사용하여 API를 호스팅하는 것은 인스턴스 및 확장 구성의 수동 관리를 요구하므로 아키텍처를 복잡하게 만들고 트래픽 급증을 서버리스 솔루션만큼 효율적으로 처리하지 못할 수 있습니다. Auto Scaling 그룹이 도움이 될 수 있지만, 여전히 서버리스 접근 방식에 비해 더 많은 오버헤드가 발생합니다.",
            "AWS Fargate는 컨테이너 관리를 위한 좋은 옵션이지만, API Gateway 및 Lambda를 사용하는 것보다 복잡성을 추가합니다. DynamoDB에 대한 직접 API 호출은 작동할 수 있지만, API Gateway의 API 관리 기능이 없으면 솔루션이 필요한 확장성과 모니터링 기능을 결여할 수 있습니다.",
            "AWS Elastic Load Balancer는 EC2 인스턴스로 트래픽을 분산할 수 있지만, 이 설정은 여전히 인스턴스를 관리하고 수동으로 확장해야 합니다. API 데이터를 Amazon S3에 저장하는 것은 동적 API 응답에 적합하지 않으며, S3는 주로 객체 저장소로 사용되며 데이터베이스 솔루션과 같은 성능 및 쿼리 기능을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "60",
        "Situation": "한 회사가 웹 애플리케이션에서 고객 트래픽이 증가하고 있으며, 부하를 처리하기 위해 인프라를 확장해야 합니다. 그들은 수평 및 수직 확장 옵션을 모두 고려하고 있습니다.",
        "Question": "수평 확장과 수직 확장의 주요 차이점은 무엇이며, 어떤 방식이 애플리케이션 중단을 최소화하는 데 더 적합합니까?",
        "Options": {
            "1": "수직 확장은 인스턴스 크기를 증가시키는 것으로, 재부팅이 필요하여 일시적인 중단이 발생할 수 있는 반면, 수평 확장은 재부팅 없이 더 많은 인스턴스를 추가하여 중단을 피합니다.",
            "2": "수평 확장은 동일한 인스턴스에 더 많은 리소스를 추가하여 중단 없이 용량을 증가시키고, 수직 확장은 더 많은 트래픽을 처리하기 위해 새로운 인스턴스를 추가합니다.",
            "3": "수직 확장은 각 새로운 인스턴스 크기에 대해 애플리케이션 수정을 요구하는 반면, 수평 확장은 애플리케이션 수정을 요구하지 않습니다.",
            "4": "수평 확장은 추가할 수 있는 인스턴스 수에 엄격한 제한이 있는 반면, 수직 확장은 무제한 용량을 제공합니다."
        },
        "Correct Answer": "수직 확장은 인스턴스 크기를 증가시키는 것으로, 재부팅이 필요하여 일시적인 중단이 발생할 수 있는 반면, 수평 확장은 재부팅 없이 더 많은 인스턴스를 추가하여 중단을 피합니다.",
        "Explanation": "수평 확장과 수직 확장의 주요 차이점은 부하 증가를 처리하기 위해 리소스를 추가하는 방식에 있습니다. 수직 확장(또는 '스케일 업')은 기존 서버의 리소스(CPU, RAM 또는 스토리지 등)를 업그레이드하는 것을 포함합니다. 이 과정은 종종 서버의 재부팅을 요구하며, 이는 일시적인 애플리케이션 다운타임을 초래할 수 있습니다. 반면, 수평 확장(또는 '스케일 아웃')은 부하를 분산하기 위해 더 많은 인스턴스나 서버를 추가하는 것을 포함합니다. 이 방법은 애플리케이션이 중단 없이 계속 실행될 수 있도록 하여, 트래픽이 증가하는 동안 중단을 최소화하는 데 더 적합합니다.",
        "Other Options": [
            "이 옵션은 수평 확장이 동일한 인스턴스에 리소스를 추가한다고 잘못 설명하고 있습니다. 수평 확장은 단일 인스턴스의 용량을 증가시키는 것이 아니라 더 많은 인스턴스를 추가합니다.",
            "이 옵션은 수직 확장이 각 새로운 인스턴스 크기에 대해 애플리케이션 수정을 요구한다고 잘못 제안합니다. 실제로 수직 확장은 애플리케이션 자체의 수정을 요구하지 않지만, 재부팅이 필요하여 중단을 초래할 수 있습니다.",
            "이 옵션은 수평 확장에 인스턴스 수에 엄격한 제한이 있다고 주장하는데, 이는 보편적으로 사실이 아닙니다. 인프라 또는 클라우드 제공업체의 기능에 따라 실질적인 제한이 있을 수 있지만, 일반적으로 수평 확장은 수직 확장보다 더 유연합니다. 수직 확장은 단일 서버의 최대 용량에 의해 제한됩니다."
        ]
    },
    {
        "Question Number": "61",
        "Situation": "두 개의 비즈니스 사이트 간에 IPSEC VPN 연결을 설정할 때, 안전한 연결을 구축하는 데 있어 IKE(Internet Key Exchange) Phase 1과 Phase 2의 역할을 올바르게 설명하는 것은 무엇입니까?",
        "Question": "IKE Phase 1과 Phase 2에 관한 다음 진술 중 어떤 것이 사실입니까? (두 가지 선택하십시오.)",
        "Options": {
            "1": "IKE Phase 1은 대칭 암호화를 사용하여 안전한 터널을 설정하고, IKE Phase 2는 터널을 통한 대량 데이터 전송을 위해 비대칭 암호화를 사용합니다.",
            "2": "IKE Phase 1은 비대칭 암호화를 사용하여 인증 및 안전한 연결을 설정하고, 대칭 키를 설정하며 IKE 보안 협정(SA)을 생성합니다. 이후 IKE Phase 2는 이 키를 사용하여 빠르고 암호화된 대량 데이터 전송을 수행하며 IPSEC SA를 생성합니다.",
            "3": "IKE Phase 1은 공개 네트워크를 통해 교환된 대칭 키를 사용하여 IPSEC SA를 직접 설정하고, IKE Phase 2는 각 세션의 재인증을 관리합니다.",
            "4": "IKE Phase 1과 Phase 2는 모두 연결 설정 및 데이터 전송 과정에서 비대칭 암호화를 사용하여 최고의 보안을 보장합니다.",
            "5": "IKE Phase 1은 IPSEC 터널의 매개변수를 협상하고, IKE Phase 2는 전송되는 데이터의 실제 암호화를 처리합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "IKE Phase 1은 비대칭 암호화를 사용하여 인증 및 안전한 연결을 설정하고, 대칭 키를 설정하며 IKE 보안 협정(SA)을 생성합니다. 이후 IKE Phase 2는 이 키를 사용하여 빠르고 암호화된 대량 데이터 전송을 수행하며 IPSEC SA를 생성합니다.",
            "IKE Phase 1은 IPSEC 터널의 매개변수를 협상하고, IKE Phase 2는 전송되는 데이터의 실제 암호화를 처리합니다."
        ],
        "Explanation": "IKE Phase 1은 피어를 인증하고 안전한 연결을 설정하며 데이터 암호화를 위한 대칭 키를 설정하는 역할을 합니다. 이 작업을 위해 비대칭 암호화를 사용하여 보안을 보장합니다. 이 작업이 완료되면 IKE 보안 협정(SA)을 생성합니다. 이후 IKE Phase 2는 Phase 1에서 설정된 대칭 키를 사용하여 빠르고 암호화된 대량 데이터 전송을 수행합니다. IPSEC SA를 생성하여 실제 데이터 전송에 사용됩니다. Phase 1은 또한 IPSEC 터널의 매개변수를 협상하고, Phase 2는 전송되는 데이터의 실제 암호화를 처리합니다.",
        "Other Options": [
            "옵션 1은 IKE Phase 1이 안전한 연결 설정 및 대칭 키 설정을 위해 비대칭 암호화를 사용하므로 잘못된 것입니다. IKE Phase 2는 데이터 전송을 위해 Phase 1의 대칭 키를 사용하며 비대칭 암호화를 사용하지 않습니다.",
            "옵션 3은 IKE Phase 1이 IPSEC SA를 직접 설정하지 않고 IKE SA를 설정하므로 잘못된 것입니다. IPSEC SA는 Phase 2에서 설정됩니다. 또한 대칭 키는 공개 네트워크를 통해 교환되지 않으며, Phase 1에서 비대칭 암호화를 사용하여 안전하게 설정됩니다.",
            "옵션 4는 IKE Phase 1이 안전한 연결 설정 및 대칭 키 설정을 위해 비대칭 암호화를 사용하지만, Phase 2는 데이터 전송을 위해 Phase 1의 대칭 키를 사용하므로 잘못된 것입니다."
        ]
    },
    {
        "Question Number": "62",
        "Situation": "한 금융 회사는 데이터 내구성과 접근성을 보장하기 위해 고가용성 및 복원력이 뛰어난 저장 솔루션에 중요한 거래 데이터를 저장해야 합니다. 또한 우발적인 삭제로부터 데이터를 보호하고 재해 발생 시 신속하게 복구할 수 있기를 원합니다.",
        "Question": "Amazon S3에서 이러한 요구 사항을 가장 잘 충족하는 구성은 무엇입니까? (두 가지 선택하십시오.)",
        "Options": {
            "1": "Amazon S3 Standard 저장 클래스를 사용하고 버전 관리를 활성화하며 교차 지역 복제를 통해 우발적인 삭제로부터 보호하고 여러 지역에서 데이터 가용성을 보장합니다.",
            "2": "저비용 저장을 위해 Amazon S3 Glacier를 사용하고 객체 잠금을 활성화하여 우발적인 삭제를 방지하면서 데이터에 대한 빠른 접근을 유지합니다.",
            "3": "Amazon S3 Intelligent-Tiering에 데이터를 저장하여 비용을 절감하고, AWS Backup을 사용하여 지역 간 재해 복구를 수행합니다.",
            "4": "Amazon S3 One Zone-Infrequent Access를 사용하여 단일 가용 영역에 데이터를 저장하고 버전 관리를 활성화하여 데이터 손실로부터 보호합니다.",
            "5": "Amazon S3 버킷에서 다단계 인증(MFA) 삭제를 활성화하여 우발적인 삭제로부터 추가적인 보호 계층을 제공합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon S3 Standard 저장 클래스를 사용하고 버전 관리를 활성화하며 교차 지역 복제를 통해 우발적인 삭제로부터 보호하고 여러 지역에서 데이터 가용성을 보장합니다.",
            "Amazon S3 버킷에서 다단계 인증(MFA) 삭제를 활성화하여 우발적인 삭제로부터 추가적인 보호 계층을 제공합니다."
        ],
        "Explanation": "Amazon S3 Standard 저장 클래스는 자주 접근되는 데이터에 대해 높은 내구성, 가용성 및 성능을 제공하는 객체 저장소입니다. 버전 관리가 활성화되면 객체의 모든 버전(모든 쓰기 및 삭제 포함)을 버킷에 유지합니다. 교차 지역 복제는 서로 다른 지역의 버킷 간에 객체를 자동으로 비동기적으로 복사하여 규정 준수 요구 사항을 충족하고 대기 시간을 최소화하는 데 도움이 됩니다. 다단계 인증(MFA) 삭제는 객체 버전을 삭제하거나 버킷에서 버전 관리를 중단하기 위해 MFA를 요구하여 추가적인 보안 계층을 제공합니다.",
        "Other Options": [
            "Amazon S3 Glacier는 데이터 아카이빙 및 장기 백업을 위한 안전하고 내구성이 뛰어난 저비용 저장 클래스입니다. 그러나 검색 시간이 몇 분에서 몇 시간까지 걸릴 수 있어 데이터에 대한 빠른 접근을 제공하지 않습니다.",
            "Amazon S3 Intelligent-Tiering은 성능 영향이나 운영 오버헤드 없이 데이터를 가장 비용 효율적인 접근 계층으로 자동으로 이동하여 비용을 최적화하도록 설계되었습니다. AWS Backup은 재해 복구에 사용할 수 있지만, 이 옵션은 우발적인 삭제로부터 보호를 제공하지 않습니다.",
            "Amazon S3 One Zone-Infrequent Access는 드물게 접근되는 데이터에 대한 저비용 옵션이지만, 단일 가용 영역에 데이터를 저장하므로 복원력이 떨어지고 높은 가용성 요구 사항을 충족하지 않습니다."
        ]
    },
    {
        "Question Number": "63",
        "Situation": "한 금융 서비스 회사가 온프레미스 애플리케이션을 AWS로 마이그레이션하고 있습니다. 이 애플리케이션은 웹 계층, 애플리케이션 계층 및 데이터베이스 계층으로 구성되어 있습니다. 이 회사는 보안 및 규정 준수 목적을 위해 계층 간의 엄격한 격리를 요구합니다. 또한 향후 성장을 수용하기 위해 IP 주소 최적화가 필요합니다.",
        "Question": "이러한 요구 사항을 충족하기 위해 솔루션 아키텍트가 설계해야 할 네트워크 아키텍처는 무엇입니까? (두 가지 선택하십시오.)",
        "Options": {
            "1": "모든 계층을 단일 공용 서브넷에 배포하고 보안 그룹으로 접근을 제어합니다.",
            "2": "모든 계층을 위한 단일 사설 서브넷을 사용하고 격리를 위해 네트워크 ACL을 사용합니다.",
            "3": "여러 가용 영역에 걸쳐 각 계층에 대해 별도의 사설 서브넷을 생성하고, 향후 확장을 허용하는 CIDR 블록을 사용하는 VPC를 사용합니다.",
            "4": "웹 계층을 공용 서브넷에 배치하고 애플리케이션 및 데이터베이스 계층을 단일 사설 서브넷에 배치하며 IP 범위가 겹치도록 합니다.",
            "5": "각 계층에 대해 VPC 내에 여러 개의 사설 서브넷을 구현하고 VPC 피어링을 사용하여 계층 간 트래픽을 격리합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "여러 가용 영역에 걸쳐 각 계층에 대해 별도의 사설 서브넷을 생성하고, 향후 확장을 허용하는 CIDR 블록을 사용하는 VPC를 사용합니다.",
            "각 계층에 대해 VPC 내에 여러 개의 사설 서브넷을 구현하고 VPC 피어링을 사용하여 계층 간 트래픽을 격리합니다."
        ],
        "Explanation": "여러 가용 영역에 걸쳐 각 계층에 대해 별도의 사설 서브넷을 생성하면 계층 간의 엄격한 격리를 허용하여 회사의 요구 사항을 충족합니다. 향후 확장을 허용하는 CIDR 블록을 사용하는 VPC는 향후 성장을 수용하기 위해 IP 주소를 최적화하는 데 도움이 됩니다. VPC 내에 각 계층에 대해 여러 개의 사설 서브넷을 구현하고 VPC 피어링을 사용하여 계층 간 트래픽을 격리하는 것도 필요한 격리 및 보안을 제공합니다.",
        "Other Options": [
            "모든 계층을 단일 공용 서브넷에 배포하고 보안 그룹으로 접근을 제어하는 것은 계층 간의 필요한 격리를 제공하지 않으며 애플리케이션을 잠재적인 보안 위험에 노출시키므로 좋은 방법이 아닙니다.",
            "모든 계층을 위한 단일 사설 서브넷을 사용하고 네트워크 ACL을 격리를 위해 사용하는 것은 모든 계층이 동일한 서브넷에 있기 때문에 필요한 격리를 제공하지 않습니다.",
            "웹 계층을 공용 서브넷에 배치하고 애플리케이션 및 데이터베이스 계층을 단일 사설 서브넷에 배치하며 IP 범위가 겹치도록 하는 것은 계층 간의 필요한 격리를 제공하지 않으며, 겹치는 IP 범위로 인해 IP 충돌이 발생할 수 있습니다."
        ]
    },
    {
        "Question Number": "64",
        "Situation": "한 회사가 Amazon RDS를 데이터베이스로 사용하고 있으며 규정 준수를 위해 데이터 암호화가 필요합니다. 이 회사는 데이터가 저장 중 및 전송 중 모두 암호화되고 암호화 키가 안전하게 관리되기를 원합니다. 또한 Oracle을 데이터베이스 엔진으로 사용하고 있습니다.",
        "Question": "이러한 보안 요구 사항을 가장 잘 충족하는 접근 방식은 무엇입니까? (두 가지 선택하십시오.)",
        "Options": {
            "1": "전송 중 암호화를 위해 RDS의 내장 SSL/TLS를 사용하고 Oracle 데이터베이스 엔진 내에서 저장 중 암호화를 위해 투명 데이터 암호화(TDE)를 활성화합니다.",
            "2": "Amazon RDS가 저장 중 암호화를 위해 KMS 관리 키를 사용하도록 활성화하고 전송 중 암호화를 처리하기 위해 SSL/TLS를 구성합니다.",
            "3": "CloudHSM을 Amazon RDS와 통합하여 Oracle의 암호화 키를 관리하고 AWS가 키에 접근할 수 없도록 하며, 전송 중 암호화를 위해 SSL/TLS를 활성화합니다.",
            "4": "RDS의 기본 암호화 설정을 사용하고 전송 중 암호화에 대한 추가 구성 없이 EBS 볼륨 암호화에 의존합니다.",
            "5": "RDS에 전송되기 전에 데이터 암호화를 처리하기 위해 애플리케이션 수준 암호화를 구현하고 전송 중 암호화를 위해 VPN 연결을 사용합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "전송 중 암호화를 위해 RDS의 내장 SSL/TLS를 사용하고 Oracle 데이터베이스 엔진 내에서 저장 중 암호화를 위해 투명 데이터 암호화(TDE)를 활성화합니다.",
            "Amazon RDS가 저장 중 암호화를 위해 KMS 관리 키를 사용하도록 활성화하고 전송 중 암호화를 처리하기 위해 SSL/TLS를 구성합니다."
        ],
        "Explanation": "첫 번째 정답은 전송 중 암호화를 위해 RDS의 내장 SSL/TLS를 사용하고 Oracle 데이터베이스 엔진 내에서 저장 중 암호화를 위해 투명 데이터 암호화(TDE)를 활성화하는 것입니다. SSL/TLS는 네트워크를 통한 데이터의 안전한 전송을 보장하는 프로토콜이며, TDE는 Oracle의 기능으로 저장 중 데이터 암호화를 제공합니다. 두 번째 정답은 Amazon RDS가 저장 중 암호화를 위해 KMS 관리 키를 사용하도록 활성화하고 전송 중 암호화를 처리하기 위해 SSL/TLS를 구성하는 것입니다. Amazon 키 관리 서비스(KMS)는 데이터를 암호화하는 데 사용되는 암호화 키를 생성하고 제어하는 것을 쉽게 해주는 관리형 서비스입니다.",
        "Other Options": [
            "CloudHSM을 Amazon RDS와 통합하여 Oracle의 암호화 키를 관리하고 전송 중 암호화를 위해 SSL/TLS를 활성화하는 것은 필요하지 않습니다. AWS KMS가 RDS의 키 관리를 처리할 수 있으며, 이는 더 간단하고 비용 효율적입니다.",
            "RDS의 기본 암호화 설정을 사용하고 전송 중 암호화에 대한 추가 구성 없이 EBS 볼륨 암호화에 의존하는 것은 전송 중 암호화를 보장하지 않기 때문에 충분하지 않습니다.",
            "RDS에 전송되기 전에 데이터 암호화를 처리하기 위해 애플리케이션 수준 암호화를 구현하고 전송 중 암호화를 위해 VPN 연결을 사용하는 것은 불필요한 복잡성과 오버헤드를 추가하기 때문에 최선의 접근 방식이 아닙니다. 저장 중 및 전송 중 암호화를 위해 AWS의 내장 서비스를 사용하는 것이 더 효율적입니다."
        ]
    },
    {
        "Question Number": "65",
        "Situation": "한 비디오 제작 회사는 수천 개의 비디오 파일을 저장하고 있으며, 이 파일들은 초기 제작 이후에는 거의 접근되지 않습니다. 이들은 이러한 파일을 아카이브할 수 있는 비용 효율적인 저장 솔루션을 원하지만 필요할 때 몇 분 내에 검색할 수 있기를 원합니다.",
        "Question": "어떤 AWS 저장 서비스가 이러한 요구 사항을 가장 잘 충족합니까? (두 가지 선택하십시오.)",
        "Options": {
            "1": "Amazon EFS",
            "2": "Amazon S3 Glacier Instant Retrieval",
            "3": "Amazon FSx for Windows File Server",
            "4": "Amazon EBS Provisioned IOPS",
            "5": "Amazon S3 Intelligent-Tiering"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon S3 Glacier Instant Retrieval",
            "Amazon S3 Intelligent-Tiering"
        ],
        "Explanation": "Amazon S3 Glacier Instant Retrieval은 데이터 아카이빙을 위한 비용 효율적인 저장 솔루션입니다. 이는 드물게 접근되는 데이터를 장기적으로 저장하도록 설계되었지만, 필요할 때 몇 분 내에 검색할 수 있습니다. 이는 비디오 제작 회사에 적합한 선택입니다. Amazon S3 Intelligent-Tiering은 성능 영향이나 운영 오버헤드 없이 데이터를 가장 비용 효율적인 접근 계층으로 자동으로 이동하므로 또 다른 적합한 선택입니다. 이는 접근 패턴이 불확실하거나 변동하는 데이터에 이상적이며, 드물게 접근되는 비디오 파일을 저장하는 데 적합합니다.",
        "Other Options": [
            "Amazon EFS(Elastic File System)는 Amazon EC2와 함께 사용할 수 있는 파일 저장 서비스입니다. 비디오 파일 저장에 기술적으로 사용할 수 있지만, 드물게 접근되는 데이터에 대해 가장 비용 효율적인 솔루션은 아닙니다.",
            "Amazon FSx for Windows File Server는 완전 관리형 네이티브 Microsoft Windows 파일 시스템을 제공합니다. 이는 드물게 접근되는 비디오 파일을 저장하는 데 가장 비용 효율적인 솔루션이 아니며, Windows 파일 시스템이 필요한 기업 워크로드에 더 적합합니다.",
            "Amazon EBS(Elastic Block Store) Provisioned IOPS는 프로비저닝된 IOPS 성능의 99.9%를 10% 이내로 제공하도록 설계된 저장 유형입니다. 이는 드물게 접근되는 데이터의 비용 효율적인 장기 저장보다는 높은 성능이 필요한 워크로드에 더 적합합니다."
        ]
    }
]