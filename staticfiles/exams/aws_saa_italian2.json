[
    {
        "Question Number": "1",
        "Situation": "Una società di servizi finanziari raccoglie dati di transazione in vari formati da più fonti. Prima di eseguire analisi, i dati devono essere puliti, normalizzati e arricchiti. La società cerca una soluzione serverless che possa automatizzare questo processo ETL (Estrai, Trasforma, Carica).",
        "Question": "Quale servizio AWS dovrebbe raccomandare l'architetto delle soluzioni per la trasformazione dei dati?",
        "Options": {
            "1": "Amazon EMR",
            "2": "AWS Glue",
            "3": "AWS Lambda",
            "4": "Amazon Redshift Spectrum"
        },
        "Correct Answer": "AWS Glue",
        "Explanation": "AWS Glue è un servizio ETL (Estrai, Trasforma, Carica) completamente gestito, progettato specificamente per la preparazione e la trasformazione dei dati. Automatizza il processo di scoperta, catalogazione e trasformazione dei dati, rendendolo ideale per la società di servizi finanziari che ha bisogno di pulire, normalizzare e arricchire i dati di transazione provenienti da varie fonti. AWS Glue può gestire operazioni serverless, il che si allinea con il requisito della società per una soluzione serverless.",
        "Other Options": [
            "Amazon EMR è una piattaforma di cluster gestita che semplifica l'esecuzione di framework di big data come Apache Hadoop e Apache Spark. Sebbene possa eseguire compiti ETL, non è una soluzione serverless e richiede maggiore gestione e configurazione rispetto a AWS Glue.",
            "AWS Lambda è un servizio di calcolo serverless che esegue codice in risposta a eventi. Sebbene possa essere utilizzato per la trasformazione dei dati, non è specificamente progettato per i processi ETL e manca delle capacità integrate per la catalogazione dei dati e l'inferenza dello schema che fornisce AWS Glue.",
            "Amazon Redshift Spectrum consente di eseguire query sui dati memorizzati in S3 senza caricarli in Redshift. Tuttavia, è principalmente un servizio di query piuttosto che un servizio ETL e non fornisce le capacità di trasformazione dei dati necessarie per pulire e arricchire i dati prima dell'analisi."
        ]
    },
    {
        "Question Number": "2",
        "Situation": "Un'azienda sta utilizzando Amazon CloudWatch per monitorare la sicurezza delle proprie risorse AWS. L'azienda deve impostare un sistema che possa rispondere automaticamente a potenziali minacce alla sicurezza attivando azioni di rimedio quando viene rilevato un modello insolito nel traffico di rete o tentativi di accesso non autorizzati.",
        "Question": "Quale delle seguenti configurazioni dovrebbe implementare l'azienda per garantire che gli incidenti di sicurezza vengano rilevati e rimediati in tempo reale?",
        "Options": {
            "1": "Utilizzare CloudWatch Logs per raccogliere i log dalle istanze EC2 e impostare CloudWatch Alarms per attivare funzioni Lambda per azioni di rimedio quando vengono rilevati modelli specifici nei log.",
            "2": "Utilizzare CloudWatch Metrics per monitorare la salute delle istanze EC2 e configurare il ridimensionamento automatico quando vengono superati i limiti di sicurezza, senza integrare altri servizi di sicurezza AWS.",
            "3": "Impostare CloudWatch Events per inoltrare i dati di log da CloudTrail a un sistema SIEM (Security Information and Event Management) esterno per analisi in tempo reale e rimedio automatizzato.",
            "4": "Abilitare CloudWatch Dashboards per visualizzare le metriche EC2 e ispezionare manualmente i dati per minacce alla sicurezza, attivando avvisi tramite Amazon SNS quando necessario."
        },
        "Correct Answer": "Utilizzare CloudWatch Logs per raccogliere i log dalle istanze EC2 e impostare CloudWatch Alarms per attivare funzioni Lambda per azioni di rimedio quando vengono rilevati modelli specifici nei log.",
        "Explanation": "Questa opzione è corretta perché affronta direttamente la necessità di rilevamento e rimedio in tempo reale degli incidenti di sicurezza. Utilizzando CloudWatch Logs per raccogliere i log dalle istanze EC2, l'azienda può monitorare modelli specifici che indicano potenziali minacce alla sicurezza. Impostare CloudWatch Alarms consente risposte automatizzate tramite funzioni AWS Lambda, che possono eseguire azioni di rimedio predefinite immediatamente quando viene rilevata una minaccia. Questa configurazione garantisce che gli incidenti di sicurezza non solo vengano rilevati in tempo reale, ma anche che vengano gestiti automaticamente, migliorando la postura di sicurezza complessiva delle risorse AWS.",
        "Other Options": [
            "Questa opzione è scorretta perché, sebbene suggerisca di utilizzare CloudWatch Logs e allarmi, non specifica l'uso delle funzioni Lambda per il rimedio automatizzato. Senza automazione, la risposta alle minacce rilevate non sarebbe in tempo reale, il che è critico per una gestione efficace della sicurezza.",
            "Questa opzione è scorretta perché si concentra sul monitoraggio della salute delle istanze EC2 e sul ridimensionamento automatico, che non è direttamente correlato al rilevamento e al rimedio delle minacce alla sicurezza. Sebbene il monitoraggio della salute delle istanze sia importante, non affronta la necessità specifica di rispondere a incidenti di sicurezza come traffico di rete insolito o tentativi di accesso non autorizzati.",
            "Questa opzione è scorretta perché, sebbene l'inoltro dei dati di log a un sistema SIEM esterno possa essere utile per l'analisi, non fornisce un meccanismo diretto per azioni di rimedio in tempo reale. La dipendenza da un sistema esterno introduce latenza nel tempo di risposta, che non è adatta per una mitigazione immediata delle minacce."
        ]
    },
    {
        "Question Number": "3",
        "Situation": "Una società di servizi finanziari deve garantire che la sua applicazione di trading critica possa essere ripristinata e operativa entro un tempo molto breve in caso di disastro. Per soddisfare i requisiti operativi, la società ha stabilito un Obiettivo di Tempo di Ripristino (RTO) di 15 minuti, il che significa che l'applicazione deve tornare online entro questo tempo se si verifica un'interruzione.",
        "Question": "Quale strategia di disaster recovery soddisferebbe meglio questo requisito RTO?",
        "Options": {
            "1": "Backup e Ripristino, utilizzando un backup notturno memorizzato in Amazon S3, che può essere ripristinato per riportare l'applicazione online quando necessario.",
            "2": "Pilot Light, mantenendo un'infrastruttura preconfigurata che rimane spenta ma può essere rapidamente avviata per ripristinare l'applicazione quando necessario.",
            "3": "Warm Standby, con una versione minima dell'applicazione che può essere scalata fino alla piena capacità di produzione entro i 15 minuti di RTO.",
            "4": "Configurazione Multi-sito Active-Active, in cui risorse completamente operative sono mantenute in più posizioni, garantendo failover istantaneo e zero downtime."
        },
        "Correct Answer": "Configurazione Multi-sito Active-Active, in cui risorse completamente operative sono mantenute in più posizioni, garantendo failover istantaneo e zero downtime.",
        "Explanation": "La configurazione Multi-sito Active-Active è la migliore strategia di disaster recovery per soddisfare l'Obiettivo di Tempo di Ripristino (RTO) di 15 minuti perché garantisce che risorse completamente operative siano disponibili in ogni momento in più posizioni. In caso di disastro, il sistema può immediatamente passare a un altro sito senza alcun downtime, soddisfacendo così il rigoroso requisito di avere l'applicazione online immediatamente. Questa configurazione fornisce il massimo livello di disponibilità e resilienza, rendendola ideale per applicazioni di trading critiche che non possono permettersi ritardi.",
        "Other Options": [
            "Backup e Ripristino non soddisferebbero il requisito RTO di 15 minuti, poiché il ripristino da un backup notturno può richiedere significativamente più di 15 minuti, specialmente se il backup è grande o se ci sono problemi durante il processo di ripristino.",
            "Pilot Light comporta il mantenimento di un'infrastruttura minima che può essere rapidamente avviata, ma richiede comunque tempo per avviare le risorse necessarie e potrebbe non garantire che l'applicazione possa essere completamente operativa entro i 15 minuti di RTO.",
            "Warm Standby mantiene una versione minima dell'applicazione che può essere scalata, ma il passaggio alla piena capacità di produzione potrebbe richiedere più di 15 minuti, specialmente se ci sono vincoli di risorse o se l'applicazione richiede un tempo di inizializzazione significativo."
        ]
    },
    {
        "Question Number": "4",
        "Situation": "Un'applicazione di calcolo ad alte prestazioni (HPC) in esecuzione su istanze Amazon EC2 richiede latenza ultra-bassa e il massimo IOPS possibile per l'archiviazione temporanea dei dati. I dati non devono essere conservati se l'istanza viene arrestata o si guasta, e il costo è una preoccupazione primaria.",
        "Question": "Quale opzione di archiviazione dovrebbe raccomandare l'architetto delle soluzioni?",
        "Options": {
            "1": "Amazon EBS General Purpose SSD (gp3)",
            "2": "Amazon EBS Provisioned IOPS SSD (io2)",
            "3": "Instance Store",
            "4": "Amazon S3 con Transfer Acceleration"
        },
        "Correct Answer": "Instance Store",
        "Explanation": "Instance Store fornisce il massimo IOPS possibile e latenza ultra-bassa perché è fisicamente collegato al server host. Questo lo rende ideale per applicazioni di calcolo ad alte prestazioni che richiedono un'archiviazione temporanea dei dati veloce. Poiché i dati non devono essere conservati se l'istanza viene arrestata o si guasta, utilizzare Instance Store è conveniente in quanto non comporta costi aggiuntivi come i volumi EBS.",
        "Other Options": [
            "Amazon EBS General Purpose SSD (gp3) offre buone prestazioni ed è conveniente, ma non fornisce lo stesso livello di IOPS e latenza di Instance Store, rendendolo meno adatto per applicazioni HPC che richiedono latenza ultra-bassa.",
            "Amazon EBS Provisioned IOPS SSD (io2) fornisce alti IOPS ed è progettato per applicazioni che richiedono prestazioni sostenute, ma è più costoso di Instance Store e non è necessario per l'archiviazione temporanea dei dati che non deve essere conservata.",
            "Amazon S3 con Transfer Acceleration è progettato per il trasferimento di dati ad alta velocità su Internet e non è adatto per requisiti di latenza ultra-bassa. Inoltre, S3 è un servizio di archiviazione di oggetti, che non è appropriato per l'archiviazione temporanea dei dati in applicazioni HPC che richiedono accesso rapido."
        ]
    },
    {
        "Question Number": "5",
        "Situation": "Un'azienda di e-commerce ha bisogno di una soluzione di disaster recovery per recuperare rapidamente il proprio database in caso di un'imprevista interruzione regionale. Richiedono un downtime e una perdita di dati minimi.",
        "Question": "Quale servizio e strategia AWS dovrebbe considerare l'azienda per soddisfare un basso obiettivo di punto di ripristino (RPO) e un basso obiettivo di tempo di ripristino (RTO)?",
        "Options": {
            "1": "Amazon RDS con una distribuzione Multi-AZ e repliche di lettura cross-region, poiché fornisce failover automatico e replicazione cross-region per un rapido recupero con minima perdita di dati.",
            "2": "Amazon S3 con versioning abilitato, poiché garantisce la durabilità dei dati mantenendo più versioni di ciascun oggetto attraverso le Availability Zone.",
            "3": "AWS Backup per snapshot regolari del database, poiché fornisce il ripristino a un punto nel tempo del database attraverso più regioni.",
            "4": "Amazon EC2 Auto Scaling con backup programmati, poiché consente il ridimensionamento automatizzato e il recupero periodico dei dati."
        },
        "Correct Answer": "Amazon RDS con una distribuzione Multi-AZ e repliche di lettura cross-region, poiché fornisce failover automatico e replicazione cross-region per un rapido recupero con minima perdita di dati.",
        "Explanation": "Amazon RDS con una distribuzione Multi-AZ è progettato per alta disponibilità e durabilità. In una configurazione Multi-AZ, RDS replica automaticamente il database a un'istanza di standby in una diversa Availability Zone, il che consente il failover automatico in caso di interruzione. Questa configurazione minimizza il downtime (basso RTO) e garantisce che i dati siano continuamente replicati, raggiungendo così un basso obiettivo di punto di ripristino (RPO). Inoltre, utilizzare repliche di lettura cross-region consente una maggiore ridondanza dei dati e un recupero più veloce in caso di un'interruzione regionale, rendendola una soluzione ideale per i requisiti dell'azienda.",
        "Other Options": [
            "Amazon S3 con versioning abilitato è principalmente per l'archiviazione di oggetti e non fornisce le necessarie capacità di recupero del database. Sebbene garantisca la durabilità dei dati mantenendo più versioni degli oggetti, non affronta la necessità di un basso RPO e RTO per un database.",
            "AWS Backup per snapshot regolari del database può fornire il ripristino a un punto nel tempo, ma potrebbe non soddisfare i requisiti di basso RPO e RTO altrettanto efficacemente quanto una distribuzione Multi-AZ con repliche di lettura cross-region. Gli snapshot possono richiedere tempo per essere ripristinati, il che potrebbe portare a un downtime più lungo.",
            "Amazon EC2 Auto Scaling con backup programmati è focalizzato sul ridimensionamento delle istanze EC2 e non fornisce intrinsecamente una soluzione di disaster recovery per i database. I backup programmati potrebbero non offrire il failover immediato e il basso RPO/RTO che l'azienda richiede."
        ]
    },
    {
        "Question Number": "6",
        "Situation": "Un'azienda sta eseguendo un'applicazione web su Amazon RDS e desidera migliorare le prestazioni di lettura dell'applicazione scaricando le query di lettura dal database principale. L'azienda deve garantire che il database principale non venga sopraffatto durante le ore di traffico intenso. Stanno considerando di utilizzare repliche di lettura per gestire il carico di lettura aumentato.",
        "Question": "Quale delle seguenti opzioni descrive meglio quando l'azienda dovrebbe utilizzare le repliche di lettura?",
        "Options": {
            "1": "Utilizzare le repliche di lettura quando l'applicazione richiede un elevato throughput di scrittura e deve distribuire le scritture su più regioni.",
            "2": "Utilizzare le repliche di lettura quando l'applicazione ha un elevato numero di query di lettura e deve scalare la capacità di lettura su più repliche.",
            "3": "Utilizzare le repliche di lettura quando l'applicazione deve memorizzare dati non strutturati come immagini o documenti e richiede alta disponibilità.",
            "4": "Utilizzare le repliche di lettura solo per scopi di migrazione dei dati, non per migliorare le prestazioni dell'applicazione."
        },
        "Correct Answer": "Utilizzare le repliche di lettura quando l'applicazione ha un elevato numero di query di lettura e deve scalare la capacità di lettura su più repliche.",
        "Explanation": "Le repliche di lettura sono progettate specificamente per scaricare il traffico di lettura dal database principale. Quando un'applicazione sperimenta un alto volume di query di lettura, l'uso delle repliche di lettura consente all'applicazione di distribuire queste query su più istanze, migliorando così le prestazioni di lettura e garantendo che il database principale non venga sopraffatto durante le ore di traffico intenso. Questa configurazione migliora la scalabilità e la reattività per i carichi di lavoro ad alta lettura.",
        "Other Options": [
            "Utilizzare le repliche di lettura quando l'applicazione richiede un elevato throughput di scrittura e deve distribuire le scritture su più regioni. Questo è errato perché le repliche di lettura sono destinate alle operazioni di lettura, non alla distribuzione delle operazioni di scrittura. Le scritture sono sempre dirette al database principale.",
            "Utilizzare le repliche di lettura quando l'applicazione deve memorizzare dati non strutturati come immagini o documenti e richiede alta disponibilità. Questo è errato perché le repliche di lettura non vengono utilizzate per memorizzare dati non strutturati; vengono utilizzate per migliorare le prestazioni di lettura per dati strutturati nei database.",
            "Utilizzare le repliche di lettura solo per scopi di migrazione dei dati, non per migliorare le prestazioni dell'applicazione. Questo è errato perché, sebbene le repliche di lettura possano essere utilizzate durante la migrazione dei dati, il loro scopo principale è migliorare le prestazioni dell'applicazione gestendo le query di lettura, non solo per la migrazione."
        ]
    },
    {
        "Question Number": "7",
        "Situation": "Un'azienda di produzione media richiede uno storage ad alte prestazioni per il montaggio video, ma desidera mantenere bassi i costi. Hanno una combinazione di carichi di lavoro ad alte e basse prestazioni e devono scegliere i tipi di storage a blocchi appropriati.",
        "Question": "Quali combinazioni di opzioni di storage a blocchi dovrebbe utilizzare l'azienda per ottimizzare i costi mantenendo i requisiti di prestazione? (Scegli due.)",
        "Options": {
            "1": "Provisioned IOPS SSD (io2) per tutti i volumi",
            "2": "General Purpose SSD (gp3) per compiti ad alte prestazioni e Throughput Optimized HDD (st1) per compiti a bassa prestazione",
            "3": "Cold HDD (sc1) per tutti i volumi",
            "4": "Utilizzare Amazon S3 invece dello storage a blocchi per tutti i dati",
            "5": "General Purpose SSD (gp3) per la maggior parte dei carichi di lavoro e Cold HDD (sc1) per le esigenze di archiviazione"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Provisioned IOPS SSD (io2) per tutti i volumi",
            "General Purpose SSD (gp3) per compiti ad alte prestazioni e Throughput Optimized HDD (st1) per compiti a bassa prestazione"
        ],
        "Explanation": "Provisioned IOPS SSD (io2) è un'opzione di storage ad alte prestazioni che fornisce throughput veloce, prevedibile e costante, rendendola adatta per carichi di lavoro ad alte prestazioni come il montaggio video. Tuttavia, è più costosa rispetto ad altre opzioni. D'altra parte, General Purpose SSD (gp3) offre un equilibrio tra prezzo e prestazioni, rendendola adatta per una vasta gamma di carichi di lavoro. Throughput Optimized HDD (st1) è un'opzione a basso costo che fornisce prestazioni moderate, rendendola adatta per compiti meno impegnativi.",
        "Other Options": [
            "Cold HDD (sc1) per tutti i volumi non è un'opzione adatta perché è progettato per dati freddi o di archiviazione a lungo termine e sequenziali che vengono acceduti raramente. Non fornisce le alte prestazioni richieste per il montaggio video.",
            "Utilizzare Amazon S3 invece dello storage a blocchi per tutti i dati non è ideale perché S3 è un servizio di storage a oggetti, non un servizio di storage a blocchi. Non è progettato per carichi di lavoro ad alte prestazioni come il montaggio video, che richiedono accesso a bassa latenza ai dati.",
            "General Purpose SSD (gp3) per la maggior parte dei carichi di lavoro e Cold HDD (sc1) per le esigenze di archiviazione non è la migliore opzione perché, sebbene gp3 sia adatto per la maggior parte dei carichi di lavoro, sc1 non è adatto per compiti ad alte prestazioni. È progettato per dati freddi o di archiviazione a lungo termine e sequenziali che vengono acceduti raramente."
        ]
    },
    {
        "Question Number": "8",
        "Situation": "In una grande architettura multi-VPC, stai affrontando sfide nel mantenere numerose connessioni punto-punto e nell'aumentare la complessità della rete.",
        "Question": "Quale soluzione semplificherebbe meglio la tua architettura di rete migliorando al contempo scalabilità e resilienza?",
        "Options": {
            "1": "Impostare una connessione VPN tra ogni coppia di VPC per garantire comunicazione diretta e migliorare la sicurezza.",
            "2": "Utilizzare AWS Direct Connect per ogni VPC, consentendo a ciascuno di connettersi indipendentemente alla tua rete on-premises.",
            "3": "Implementare un Transit Gateway (TGW) per fungere da hub centralizzato, collegando tutti i VPC e riducendo la necessità di connessioni individuali.",
            "4": "Configurare una connessione di peering tra ogni VPC per mantenere alta disponibilità e garantire latenza minima tra le connessioni."
        },
        "Correct Answer": "Implementare un Transit Gateway (TGW) per fungere da hub centralizzato, collegando tutti i VPC e riducendo la necessità di connessioni individuali.",
        "Explanation": "Un Transit Gateway (TGW) semplifica l'architettura di rete fungendo da hub centrale per interconnettere più VPC e reti on-premises. Questo riduce la complessità nella gestione di numerose connessioni punto-punto, poiché tutti i VPC possono comunicare tramite il TGW. Migliora la scalabilità perché puoi facilmente aggiungere più VPC senza dover stabilire nuove connessioni per ogni coppia. Inoltre, migliora la resilienza fornendo un unico punto di gestione e monitoraggio, il che può semplificare la risoluzione dei problemi e la manutenzione.",
        "Other Options": [
            "Impostare una connessione VPN tra ogni coppia di VPC creerebbe una rete complessa di connessioni, portando a un aumento del carico di gestione e potenziali colli di bottiglia nelle prestazioni. Questo approccio non scala bene man mano che il numero di VPC aumenta.",
            "Utilizzare AWS Direct Connect per ogni VPC consente connessioni indipendenti alle reti on-premises, ma non affronta la complessità della comunicazione tra VPC. Ogni VPC richiederebbe comunque la propria configurazione e gestione, il che può portare a un'architettura di rete frammentata.",
            "Configurare una connessione di peering tra ogni VPC creerebbe anch'essa una rete complessa. Sebbene possa fornire connessioni a bassa latenza, la gestione di numerose connessioni di peering diventa ingombrante man mano che il numero di VPC cresce, rendendola meno scalabile rispetto a un Transit Gateway."
        ]
    },
    {
        "Question Number": "9",
        "Situation": "Un'azienda sanitaria deve eseguire il backup dei dati dei pazienti su AWS per scopi di disaster recovery. Per ridurre i costi, richiedono una soluzione che minimizzi i costi di storage garantendo al contempo la conservazione a lungo termine dei backup. Vogliono anche l'opzione di recuperare i dati entro poche ore se necessario.",
        "Question": "Quale strategia di backup soddisferebbe meglio questi requisiti?",
        "Options": {
            "1": "Memorizzare i backup in Amazon S3 Standard",
            "2": "Utilizzare Amazon S3 Glacier Flexible Retrieval per l'archiviazione",
            "3": "Memorizzare i backup in Amazon S3 Standard-IA",
            "4": "Utilizzare Amazon EBS Snapshots memorizzati nella stessa regione"
        },
        "Correct Answer": "Utilizzare Amazon S3 Glacier Flexible Retrieval per l'archiviazione",
        "Explanation": "Amazon S3 Glacier Flexible Retrieval è progettato per l'archiviazione a lungo termine dei dati e offre una soluzione economica per memorizzare dati che vengono acceduti raramente. Consente il recupero dei dati entro poche ore, il che si allinea con il requisito dell'azienda sanitaria di recuperare i backup in modo tempestivo. Questa opzione minimizza i costi di storage garantendo al contempo che i dati siano conservati per lunghi periodi, rendendola la scelta migliore per scopi di disaster recovery.",
        "Other Options": [
            "Memorizzare i backup in Amazon S3 Standard non è economico per lo storage a lungo termine poiché è progettato per dati frequentemente accessibili. Questa opzione comporterebbe costi più elevati rispetto a Glacier per la stessa quantità di dati nel tempo.",
            "Utilizzare Amazon S3 Glacier Flexible Retrieval per l'archiviazione è la risposta corretta, ma se consideriamo l'opzione di S3 Glacier Deep Archive, sarebbe ancora più economica per lo storage a lungo termine. Tuttavia, non soddisfa il requisito di recuperare i dati entro poche ore, poiché i tempi di recupero possono richiedere fino a 12 ore.",
            "Memorizzare i backup in Amazon S3 Standard-IA (Infrequent Access) è un'opzione migliore rispetto a Standard ma non è ancora così economica come Glacier per lo storage a lungo termine. Sebbene sia adatta per dati che vengono accessi meno frequentemente, non offre lo stesso livello di risparmio sui costi per la conservazione a lungo termine come fa Glacier."
        ]
    },
    {
        "Question Number": "10",
        "Situation": "Un'azienda SaaS offre un'applicazione web che si connette a un database centrale Amazon RDS per MySQL. L'applicazione sperimenta picchi di connessione intermittenti che occasionalmente superano il numero massimo di connessioni consentite sul database.",
        "Question": "Quale soluzione dovrebbe implementare l'architetto delle soluzioni per gestire efficacemente le connessioni al database e prevenire il superamento del limite di connessione?",
        "Options": {
            "1": "Aumentare il numero massimo di connessioni consentite sull'istanza Amazon RDS.",
            "2": "Distribuire un cluster Amazon ElastiCache per gestire le query del database e ridurre le connessioni dirette.",
            "3": "Implementare Amazon RDS Proxy per raggruppare e condividere le connessioni al database in modo efficiente.",
            "4": "Utilizzare funzioni AWS Lambda per gestire e distribuire dinamicamente le connessioni al database."
        },
        "Correct Answer": "Implementare Amazon RDS Proxy per raggruppare e condividere le connessioni al database in modo efficiente.",
        "Explanation": "Amazon RDS Proxy è progettato per gestire le connessioni al database in modo efficiente raggruppando e condividendo le connessioni tra più istanze dell'applicazione. Questo aiuta a ridurre il numero di connessioni concorrenti al database, il che è particolarmente utile in scenari in cui l'applicazione sperimenta picchi nelle richieste di connessione. Utilizzando RDS Proxy, l'applicazione può mantenere un numero ridotto di connessioni attive al database, prevenendo così il superamento del limite di connessione e migliorando le prestazioni e l'affidabilità complessive dell'applicazione.",
        "Other Options": [
            "Aumentare il numero massimo di connessioni consentite sull'istanza Amazon RDS può fornire una soluzione temporanea, ma non affronta il problema sottostante dei picchi di connessione. Questo approccio può portare a un maggiore consumo di risorse e potrebbe non essere sostenibile se l'applicazione continua a crescere.",
            "Distribuire un cluster Amazon ElastiCache può aiutare a ridurre il carico sul database memorizzando nella cache i dati frequentemente accessibili, ma non gestisce direttamente le connessioni al database. Sebbene possa migliorare le prestazioni riducendo il numero di query inviate al database, non risolve il problema del superamento del limite massimo di connessione.",
            "Utilizzare funzioni AWS Lambda per gestire e distribuire dinamicamente le connessioni al database non è una soluzione efficace per questo scenario. Le funzioni Lambda sono senza stato e progettate per architetture basate su eventi, il che potrebbe non fornire le necessarie capacità di pooling e gestione delle connessioni necessarie per gestire i picchi nelle connessioni al database."
        ]
    },
    {
        "Question Number": "11",
        "Situation": "Un'azienda sta cercando di implementare una soluzione di database su AWS e desidera mantenere la flessibilità per patch personalizzate del sistema operativo e installazioni software, beneficiando al contempo di un servizio gestito per backup e scalabilità. Stanno considerando Amazon RDS, RDS Custom e l'esecuzione del database su EC2.",
        "Question": "Quale opzione si allinea meglio ai loro requisiti per un equilibrio tra controllo e servizi gestiti?",
        "Options": {
            "1": "Amazon RDS, poiché fornisce una gestione completa da parte di AWS con backup automatici e scalabilità, ma con una personalizzazione limitata del sistema operativo e del software.",
            "2": "RDS Custom, che consente all'azienda di gestire patch personalizzate del sistema operativo e installazioni software mentre AWS gestisce backup e scalabilità.",
            "3": "EC2 con un database autogestito, che offre il pieno controllo sul sistema operativo e sul software, ma richiede all'azienda di gestire tutti i compiti di gestione, inclusi i backup.",
            "4": "Amazon RDS con Multi-AZ abilitato, poiché bilancia disponibilità e backup, ma non consente l'accesso a livello di sistema operativo per la personalizzazione."
        },
        "Correct Answer": "RDS Custom, che consente all'azienda di gestire patch personalizzate del sistema operativo e installazioni software mentre AWS gestisce backup e scalabilità.",
        "Explanation": "RDS Custom è progettato specificamente per fornire la flessibilità di patch personalizzate del sistema operativo e installazioni software, beneficiando al contempo dei servizi gestiti offerti da AWS, come backup automatici e scalabilità. Questa opzione trova il giusto equilibrio tra controllo e gestione, consentendo all'azienda di personalizzare il proprio ambiente database in base alle proprie esigenze specifiche senza sacrificare i vantaggi di un servizio gestito.",
        "Other Options": [
            "Amazon RDS fornisce una gestione completa da parte di AWS, inclusi backup automatici e scalabilità, ma non consente la personalizzazione del sistema operativo o delle installazioni software, il che non soddisfa il requisito di flessibilità dell'azienda.",
            "EC2 con un database autogestito offre il pieno controllo sul sistema operativo e sul software, ma richiede all'azienda di gestire tutti gli aspetti del database, inclusi backup e scalabilità, il che contraddice il loro desiderio di un servizio gestito.",
            "Amazon RDS con Multi-AZ abilitato migliora la disponibilità e fornisce backup automatici, ma come RDS standard, non consente l'accesso a livello di sistema operativo o personalizzazione, rendendolo inadeguato per le esigenze dell'azienda."
        ]
    },
    {
        "Question Number": "12",
        "Situation": "Un'azienda con più account AWS desidera implementare un approccio centralizzato per gestire la sicurezza e le autorizzazioni in tutti gli account. L'azienda richiede che ogni account segua politiche di conformità rigorose, consentendo al contempo agli amministratori di account individuali di gestire gli utenti all'interno dei propri account.",
        "Question": "Quale servizio AWS dovrebbe utilizzare l'azienda per raggiungere questi requisiti?",
        "Options": {
            "1": "AWS IAM Identity Center (AWS Single Sign-On)",
            "2": "AWS Organizations con Service Control Policies (SCPs)",
            "3": "AWS IAM con ruoli cross-account",
            "4": "Amazon Cognito"
        },
        "Correct Answer": "AWS Organizations con Service Control Policies (SCPs)",
        "Explanation": "AWS Organizations consente di gestire centralmente più account AWS e applicare politiche in questi account. Le Service Control Policies (SCPs) sono una funzione di AWS Organizations che consente di impostare limiti di autorizzazione per i propri account, garantendo la conformità a politiche rigorose, consentendo al contempo agli amministratori di account individuali di gestire utenti e autorizzazioni all'interno dei propri account. Questa configurazione soddisfa il requisito dell'azienda per una gestione centralizzata e l'applicazione della conformità in più account.",
        "Other Options": [
            "AWS IAM Identity Center (AWS Single Sign-On) è principalmente utilizzato per gestire l'accesso degli utenti e il single sign-on tra account e applicazioni AWS. Sebbene aiuti nella gestione degli utenti, non fornisce le capacità di applicazione centralizzata delle politiche che offre AWS Organizations con SCPs.",
            "AWS IAM con ruoli cross-account consente di concedere autorizzazioni tra diversi account AWS, ma non fornisce un modo centralizzato per applicare politiche di conformità in più account. Ogni account dovrebbe comunque gestire le proprie politiche IAM senza il controllo generale fornito da SCPs.",
            "Amazon Cognito è progettato per l'autenticazione e la gestione degli utenti per applicazioni web e mobili. Non è adatto per gestire autorizzazioni e conformità tra più account AWS, poiché si concentra sull'identità degli utenti piuttosto che sull'applicazione delle politiche a livello di account."
        ]
    },
    {
        "Question Number": "13",
        "Situation": "Un'azienda di e-commerce, ABC Online, ospita il proprio sito web e le API su AWS utilizzando servizi come CloudFront, Application Load Balancer (ALB), AppSync e API Gateway. Per proteggersi da minacce come SQL injection, cross-site scripting (XSS) e attacchi basati su IP, ABC Online desidera implementare una soluzione firewall che possa bloccare dinamicamente il traffico malevolo consentendo al contempo agli utenti legittimi un accesso ininterrotto. Stanno considerando di utilizzare AWS Web Application Firewall (WAF) insieme a Web Access Control Lists (Web ACLs) per proteggere le loro applicazioni su più servizi AWS. Il team di sicurezza desidera configurare regole personalizzate e controllare il flusso di traffico in base a criteri specifici per prevenire attacchi che potrebbero compromettere la loro applicazione e i dati dei clienti.",
        "Question": "Quale delle seguenti affermazioni descrive meglio come AWS Web Application Firewall (WAF) e Web ACLs funzionano per proteggere le applicazioni distribuite su servizi AWS come CloudFront, ALB, AppSync e API Gateway?",
        "Options": {
            "1": "AWS WAF applica regole predefinite per consentire o negare automaticamente tutto il traffico in ingresso senza alcun aggiustamento o aggiornamento manuale, offrendo una protezione statica contro minacce comuni.",
            "2": "Le Web ACL in AWS WAF consistono in regole e gruppi di regole che possono essere applicati a risorse specifiche, come CloudFront o servizi regionali, per controllare l'accesso in base a criteri definiti come reputazione IP, SQL injection e attacchi cross-site scripting (XSS).",
            "3": "AWS WAF opera utilizzando Web ACLs, che bloccano solo il traffico proveniente da indirizzi IP specifici, rendendolo efficace solo per prevenire attacchi basati su IP.",
            "4": "Le Web ACL sono compatibili solo con le distribuzioni CloudFront e non possono essere utilizzate con altri servizi AWS come ALB, AppSync o API Gateway."
        },
        "Correct Answer": "Le Web ACL in AWS WAF consistono in regole e gruppi di regole che possono essere applicati a risorse specifiche, come CloudFront o servizi regionali, per controllare l'accesso in base a criteri definiti come reputazione IP, SQL injection e attacchi cross-site scripting (XSS).",
        "Explanation": "AWS WAF consente agli utenti di creare Web Access Control Lists (Web ACLs) che contengono regole e gruppi di regole per filtrare il traffico web. Queste regole possono essere personalizzate per mirare a minacce specifiche, come SQL injection e XSS, e possono essere applicate a vari servizi AWS, inclusi CloudFront, ALB, AppSync e API Gateway. Questa flessibilità consente alle organizzazioni di bloccare dinamicamente il traffico malevolo consentendo al contempo agli utenti legittimi un accesso ininterrotto, essenziale per mantenere la sicurezza dell'applicazione.",
        "Other Options": [
            "AWS WAF non si basa esclusivamente su regole predefinite; consente la creazione di regole personalizzate e richiede aggiustamenti manuali per adattarsi a minacce in evoluzione. Fornisce protezione dinamica piuttosto che statica.",
            "AWS WAF non è limitato a bloccare il traffico proveniente da indirizzi IP specifici. Può bloccare o consentire il traffico in base a una vasta gamma di criteri, inclusi SQL injection e XSS, rendendolo una soluzione completa per la sicurezza delle applicazioni web.",
            "Le Web ACL sono compatibili con più servizi AWS, non solo CloudFront. Possono essere applicate anche a Application Load Balancers, API Gateway e altri servizi regionali, fornendo un approccio unificato alla sicurezza delle applicazioni web su varie piattaforme."
        ]
    },
    {
        "Question Number": "14",
        "Situation": "Un'azienda desidera implementare un database relazionale altamente disponibile su AWS che possa effettuare failover senza soluzione di continuità in caso di un'interruzione della Availability Zone. Sono anche interessati a scaricare il traffico di lettura e mantenere backup per il disaster recovery.",
        "Question": "Quale configurazione AWS RDS dovrebbero utilizzare per raggiungere questi requisiti?",
        "Options": {
            "1": "Configurare Amazon RDS con distribuzioni Multi-AZ per la replica sincrona a un'istanza di standby e creare repliche di lettura in diverse regioni per la scalabilità in lettura.",
            "2": "Utilizzare un'unica istanza Amazon RDS con snapshot EBS regolari e configurare un indirizzamento pubblico per consentire l'accesso remoto per il failover.",
            "3": "Impostare Amazon RDS con distribuzioni Multi-AZ e replica asincrona per repliche di lettura all'interno della stessa Availability Zone.",
            "4": "Distribuire Amazon RDS con replica cross-region, abilitando il failover a un'istanza primaria in un'altra regione AWS quando l'istanza principale fallisce."
        },
        "Correct Answer": "Configurare Amazon RDS con distribuzioni Multi-AZ per la replica sincrona a un'istanza di standby e creare repliche di lettura in diverse regioni per la scalabilità in lettura.",
        "Explanation": "Questa configurazione soddisfa tutti i requisiti delineati nella situazione. Le distribuzioni Multi-AZ forniscono alta disponibilità effettuando automaticamente il failover a un'istanza di standby in un'altra Availability Zone in caso di interruzione, garantendo un failover senza soluzione di continuità. La replica sincrona assicura che i dati siano replicati in modo coerente all'istanza di standby. Inoltre, creare repliche di lettura in diverse regioni consente all'azienda di scaricare il traffico di lettura e scalare le operazioni di lettura, fornendo anche opzioni per il disaster recovery tramite backup.",
        "Other Options": [
            "Utilizzare un'unica istanza Amazon RDS con snapshot EBS regolari non fornisce alta disponibilità o failover senza soluzione di continuità, poiché si basa su un intervento manuale per il recupero. L'indirizzamento pubblico non migliora la disponibilità e può esporre il database a rischi di sicurezza.",
            "Impostare Amazon RDS con distribuzioni Multi-AZ e replica asincrona per repliche di lettura all'interno della stessa Availability Zone non fornisce le necessarie capacità di alta disponibilità e failover, poiché non utilizza i vantaggi di Multi-AZ per il failover e non consente di scaricare efficacemente il traffico di lettura.",
            "Distribuire Amazon RDS con replica cross-region non è necessario per i requisiti dichiarati, poiché complica la configurazione e potrebbe introdurre latenza. L'attenzione principale dovrebbe essere sulle distribuzioni Multi-AZ per alta disponibilità all'interno della stessa regione, con repliche di lettura per la scalabilità."
        ]
    },
    {
        "Question Number": "15",
        "Situation": "Un'azienda sta configurando una distribuzione CloudFront per servire contenuti in modo sicuro utilizzando SSL. Vogliono utilizzare un nome di dominio alternativo e garantire connessioni sicure dagli spettatori a CloudFront e poi da CloudFront alle loro origini, che includono un bucket S3 e un Application Load Balancer (ALB).",
        "Question": "Quali passaggi devono seguire per garantire connessioni SSL sicure in tutto il processo?",
        "Options": {
            "1": "Configurare un certificato SSL in CloudFront utilizzando ACM nella regione in cui è distribuito CloudFront.",
            "2": "Configurare un certificato SSL in ACM per il bucket S3, consentendo a CloudFront di utilizzare il bucket direttamente con HTTPS.",
            "3": "Utilizzare un certificato da ACM per l'ALB e un certificato esterno per eventuali origini personalizzate; i certificati autofirmati sono accettabili.",
            "4": "Configurare il supporto SNI in CloudFront per gestire più siti HTTPS su un singolo IP e generare un certificato ACM in us-east-1 per il nome di dominio alternativo."
        },
        "Correct Answer": "Configurare un certificato SSL in CloudFront utilizzando ACM nella regione in cui è distribuito CloudFront.",
        "Explanation": "Per garantire connessioni SSL sicure in tutta la configurazione, l'azienda deve configurare un certificato SSL in CloudFront utilizzando AWS Certificate Manager (ACM). Questo certificato sarà utilizzato per crittografare la connessione tra gli spettatori e CloudFront. È importante notare che CloudFront richiede che il certificato SSL sia nella regione US East (N. Virginia) (us-east-1) affinché possa essere utilizzato con nomi di dominio alternativi. Questo passaggio garantisce che i contenuti serviti da CloudFront siano consegnati in modo sicuro tramite HTTPS.",
        "Other Options": [
            "Configurare un certificato SSL in ACM per il bucket S3 non è necessario perché CloudFront può servire contenuti da S3 tramite HTTPS senza necessità di un certificato SSL separato per il bucket stesso. CloudFront gestisce la terminazione SSL.",
            "Utilizzare un certificato da ACM per l'ALB e un certificato esterno per eventuali origini personalizzate non è la migliore pratica. Tutte le origini dovrebbero idealmente utilizzare certificati ACM per coerenza e facilità di gestione. I certificati autofirmati non sono generalmente raccomandati per ambienti di produzione a causa di problemi di fiducia.",
            "Configurare il supporto SNI in CloudFront non è necessario per questo scenario. Sebbene SNI (Server Name Indication) consenta di servire più certificati SSL da un singolo indirizzo IP, il requisito principale è avere il certificato SSL configurato correttamente in ACM per CloudFront, che gestisce la terminazione SSL per il nome di dominio alternativo."
        ]
    },
    {
        "Question Number": "16",
        "Situation": "Un'azienda deve stabilire una connessione sicura e affidabile tra il proprio data center on-premises e il proprio ambiente AWS per accedere a dati sensibili. L'azienda richiede bassa latenza, alta larghezza di banda e crittografia per i dati in transito.",
        "Question": "Quale soluzione soddisferebbe meglio questi requisiti?",
        "Options": {
            "1": "Impostare una connessione AWS Direct Connect con un overlay VPN per fornire crittografia e trasmissione sicura dei dati tra on-premises e AWS.",
            "2": "Configurare un Internet Gateway standard nel VPC e utilizzare tunnel VPN IPsec per crittografare i dati durante il transito.",
            "3": "Utilizzare un Internet Gateway insieme ad AWS Shield per la protezione DDoS e fare affidamento su HTTPS per la crittografia.",
            "4": "Stabilire una connessione VPC Peering tra il data center on-premises e il VPC AWS per garantire comunicazioni sicure e a bassa latenza."
        },
        "Correct Answer": "Impostare una connessione AWS Direct Connect con un overlay VPN per fornire crittografia e trasmissione sicura dei dati tra on-premises e AWS.",
        "Explanation": "AWS Direct Connect fornisce una connessione di rete dedicata dal data center on-premises ad AWS, garantendo bassa latenza e alta larghezza di banda. Aggiungendo un overlay VPN, i dati in transito possono essere crittografati, soddisfacendo il requisito dell'azienda per la trasmissione sicura di dati sensibili. Questa combinazione offre sia i vantaggi prestazionali di Direct Connect che la sicurezza di una VPN, rendendola la migliore soluzione per il contesto fornito.",
        "Other Options": [
            "Configurare un Internet Gateway standard nel VPC e utilizzare tunnel VPN IPsec fornirebbe crittografia, ma l'Internet Gateway si basa su Internet pubblico, il che potrebbe introdurre latenza più elevata e minore affidabilità rispetto a una connessione dedicata come Direct Connect.",
            "Utilizzare un Internet Gateway insieme ad AWS Shield per la protezione DDoS e fare affidamento su HTTPS per la crittografia non soddisfa i requisiti di bassa latenza e alta larghezza di banda. HTTPS è adatto per garantire la sicurezza dei dati in transito, ma la dipendenza da Internet pubblico può portare a prestazioni variabili, che non sono ideali per accedere a dati sensibili.",
            "Stabilire una connessione VPC Peering non si applica in questo contesto, poiché VPC Peering è utilizzato per connettere due VPC all'interno di AWS, non per connettere un data center on-premises ad AWS. Inoltre, VPC Peering non fornisce crittografia o una connessione dedicata, che sono critiche per le esigenze dell'azienda."
        ]
    },
    {
        "Question Number": "17",
        "Situation": "Un'azienda ha distribuito un'applicazione su istanze Amazon EC2 all'interno di una subnet privata di un VPC. L'applicazione deve accedere a Internet per scaricare aggiornamenti e comunicare con altri servizi pubblici, ma non dovrebbe essere accessibile direttamente da Internet.",
        "Question": "Quale configurazione dovrebbe utilizzare l'azienda per soddisfare questi requisiti?",
        "Options": {
            "1": "Collegare un Internet Gateway alla subnet privata e configurare le istanze EC2 con IP pubblici per l'accesso in uscita.",
            "2": "Distribuire un NAT Gateway in una subnet pubblica, associare una tabella di routing alla subnet privata per indirizzare il traffico 0.0.0.0/0 al NAT Gateway e assicurarsi che il NAT Gateway abbia un Elastic IP.",
            "3": "Utilizzare VPC Peering per connettere la subnet privata a un altro VPC che ha accesso a Internet e configurare il routing tra i due VPC.",
            "4": "Impostare una connessione VPN tra la subnet privata e una rete on-premises con accesso a Internet, consentendo alle istanze EC2 di instradare il traffico attraverso la rete on-premises."
        },
        "Correct Answer": "Distribuire un NAT Gateway in una subnet pubblica, associare una tabella di routing alla subnet privata per indirizzare il traffico 0.0.0.0/0 al NAT Gateway e assicurarsi che il NAT Gateway abbia un Elastic IP.",
        "Explanation": "Un NAT Gateway consente alle istanze in una subnet privata di avviare traffico in uscita verso Internet, impedendo il traffico in ingresso da Internet. Distribuendo un NAT Gateway in una subnet pubblica e associando la tabella di routing della subnet privata con una rotta che indirizza il traffico 0.0.0.0/0 al NAT Gateway, le istanze EC2 possono accedere a Internet per aggiornamenti e comunicazioni senza essere direttamente accessibili da Internet. L'Elastic IP assegnato al NAT Gateway fornisce un IP pubblico per il traffico in uscita, garantendo una corretta connettività a Internet.",
        "Other Options": [
            "Collegare un Internet Gateway alla subnet privata e configurare le istanze EC2 con IP pubblici esporrebbe le istanze direttamente a Internet, il che contraddice il requisito di non essere direttamente accessibili da Internet.",
            "Utilizzare VPC Peering per connettere la subnet privata a un altro VPC con accesso a Internet non fornisce una rotta diretta per le istanze della subnet privata per accedere a Internet. VPC Peering non facilita l'accesso a Internet per le subnet private senza configurazioni aggiuntive, come NAT.",
            "Impostare una connessione VPN tra la subnet privata e una rete on-premises con accesso a Internet complicherebbe l'architettura e introdurrebbe latenza. Non affronta direttamente il requisito per le istanze EC2 di accedere a Internet senza essere esposte, poiché si basa su una rete esterna per l'accesso a Internet."
        ]
    },
    {
        "Question Number": "18",
        "Situation": "Un'azienda di servizi finanziari genera e memorizza grandi volumi di dati dei clienti on-premises ogni giorno. A causa di rigorosi requisiti normativi e di conformità, devono mantenere questi dati localmente ma vogliono scaricare dati più vecchi e raramente accessibili su AWS per risparmiare sui costi di archiviazione. Hanno bisogno di una soluzione che possa estendere senza problemi la loro attuale infrastruttura di archiviazione su AWS, consentendo l'accesso ai dati archiviati senza interrompere le loro applicazioni o flussi di lavoro esistenti.",
        "Question": "Quale servizio AWS soddisferebbe meglio i requisiti dell'azienda? (Scegli due.)",
        "Options": {
            "1": "Amazon S3 con politiche di ciclo di vita",
            "2": "AWS Direct Connect",
            "3": "AWS Storage Gateway",
            "4": "Amazon EBS Snapshot Export",
            "5": "Amazon Glacier Deep Archive con Vault Lock"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon S3 con politiche di ciclo di vita",
            "AWS Storage Gateway"
        ],
        "Explanation": "Amazon S3 con politiche di ciclo di vita è una risposta corretta perché consente la migrazione automatica dei dati a diverse classi di archiviazione in base a regole definite, il che può aiutare l'azienda a risparmiare sui costi di archiviazione per i dati raramente accessibili. AWS Storage Gateway è anche corretto in quanto fornisce un modo senza soluzione di continuità per connettere le applicazioni on-premises all'archiviazione AWS. Supporta tipi di archiviazione file, volume e nastro e può essere utilizzato per memorizzare dati in S3, Glacier ed EBS, rendendolo adatto ai requisiti dell'azienda.",
        "Other Options": [
            "AWS Direct Connect è utilizzato principalmente per stabilire una connessione di rete dedicata dai tuoi locali a AWS, non specificamente per scopi di archiviazione o archiviazione.",
            "Amazon EBS Snapshot Export consente di esportare uno snapshot di Amazon EBS in un bucket Amazon S3, ma non fornisce un'estensione senza soluzione di continuità dell'infrastruttura di archiviazione on-premises su AWS.",
            "Amazon Glacier Deep Archive con Vault Lock è una classe di archiviazione per l'archiviazione dei dati e il backup a lungo termine a costi molto bassi. Tuttavia, non fornisce un modo senza soluzione di continuità per estendere l'archiviazione on-premises su AWS, e i tempi di recupero dei dati possono arrivare fino a 12 ore, il che potrebbe non soddisfare le esigenze dell'azienda per accedere ai dati archiviati."
        ]
    },
    {
        "Question Number": "19",
        "Situation": "Un servizio di streaming video sperimenta picchi imprevedibili nel traffico degli spettatori, specialmente durante eventi dal vivo. Il servizio deve garantire di poter gestire improvvisi aumenti di carico senza intervento manuale, riducendo al minimo i costi durante i periodi di bassa affluenza.",
        "Question": "Quale funzionalità AWS dovrebbe configurare l'architetto delle soluzioni per regolare automaticamente il numero di istanze EC2 in base ai modelli di traffico?",
        "Options": {
            "1": "AWS Elastic Beanstalk scaling",
            "2": "Amazon CloudWatch Alarms",
            "3": "Amazon EC2 Auto Scaling",
            "4": "AWS Lambda auto-scaling"
        },
        "Correct Answer": "Amazon EC2 Auto Scaling",
        "Explanation": "Amazon EC2 Auto Scaling è progettato per regolare automaticamente il numero di istanze EC2 in risposta a modelli di traffico in cambiamento. Può scalare verso l'esterno (aggiungere istanze) durante i periodi di picco e scalare verso l'interno (rimuovere istanze) durante i periodi di bassa affluenza senza intervento manuale. Questa funzionalità è ideale per gestire picchi imprevedibili nel traffico degli spettatori, come durante eventi dal vivo, riducendo al contempo i costi durante i periodi di bassa domanda.",
        "Other Options": [
            "AWS Elastic Beanstalk scaling è una funzionalità che consente la gestione delle applicazioni e dei loro ambienti, inclusa la scalabilità, ma non è così direttamente focalizzata sulla gestione delle istanze EC2 come EC2 Auto Scaling. È più adatta per le applicazioni piuttosto che per la scalabilità delle istanze in base ai modelli di traffico.",
            "Amazon CloudWatch Alarms può monitorare le metriche e attivare azioni in base a soglie, ma non scala direttamente le istanze EC2. Possono essere utilizzate in combinazione con EC2 Auto Scaling per attivare azioni di scaling, ma non eseguono il scaling da sole.",
            "AWS Lambda auto-scaling è correlato al computing serverless e regola automaticamente il numero di istanze della funzione Lambda in base al numero di richieste in arrivo. Tuttavia, non è applicabile per scalare le istanze EC2, che è il requisito in questo scenario."
        ]
    },
    {
        "Question Number": "20",
        "Situation": "Un'azienda esegue applicazioni critiche su istanze Amazon EC2 all'interno della regione us-east-1 per garantire disponibilità continua e resilienza. Per raggiungere un'architettura altamente disponibile, devono progettare il loro deployment EC2 per resistere a potenziali guasti a diversi livelli, come host individuali, Availability Zones (AZ) o istanze.",
        "Question": "Quale dei seguenti approcci supporta meglio un'architettura EC2 resiliente? (Scegli due.)",
        "Options": {
            "1": "Distribuire istanze EC2 su più Availability Zones all'interno della regione per fornire isolamento dei guasti e ridondanza in caso di guasto di un'AZ.",
            "2": "Distribuire istanze EC2 in un'unica Availability Zone, ma utilizzare EC2 Auto Scaling per sostituire immediatamente le istanze guaste.",
            "3": "Posizionare tutte le istanze EC2 in un host dedicato all'interno di un'Availability Zone per massimizzare l'utilizzo delle risorse e semplificare la gestione.",
            "4": "Configurare le istanze EC2 con volumi di archiviazione istanza solo per garantire alte prestazioni, facendo affidamento su snapshot per la durabilità.",
            "5": "Utilizzare Elastic Load Balancing (ELB) insieme a gruppi di Auto Scaling distribuiti su più Availability Zones per distribuire il traffico e gestire senza problemi i guasti delle istanze."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Distribuire istanze EC2 su più Availability Zones all'interno della regione per fornire isolamento dei guasti e ridondanza in caso di guasto di un'AZ.",
            "Utilizzare Elastic Load Balancing (ELB) insieme a gruppi di Auto Scaling distribuiti su più Availability Zones per distribuire il traffico e gestire senza problemi i guasti delle istanze."
        ],
        "Explanation": "Distribuire istanze EC2 su più Availability Zones all'interno della regione fornisce isolamento dei guasti e ridondanza in caso di guasto di un'AZ. Questo garantisce che anche se un'AZ va giù, l'applicazione rimanga disponibile nelle altre AZ. Utilizzare Elastic Load Balancing (ELB) insieme a gruppi di Auto Scaling distribuiti su più Availability Zones consente la distribuzione del traffico e la gestione dei guasti delle istanze senza problemi. ELB garantisce che il traffico sia distribuito uniformemente tra le istanze e Auto Scaling garantisce che il numero di istanze si adatti in base alla domanda, fornendo alta disponibilità e tolleranza ai guasti.",
        "Other Options": [
            "Distribuire istanze EC2 in un'unica Availability Zone e utilizzare EC2 Auto Scaling per sostituire immediatamente le istanze guaste non fornisce tolleranza ai guasti a livello di AZ. Se l'unica AZ va giù, l'intera applicazione diventa non disponibile.",
            "Posizionare tutte le istanze EC2 in un host dedicato all'interno di un'Availability Zone per massimizzare l'utilizzo delle risorse e semplificare la gestione non fornisce tolleranza ai guasti a livello di AZ. Se l'unica AZ va giù, l'intera applicazione diventa non disponibile.",
            "Configurare le istanze EC2 con volumi di archiviazione istanza solo per garantire alte prestazioni, facendo affidamento su snapshot per la durabilità, non fornisce tolleranza ai guasti a livello di AZ. I volumi di archiviazione istanza sono effimeri e i dati vengono persi se l'istanza viene arrestata o guasta, rendendo questa opzione meno resiliente."
        ]
    },
    {
        "Question Number": "21",
        "Situation": "Una startup sta costruendo una pipeline di elaborazione dei dati su AWS che acquisisce dati da varie fonti, li elabora e memorizza i risultati per l'analisi. La pipeline deve gestire carichi di lavoro variabili e scalare automaticamente in base al volume di dati in ingresso. L'azienda desidera ridurre al minimo il sovraccarico operativo nella gestione dei server.",
        "Question": "Quale combinazione di servizi AWS dovrebbe raccomandare l'architetto delle soluzioni per questa pipeline? (Scegli DUE.)",
        "Options": {
            "1": "Istanza Amazon EC2 con Auto Scaling",
            "2": "AWS Lambda",
            "3": "Amazon EMR",
            "4": "Amazon Kinesis Data Firehose",
            "5": "Amazon RDS"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "AWS Lambda",
            "Amazon Kinesis Data Firehose"
        ],
        "Explanation": "AWS Lambda è un servizio di calcolo serverless che esegue il tuo codice in risposta a eventi e gestisce automaticamente le risorse di calcolo sottostanti, il che si allinea con il requisito dell'azienda di ridurre al minimo il sovraccarico operativo. Può anche scalare automaticamente in base al volume di dati in ingresso, ideale per gestire carichi di lavoro variabili. Amazon Kinesis Data Firehose è il modo più semplice per caricare in modo affidabile i dati in streaming in data lake, archivi di dati e servizi di analisi. Può acquisire, trasformare e caricare dati in streaming in servizi AWS come Amazon S3, Amazon Redshift, Amazon Elasticsearch Service e Splunk, abilitando analisi quasi in tempo reale con strumenti di business intelligence e dashboard esistenti.",
        "Other Options": [
            "Istanza Amazon EC2 con Auto Scaling: Anche se le istanze EC2 con Auto Scaling possono gestire carichi di lavoro variabili e scalare in base al volume di dati in ingresso, non riducono il sovraccarico operativo nella gestione dei server, poiché l'azienda dovrebbe comunque gestire le istanze EC2.",
            "Amazon EMR: Amazon EMR è una piattaforma di big data nativa del cloud, che consente di elaborare enormi quantità di dati rapidamente e in modo conveniente su larga scala utilizzando framework distribuiti popolari come Apache Spark e Hadoop. Tuttavia, richiede la gestione di cluster di server, il che non si allinea con il requisito dell'azienda di ridurre al minimo il sovraccarico operativo.",
            "Amazon RDS: Amazon RDS è un servizio di database relazionale, che non si allinea con i requisiti di una pipeline di elaborazione dei dati che deve gestire carichi di lavoro variabili e scalare automaticamente in base al volume di dati in ingresso."
        ]
    },
    {
        "Question Number": "22",
        "Situation": "Una piattaforma di streaming video sperimenta picchi di traffico imprevedibili, in particolare durante eventi dal vivo che attirano milioni di spettatori. Per mantenere le prestazioni e evitare interruzioni, la piattaforma deve scalare rapidamente ed efficientemente la propria capacità di calcolo. L'applicazione di streaming attualmente gira su istanze Amazon EC2 in più zone di disponibilità, e il team vuole assicurarsi che queste istanze siano fornite automaticamente in base alla domanda, specialmente durante picchi di traffico imprevisti, per prevenire il degrado delle prestazioni.",
        "Question": "Quale configurazione dovrebbe implementare l'architetto delle soluzioni per soddisfare questi requisiti? (Scegli due.)",
        "Options": {
            "1": "Impostare un numero fisso di istanze EC2 in tutte le zone di disponibilità per gestire i carichi di picco",
            "2": "Utilizzare un Auto Scaling Group configurato con politiche di scaling dinamico basate su metriche come l'utilizzo della CPU per scalare automaticamente su e giù man mano che la domanda fluttua",
            "3": "Monitorare manualmente i modelli di traffico e aggiungere istanze EC2 secondo necessità durante eventi ad alto traffico",
            "4": "Ospitare il contenuto del sito web su Amazon S3 e rimuovere la necessità di istanze EC2 per gestire il traffico del sito web",
            "5": "Implementare il scaling predittivo utilizzando Amazon CloudWatch per anticipare i picchi di traffico e regolare proattivamente la capacità"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Utilizzare un Auto Scaling Group configurato con politiche di scaling dinamico basate su metriche come l'utilizzo della CPU per scalare automaticamente su e giù man mano che la domanda fluttua",
            "Implementare il scaling predittivo utilizzando Amazon CloudWatch per anticipare i picchi di traffico e regolare proattivamente la capacità"
        ],
        "Explanation": "Gli Auto Scaling Groups in AWS consentono lo scaling dinamico delle istanze EC2 in base alla domanda. Ciò significa che man mano che la domanda aumenta, possono essere fornite più istanze per gestire il carico, e man mano che la domanda diminuisce, le istanze possono essere terminate per risparmiare costi. Questo è ideale per gestire picchi di traffico imprevedibili. Il scaling predittivo in Amazon CloudWatch utilizza algoritmi di machine learning per prevedere la domanda futura e regolare la capacità in anticipo. Questo è utile per anticipare i picchi di traffico e scalare proattivamente per soddisfare la domanda.",
        "Other Options": [
            "Impostare un numero fisso di istanze EC2 in tutte le zone di disponibilità per gestire i carichi di picco non è una soluzione efficiente. Non tiene conto delle fluttuazioni nella domanda e può portare a sovraprovisionamento (spreco di risorse quando la domanda è bassa) o sottoprovisionamento (non avere risorse sufficienti quando la domanda è alta).",
            "Monitorare manualmente i modelli di traffico e aggiungere istanze EC2 secondo necessità durante eventi ad alto traffico non è una soluzione scalabile o efficiente. Richiede monitoraggio costante e intervento manuale, e potrebbero esserci ritardi nel scaling che potrebbero influire sulle prestazioni.",
            "Ospitare il contenuto del sito web su Amazon S3 e rimuovere la necessità di istanze EC2 per gestire il traffico del sito web non è una soluzione adatta per una piattaforma di streaming video. Anche se S3 è ottimo per l'hosting di siti web statici, una piattaforma di streaming video richiede una consegna di contenuti dinamici e capacità di calcolo, che è meglio gestita da istanze EC2."
        ]
    },
    {
        "Question Number": "23",
        "Situation": "Un'azienda sta considerando AWS Direct Connect per migliorare la coerenza e la velocità della connettività di rete tra il proprio data center on-premises e AWS.",
        "Question": "Quale delle seguenti affermazioni descrive accuratamente un vantaggio e una limitazione dell'uso di AWS Direct Connect per questo scopo?",
        "Options": {
            "1": "AWS Direct Connect fornisce trasferimenti di dati sicuri tramite una linea privata e dedicata con resilienza integrata; tuttavia, è limitato a 1 Gbps di larghezza di banda per connessione.",
            "2": "AWS Direct Connect può fornire connettività ad alta velocità e bassa latenza direttamente ai servizi pubblici e privati di AWS senza dipendenza da internet; tuttavia, non fornisce intrinsecamente resilienza, poiché si basa su cavi fisici che possono essere soggetti a interruzioni.",
            "3": "AWS Direct Connect offre trasferimenti di dati ad alta velocità e resilienti tra AWS e ambienti on-premises, con l'opzione di failover automatico; tuttavia, è disponibile solo in alcune regioni AWS nel mondo.",
            "4": "AWS Direct Connect fornisce una soluzione economica per il trasferimento di dati basato su internet, consentendo ai dati di essere instradati attraverso endpoint pubblici AWS; tuttavia, potrebbe affrontare una latenza più elevata rispetto alle soluzioni basate su VPN a causa dell'infrastruttura condivisa."
        },
        "Correct Answer": "AWS Direct Connect può fornire connettività ad alta velocità e bassa latenza direttamente ai servizi pubblici e privati di AWS senza dipendenza da internet; tuttavia, non fornisce intrinsecamente resilienza, poiché si basa su cavi fisici che possono essere soggetti a interruzioni.",
        "Explanation": "AWS Direct Connect è progettato per offrire connessioni ad alta velocità e bassa latenza ai servizi AWS, bypassando internet pubblico, il che migliora le prestazioni e l'affidabilità. Tuttavia, mentre fornisce una connessione dedicata, non include automaticamente ridondanza o resilienza; se la connessione fisica viene interrotta, può portare a interruzioni. Pertanto, gli utenti devono implementare misure aggiuntive, come l'uso di più connessioni o strategie di failover, per garantire la resilienza.",
        "Other Options": [
            "Sebbene AWS Direct Connect fornisca trasferimenti di dati sicuri tramite una linea privata, non ha una limitazione rigorosa di 1 Gbps di larghezza di banda per connessione. AWS Direct Connect offre più velocità di connessione, inclusi 10 Gbps e superiori, a seconda delle esigenze.",
            "AWS Direct Connect offre opzioni per la resilienza, come la possibilità di creare connessioni ridondanti in diverse località. Inoltre, è disponibile in molte regioni AWS, non solo in alcune, il che ne migliora l'accessibilità.",
            "AWS Direct Connect non è una soluzione basata su internet; fornisce una connessione dedicata che di solito risulta in una latenza inferiore rispetto alle soluzioni VPN. Non instrada i dati attraverso endpoint pubblici, che è un vantaggio chiave dell'uso di Direct Connect."
        ]
    },
    {
        "Question Number": "24",
        "Situation": "Una multinazionale sta pianificando di distribuire una nuova applicazione rivolta ai clienti su AWS che servirà utenti in Nord America, Europa e Asia. Per ottimizzare le prestazioni dell'applicazione e rispettare le normative sulla residenza dei dati in ciascuna regione, la multinazionale desidera garantire che i dati degli utenti siano elaborati e memorizzati vicino alle loro posizioni geografiche. Inoltre, vogliono ridurre al minimo la latenza servendo la base utenti di ciascuna regione con l'infrastruttura più vicina.",
        "Question": "Qual è la strategia più appropriata per distribuire questa applicazione?",
        "Options": {
            "1": "Distribuire l'applicazione in una singola regione AWS con istanze ad alta capacità, sfruttando le risorse della regione per gestire tutti gli utenti globali da una posizione centralizzata",
            "2": "Distribuire l'applicazione in più regioni AWS, assicurando che ogni regione abbia un'infrastruttura locale per servire la propria base utenti e soddisfare i requisiti di residenza dei dati",
            "3": "Distribuire l'applicazione in una regione AWS centrale, quindi utilizzare una rete di distribuzione dei contenuti (CDN) per memorizzare i dati in altre regioni, migliorando la velocità di accesso",
            "4": "Utilizzare le zone di disponibilità all'interno di una singola regione AWS per servire gli utenti globali, garantendo ridondanza senza distribuire in più regioni"
        },
        "Correct Answer": "Distribuire l'applicazione in più regioni AWS, assicurando che ogni regione abbia un'infrastruttura locale per servire la propria base utenti e soddisfare i requisiti di residenza dei dati",
        "Explanation": "Distribuire l'applicazione in più regioni AWS consente alla multinazionale di posizionare l'elaborazione e la memorizzazione dei dati degli utenti vicino agli utenti in Nord America, Europa e Asia. Questa strategia non solo ottimizza le prestazioni dell'applicazione riducendo la latenza per gli utenti che accedono all'applicazione, ma garantisce anche la conformità alle normative sulla residenza dei dati che richiedono che i dati siano memorizzati all'interno di specifiche posizioni geografiche. Avere un'infrastruttura locale in ciascuna regione consente alla multinazionale di servire efficacemente la propria base utenti rispettando i requisiti legali.",
        "Other Options": [
            "Distribuire l'applicazione in una singola regione AWS con istanze ad alta capacità creerebbe un punto di guasto centralizzato e aumenterebbe la latenza per gli utenti situati lontano da quella regione. Questo approccio non affronta le normative sulla residenza dei dati, che potrebbero richiedere che i dati siano memorizzati in specifiche posizioni geografiche.",
            "Utilizzare una rete di distribuzione dei contenuti (CDN) per memorizzare i dati in altre regioni può migliorare la velocità di accesso per i contenuti statici, ma non risolve il problema della residenza dei dati e dei requisiti di elaborazione. L'elaborazione e la memorizzazione dei dati dinamici devono comunque avvenire nelle regioni appropriate per rispettare le normative.",
            "Utilizzare le zone di disponibilità all'interno di una singola regione AWS fornisce ridondanza e alta disponibilità, ma non affronta la necessità di distribuzione geografica. Questa opzione comporterebbe comunque un aumento della latenza per gli utenti situati lontano da quella singola regione e non soddisferebbe i requisiti di residenza dei dati."
        ]
    },
    {
        "Question Number": "25",
        "Situation": "Un'organizzazione sanitaria sta cercando una soluzione di backup completa per i dati sensibili dei pazienti memorizzati in più servizi AWS, tra cui istanze Amazon EC2, database RDS e sistemi di file EFS. Richiedono una soluzione che possa gestire i backup attraverso più account e regioni AWS, garantire l'integrità dei dati con la conformità WORM (write-once, read-many) per prevenire modifiche accidentali e offrire il ripristino a un punto nel tempo per soddisfare le esigenze normative e operative per la protezione dei dati critici.",
        "Question": "Quale configurazione del servizio AWS soddisferebbe meglio questi requisiti?",
        "Options": {
            "1": "Impostare snapshot manuali per ciascuna risorsa e abilitare la replica tra regioni per una maggiore ridondanza",
            "2": "Utilizzare AWS Backup con Piani di Backup, Vault Lock per la conformità WORM e Ripristino a Punto nel Tempo (PITR) per backup e recuperi affidabili",
            "3": "Memorizzare i backup in Amazon S3 con versioning e replica abilitati per garantire l'integrità dei dati e la disponibilità tra regioni",
            "4": "Abilitare AWS CloudTrail per il logging e creare procedure di recupero manuali basate sui dati di log"
        },
        "Correct Answer": "Utilizzare AWS Backup con Piani di Backup, Vault Lock per la conformità WORM e Ripristino a Punto nel Tempo (PITR) per backup e recuperi affidabili",
        "Explanation": "AWS Backup è specificamente progettato per centralizzare e automatizzare il backup delle risorse AWS attraverso più account e regioni. Consente agli utenti di creare piani di backup che definiscono la frequenza e le politiche di conservazione dei backup. Inoltre, AWS Backup supporta Vault Lock, che fornisce conformità WORM per prevenire modifiche accidentali ai dati di backup, garantendo l'integrità dei dati. La funzionalità di Ripristino a Punto nel Tempo (PITR) consente di ripristinare i dati a un punto specifico nel tempo, fondamentale per soddisfare le esigenze normative e operative per la protezione dei dati critici.",
        "Other Options": [
            "Impostare snapshot manuali per ciascuna risorsa e abilitare la replica tra regioni può fornire un certo livello di ridondanza, ma manca di automazione e gestione centralizzata. Questo approccio è laborioso e non garantisce la conformità WORM o il ripristino a punto nel tempo, rendendolo meno adatto alle esigenze di backup complete dell'organizzazione.",
            "Memorizzare i backup in Amazon S3 con versioning e replica abilitati può aiutare con l'integrità dei dati e la disponibilità, ma non fornisce le necessarie funzionalità di gestione per i backup attraverso più servizi o account AWS. Inoltre, non offre intrinsecamente conformità WORM o ripristino a punto nel tempo, che sono critici per i dati sensibili dei pazienti.",
            "Abilitare AWS CloudTrail per il logging e creare procedure di recupero manuali basate sui dati di log non è una soluzione di backup. CloudTrail è principalmente per l'audit e il monitoraggio delle chiamate API, e mentre può aiutare a comprendere le modifiche apportate alle risorse, non fornisce un meccanismo per il backup o il recupero dei dati, né soddisfa i requisiti per la conformità WORM o il ripristino a punto nel tempo."
        ]
    },
    {
        "Question Number": "26",
        "Situation": "Un'azienda tecnologica sta configurando un gruppo di Auto Scaling per le proprie istanze EC2. Mira a implementare una configurazione che consenta aggiornamenti senza la necessità di ricreare l'intera infrastruttura ogni volta che è necessario un cambiamento.",
        "Question": "Quale opzione dovrebbe selezionare l'azienda per facilitare gli aggiornamenti di configurazione in modo efficiente, e qual è la giustificazione per questa scelta?",
        "Options": {
            "1": "Utilizzare le Launch Configurations, poiché supportano il versioning e consentono aggiornamenti senza la necessità di ricreare.",
            "2": "Impiega le Launch Templates, in quanto offrono capacità di versioning, consentendo aggiornamenti di configurazione senza creare nuovi template.",
            "3": "Scegliere le Launch Configurations per la loro facilità di gestione e le caratteristiche di versioning intrinseche.",
            "4": "Optare per le Launch Templates, che consentono aggiornamenti in tempo reale direttamente all'interno del gruppo di Auto Scaling senza richiedere il controllo delle versioni."
        },
        "Correct Answer": "Impiega le Launch Templates, in quanto offrono capacità di versioning, consentendo aggiornamenti di configurazione senza creare nuovi template.",
        "Explanation": "Le Launch Templates sono la scelta preferita per configurare i gruppi di Auto Scaling perché supportano il versioning, il che consente agli utenti di creare più versioni di un template. Ciò significa che quando sono necessari cambiamenti di configurazione, l'azienda può semplicemente creare una nuova versione del template esistente senza dover ricreare l'intera infrastruttura. Questa caratteristica semplifica il processo di aggiornamento delle configurazioni e migliora l'efficienza della gestione, rendendo più facile tornare a versioni precedenti se necessario.",
        "Other Options": [
            "Utilizzare le Launch Configurations, poiché supportano il versioning e consentono aggiornamenti senza la necessità di ricreare. (Errato perché le Launch Configurations non supportano il versioning; sono statiche e non possono essere aggiornate una volta create. Qualsiasi cambiamento richiede la creazione di una nuova Launch Configuration.)",
            "Scegliere le Launch Configurations per la loro facilità di gestione e le caratteristiche di versioning intrinseche. (Errato perché le Launch Configurations mancano di capacità di versioning, il che le rende meno flessibili per aggiornamenti di configurazione rispetto alle Launch Templates.)",
            "Optare per le Launch Templates, che consentono aggiornamenti in tempo reale direttamente all'interno del gruppo di Auto Scaling senza richiedere il controllo delle versioni. (Errato perché, sebbene le Launch Templates consentano il versioning, non consentono aggiornamenti in tempo reale direttamente all'interno del gruppo di Auto Scaling; gli aggiornamenti richiedono comunque la creazione di una nuova versione del template.)"
        ]
    },
    {
        "Question Number": "27",
        "Situation": "Un team di ricerca sta eseguendo simulazioni di modellazione scientifica altamente complesse che richiedono una potenza di CPU estremamente elevata e velocità di elaborazione rapide per generare risultati accurati rapidamente. Queste simulazioni sono intensive in termini di calcolo e includono attività come l'encoding multimediale, la dinamica dei fluidi computazionale e l'addestramento di modelli di machine learning. Il team non ha bisogno di un elevato supporto di memoria o GPU, poiché queste attività sono principalmente legate alla CPU.",
        "Question": "Quale categoria di istanze EC2 si adatterebbe meglio alle loro esigenze?",
        "Options": {
            "1": "General Purpose",
            "2": "Memory Optimized",
            "3": "Compute Optimized",
            "4": "Accelerated Computing"
        },
        "Correct Answer": "Compute Optimized",
        "Explanation": "La categoria di istanze EC2 Compute Optimized è specificamente progettata per attività intensive in termini di calcolo che richiedono elevate prestazioni della CPU. Poiché le simulazioni del team di ricerca sono legate alla CPU e non richiedono un elevato supporto di memoria o GPU, le istanze Compute Optimized forniranno la potenza di elaborazione e la velocità necessarie per gestire in modo efficiente attività come l'encoding multimediale, la dinamica dei fluidi computazionale e l'addestramento di modelli di machine learning. Queste istanze sono ideali per carichi di lavoro che richiedono un'elevata capacità di calcolo e possono ridurre significativamente il tempo necessario per generare risultati accurati.",
        "Other Options": [
            "Le istanze General Purpose forniscono un equilibrio tra risorse di calcolo, memoria e rete, rendendole adatte a una varietà di carichi di lavoro, ma non specificamente ottimizzate per attività intensive in termini di calcolo. Potrebbero non fornire le elevate prestazioni della CPU richieste per le simulazioni descritte.",
            "Le istanze Memory Optimized sono progettate per carichi di lavoro che richiedono un'elevata capacità di memoria e throughput, come database in-memory e analisi di big data in tempo reale. Poiché il team di ricerca non ha bisogno di un elevato supporto di memoria, questa categoria non è adatta per le loro simulazioni intensive in termini di calcolo.",
            "Le istanze Accelerated Computing sono progettate per carichi di lavoro che beneficiano di acceleratori hardware, come GPU o FPGA. Queste istanze sono ideali per attività come l'inferenza di machine learning e l'elaborazione grafica, ma non sono necessarie per attività legate alla CPU, rendendole meno appropriate per le esigenze del team."
        ]
    },
    {
        "Question Number": "28",
        "Situation": "Un'azienda di logistica deve elaborare dati dai veicoli di consegna in tempo reale per monitorare percorsi e condizioni del traffico. Vuole elaborare i dati il più vicino possibile alla fonte per ridurre la latenza e minimizzare la quantità di dati inviati al cloud.",
        "Question": "Quale strategia di calcolo distribuito soddisferebbe meglio queste esigenze?",
        "Options": {
            "1": "Eseguire tutta l'elaborazione dei dati su istanze Amazon EC2 nella regione AWS più vicina",
            "2": "Utilizzare l'elaborazione edge per gestire i dati localmente sui dispositivi",
            "3": "Inviare i dati ad AWS Lambda per l'elaborazione serverless",
            "4": "Utilizzare un rack AWS Outposts nel data center dell'azienda"
        },
        "Correct Answer": "Utilizzare l'elaborazione edge per gestire i dati localmente sui dispositivi",
        "Explanation": "L'elaborazione edge consente di elaborare i dati il più vicino possibile alla fonte, il che è cruciale per il monitoraggio in tempo reale dei veicoli di consegna. Gestendo i dati localmente sui dispositivi, l'azienda di logistica può ridurre significativamente la latenza, poiché i dati non devono viaggiare verso un server cloud distante per l'elaborazione. Questo approccio minimizza anche la quantità di dati inviati al cloud, allineandosi perfettamente con le esigenze dell'azienda in termini di efficienza e velocità nell'elaborazione dei dati.",
        "Other Options": [
            "Eseguire tutta l'elaborazione dei dati su istanze Amazon EC2 nella regione AWS più vicina introdurrebbe latenza a causa della distanza che i dati devono percorrere per raggiungere il cloud. Questa opzione non soddisfa il requisito per l'elaborazione in tempo reale tanto quanto l'elaborazione edge.",
            "Inviare i dati ad AWS Lambda per l'elaborazione serverless comporterebbe anche latenza poiché i dati devono essere trasmessi al cloud per l'elaborazione. Sebbene AWS Lambda sia efficiente per molti casi d'uso, non è ottimale per l'elaborazione in tempo reale dei dati generati dai veicoli di consegna che necessitano di analisi immediata.",
            "Utilizzare un rack AWS Outposts nel data center dell'azienda potrebbe fornire alcuni vantaggi dell'elaborazione locale, ma richiede comunque una configurazione fisica e potrebbe non essere così agile o conveniente come una vera elaborazione edge. Inoltre, potrebbe non essere così vicino alla fonte dei dati come i dispositivi edge, il che può portare a una maggiore latenza rispetto all'elaborazione direttamente sui dispositivi."
        ]
    },
    {
        "Question Number": "29",
        "Situation": "Un'azienda sta ospitando due applicazioni web, ognuna con un nome di dominio HTTPS unico. Deve ridurre il numero di bilanciatori di carico utilizzati, mantenendo comunque il supporto HTTPS per entrambe le applicazioni.",
        "Question": "Quale tipo di bilanciatore di carico AWS sarebbe più adatto a questo requisito, e perché?",
        "Options": {
            "1": "Classic Load Balancer (CLB), perché consente di consolidare più domini in un singolo bilanciatore di carico.",
            "2": "Application Load Balancer (ALB), perché supporta il routing basato su host con Server Name Indication (SNI), consentendo più domini HTTPS su un singolo bilanciatore di carico.",
            "3": "Network Load Balancer (NLB), perché fornisce routing di livello 4 e può gestire più domini HTTPS.",
            "4": "Elastic Load Balancer (ELB) con sessioni sticky, poiché consente più gruppi di destinazione sotto lo stesso bilanciatore di carico."
        },
        "Correct Answer": "Application Load Balancer (ALB), perché supporta il routing basato su host con Server Name Indication (SNI), consentendo più domini HTTPS su un singolo bilanciatore di carico.",
        "Explanation": "L'Application Load Balancer (ALB) è specificamente progettato per gestire il traffico HTTP e HTTPS e supporta funzionalità di routing avanzate, incluso il routing basato su host. Ciò significa che può instradare le richieste a diversi gruppi di destinazione in base al nome host nella richiesta, il che è essenziale per ospitare più applicazioni web con nomi di dominio HTTPS unici. Inoltre, l'ALB supporta il Server Name Indication (SNI), che consente di servire più certificati SSL su un singolo indirizzo IP, abilitando connessioni sicure per ciascun dominio senza la necessità di bilanciatori di carico separati.",
        "Other Options": [
            "Il Classic Load Balancer (CLB) non supporta il routing basato su host o SNI, rendendolo meno adatto a gestire più domini HTTPS in modo efficiente. È principalmente progettato per il bilanciamento del carico di base e manca delle funzionalità avanzate necessarie per questo scenario.",
            "Il Network Load Balancer (NLB) opera a livello 4 ed è ottimizzato per gestire il traffico TCP. Sebbene possa gestire più domini, non fornisce le funzionalità necessarie per la terminazione SSL o il routing basato su host, che sono cruciali per gestire efficacemente il traffico HTTPS.",
            "L'Elastic Load Balancer (ELB) è un termine generale che comprende sia l'ALB che l'NLB. Sebbene le sessioni sticky possano essere configurate, non affrontano il requisito di supportare più domini HTTPS su un singolo bilanciatore di carico. L'ALB è il tipo specifico che soddisfa le esigenze di questo scenario."
        ]
    },
    {
        "Question Number": "30",
        "Situation": "Un'azienda sta pianificando di migrare le proprie applicazioni on-premises su AWS. Queste applicazioni si basano fortemente su Active Directory per l'autenticazione degli utenti e la gestione dei gruppi. Il team IT desidera una soluzione gestita su AWS che supporti fino a 3.000 utenti, si integri con Amazon Workspaces e non richieda integrazioni complesse on-premises. Inoltre, hanno bisogno di una soluzione che possa supportare ambienti Windows con lo stesso nome utente e password per la gestione centralizzata delle risorse.",
        "Question": "Quale opzione del servizio Directory AWS soddisferebbe meglio questi requisiti?",
        "Options": {
            "1": "Simple AD con un'istanza Small per la gestione del directory standalone",
            "2": "AWS Managed Microsoft AD con distribuzione multi-AZ",
            "3": "AWS SSO (Single Sign-On) per l'accesso cross-account",
            "4": "Amazon Cognito per la gestione dei pool utenti"
        },
        "Correct Answer": "AWS Managed Microsoft AD con distribuzione multi-AZ",
        "Explanation": "AWS Managed Microsoft AD è progettato per fornire un Active Directory completamente gestito nel cloud AWS. Supporta ambienti Windows e consente un'integrazione senza soluzione di continuità con applicazioni che si basano su Active Directory per l'autenticazione e la gestione dei gruppi. Può supportare fino a 50.000 utenti, il che supera il requisito di 3.000 utenti. Inoltre, si integra bene con Amazon Workspaces, consentendo agli utenti di avere lo stesso nome utente e password per la gestione centralizzata, soddisfacendo le esigenze dell'azienda senza richiedere integrazioni complesse on-premises. La distribuzione multi-AZ garantisce alta disponibilità e resilienza.",
        "Other Options": [
            "Simple AD con un'istanza Small è un servizio directory di base che supporta solo un insieme limitato di funzionalità di Active Directory e non è adatto per applicazioni che richiedono capacità complete di Active Directory. Non supporta nemmeno lo stesso livello di integrazione con Amazon Workspaces come AWS Managed Microsoft AD.",
            "AWS SSO (Single Sign-On) è principalmente progettato per gestire l'accesso a più account e applicazioni AWS, ma non fornisce le funzionalità complete di Active Directory necessarie per l'autenticazione degli utenti e la gestione dei gruppi in un ambiente Windows. Non è un sostituto diretto di Active Directory.",
            "Amazon Cognito è focalizzato sull'autenticazione e gestione degli utenti per applicazioni web e mobili, ma non fornisce le capacità di Active Directory richieste per le applicazioni dell'azienda. È più adatto per pool utenti e identità federate piuttosto che per gestire ambienti Windows con integrazione Active Directory."
        ]
    },
    {
        "Question Number": "31",
        "Situation": "Un'azienda sta distribuendo un'applicazione web su più istanze Amazon EC2 in diverse Availability Zone. L'applicazione ha bisogno di un file system condiviso per memorizzare e accedere ai contenuti generati dagli utenti. L'azienda desidera anche la flessibilità di collegare il proprio data center on-premises allo storage condiviso in AWS.",
        "Question": "Quale soluzione AWS dovrebbe raccomandare l'architetto delle soluzioni per soddisfare questi requisiti?",
        "Options": {
            "1": "Amazon EBS con Multi-Attach tra le Availability Zone",
            "2": "Amazon EFS con mount targets in ciascuna Availability Zone e accesso tramite VPN o Direct Connect per la connettività on-premises",
            "3": "Amazon S3 con Transfer Acceleration per accesso cross-region",
            "4": "Amazon RDS con repliche di lettura in ciascuna Availability Zone"
        },
        "Correct Answer": "Amazon EFS con mount targets in ciascuna Availability Zone e accesso tramite VPN o Direct Connect per la connettività on-premises",
        "Explanation": "Amazon EFS (Elastic File System) è un servizio di storage file completamente gestito che può essere montato su più istanze EC2 in diverse Availability Zone, fornendo un file system condiviso per le applicazioni. Supporta i protocolli NFS (Network File System), rendendolo adatto per applicazioni che richiedono accesso condiviso ai file. Inoltre, EFS può essere accessibile dai data center on-premises tramite una VPN o AWS Direct Connect, soddisfacendo il requisito di connettività tra on-premises e storage AWS.",
        "Other Options": [
            "Amazon EBS (Elastic Block Store) con Multi-Attach consente a più istanze EC2 di collegarsi a un singolo volume EBS, ma è limitato a una singola Availability Zone. Questo non soddisfa il requisito di un file system condiviso tra più Availability Zone.",
            "Amazon S3 (Simple Storage Service) è un servizio di storage a oggetti e, sebbene possa memorizzare contenuti generati dagli utenti, non fornisce un'interfaccia di file system tradizionale che le applicazioni richiedono tipicamente per l'accesso condiviso. Transfer Acceleration serve a velocizzare upload e download, ma non affronta la necessità di un file system condiviso tra le istanze EC2.",
            "Amazon RDS (Relational Database Service) è un servizio di database gestito e, sebbene possa avere repliche di lettura in diverse Availability Zone per alta disponibilità, non è adatto per memorizzare contenuti generati dagli utenti in un formato di file system condiviso. RDS è progettato per dati strutturati e casi d'uso di database relazionali, non per lo storage di file."
        ]
    },
    {
        "Question Number": "32",
        "Situation": "Un'azienda media sta trasmettendo contenuti video a livello globale e ha bisogno di migliorare la velocità di consegna e ridurre la latenza per gli utenti in diverse regioni geografiche. L'azienda sta vedendo un'alta domanda durante le ore di punta e il buffering dei contenuti sta influenzando l'esperienza dell'utente. Hanno anche bisogno di ridurre il carico sui loro server di origine per prevenire l'esaurimento delle risorse.",
        "Question": "Quale servizio AWS dovrebbe utilizzare l'azienda per raggiungere questi obiettivi e quali vantaggi offre?",
        "Options": {
            "1": "Utilizzare Amazon CloudFront come CDN per memorizzare nella cache i contenuti in posizioni edge in tutto il mondo, riducendo la latenza e alleggerendo il traffico dai server di origine.",
            "2": "Utilizzare Amazon Route 53 con routing geolocalizzato per indirizzare gli utenti al bucket S3 più vicino, dove sono memorizzati i contenuti video.",
            "3": "Utilizzare Amazon S3 per lo storage e indirizzare gli utenti a una singola istanza EC2 in una regione per servire tutti i contenuti video.",
            "4": "Utilizzare AWS Direct Connect per stabilire connessioni di rete dedicate a tutti i clienti a livello globale per una consegna dei contenuti più veloce."
        },
        "Correct Answer": "Utilizzare Amazon CloudFront come CDN per memorizzare nella cache i contenuti in posizioni edge in tutto il mondo, riducendo la latenza e alleggerendo il traffico dai server di origine.",
        "Explanation": "Amazon CloudFront è una Content Delivery Network (CDN) che memorizza nella cache i contenuti in posizioni edge a livello globale. Utilizzando CloudFront, l'azienda media può consegnare contenuti video più vicino agli utenti, riducendo significativamente la latenza e migliorando la velocità di consegna. Questo meccanismo di caching alleggerisce anche il traffico dai server di origine, il che aiuta a prevenire l'esaurimento delle risorse durante i periodi di alta domanda. In generale, CloudFront migliora l'esperienza dell'utente minimizzando il buffering e garantendo un accesso più veloce ai contenuti.",
        "Other Options": [
            "Utilizzare Amazon Route 53 con routing geolocalizzato potrebbe aiutare a indirizzare gli utenti verso le risorse più vicine, ma non memorizza nella cache i contenuti né riduce efficacemente la latenza. Gestisce principalmente il routing DNS e non affronta i problemi di buffering o il carico sui server di origine.",
            "Utilizzare Amazon S3 per lo storage e indirizzare gli utenti a una singola istanza EC2 in una regione non sarebbe efficace per la consegna globale dei contenuti. Questo approccio potrebbe portare a un'alta latenza per gli utenti lontani dall'istanza EC2 e non allevierebbe il carico sui server di origine, risultando in potenziali problemi di prestazioni durante le ore di punta.",
            "AWS Direct Connect fornisce connessioni di rete dedicate ma non è progettato per la consegna dei contenuti. È più adatto per stabilire connessioni private tra data center on-premises e AWS, piuttosto che migliorare la velocità di consegna dei contenuti agli utenti finali in tutto il mondo."
        ]
    },
    {
        "Question Number": "33",
        "Situation": "Un'organizzazione desidera stabilire una connessione sicura tra il proprio data center on-premises e il proprio ambiente AWS. La connessione deve supportare alta disponibilità e un collegamento a bassa latenza per i dati critici delle applicazioni.",
        "Question": "Quale soluzione soddisfa meglio questi requisiti?",
        "Options": {
            "1": "Impostare una connessione VPN su Internet",
            "2": "Utilizzare AWS Direct Connect con una connessione ridondante",
            "3": "Configurare un Elastic Load Balancer per distribuire il traffico",
            "4": "Utilizzare una connessione di peering VPC"
        },
        "Correct Answer": "Utilizzare AWS Direct Connect con una connessione ridondante",
        "Explanation": "AWS Direct Connect fornisce una connessione di rete dedicata dal data center on-premises ad AWS, che è ideale per requisiti di alta disponibilità e bassa latenza. Utilizzando Direct Connect con una connessione ridondante, l'organizzazione può garantire che ci sia un collegamento di backup disponibile nel caso in cui il collegamento principale fallisca, mantenendo così alta disponibilità. Questa soluzione è specificamente progettata per la connettività a livello aziendale e può gestire i dati critici delle applicazioni in modo efficiente.",
        "Other Options": [
            "Impostare una connessione VPN su Internet può fornire una connessione sicura, ma tipicamente non garantisce bassa latenza o alta disponibilità rispetto a una connessione dedicata come AWS Direct Connect. Le connessioni VPN possono essere influenzate dal traffico Internet e possono introdurre variabilità nella latenza.",
            "Configurare un Elastic Load Balancer non è pertinente per stabilire una connessione diretta tra il data center on-premises e AWS. I load balancer vengono utilizzati per distribuire il traffico delle applicazioni in entrata tra più destinazioni, ma non facilitano la connessione sicura necessaria in questo scenario.",
            "Utilizzare una connessione di peering VPC è utile per collegare due VPC all'interno di AWS, ma non affronta il requisito di collegare un data center on-premises ad AWS. Il peering VPC non fornisce una connessione dedicata e a bassa latenza ed è quindi inadeguato per questo scenario."
        ]
    },
    {
        "Question Number": "34",
        "Situation": "Un'azienda deve concedere accesso temporaneo a un bucket S3 a appaltatori esterni. L'accesso deve scadere automaticamente dopo un periodo specificato e deve essere limitato a specifiche azioni.",
        "Question": "Quali soluzioni dovrebbe implementare l'azienda? (Scegli due.)",
        "Options": {
            "1": "Creare utenti IAM per ciascun appaltatore e allegare una policy di accesso S3",
            "2": "Utilizzare AWS IAM Identity Center (AWS Single Sign-On) con un ruolo di accesso temporaneo",
            "3": "Generare URL pre-firmati per gli oggetti S3 a cui gli appaltatori devono accedere",
            "4": "Allegare una policy del bucket con una condizione basata sul tempo per limitare l'accesso",
            "5": "Implementare credenziali di sicurezza temporanee utilizzando AWS Security Token Service (STS)"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Generare URL pre-firmati per gli oggetti S3 a cui gli appaltatori devono accedere",
            "Implementare credenziali di sicurezza temporanee utilizzando AWS Security Token Service (STS)"
        ],
        "Explanation": "Gli URL pre-firmati forniscono un modo per concedere accesso temporaneo a specifici oggetti S3. Vengono generati con un tempo di scadenza, dopo il quale non sono più validi. Questo si allinea con il requisito di avere accesso che scade automaticamente dopo un periodo specificato. AWS Security Token Service (STS) è un servizio web che consente di richiedere credenziali temporanee e con privilegi limitati per gli utenti AWS Identity and Access Management (IAM). È possibile specificare i permessi per queste credenziali di sicurezza temporanee, rendendo possibile limitare le azioni che gli appaltatori possono eseguire.",
        "Other Options": [
            "Creare utenti IAM per ciascun appaltatore e allegare una policy di accesso S3 non è una soluzione temporanea e non scade automaticamente. Ciò richiederebbe un intervento manuale per revocare l'accesso.",
            "Utilizzare AWS IAM Identity Center (AWS Single Sign-On) con un ruolo di accesso temporaneo potrebbe essere utilizzato per concedere accesso temporaneo, ma non limita intrinsecamente l'accesso a specifiche azioni o oggetti S3.",
            "Allegare una policy del bucket con una condizione basata sul tempo per limitare l'accesso non è una soluzione fattibile poiché AWS non supporta condizioni basate sul tempo nelle policy dei bucket."
        ]
    },
    {
        "Question Number": "35",
        "Situation": "Un'azienda sta progettando un'applicazione web e desidera implementare un'architettura multi-tier per separare le preoccupazioni e migliorare la scalabilità. Si aspetta di vedere carichi di lavoro fluttuanti in base alla domanda degli utenti e l'architettura deve scalare automaticamente in base ai modelli di traffico. L'azienda sta anche cercando di migliorare la sicurezza isolando i livelli per prevenire accessi non autorizzati.",
        "Question": "Quale delle seguenti descrizioni rappresenta meglio l'architettura che l'azienda dovrebbe implementare? (Scegli due.)",
        "Options": {
            "1": "Utilizzare un'istanza Amazon EC2 come livello web, Amazon RDS come livello database e un Application Load Balancer (ALB) per distribuire il traffico tra le istanze nel livello web.",
            "2": "Utilizzare funzioni AWS Lambda sia per il livello web che per il livello database per ridurre la gestione dell'infrastruttura e abilitare la scalabilità automatica.",
            "3": "Utilizzare Amazon S3 per lo storage, istanze Amazon EC2 per il calcolo e AWS Direct Connect per la comunicazione sicura tra i livelli.",
            "4": "Implementare un VPC con subnet pubbliche per il livello web e subnet private per i livelli applicazione e database, utilizzare gruppi di Auto Scaling per i livelli web e applicazione e distribuire un'istanza RDS nella subnet privata.",
            "5": "Utilizzare un'unica istanza EC2 sia per i livelli web che database e collegarli tramite un Virtual Private Cloud (VPC) per isolamento."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Utilizzare un'istanza Amazon EC2 come livello web, Amazon RDS come livello database e un Application Load Balancer (ALB) per distribuire il traffico tra le istanze nel livello web.",
            "Implementare un VPC con subnet pubbliche per il livello web e subnet private per i livelli applicazione e database, utilizzare gruppi di Auto Scaling per i livelli web e applicazione e distribuire un'istanza RDS nella subnet privata."
        ],
        "Explanation": "La prima risposta corretta utilizza Amazon EC2 per il livello web, che può gestire carichi di lavoro fluttuanti e può essere scalato automaticamente. Amazon RDS è utilizzato per il livello database, che fornisce una soluzione scalabile e sicura per la gestione dei database. L'Application Load Balancer distribuisce il traffico tra le istanze nel livello web, il che aiuta nella gestione dei carichi di lavoro fluttuanti. La seconda risposta corretta utilizza un VPC con subnet pubbliche per il livello web e subnet private per i livelli applicazione e database, che fornisce isolamento e migliora la sicurezza. I gruppi di Auto Scaling vengono utilizzati per i livelli web e applicazione, che possono gestire carichi di lavoro fluttuanti e possono essere scalati automaticamente. Un'istanza RDS è distribuita nella subnet privata, che fornisce una soluzione scalabile e sicura per la gestione dei database.",
        "Other Options": [
            "Utilizzare funzioni AWS Lambda sia per il livello web che per il livello database può effettivamente ridurre la gestione dell'infrastruttura e abilitare la scalabilità automatica. Tuttavia, potrebbe non fornire l'isolamento necessario tra i livelli per migliorare la sicurezza.",
            "Utilizzare Amazon S3 per lo storage, istanze Amazon EC2 per il calcolo e AWS Direct Connect per la comunicazione sicura tra i livelli può fornire un'architettura multi-tier. Tuttavia, non menziona alcun meccanismo per gestire carichi di lavoro fluttuanti o per scalare automaticamente in base ai modelli di traffico.",
            "Utilizzare un'unica istanza EC2 sia per i livelli web che database e collegarli tramite un Virtual Private Cloud (VPC) per isolamento non fornisce un'architettura multi-tier. Non menziona nemmeno alcun meccanismo per gestire carichi di lavoro fluttuanti o per scalare automaticamente in base ai modelli di traffico."
        ]
    },
    {
        "Question Number": "36",
        "Situation": "Un'applicazione sanitaria deve memorizzare in modo sicuro i registri dei pazienti. I registri devono essere accessibili frequentemente per aggiornamenti e devono mantenere la gerarchia dei file e i metadati. Il team dell'applicazione desidera ottimizzare i costi di archiviazione, ma richiede anche un accesso costante e a bassa latenza.",
        "Question": "Quale tipo di archiviazione soddisferebbe meglio questi requisiti?",
        "Options": {
            "1": "Object storage (Amazon S3)",
            "2": "File storage (Amazon EFS)",
            "3": "Block storage (Amazon EBS)",
            "4": "Cold storage (Amazon S3 Glacier)"
        },
        "Correct Answer": "File storage (Amazon EFS)",
        "Explanation": "Il file storage, come Amazon EFS (Elastic File System), è progettato per casi d'uso che richiedono una gerarchia di file e metadati, rendendolo ideale per memorizzare i registri dei pazienti. EFS fornisce accesso a bassa latenza e consente a più istanze di accedere agli stessi dati simultaneamente, il che è essenziale per le applicazioni che devono aggiornare frequentemente i registri dei pazienti. Inoltre, EFS può scalare automaticamente, ottimizzando i costi di archiviazione mantenendo le prestazioni.",
        "Other Options": [
            "L'object storage (Amazon S3) non è adatto per questo scenario perché è progettato per dati non strutturati e non mantiene una gerarchia di file né supporta le semantiche tradizionali dei file, necessarie per gestire efficacemente i registri dei pazienti.",
            "Il block storage (Amazon EBS) è tipicamente utilizzato per applicazioni che richiedono archiviazione ad alte prestazioni per database o macchine virtuali. Sebbene offra accesso a bassa latenza, non fornisce una gerarchia di file o una facile condivisione di file tra più istanze, che è un requisito per l'applicazione sanitaria.",
            "Il cold storage (Amazon S3 Glacier) è progettato per dati che vengono accessi raramente e non è adatto per applicazioni che richiedono aggiornamenti frequenti e accesso a bassa latenza. È utilizzato principalmente per l'archiviazione dei dati piuttosto che per la gestione attiva dei dati."
        ]
    },
    {
        "Question Number": "37",
        "Situation": "Un'azienda ha un bucket S3 contenente dati sensibili che devono essere accessibili da specifici ruoli IAM attraverso più account AWS. L'azienda desidera garantire che solo questi ruoli abbiano accesso, mantenendo la gestione semplice ed evitando la necessità di configurazioni complesse degli utenti IAM.",
        "Question": "Quali sono i modi più appropriati per implementare questo controllo degli accessi? (Scegli due.)",
        "Options": {
            "1": "Creare una policy IAM in ogni account che concede accesso al bucket S3 e allegarla ai ruoli richiesti.",
            "2": "Allegare una policy del bucket al bucket S3 che concede esplicitamente accesso ai ruoli IAM richiesti in ogni account.",
            "3": "Utilizzare AWS Secrets Manager per memorizzare e gestire le credenziali di accesso per ogni ruolo IAM che necessita di accesso al bucket.",
            "4": "Impostare endpoint VPC in ogni account per controllare l'accesso al bucket S3 in base alla configurazione della rete VPC.",
            "5": "Utilizzare Amazon S3 Access Points con policy che specificano i ruoli IAM consentiti attraverso più account."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Creare una policy IAM in ogni account che concede accesso al bucket S3 e allegarla ai ruoli richiesti.",
            "Allegare una policy del bucket al bucket S3 che concede esplicitamente accesso ai ruoli IAM richiesti in ogni account."
        ],
        "Explanation": "Creare una policy IAM in ogni account che concede accesso al bucket S3 e allegarla ai ruoli richiesti è una risposta corretta perché le policy IAM sono un modo per gestire i permessi per più account AWS. Questo approccio consente all'azienda di specificare quali ruoli in ogni account hanno accesso al bucket S3. Allegare una policy del bucket al bucket S3 che concede esplicitamente accesso ai ruoli IAM richiesti in ogni account è anch'essa corretta. Una policy del bucket si applica a tutti gli oggetti in quel bucket e può essere utilizzata per concedere accesso cross-account al bucket S3, che è ciò che l'azienda desidera.",
        "Other Options": [
            "Utilizzare AWS Secrets Manager per memorizzare e gestire le credenziali di accesso per ogni ruolo IAM che necessita di accesso al bucket non è la scelta migliore perché aggiungerebbe complessità non necessaria alla gestione delle credenziali di accesso. L'azienda desidera evitare configurazioni complesse degli utenti IAM, e utilizzare Secrets Manager non semplificherebbe la gestione dell'accesso al bucket S3.",
            "Impostare endpoint VPC in ogni account per controllare l'accesso al bucket S3 in base alla configurazione della rete VPC non è la scelta migliore perché non controllerebbe direttamente quali ruoli IAM hanno accesso al bucket S3. Gli endpoint VPC vengono utilizzati per connettere privatamente la tua VPC ai servizi AWS supportati, non per gestire l'accesso ai bucket S3 a livello di ruolo IAM.",
            "Utilizzare Amazon S3 Access Points con policy che specificano i ruoli IAM consentiti attraverso più account non è la scelta migliore perché gli S3 Access Points vengono utilizzati per semplificare la gestione dell'accesso ai dati su larga scala per applicazioni che utilizzano set di dati condivisi. Non forniscono un modo per gestire l'accesso ai bucket S3 a livello di ruolo IAM attraverso più account."
        ]
    },
    {
        "Question Number": "38",
        "Situation": "Un'azienda desidera progettare un'applicazione web altamente disponibile che possa resistere a guasti infrastrutturali all'interno di una regione e fornire accesso a bassa latenza agli utenti in diverse località.",
        "Question": "Quale servizio AWS dovrebbe utilizzare l'azienda per gestire la distribuzione del traffico attraverso più Availability Zone, e quale vantaggio offre?",
        "Options": {
            "1": "Amazon Route 53",
            "2": "AWS Direct Connect",
            "3": "Amazon S3",
            "4": "Amazon DynamoDB"
        },
        "Correct Answer": "Amazon Route 53",
        "Explanation": "Amazon Route 53 è un servizio web DNS scalabile che fornisce registrazione di nomi di dominio altamente affidabile e conveniente, instradamento DNS e controllo della salute delle risorse. Può gestire la distribuzione del traffico attraverso più Availability Zone instradando le richieste degli utenti al punto di accesso sano più vicino, garantendo accesso a bassa latenza e alta disponibilità. Questo lo rende una scelta ideale per applicazioni che devono resistere a guasti infrastrutturali e mantenere prestazioni in diverse località geografiche.",
        "Other Options": [
            "AWS Direct Connect è un servizio cloud che fornisce una connessione di rete dedicata dai tuoi locali ad AWS. Sebbene possa migliorare le prestazioni della rete, non gestisce la distribuzione del traffico attraverso le Availability Zone.",
            "Amazon S3 (Simple Storage Service) è un servizio di archiviazione a oggetti che fornisce archiviazione altamente scalabile per i dati. Non gestisce la distribuzione del traffico o l'instradamento per le applicazioni web.",
            "Amazon DynamoDB è un servizio di database NoSQL completamente gestito che fornisce prestazioni rapide e prevedibili con scalabilità senza soluzione di continuità. Non è progettato per la distribuzione del traffico o per gestire le richieste degli utenti attraverso più Availability Zone."
        ]
    },
    {
        "Question Number": "39",
        "Situation": "Un'azienda desidera integrare in modo sicuro la propria funzione AWS Lambda con DynamoDB e S3. Deve garantire che la funzione Lambda possa eseguire solo azioni specifiche su questi servizi, limitando anche quali altri servizi e account AWS possono invocare la funzione.",
        "Question": "Quale delle seguenti strategie dovrebbe adottare per raggiungere questo obiettivo?",
        "Options": {
            "1": "Allegare una policy inline alla funzione Lambda che specifica le azioni consentite su DynamoDB e S3, e applicare una policy di risorsa che limita quali servizi e account possono invocare la funzione Lambda.",
            "2": "Utilizzare un ruolo di esecuzione Lambda che concede permessi per le azioni necessarie su DynamoDB e S3, e aggiungere una policy di risorsa Lambda per controllare i permessi di invocazione.",
            "3": "Allegare una policy IAM gestita alla funzione Lambda per accedere a DynamoDB e S3, e configurare un confine di permessi Lambda per limitare l'invocazione.",
            "4": "Creare un ruolo collegato al servizio per la funzione Lambda per accedere a DynamoDB e S3 e utilizzare una policy del bucket S3 per limitare l'invocazione."
        },
        "Correct Answer": "Utilizzare un ruolo di esecuzione Lambda che concede permessi per le azioni necessarie su DynamoDB e S3, e aggiungere una policy di risorsa Lambda per controllare i permessi di invocazione.",
        "Explanation": "Utilizzare un ruolo di esecuzione Lambda è la prassi migliore per concedere permessi alle funzioni AWS Lambda. Questo ruolo consente alla funzione di eseguire azioni specifiche su DynamoDB e S3, garantendo che vengano concessi solo i permessi necessari. Inoltre, una policy di risorsa Lambda può essere applicata per controllare quali servizi e account AWS possono invocare la funzione Lambda, fornendo un modo sicuro e flessibile per gestire l'accesso.",
        "Other Options": [
            "Allegare una policy inline alla funzione Lambda non è raccomandato perché le policy inline sono legate a una risorsa specifica e possono diventare difficili da gestire. Un ruolo di esecuzione Lambda è un approccio più scalabile e gestibile. Sebbene una policy di risorsa sia importante, il ruolo di esecuzione è il metodo principale per concedere permessi per accedere ad altri servizi AWS.",
            "Allegare una policy IAM gestita alla funzione Lambda non è il miglior approccio perché le policy gestite sono più ampie e potrebbero concedere più permessi del necessario. Inoltre, mentre un confine di permessi può aiutare a limitare i permessi, non è il metodo principale per controllare i permessi di invocazione, che è meglio gestito da una policy di risorsa.",
            "Creare un ruolo collegato al servizio per la funzione Lambda non è applicabile in questo caso, poiché i ruoli collegati al servizio sono ruoli predefiniti che i servizi AWS utilizzano per eseguire azioni per tuo conto. Non forniscono la granularità necessaria per controllare l'accesso a DynamoDB e S3. Anche una policy del bucket S3 non è adatta per controllare i permessi di invocazione di Lambda, poiché è specifica per S3 e non si applica alle funzioni Lambda."
        ]
    },
    {
        "Question Number": "40",
        "Situation": "Una piattaforma di trading finanziario globale deve minimizzare la latenza per gli utenti in diverse parti del mondo. La piattaforma richiede trasferimenti di dati coerenti e ad alta velocità con il minor numero possibile di salti per ridurre il rischio di ritardi o perdita di pacchetti. Inoltre, deve supportare il traffico TCP e UDP per varie applicazioni in tempo reale.",
        "Question": "Quale servizio AWS soddisferebbe meglio questi requisiti?",
        "Options": {
            "1": "Amazon CloudFront con caching edge",
            "2": "AWS Direct Connect per connessioni dedicate",
            "3": "AWS Global Accelerator con indirizzi IP Anycast",
            "4": "Amazon Route 53 con instradamento basato sulla latenza"
        },
        "Correct Answer": "AWS Global Accelerator con indirizzi IP Anycast",
        "Explanation": "AWS Global Accelerator è progettato specificamente per migliorare la disponibilità e le prestazioni delle applicazioni con utenti distribuiti a livello globale. Utilizza indirizzi IP Anycast per instradare il traffico degli utenti al punto di accesso AWS più vicino, minimizzando la latenza e fornendo un percorso coerente per il trasferimento dei dati. Questo servizio supporta sia il traffico TCP che UDP, rendendolo ideale per applicazioni in tempo reale che richiedono bassa latenza e trasferimenti di dati ad alta velocità. Inoltre, riduce il numero di salti tra l'utente e l'applicazione, contribuendo a minimizzare ritardi e perdita di pacchetti.",
        "Other Options": [
            "Amazon CloudFront con caching edge è principalmente una rete di distribuzione dei contenuti (CDN) che memorizza nella cache i contenuti presso le località edge per ridurre la latenza nella consegna di contenuti statici. Sebbene possa migliorare le prestazioni per alcuni tipi di applicazioni, non è ottimizzato per applicazioni in tempo reale che richiedono trasferimenti di dati coerenti e ad alta velocità e supporto sia per il traffico TCP che UDP.",
            "AWS Direct Connect fornisce connessioni di rete dedicate dai tuoi locali ad AWS, che possono ridurre la latenza per il trasferimento dei dati. Tuttavia, è più adatto per architetture cloud ibride e non fornisce intrinsecamente instradamento globale o supporto per il traffico TCP e UDP attraverso più regioni, rendendolo meno ideale per una piattaforma di trading finanziario globale.",
            "Amazon Route 53 con instradamento basato sulla latenza è un servizio DNS che dirige le richieste degli utenti alla regione AWS più vicina in base alla latenza. Sebbene possa aiutare a migliorare le prestazioni, non fornisce lo stesso livello di trasferimento di dati coerente e ad alta velocità e salti minimi come AWS Global Accelerator, né supporta direttamente il traffico TCP e UDP nello stesso modo."
        ]
    },
    {
        "Question Number": "41",
        "Situation": "Un amministratore IAM sta configurando l'accesso per un team di sviluppatori che ha bisogno di accesso a lungo termine alle risorse AWS. Per ridurre il carico di gestione, l'amministratore desidera applicare le stesse autorizzazioni a più membri del team, garantendo che le politiche siano riutilizzabili e facilmente aggiornabili.",
        "Question": "Quale approccio dovrebbe adottare l'amministratore per implementare questi requisiti?",
        "Options": {
            "1": "Allegare politiche inline individuali a ciascun utente IAM con autorizzazioni specifiche.",
            "2": "Creare una politica gestita dal cliente e allegarla a un gruppo IAM, quindi aggiungere gli utenti al gruppo.",
            "3": "Utilizzare una politica gestita da AWS e allegarla direttamente a ciascun utente IAM.",
            "4": "Definire una politica delle risorse con le autorizzazioni necessarie e applicarla direttamente alle risorse."
        },
        "Correct Answer": "Creare una politica gestita dal cliente e allegarla a un gruppo IAM, quindi aggiungere gli utenti al gruppo.",
        "Explanation": "Creare una politica gestita dal cliente consente all'amministratore IAM di definire un insieme di autorizzazioni che possono essere riutilizzate tra più utenti. Allegando questa politica a un gruppo IAM, tutti gli utenti di quel gruppo ereditano le autorizzazioni definite nella politica. Questo approccio riduce il carico di gestione perché, se le autorizzazioni devono essere aggiornate, l'amministratore può semplicemente modificare la politica in un unico luogo anziché aggiornare ciascun utente individualmente. Questo metodo garantisce anche che le autorizzazioni siano coerenti tra tutti i membri del team.",
        "Other Options": [
            "Allegare politiche inline individuali a ciascun utente IAM crea una politica unica per ciascun utente, il che aumenta il carico di gestione e rende difficile mantenere autorizzazioni coerenti tra il team. Le politiche inline non sono riutilizzabili e devono essere aggiornate individualmente per ciascun utente.",
            "Utilizzare una politica gestita da AWS e allegarla direttamente a ciascun utente IAM può portare a sfide nella gestione delle autorizzazioni, poiché le politiche gestite da AWS sono predefinite e potrebbero non soddisfare le esigenze specifiche del team di sviluppatori. Inoltre, se sono necessarie modifiche, ciascun utente dovrebbe essere aggiornato individualmente, aumentando il carico di gestione.",
            "Definire una politica delle risorse con le autorizzazioni necessarie e applicarla direttamente alle risorse non è adatto per gestire le autorizzazioni degli utenti. Le politiche delle risorse sono destinate a controllare l'accesso a specifiche risorse AWS piuttosto che gestire le autorizzazioni degli utenti tra più utenti. Questo approccio non affronta il requisito di autorizzazioni riutilizzabili e facilmente aggiornabili per un team di utenti."
        ]
    },
    {
        "Question Number": "42",
        "Situation": "Un'azienda sta memorizzando dati aziendali critici in AWS e deve scegliere una soluzione di archiviazione che fornisca alta durabilità e replica attraverso più regioni per il recupero in caso di disastro.",
        "Question": "Quale opzione di archiviazione dovrebbe scegliere l'azienda per garantire durabilità e replica dei dati?",
        "Options": {
            "1": "Utilizzare Amazon EBS (Elastic Block Store) con snapshot per backup e replica, assicurando che i dati siano replicati in un'altra Availability Zone.",
            "2": "Utilizzare Amazon S3 con versioning abilitato e replica tra regioni per garantire la durabilità dei dati e la replica globale.",
            "3": "Utilizzare Amazon EFS (Elastic File System) per accesso condiviso, poiché fornisce replica automatica ma non garantisce la durabilità dei dati tra le regioni.",
            "4": "Utilizzare Amazon Glacier per archiviazione di archiviazione, poiché fornisce durabilità a basso costo ma non supporta la replica tra regioni."
        },
        "Correct Answer": "Utilizzare Amazon S3 con versioning abilitato e replica tra regioni per garantire la durabilità dei dati e la replica globale.",
        "Explanation": "Amazon S3 è progettato per alta durabilità e disponibilità, con un SLA di 99.999999999% (11 nove) di durabilità. Abilitando il versioning, l'azienda può mantenere più versioni di un oggetto, il che aiuta a recuperare da cancellazioni accidentali o sovrascritture. La replica tra regioni (CRR) consente all'azienda di replicare automaticamente i dati tra diverse regioni AWS, fornendo un ulteriore livello di recupero in caso di disastro e garantendo che i dati critici siano disponibili anche se una regione subisce un'interruzione. Questo rende S3 la scelta migliore per le esigenze dell'azienda in termini di durabilità e replica attraverso più regioni.",
        "Other Options": [
            "Utilizzare Amazon EBS con snapshot fornisce durabilità e la possibilità di creare backup, ma replica principalmente i dati all'interno della stessa Availability Zone o può essere copiato in un'altra regione manualmente. EBS non è progettato per la replica automatica tra regioni, rendendolo meno adatto per il recupero in caso di disastro attraverso più regioni.",
            "Amazon EFS fornisce un file system gestito che può essere accessibile da più istanze e offre un certo livello di ridondanza e disponibilità. Tuttavia, non replica automaticamente i dati tra le regioni, il che è un requisito critico per il recupero in caso di disastro in questo scenario.",
            "Amazon Glacier è progettato principalmente per l'archiviazione a lungo termine e fornisce durabilità a basso costo. Sebbene sia altamente durevole, non supporta la replica automatica tra regioni, rendendolo inadatto per le esigenze dell'azienda di accesso immediato e capacità di recupero in caso di disastro."
        ]
    },
    {
        "Question Number": "43",
        "Situation": "Un'azienda vuole garantire di avere una strategia di backup resiliente per il proprio database Amazon RDS per recuperare i dati in caso di guasto. Richiedono che i backup vengano creati automaticamente e conservati per un massimo di 35 giorni, con la possibilità di ripristinare a un punto specifico nel tempo se necessario.",
        "Question": "Quale configurazione dovrebbero utilizzare per soddisfare questi requisiti, e quali sono le caratteristiche chiave? (Scegli due.)",
        "Options": {
            "1": "Configurare backup automatici per conservare i dati per un massimo di 35 giorni, con backup incrementali dopo lo snapshot completo iniziale. I backup automatici consentono il ripristino a un punto nel tempo a qualsiasi intervallo di 5 minuti all'interno del periodo di conservazione.",
            "2": "Utilizzare snapshot manuali giornalieri e conservare ciascuno snapshot indefinitamente per garantire il recupero dei dati, poiché i backup automatici non supportano il ripristino a un punto nel tempo.",
            "3": "Impostare la replica tra regioni per i backup per garantire che siano resilienti attraverso più regioni, ma limitare la conservazione a 7 giorni per ridurre i costi.",
            "4": "Implementare un singolo backup completo una volta e abilitare snapshot automatici RDS ogni 5 minuti per soddisfare il requisito di ripristino a un punto nel tempo.",
            "5": "Abilitare il backup continuo su Amazon S3 con versioning abilitato, consentendo il ripristino a qualsiasi stato precedente entro 35 giorni."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Configurare backup automatici per conservare i dati per un massimo di 35 giorni, con backup incrementali dopo lo snapshot completo iniziale. I backup automatici consentono il ripristino a un punto nel tempo a qualsiasi intervallo di 5 minuti all'interno del periodo di conservazione.",
            "Abilitare il backup continuo su Amazon S3 con versioning abilitato, consentendo il ripristino a qualsiasi stato precedente entro 35 giorni."
        ],
        "Explanation": "I backup automatici in Amazon RDS sono una funzionalità che crea automaticamente un backup del database, con la possibilità di conservare questi backup per un massimo di 35 giorni. Consentono anche il ripristino a un punto nel tempo, il che significa che puoi ripristinare il database a un momento specifico all'interno del periodo di conservazione. Questo soddisfa il requisito dell'azienda per la creazione automatica e la conservazione dei backup, nonché la possibilità di ripristinare a un punto specifico nel tempo. Il backup continuo su Amazon S3 con versioning abilitato soddisfa anch'esso questi requisiti, poiché consente il ripristino a qualsiasi stato precedente entro il periodo di conservazione.",
        "Other Options": [
            "Gli snapshot manuali non soddisfano il requisito per la creazione automatica di backup. Inoltre, sebbene possano essere conservati indefinitamente, non supportano il ripristino a un punto nel tempo, che è un requisito.",
            "La replica tra regioni per i backup fornisce resilienza, ma limitare la conservazione a 7 giorni non soddisfa il requisito di conservazione fino a 35 giorni.",
            "Implementare un singolo backup completo e abilitare snapshot automatici RDS ogni 5 minuti non soddisfa il requisito di conservazione fino a 35 giorni, poiché non specifica per quanto tempo questi snapshot sarebbero conservati."
        ]
    },
    {
        "Question Number": "44",
        "Situation": "Un'azienda di e-commerce gestisce un grande volume di dati di transazione e vuole garantire la durabilità e la disponibilità dei dati attraverso le regioni. Hanno bisogno di una strategia di backup e replica affidabile che consenta loro di ripristinare rapidamente i dati in caso di disastro o corruzione dei dati. Per soddisfare questi requisiti, l'azienda deve determinare i servizi e le configurazioni AWS più appropriati per implementare backup e replica tra regioni.",
        "Question": "Cosa dovrebbero considerare nell'impostare questa strategia di backup e replica?",
        "Options": {
            "1": "Utilizzare Amazon S3 con replica tra regioni abilitata per duplicare automaticamente i dati attraverso diverse regioni e impostare politiche di ciclo di vita per gestire i backup.",
            "2": "Fare affidamento su snapshot di Amazon EC2 e trasferire manualmente i file di backup tra le regioni per ciascuna istanza.",
            "3": "Abilitare AWS Shield Advanced per replicare e proteggere i dati in caso di disastro.",
            "4": "Memorizzare i backup solo in Amazon Glacier e recuperarli durante un'emergenza per costi di archiviazione inferiori."
        },
        "Correct Answer": "Utilizzare Amazon S3 con replica tra regioni abilitata per duplicare automaticamente i dati attraverso diverse regioni e impostare politiche di ciclo di vita per gestire i backup.",
        "Explanation": "Utilizzare Amazon S3 con replica tra regioni (CRR) è la strategia più efficace per garantire la durabilità e la disponibilità dei dati attraverso le regioni. CRR replica automaticamente gli oggetti nei bucket S3 in una diversa regione AWS, fornendo ridondanza e opzioni di recupero rapide in caso di perdita o corruzione dei dati. Inoltre, impostare politiche di ciclo di vita consente all'azienda di gestire la conservazione dei dati e di passare i dati più vecchi a classi di archiviazione a costo inferiore, ottimizzando i costi mentre si garantisce che i dati siano adeguatamente archiviati.",
        "Other Options": [
            "Fare affidamento su snapshot di Amazon EC2 e trasferire manualmente i file di backup tra le regioni non è ideale per un grande volume di dati di transazione. Gli snapshot sono legati a singole istanze EC2 e non forniscono lo stesso livello di automazione ed efficienza di S3 con CRR. Questo metodo aumenta anche il rischio di errore umano e può portare a backup incoerenti.",
            "Abilitare AWS Shield Advanced è principalmente focalizzato sulla protezione DDoS e non fornisce capacità di backup o replica. Sebbene sia importante per la sicurezza, non affronta la necessità dell'azienda di durabilità e disponibilità dei dati attraverso le regioni.",
            "Memorizzare i backup solo in Amazon Glacier non è adatto per esigenze di recupero rapido. Glacier è progettato per l'archiviazione a lungo termine e i tempi di recupero possono richiedere ore, il che non è ideale per scenari di recupero in caso di disastro in cui è necessario un accesso immediato ai dati. Questa opzione non fornisce nemmeno replica tra regioni."
        ]
    },
    {
        "Question Number": "45",
        "Situation": "Un'azienda sta configurando un Elastic Load Balancer (ELB) in AWS per distribuire il traffico in ingresso su più istanze EC2 in diverse Availability Zone (AZ). Vogliono che il bilanciatore di carico sia accessibile tramite internet, ma vogliono anche controllare l'accesso sia alle istanze pubbliche che a quelle private all'interno del loro VPC.",
        "Question": "Quale configurazione dovrebbero scegliere, e perché questa configurazione è vantaggiosa per gestire il traffico su larga scala?",
        "Options": {
            "1": "Configurare un ELB rivolto a internet con IP pubblici assegnati ai nodi, consentendo di instradare il traffico sia verso istanze EC2 pubbliche che private all'interno del VPC. Questa configurazione supporta la scalabilità tra le AZ e fornisce alta disponibilità.",
            "2": "Utilizzare un bilanciatore di carico interno con IP privati, limitando l'accesso al VPC e garantendo che solo il traffico interno venga bilanciato tra le istanze.",
            "3": "Impostare un ELB rivolto a internet con solo istanze EC2 private per limitare l'accesso pubblico mantenendo la scalabilità.",
            "4": "Configurare il bilanciatore di carico come un'installazione a nodo singolo in una AZ per ottimizzare l'utilizzo delle risorse e limitare la scalabilità tra più AZ."
        },
        "Correct Answer": "Configurare un ELB rivolto a internet con IP pubblici assegnati ai nodi, consentendo di instradare il traffico sia verso istanze EC2 pubbliche che private all'interno del VPC. Questa configurazione supporta la scalabilità tra le AZ e fornisce alta disponibilità.",
        "Explanation": "Un Elastic Load Balancer (ELB) rivolto a internet è progettato per gestire il traffico in ingresso da internet e può instradare le richieste sia verso istanze EC2 pubbliche che private. Assegnando IP pubblici all'ELB, può ricevere direttamente il traffico da fonti esterne mentre gestisce il traffico interno verso istanze private. Questa configurazione consente alta disponibilità e tolleranza ai guasti distribuendo il traffico su più istanze EC2 in diverse Availability Zone (AZ), garantendo che se una AZ va giù, le altre possano comunque gestire il carico. Questa configurazione è vantaggiosa per gestire il traffico su larga scala perché consente una scalabilità senza soluzione di continuità delle risorse in base alla domanda, mantenendo il controllo sull'accesso alle istanze.",
        "Other Options": [
            "Utilizzare un bilanciatore di carico interno con IP privati limita l'accesso solo al traffico interno all'interno del VPC, il che non soddisfa il requisito di essere accessibile tramite internet. Questa opzione non consentirebbe agli utenti esterni di accedere ai servizi ospitati sulle istanze EC2.",
            "Impostare un ELB rivolto a internet con solo istanze EC2 private non funzionerebbe perché le istanze private non possono essere direttamente accessibili da internet. Questa configurazione impedirebbe all'ELB di instradare il traffico in modo efficace, poiché non avrebbe istanze pubbliche per gestire le richieste in arrivo.",
            "Configurare il bilanciatore di carico come un'installazione a nodo singolo in una AZ limita i benefici del bilanciamento del carico, come alta disponibilità e tolleranza ai guasti. Questa configurazione non sfrutta i vantaggi di distribuire il traffico tra più AZ, che è cruciale per gestire il traffico su larga scala."
        ]
    },
    {
        "Question Number": "46",
        "Situation": "Una startup vuole monitorare da vicino i propri costi mensili di rete su AWS e ricevere avvisi se la spesa supera l'importo previsto. Vogliono anche analizzare i costi di trasferimento dati tra le regioni nel tempo.",
        "Question": "Quali strumenti di gestione dei costi AWS dovrebbero utilizzare per raggiungere questi obiettivi?",
        "Options": {
            "1": "AWS Cost and Usage Report e AWS Trusted Advisor",
            "2": "AWS Budgets e AWS Cost Explorer",
            "3": "AWS Trusted Advisor e AWS Budgets",
            "4": "AWS Support e AWS Cost Explorer"
        },
        "Correct Answer": "AWS Budgets e AWS Cost Explorer",
        "Explanation": "AWS Budgets consente agli utenti di impostare budget personalizzati per costi e utilizzo che possono attivare avvisi quando la spesa supera le soglie definite. Questo è essenziale per la startup per monitorare i propri costi mensili di rete e ricevere avvisi. AWS Cost Explorer fornisce approfondimenti dettagliati sui modelli di costo e utilizzo nel tempo, utili per analizzare i costi di trasferimento dati tra le regioni. Insieme, questi strumenti soddisfano efficacemente i requisiti della startup per il monitoraggio del budget e l'analisi dei costi.",
        "Other Options": [
            "AWS Cost and Usage Report fornisce informazioni dettagliate sulla fatturazione ma non offre funzionalità di avviso. AWS Trusted Advisor offre raccomandazioni sulle migliori pratiche ma non è specificamente progettato per il monitoraggio del budget o per un'analisi dettagliata dei costi.",
            "Sebbene AWS Budgets sia correttamente identificato per il monitoraggio del budget, AWS Cost Explorer è la scelta migliore per analizzare i costi nel tempo rispetto a AWS Trusted Advisor, che si concentra sull'ottimizzazione delle risorse piuttosto che sulla gestione dei costi.",
            "AWS Support è un servizio per assistenza tecnica e non fornisce funzionalità di gestione dei costi. AWS Cost Explorer è utile per analizzare i costi, ma senza AWS Budgets, la startup mancherebbe della funzionalità di avviso necessaria per il monitoraggio del budget."
        ]
    },
    {
        "Question Number": "47",
        "Situation": "Un'applicazione di e-commerce utilizza Amazon DynamoDB per memorizzare i dati del catalogo prodotti e deve gestire un alto volume di richieste di lettura durante le vendite lampo. Il team dell'applicazione vuole ridurre la latenza per le richieste di lettura, assicurando che gli utenti possano accedere ai dettagli dei prodotti quasi istantaneamente. Tuttavia, non richiedono letture fortemente consistenti.",
        "Question": "Quale soluzione soddisferebbe meglio questi requisiti?",
        "Options": {
            "1": "Abilitare il DynamoDB Auto Scaling per gestire il carico aumentato durante le vendite lampo",
            "2": "Integrare DynamoDB con Amazon ElastiCache per Redis per un accesso più veloce in lettura",
            "3": "Abilitare DynamoDB Accelerator (DAX) per fornire una cache in memoria per carichi di lavoro pesanti in lettura",
            "4": "Utilizzare tabelle globali DynamoDB per replicare il catalogo prodotti in più regioni"
        },
        "Correct Answer": "Abilitare DynamoDB Accelerator (DAX) per fornire una cache in memoria per carichi di lavoro pesanti in lettura",
        "Explanation": "DynamoDB Accelerator (DAX) è specificamente progettato per fornire una cache in memoria veloce per DynamoDB, riducendo significativamente la latenza in lettura. Poiché l'applicazione non richiede letture fortemente consistenti, DAX può servire letture di coerenza eventuale con latenza molto bassa, rendendolo ideale per gestire alti volumi di richieste di lettura durante le vendite lampo. DAX può gestire picchi di traffico e migliorare le prestazioni di carichi di lavoro pesanti in lettura, assicurando che gli utenti possano accedere ai dettagli dei prodotti quasi istantaneamente.",
        "Other Options": [
            "Abilitare il DynamoDB Auto Scaling aiuterebbe a gestire il carico aumentato regolando automaticamente la capacità di lettura e scrittura in base ai modelli di traffico. Tuttavia, non affronta direttamente il problema della latenza per le richieste di lettura, che è critico durante le vendite lampo.",
            "Integrare DynamoDB con Amazon ElastiCache per Redis potrebbe migliorare le prestazioni di lettura memorizzando i dati frequentemente accessibili. Tuttavia, aggiunge complessità all'architettura e potrebbe non essere integrato così strettamente con DynamoDB come DAX, che è specificamente ottimizzato per questo scopo.",
            "Utilizzare tabelle globali DynamoDB consentirebbe di replicare il catalogo prodotti in più regioni, migliorando la disponibilità e riducendo la latenza per gli utenti in diverse posizioni geografiche. Tuttavia, questa soluzione non affronta direttamente la necessità di ridurre la latenza durante l'alta domanda di lettura, poiché si concentra maggiormente sulla disponibilità e ridondanza dei dati."
        ]
    },
    {
        "Question Number": "48",
        "Situation": "Un'azienda di giochi online deve memorizzare i dati dei giocatori, inclusi profili, stati di gioco e oggetti di inventario. I dati devono essere altamente disponibili e durevoli, con la capacità di gestire milioni di richieste di lettura e scrittura al secondo. L'azienda prevede anche una rapida crescita e richiede una soluzione di archiviazione che possa scalare senza problemi per soddisfare la crescente domanda senza compromettere le prestazioni.",
        "Question": "Quale soluzione di archiviazione dovrebbe raccomandare l'architetto delle soluzioni per soddisfare questi requisiti?",
        "Options": {
            "1": "Amazon RDS per MySQL",
            "2": "Amazon DynamoDB",
            "3": "Amazon S3 Intelligent-Tiering",
            "4": "Amazon Redshift"
        },
        "Correct Answer": "Amazon DynamoDB",
        "Explanation": "Amazon DynamoDB è un servizio di database NoSQL completamente gestito che fornisce alta disponibilità e durevolezza. È progettato per gestire milioni di richieste di lettura e scrittura al secondo, rendendolo ideale per applicazioni con requisiti di elevato throughput, come i giochi online. DynamoDB scala automaticamente per soddisfare la crescente domanda senza compromettere le prestazioni, il che si allinea perfettamente con la necessità dell'azienda di una soluzione di archiviazione che possa crescere rapidamente man mano che la base di giocatori si espande. Inoltre, offre funzionalità come backup automatici e replicazione globale, garantendo durevolezza e disponibilità dei dati.",
        "Other Options": [
            "Amazon RDS per MySQL è un servizio di database relazionale adatto per dati strutturati e supporta query SQL. Tuttavia, potrebbe non gestire lo stesso livello di throughput di DynamoDB e richiede maggiore gestione per la scalabilità, rendendolo meno ideale per le esigenze di un'azienda di giochi online in rapida crescita e altamente disponibile.",
            "Amazon S3 Intelligent-Tiering è un servizio di archiviazione a oggetti progettato per memorizzare grandi quantità di dati non strutturati. Sebbene offra durevolezza e disponibilità, non è ottimizzato per operazioni di lettura e scrittura ad alta frequenza come quelle richieste per i dati dei giocatori in un contesto di gioco online, rendendolo inadatto per questo scenario.",
            "Amazon Redshift è un servizio di data warehousing ottimizzato per query analitiche e reporting. Non è progettato per carichi di lavoro transazionali ad alta velocità come quelli necessari per la gestione dei dati dei giocatori in tempo reale nei giochi, rendendolo quindi una scelta inappropriata per i requisiti delineati."
        ]
    },
    {
        "Question Number": "49",
        "Situation": "Un'azienda sta progettando un'architettura VPC sicura per le proprie applicazioni su AWS. Deve controllare sia il traffico in entrata che quello in uscita verso specifiche istanze all'interno di una subnet e applicare controlli di sicurezza aggiuntivi a livello di subnet.",
        "Question": "Quale delle seguenti affermazioni spiega correttamente l'uso e le differenze tra NACL e Security Groups per questo scopo? (Scegli due.)",
        "Options": {
            "1": "NACL operano a livello di istanza e forniscono filtraggio del traffico stateful, mentre i Security Groups operano a livello di subnet e offrono controlli stateless per ogni richiesta.",
            "2": "I Security Groups sono applicati a livello di istanza e forniscono controlli stateful, consentendo o negando indirizzi IP specifici, mentre i NACL sono applicati a livello di subnet e possono essere configurati per consentire o negare intervalli IP specifici in modo stateless.",
            "3": "I NACL si applicano solo al traffico in entrata a livello di subnet, mentre i Security Groups controllano sia il traffico in entrata che quello in uscita e sono stateful per impostazione predefinita.",
            "4": "I Security Groups e i NACL operano entrambi a livello di istanza, ma i NACL sono stateful, consentendo il filtraggio dinamico dei pacchetti tra più istanze.",
            "5": "I NACL forniscono uno strato di sicurezza aggiuntivo fungendo da firewall per controllare il traffico in entrata e in uscita da una o più subnet, indipendentemente dai Security Groups."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "I Security Groups sono applicati a livello di istanza e forniscono controlli stateful, consentendo o negando indirizzi IP specifici, mentre i NACL sono applicati a livello di subnet e possono essere configurati per consentire o negare intervalli IP specifici in modo stateless.",
            "I NACL forniscono uno strato di sicurezza aggiuntivo fungendo da firewall per controllare il traffico in entrata e in uscita da una o più subnet, indipendentemente dai Security Groups."
        ],
        "Explanation": "I Security Groups in AWS sono applicati a livello di istanza e forniscono controlli stateful, il che significa che tengono traccia dello stato delle connessioni di rete e consentono automaticamente il traffico di ritorno per le connessioni in uscita consentite. Possono essere configurati per consentire o negare indirizzi IP specifici. D'altra parte, le Network Access Control Lists (NACL) sono applicate a livello di subnet e forniscono controlli stateless, il che significa che valutano ogni pacchetto singolarmente senza considerare eventuali connessioni esistenti. Possono essere configurati per consentire o negare intervalli IP specifici. I NACL forniscono anche uno strato di sicurezza aggiuntivo fungendo da firewall per controllare il traffico in entrata e in uscita da una o più subnet, indipendentemente dai Security Groups.",
        "Other Options": [
            "I NACL operano a livello di subnet e forniscono filtraggio del traffico stateless, non a livello di istanza. Inoltre, i Security Groups operano a livello di istanza e offrono controlli stateful, non a livello di subnet.",
            "I NACL si applicano sia al traffico in entrata che a quello in uscita a livello di subnet, non solo al traffico in entrata.",
            "I Security Groups e i NACL non operano entrambi a livello di istanza. I Security Groups operano a livello di istanza, mentre i NACL operano a livello di subnet. Inoltre, i NACL sono stateless, non stateful."
        ]
    },
    {
        "Question Number": "50",
        "Situation": "Un'azienda media sta impostando un'architettura serverless per gestire l'afflusso di caricamenti video festivi dai propri utenti. Vuole che l'impostazione sia completamente gestita, si scaldi automaticamente per gestire traffico imprevedibile e consenta agli utenti di autenticarsi senza problemi. Il flusso di lavoro ideale dovrebbe coinvolgere caricamenti video, elaborazione per più formati e archiviazione, il tutto con un sovraccarico minimo.",
        "Question": "Data questa situazione, quale combinazione di servizi AWS supporterebbe meglio questa architettura e cosa la rende la scelta ottimale?",
        "Options": {
            "1": "Sfruttare Amazon Cognito per l'autenticazione degli utenti per scambiare in modo sicuro i token del provider di identità con credenziali temporanee AWS, consentendo caricamenti diretti in un bucket S3. Attivare una funzione AWS Lambda ad ogni caricamento per avviare il pipeline di elaborazione video.",
            "2": "Utilizzare una flotta di istanze Amazon EC2 per l'autenticazione degli utenti, i caricamenti video e la transcodifica, memorizzando i file video su volumi EBS collegati. Scalare manualmente le istanze per soddisfare i picchi di domanda.",
            "3": "Impostare Amazon S3 per l'archiviazione video, avviare una funzione AWS Lambda per ogni caricamento video per l'elaborazione e registrare i dettagli del lavoro di elaborazione in un database Amazon RDS per resilienza.",
            "4": "Autenticare gli utenti utilizzando ruoli IAM, memorizzare i video in DynamoDB e utilizzare istanze EC2 per gestire i compiti di elaborazione, con i video elaborati finali memorizzati nuovamente in S3 per il recupero."
        },
        "Correct Answer": "Sfruttare Amazon Cognito per l'autenticazione degli utenti per scambiare in modo sicuro i token del provider di identità con credenziali temporanee AWS, consentendo caricamenti diretti in un bucket S3. Attivare una funzione AWS Lambda ad ogni caricamento per avviare il pipeline di elaborazione video.",
        "Explanation": "Questa opzione è ottimale perché utilizza servizi completamente gestiti che si scalano automaticamente e richiedono un sovraccarico operativo minimo. Amazon Cognito fornisce un'autenticazione degli utenti senza soluzione di continuità, consentendo agli utenti di caricare video direttamente in un bucket S3, progettato per alta disponibilità e durevolezza. L'uso di AWS Lambda per attivare l'elaborazione video al caricamento garantisce che l'elaborazione possa scalare automaticamente con il numero di caricamenti, gestendo in modo efficiente il traffico imprevedibile. Questa architettura si allinea perfettamente con i requisiti di essere serverless e completamente gestita.",
        "Other Options": [
            "Utilizzare una flotta di istanze Amazon EC2 per l'autenticazione degli utenti, i caricamenti video e la transcodifica introduce un notevole sovraccarico di gestione e non fornisce scalabilità automatica. Le istanze EC2 richiedono intervento manuale per scalare, il che non è ideale per modelli di traffico imprevedibili, rendendo questa opzione meno adatta.",
            "Impostare Amazon S3 per l'archiviazione video e avviare una funzione AWS Lambda per ogni caricamento video per l'elaborazione è un buon approccio, ma registrare i dettagli del lavoro di elaborazione in un database Amazon RDS aggiunge complessità e sovraccarico di gestione non necessari. L'attenzione dovrebbe essere rivolta a minimizzare il sovraccarico, e utilizzare un database per questo scopo potrebbe non essere necessario in un'architettura serverless completamente gestita.",
            "Autenticare gli utenti utilizzando ruoli IAM non è adatto per l'autenticazione degli utenti in questo contesto, poiché i ruoli IAM sono tipicamente utilizzati per le autorizzazioni dei servizi AWS piuttosto che per l'autenticazione degli utenti. Memorizzare video in DynamoDB non è nemmeno ideale per grandi file video, poiché S3 è specificamente progettato per tali casi d'uso. Inoltre, utilizzare istanze EC2 per i compiti di elaborazione contraddice il requisito di un'architettura serverless."
        ]
    },
    {
        "Question Number": "51",
        "Situation": "Un'azienda sta utilizzando Amazon Elastic Block Store (EBS) per memorizzare dati collegati alle proprie istanze EC2 all'interno di una singola Availability Zone (AZ) nella regione us-east-1. Per migliorare la durabilità e la resilienza dei dati, l'azienda vuole assicurarsi che i propri dati siano al sicuro anche in caso di un guasto dell'AZ.",
        "Question": "Quale strategia fornirebbe la migliore resilienza per i loro dati EBS?",
        "Options": {
            "1": "Utilizzare snapshot EBS memorizzati in Amazon S3 e copiarli in una regione diversa per abilitare il disaster recovery interregionale.",
            "2": "Collegare volumi EBS a più istanze EC2 in diverse AZ all'interno della stessa regione per ridondanza.",
            "3": "Configurare i volumi EBS per replicarsi automaticamente in tutte le Availability Zone all'interno della regione.",
            "4": "Utilizzare S3 per la memorizzazione diretta dei dati invece di EBS, poiché offre una maggiore durabilità e disponibilità tra le AZ."
        },
        "Correct Answer": "Utilizzare snapshot EBS memorizzati in Amazon S3 e copiarli in una regione diversa per abilitare il disaster recovery interregionale.",
        "Explanation": "Utilizzare snapshot EBS memorizzati in Amazon S3 e copiarli in una regione diversa fornisce la migliore resilienza per i dati EBS perché garantisce che i dati siano non solo sottoposti a backup, ma anche memorizzati in una posizione geografica diversa. Questo protegge dalla perdita di dati a causa di un guasto dell'intera Availability Zone, poiché gli snapshot possono essere ripristinati in un'altra regione. Questa strategia sfrutta la durabilità di Amazon S3 e le capacità interregionali per migliorare le opzioni di disaster recovery.",
        "Other Options": [
            "Collegare volumi EBS a più istanze EC2 in diverse AZ all'interno della stessa regione non fornisce resilienza contro un guasto dell'AZ perché i volumi EBS possono essere collegati solo a un'istanza alla volta. Sebbene possa fornire un certo livello di ridondanza, non protegge dalla perdita dell'intera AZ.",
            "Configurare i volumi EBS per replicarsi automaticamente in tutte le Availability Zone all'interno della regione non è una funzionalità offerta da EBS. I volumi EBS sono legati a un'AZ specifica e, sebbene tu possa creare snapshot, non esiste una replicazione automatica tra le AZ. Pertanto, questa opzione non migliora la resilienza contro i guasti dell'AZ.",
            "Utilizzare S3 per la memorizzazione diretta dei dati invece di EBS offre una maggiore durabilità e disponibilità tra le AZ, ma potrebbe non essere adatto a tutti i casi d'uso, specialmente quelli che richiedono storage a blocchi. Inoltre, non affronta direttamente la necessità di resilienza dei dati EBS nel contesto delle istanze EC2, poiché implica un paradigma di storage diverso."
        ]
    },
    {
        "Question Number": "52",
        "Situation": "Un'azienda di servizi finanziari sta migrando il proprio data warehouse on-premises su AWS. Il data warehouse elabora grandi volumi di dati transazionali e richiede un elevato throughput per le operazioni ETL. L'azienda mira a ridurre i costi garantendo al contempo scalabilità e prestazioni.",
        "Question": "Quale servizio AWS dovrebbe raccomandare l'architetto delle soluzioni per la memorizzazione del data warehouse?",
        "Options": {
            "1": "Amazon RDS per PostgreSQL",
            "2": "Amazon Redshift",
            "3": "Amazon DynamoDB",
            "4": "Amazon Aurora"
        },
        "Correct Answer": "Amazon Redshift",
        "Explanation": "Amazon Redshift è un servizio di data warehouse completamente gestito, su scala petabyte, progettato specificamente per carichi di lavoro analitici. È ottimizzato per un elevato throughput e può gestire in modo efficiente grandi volumi di dati transazionali, rendendolo ideale per le operazioni ETL. Le capacità di archiviazione colonnare di Redshift e il processamento parallelo consentono prestazioni di query rapide e scalabilità, che si allineano con i requisiti dell'azienda per prestazioni e costi contenuti durante la migrazione del proprio data warehouse su AWS.",
        "Other Options": [
            "Amazon RDS per PostgreSQL è un servizio di database relazionale adatto per carichi di lavoro transazionali, ma non è ottimizzato per il data warehousing e l'analisi su larga scala come Redshift. Potrebbe non fornire lo stesso livello di prestazioni e scalabilità per le operazioni ETL su grandi dataset.",
            "Amazon DynamoDB è un servizio di database NoSQL progettato per alta disponibilità e accesso a bassa latenza a dati chiave-valore e documenti. Sebbene sia eccellente per alcuni tipi di applicazioni, non è adatto per le esigenze tradizionali di data warehousing, specialmente per query complesse e analisi su grandi dataset.",
            "Amazon Aurora è un servizio di database relazionale che offre alte prestazioni e disponibilità. Tuttavia, come RDS, non è specificamente progettato per il data warehousing e potrebbe non fornire lo stesso livello di prestazioni per query analitiche e operazioni ETL come Amazon Redshift."
        ]
    },
    {
        "Question Number": "53",
        "Situation": "Un'azienda di produzione media richiede storage ad alte prestazioni per il montaggio video, ma desidera mantenere bassi i costi. Hanno una combinazione di carichi di lavoro ad alte e basse prestazioni e devono scegliere i tipi di storage a blocchi appropriati.",
        "Question": "Quale combinazione di opzioni di storage a blocchi dovrebbe utilizzare l'azienda per ottimizzare i costi mantenendo i requisiti di prestazioni?",
        "Options": {
            "1": "Provisioned IOPS SSD (io2) per tutti i volumi",
            "2": "General Purpose SSD (gp3) per compiti ad alte prestazioni e Throughput Optimized HDD (st1) per compiti a bassa prestazione",
            "3": "Cold HDD (sc1) per tutti i volumi",
            "4": "Utilizzare Amazon S3 invece dello storage a blocchi per tutti i dati"
        },
        "Correct Answer": "General Purpose SSD (gp3) per compiti ad alte prestazioni e Throughput Optimized HDD (st1) per compiti a bassa prestazione",
        "Explanation": "Questa combinazione consente all'azienda di produzione media di bilanciare prestazioni e costi in modo efficace. General Purpose SSD (gp3) fornisce un buon equilibrio tra prezzo e prestazioni per carichi di lavoro ad alte prestazioni, come il montaggio video, dove la bassa latenza e l'elevato throughput sono essenziali. D'altra parte, Throughput Optimized HDD (st1) è più conveniente per compiti a bassa prestazione, come la memorizzazione di file video meno frequentemente accessibili o backup. Questo approccio ibrido ottimizza i costi mantenendo comunque i requisiti di prestazioni per entrambi i tipi di carichi di lavoro.",
        "Other Options": [
            "Provisioned IOPS SSD (io2) per tutti i volumi sarebbe inutilmente costoso per compiti a bassa prestazione, poiché è progettato per carichi di lavoro ad alta IOPS e non fornirebbe efficienza dei costi per compiti che non richiedono tali prestazioni.",
            "Cold HDD (sc1) per tutti i volumi non soddisferebbe i requisiti di prestazione per compiti ad alte prestazioni come il montaggio video, poiché sc1 è progettato per accessi poco frequenti e ha prestazioni molto inferiori rispetto alle opzioni SSD.",
            "Utilizzare Amazon S3 invece dello storage a blocchi per tutti i dati potrebbe non essere adatto per carichi di lavoro di montaggio video che richiedono bassa latenza e alto throughput, poiché S3 è storage a oggetti e non ottimizzato per l'accesso a livello di blocco necessario per applicazioni ad alte prestazioni."
        ]
    },
    {
        "Question Number": "54",
        "Situation": "Un'azienda desidera impostare un accesso sicuro per un team di sviluppatori che lavora a un progetto in un account AWS condiviso. Il team richiede un accesso flessibile a risorse AWS specifiche all'interno dell'account, e l'accesso deve essere revocabile su base per utente.",
        "Question": "Quale delle seguenti è l'approccio PIÙ sicuro e flessibile per concedere accesso a queste risorse?",
        "Options": {
            "1": "Creare utenti IAM per ogni sviluppatore con permessi e politiche specifiche",
            "2": "Creare un singolo utente IAM con chiavi di accesso condivise tra gli sviluppatori",
            "3": "Utilizzare AWS IAM Identity Center (AWS Single Sign-On) per assegnare ruoli a ciascun sviluppatore",
            "4": "Assegnare un ruolo IAM alle risorse condivise e concedere permessi a un gruppo IAM contenente gli sviluppatori"
        },
        "Correct Answer": "Utilizzare AWS IAM Identity Center (AWS Single Sign-On) per assegnare ruoli a ciascun sviluppatore",
        "Explanation": "Utilizzare AWS IAM Identity Center (AWS Single Sign-On) consente una gestione centralizzata dell'accesso degli utenti attraverso gli account e le applicazioni AWS. Fornisce un modo flessibile e sicuro per assegnare ruoli a singoli sviluppatori, consentendo loro di accedere solo alle risorse di cui hanno bisogno. Questo approccio consente anche una facile revoca dell'accesso su base per utente, essenziale per mantenere la sicurezza in un ambiente condiviso. Inoltre, IAM Identity Center supporta l'integrazione con fornitori di identità esistenti, migliorando la sicurezza e la gestione degli utenti.",
        "Other Options": [
            "Creare utenti IAM per ogni sviluppatore con permessi e politiche specifiche è un approccio valido, ma può diventare ingombrante da gestire man mano che il team cresce. Ogni utente dovrebbe essere gestito individualmente e revocare l'accesso richiederebbe di modificare i permessi di ciascun utente, il che è meno efficiente rispetto all'utilizzo di IAM Identity Center.",
            "Creare un singolo utente IAM con chiavi di accesso condivise tra gli sviluppatori è altamente insicuro. Questo approccio viola il principio del minimo privilegio e rende difficile tracciare le azioni degli utenti individuali. Se le chiavi di accesso vengono compromesse, l'accesso di tutti gli sviluppatori è a rischio e revocare l'accesso per un utente richiederebbe di cambiare le chiavi per tutti.",
            "Assegnare un ruolo IAM alle risorse condivise e concedere permessi a un gruppo IAM contenente gli sviluppatori è un approccio ragionevole, ma manca della flessibilità e della facilità di gestione fornite da AWS IAM Identity Center. Sebbene consenta un certo livello di controllo degli accessi, non fornisce lo stesso livello di gestione degli utenti individuali e capacità di revoca di IAM Identity Center."
        ]
    },
    {
        "Question Number": "55",
        "Situation": "Un'azienda di e-commerce multinazionale ha utenti in tutto il mondo che necessitano di un accesso rapido alle informazioni sui loro ordini. L'applicazione richiede la replicazione dei dati in più regioni per garantire alta disponibilità e bassa latenza per gli utenti in diversi continenti. Inoltre, il sistema deve gestire eventuali conflitti in modo elegante quando gli aggiornamenti avvengono simultaneamente in diverse regioni.",
        "Question": "Quale funzionalità di DynamoDB Global Tables soddisfa meglio questi requisiti?",
        "Options": {
            "1": "Replicazione multi-master con risoluzione dei conflitti \"l'ultimo scrittore vince\"",
            "2": "Replicazione single-master per garantire la coerenza dei dati",
            "3": "Coerenza globale forte per tutte le letture e scritture tra le regioni",
            "4": "Risoluzione dei conflitti FIFO (First-In-First-Out) rigorosa tra le regioni"
        },
        "Correct Answer": "Replicazione multi-master con 'l'ultimo scrittore vince' risoluzione dei conflitti",
        "Explanation": "DynamoDB Global Tables utilizza la replicazione multi-master, che consente aggiornamenti in più regioni simultaneamente. Questo è cruciale per un'azienda di e-commerce multinazionale che deve fornire accesso rapido alle informazioni sugli ordini in diversi continenti. La strategia di risoluzione dei conflitti 'l'ultimo scrittore vince' garantisce che quando gli aggiornamenti avvengono in diverse regioni contemporaneamente, l'aggiornamento più recente (basato su un timestamp) sia quello mantenuto, consentendo una gestione elegante dei potenziali conflitti. Questa funzionalità supporta alta disponibilità e bassa latenza, soddisfacendo efficacemente i requisiti dell'applicazione.",
        "Other Options": [
            "La replicazione single-master non soddisferebbe il requisito di alta disponibilità e bassa latenza tra più regioni, poiché limita gli aggiornamenti a una singola regione, portando potenzialmente a ritardi per gli utenti in altre regioni.",
            "La coerenza globale forte per tutte le letture e scritture tra le regioni non è supportata in DynamoDB Global Tables, poiché richiederebbe coordinamento che potrebbe introdurre latenza e ridurre la disponibilità, il che contraddice la necessità di accesso rapido e bassa latenza.",
            "La risoluzione dei conflitti FIFO (First-In-First-Out) rigorosa non è una funzionalità di DynamoDB Global Tables. Questo approccio non sarebbe adatto per un setup multi-regione in cui gli aggiornamenti possono avvenire simultaneamente, poiché potrebbe portare a ritardi e incoerenze nella disponibilità dei dati."
        ]
    },
    {
        "Question Number": "56",
        "Situation": "Un'azienda sta allestendo un nuovo ambiente AWS e ha bisogno di una rete privata e isolata all'interno di una specifica Regione AWS. Vogliono controllare l'intervallo degli indirizzi IP per questa rete e avere più subnet, ciascuna all'interno di una diversa Availability Zone (AZ) per garantire alta disponibilità. L'azienda vuole anche sapere se possono avere più VPC nella stessa regione e quali impostazioni predefinite vengono applicate se utilizzano il VPC predefinito.",
        "Question": "Quale approccio dovrebbe adottare l'azienda per configurare la propria rete secondo questi requisiti?",
        "Options": {
            "1": "Creare un VPC predefinito, che fornisce automaticamente subnet in ciascuna Availability Zone all'interno della regione. Il VPC predefinito ha un intervallo CIDR fisso di 172.31.0.0/16 e non possono essere creati ulteriori VPC personalizzati nella stessa regione.",
            "2": "Creare un VPC personalizzato, che consente all'azienda di specificare il proprio intervallo CIDR e creare più subnet in ciascuna Availability Zone. Il VPC predefinito sarà anche disponibile per impostazione predefinita e possono eliminarlo o ricrearlo se necessario.",
            "3": "Utilizzare il VPC predefinito fornito da AWS, che consente intervalli CIDR personalizzati e offre il pieno controllo sulle assegnazioni degli indirizzi IP delle subnet. Il VPC predefinito consente solo una subnet per Availability Zone.",
            "4": "Impostare un singolo VPC su più regioni, poiché i VPC sono globali per impostazione predefinita. Questa configurazione consente all'azienda di avere più Availability Zone in un singolo VPC attraverso diverse regioni, fornendo ridondanza e alta disponibilità."
        },
        "Correct Answer": "Creare un VPC personalizzato, che consente all'azienda di specificare il proprio intervallo CIDR e creare più subnet in ciascuna Availability Zone. Il VPC predefinito sarà anche disponibile per impostazione predefinita e possono eliminarlo o ricrearlo se necessario.",
        "Explanation": "Creare un VPC personalizzato consente all'azienda di definire il proprio intervallo di indirizzi IP (blocco CIDR) e creare più subnet attraverso diverse Availability Zones (AZ) per garantire alta disponibilità. Questa configurazione soddisfa il loro requisito di una rete privata e isolata con controllo sull'intervallo degli indirizzi IP. Inoltre, AWS consente di creare più VPC all'interno della stessa regione, e il VPC predefinito è disponibile per impostazione predefinita, il quale può essere eliminato o ricreato se necessario.",
        "Other Options": [
            "Creare un VPC predefinito non consente all'azienda di specificare il proprio intervallo CIDR, poiché ha un intervallo CIDR fisso di 172.31.0.0/16. Inoltre, più VPC personalizzati possono effettivamente essere creati nella stessa regione, quindi questa opzione è errata.",
            "Il VPC predefinito non consente intervalli CIDR personalizzati; ha un intervallo CIDR fisso. Inoltre, mentre il VPC predefinito fornisce subnet in ciascuna AZ, non consente il pieno controllo sulle assegnazioni degli indirizzi IP delle subnet come farebbe un VPC personalizzato. Questa opzione è quindi errata.",
            "I VPC non sono globali; sono regionali. Ogni VPC è confinato a una singola regione e, mentre un VPC può estendersi su più AZ all'interno di quella regione, non può estendersi su più regioni. Questa opzione è errata poiché rappresenta in modo errato il funzionamento dei VPC in AWS."
        ]
    },
    {
        "Question Number": "57",
        "Situation": "Stai configurando un sistema di distribuzione dei contenuti con Amazon CloudFront per servire contenuti sicuri da un bucket S3 e un Application Load Balancer (ALB). Per garantire comunicazioni criptate, decidi di configurare i certificati SSL.",
        "Question": "Considerando i requisiti SSL, quale delle seguenti è cruciale per abilitare connessioni HTTPS sicure tra il visualizzatore e la tua distribuzione CloudFront?",
        "Options": {
            "1": "Generare o importare un certificato pubblico valido in ACM (Amazon Certificate Manager) nella regione us-east-1, assicurandosi che corrisponda al nome DNS del tuo dominio.",
            "2": "Utilizzare certificati autofirmati sugli origini (S3 e ALB) per risparmiare costi, poiché CloudFront gestirà la terminazione SSL.",
            "3": "Assegnare un IP dedicato per il supporto SSL in ciascuna posizione Edge di CloudFront, poiché questo è obbligatorio per i browser moderni per stabilire connessioni HTTPS.",
            "4": "Abilitare SSL solo sulla distribuzione CloudFront e non sui server di origine, poiché CloudFront cripta automaticamente tutto il traffico con i visualizzatori."
        },
        "Correct Answer": "Generare o importare un certificato pubblico valido in ACM (Amazon Certificate Manager) nella regione us-east-1, assicurandosi che corrisponda al nome DNS del tuo dominio.",
        "Explanation": "Per abilitare connessioni HTTPS sicure tra il visualizzatore e la tua distribuzione CloudFront, è cruciale avere un certificato SSL valido. Amazon Certificate Manager (ACM) consente di generare o importare certificati SSL necessari per stabilire connessioni sicure. Il certificato deve essere nella regione us-east-1 perché CloudFront richiede che il certificato SSL sia emesso da questa regione per poter essere utilizzato con le distribuzioni. Inoltre, il certificato deve corrispondere al nome di dominio utilizzato nella distribuzione CloudFront per garantire una corretta validazione durante il handshake SSL.",
        "Other Options": [
            "Utilizzare certificati autofirmati sugli origini (S3 e ALB) non è raccomandato per ambienti di produzione poiché non sono fidati dai clienti e possono portare a avvisi di sicurezza. CloudFront non gestisce la terminazione SSL per certificati autofirmati e i clienti non stabiliranno connessioni sicure senza un certificato fidato.",
            "Assegnare un IP dedicato per il supporto SSL in ciascuna posizione Edge di CloudFront non è necessario. CloudFront utilizza un'infrastruttura condivisa per la terminazione SSL e i browser moderni non richiedono IP dedicati per le connessioni HTTPS. Invece, si basano sui certificati SSL per stabilire connessioni sicure.",
            "Abilitare SSL solo sulla distribuzione CloudFront e non sui server di origine non è consigliabile. Sebbene CloudFront possa criptare il traffico tra sé e i visualizzatori, è essenziale anche proteggere la connessione tra CloudFront e i server di origine (S3 e ALB) per garantire la crittografia end-to-end. Questo previene potenziali vulnerabilità durante il trasferimento dei dati da CloudFront all'origine."
        ]
    },
    {
        "Question Number": "58",
        "Situation": "Un'azienda di machine learning sta eseguendo simulazioni di calcolo ad alte prestazioni (HPC) che richiedono una latenza di rete estremamente bassa e alte prestazioni in pacchetti al secondo (PPS) tra le istanze. Le simulazioni sono intensive in termini di calcolo e necessitano che le istanze comunichino direttamente tra loro con il minimo ritardo.",
        "Question": "Quale configurazione del Placement Group EC2 dovrebbe scegliere l'architetto delle soluzioni per soddisfare questi requisiti?",
        "Options": {
            "1": "Spread Placement Group su più Availability Zone",
            "2": "Cluster Placement Group all'interno di una singola Availability Zone",
            "3": "Partition Placement Group su più rack",
            "4": "Dedicated Host Placement"
        },
        "Correct Answer": "Cluster Placement Group all'interno di una singola Availability Zone",
        "Explanation": "Un Cluster Placement Group è progettato per fornire bassa latenza e alta larghezza di banda tra le istanze posizionandole fisicamente vicine l'una all'altra nella stessa Availability Zone. Questa configurazione è ideale per applicazioni intensive in termini di calcolo che richiedono comunicazioni rapide tra le istanze, poiché minimizza la latenza di rete e massimizza le prestazioni in pacchetti al secondo. Poiché le simulazioni sono intensive in termini di calcolo e richiedono comunicazione diretta con il minimo ritardo, il Cluster Placement Group è la scelta migliore.",
        "Other Options": [
            "Spread Placement Group su più Availability Zone è progettato per distribuire le istanze su diverse hardware fisici per ridurre il rischio di guasti simultanei. Sebbene offra alta disponibilità, non fornisce la bassa latenza e le alte prestazioni PPS richieste per simulazioni intensive in termini di calcolo, poiché le istanze non sono posizionate vicine tra loro.",
            "Partition Placement Group su più rack è utile per applicazioni che richiedono alta disponibilità e tolleranza ai guasti, poiché distribuisce le istanze su diversi rack. Tuttavia, non garantisce la bassa latenza e l'alta larghezza di banda necessarie per la comunicazione diretta tra le istanze, rendendola meno adatta per lo scenario dato.",
            "Dedicated Host Placement è un server fisico dedicato al tuo utilizzo, che consente un maggiore controllo sul posizionamento delle istanze e sulla licenza. Tuttavia, non fornisce intrinsecamente la bassa latenza e le alte prestazioni in pacchetti al secondo che sono critiche per le simulazioni HPC descritte, poiché si concentra più sulla conformità e sul controllo piuttosto che sulle prestazioni di rete."
        ]
    },
    {
        "Question Number": "59",
        "Situation": "Un'organizzazione sanitaria deve stabilire una connessione sicura e affidabile tra il proprio data center on-premises e il proprio ambiente AWS per conformarsi ai requisiti normativi. La connessione deve supportare un'alta larghezza di banda e fornire bassa latenza per l'elaborazione dei dati in tempo reale.",
        "Question": "Quale opzione di connessione di rete dovrebbe raccomandare l'architetto delle soluzioni?",
        "Options": {
            "1": "AWS Site-to-Site VPN con routing dinamico",
            "2": "AWS Direct Connect con una connessione dedicata",
            "3": "AWS Transit Gateway con VPC peering",
            "4": "AWS PrivateLink per accedere ai servizi AWS in modo privato"
        },
        "Correct Answer": "AWS Direct Connect con una connessione dedicata",
        "Explanation": "AWS Direct Connect fornisce una connessione dedicata, ad alta larghezza di banda e a bassa latenza tra un data center on-premises e AWS. Questa opzione è ideale per le organizzazioni che richiedono una connessione sicura e affidabile per soddisfare la conformità normativa, specialmente per l'elaborazione dei dati in tempo reale. Direct Connect bypassa Internet pubblico, riducendo la latenza e migliorando le prestazioni, rendendolo adatto per applicazioni ad alta capacità.",
        "Other Options": [
            "AWS Site-to-Site VPN con routing dinamico utilizza Internet pubblico per stabilire una connessione sicura, il che può introdurre variabilità nella latenza e nella larghezza di banda. Sebbene sia un'opzione sicura, potrebbe non soddisfare i requisiti di alta larghezza di banda e bassa latenza necessari per l'elaborazione dei dati in tempo reale.",
            "AWS Transit Gateway con VPC peering è principalmente utilizzato per connettere più VPC e reti on-premises. Sebbene possa facilitare la comunicazione tra varie reti, non fornisce una connessione dedicata e potrebbe non soddisfare i requisiti di alta larghezza di banda e bassa latenza in modo efficace come Direct Connect.",
            "AWS PrivateLink è progettato per accedere ai servizi AWS in modo privato senza esporre il traffico a Internet pubblico. Tuttavia, non stabilisce una connessione diretta tra un data center on-premises e AWS, rendendolo inadatto per il requisito specifico di una connessione sicura e affidabile per alta larghezza di banda e bassa latenza."
        ]
    },
    {
        "Question Number": "60",
        "Situation": "Un'azienda di servizi finanziari desidera monitorare i costi tra i diversi dipartimenti utilizzando un unico account AWS. Hanno bisogno di un metodo per categorizzare le risorse per dipartimento e generare report di costo dettagliati.",
        "Question": "Quale funzionalità di gestione dei costi AWS li aiuterebbe meglio a raggiungere questo obiettivo?",
        "Options": {
            "1": "Abilitare la fatturazione multi-account",
            "2": "Utilizzare tag di allocazione dei costi",
            "3": "Impostare budget AWS per ciascun dipartimento",
            "4": "Abilitare S3 Requester Pays per lo storage specifico del dipartimento"
        },
        "Correct Answer": "Utilizzare tag di allocazione dei costi",
        "Explanation": "I tag di allocazione dei costi consentono di categorizzare le risorse AWS per dipartimento o qualsiasi altro criterio scelto. Applicando questi tag alle risorse, l'azienda di servizi finanziari può monitorare i costi associati a ciascun dipartimento e generare report di costo dettagliati basati su questi tag. Questa funzionalità è specificamente progettata per monitorare e riportare i costi, rendendola l'opzione migliore per le loro esigenze.",
        "Other Options": [
            "Abilitare la fatturazione multi-account non è adatto perché implica l'uso di più account AWS per separare i costi, il che non è ciò che l'azienda desidera poiché stanno cercando di monitorare i costi all'interno di un unico account AWS.",
            "Impostare budget AWS per ciascun dipartimento è utile per monitorare la spesa e impostare avvisi, ma non fornisce la categorizzazione delle risorse necessaria per report di costo dettagliati. I budget riguardano più il monitoraggio e il controllo dei costi piuttosto che la loro categorizzazione.",
            "Abilitare S3 Requester Pays per lo storage specifico del dipartimento non è rilevante in questo contesto. Questa funzionalità consente di addebitare al richiedente l'accesso ai dati S3, ma non aiuta a categorizzare i costi tra i dipartimenti o a generare report di costo dettagliati."
        ]
    },
    {
        "Question Number": "61",
        "Situation": "Un'azienda di e-commerce gestisce più account AWS attraverso varie unità aziendali, come marketing, vendite e sviluppo, e desidera monitorare e tracciare accuratamente i costi AWS per dipartimento. Hanno bisogno di un metodo per allocare risorse condivise come database e risorse di calcolo al budget di ciascun dipartimento e garantire un tracciamento dei costi trasparente per ogni unità aziendale.",
        "Question": "Quale funzionalità di gestione dei costi AWS dovrebbero utilizzare per soddisfare questi requisiti?",
        "Options": {
            "1": "Utilizzare la fatturazione consolidata per tutti gli account e applicare tag di allocazione dei costi per assegnare i costi a dipartimenti specifici",
            "2": "Creare un unico account AWS per tutti i dipartimenti e utilizzare pratiche di fatturazione interne per allocare i costi",
            "3": "Abilitare S3 Requester Pays per le risorse di ciascun dipartimento per trasferire i costi agli utenti individuali all'interno di ciascun dipartimento",
            "4": "Impostare avvisi di fatturazione separati per ciascun dipartimento per monitorare i costi in modo indipendente"
        },
        "Correct Answer": "Utilizzare la fatturazione consolidata per tutti gli account e applicare tag di allocazione dei costi per assegnare i costi a dipartimenti specifici",
        "Explanation": "Utilizzare la fatturazione consolidata consente all'azienda di e-commerce di gestire più account AWS sotto un unico account di fatturazione, semplificando il processo di pagamento. Applicando i tag di allocazione dei costi, possono categorizzare e tracciare i costi associati a risorse specifiche utilizzate da ciascun dipartimento. Questo metodo fornisce trasparenza nell'allocazione dei costi e consente un tracciamento accurato del budget per ogni unità aziendale, soddisfacendo il requisito di monitorare efficacemente i costi AWS.",
        "Other Options": [
            "Creare un unico account AWS per tutti i dipartimenti complicerebbe il tracciamento dei costi, poiché tutte le risorse sarebbero aggregate sotto un unico account. Questo approccio manca della granularità necessaria per allocare i costi in modo accurato ai singoli dipartimenti, rendendo difficile gestire i budget in modo efficace.",
            "Abilitare S3 Requester Pays non è adatto per tracciare i costi tra i dipartimenti poiché si applica solo alle risorse Amazon S3. Questa funzionalità consente al richiedente dei dati di pagare i costi di trasferimento dei dati, ma non fornisce una soluzione completa per tracciare e allocare i costi attraverso vari servizi e dipartimenti AWS.",
            "Impostare avvisi di fatturazione separati per ciascun dipartimento può aiutare a monitorare i costi, ma non fornisce un metodo per allocare risorse condivise o tracciare accuratamente i costi rispetto ai budget dipartimentali. Gli avvisi sono reattivi piuttosto che proattivi e non facilitano una gestione o allocazione dettagliata dei costi."
        ]
    },
    {
        "Question Number": "62",
        "Situation": "Un'azienda finanziaria desidera crittografare i dati in transito tra il proprio ambiente on-premises e AWS. I dati devono essere crittografati utilizzando un certificato TLS.",
        "Question": "Quale servizio AWS dovrebbe utilizzare l'azienda per gestire e distribuire il certificato TLS?",
        "Options": {
            "1": "AWS Key Management Service (AWS KMS)",
            "2": "AWS Secrets Manager",
            "3": "AWS Certificate Manager (ACM)",
            "4": "Amazon S3"
        },
        "Correct Answer": "AWS Certificate Manager (ACM)",
        "Explanation": "AWS Certificate Manager (ACM) è progettato specificamente per gestire e distribuire certificati TLS/SSL per l'uso con i servizi e le applicazioni AWS. Semplifica il processo di provisioning, gestione e distribuzione dei certificati, consentendo all'azienda finanziaria di crittografare facilmente i dati in transito tra il proprio ambiente on-premises e AWS. ACM gestisce anche il rinnovo dei certificati automaticamente, garantendo che la crittografia rimanga valida senza intervento manuale.",
        "Other Options": [
            "AWS Key Management Service (AWS KMS) è utilizzato principalmente per gestire chiavi crittografiche per le tue applicazioni e servizi. Sebbene svolga un ruolo cruciale nei processi di crittografia e decrittografia, non gestisce direttamente i certificati TLS.",
            "AWS Secrets Manager è utilizzato per gestire segreti come credenziali di database, chiavi API e altre informazioni sensibili. Non fornisce funzionalità per gestire certificati TLS, rendendolo inadeguato per questo requisito specifico.",
            "Amazon S3 è un servizio di archiviazione che consente di memorizzare e recuperare qualsiasi quantità di dati in qualsiasi momento. Non ha capacità per gestire o distribuire certificati TLS, e quindi non è rilevante per il compito di crittografare i dati in transito."
        ]
    },
    {
        "Question Number": "63",
        "Situation": "Un'azienda sta sviluppando un'applicazione web su AWS che richiede un'autenticazione sicura degli utenti e protezione contro minacce esterne, come attacchi DDoS e SQL injection. L'applicazione deve anche garantire che le credenziali degli utenti siano gestite in modo sicuro e che gli utenti abbiano accesso limitato in base ai loro ruoli.",
        "Question": "Quale combinazione di servizi AWS dovrebbe utilizzare l'azienda per soddisfare questi requisiti di sicurezza?",
        "Options": {
            "1": "Utilizzare AWS Shield per la protezione DDoS, Amazon Cognito per l'autenticazione degli utenti e AWS WAF per bloccare gli attacchi di SQL injection.",
            "2": "Utilizzare Amazon GuardDuty per la protezione DDoS, IAM roles per l'autenticazione degli utenti e AWS CloudFront per la protezione contro SQL injection.",
            "3": "Utilizzare AWS Identity Center (AWS SSO) per l'autenticazione degli utenti, AWS WAF per la protezione DDoS e Amazon Macie per la prevenzione di SQL injection.",
            "4": "Utilizzare AWS Secrets Manager per l'autenticazione degli utenti, AWS Shield per la protezione DDoS e AWS Lambda per la protezione contro SQL injection."
        },
        "Correct Answer": "Utilizzare AWS Shield per la protezione DDoS, Amazon Cognito per l'autenticazione degli utenti e AWS WAF per bloccare gli attacchi di SQL injection.",
        "Explanation": "Questa combinazione di servizi affronta efficacemente tutti i requisiti di sicurezza delineati nello scenario. AWS Shield fornisce una robusta protezione DDoS, essenziale per proteggere l'applicazione web da minacce esterne. Amazon Cognito è progettato specificamente per l'autenticazione degli utenti, consentendo una gestione sicura delle credenziali degli utenti e abilitando il controllo degli accessi basato sui ruoli. AWS WAF (Web Application Firewall) è specificamente progettato per proteggere le applicazioni web da exploit comuni, inclusi gli attacchi di SQL injection, consentendo di creare regole che bloccano tali richieste malevole.",
        "Other Options": [
            "Utilizzare Amazon GuardDuty per la protezione DDoS è errato perché GuardDuty è principalmente un servizio di rilevamento delle minacce che monitora attività malevole e comportamenti non autorizzati, piuttosto che fornire una protezione DDoS diretta. Le IAM roles non sono un servizio di autenticazione degli utenti; vengono utilizzate per concedere permessi alle risorse AWS. AWS CloudFront è una rete di distribuzione dei contenuti e non fornisce protezione diretta contro SQL injection.",
            "AWS Identity Center (AWS SSO) è un servizio per il single sign-on e l'autenticazione degli utenti, ma AWS WAF non è progettato per la protezione DDoS; è destinato alla sicurezza delle applicazioni web. Amazon Macie è un servizio di sicurezza e privacy dei dati che aiuta a scoprire e proteggere dati sensibili, ma non previene attacchi di SQL injection.",
            "AWS Secrets Manager è utilizzato per gestire segreti come chiavi API e credenziali di database, ma non è un servizio di autenticazione. AWS Shield è appropriato per la protezione DDoS, ma AWS Lambda non fornisce intrinsecamente protezione contro SQL injection; è un servizio di calcolo che può eseguire codice in risposta a eventi e non affronta direttamente la sicurezza delle applicazioni web."
        ]
    },
    {
        "Question Number": "64",
        "Situation": "Un'azienda sta configurando un Virtual Private Cloud (VPC) e deve progettare più subnet per un'applicazione che sarà distribuita attraverso più Availability Zones (AZ). Vogliono garantire che gli indirizzi IP all'interno di ciascuna subnet siano correttamente allocati e riservati per funzioni specifiche all'interno della rete.",
        "Question": "Quale delle seguenti affermazioni descrive meglio le regole per impostare le subnet VPC e gestire gli indirizzi IP riservati?",
        "Options": {
            "1": "Una singola subnet può estendersi su più zone di disponibilità per massimizzare l'utilizzo degli indirizzi IP all'interno del blocco CIDR del VPC.",
            "2": "Ogni subnet ha un intervallo di indirizzi IP, con cinque indirizzi IP specifici in ciascuna subnet automaticamente riservati da AWS per funzioni di rete, inclusi indirizzi per DNS e routing VPC.",
            "3": "I blocchi CIDR IPv4 assegnati alle subnet possono sovrapporsi tra loro per ottimizzare l'uso dello spazio, specialmente quando le subnet si trovano in diverse AZ.",
            "4": "Le opzioni DHCP in AWS consentono di modificare e rimuovere indirizzi IP assegnati automaticamente all'interno di ciascuna subnet."
        },
        "Correct Answer": "Ogni subnet ha un intervallo di indirizzi IP, con cinque indirizzi IP specifici in ciascuna subnet automaticamente riservati da AWS per funzioni di rete, inclusi indirizzi per DNS e routing VPC.",
        "Explanation": "In AWS, a ciascuna subnet viene assegnato un intervallo di indirizzi IP dal blocco CIDR del VPC, e AWS riserva automaticamente cinque indirizzi IP in ciascuna subnet per specifiche funzioni di rete. Questi indirizzi riservati vengono utilizzati per il router VPC, DNS e altri servizi essenziali, garantendo che non siano disponibili per l'assegnazione alle istanze. Questa regola è cruciale per mantenere la funzionalità del VPC e delle sue subnet.",
        "Other Options": [
            "Una singola subnet non può estendersi su più zone di disponibilità; ciascuna subnet deve risiedere interamente all'interno di una zona di disponibilità. Questo design garantisce che le risorse in diverse AZ siano isolate e possano fornire alta disponibilità e tolleranza ai guasti.",
            "I blocchi CIDR IPv4 assegnati alle subnet non possono sovrapporsi tra loro. Ogni subnet deve avere un intervallo unico di indirizzi IP per evitare conflitti e garantire un routing corretto all'interno del VPC. Blocchi CIDR sovrapposti porterebbero a problemi di routing e connettività.",
            "Le opzioni DHCP in AWS non consentono di modificare o rimuovere indirizzi IP assegnati automaticamente all'interno di ciascuna subnet. Le opzioni DHCP vengono utilizzate per configurare le impostazioni DHCP per le istanze, come i server DNS e i server NTP, ma non influenzano gli indirizzi IP riservati all'interno della subnet."
        ]
    },
    {
        "Question Number": "65",
        "Situation": "Un'azienda sta distribuendo un'applicazione web globale e desidera garantire alta disponibilità e accesso a bassa latenza per gli utenti in tutto il mondo. L'azienda sta utilizzando Amazon Route 53 per la gestione DNS e sta considerando di distribuire l'applicazione attraverso più Availability Zones (AZ) in più regioni AWS per garantire la tolleranza ai guasti.",
        "Question": "Quale delle seguenti strategie soddisferebbe meglio i requisiti dell'azienda per alta disponibilità e disaster recovery?",
        "Options": {
            "1": "Utilizzare Route 53 con routing geolocalizzato per indirizzare gli utenti alla regione più vicina e distribuire l'applicazione in più Availability Zones in quelle regioni per garantire alta disponibilità.",
            "2": "Utilizzare Route 53 con una politica di routing di failover per garantire che il traffico venga indirizzato a una regione di backup in caso di guasto nella regione primaria.",
            "3": "Distribuire l'applicazione in una singola Availability Zone in una regione per semplificare la gestione e ridurre la complessità operativa.",
            "4": "Utilizzare Route 53 con routing ponderato per indirizzare il traffico in modo equo a tutte le regioni, indipendentemente dalla disponibilità o dalla latenza, per una distribuzione del traffico più equilibrata."
        },
        "Correct Answer": "Utilizzare Route 53 con routing geolocalizzato per indirizzare gli utenti alla regione più vicina e distribuire l'applicazione in più Availability Zones in quelle regioni per garantire alta disponibilità.",
        "Explanation": "Utilizzare Route 53 con routing geolocalizzato consente all'azienda di indirizzare gli utenti alla regione AWS più vicina, riducendo la latenza e migliorando l'esperienza dell'utente. Distribuendo l'applicazione in più Availability Zones (AZ) all'interno di quelle regioni, l'azienda può garantire alta disponibilità, poiché il traffico può essere automaticamente indirizzato a istanze sane in diverse AZ in caso di guasto. Questo approccio fornisce anche capacità di tolleranza ai guasti e disaster recovery, poiché sfrutta la ridondanza di più AZ e regioni.",
        "Other Options": [
            "Utilizzare Route 53 con una politica di routing di failover è utile per il disaster recovery, ma si concentra principalmente sull'instradamento del traffico a una regione di backup solo quando la regione primaria fallisce. Questo non affronta la necessità di accesso a bassa latenza per gli utenti in tutto il mondo, poiché potrebbe non indirizzare gli utenti alla regione più vicina per prestazioni ottimali.",
            "Distribuire l'applicazione in una singola Availability Zone in una regione aumenta significativamente il rischio di inattività e non fornisce alta disponibilità o tolleranza ai guasti. Se quell'unica AZ subisce un'interruzione, l'intera applicazione sarebbe non disponibile, il che contraddice i requisiti dell'azienda per alta disponibilità.",
            "Utilizzare Route 53 con routing ponderato per indirizzare il traffico in modo equo a tutte le regioni ignora la disponibilità e la latenza di quelle regioni. Questo potrebbe portare a prestazioni subottimali per gli utenti, poiché il traffico potrebbe essere inviato a una regione più lontana o che sta affrontando problemi, non soddisfacendo così gli obiettivi dell'azienda per accesso a bassa latenza e alta disponibilità."
        ]
    }
]