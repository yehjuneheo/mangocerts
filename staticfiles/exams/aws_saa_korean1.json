[
    {
        "Question Number": "1",
        "Situation": "한 회사가 애플리케이션 배포를 위해 불변 인프라를 채택하고 있습니다. 이들은 모든 인프라 변경이 자원을 수정하는 대신 교체함으로써 이루어지도록 하여 일관성을 높이고 롤백을 쉽게 하기를 원합니다.",
        "Question": "다음 중 불변 인프라의 원칙과 그 이점을 가장 잘 설명하는 것은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "불변 인프라는 서버와 자원이 항상 제자리에서 수정되도록 보장하여 자원 교체의 필요성을 방지합니다.",
            "2": "불변 인프라는 변경이 필요할 때 서버나 인프라 구성 요소를 완전히 교체하여 실행 중인 인스턴스에 변경 사항이 적용되지 않도록 하고 롤백을 쉽게 합니다.",
            "3": "불변 인프라는 모든 업데이트가 기존 자원에 자동으로 통합되므로 버전 관리의 필요성을 없앱니다.",
            "4": "불변 인프라는 서버의 수동 구성을 기반으로 하여 배포 과정에서 자동화가 사용되지 않도록 보장합니다.",
            "5": "불변 인프라는 모든 배포가 동일하도록 보장하여 일관성을 높이고 구성 편차를 줄입니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "불변 인프라는 변경이 필요할 때 서버나 인프라 구성 요소를 완전히 교체하여 실행 중인 인스턴스에 변경 사항이 적용되지 않도록 하고 롤백을 쉽게 합니다.",
            "불변 인프라는 모든 배포가 동일하도록 보장하여 일관성을 높이고 구성 편차를 줄입니다."
        ],
        "Explanation": "불변 인프라는 변경이 필요할 때 서버나 인프라 구성 요소를 완전히 교체하는 원칙입니다. 이는 실행 중인 인스턴스에 변경 사항이 적용되지 않도록 하여 롤백을 쉽게 합니다. 또한 모든 배포가 동일하도록 보장하여 일관성을 높이고 구성 편차를 줄입니다. 이 접근 방식은 인프라의 불일치와 오류 위험을 크게 줄여 신뢰성을 높이고 관리하기 쉽게 만듭니다.",
        "Other Options": [
            "옵션 1은 불변 인프라가 서버와 자원을 제자리에서 수정하는 것과 관련이 없기 때문에 잘못된 것입니다. 대신, 변경이 필요할 때 완전히 교체하는 것이 포함됩니다.",
            "옵션 3은 불변 인프라가 버전 관리의 필요성을 없애지 않기 때문에 잘못된 것입니다. 실제로, 불변 인프라에서는 인프라 구성 요소의 다양한 버전을 추적하기 위해 버전 관리가 중요합니다.",
            "옵션 4는 불변 인프라가 서버의 수동 구성에 의존하지 않기 때문에 잘못된 것입니다. 대신, 모든 배포가 동일하도록 보장하고 변경이 필요할 때 서버나 인프라 구성 요소의 교체를 용이하게 하기 위해 자동화를 포함하는 경우가 많습니다."
        ]
    },
    {
        "Question Number": "2",
        "Situation": "한 소매 회사가 Amazon EC2 인스턴스에서 애플리케이션 로드 밸런서 뒤에 전자상거래 웹사이트를 운영하고 있습니다. 이 회사는 변동하는 트래픽 패턴을 경험하고 있으며, 애플리케이션이 다양한 부하를 처리할 수 있도록 자동으로 확장되면서 비용을 최소화하기를 원합니다.",
        "Question": "이러한 요구 사항을 충족하기 위해 솔루션 아키텍트가 구현해야 할 구성은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "고정된 수의 EC2 인스턴스를 가진 Auto Scaling 그룹을 구성하고 비용 절감을 위해 예약 인스턴스를 사용합니다.",
            "2": "변동하는 트래픽을 처리하기 위해 Auto Scaling 그룹과 함께 Spot 인스턴스를 사용합니다.",
            "3": "CPU 사용률을 기반으로 하는 목표 추적 확장 정책으로 Auto Scaling 그룹을 설정합니다.",
            "4": "수동 확장 정책으로 AWS Elastic Beanstalk에 애플리케이션을 배포합니다.",
            "5": "Amazon CloudWatch를 사용하여 트래픽을 예측하고 용량을 사전 조정하는 예측 확장을 구현합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "변동하는 트래픽을 처리하기 위해 Auto Scaling 그룹과 함께 Spot 인스턴스를 사용합니다.",
            "CPU 사용률을 기반으로 하는 목표 추적 확장 정책으로 Auto Scaling 그룹을 설정합니다."
        ],
        "Explanation": "Auto Scaling 그룹과 함께 Spot 인스턴스를 사용하는 것은 변동하는 트래픽을 처리하기 위한 비용 효율적인 선택입니다. 이는 AWS 클라우드에서 사용되지 않는 EC2 용량을 활용할 수 있게 해줍니다. Spot 인스턴스는 온디맨드 가격에 비해 최대 90% 할인된 가격으로 제공됩니다. CPU 사용률을 기반으로 하는 목표 추적 확장 정책을 가진 Auto Scaling 그룹은 수요에 따라 애플리케이션이 자동으로 확장되도록 합니다. 수요가 증가하면 새로운 인스턴스가 자동으로 추가되고, 수요가 감소하면 인스턴스가 자동으로 제거됩니다. 이는 필요한 만큼만 사용하고 비용을 지불하도록 보장합니다.",
        "Other Options": [
            "고정된 수의 EC2 인스턴스를 가진 Auto Scaling 그룹을 구성하고 예약 인스턴스를 사용하는 것은 수요에 따라 자동 확장을 허용하지 않기 때문에 변동하는 트래픽을 처리하는 최선의 옵션이 아닙니다. 예약 인스턴스는 온디맨드 인스턴스에 비해 비용 절감을 제공하지만, 변동하는 트래픽 패턴에 필요한 유연성을 제공하지 않습니다.",
            "수동 확장 정책으로 AWS Elastic Beanstalk에 애플리케이션을 배포하는 것은 자동 확장을 허용하지 않기 때문에 최선의 옵션이 아닙니다. 수동 확장은 인스턴스를 추가하거나 제거하기 위해 수동 개입이 필요하며, 이는 변동하는 트래픽 패턴을 처리하는 데 이상적이지 않습니다.",
            "Amazon CloudWatch를 사용하여 트래픽을 예측하고 용량을 사전 조정하는 예측 확장을 구현하는 것은 일부 사용 사례에 대해 좋은 옵션이 될 수 있지만, 이 특정 시나리오에 대해 가장 비용 효율적인 솔루션은 아닙니다. 예측 확장은 머신 러닝 알고리즘을 사용하여 미래의 트래픽 패턴을 예측하고 용량을 조정하는데, 이는 다른 옵션보다 더 비쌀 수 있습니다."
        ]
    },
    {
        "Question Number": "3",
        "Situation": "한 회사가 변동하는 트래픽을 경험하는 웹 애플리케이션을 운영하고 있습니다. 이들은 피크 시간 동안 높은 트래픽을 처리할 수 있도록 하면서 자원을 과도하게 프로비저닝하지 않기를 원합니다.",
        "Question": "회사가 트래픽 변동성과 비용 효율성을 최적으로 관리하기 위해 어떤 확장 전략을 사용해야 합니까?",
        "Options": {
            "1": "로드 밸런서 뒤에 더 많은 EC2 인스턴스를 추가하여 수평 확장을 사용하여 트래픽을 분산시키고, 자원이 수요 변화에 따라 확장되도록 합니다.",
            "2": "EC2 인스턴스의 크기를 늘려 더 많은 트래픽을 처리하는 수직 확장을 사용하지만, 이는 트래픽 급증 시 유연성을 제공하지 않을 수 있습니다.",
            "3": "수평 확장과 수직 확장을 조합하여 사용하되, 수평 확장은 경미한 트래픽 변화에 사용하고 수직 확장은 극단적인 급증을 처리하는 데 사용합니다.",
            "4": "예상되는 트래픽 패턴에 따라 EC2 인스턴스의 크기와 수를 조정하는 수동 확장을 사용합니다."
        },
        "Correct Answer": "로드 밸런서 뒤에 더 많은 EC2 인스턴스를 추가하여 수평 확장을 사용하여 트래픽을 분산시키고, 자원이 수요 변화에 따라 확장되도록 합니다.",
        "Explanation": "수평 확장은 변동하는 트래픽을 관리하는 가장 효과적인 전략입니다. 이는 애플리케이션이 실시간 수요에 따라 인스턴스를 추가하거나 제거할 수 있게 해줍니다. 이 접근 방식은 피크 시간 동안 추가 EC2 인스턴스를 프로비저닝하여 증가된 트래픽을 처리할 수 있도록 하고, 비피크 시간 동안에는 인스턴스를 줄여 비용을 절감할 수 있도록 합니다. 이 동적 확장 기능은 유연성과 비용 효율성을 모두 제공하며, 자원은 필요할 때만 사용됩니다.",
        "Other Options": [
            "수직 확장은 기존 EC2 인스턴스의 크기를 늘려 더 많은 트래픽을 처리하는 것입니다. 이는 효과적일 수 있지만 유연성에 한계가 있으며 확장 작업 중 다운타임을 초래할 수 있습니다. 또한 인스턴스의 최대 크기 제한이 있어 극단적인 트래픽 급증 시 충분하지 않을 수 있습니다.",
            "수평 확장과 수직 확장을 조합하여 사용하는 것은 이점을 제공할 수 있지만, 확장 전략을 복잡하게 만들고 수평 확장만 사용하는 것만큼 효율적이지 않을 수 있습니다. 수평 확장은 자원 할당에 대한 더 세밀한 제어를 허용하기 때문에 변동하는 트래픽을 처리하는 데 일반적으로 선호됩니다.",
            "수동 확장은 트래픽 패턴에 대한 예측에 의존하며, 이는 부정확할 수 있습니다. 이 접근 방식은 갑작스러운 트래픽 변화에 대응하는 데 필요한 민첩성을 제공하지 않으며, 예상치 못한 급증 동안 성능 문제를 초래하고 낮은 트래픽 기간 동안 불필요한 비용을 초래할 수 있습니다."
        ]
    },
    {
        "Question Number": "4",
        "Situation": "한 의료 기관이 Amazon RDS for PostgreSQL에 저장된 모든 데이터가 정지 상태에서 암호화되고 암호화 키가 안전하게 관리되도록 해야 합니다. 이 기관은 데이터 보호를 위한 엄격한 규제 요구 사항을 준수해야 합니다.",
        "Question": "어떤 솔루션이 이러한 요구 사항을 충족할 수 있습니까?",
        "Options": {
            "1": "Amazon RDS 암호화를 사용하여 정지 상태에서 암호화를 활성화하고 AWS Key Management Service (KMS)로 키를 관리합니다.",
            "2": "Amazon S3를 사용하여 데이터베이스 백업을 저장하고 S3 암호화를 활성화합니다.",
            "3": "전송 중 데이터에 대해 SSL/TLS를 구현하고 RDS 기본 암호화에 의존합니다.",
            "4": "RDS 데이터베이스에 저장하기 전에 애플리케이션 내에서 데이터를 암호화합니다."
        },
        "Correct Answer": "Amazon RDS 암호화를 사용하여 정지 상태에서 암호화를 활성화하고 AWS Key Management Service (KMS)로 키를 관리합니다.",
        "Explanation": "이 옵션은 Amazon RDS for PostgreSQL에서 정지 상태에서 데이터를 암호화하는 요구 사항을 직접적으로 해결합니다. Amazon RDS는 데이터베이스에 저장된 모든 데이터가 암호화되도록 활성화할 수 있는 내장 암호화 기능을 제공합니다. 또한 AWS Key Management Service (KMS)를 사용하면 암호화 키를 안전하게 관리할 수 있어 데이터 보호와 관련된 규제 요구 사항을 준수하는 데 중요합니다. 이 솔루션은 암호화와 안전한 키 관리를 원활하게 보장합니다.",
        "Other Options": [
            "Amazon S3를 사용하여 데이터베이스 백업을 저장하고 S3 암호화를 활성화하는 것은 RDS 데이터베이스 내에서 정지 상태에서 데이터를 암호화하는 요구 사항을 충족하지 않습니다. S3 암호화는 백업에 유용하지만, RDS에 저장된 라이브 데이터의 암호화는 해결하지 않습니다.",
            "전송 중 데이터에 대해 SSL/TLS를 구현하는 것은 클라이언트와 데이터베이스 간의 데이터가 이동할 때 보안을 강화하는 데 중요하지만, 정지 상태에서 데이터 암호화를 제공하지 않습니다. 또한 RDS 기본 암호화에 의존하는 것은 특정 규제 요구 사항을 충족하지 않을 수 있으며, 사용자 정의 키 관리나 준수 검사를 허용하지 않습니다.",
            "RDS 데이터베이스에 저장하기 전에 애플리케이션 내에서 데이터를 암호화하는 것은 유효한 접근 방식이지만, 추가 개발 노력이 필요하고 데이터 접근 및 관리가 복잡해질 수 있습니다. 또한, 데이터 보호 규정을 준수하는 데 설계된 RDS의 내장 암호화 기능을 활용하지 않습니다."
        ]
    },
    {
        "Question Number": "5",
        "Situation": "한 회사가 온프레미스 애플리케이션을 AWS로 마이그레이션하고 있습니다. 이 애플리케이션은 웹 서버, 애플리케이션 서버 및 데이터베이스 서버로 구성되어 있습니다. 이 회사는 데이터베이스 서버가 인터넷에서 직접 접근할 수 없고 애플리케이션 서버만 접근할 수 있도록 하기를 원합니다.",
        "Question": "어떤 네트워크 구성이 이러한 요구 사항을 충족할 수 있습니까? (두 가지 선택)",
        "Options": {
            "1": "웹 서버와 애플리케이션 서버를 공용 서브넷에 배치하고 데이터베이스 서버를 개인 서브넷에 배치합니다. 보안 그룹을 구성하여 애플리케이션 서버에서 데이터베이스 서버로의 트래픽만 허용합니다.",
            "2": "모든 서버를 공용 서브넷에 배치하고 네트워크 ACL을 사용하여 데이터베이스 서버에 대한 접근을 제한합니다.",
            "3": "웹 서버를 공용 서브넷에 배치하고 애플리케이션 서버와 데이터베이스 서버를 별도의 개인 서브넷에 배치합니다. 보안 그룹을 사용하여 웹 서버에서 애플리케이션 서버로, 애플리케이션 서버에서 데이터베이스 서버로의 트래픽만 허용합니다.",
            "4": "웹 서버와 데이터베이스 서버를 공용 서브넷에 배치하고 애플리케이션 서버를 개인 서브넷에 배치합니다. 보안 그룹을 사용하여 웹 서버에서 애플리케이션 서버로의 트래픽만 허용합니다.",
            "5": "AWS Transit Gateway를 사용하여 서브넷 간 라우팅을 관리하고 라우트 테이블을 통해 데이터베이스 서버에 대한 접근을 제한합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "웹 서버와 애플리케이션 서버를 공용 서브넷에 배치하고 데이터베이스 서버를 개인 서브넷에 배치합니다. 보안 그룹을 구성하여 애플리케이션 서버에서 데이터베이스 서버로의 트래픽만 허용합니다.",
            "웹 서버를 공용 서브넷에 배치하고 애플리케이션 서버와 데이터베이스 서버를 별도의 개인 서브넷에 배치합니다. 보안 그룹을 사용하여 웹 서버에서 애플리케이션 서버로, 애플리케이션 서버에서 데이터베이스 서버로의 트래픽만 허용합니다."
        ],
        "Explanation": "정답은 웹 서버와 애플리케이션 서버를 공용 서브넷에 배치하고 데이터베이스 서버를 개인 서브넷에 배치하는 옵션입니다. 이 구성은 데이터베이스 서버가 인터넷에서 직접 접근할 수 없도록 보장합니다. 그런 다음 보안 그룹을 사용하여 트래픽을 제어하여 애플리케이션 서버만 데이터베이스 서버에 접근할 수 있도록 합니다. 두 번째 정답 옵션에서는 애플리케이션 서버와 데이터베이스 서버가 별도의 개인 서브넷에 있어 추가적인 보안과 격리를 제공합니다.",
        "Other Options": [
            "모든 서버를 공용 서브넷에 배치하고 네트워크 ACL을 사용하여 데이터베이스 서버에 대한 접근을 제한하는 것은 좋은 방법이 아닙니다. 이는 모든 서버를 인터넷에 노출시켜 보안 침해의 위험을 증가시킵니다.",
            "웹 서버와 데이터베이스 서버를 공용 서브넷에 배치하고 애플리케이션 서버를 개인 서브넷에 배치하는 것은 데이터베이스 서버가 인터넷에서 접근할 수 없다는 요구 사항을 충족하지 않습니다.",
            "AWS Transit Gateway를 사용하여 서브넷 간 라우팅을 관리하고 라우트 테이블을 통해 데이터베이스 서버에 대한 접근을 제한하는 것은 가장 효율적이거나 안전한 방법이 아닙니다. 이는 관리가 복잡할 수 있으며, 보안 그룹과 함께 개인 및 공용 서브넷을 사용하는 것만큼의 보안 수준을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "6",
        "Situation": "소매 회사가 Amazon EC2 인스턴스에서 호스팅되는 전자상거래 웹사이트를 운영하고 있으며, 애플리케이션 로드 밸런서 뒤에 있습니다. 웹사이트는 특히 쇼핑 성수기 동안 트래픽 패턴이 변동하며, 회사는 저트래픽 기간 동안 불필요한 비용을 발생시키지 않으면서 자동으로 애플리케이션이 확장되도록 하고 싶어합니다. 팀은 인프라 비용을 최소화하면서 자동 확장을 지원하는 최적의 설정을 찾고 있습니다.",
        "Question": "이 요구 사항을 충족하기 위해 솔루션 아키텍트가 구현해야 할 구성은 무엇입니까?",
        "Options": {
            "1": "EC2 인스턴스의 고정 수로 Auto Scaling 그룹을 구성하고 장기 비용 절감을 위해 Reserved Instances로 용량을 예약합니다.",
            "2": "Auto Scaling 그룹 내에서 Spot Instances를 사용하여 변동하는 트래픽을 처리하고, 피크 로드 동안 인스턴스를 확장하며 비용을 줄입니다.",
            "3": "CPU 사용률을 기반으로 하는 목표 추적 확장 정책으로 Auto Scaling 그룹을 설정하여 수요에 따라 용량을 동적으로 조정합니다.",
            "4": "AWS Elastic Beanstalk에 애플리케이션을 배포하고 트래픽 패턴이 변경됨에 따라 인스턴스를 추가하거나 제거하기 위해 수동 확장 정책을 사용합니다."
        },
        "Correct Answer": "CPU 사용률을 기반으로 하는 목표 추적 확장 정책으로 Auto Scaling 그룹을 설정하여 수요에 따라 용량을 동적으로 조정합니다.",
        "Explanation": "목표 추적 확장 정책으로 Auto Scaling 그룹을 설정하면 애플리케이션이 실시간 수요, 특히 이 경우 CPU 사용률에 따라 EC2 인스턴스 수를 자동으로 조정할 수 있습니다. 이 구성은 애플리케이션이 피크 트래픽 기간 동안 증가된 부하를 처리하기 위해 확장하고, 저트래픽 기간 동안 비용을 최소화하기 위해 축소할 수 있도록 보장합니다. 목표 추적 확장 정책은 구현 및 관리가 간단하여 성능과 비용 효율성 간의 균형을 제공합니다.",
        "Other Options": [
            "EC2 인스턴스의 고정 수로 Auto Scaling 그룹을 구성하면 트래픽 패턴에 따라 동적 확장이 불가능합니다. Reserved Instances는 장기 사용에 대한 비용 절감을 제공할 수 있지만, 이 접근 방식은 저트래픽 기간 동안 축소되지 않기 때문에 변동하는 트래픽 요구를 효과적으로 해결하지 못합니다.",
            "Auto Scaling 그룹 내에서 Spot Instances를 사용하면 비용을 줄일 수 있지만, Spot Instances는 AWS에 의해 예고 없이 종료될 수 있어 피크 로드 동안 애플리케이션 불안정성을 초래할 수 있습니다. 이 옵션은 고트래픽 쇼핑 시즌 동안 일관된 가용성이 필요한 소매 회사에는 이상적이지 않습니다.",
            "AWS Elastic Beanstalk에 애플리케이션을 배포하고 수동 확장 정책을 사용하는 것은 변동하는 트래픽 패턴에 필요한 자동 확장을 제공하지 않습니다. 수동 확장은 인스턴스 수를 조정하기 위해 인간의 개입이 필요하며, 이는 피크 시간 동안 지연 및 잠재적인 성능 문제를 초래할 수 있습니다."
        ]
    },
    {
        "Question Number": "7",
        "Situation": "미디어 회사가 여러 AWS 계정에 걸쳐 여러 VPC를 보유하고 있으며, 공용 인터넷을 통하지 않고 VPC 간의 비용 효율적인 개인 통신을 가능하게 하기를 원합니다. 또한 이 설정과 관련된 데이터 전송 비용을 줄이고자 합니다.",
        "Question": "가장 비용 효율적인 네트워크 구성은 무엇입니까?",
        "Options": {
            "1": "각 VPC 간에 VPC Peering을 사용합니다.",
            "2": "중앙 집중식 VPC 통신을 위해 AWS Transit Gateway를 사용합니다.",
            "3": "NAT 게이트웨이를 통해 트래픽을 라우팅하여 안전한 액세스를 제공합니다.",
            "4": "각 VPC에 대해 VPN 연결을 설정합니다."
        },
        "Correct Answer": "중앙 집중식 VPC 통신을 위해 AWS Transit Gateway를 사용합니다.",
        "Explanation": "AWS Transit Gateway는 여러 VPC의 관리를 간소화하도록 설계되었으며, VPC 간의 비용 효율적인 개인 통신을 가능하게 합니다. 모든 VPC가 중앙 게이트웨이에 연결될 수 있는 허브-스포크 모델을 허용하여 여러 VPC 피어링 연결 관리와 관련된 복잡성과 비용을 줄입니다. 또한 Transit Gateway는 트래픽을 단일 지점을 통해 집계하여 데이터 전송 비용을 줄이는 데 도움을 줄 수 있습니다.",
        "Other Options": [
            "각 VPC 간에 VPC Peering을 사용하는 것은 VPC 수가 증가함에 따라 복잡하고 비용이 많이 들 수 있습니다. 각 VPC는 별도의 피어링 연결이 필요하여 연결의 조합 폭발과 더 높은 관리 오버헤드를 초래하며, VPC 피어링의 특성으로 인해 데이터 전송 비용이 더 높아질 수 있습니다.",
            "NAT 게이트웨이를 통해 트래픽을 라우팅하는 것은 VPC 간 통신에 적합하지 않습니다. NAT 게이트웨이는 주로 개인 서브넷에서 외부 인터넷 액세스를 위해 사용됩니다. 이 옵션은 VPC 간의 직접 통신을 용이하게 하지 않으며 NAT 게이트웨이를 통한 데이터 전송에 추가 비용이 발생합니다.",
            "각 VPC에 대해 VPN 연결을 설정하는 것은 비효율적이고 비용이 많이 들며, 특히 여러 VPC를 다룰 때 더욱 그렇습니다. 각 VPN 연결은 비용이 발생하고 네트워크 아키텍처에 복잡성을 추가합니다. 또한 VPN 연결은 일반적으로 다른 옵션에 비해 낮은 처리량을 가지며 지연을 초래할 수 있습니다."
        ]
    },
    {
        "Question Number": "8",
        "Situation": "회사가 SQL 인젝션 및 크로스 사이트 스크립팅과 같은 일반적인 웹 기반 공격으로부터 보호해야 하는 웹 애플리케이션을 배포하고 있습니다.",
        "Question": "이 보호를 제공하기 위해 어떤 AWS 서비스를 사용해야 합니까?",
        "Options": {
            "1": "AWS Shield",
            "2": "AWS WAF (Web Application Firewall)",
            "3": "Amazon Macie",
            "4": "Amazon GuardDuty"
        },
        "Correct Answer": "AWS WAF (Web Application Firewall)",
        "Explanation": "AWS WAF (Web Application Firewall)는 SQL 인젝션 및 크로스 사이트 스크립팅(XSS)과 같은 일반적인 웹 기반 공격으로부터 웹 애플리케이션을 보호하도록 특별히 설계되었습니다. 사용자는 사용자 정의 조건에 따라 HTTP 요청을 필터링하고 모니터링하는 규칙을 생성할 수 있어, 악의적인 트래픽이 애플리케이션에 도달하기 전에 효과적으로 차단할 수 있습니다. 이는 설명된 시나리오에 가장 적합한 선택입니다.",
        "Other Options": [
            "AWS Shield는 분산 서비스 거부(DDoS) 공격으로부터 애플리케이션을 보호하는 관리형 서비스입니다. 중요한 보안 기능을 제공하지만, SQL 인젝션이나 크로스 사이트 스크립팅 취약점을 구체적으로 해결하지는 않습니다.",
            "Amazon Macie는 AWS에 저장된 민감한 데이터를 발견, 분류 및 보호하기 위해 머신 러닝을 사용하는 데이터 보안 및 개인 정보 보호 서비스입니다. 웹 기반 공격으로부터 웹 애플리케이션을 보호하도록 설계되지 않았습니다.",
            "Amazon GuardDuty는 악의적인 활동 및 무단 행동을 지속적으로 모니터링하여 AWS 계정 및 워크로드를 보호하는 위협 탐지 서비스입니다. 전반적인 보안을 강화하지만, SQL 인젝션이나 크로스 사이트 스크립팅 공격에 대한 보호를 구체적으로 제공하지는 않습니다."
        ]
    },
    {
        "Question Number": "9",
        "Situation": "회사가 AWS에 다계층 웹 애플리케이션을 배포하고 있습니다. 이 애플리케이션은 Amazon EC2 인스턴스에서 프론트 엔드 레이어로 구성되고, Amazon RDS에서 백엔드 데이터베이스로 구성됩니다. 회사는 데이터베이스가 인터넷에서 직접 접근할 수 없고, 오직 프론트 엔드 레이어만 데이터베이스와 통신할 수 있도록 요구합니다.",
        "Question": "솔루션 아키텍트가 구현해야 할 네트워크 구성은 무엇입니까?",
        "Options": {
            "1": "프론트 엔드와 데이터베이스 레이어를 모두 퍼블릭 서브넷에 배치하고 보안 그룹을 사용하여 접근을 제한합니다.",
            "2": "프론트 엔드 레이어를 퍼블릭 서브넷에 배치하고 데이터베이스 레이어를 프라이빗 서브넷에 배치합니다. 보안 그룹을 구성하여 오직 프론트 엔드 인스턴스만 데이터베이스와 통신할 수 있도록 합니다.",
            "3": "두 레이어를 모두 프라이빗 서브넷에 배치하고 인터넷 액세스를 위해 NAT 게이트웨이를 사용합니다.",
            "4": "인터넷 게이트웨이와 라우팅 테이블을 사용하여 프론트 엔드와 데이터베이스 레이어 간의 접근을 제어합니다."
        },
        "Correct Answer": "프론트 엔드 레이어를 퍼블릭 서브넷에 배치하고 데이터베이스 레이어를 프라이빗 서브넷에 배치합니다. 보안 그룹을 구성하여 오직 프론트 엔드 인스턴스만 데이터베이스와 통신할 수 있도록 합니다.",
        "Explanation": "이 구성은 데이터베이스가 프라이빗 서브넷에 위치하여 인터넷에서 직접 접근할 수 없도록 보장합니다. 퍼블릭 서브넷에 있는 프론트 엔드 레이어는 보안 그룹을 통해 데이터베이스와 통신할 수 있으며, 이는 오직 프론트 엔드 인스턴스에서 오는 트래픽만 허용합니다. 이 설정은 AWS의 보안 및 아키텍처에 대한 모범 사례를 준수하여 데이터베이스가 외부 접근으로부터 보호되면서도 필요한 애플리케이션 레이어에 접근할 수 있도록 합니다.",
        "Other Options": [
            "프론트 엔드와 데이터베이스 레이어를 모두 퍼블릭 서브넷에 배치하면 데이터베이스가 인터넷에 노출되어 데이터베이스가 인터넷에서 직접 접근할 수 없다는 요구 사항을 위반합니다.",
            "두 레이어를 모두 프라이빗 서브넷에 배치하면 보안이 강화되지만, 추가 구성(예: NAT 게이트웨이)이 구현되지 않는 한 프론트 엔드 레이어가 데이터베이스와 통신할 수 없습니다. 이 시나리오에서는 프론트 엔드가 퍼블릭이어야 하므로 불필요합니다.",
            "인터넷 게이트웨이와 라우팅 테이블을 사용하여 접근을 제어하면 데이터베이스가 인터넷에 노출되어 데이터베이스를 인터넷에서 접근할 수 없도록 하는 요구 사항과 모순됩니다."
        ]
    },
    {
        "Question Number": "10",
        "Situation": "전자상거래 플랫폼이 데이터베이스를 AWS로 마이그레이션하려고 하지만 코드 변경을 최소화하고 싶어합니다. 기존 온프레미스 데이터베이스는 PostgreSQL이며, 고가용성과 읽기 확장을 지원하는 관리형 솔루션이 필요합니다.",
        "Question": "이 요구 사항을 가장 잘 충족하는 AWS의 데이터베이스 엔진은 무엇입니까?",
        "Options": {
            "1": "Amazon DynamoDB",
            "2": "Amazon Aurora with PostgreSQL compatibility",
            "3": "Amazon RDS for MySQL",
            "4": "Amazon DocumentDB"
        },
        "Correct Answer": "Amazon Aurora with PostgreSQL compatibility",
        "Explanation": "Amazon Aurora with PostgreSQL compatibility는 온프레미스 PostgreSQL 데이터베이스에서 마이그레이션하기에 가장 좋은 선택입니다. PostgreSQL과 호환되도록 설계되었기 때문에 마이그레이션 중 코드 변경이 최소화됩니다. Aurora는 또한 다중 AZ 배포를 통해 고가용성을 제공하고 읽기 복제본을 통해 읽기 확장 기능을 제공하여 신뢰할 수 있는 성능과 확장이 필요한 전자상거래 플랫폼에 적합합니다.",
        "Other Options": [
            "Amazon DynamoDB는 SQL 쿼리를 지원하지 않는 NoSQL 데이터베이스 서비스로, 기존 애플리케이션이 의존할 가능성이 있는 PostgreSQL 기능을 지원하지 않습니다. DynamoDB로 마이그레이션하려면 상당한 코드 변경과 애플리케이션의 완전한 재구성이 필요합니다.",
            "Amazon RDS for MySQL은 관리형 관계형 데이터베이스 서비스이지만 MySQL을 기반으로 하며 PostgreSQL이 아닙니다. RDS for MySQL로 마이그레이션하려면 애플리케이션을 MySQL 구문 및 기능에 맞게 조정하기 위해 상당한 코드 변경이 필요하므로 코드 변경을 최소화하는 데 이상적이지 않습니다.",
            "Amazon DocumentDB는 MongoDB와 호환되는 관리형 문서 데이터베이스 서비스입니다. DynamoDB와 마찬가지로 PostgreSQL과 호환되지 않으며 데이터 모델과 애플리케이션 코드를 완전히 재구성해야 하므로 이 마이그레이션 시나리오에 적합하지 않습니다."
        ]
    },
    {
        "Question Number": "11",
        "Situation": "한 회사가 고가용성 데이터베이스 솔루션을 위해 Amazon Aurora를 사용하려고 계획하고 있습니다. 그들은 스토리지 프로비저닝을 관리하지 않고도 빠른 읽기 성능과 향상된 가용성을 보장하고 싶어합니다.",
        "Question": "Amazon Aurora의 어떤 기능이 이 요구 사항에 적합하게 만들며, 그 아키텍처는 표준 RDS와 어떻게 다릅니까? (두 가지 선택)",
        "Options": {
            "1": "Aurora는 SSD 기반 스토리지를 사용하는 여러 가용 영역(AZ)에서 공유 클러스터 볼륨을 사용하여 높은 IOPS와 낮은 대기 시간을 가능하게 합니다. 쓰기 작업을 위한 클러스터 엔드포인트와 복제본 간의 읽기 트래픽을 분산시키기 위한 리더 엔드포인트를 포함하여 읽기 성능을 향상시킵니다.",
            "2": "Aurora는 각 인스턴스에 로컬 스토리지를 요구하므로 스토리지를 별도로 프로비저닝하고 관리해야 하며, 데이터 분배에 대한 더 나은 제어를 가능하게 합니다.",
            "3": "Aurora는 단일 AZ 내에서 수직으로 자동 확장되며, 여러 인스턴스나 복제본이 필요하지 않아 최소한의 설정으로 높은 가용성을 보장합니다.",
            "4": "Aurora는 수동 스토리지 관리를 의존하며, 기본 인스턴스가 읽기 및 쓰기 트래픽을 모두 처리해야 하므로 낮은 I/O 요구 사항을 가진 소규모 데이터베이스에만 적합합니다.",
            "5": "Aurora의 아키텍처는 컴퓨트와 스토리지를 분리하여 각각 독립적으로 확장할 수 있게 하며, 여러 AZ에 걸쳐 데이터를 복제하여 내장된 내결함성을 제공합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Aurora는 SSD 기반 스토리지를 사용하는 여러 가용 영역(AZ)에서 공유 클러스터 볼륨을 사용하여 높은 IOPS와 낮은 대기 시간을 가능하게 합니다. 쓰기 작업을 위한 클러스터 엔드포인트와 복제본 간의 읽기 트래픽을 분산시키기 위한 리더 엔드포인트를 포함하여 읽기 성능을 향상시킵니다.",
            "Aurora의 아키텍처는 컴퓨트와 스토리지를 분리하여 각각 독립적으로 확장할 수 있게 하며, 여러 AZ에 걸쳐 데이터를 복제하여 내장된 내결함성을 제공합니다."
        ],
        "Explanation": "Amazon Aurora는 높은 가용성과 내구성을 위해 설계되었습니다. 여러 가용 영역에 걸쳐 데이터베이스의 복사본을 가진 공유 클러스터 볼륨을 사용합니다. 이 아키텍처는 높은 IOPS와 낮은 대기 시간을 가능하게 하여 읽기 성능을 향상시킵니다. Aurora는 또한 컴퓨트와 스토리지를 분리하여 각각 독립적으로 확장할 수 있게 하며, 이 분리는 여러 AZ에 걸쳐 데이터를 복제하여 내장된 내결함성을 제공합니다.",
        "Other Options": [
            "Aurora는 각 인스턴스에 로컬 스토리지를 요구하지 않습니다. 대신, 여러 AZ에 걸쳐 있는 공유 스토리지 볼륨을 사용합니다. 따라서 스토리지를 별도로 프로비저닝하고 관리할 필요가 없습니다.",
            "Aurora는 단일 AZ 내에서 수직으로 자동 확장되지 않습니다. 대신, 여러 AZ에 걸쳐 분산 아키텍처를 사용합니다. 이 아키텍처는 높은 가용성과 내결함성을 제공합니다.",
            "Aurora는 수동 스토리지 관리를 의존하지 않습니다. 대신, 필요에 따라 스토리지를 자동으로 관리하고 확장합니다. 기본 인스턴스는 읽기 및 쓰기 트래픽을 모두 처리할 필요가 없으며, Aurora는 쓰기 작업을 위한 클러스터 엔드포인트와 읽기 작업을 위한 리더 엔드포인트를 제공합니다."
        ]
    },
    {
        "Question Number": "12",
        "Situation": "소셜 미디어 애플리케이션이 사용자 게시물을 저장하고 있으며, 고용량 읽기 작업과 빈번한 쓰기 업데이트를 위해 데이터베이스를 최적화해야 합니다. 이 애플리케이션은 사용자 참여에 대한 실시간 분석도 필요합니다.",
        "Question": "혼합 접근 패턴을 효율적으로 처리하기 위해 솔루션 아키텍트가 추천해야 할 데이터베이스 솔루션은 무엇입니까?",
        "Options": {
            "1": "Amazon RDS for PostgreSQL와 읽기 복제본, Amazon Redshift를 통한 분석.",
            "2": "Amazon DynamoDB와 프로비저닝된 용량, AWS Lambda와 통합된 DynamoDB Streams를 통한 실시간 처리.",
            "3": "읽기 및 쓰기 작업을 처리하기 위한 다중 마스터 구성의 Amazon Aurora Serverless.",
            "4": "쿼리를 위한 Amazon S3와 실시간 분석을 위한 Amazon Athena 및 Amazon Kinesis."
        },
        "Correct Answer": "Amazon DynamoDB와 프로비저닝된 용량, AWS Lambda와 통합된 DynamoDB Streams를 통한 실시간 처리.",
        "Explanation": "Amazon DynamoDB는 읽기 및 쓰기 작업 모두에 대해 높은 성능을 제공하는 완전 관리형 NoSQL 데이터베이스 서비스로, 혼합 접근 패턴을 가진 애플리케이션에 이상적입니다. 프로비저닝된 용량은 애플리케이션의 필요에 따라 확장을 가능하게 하여 고용량 읽기 작업을 효율적으로 처리할 수 있도록 합니다. 또한, DynamoDB Streams는 데이터베이스의 항목 변경 사항을 캡처하여 AWS Lambda 함수를 트리거하여 사용자 참여에 대한 실시간 처리 및 분석을 수행할 수 있습니다. 이 조합은 효율적인 데이터 저장과 실시간 분석을 가능하게 하여 애플리케이션의 요구 사항을 효과적으로 충족합니다.",
        "Other Options": [
            "Amazon RDS for PostgreSQL와 읽기 복제본, Amazon Redshift를 통한 분석은 최선의 선택이 아닙니다. RDS는 읽기 복제본으로 읽기 작업을 처리할 수 있지만, DynamoDB에 비해 고용량 쓰기 작업에 대해 효율적으로 확장되지 않을 수 있습니다. 또한, Redshift를 분석에 사용하면 배치 처리에 최적화되어 실시간 분석에 비해 지연이 발생합니다.",
            "다중 마스터 구성의 Amazon Aurora Serverless는 읽기 및 쓰기 작업을 처리할 수 있지만, DynamoDB만큼 고용량 접근 패턴에 대한 확장성과 성능을 제공하지 않을 수 있습니다. Aurora는 관계형 데이터에 더 적합하며, DynamoDB의 Lambda 통합에 비해 실시간 분석에 덜 효율적일 수 있습니다.",
            "쿼리를 위한 Amazon S3와 실시간 분석을 위한 Amazon Athena 및 Amazon Kinesis 조합은 적합하지 않습니다. S3는 주로 스토리지 서비스이며 고빈도 쓰기 작업을 효율적으로 지원하지 않습니다. Kinesis는 실시간 데이터 스트림을 처리할 수 있지만, 이 조합은 DynamoDB가 제공하는 혼합 접근 패턴에 대한 강력한 솔루션을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "13",
        "Situation": "여러 부서를 가진 대기업이 각 비즈니스 유닛에 대해 별도의 AWS 계정을 사용하고 있으며, 네트워크 관련 비용을 모니터링하고 제어하고 싶어합니다. 그들은 VPC, NAT 게이트웨이 및 데이터 전송 비용과 같은 네트워크 비용을 적절한 부서에 식별하고 할당할 수 있는 방법이 필요하여 조직 전반에 걸쳐 정확한 비용 분배와 책임을 보장하고자 합니다.",
        "Question": "이 목표를 달성하는 데 가장 도움이 되는 AWS 비용 관리 기능은 무엇입니까?",
        "Options": {
            "1": "네트워크 리소스에 대한 비용 할당 태그를 활성화하여 부서별로 태그를 할당하여 네트워크 관련 비용을 정확하게 할당합니다.",
            "2": "각 부서에 대해 별도의 가상 사설 클라우드(VPC)를 설정하고 각 VPC의 비용을 개별적으로 모니터링합니다.",
            "3": "AWS Trusted Advisor를 사용하여 네트워크 사용을 정기적으로 모니터링하고 최적화하며 비용 절감에 대한 권장 사항을 얻습니다.",
            "4": "각 부서에 대해 서로 다른 가용 영역을 설정하여 각 영역의 데이터 전송 비용을 추적합니다."
        },
        "Correct Answer": "네트워크 리소스에 대한 비용 할당 태그를 활성화하여 부서별로 태그를 할당하여 네트워크 관련 비용을 정확하게 할당합니다.",
        "Explanation": "네트워크 리소스에 대한 비용 할당 태그를 활성화하면 기업이 특정 부서와 관련된 비용을 분류하고 추적할 수 있습니다. VPC, NAT 게이트웨이 및 데이터 전송과 같은 리소스에 태그를 할당함으로써 조직은 각 부서에서 발생한 비용을 반영하는 상세한 비용 보고서를 생성할 수 있습니다. 이 방법은 네트워크 관련 비용을 할당하는 명확하고 조직적인 방법을 제공하여 비즈니스 유닛 간의 책임과 투명성을 보장합니다.",
        "Other Options": [
            "각 부서에 대해 별도의 가상 사설 클라우드(VPC)를 설정하는 것은 리소스를 격리하는 데 도움이 될 수 있지만, 비용 추적 및 할당을 위한 메커니즘을 본질적으로 제공하지 않습니다. 태그나 비용 관리 전략이 없으면 부서 간 비용을 정확하게 분배하기 어려울 것입니다.",
            "AWS Trusted Advisor를 사용하면 리소스 사용 최적화 및 비용 절감에 대한 통찰력과 권장 사항을 제공할 수 있지만, 특정 부서에 비용을 직접 할당하지는 않습니다. 이는 자세한 비용 추적 및 할당보다는 모범 사례 및 비용 최적화에 더 중점을 둡니다.",
            "각 부서에 대해 서로 다른 가용 영역을 설정하는 것은 데이터 전송 비용 추적과 직접적인 관련이 없습니다. 가용 영역은 주로 중복성과 가용성에 관한 것이며, 비용 할당과는 관련이 없습니다. 데이터 전송 비용은 일반적으로 사용된 리소스와 그 구성에 따라 발생하며, 영역 자체와는 관련이 없습니다."
        ]
    },
    {
        "Question Number": "14",
        "Situation": "한 스타트업이 다양한 IoT 장치에서 실시간 메트릭을 표시하는 대시보드를 개발하고 있습니다. 대시보드는 신속한 데이터 수집과 최신 메트릭에 대한 저지연 액세스가 필요하여 적시 업데이트를 보장해야 합니다. 이 솔루션은 장치 수가 증가함에 따라 다양한 데이터 볼륨을 처리할 수 있어야 합니다.",
        "Question": "이러한 크기와 속도 요구 사항을 충족하기 위해 솔루션 아키텍트가 어떤 AWS 서비스를 사용해야 합니까? (두 가지 선택)",
        "Options": {
            "1": "Amazon S3와 Amazon Athena",
            "2": "Amazon Kinesis Data Streams",
            "3": "AWS Batch와 Amazon EC2 스팟 인스턴스",
            "4": "읽기 복제본이 있는 Amazon RDS",
            "5": "DynamoDB와 DynamoDB Streams"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon Kinesis Data Streams",
            "DynamoDB와 DynamoDB Streams"
        ],
        "Explanation": "Amazon Kinesis Data Streams는 실시간 데이터 스트리밍을 위해 설계되었습니다. 수백만 개의 소스에서 초당 기가바이트의 데이터를 지속적으로 캡처할 수 있어 대시보드에서 요구하는 신속한 데이터 수집과 저지연 액세스를 처리하는 데 적합합니다. DynamoDB와 DynamoDB Streams도 적합한 선택으로, 데이터에 대한 저지연 액세스를 제공하고 높은 트래픽 부하를 처리할 수 있어 장치 수가 증가할 때 유용합니다. DynamoDB Streams는 DynamoDB 테이블의 항목 수준 수정 사항을 시간 순서대로 캡처하고 이 데이터를 24시간 동안 저장합니다.",
        "Other Options": [
            "Amazon S3와 Amazon Athena 조합은 대규모 데이터 세트를 저장하고 쿼리하는 데 더 적합하며, 실시간 데이터 수집 및 저지연 액세스에는 적합하지 않습니다.",
            "AWS Batch와 Amazon EC2 스팟 인스턴스는 배치 처리 작업에 더 적합하며, 실시간 데이터 수집 및 저지연 액세스에는 적합하지 않습니다.",
            "읽기 복제본이 있는 Amazon RDS는 읽기 트래픽을 분산하는 데 도움이 될 수 있지만, 수천 개의 장치에서 발생하는 다양한 데이터 볼륨을 처리하거나 실시간 데이터 수집을 위해 설계되지 않았습니다."
        ]
    },
    {
        "Question Number": "15",
        "Situation": "소셜 미디어 애플리케이션은 높은 볼륨의 읽기 요청을 가지고 있으며, 사용자가 프로필 정보와 뉴스 피드를 자주 검색합니다. 이 애플리케이션은 현재 각 읽기 요청에 대해 Amazon Aurora 데이터베이스를 직접 쿼리하여 지연 문제에 직면해 있습니다. 개발 팀은 읽기 성능을 개선하고 데이터베이스 부하를 비용 효율적으로 줄이기를 원하며, 약간의 애플리케이션 변경을 기꺼이 수용합니다.",
        "Question": "솔루션 아키텍트가 추천해야 할 솔루션은 무엇입니까?",
        "Options": {
            "1": "Amazon ElastiCache와 Redis를 구현하여 자주 액세스되는 데이터를 캐시하고 데이터베이스 쿼리를 줄입니다.",
            "2": "Amazon Aurora 데이터베이스에서 읽기 복제본을 활성화하여 읽기 부하를 분산합니다.",
            "3": "Amazon RDS Proxy를 사용하여 데이터베이스 연결을 풀링하고 공유하여 성능을 개선합니다.",
            "4": "자주 액세스되는 데이터를 Amazon S3에 저장하고 애플리케이션에서 직접 액세스합니다."
        },
        "Correct Answer": "Amazon ElastiCache와 Redis를 구현하여 자주 액세스되는 데이터를 캐시하고 데이터베이스 쿼리를 줄입니다.",
        "Explanation": "Amazon ElastiCache와 Redis를 구현하는 것은 읽기 성능을 개선하고 Amazon Aurora 데이터베이스의 부하를 줄이는 가장 효과적인 솔루션입니다. 사용자 프로필 및 뉴스 피드와 같은 자주 액세스되는 데이터를 캐시함으로써 애플리케이션은 각 요청에 대해 데이터베이스를 쿼리하는 대신 캐시에서 직접 읽기 요청을 처리할 수 있습니다. 이는 지연 시간과 데이터베이스 부하를 크게 줄여 비용 절감과 사용자 경험 개선으로 이어집니다. ElastiCache는 고속 데이터 검색을 위해 설계되어 높은 읽기 요청 볼륨을 가진 애플리케이션에 이상적입니다.",
        "Other Options": [
            "Amazon Aurora 데이터베이스에서 읽기 복제본을 활성화하면 읽기 부하를 분산하는 데 도움이 될 수 있지만, 캐싱만큼 효과적으로 지연 문제를 해결하지는 못합니다. 읽기 복제본은 여전히 비용이 발생할 수 있으며, 고용량 읽기 요청에 필요한 즉각적인 성능 개선을 제공하지 않을 수 있습니다.",
            "Amazon RDS Proxy를 사용하여 데이터베이스 연결을 풀링하고 공유하면 연결을 설정하는 오버헤드를 줄여 성능을 개선할 수 있지만, 데이터베이스에 전송되는 읽기 쿼리 수를 직접 줄이지는 않습니다. 이 옵션은 연결 관리에 도움이 될 수 있지만, 높은 읽기 요청 볼륨으로 인한 기본 지연 문제를 해결하지는 않습니다.",
            "자주 액세스되는 데이터를 Amazon S3에 저장하고 애플리케이션에서 직접 액세스하는 것은 실시간 데이터 검색에 이상적이지 않습니다. S3는 객체 저장소로 설계되어 추가 지연을 초래할 수 있습니다. 이 접근 방식은 정적 콘텐츠에 더 적합하며, 빈번한 업데이트가 필요한 동적 데이터에는 덜 효과적입니다."
        ]
    },
    {
        "Question Number": "16",
        "Situation": "한 금융 회사는 민감한 고객 데이터를 저장하고 처리하기 위해 높은 IOPS, 낮은 대기 시간 및 기본 Windows 파일 시스템 기능을 지원하는 AWS의 완전 관리형 파일 저장 솔루션이 필요합니다. 이 시스템은 SMB를 통한 안전한 액세스를 제공하고 사용자 인증을 위해 회사의 온프레미스 Active Directory와 통합되어야 합니다.",
        "Question": "어떤 AWS 서비스 구성이 이러한 요구 사항을 가장 잘 충족합니까? (두 가지 선택하세요.)",
        "Options": {
            "1": "고속 액세스를 위한 Amazon S3와 Transfer Acceleration",
            "2": "Multi-AZ 배포에서 Amazon FSx for Windows File Server",
            "3": "암호화된 Amazon EFS (정지 및 전송 중)",
            "4": "캐시된 볼륨을 가진 AWS Storage Gateway",
            "5": "Active Directory 통합을 가진 Amazon FSx for NetApp ONTAP"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Multi-AZ 배포에서 Amazon FSx for Windows File Server",
            "캐시된 볼륨을 가진 AWS Storage Gateway"
        ],
        "Explanation": "Multi-AZ 배포에서 Amazon FSx for Windows File Server는 높은 IOPS, 낮은 대기 시간 및 기본 Windows 파일 시스템 기능을 지원하는 완전 관리형 Microsoft Windows 파일 시스템입니다. 또한 SMB를 통한 안전한 액세스를 제공하고 온프레미스 Active Directory와 통합되어 사용자 인증을 지원하여 모든 요구 사항을 충족합니다. 캐시된 볼륨을 가진 AWS Storage Gateway는 자주 액세스되는 데이터를 로컬에 저장하면서 Amazon S3에 모든 데이터를 유지하여 온프레미스 애플리케이션에서 AWS의 데이터에 대한 낮은 대기 시간 액세스를 제공할 수 있습니다. 또한 사용자 인증을 위해 온프레미스 Active Directory와 통합됩니다.",
        "Other Options": [
            "고속 액세스를 위한 Amazon S3와 Transfer Acceleration은 기본 Windows 파일 시스템 기능과 SMB 프로토콜을 지원하지 않습니다. 또한 사용자 인증을 위해 온프레미스 Active Directory와 통합되지 않습니다.",
            "정지 및 전송 중 암호화된 Amazon EFS는 높은 IOPS, 낮은 대기 시간을 위해 설계되지 않았으며 기본 Windows 파일 시스템 기능이나 SMB 프로토콜을 지원하지 않습니다.",
            "Active Directory 통합을 가진 Amazon FSx for NetApp ONTAP는 SMB 프로토콜을 지원하고 온프레미스 Active Directory와 통합되는 완전 관리형 파일 시스템 서비스이지만 기본 Windows 파일 시스템 기능을 지원하지 않습니다."
        ]
    },
    {
        "Question Number": "17",
        "Situation": "한 회사는 EC2 인스턴스에서 애플리케이션 로드 밸런서(ALB) 뒤에서 웹 애플리케이션을 실행하고 있습니다. 이 애플리케이션은 URL 경로에 따라 트래픽을 라우팅해야 하며, 특정 서비스가 특정 유형의 요청을 처리해야 합니다. 또한 트래픽이 인스턴스 간에 고르게 분배되어야 하며, 고트래픽 기간 동안 한 인스턴스가 과부하되지 않도록 해야 합니다.",
        "Question": "회사가 효율적인 로드 밸런싱을 달성하기 위해 적용해야 할 구성은 무엇입니까?",
        "Options": {
            "1": "ALB를 경로 기반 라우팅으로 구성하여 URL 경로에 따라 서로 다른 대상 그룹으로 트래픽을 유도하고 각 그룹의 EC2 인스턴스 간에 트래픽이 고르게 분배되도록 합니다.",
            "2": "ALB를 구성하여 모든 트래픽을 단일 EC2 인스턴스로 라우팅하여 단순성을 추구하되, 피크 트래픽 시간 동안 인스턴스 크기를 늘리기 위해 Auto Scaling을 사용합니다.",
            "3": "경로 기반 라우팅을 지원하고 여러 애플리케이션 엔드포인트에 따라 트래픽을 분배하기 위해 Classic Load Balancer(CL) 대신 ALB를 사용합니다.",
            "4": "각기 다른 애플리케이션 도메인에 대해 트래픽을 제공하는 여러 ALB를 설정하고 트래픽 패턴에 따라 각 ALB로 수동으로 트래픽을 유도합니다."
        },
        "Correct Answer": "ALB를 경로 기반 라우팅으로 구성하여 URL 경로에 따라 서로 다른 대상 그룹으로 트래픽을 유도하고 각 그룹의 EC2 인스턴스 간에 트래픽이 고르게 분배되도록 합니다.",
        "Explanation": "ALB를 경로 기반 라우팅으로 구성하면 회사는 들어오는 요청의 URL 경로에 따라 트래픽을 서로 다른 대상 그룹으로 유도할 수 있습니다. 이는 특정 서비스가 특정 유형의 요청을 처리할 수 있도록 하여 애플리케이션 아키텍처에 필수적입니다. 또한 ALB는 각 대상 그룹의 EC2 인스턴스 간에 트래픽을 자동으로 균형 있게 분배하여 고트래픽 기간 동안 단일 인스턴스가 과부하되지 않도록 합니다. 이 구성은 트래픽을 효율적으로 관리하고 애플리케이션 성능을 유지하는 데 최적입니다.",
        "Other Options": [
            "ALB를 구성하여 모든 트래픽을 단일 EC2 인스턴스로 라우팅하는 것은 로드 밸런싱의 목적에 어긋나는 비효율적인 솔루션입니다. 이는 피크 트래픽 시간 동안 단일 인스턴스에 과부하가 걸릴 수 있으며, 여러 인스턴스를 활용하는 이점을 활용하지 못합니다.",
            "ALB 대신 Classic Load Balancer(CL)를 사용하는 것은 잘못된 선택입니다. CL은 경로 기반 라우팅을 지원하지 않으며, ALB는 경로 기반 라우팅을 포함한 고급 라우팅 기능을 위해 특별히 설계되었습니다.",
            "여러 ALB를 설정하고 각 ALB로 수동으로 트래픽을 유도하는 것은 아키텍처에 불필요한 복잡성을 추가합니다. 여러 서비스의 트래픽을 관리하기 위해 경로 기반 라우팅을 사용하는 단일 ALB를 사용하는 것이 더 효율적이며, 구성 단순화와 운영 오버헤드를 줄일 수 있습니다."
        ]
    },
    {
        "Question Number": "18",
        "Situation": "한 조직은 AWS Organizations를 사용하고 있으며, 여러 계정에 걸쳐 특정 작업을 방지하기 위해 권한 경계를 구현하고자 합니다. 이는 전체 관리 액세스 권한을 가진 사용자에게도 적용됩니다. 조직은 관리 오버헤드를 낮게 유지하고 싶어합니다.",
        "Question": "어떤 유형의 서비스 제어 정책(SCP) 아키텍처가 이러한 요구 사항을 가장 잘 충족하며, 조직 내 IAM 사용자 권한에 어떤 영향을 미칠까요?",
        "Options": {
            "1": "특정 서비스만 명시적으로 허용하는 허용 목록 아키텍처를 사용하여 보안을 강화하고 더 많은 제어를 제공합니다.",
            "2": "특정 작업을 거부하고 기본적으로 모든 작업을 허용하는 거부 목록 아키텍처를 사용하여 관리 오버헤드를 최소화합니다.",
            "3": "모든 작업을 명시적으로 거부하고 필요한 각 서비스에 대한 권한을 수동으로 추가해야 하는 거부 목록 아키텍처를 사용합니다.",
            "4": "루트 사용자만 작업을 허용하는 허용 목록 아키텍처를 사용하여 조직 내 모든 IAM 사용자에 대한 권한을 차단합니다."
        },
        "Correct Answer": "특정 작업을 거부하고 기본적으로 모든 작업을 허용하는 거부 목록 아키텍처를 사용하여 관리 오버헤드를 최소화합니다.",
        "Explanation": "거부 목록 아키텍처는 조직이 거부해야 할 작업만 지정할 수 있게 해주며, 모든 다른 작업은 기본적으로 허용됩니다. 이 접근 방식은 허용된 작업의 광범위한 목록을 관리할 필요가 없으므로 관리 오버헤드를 최소화합니다. 대신, 조직은 위험을 초래하는 특정 작업을 식별하고 거부하는 데 집중할 수 있어 IAM 사용자가 불필요한 제한 없이 작업을 수행할 수 있는 유연성을 유지합니다.",
        "Other Options": [
            "허용 목록 아키텍처를 사용하면 조직이 특정 서비스만 명시적으로 정의하고 허용해야 하므로, 새로운 서비스가 도입되거나 기존 서비스가 수정될 때마다 허용된 서비스 목록을 지속적으로 업데이트해야 하므로 관리 오버헤드가 증가할 수 있습니다.",
            "모든 작업을 명시적으로 거부하는 거부 목록 아키텍처는 지나치게 제한적이고 비현실적이며, 필요한 각 서비스에 대한 권한을 수동으로 추가해야 하므로 상당한 관리 오버헤드를 초래하고 생산성을 저해할 수 있습니다.",
            "루트 사용자만 작업을 허용하는 허용 목록 아키텍처를 사용하면 조직 내 모든 IAM 사용자에 대한 권한이 차단되어, 관리 액세스 권한이 있는 사용자가 자신의 업무를 수행할 수 없게 됩니다. 이는 권한 경계를 구현하면서도 IAM 사용자가 필요한 작업을 수행할 수 있도록 하는 조직의 목표에 부합하지 않습니다."
        ]
    },
    {
        "Question Number": "19",
        "Situation": "한 회사는 AWS Key Management Service(KMS)를 사용하여 민감한 데이터를 보호하고 있습니다. 이 회사는 이 데이터를 암호화하는 데 사용되는 키가 AWS 내에서 안전하게 관리되고 저장되며, AWS 환경을 벗어나지 않도록 하기를 원합니다.",
        "Question": "AWS KMS의 어떤 특성이 암호화 키가 안전하게 유지되고 AWS 인프라 내에 남아 있도록 보장하며, 어떤 유형의 암호화를 지원합니까?",
        "Options": {
            "1": "KMS 키는 전용 KMS 리전 내에서 격리되어 있으며 대칭 암호화만 지원합니다.",
            "2": "KMS 키는 AWS KMS를 벗어나지 않으며 대칭 및 비대칭 암호화를 모두 지원합니다.",
            "3": "KMS 키는 외부 사용을 위해 AWS에서 내보낼 수 있으며 비대칭 암호화만 지원합니다.",
            "4": "KMS 키는 여러 AWS 계정 간에 공유되며 대칭 암호화만 지원합니다."
        },
        "Correct Answer": "KMS 키는 AWS KMS를 벗어나지 않으며 대칭 및 비대칭 암호화를 모두 지원합니다.",
        "Explanation": "AWS Key Management Service(KMS)는 AWS 환경 내에서 암호화 키를 안전하게 관리하도록 설계되었습니다. 그 주요 특성 중 하나는 암호화 키가 AWS 인프라 외부에 노출되지 않도록 하여 안전성을 보장하는 것입니다. 또한 AWS KMS는 대칭 암호화(암호화와 복호화에 동일한 키를 사용하는 방식)와 비대칭 암호화(키 쌍을 사용하는 방식)를 모두 지원합니다. 이러한 유연성은 사용자가 보안 요구 사항에 따라 적절한 암호화 방법을 선택할 수 있게 해줍니다.",
        "Other Options": [
            "KMS 키는 전용 KMS 리전 내에서 격리되어 있으며 대칭 암호화만 지원합니다. 이 옵션은 KMS 키가 리전 특정이긴 하지만 대칭 및 비대칭 암호화를 모두 지원하므로 잘못된 것입니다.",
            "KMS 키는 외부 사용을 위해 AWS에서 내보낼 수 있으며 비대칭 암호화만 지원합니다. 이 옵션은 KMS 키가 외부 사용을 위해 내보낼 수 없으며 AWS 내에 남아 있도록 설계되었기 때문에 잘못된 것입니다. 또한 KMS는 비대칭 암호화뿐만 아니라 대칭 암호화도 지원합니다.",
            "KMS 키는 여러 AWS 계정 간에 공유되며 대칭 암호화만 지원합니다. 이 옵션은 KMS 키가 리소스 정책을 통해 계정 간에 공유될 수 있지만 대칭 및 비대칭 암호화를 모두 지원하므로 잘못된 것입니다."
        ]
    },
    {
        "Question Number": "20",
        "Situation": "한 회사는 여러 가용 영역(AZ)에 걸쳐 애플리케이션 로드 밸런서(ALB)를 배포하고 수신 트래픽을 분산하기 위해 교차 영역 로드 밸런싱을 활성화했습니다.",
        "Question": "교차 영역 로드 밸런싱이 로드 분배를 어떻게 개선하며, 한 AZ에서 트래픽 급증을 처리하는 데 어떤 이점을 제공합니까?",
        "Options": {
            "1": "교차 영역 로드 밸런싱은 각 로드 밸런서 노드가 자신의 AZ 내의 대상에게만 트래픽을 라우팅할 수 있게 하여 AZ 실패 시 격리 및 복원력을 제공합니다.",
            "2": "교차 영역 로드 밸런싱은 각 로드 밸런서 노드가 모든 AZ의 대상 간에 트래픽을 고르게 라우팅할 수 있게 하여 더 균형 잡힌 로드 분배를 보장하고 한 AZ의 대상이 과부하되는 위험을 줄입니다.",
            "3": "교차 영역 로드 밸런싱은 요청당 단일 대상에게만 트래픽을 라우팅하여 대기 시간을 줄이고 각 AZ의 사용자 성능을 개선합니다.",
            "4": "교차 영역 로드 밸런싱은 단일 AZ 설정에서만 효과적이며 여러 AZ가 관련될 때는 영향을 미치지 않습니다."
        },
        "Correct Answer": "교차 영역 로드 밸런싱은 각 로드 밸런서 노드가 모든 AZ의 대상 간에 트래픽을 고르게 라우팅할 수 있게 하여 더 균형 잡힌 로드 분배를 보장하고 한 AZ의 대상이 과부하되는 위험을 줄입니다.",
        "Explanation": "교차 영역 로드 밸런싱은 애플리케이션 로드 밸런서가 다양한 가용 영역에 등록된 모든 대상 간에 수신 트래픽을 고르게 분배할 수 있게 해줍니다. 이는 한 AZ에서 트래픽이 급증할 경우 로드 밸런서가 다른 AZ의 대상에게 트래픽을 유도할 수 있게 하여 단일 AZ가 병목 현상이 되는 것을 방지합니다. 이 기능은 특히 트래픽 급증 시 애플리케이션의 전반적인 복원력과 성능을 향상시킵니다.",
        "Other Options": [
            "교차 영역 로드 밸런싱은 각 로드 밸런서 노드가 자신의 AZ 내의 대상에게만 트래픽을 라우팅할 수 있게 하여 AZ 실패 시 격리 및 복원력을 제공합니다. 이는 잘못된 것입니다. 교차 영역 로드 밸런싱은 여러 AZ 간에 트래픽을 라우팅할 수 있도록 하며, 단일 AZ 내에서만 라우팅하는 것이 아닙니다.",
            "이 옵션은 교차 영역 로드 밸런싱의 기능을 잘못 설명하고 있습니다. 로드 밸런싱의 목표는 균형 잡힌 로드를 유지하는 것이지만, 이는 모든 AZ 간에 트래픽을 분배하여 이루어집니다.",
            "이 옵션은 교차 영역 로드 밸런싱이 요청당 단일 대상에게만 트래픽을 제한하지 않기 때문에 잘못된 것입니다. 대신, 여러 대상 간에 트래픽을 분배하여 로드를 효과적으로 관리하고 성능을 개선합니다."
        ]
    },
    {
        "Question Number": "21",
        "Situation": "소셜 미디어 플랫폼은 부적절한 게시물을 신속하게 감지하고 대응하기 위해 사용자 생성 콘텐츠를 실시간으로 모니터링하고 분석하고자 합니다. 이 플랫폼은 수백만 명의 사용자로부터 동시에 지속적인 데이터 스트림을 처리할 수 있는 확장 가능한 솔루션이 필요합니다.",
        "Question": "이 시나리오에서 스트리밍 데이터 처리를 위해 솔루션 아키텍트가 추천해야 할 AWS 서비스는 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "Amazon Simple Queue Service (SQS)",
            "2": "Amazon Kinesis Data Streams",
            "3": "Amazon Managed Streaming for Apache Kafka (MSK)",
            "4": "AWS Lambda와 예약 트리거",
            "5": "Amazon EventBridge"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "Amazon Kinesis Data Streams",
            "Amazon Managed Streaming for Apache Kafka (MSK)"
        ],
        "Explanation": "Amazon Kinesis Data Streams는 실시간 스트리밍 데이터를 수집, 처리 및 분석하도록 설계되어 있어 적시에 통찰력을 얻고 새로운 정보에 신속하게 반응할 수 있습니다. 이는 스트리밍 데이터의 양에 관계없이 처리할 수 있으며, 수십만 개의 소스에서 매우 낮은 지연으로 데이터를 처리할 수 있습니다. Amazon Managed Streaming for Apache Kafka (MSK)는 Apache Kafka를 사용하여 스트리밍 데이터를 처리하는 애플리케이션을 쉽게 구축하고 실행할 수 있도록 하는 완전 관리형 서비스입니다. 이는 대량의 실시간 데이터 처리 작업에 매우 적합합니다.",
        "Other Options": [
            "Amazon Simple Queue Service (SQS)는 마이크로서비스, 분산 시스템 및 서버리스 애플리케이션을 분리하고 확장할 수 있도록 하는 완전 관리형 메시지 큐 서비스입니다. 그러나 이는 실시간 스트리밍 데이터 처리에 적합하지 않습니다.",
            "AWS Lambda와 예약 트리거는 서버를 프로비저닝하거나 관리하지 않고 코드를 실행할 수 있는 컴퓨팅 서비스입니다. Lambda는 실시간 파일 변경을 처리할 수 있지만, '예약 트리거' 옵션은 시나리오의 실시간 요구 사항에 맞지 않습니다.",
            "Amazon EventBridge는 자체 애플리케이션, 통합된 소프트웨어 서비스(SaaS) 애플리케이션 및 AWS 서비스의 데이터를 사용하여 애플리케이션을 쉽게 연결할 수 있는 서버리스 이벤트 버스입니다. 이는 실시간 스트리밍 데이터 처리를 위해 특별히 설계되지 않았습니다."
        ]
    },
    {
        "Question Number": "22",
        "Situation": "회사는 AWS Key Management Service (KMS)를 사용하여 4 KB를 초과하는 대용량 파일을 암호화해야 합니다. 암호화 프로세스는 즉시 사용할 수 있는 평문 버전과 암호화된 데이터와 함께 저장할 안전한 버전을 포함해야 합니다.",
        "Question": "회사가 이러한 요구 사항을 충족하기 위해 어떤 KMS 기능을 사용해야 하며, 4 KB보다 큰 데이터의 암호화를 어떻게 처리합니까?",
        "Options": {
            "1": "KMS 키를 직접 사용하여 데이터를 암호화합니다. KMS는 추가 단계 없이 모든 크기의 파일을 지원합니다.",
            "2": "KMS로 데이터 암호화 키(DEK)를 생성하고, 평문 DEK를 사용하여 데이터를 암호화한 후 암호문 DEK를 암호화된 데이터와 함께 저장합니다.",
            "3": "고객 관리 KMS 키와 사용자 지정 정책을 사용하여 대용량 파일 암호화를 허용하고 평문 및 암호문 복사본을 모두 유지합니다.",
            "4": "데이터를 4 KB 청크로 나누어 KMS에서 직접 암호화하고 각 청크를 별도로 암호화한 후 복호화 후 재조립합니다."
        },
        "Correct Answer": "KMS로 데이터 암호화 키(DEK)를 생성하고, 평문 DEK를 사용하여 데이터를 암호화한 후 암호문 DEK를 암호화된 데이터와 함께 저장합니다.",
        "Explanation": "AWS Key Management Service (KMS)는 직접 암호화 작업에 대해 4 KB의 제한이 있습니다. 더 큰 파일을 암호화하기 위해 권장되는 방법은 KMS를 사용하여 데이터 암호화 키(DEK)를 생성하는 것입니다. 그런 다음 DEK를 사용하여 데이터를 암호화하여 4 KB보다 큰 파일의 암호화를 가능하게 합니다. 평문 DEK는 즉시 복호화에 사용될 수 있으며, 암호문 DEK(암호화된 KMS 키로 암호화됨)는 안전한 접근을 위해 암호화된 데이터와 함께 저장됩니다. 이 방법은 대용량 파일에 대한 암호화 프로세스가 효율적이고 확장 가능하도록 보장합니다.",
        "Other Options": [
            "KMS 키를 직접 사용하여 데이터를 암호화하는 것은 KMS의 암호화 작업에 대한 크기 제한이 4 KB이기 때문에 잘못된 것입니다. 이보다 큰 파일은 DEK를 사용하는 등 다른 방식으로 처리해야 합니다.",
            "DEK를 생성하는 것은 올바르지만, 이 옵션은 DEK가 암호화된 데이터와 함께 암호문으로 저장되어야 한다고 명시하지 않습니다. 이는 보안을 유지하고 나중에 복호화를 허용하는 데 중요합니다.",
            "고객 관리 KMS 키와 사용자 지정 정책을 사용하는 것은 KMS 암호화의 크기 제한을 직접 해결하지 않습니다. 대용량 파일을 암호화하는 방법은 키 관리 정책과 관계없이 여전히 DEK를 사용해야 합니다."
        ]
    },
    {
        "Question Number": "23",
        "Situation": "회사는 AWS 환경이 보안 모범 사례 및 규정 준수 표준을 준수하도록 보장해야 합니다. 회사는 잠재적인 보안 취약점을 감지하고 규정 준수를 보장하기 위해 AWS 리소스를 지속적으로 모니터링하고자 합니다.",
        "Question": "솔루션 아키텍트가 추천해야 할 AWS 서비스는 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "AWS Config",
            "2": "Amazon GuardDuty",
            "3": "AWS Security Hub",
            "4": "AWS CloudTrail",
            "5": "AWS Shield Advanced"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "AWS Security Hub",
            "Amazon GuardDuty"
        ],
        "Explanation": "AWS Security Hub는 AWS 계정 전반에 걸쳐 고우선 보안 경고 및 규정 준수 상태에 대한 포괄적인 뷰를 제공합니다. 이는 Amazon GuardDuty, Amazon Inspector 및 Amazon Macie와 같은 여러 AWS 서비스 및 AWS 파트너 솔루션에서 보안 경고 또는 발견 사항을 집계, 조직 및 우선 순위를 매깁니다. Amazon GuardDuty는 악의적인 활동 및 무단 행동을 지속적으로 모니터링하여 AWS 계정 및 워크로드를 보호하는 위협 탐지 서비스입니다. 이는 AWS CloudTrail 이벤트 로그, Amazon VPC 흐름 로그 및 DNS 로그와 같은 여러 AWS 데이터 소스에서 수십억 개의 이벤트를 분석합니다.",
        "Other Options": [
            "AWS Config는 AWS 리소스의 구성을 평가, 감사 및 평가할 수 있는 서비스입니다. 이는 잠재적인 보안 취약점에 대한 지속적인 모니터링을 제공하지 않습니다.",
            "AWS CloudTrail은 AWS 계정의 거버넌스, 규정 준수, 운영 감사 및 위험 감사를 가능하게 하는 서비스입니다. 그러나 이는 잠재적인 보안 취약점에 대한 지속적인 모니터링을 제공하지 않습니다.",
            "AWS Shield Advanced는 DDoS 보호 및 비용 보호를 제공하지만, 잠재적인 보안 취약점에 대한 지속적인 모니터링을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "24",
        "Situation": "다국적 전자상거래 회사는 여러 지역의 고객에게 저지연 읽기 액세스를 제공하는 고가용성 데이터베이스 솔루션이 필요합니다. 지역 중단에 대한 복원력을 보장하고 보호하기 위해, 회사는 기본 데이터베이스에 최소한의 성능 영향을 주는 교차 지역 재해 복구 설정도 요구합니다. 또한, 가능한 한 빠른 데이터 업데이트를 위해 보조 지역에 대한 거의 실시간 복제를 필요로 합니다.",
        "Question": "이러한 요구 사항을 가장 잘 충족하는 AWS 데이터베이스 솔루션은 무엇입니까?",
        "Options": {
            "1": "Amazon RDS를 Multi-AZ로 배포하여 단일 AWS 리전 내에서 고가용성을 향상시킵니다.",
            "2": "Aurora Global Database를 사용하여 교차 지역 읽기 복제를 활성화하고, 저지연 읽기 액세스 및 기본 데이터베이스에 대한 최소한의 영향을 주는 거의 실시간 복제를 제공합니다.",
            "3": "Amazon DynamoDB Global Tables를 구성하여 다중 지역 복제 및 NoSQL 워크로드에 대한 저지연 액세스를 달성합니다.",
            "4": "Amazon Redshift를 설정하여 교차 지역 스냅샷을 생성하여 각 지역에 백업을 만듭니다."
        },
        "Correct Answer": "Aurora Global Database를 사용하여 교차 지역 읽기 복제를 활성화하고, 저지연 읽기 액세스 및 기본 데이터베이스에 대한 최소한의 영향을 주는 거의 실시간 복제를 제공합니다.",
        "Explanation": "Aurora Global Database는 여러 지역에서 저지연 읽기 및 고가용성이 필요한 글로벌 애플리케이션을 위해 특별히 설계되었습니다. 이는 보조 지역으로의 거의 실시간 데이터 복제를 허용하여 해당 지역의 고객이 데이터를 빠르고 효율적으로 접근할 수 있도록 보장합니다. 또한, 지역 중단에 대한 복원력을 제공하여 데이터베이스가 기본 데이터베이스에 최소한의 성능 영향을 주며 보조 지역으로 장애 조치를 수행할 수 있습니다. 이는 회사의 고가용성, 저지연 액세스 및 교차 지역 재해 복구 요구 사항에 가장 적합합니다.",
        "Other Options": [
            "Amazon RDS를 Multi-AZ로 배포하면 단일 AWS 리전 내에서 고가용성이 향상되지만, 교차 지역 복제 또는 재해 복구 기능을 제공하지 않습니다. 따라서 지역 중단에 대한 복원력 요구 사항을 충족하지 않습니다.",
            "Aurora Global Database를 사용하는 것이 올바른 선택이므로 이 옵션은 대안으로 적용되지 않습니다. 이는 명시된 요구 사항에 대한 최상의 솔루션입니다.",
            "Amazon DynamoDB Global Tables를 구성하면 다중 지역 복제 및 저지연 액세스를 제공하지만, 이는 주로 NoSQL 워크로드에 적합합니다. 시나리오는 NoSQL 데이터베이스의 필요성을 명시하지 않으며, Aurora Global Database는 지정된 요구 사항에 대한 관계형 데이터베이스 요구에 더 적합한 옵션입니다."
        ]
    },
    {
        "Question Number": "25",
        "Situation": "회사는 AWS에서 중요한 웹 애플리케이션을 운영하고 있으며, 대기 환경에서 사용량을 관리하기 위해 서비스 할당량을 구성해야 합니다. 그들은 워크로드가 수요에 따라 확장될 수 있도록 하면서 서비스 한도를 초과하지 않도록 하고, 서비스 중단을 피하기 위해 스로틀링을 적용하고자 합니다.",
        "Question": "회사가 대기 환경에서 서비스 할당량 및 스로틀링을 관리하기 위해 어떤 단계를 취해야 합니까?",
        "Options": {
            "1": "AWS Service Quotas를 사용하여 서비스 사용에 대한 한계를 설정하고, 이러한 할당량에 따라 리소스를 자동으로 확장하도록 AWS Lambda를 구성하며, 서비스 안정성을 유지하기 위해 스로틀링을 적용합니다.",
            "2": "Auto Scaling 그룹을 구성하여 워크로드에 따라 EC2 인스턴스를 확장하고, AWS Management Console에서 수동으로 서비스 할당량을 조정하여 피크 트래픽을 처리합니다.",
            "3": "Amazon API Gateway를 사용하여 API 요청에 대한 스로틀링 한계를 설정하고, CloudWatch를 구성하여 대기 환경에서 사용량을 모니터링하여 한도를 초과하지 않도록 합니다.",
            "4": "Amazon SQS를 사용하여 초과 요청을 큐에 넣고 처리 지연을 통해 스로틀링을 방지하며, AWS Lambda를 자동 확장을 위해 구성합니다."
        },
        "Correct Answer": "Amazon API Gateway를 사용하여 API 요청에 대한 스로틀링 한계를 설정하고, CloudWatch를 구성하여 대기 환경에서 사용량을 모니터링하여 한도를 초과하지 않도록 합니다.",
        "Explanation": "Amazon API Gateway를 사용하여 스로틀링 한계를 설정하는 것은 웹 애플리케이션이 처리할 수 있는 요청 수를 관리하는 효과적인 방법으로, 과도한 부하로 인한 서비스 중단을 방지합니다. API Gateway는 요청을 스로틀링하고 할당량을 설정할 수 있는 사용 계획을 정의할 수 있어, 애플리케이션이 다양한 부하에서 안정적으로 유지될 수 있도록 합니다. 또한, CloudWatch와의 통합을 통해 회사는 실시간으로 사용량 메트릭을 추적할 수 있어 서비스 한계를 사전에 관리하고 정의된 임계값을 초과하지 않도록 보장합니다.",
        "Other Options": [
            "AWS Service Quotas를 사용하여 서비스 사용에 대한 한계를 설정하고 AWS Lambda를 자동 확장을 위해 구성하는 것은 API 요청에 대한 스로틀링을 직접적으로 다루지 않습니다. 서비스 한계를 관리하는 데 도움이 되지만, API Gateway가 제공하는 특정 스로틀링 기능이 부족하여 부하 하에서 서비스 안정성을 유지하는 데 중요합니다.",
            "Auto Scaling 그룹을 구성하여 EC2 인스턴스를 확장하는 것은 워크로드 증가를 처리하는 좋은 방법이지만, 본질적으로 서비스 할당량을 관리하거나 스로틀링을 적용하지 않습니다. 서비스 할당량을 수동으로 조정하면 실시간으로 수행되지 않을 경우 지연 및 잠재적인 서비스 중단이 발생할 수 있으며, 이는 수요 변화에 신속하게 대응해야 하는 대기 환경에 적합하지 않습니다.",
            "Amazon SQS를 사용하여 초과 요청을 큐에 넣는 것은 부하 관리를 위한 유효한 접근 방식이지만, API 요청에 대한 스로틀링을 직접 적용하지 않습니다. SQS는 백엔드 서비스를 압도하는 것을 방지하는 데 도움이 될 수 있지만, API Gateway가 제공하는 요청 속도에 대한 제어 수준을 제공하지 않으며, 요청 처리에 지연을 초래할 수 있습니다."
        ]
    },
    {
        "Question Number": "26",
        "Situation": "헬스케어 회사인 HealthSecure는 클라우드 리소스 구성의 지속적인 모니터링 및 문서화를 요구하는 엄격한 규정 준수 규정을 준수해야 합니다. HealthSecure는 AWS Config를 선택하여 AWS 환경 전반에 걸쳐 변경 사항을 추적하고 감사하여 HIPAA와 같은 기준에 대한 준수를 보장합니다. 그들은 특정 규정 준수 규칙에 대해 리소스를 평가하고 비준수 리소스를 자동으로 수정할 수 있는 솔루션이 필요합니다. 그러나 HealthSecure는 AWS Config의 한계, 특히 구성 변경을 적극적으로 방지할 수 있는지 아니면 모니터링 및 경고 기능만 제공하는지 이해하고 싶어합니다.",
        "Question": "AWS Config는 AWS 계정에서 규정 준수 관리 및 리소스 구성 추적을 어떻게 지원하며, 그 운영과 관련된 몇 가지 한계는 무엇입니까?",
        "Options": {
            "1": "AWS Config는 사용자가 리소스 전반에 걸쳐 구성 변경을 추적할 수 있게 하며, 실시간으로 규정을 준수하도록 강제하여 무단 변경을 방지합니다.",
            "2": "AWS Config는 지원되는 리소스 전반에 걸쳐 구성 변경을 모니터링하고 기록하며, 규정 준수 기준에 대한 감사 기능을 제공하고, AWS Lambda와의 통합을 통해 비준수 리소스를 자동으로 수정할 수 있습니다. 그러나 변경이 발생하는 것을 적극적으로 방지하지는 않습니다.",
            "3": "AWS Config는 특정 간격으로 구성 스냅샷만 제공하므로 규정 준수 관리의 효과가 제한됩니다. 실시간 모니터링은 지원되지 않습니다.",
            "4": "AWS Config는 단일 리전에서만 작동하며 여러 계정의 데이터를 집계할 수 없으므로 리소스가 정적으로 유지되는 격리된 환경에만 적합합니다."
        },
        "Correct Answer": "AWS Config는 지원되는 리소스 전반에 걸쳐 구성 변경을 모니터링하고 기록하며, 규정 준수 기준에 대한 감사 기능을 제공하고, AWS Lambda와의 통합을 통해 비준수 리소스를 자동으로 수정할 수 있습니다. 그러나 변경이 발생하는 것을 적극적으로 방지하지는 않습니다.",
        "Explanation": "AWS Config는 AWS 리소스 구성의 지속적인 모니터링을 제공하고 시간에 따른 변경 사항을 추적하도록 설계되었습니다. 사용자가 리소스를 규정 준수 규칙에 대해 평가할 수 있게 하며, 비준수 구성이 감지되면 AWS Lambda를 통해 수정 작업을 트리거할 수 있습니다. 그러나 AWS Config는 구성 변경을 적극적으로 방지할 수 있는 기능이 없으며, 발생하는 변경 사항을 모니터링하고 경고하는 기능만 제공하므로 규정 준수 관리에 강력한 도구이지만 예방적인 도구는 아닙니다.",
        "Other Options": [
            "옵션 1은 AWS Config가 실시간으로 무단 변경을 방지하지 않기 때문에 잘못되었습니다. 변경이 발생한 후에만 모니터링하고 경고합니다.",
            "옵션 3은 AWS Config가 거의 실시간 모니터링을 제공하며 특정 간격의 구성 스냅샷으로 제한되지 않기 때문에 잘못되었습니다. 구성 변경을 지속적으로 기록합니다.",
            "옵션 4는 AWS Config가 AWS Organizations와 함께 사용될 때 여러 리전 및 계정에서 작동할 수 있으므로 잘못되었습니다. 이는 전체 조직의 리소스 구성에 대한 보다 포괄적인 뷰를 제공합니다."
        ]
    },
    {
        "Question Number": "27",
        "Situation": "과학 연구 조직은 외부 사용자가 자주 접근하는 대규모 데이터 세트를 Amazon S3에 저장합니다. 비용을 최소화하기 위해, 그들은 외부 사용자가 데이터 접근 비용을 부담하기를 원합니다.",
        "Question": "이 요구 사항을 충족하기 위해 어떤 S3 구성을 사용해야 합니까?",
        "Options": {
            "1": "S3 전송 가속화 활성화",
            "2": "Requester Pays가 활성화된 S3 버킷 설정",
            "3": "저장 클래스에 S3 Intelligent-Tiering 사용",
            "4": "비용 공유를 위한 교차 리전 복제 활성화"
        },
        "Correct Answer": "Requester Pays가 활성화된 S3 버킷 설정",
        "Explanation": "S3 버킷에서 Requester Pays를 활성화하면 데이터를 접근하는 외부 사용자가 요청과 관련된 비용을 부담하게 됩니다. 즉, 사용자가 데이터를 접근할 때 데이터 전송 및 요청에 대한 요금이 부과되어, 비용 부담이 조직에서 데이터를 접근하는 사용자로 전가됩니다. 이 구성은 외부 당사자와 데이터를 공유하는 시나리오에 특별히 설계되어 있어, 비용을 최소화하려는 조직의 요구 사항에 가장 적합한 옵션입니다.",
        "Other Options": [
            "S3 전송 가속화를 활성화하면 S3로의 파일 전송 속도가 빨라지지만, 데이터 접근 비용을 누가 부담하는지는 변경되지 않습니다. 전송 가속화 사용에 대한 비용은 여전히 버킷 소유자가 부담합니다.",
            "S3 Intelligent-Tiering은 접근 패턴의 변화에 따라 데이터를 두 개의 접근 계층 간에 자동으로 이동하는 저장 클래스이지만, 데이터 접근에 대한 비용 할당 문제를 해결하지 않습니다. 조직은 여전히 데이터 검색과 관련된 비용을 부담해야 합니다.",
            "교차 리전 복제를 활성화하면 다양한 AWS 리전 간에 데이터를 자동으로 복제하여 중복성과 가용성을 높입니다. 이 기능은 데이터 접근에 대한 비용 공유와 관련이 없으며, 외부 사용자가 접근 비용을 부담하도록 요구 사항을 해결하지 않고 조직에 추가 비용을 발생시킵니다."
        ]
    },
    {
        "Question Number": "28",
        "Situation": "금융 서비스 회사는 변동하는 작업 부하를 경험하는 트랜잭션 데이터베이스를 관리하고 있으며, 여기에는 높은 IOPS와 저장 용량이 필요한 피크 기간이 포함됩니다. 회사는 피크 시간 동안 성능을 보장하면서 비용을 최적화하는 것을 목표로 합니다.",
        "Question": "이 요구 사항을 충족하기 위해 솔루션 아키텍트가 추천해야 할 Amazon RDS 저장소 구성은 무엇입니까?",
        "Options": {
            "1": "자동 스케일링이 활성화된 일반 목적 SSD (gp3) 저장소 프로비저닝.",
            "2": "자동 백업 및 스냅샷 기능이 있는 자기 저장소 사용.",
            "3": "피크 시간 동안 최대 요구되는 IOPS로 설정된 프로비저닝된 IOPS SSD (io1) 저장소 프로비저닝.",
            "4": "내장된 저장소 스케일링 및 고성능 기능을 갖춘 Amazon Aurora 구현."
        },
        "Correct Answer": "내장된 저장소 스케일링 및 고성능 기능을 갖춘 Amazon Aurora 구현.",
        "Explanation": "Amazon Aurora는 높은 성능과 가용성을 위해 설계되어 변동하는 작업 부하를 가진 애플리케이션에 적합한 선택입니다. 필요에 따라 저장소를 최대 128TB까지 자동으로 확장하므로 높은 IOPS와 저장 용량이 필요한 피크 기간 동안 유리합니다. Aurora는 또한 높은 처리량과 낮은 대기 시간을 제공하여, 높은 부하에서도 성능을 유지하며 비용을 최적화하면서 성능 요구 사항을 충족합니다.",
        "Other Options": [
            "자동 스케일링이 활성화된 일반 목적 SSD (gp3) 저장소 프로비저닝은 일반 작업 부하에 좋은 옵션이지만, 피크 시간 동안 특히 일관된 높은 IOPS가 필요한 트랜잭션 데이터베이스에 대해 Amazon Aurora와 같은 수준의 성능과 확장성을 제공하지 않을 수 있습니다.",
            "자동 백업 및 스냅샷 기능이 있는 자기 저장소 사용은 고성능 요구 사항에 적합하지 않습니다. 자기 저장소는 느리며 트랜잭션 작업 부하에 필요한 IOPS를 제공하지 않으므로 피크 성능 요구에 부적합합니다.",
            "피크 시간 동안 최대 요구되는 IOPS로 설정된 프로비저닝된 IOPS SSD (io1) 저장소 프로비저닝은 효과적일 수 있지만, 비용이 많이 들 수 있으며, 특히 작업 부하가 변동적이고 예측할 수 없는 경우 Amazon Aurora와 같은 수준의 자동 스케일링 및 성능 최적화를 제공하지 않을 수 있습니다."
        ]
    },
    {
        "Question Number": "29",
        "Situation": "연구 조직은 온프레미스 NFS 저장소에서 Amazon S3로 80TB의 과학 데이터를 마이그레이션해야 합니다. 데이터는 자주 업데이트되며, 조직은 온프레미스에서 이루어진 변경 사항이 AWS로 점진적으로 동기화되도록 하기를 원합니다. 또한, 그들은 근무 시간 동안 네트워크 대역폭이 포화되는 것에 대해 우려하고 있습니다.",
        "Question": "솔루션 아키텍트가 이 마이그레이션의 이점으로 강조해야 할 AWS DataSync 기능은 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "데이터 무결성을 보장하기 위한 전송 중 데이터 검증",
            "2": "재해 복구를 위한 다중 리전 복제",
            "3": "피크 시간 동안 네트워크 사용량을 제어하기 위한 대역폭 제한기",
            "4": "제로 대기 시간으로 실시간 동기화 지원",
            "5": "신뢰할 수 있는 전송을 위한 전송 오류 자동 복구"
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "데이터 무결성을 보장하기 위한 전송 중 데이터 검증",
            "피크 시간 동안 네트워크 사용량을 제어하기 위한 대역폭 제한기"
        ],
        "Explanation": "전송 중 데이터 검증은 AWS DataSync의 주요 기능으로, 데이터 무결성을 보장합니다. 이는 소스 위치에서 읽은 데이터가 대상에 기록된 데이터와 일치하는지 확인하여 전송 중 데이터가 손상되지 않도록 합니다. 이는 연구 조직에 매우 중요하며, 과학 데이터의 무결성을 보장해야 합니다. 대역폭 제한기 기능은 조직이 피크 시간 동안 네트워크 사용량을 제어할 수 있게 합니다. 이는 조직이 근무 시간 동안 네트워크 대역폭이 포화되는 것에 대해 우려하고 있기 때문에 중요합니다. AWS DataSync는 사용자가 DataSync가 사용하는 대역폭에 제한을 설정할 수 있게 하여 네트워크가 포화되지 않도록 합니다.",
        "Other Options": [
            "재해 복구를 위한 다중 리전 복제는 AWS DataSync의 기능이 아닙니다. 이는 Amazon S3의 기능이며, DataSync는 AWS 저장소 서비스 간의 데이터 전송에 사용되며 다중 리전 복제를 제공하지 않습니다.",
            "제로 대기 시간으로 실시간 동기화 지원은 AWS DataSync의 기능이 아닙니다. DataSync는 예약된 또는 온디맨드 데이터 전송 작업을 지원하지만, 제로 대기 시간의 실시간 동기화를 제공하지 않습니다.",
            "신뢰할 수 있는 전송을 위한 전송 오류 자동 복구는 AWS DataSync의 특정 기능이 아닙니다. DataSync는 강력한 오류 처리를 제공하지만, '전송 오류 자동 복구' 기능을 특별히 제공하지는 않습니다."
        ]
    },
    {
        "Question Number": "30",
        "Situation": "한 회사가 웹 서버에서 생성된 대량의 로그 파일을 처리하는 데이터 분석 애플리케이션을 개발하고 있습니다. 이 애플리케이션은 자주 접근되는 로그 데이터에 대한 낮은 대기 시간 접근이 필요하며, 여러 인스턴스에서 동시 읽기 및 쓰기 작업을 지원해야 합니다. 또한, 저장 솔루션은 수동 개입 없이 증가하는 데이터 볼륨을 수용할 수 있도록 자동으로 확장해야 합니다.",
        "Question": "이 요구 사항을 충족하기 위해 솔루션 아키텍트가 추천해야 할 AWS 저장소 서비스는 무엇입니까?",
        "Options": {
            "1": "Amazon S3 Standard",
            "2": "Amazon Elastic File System (Amazon EFS)",
            "3": "Amazon Elastic Block Store (Amazon EBS) 프로비저닝된 IOPS",
            "4": "Amazon FSx for Windows File Server"
        },
        "Correct Answer": "Amazon Elastic File System (Amazon EFS)",
        "Explanation": "Amazon Elastic File System (EFS)은 낮은 대기 시간 접근을 위해 설계되었으며, 여러 인스턴스에서 동시 읽기 및 쓰기 작업을 지원할 수 있어 데이터에 자주 접근해야 하는 애플리케이션에 적합합니다. EFS는 데이터가 추가되거나 제거됨에 따라 자동으로 확장되므로, 수동 개입 없이 증가하는 데이터 볼륨을 수용할 수 있는 저장 솔루션 요구 사항과 완벽하게 일치합니다. 또한, EFS는 여러 EC2 인스턴스에서 접근할 수 있는 관리형 파일 시스템을 제공하여 로그 데이터의 높은 가용성과 내구성을 보장합니다.",
        "Other Options": [
            "Amazon S3 Standard는 내구성과 확장성을 최적화한 객체 저장소 서비스이지만, 파일 시스템처럼 낮은 대기 시간 접근이나 동시 읽기/쓰기 작업을 위해 설계되지 않았습니다. 이는 대량의 비구조적 데이터를 저장하는 데 더 적합합니다.",
            "Amazon Elastic Block Store (Amazon EBS) 프로비저닝된 IOPS는 EC2 인스턴스에 대해 높은 성능을 제공하는 블록 저장소 서비스입니다. 그러나 일반적으로 한 번에 단일 EC2 인스턴스에 연결되므로 여러 인스턴스에서 동시 접근을 위해 설계되지 않았습니다. 이는 동시 읽기 및 쓰기 작업 요구 사항에 덜 적합합니다.",
            "Amazon FSx for Windows File Server는 공유 파일 저장소를 제공하는 관리형 Windows 파일 시스템입니다. 동시 접근을 지원하지만, EFS와 같은 방식으로 자동으로 확장되지 않을 수 있으며, 더 복잡할 수 있습니다. 또한, 이 애플리케이션에 필요하지 않을 수 있는 Windows 환경에 더 적합합니다."
        ]
    },
    {
        "Question Number": "31",
        "Situation": "한 회사가 웹 애플리케이션을 배포하고 있으며, 여러 가용 영역(AZ)에서 높은 가용성을 제공하면서 동적으로 확장할 수 있도록 보장하고자 합니다. 그들은 트래픽을 효율적으로 분산하기 위해 Application Load Balancer(ALB)를 사용하고자 합니다.",
        "Question": "다음 구성 중 회사가 이 목표를 달성하는 데 가장 적합한 것은 무엇입니까?",
        "Options": {
            "1": "ALB를 사용하여 URL 경로에 따라 트래픽을 분산하고 요청을 서로 다른 대상 그룹으로 전달하여 여러 EC2 인스턴스에 트래픽이 고르게 분산되도록 합니다.",
            "2": "Classic Load Balancer(CL)B를 사용하여 URL 경로 라우팅 없이 IP 주소에만 기반하여 트래픽을 분산합니다.",
            "3": "ALB를 사용하되 모든 트래픽을 단일 EC2 인스턴스로 라우팅하여 복잡성을 줄이고 성능을 향상시킵니다.",
            "4": "정적 콘텐츠에 대해서만 ALB를 사용하고 동적 콘텐츠 트래픽을 단일 EC2 인스턴스로 전달하여 효율적인 로드 밸런싱을 유지합니다."
        },
        "Correct Answer": "ALB를 사용하여 URL 경로에 따라 트래픽을 분산하고 요청을 서로 다른 대상 그룹으로 전달하여 여러 EC2 인스턴스에 트래픽이 고르게 분산되도록 합니다.",
        "Explanation": "Application Load Balancer(ALB)를 사용하여 URL 경로에 따라 트래픽을 분산하면 고급 라우팅 기능을 활용할 수 있어 애플리케이션이 다양한 유형의 요청을 효율적으로 처리할 수 있습니다. 요청을 서로 다른 대상 그룹으로 전달함으로써 ALB는 여러 EC2 인스턴스에 트래픽이 고르게 분산되도록 보장할 수 있으며, 이는 동적 확장 및 여러 가용 영역(AZ)에서 높은 가용성을 유지하는 데 필수적입니다. 이 구성은 수평 확장과 효율적인 리소스 활용을 지원하여 현대 웹 애플리케이션에 매우 중요합니다.",
        "Other Options": [
            "Classic Load Balancer(CL)B를 사용하여 IP 주소에만 기반하여 트래픽을 분산하는 것은 트래픽 관리의 유연성과 효율성을 제한합니다. CLB는 경로 기반 라우팅과 같은 고급 라우팅 기능을 지원하지 않으므로 트래픽이 고르게 분산되지 않고 특정 인스턴스가 과부하되거나 다른 인스턴스가 저조하게 활용될 수 있습니다.",
            "모든 트래픽을 단일 EC2 인스턴스로 라우팅하는 것은 ALB를 로드 밸런싱에 사용하는 목적을 저해합니다. 이 구성은 단일 실패 지점을 생성하고 높은 가용성과 확장성의 이점을 무효화하며, ALB의 여러 인스턴스에 트래픽을 분산하는 능력을 활용하지 않습니다.",
            "정적 콘텐츠에 대해서만 ALB를 사용하고 동적 콘텐츠 트래픽을 단일 EC2 인스턴스로 전달하는 것은 로드 밸런서의 기능을 제한하고 성능 병목 현상을 초래할 수 있습니다. 이 접근 방식은 ALB의 정적 및 동적 콘텐츠를 여러 인스턴스에 분산하는 능력을 활용하지 않으며, 이는 높은 가용성과 확장성을 유지하는 데 필수적입니다."
        ]
    },
    {
        "Question Number": "32",
        "Situation": "한 제조 회사가 인터넷 연결이 제한된 원격 위치에서 운영되고 있습니다. 그들은 기계 데이터를 분석하고 애플리케이션을 실행하기 위해 로컬 컴퓨팅 리소스가 필요하지만, 연결이 가능할 때 AWS와 데이터를 동기화할 수 있는 기능도 원합니다.",
        "Question": "이 요구 사항을 가장 잘 충족하는 하이브리드 컴퓨팅 옵션은 무엇입니까?",
        "Options": {
            "1": "AWS Snowball Edge",
            "2": "AWS Lambda와 VPC 엔드포인트",
            "3": "가장 가까운 AWS 리전의 Amazon EC2 인스턴스",
            "4": "온디맨드 스케일링이 가능한 Amazon EKS"
        },
        "Correct Answer": "AWS Snowball Edge",
        "Explanation": "AWS Snowball Edge는 제한적이거나 인터넷 연결이 없는 환경에서 엣지 컴퓨팅 및 데이터 전송을 위해 설계되었습니다. 사용자는 이 장치에서 애플리케이션을 실행하고 데이터를 로컬에서 분석할 수 있으며, 이는 원격 위치에 있는 제조 회사에 이상적입니다. 또한 Snowball Edge는 연결이 가능할 때 AWS와 데이터 동기화를 지원하므로 이들의 요구 사항에 완벽하게 적합합니다.",
        "Other Options": [
            "AWS Lambda와 VPC 엔드포인트는 AWS 서비스에 접근하기 위해 안정적인 인터넷 연결이 필요하므로 적합하지 않습니다. 연결이 제한된 원격 위치에서는 이 옵션이 필요한 로컬 컴퓨팅 리소스를 제공하지 않습니다.",
            "가장 가까운 AWS 리전의 Amazon EC2 인스턴스는 이러한 인스턴스에 접근하기 위해 지속적인 인터넷 연결이 필요하므로 회사의 요구를 충족하지 않습니다. 이 옵션은 원격 지역에서 데이터 분석을 위한 로컬 컴퓨팅 리소스를 제공하지 않습니다.",
            "온디맨드 스케일링이 가능한 Amazon EKS는 클라우드에서 Kubernetes 클러스터를 관리하기 위해 안정적인 인터넷 연결에 의존하므로, 연결이 제한된 원격 위치에서는 효과적으로 작동하지 않으며 로컬 컴퓨팅 리소스를 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "33",
        "Situation": "한 핀테크 회사가 대량의 거래 데이터를 실시간으로 처리하기 위한 새로운 데이터 분석 플랫폼을 설계하고 있습니다. 높은 성능을 보장하기 위해 플랫폼은 데이터가 도착하는 즉시 최소한의 지연으로 처리하고, 최종 사용자에게 신속하게 통찰력을 제공해야 합니다.",
        "Question": "이러한 높은 성능 요구 사항을 가장 효과적으로 충족하는 아키텍처 선택은 무엇입니까?",
        "Options": {
            "1": "정기적으로 거래 데이터를 배치 처리",
            "2": "실시간 데이터 스트리밍을 통한 이벤트 기반 아키텍처",
            "3": "모든 거래 데이터를 전통적인 관계형 데이터베이스에 저장",
            "4": "더 빠른 접근을 위해 모든 애플리케이션 구성 요소를 단일 가용 영역에 배포"
        },
        "Correct Answer": "실시간 데이터 스트리밍을 통한 이벤트 기반 아키텍처",
        "Explanation": "실시간 데이터 스트리밍을 통한 이벤트 기반 아키텍처는 대량의 거래 데이터를 실시간으로 처리하는 데 가장 효과적인 선택입니다. 이 아키텍처는 시스템이 도착하는 데이터에 즉각적으로 반응할 수 있게 하여 즉시 처리 및 분석을 가능하게 합니다. 높은 처리량과 낮은 지연을 지원하여 최종 사용자에게 적시에 통찰력을 제공하는 데 필수적입니다. 메시지 큐 및 스트림 처리 프레임워크와 같은 기술을 활용함으로써 플랫폼은 지속적인 데이터 흐름을 효율적으로 처리하고 знач지 않은 지연 없이 결과를 제공할 수 있습니다.",
        "Other Options": [
            "정기적으로 거래 데이터를 배치 처리하는 것은 실시간 처리를 요구하는 높은 성능 요구 사항에 적합하지 않습니다. 이 접근 방식은 데이터를 수집하고 배치로 처리하는 동안 지연을 초래하여 통찰력과 반응성을 지연시킬 수 있습니다.",
            "모든 거래 데이터를 전통적인 관계형 데이터베이스에 저장하는 것은 구조화된 데이터 저장을 제공할 수 있지만, 실시간 처리에 최적화되어 있지 않습니다. 관계형 데이터베이스는 일반적으로 쿼리에 더 많은 시간이 필요하며, 고속 데이터 스트림을 효율적으로 처리하지 못해 성능 병목 현상을 초래할 수 있습니다.",
            "모든 애플리케이션 구성 요소를 단일 가용 영역에 배포하여 더 빠른 접근을 제공하는 것은 데이터 처리 성능을 본질적으로 개선하지 않습니다. 로컬 접근에 대한 지연을 줄일 수는 있지만, 실시간 데이터 처리의 필요성을 해결하지 않으며 단일 실패 지점을 초래하여 시스템 신뢰성을 저하시킬 수 있습니다."
        ]
    },
    {
        "Question Number": "34",
        "Situation": "한 웹 개발 회사가 AWS에서 여러 애플리케이션을 호스팅하고 있으며, 트래픽 패턴이 다양합니다. 비용을 최적화하기 위해 그들은 사용한 만큼만 지불하고 서버를 직접 관리하는 것을 피하고자 합니다.",
        "Question": "이 요구 사항을 가장 잘 충족하는 접근 방식은 무엇입니까?",
        "Options": {
            "1": "Amazon EC2에 애플리케이션을 배포하고 Auto Scaling 사용",
            "2": "Amazon ECS에서 Fargate를 사용하여 컨테이너 실행",
            "3": "예약 인스턴스에서 애플리케이션 실행",
            "4": "정적 콘텐츠에 Amazon S3 사용하고 데이터베이스에 Amazon RDS 사용"
        },
        "Correct Answer": "Amazon ECS에서 Fargate를 사용하여 컨테이너 실행",
        "Explanation": "Amazon ECS에서 Fargate를 사용하면 웹 개발 회사가 기본 서버를 관리하지 않고도 애플리케이션을 컨테이너에서 실행할 수 있습니다. Fargate는 컴퓨팅 리소스를 자동으로 프로비저닝하고 관리하므로 회사는 애플리케이션의 트래픽 패턴에 따라 실제로 사용하는 리소스에 대해서만 비용을 지불합니다. 이 서버리스 접근 방식은 비용을 최적화하면서 수요에 따라 확장할 수 있는 유연성을 제공합니다.",
        "Other Options": [
            "Amazon EC2에 애플리케이션을 배포하고 Auto Scaling을 사용하는 것은 EC2 인스턴스를 관리해야 하므로, 자동으로 확장하더라도 직접 서버 관리를 피하는 요구 사항을 완전히 충족하지 못할 수 있습니다. 회사는 여전히 인스턴스 프로비저닝 및 유지 관리를 처리해야 합니다.",
            "예약 인스턴스에서 애플리케이션을 실행하는 것은 특정 인스턴스 유형 및 크기에 대해 1년 또는 3년 기간 동안 약정해야 하므로, 사용한 만큼만 지불하겠다는 목표와 일치하지 않습니다. 이 옵션은 예측 가능한 워크로드에 대해 더 비용 효율적이지만, 다양한 트래픽 패턴에 필요한 유연성을 제공하지 않습니다.",
            "정적 콘텐츠에 Amazon S3를 사용하고 데이터베이스에 Amazon RDS를 사용하는 것은 특정 사용 사례에 적합한 접근 방식이지만, 동적 애플리케이션 호스팅 요구 사항을 해결하지 않습니다. 이 옵션은 저장소와 데이터베이스 관리를 분리하지만, 다양한 트래픽 패턴을 가진 애플리케이션을 실행하기 위한 완전한 솔루션을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "35",
        "Situation": "한 연구 기관이 분석을 위해 실험 데이터를 데이터베이스에 저장해야 합니다. 데이터는 처음 3개월 동안 활발히 사용되며, 이후에는 거의 접근되지 않지만 규정 준수를 위해 5년 동안 보관해야 합니다. 그들은 장기 저장 비용을 최소화하고자 합니다.",
        "Question": "가장 비용 효율적인 데이터 보존 정책은 무엇입니까?",
        "Options": {
            "1": "모든 데이터를 고성능 데이터베이스에 저장하고 매일 백업",
            "2": "3개월 후 Amazon S3 Glacier에 데이터 아카이브",
            "3": "저장 비용을 줄이기 위해 3개월 후 데이터 삭제",
            "4": "3개월 후 저비용 데이터베이스 계층으로 데이터 이동"
        },
        "Correct Answer": "3개월 후 Amazon S3 Glacier에 데이터 아카이브",
        "Explanation": "3개월 후 Amazon S3 Glacier에 데이터를 아카이브하는 것은 장기 저장을 위한 가장 비용 효율적인 솔루션입니다. S3 Glacier는 드물게 접근되는 데이터를 위해 설계되었으며, 고성능 데이터베이스에 비해 훨씬 낮은 저장 비용을 제공합니다. 데이터는 초기 3개월 후에는 거의 접근되지 않지만, 5년 동안 규정 준수를 위해 보관해야 하므로 S3 Glacier는 비용과 접근성의 적절한 균형을 제공하여 기관이 비용을 최소화하면서도 보존 요구 사항을 충족할 수 있도록 합니다.",
        "Other Options": [
            "모든 데이터를 고성능 데이터베이스에 저장하고 매일 백업하는 것은 장기 저장에 비용 효율적이지 않습니다. 특히 데이터가 처음 3개월 후에는 활발히 사용되지 않기 때문입니다. 고성능 데이터베이스는 일반적으로 더 비쌉니다. 매일 백업은 드물게 접근될 데이터에 대해 불필요한 추가 비용을 초래합니다.",
            "3개월 후 데이터를 삭제하면 저장 비용을 줄일 수 있지만, 5년 동안 데이터를 보관해야 하는 규정 준수 요구 사항을 충족하지 않습니다. 이 옵션은 비준수로 인해 기관이 법적 및 규제 위험에 노출될 수 있습니다.",
            "3개월 후 데이터를 저비용 데이터베이스 계층으로 이동하는 것은 고성능 데이터베이스에 보관하는 것보다 나은 옵션이지만, S3 Glacier에 아카이브하는 것보다 여전히 더 비쌀 수 있습니다. 저비용 데이터베이스 계층은 여전히 드물게 접근되는 데이터를 위한 아카이브 솔루션보다 더 높은 비용이 발생할 수 있어 장기 저장에 덜 최적화된 옵션입니다."
        ]
    },
    {
        "Question Number": "36",
        "Situation": "조직은 특정 기록을 최소 7년 동안 보관해야 하는 데이터 보존 정책을 준수해야 합니다.",
        "Question": "저장 비용을 최소화하면서 준수를 보장하기 위한 가장 적절한 솔루션은 무엇입니까?",
        "Options": {
            "1": "Amazon S3 Standard에 데이터를 저장하고 S3 Lifecycle 정책을 사용하여 데이터를 S3 Glacier로 전환합니다.",
            "2": "암호화가 활성화된 Amazon Elastic File System (EFS)에 데이터를 저장합니다.",
            "3": "자동 백업이 구성된 Amazon RDS를 사용하여 스냅샷을 7년 동안 보관합니다.",
            "4": "온디맨드 백업이 있는 Amazon DynamoDB에 데이터를 저장합니다."
        },
        "Correct Answer": "Amazon S3 Standard에 데이터를 저장하고 S3 Lifecycle 정책을 사용하여 데이터를 S3 Glacier로 전환합니다.",
        "Explanation": "이 옵션은 비용 효율적인 저장 관리가 가능하기 때문에 가장 적절합니다. Amazon S3 Standard는 자주 접근하는 데이터에 적합하며, S3 Glacier는 저렴한 비용으로 장기 아카이브 저장을 위해 설계되었습니다. S3 Lifecycle 정책을 구현함으로써 조직은 지정된 기간 후에 데이터를 자동으로 S3 Glacier로 전환하여 7년 보존 정책을 준수하면서 시간에 따라 저장 비용을 최소화할 수 있습니다.",
        "Other Options": [
            "암호화가 활성화된 Amazon Elastic File System (EFS)에 데이터를 저장하는 것은 S3 Glacier에 비해 더 높은 비용 때문에 장기 저장에 최선의 선택이 아닙니다. EFS는 저지연 접근을 위해 설계되었으며, 자주 접근하지 않는 데이터를 저장하는 데 더 비쌉니다.",
            "자동 백업이 구성된 Amazon RDS를 사용하는 것은 비용이 많이 들 수 있으며 관계형 데이터베이스의 기능이 필요하지 않은 데이터에는 필요하지 않을 수 있습니다. RDS는 일반적으로 트랜잭션 데이터에 사용되며 S3 Glacier에 비해 장기 저장에 더 높은 비용이 발생할 수 있습니다.",
            "온디맨드 백업이 있는 Amazon DynamoDB에 데이터를 저장하는 것도 장기 보존을 위한 가장 비용 효율적인 솔루션이 아닙니다. DynamoDB는 고성능 애플리케이션에 적합하지만, 백업에 대한 가격 모델이 시간이 지남에 따라 비쌀 수 있으며, 특히 여러 년 동안 보존해야 하는 데이터에 대해 그렇습니다."
        ]
    },
    {
        "Question Number": "37",
        "Situation": "회사는 \"secretcatproject\"라는 이름의 S3 버킷을 가지고 있으며, 이 버킷에는 민감한 데이터가 포함되어 있습니다. 회사는 데이터가 공개 접근으로부터 안전하게 유지되도록 하면서 파트너 계정의 특정 사용자에게 이 버킷에 대한 접근을 허용해야 합니다.",
        "Question": "회사는 무단 접근을 방지하면서 필요한 접근을 부여하기 위해 어떤 방법을 사용해야 합니까?",
        "Options": {
            "1": "모든 사용자에게 공개 접근을 허용하는 버킷 정책을 설정하여 접근 관리를 단순화합니다.",
            "2": "파트너 계정의 IAM 역할을 주체로 지정하여 버킷에 접근할 수 있는 권한을 부여하는 S3 버킷 정책을 사용합니다.",
            "3": "버킷에서 'Block Public Access'를 활성화하고 접근 제어 목록(ACL)을 사용하여 파트너 계정의 접근을 관리합니다.",
            "4": "버킷에 IAM 정책을 직접 연결하여 파트너 계정의 사용자에 대한 접근을 제어합니다."
        },
        "Correct Answer": "파트너 계정의 IAM 역할을 주체로 지정하여 버킷에 접근할 수 있는 권한을 부여하는 S3 버킷 정책을 사용합니다.",
        "Explanation": "파트너 계정의 IAM 역할을 주체로 지정하는 S3 버킷 정책을 사용하면 버킷에 접근할 수 있는 사람을 정확하게 제어할 수 있습니다. 이 방법은 지정된 파트너 계정의 사용자만 민감한 데이터에 접근할 수 있도록 보장하며, 공개 접근을 방지합니다. 버킷 정책은 버킷 수준에서 권한을 정의할 수 있는 강력한 도구이며, 접근을 추가로 제한하기 위한 조건을 포함할 수 있어 민감한 데이터에 대한 접근을 안전하게 관리하는 데 이상적입니다.",
        "Other Options": [
            "모든 사용자에게 공개 접근을 허용하는 버킷 정책을 설정하는 것은 매우 불안전하며, 데이터를 공개 접근으로부터 안전하게 유지해야 한다는 요구와 모순됩니다. 이는 민감한 데이터를 인터넷의 누구에게나 노출시켜서는 안 됩니다.",
            "파트너 계정의 IAM 역할을 지정하는 S3 버킷 정책을 사용하는 것은 올바르지만, 이 옵션은 주체로서 IAM 역할을 사용하는 것을 명시적으로 언급하지 않으므로 안전하게 접근을 부여하는 중요한 측면이 부족합니다. 따라서 올바른 답변보다 덜 정확합니다.",
            "'Block Public Access'를 활성화하는 것은 공개 접근을 방지하는 좋은 방법이지만, 이 시나리오에서 접근 제어 목록(ACL)을 사용하는 것은 최선의 방법이 아닙니다. ACL은 버킷 정책보다 더 복잡하고 유연성이 떨어질 수 있으며, 버킷 정책이 제공하는 것과 같은 수준의 명확성과 권한 제어를 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "38",
        "Situation": "회사는 Amazon Route 53을 사용하여 도메인의 DNS 레코드를 관리하고 있습니다. 그들은 DNS 스푸핑 및 DDoS 공격과 같은 잠재적인 DNS 공격에 대해 우려하고 있으며, DNS 인프라가 안전하도록 보장하고 싶어합니다.",
        "Question": "회사가 Route 53 설정의 보안을 강화하기 위해 어떤 조치를 취해야 합니까?",
        "Options": {
            "1": "DNS 응답이 암호화 서명되도록 Route 53 호스팅 영역에서 DNSSEC(도메인 이름 시스템 보안 확장)를 활성화하여 DNS 스푸핑 공격을 방지합니다.",
            "2": "Route 53 Resolver DNS Firewall을 사용하여 악성 쿼리를 필터링하고 알려진 악성 IP로부터의 트래픽을 차단하여 합법적인 트래픽만 자원에 도달하도록 합니다.",
            "3": "DNS 쿼리에 대해 HTTP만 사용하도록 Route 53을 구성하여 보안을 단순화합니다. HTTP는 다른 프로토콜에 비해 DDoS 공격에 덜 취약합니다.",
            "4": "DNS 쿼리 성능을 모니터링하기 위해 Route 53 Health Checks를 설정하지만, DNS 보안이 다른 AWS 서비스에 의해 커버된다고 가정하고 추가 보안 기능을 활성화하지 않습니다."
        },
        "Correct Answer": "DNS 응답이 암호화 서명되도록 Route 53 호스팅 영역에서 DNSSEC(도메인 이름 시스템 보안 확장)를 활성화하여 DNS 스푸핑 공격을 방지합니다.",
        "Explanation": "Route 53 호스팅 영역에서 DNSSEC를 활성화하면 DNS 응답이 암호화 서명되도록 하여 보안 계층을 추가합니다. 이는 응답이 진짜이며 변조되지 않았음을 보장하여 DNS 스푸핑 공격을 효과적으로 방지합니다. DNSSEC는 DNS 데이터의 무결성을 검증하는 데 도움을 주어 공격자가 위조된 DNS 응답을 통해 사용자를 악성 사이트로 리디렉션하는 것을 훨씬 더 어렵게 만듭니다.",
        "Other Options": [
            "Route 53 Resolver DNS Firewall을 사용하는 것은 악성 쿼리를 필터링하는 좋은 방법이지만, DNS 스푸핑 문제를 직접적으로 해결하지는 않습니다. 일부 위협을 완화하는 데 도움이 될 수 있지만, DNS 응답의 진위를 보장하는 데 있어 DNSSEC만큼 효과적이지 않습니다.",
            "Route 53을 DNS 쿼리에 대해 HTTP만 사용하도록 구성하는 것은 잘못된 것입니다. DNS 쿼리는 일반적으로 UDP 및 TCP 프로토콜을 사용하며, HTTP는 DDoS 공격에 대한 보안을 본질적으로 제공하지 않습니다. 오히려 HTTP는 DNS 인프라를 더 많은 위험에 노출시킬 수 있습니다. DNS over HTTPS (DoH) 또는 DNS over TLS (DoT)와 같은 보안 프로토콜을 사용하는 것이 더 적절합니다.",
            "Route 53 Health Checks를 설정하는 것은 DNS 쿼리 성능을 모니터링하는 데 유용하지만 보안을 강화하지는 않습니다. 추가 보안 기능을 활성화하지 않고 건강 검진에만 의존하면 DNS 인프라가 스푸핑 및 DDoS와 같은 공격에 취약하게 남아 있게 되며, 이는 DNSSEC 및 기타 보안 조치를 구현하여 완화할 수 있습니다."
        ]
    },
    {
        "Question Number": "39",
        "Situation": "회사는 AWS Lambda 함수의 애플리케이션 자격 증명을 보호하고 싶어합니다. 이 함수는 Amazon RDS 데이터베이스에 연결해야 합니다.",
        "Question": "데이터베이스 자격 증명을 저장하고 관리하는 가장 안전한 방법은 무엇입니까?",
        "Options": {
            "1": "Lambda 함수 내의 평문 구성 파일에 데이터베이스 자격 증명을 저장합니다.",
            "2": "데이터베이스에 직접 접근할 수 있는 권한을 가진 AWS IAM 역할을 사용합니다.",
            "3": "AWS Secrets Manager에 데이터베이스 자격 증명을 저장하고 Lambda 함수에 비밀을 검색할 수 있는 권한을 부여합니다.",
            "4": "서버 측 암호화가 활성화된 Amazon S3에 데이터베이스 자격 증명을 저장합니다."
        },
        "Correct Answer": "AWS Secrets Manager에 데이터베이스 자격 증명을 저장하고 Lambda 함수에 비밀을 검색할 수 있는 권한을 부여합니다.",
        "Explanation": "AWS Secrets Manager를 사용하여 데이터베이스 자격 증명을 저장하는 것은 민감한 정보를 관리하기 위해 특별히 설계되었기 때문에 가장 안전한 접근 방식입니다. Secrets Manager는 자격 증명을 암호화하여 저장하고 AWS IAM을 통해 세밀한 접근 제어를 제공합니다. 이를 통해 Lambda 함수는 자격 증명을 안전하게 검색할 수 있으며, 함수의 코드나 구성 파일에 하드코딩할 필요가 없습니다. 또한, Secrets Manager는 자격 증명을 자동으로 회전할 수 있어 보안을 더욱 강화합니다.",
        "Other Options": [
            "Lambda 함수 내의 평문 구성 파일에 데이터베이스 자격 증명을 저장하는 것은 매우 불안전합니다. 이는 코드 내에 민감한 정보를 직접 노출시켜, 코드가 노출되거나 공유될 경우 무단 접근에 취약하게 만듭니다.",
            "데이터베이스에 직접 접근할 수 있는 권한을 가진 AWS IAM 역할을 사용하는 것은 데이터베이스 자격 증명을 안전하게 저장할 필요를 해결하지 않습니다. IAM 역할은 접근 권한을 관리할 수 있지만, 데이터베이스 자격 증명과 같은 민감한 정보를 안전하게 저장하는 메커니즘을 제공하지 않습니다.",
            "서버 측 암호화가 활성화된 Amazon S3에 데이터베이스 자격 증명을 저장하는 것은 평문 저장보다 나은 방법이지만, Secrets Manager를 사용하는 것만큼 안전하지는 않습니다. S3는 비밀 관리를 위해 설계되지 않았으며, 서버 측 암호화는 데이터가 저장될 때 보호하지만, Secrets Manager가 제공하는 것과 같은 수준의 접근 제어 및 비밀 관리 기능을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "40",
        "Situation": "당신은 AWS Direct Connect를 사용하여 온프레미스 데이터 센터와 AWS 간의 매우 탄력적인 연결을 구축하는 임무를 맡았습니다. 이는 중요한 애플리케이션을 위한 것입니다.",
        "Question": "Direct Connect는 본질적으로 탄력성이 없는 물리적 링크이므로, 장애 내성을 보장하기 위한 최선의 접근 방식은 무엇입니까?",
        "Options": {
            "1": "별도의 위치(DX 위치)에 두 개의 Direct Connect 연결을 배포하여 하나의 연결이 실패할 경우 중복 경로를 제공합니다.",
            "2": "단일 고대역폭 Direct Connect 연결을 사용하여 과부하로 인한 중단 위험을 줄입니다.",
            "3": "Direct Connect 연결과 VPN 백업을 결합하여 Direct Connect 링크가 다운될 경우 연결을 유지합니다.",
            "4": "서로 다른 AWS 리전에서 Direct Connect 연결을 설정하여 한 리전에서 문제가 발생할 경우 연결을 보장합니다."
        },
        "Correct Answer": "Direct Connect 연결과 VPN 백업을 결합하여 Direct Connect 링크가 다운될 경우 연결을 유지합니다.",
        "Explanation": "Direct Connect 연결과 VPN 백업을 결합하는 것은 데이터 전송을 위한 보조 경로를 제공하므로 장애 내성을 보장하는 최선의 접근 방식입니다. Direct Connect 링크가 실패할 경우 VPN이 대체 경로를 제공하여 지속적인 연결을 보장합니다. 이 하이브리드 접근 방식은 Direct Connect의 신뢰성을 활용하면서도 인터넷 기반 VPN을 장애 조치 옵션으로 활용하여 전체적인 탄력성을 향상시킵니다.",
        "Other Options": [
            "같은 AWS 리전 내의 별도의 위치에 두 개의 Direct Connect 연결을 배포하는 것은 중복성을 제공할 수 있지만, 지역 중단이나 두 연결 모두에 영향을 미칠 수 있는 기타 문제를 해결하지는 않습니다. 또한, VPN과 하이브리드 솔루션에 비해 비용 효율적이지 않을 수 있습니다.",
            "단일 고대역폭 Direct Connect 연결을 사용하는 것은 장애 내성을 제공하지 않습니다. 해당 연결이 다운되면 데이터 전송을 위한 대체 경로가 없으므로 중요한 애플리케이션의 다운타임이 발생할 수 있습니다.",
            "서로 다른 AWS 리전에서 Direct Connect 연결을 설정하는 것은 일부 수준의 중복성을 제공할 수 있지만, 리전 간 트래픽 관리의 지연 및 복잡성을 초래할 수 있습니다. 또한, 두 연결이 동시에 사용 가능하다는 보장을 제공하지 않으며, 특히 리전 자체에 영향을 미치는 문제가 발생할 경우 더욱 그렇습니다."
        ]
    },
    {
        "Question Number": "41",
        "Situation": "한 회사가 애플리케이션을 AWS로 마이그레이션할 계획을 세우고 있으며, AWS 공유 책임 모델의 일환으로 관리해야 할 보안 책임을 이해하고자 합니다. 이 회사는 애플리케이션 서버에 Amazon EC2를, 데이터베이스에 Amazon RDS를, 데이터 저장에 Amazon S3를 사용할 것입니다.",
        "Question": "다음 중 회사가 유지해야 할 책임과 AWS가 관리할 책임은 무엇입니까?",
        "Options": {
            "1": "회사는 기본 물리적 인프라의 보안에 대한 책임이 있으며, AWS는 데이터가 저장될 때의 암호화를 관리합니다.",
            "2": "AWS는 Amazon EC2 인스턴스의 패치를 담당하며, 회사는 보안 그룹과 네트워크 ACL을 사용하여 네트워크 트래픽 필터링을 관리합니다.",
            "3": "회사는 Amazon RDS의 보안 구성 관리, 즉 데이터베이스 소프트웨어의 패치를 포함하여 책임이 있으며, AWS는 RDS 인스턴스가 호스팅되는 데이터 센터의 보안을 관리합니다.",
            "4": "AWS는 Amazon S3에 저장된 고객 데이터의 보안을 관리하며, 회사는 해당 데이터에 대한 접근 권한 및 암호화 설정을 구성할 책임이 있습니다."
        },
        "Correct Answer": "회사는 Amazon RDS의 보안 구성 관리, 즉 데이터베이스 소프트웨어의 패치를 포함하여 책임이 있으며, AWS는 RDS 인스턴스가 호스팅되는 데이터 센터의 보안을 관리합니다.",
        "Explanation": "AWS 공유 책임 모델에서 AWS는 클라우드 인프라의 보안, 즉 데이터 센터의 물리적 보안과 AWS 서비스가 실행되는 하드웨어의 보안에 대한 책임이 있습니다. 그러나 고객은 애플리케이션과 데이터의 보안, 즉 Amazon RDS와 같은 서비스의 구성 관리 및 패치에 대한 책임이 있습니다. 이는 AWS가 기본 인프라를 보호하는 동안 회사는 데이터베이스 구성이 안전하고 최신 상태인지 확인해야 함을 의미합니다.",
        "Other Options": [
            "회사는 애플리케이션과 데이터의 보안에 대한 책임이 있으며, 기본 물리적 인프라는 AWS가 관리합니다. AWS는 데이터가 저장될 때의 암호화를 관리하지만, 이는 회사가 자신의 데이터에 대해 구현해야 할 책임입니다.",
            "AWS는 기본 인프라의 패치를 담당하지만, 회사는 Amazon EC2 인스턴스의 운영 체제 및 애플리케이션 수준 패치를 관리해야 합니다. 회사는 또한 네트워크 트래픽 필터링을 위한 보안 그룹과 네트워크 ACL을 구성할 책임이 있습니다.",
            "AWS는 Amazon S3를 지원하는 인프라의 보안을 관리하지만, 회사는 S3에 저장된 데이터에 대한 접근 권한 및 암호화 설정을 관리할 책임이 있습니다. AWS는 고객 데이터 보안을 직접 관리하지 않으며, 고객이 데이터를 보호할 수 있는 도구를 제공합니다."
        ]
    },
    {
        "Question Number": "42",
        "Situation": "한 회사가 여러 가용 영역(AZ)에 걸쳐 여러 서브넷을 가진 가상 사설 클라우드(VPC)를 설계하고 있습니다. 그들은 각 서브넷이 고유하게 정의되고 다른 서브넷과 겹치지 않으며, 각 서브넷 내에서 특정 기능을 위해 특정 IP 주소가 예약되어야 함을 보장해야 합니다.",
        "Question": "그들이 서브넷을 올바르게 구성하고 IP 충돌을 피하기 위해 따라야 할 지침은 무엇입니까? (두 가지 선택하세요.)",
        "Options": {
            "1": "각 서브넷에 대해 고유한 CIDR 블록을 정의하고, 다른 AZ의 다른 서브넷과 겹치도록 하며, 네트워크 및 브로드캐스트 기능을 위해 예약된 IP 주소를 사용합니다.",
            "2": "VPC 내의 모든 서브넷에 대해 동일한 CIDR 블록을 사용하여 서브넷이 AZ 간에 원활하게 통신할 수 있도록 하고, 각 서브넷의 첫 번째 IP 주소를 DNS에 예약합니다.",
            "3": "VPC 내의 각 서브넷에 대해 겹치지 않는 CIDR 블록을 할당하고, AZ당 하나의 서브넷을 두며, AWS의 요구 사항에 따라 특정 IP 주소(예: 네트워크 및 브로드캐스트 주소)를 예약합니다.",
            "4": "VPC 내의 모든 서브넷에 대해 단일 큰 CIDR 블록을 할당하고, 서브넷 간의 IP 충돌을 방지하기 위해 동적 호스트 구성 프로토콜(DHCP)을 사용합니다.",
            "5": "각 서브넷의 CIDR 블록이 VPC의 CIDR 블록의 하위 집합이 되도록 하고, 겹치지 않도록 미래 성장을 수용할 수 있도록 IP 범위를 계획합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "VPC 내의 각 서브넷에 대해 겹치지 않는 CIDR 블록을 할당하고, AZ당 하나의 서브넷을 두며, AWS의 요구 사항에 따라 특정 IP 주소(예: 네트워크 및 브로드캐스트 주소)를 예약합니다.",
            "각 서브넷의 CIDR 블록이 VPC의 CIDR 블록의 하위 집합이 되도록 하고, 겹치지 않도록 미래 성장을 수용할 수 있도록 IP 범위를 계획합니다."
        ],
        "Explanation": "정답은 옵션 3과 5입니다. 옵션 3은 VPC 내의 각 서브넷에 겹치지 않는 CIDR 블록을 할당하는 것이 각 서브넷이 고유하게 정의되고 다른 서브넷과 충돌하지 않도록 보장하기 때문에 올바릅니다. 네트워크 및 브로드캐스트 기능을 위한 특정 IP 주소를 예약하는 것은 네트워크 설계의 표준 관행입니다. 옵션 5는 각 서브넷의 CIDR 블록이 VPC의 CIDR 블록의 하위 집합이어야 하므로 올바릅니다. 이는 서브넷 내의 IP 주소가 VPC 내에서 고유함을 보장합니다. 겹치지 않도록 미래 성장을 수용할 수 있도록 IP 범위를 계획하는 것은 향후 잠재적인 IP 충돌을 피하기 위한 좋은 관행입니다.",
        "Other Options": [
            "서브넷 간의 겹치는 CIDR 블록은 IP 충돌을 초래할 수 있습니다. 또한 특정 IP 주소는 네트워크 및 브로드캐스트 기능을 위해 예약되어야 한다는 것은 사실이지만, 이 옵션은 겹치는 CIDR 블록이 좋은 관행이라고 잘못 제안합니다.",
            "VPC 내의 모든 서브넷에 대해 동일한 CIDR 블록을 사용하면 IP 충돌이 발생할 수 있습니다. 각 서브넷의 첫 번째 IP 주소가 일반적으로 DNS에 예약된다는 것은 사실이지만, 이 옵션은 모든 서브넷에 대해 동일한 CIDR 블록을 사용하는 것이 좋은 관행이라고 잘못 제안합니다.",
            "VPC 내의 모든 서브넷에 대해 단일 큰 CIDR 블록을 할당하면 IP 충돌이 발생할 수 있습니다. DHCP는 서브넷 내의 IP 주소를 관리하는 데 도움이 될 수 있지만, 동일한 CIDR 블록을 공유하는 서브넷 간의 IP 충돌을 방지할 수는 없습니다."
        ]
    },
    {
        "Question Number": "43",
        "Situation": "한 회사가 데이터베이스 요구를 위해 Amazon RDS를 사용하고 있지만, 데이터베이스 연결의 확장성과 가용성에 대해 우려하고 있습니다. 그들은 데이터베이스 연결 관리를 개선하고 RDS 인스턴스에 과부하를 주지 않으면서 애플리케이션의 높은 가용성을 보장하고자 합니다.",
        "Question": "회사가 이 목표를 달성하기 위해 어떤 AWS 서비스를 사용해야 하며, 그 이점은 무엇인가요?",
        "Options": {
            "1": "Amazon RDS Proxy를 사용하여 데이터베이스 연결을 관리하고, 연결 풀링 및 다중화를 통해 RDS 인스턴스의 부하를 줄이고 확장성을 개선합니다.",
            "2": "Amazon CloudFront를 프록시로 사용하여 데이터베이스 쿼리를 캐시하고 RDS 인스턴스의 부하를 줄입니다.",
            "3": "Amazon SQS를 사용하여 데이터베이스 요청을 큐에 넣고 순차적으로 처리하여 데이터베이스 연결의 높은 가용성을 보장합니다.",
            "4": "Amazon ElastiCache를 사용하여 데이터베이스 쿼리를 프록시하고 캐시하여 데이터베이스 부하를 최소화합니다."
        },
        "Correct Answer": "Amazon RDS Proxy를 사용하여 데이터베이스 연결을 관리하고, 연결 풀링 및 다중화를 통해 RDS 인스턴스의 부하를 줄이고 확장성을 개선합니다.",
        "Explanation": "Amazon RDS Proxy는 Amazon RDS의 데이터베이스 연결 관리를 향상시키기 위해 특별히 설계되었습니다. 연결 풀링 및 다중화를 제공하여 RDS 인스턴스와 설정해야 하는 연결 수를 줄이는 데 도움을 줍니다. 이는 더 많은 동시 연결을 허용하여 애플리케이션의 확장성을 개선할 뿐만 아니라, 장애 조치 시나리오를 원활하게 관리하여 가용성을 향상시킵니다. RDS Proxy를 사용함으로써 회사는 데이터베이스 연결이 효율적으로 관리되도록 보장하고, RDS 인스턴스의 부하를 줄이며 전체 애플리케이션 성능을 개선할 수 있습니다.",
        "Other Options": [
            "Amazon CloudFront를 프록시로 사용하여 데이터베이스 쿼리를 캐시하는 것은 잘못된 선택입니다. CloudFront는 주로 정적 콘텐츠를 캐시하고 웹 애플리케이션의 전달 속도를 높이기 위해 설계된 콘텐츠 전송 네트워크(CDN)로, 데이터베이스 연결 관리나 데이터베이스 쿼리 캐싱을 위한 것이 아닙니다.",
            "Amazon SQS를 사용하여 데이터베이스 요청을 큐에 넣는 것은 이 시나리오에 적합하지 않습니다. SQS는 마이크로서비스, 분산 시스템 및 서버리스 애플리케이션을 분리하고 확장하기 위해 설계된 메시지 큐 서비스로, 데이터베이스 연결을 직접 관리하거나 가용성을 개선하지 않습니다.",
            "Amazon ElastiCache를 사용하여 데이터베이스 쿼리를 프록시하고 캐시하는 것은 이 맥락에서 최선의 선택이 아닙니다. ElastiCache는 자주 접근되는 데이터를 캐시하여 데이터베이스의 부하를 줄이는 데 사용할 수 있지만, 데이터베이스 연결을 관리하거나 연결 풀링을 제공하지 않으며, 이는 이 시나리오에서 확장성과 가용성의 주요 관심사입니다."
        ]
    },
    {
        "Question Number": "44",
        "Situation": "한 회사가 확장성, 이식성 및 자원 관리를 개선하기 위해 단일 애플리케이션을 컨테이너화된 아키텍처로 마이그레이션할 계획입니다. 이 회사는 트래픽 급증 시 효율적인 확장을 보장하기 위해 단일 애플리케이션을 더 작고 관리하기 쉬운 구성 요소로 분해하고자 합니다. 또한 애플리케이션이 환경과 플랫폼 간에 쉽게 이동할 수 있도록 해야 합니다.",
        "Question": "애플리케이션을 컨테이너로 마이그레이션하는 가장 효과적인 접근 방식은 무엇입니까?",
        "Options": {
            "1": "각 마이크로서비스에 대한 Docker 이미지를 생성하여 각 애플리케이션 구성 요소를 컨테이너화하고, Amazon ECS 또는 EKS에서 컨테이너를 배포하여 오케스트레이션 및 관리를 수행합니다.",
            "2": "전체 애플리케이션을 가상 머신으로 AWS에 마이그레이션하고 EC2 Auto Scaling 그룹을 통해 애플리케이션을 관리합니다.",
            "3": "AWS Lambda를 사용하여 애플리케이션을 마이그레이션하고 서버리스 함수로 분해하여 컨테이너의 필요성을 없앱니다.",
            "4": "애플리케이션을 Amazon S3에 저장하고 AWS Fargate를 사용하여 관리되는 컨테이너 환경에서 애플리케이션을 실행합니다."
        },
        "Correct Answer": "각 마이크로서비스에 대한 Docker 이미지를 생성하여 각 애플리케이션 구성 요소를 컨테이너화하고, Amazon ECS 또는 EKS에서 컨테이너를 배포하여 오케스트레이션 및 관리를 수행합니다.",
        "Explanation": "이 접근 방식은 단일 애플리케이션을 컨테이너화된 아키텍처로 마이그레이션하는 데 가장 효과적입니다. 애플리케이션을 더 작고 관리하기 쉬운 마이크로서비스로 분해할 수 있기 때문입니다. 각 구성 요소에 대한 Docker 이미지를 생성함으로써 회사는 각 마이크로서비스가 독립적으로 배포 가능하고 확장 가능하며 유지 관리 가능하도록 보장할 수 있습니다. Amazon ECS(Elastic Container Service) 또는 EKS(Elastic Kubernetes Service)를 사용하면 트래픽 급증 시 효율적인 확장과 다양한 환경 및 플랫폼 간의 원활한 이동을 가능하게 하는 강력한 오케스트레이션 및 관리 기능을 제공합니다.",
        "Other Options": [
            "전체 애플리케이션을 가상 머신으로 AWS에 마이그레이션하는 것은 컨테이너화의 이점을 충분히 활용하지 못합니다. EC2 Auto Scaling 그룹을 통해 확장이 가능하지만, 단일 애플리케이션을 마이크로서비스로 분해하지 않기 때문에 원하는 확장성과 자원 관리를 달성하는 데 필수적입니다.",
            "AWS Lambda를 사용하여 애플리케이션을 서버리스 함수로 마이그레이션하는 것은 모든 애플리케이션에 적합하지 않으며, 특히 서버리스로 설계되지 않은 애플리케이션에는 적합하지 않습니다. 이 접근 방식은 애플리케이션의 상당한 재설계를 요구할 수 있으며, 회사가 구현하고자 하는 컨테이너를 활용하지 않습니다.",
            "애플리케이션을 Amazon S3에 저장하고 AWS Fargate를 사용하여 관리되는 컨테이너 환경에서 애플리케이션을 실행하는 것은 완전한 솔루션이 아닙니다. Fargate는 서버를 관리하지 않고 컨테이너를 실행할 수 있게 해주지만, 단순히 S3에 애플리케이션을 저장하는 것은 단일 애플리케이션을 마이크로서비스로 분해하거나 Docker 이미지를 생성하는 필요성을 해결하지 않습니다. 이는 효과적인 컨테이너화를 위해 매우 중요합니다."
        ]
    },
    {
        "Question Number": "45",
        "Situation": "한 금융 서비스 회사는 클라이언트 데이터를 보호하기 위해 새로운 웹 애플리케이션을 HTTPS로 안전하게 설정해야 합니다. 그들은 만료된 인증서로 인한 다운타임 위험을 피하기 위해 SSL/TLS 인증서 발급, 배포 및 갱신을 간소화하는 솔루션을 원합니다. 대부분의 인프라가 AWS에 구축되어 있어, ELB, CloudFront 및 API Gateway와 같은 서비스에서 인증서를 관리하기 위해 AWS Certificate Manager (ACM)를 고려하고 있습니다.",
        "Question": "AWS Certificate Manager (ACM)는 회사의 요구에 맞춰 안전하고 자동화된 SSL/TLS 인증서 관리를 어떻게 지원합니까?",
        "Options": {
            "1": "ACM은 수동 인증서 발급 및 갱신을 허용하여 갱신 프로세스에 대한 제어를 제공합니다.",
            "2": "ACM은 인증서를 자동으로 발급, 배포 및 갱신하며, AWS 서비스와 통합되고 AWS 리소스와 함께 사용할 때 무료로 인증서를 제공합니다.",
            "3": "ACM은 자가 서명된 인증서만 지원하여 회사가 갱신 및 보안을 별도로 처리해야 합니다.",
            "4": "ACM은 인증서를 발급하지만 갱신을 위해 타사 도구가 필요하며 AWS 서비스와 직접 통합되지 않습니다."
        },
        "Correct Answer": "ACM은 인증서를 자동으로 발급, 배포 및 갱신하며, AWS 서비스와 통합되고 AWS 리소스와 함께 사용할 때 무료로 인증서를 제공합니다.",
        "Explanation": "AWS Certificate Manager (ACM)는 SSL/TLS 인증서의 발급, 배포 및 갱신 프로세스를 자동화하여 관리의 간소화를 제공합니다. 이는 금융 서비스 회사가 만료된 인증서로 인한 다운타임 위험을 피할 수 있도록 하며, ACM이 자동으로 갱신을 처리하기 때문입니다. 또한, ACM은 Elastic Load Balancing (ELB), CloudFront 및 API Gateway와 같은 다양한 AWS 서비스와 원활하게 통합되며, 이러한 서비스와 함께 사용할 때 무료로 인증서를 제공하여 웹 애플리케이션 보안을 위한 비용 효율적인 솔루션이 됩니다.",
        "Other Options": [
            "ACM은 수동 인증서 발급 및 갱신을 허용하지만, 회사의 요구는 만료된 인증서의 위험을 피하기 위한 자동화에 중점을 두고 있습니다. 수동 프로세스는 요구되는 인증서 관리의 간소화를 제공하지 않습니다.",
            "ACM은 자가 서명된 인증서만 지원하지 않습니다. 주로 브라우저와 클라이언트에서 신뢰받는 공개 인증서를 발급하며, 이는 프로덕션 환경에서 클라이언트 데이터를 보호하는 데 필수적입니다.",
            "ACM은 갱신을 위해 타사 도구를 필요로 하지 않으며, 갱신 프로세스를 자동화합니다. 또한, ACM은 AWS 서비스와 직접 통합되도록 설계되어 있어 회사의 인프라 요구를 지원하는 주요 기능입니다."
        ]
    },
    {
        "Question Number": "46",
        "Situation": "",
        "Question": "Amazon Redshift의 어떤 기능이 백업 및 재해 복구 기능을 제공하여 데이터 내구성과 복원력을 보장합니까?",
        "Options": {
            "1": "Enhanced VPC Routing, 이는 VPC 내에서 맞춤형 네트워킹을 허용합니다.",
            "2": "Compute Nodes의 Slices, 이는 여러 노드에 걸쳐 데이터와 쿼리를 분산할 수 있게 합니다.",
            "3": "S3에 대한 자동 스냅샷, 데이터가 8시간마다 또는 5GB 증가할 때마다 Amazon S3에 백업됩니다.",
            "4": "Redshift Spectrum, S3에 있는 데이터를 Redshift로 로드하지 않고 직접 쿼리할 수 있게 합니다."
        },
        "Correct Answer": "S3에 대한 자동 스냅샷, 데이터가 8시간마다 또는 5GB 증가할 때마다 Amazon S3에 백업됩니다.",
        "Explanation": "Amazon Redshift는 데이터 내구성과 복원력을 보장하기 위해 S3에 대한 자동 스냅샷을 제공하는 주요 기능을 갖추고 있습니다. 이 기능은 Redshift에 저장된 데이터를 8시간마다 또는 데이터 크기가 5GB 증가할 때마다 Amazon S3에 자동으로 백업합니다. 이러한 스냅샷은 데이터 손실 또는 손상 시 이전 상태로 데이터를 복원할 수 있게 하여 데이터의 무결성과 가용성을 보장하는 데 중요합니다.",
        "Other Options": [
            "Enhanced VPC Routing은 주로 가상 사설 클라우드(VPC) 내에서 네트워크 보안 및 트래픽 관리를 개선하는 데 중점을 두며, 데이터 내구성이나 백업 기능과는 직접적인 관련이 없습니다.",
            "Compute Nodes의 Slices는 Redshift 클러스터 내에서 데이터가 여러 노드에 걸쳐 분산되고 처리되는 방식을 나타냅니다. 이는 성능과 확장성을 향상시키지만 백업이나 재해 복구 기능을 제공하지 않습니다.",
            "Redshift Spectrum은 사용자가 S3에 있는 데이터를 Redshift로 로드하지 않고 직접 쿼리할 수 있게 하여 대용량 데이터 세트에 접근하는 데 유용하지만 백업이나 재해 복구 기능을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "47",
        "Situation": "한 회사가 AWS에서 보안 네트워크 아키텍처를 설계하고 있으며, 일부 리소스는 공용 액세스가 필요하고 다른 리소스는 VPC 내에서 비공식 액세스로 제한되어야 합니다. 그들은 민감한 데이터가 인터넷으로부터 격리되도록 하면서 특정 공용 AWS 서비스에 대한 안전한 액세스를 허용하고자 합니다.",
        "Question": "다음 접근 방식 중 어떤 것이 그들의 보안 요구 사항을 가장 잘 충족합니까?",
        "Options": {
            "1": "모든 리소스를 AWS Public Zone에 공용 IP로 배포하여 액세스 및 보안 관리를 단순화합니다.",
            "2": "민감한 EC2 인스턴스를 AWS Private Zone 내의 프라이빗 서브넷에 배치하고, NAT 게이트웨이를 통해 인터넷에 액세스하며, VPC에 대한 안전한 온프레미스 액세스를 위해 VPN 또는 Direct Connect를 사용합니다.",
            "3": "민감한 서비스에 대해 공용 서브넷을 사용하고 보안 그룹을 적용하여 인바운드 및 아웃바운드 트래픽을 제어합니다.",
            "4": "공용 서브넷에서 AWS 서비스에 직접 인터넷을 통해 액세스하도록 비공용 서비스를 구성합니다."
        },
        "Correct Answer": "민감한 EC2 인스턴스를 AWS Private Zone 내의 프라이빗 서브넷에 배치하고, NAT 게이트웨이를 통해 인터넷에 액세스하며, VPC에 대한 안전한 온프레미스 액세스를 위해 VPN 또는 Direct Connect를 사용합니다.",
        "Explanation": "이 접근 방식은 민감한 데이터와 리소스를 프라이빗 서브넷에 배치하여 효과적으로 격리합니다. NAT 게이트웨이를 사용하면 이러한 프라이빗 인스턴스가 인터넷으로 아웃바운드 트래픽을 시작할 수 있지만(업데이트 등을 위해) 인터넷으로부터의 인바운드 트래픽은 차단되어 보안을 유지합니다. 또한 VPN 또는 Direct Connect를 사용하면 VPC에 대한 온프레미스 액세스를 위한 안전한 연결을 제공하여 민감한 데이터가 공공 노출로부터 보호되도록 합니다.",
        "Other Options": [
            "모든 리소스를 AWS Public Zone에 공용 IP로 배포하면 액세스는 단순해지지만 모든 리소스가 인터넷에 노출되어 민감한 데이터에 대한 심각한 보안 위험이 발생합니다.",
            "민감한 서비스에 대해 공용 서브넷을 사용하는 것은 인터넷으로부터의 격리 요구 사항에 위배됩니다. 공용 서브넷은 인터넷에서 접근 가능하여 민감한 데이터에 대한 무단 접근을 초래할 수 있습니다.",
            "공용 서브넷에서 AWS 서비스에 직접 인터넷을 통해 액세스하도록 비공용 서비스를 구성하는 것은 불가능합니다. 공용 서브넷은 본질적으로 인터넷에 노출되어 있어 민감한 데이터의 격리라는 보안 요구 사항을 충족하지 않습니다."
        ]
    },
    {
        "Question Number": "48",
        "Situation": "한 회사가 AWS에서 새로운 마이크로서비스 기반 애플리케이션을 배포하고 있습니다. 각 마이크로서비스는 Docker 컨테이너에 패키징되어 있습니다. 이 애플리케이션은 컨테이너를 관리하고, 확장을 처리하며, 고가용성을 보장하기 위한 오케스트레이션이 필요합니다.",
        "Question": "컨테이너 오케스트레이션을 위해 솔루션 아키텍트가 추천해야 할 AWS 서비스는 무엇입니까?",
        "Options": {
            "1": "Amazon EC2 Auto Scaling",
            "2": "AWS Lambda",
            "3": "Amazon Elastic Kubernetes Service (EKS)",
            "4": "Amazon Elastic Container Service (ECS)"
        },
        "Correct Answer": "Amazon Elastic Kubernetes Service (EKS)",
        "Explanation": "Amazon Elastic Kubernetes Service (EKS)는 Kubernetes를 AWS에서 쉽게 실행할 수 있도록 해주는 완전 관리형 서비스입니다. EKS는 Docker 컨테이너 관리를 위한 오케스트레이션을 제공하며, 확장 및 고가용성을 포함합니다. EKS는 마이크로서비스 아키텍처에 특히 적합하며, Kubernetes를 사용하여 컨테이너화된 애플리케이션의 배포, 확장 및 관리를 가능하게 합니다. Kubernetes는 업계에서 널리 채택된 오케스트레이션 도구입니다.",
        "Other Options": [
            "Amazon EC2 Auto Scaling은 수요에 따라 EC2 인스턴스 수를 자동으로 조정하는 서비스입니다. 애플리케이션의 확장을 도울 수 있지만 Docker 컨테이너 관리를 위한 컨테이너 오케스트레이션 기능을 제공하지 않습니다.",
            "AWS Lambda는 이벤트에 응답하여 코드를 실행하고 필요한 컴퓨팅 리소스를 자동으로 관리하는 서버리스 컴퓨팅 서비스입니다. 이는 컨테이너 오케스트레이션을 위해 설계되지 않았으며, 여러 마이크로서비스를 관리하기보다는 이벤트 기반 아키텍처에 더 적합합니다.",
            "Amazon Elastic Container Service (ECS)는 AWS에서 제공하는 또 다른 컨테이너 오케스트레이션 서비스입니다. Docker 컨테이너를 관리할 수 있으며 확장 및 고가용성을 처리할 수 있지만, 질문은 오케스트레이션을 구체적으로 요구하며, EKS는 광범위한 기능과 커뮤니티 지원으로 인해 Kubernetes 기반 애플리케이션에 선호됩니다."
        ]
    },
    {
        "Question Number": "49",
        "Situation": "빠르게 성장하는 전자상거래 플랫폼이 백엔드 서비스를 확장하여 높은 트래픽 볼륨을 처리하기 위해 들어오는 API 요청을 효율적으로 관리하고자 합니다. 그들은 요청이 승인되고, 검증되며, 변환되고, 최적의 성능을 위해 캐시되도록 하기를 원합니다. 또한 플랫폼은 요청-응답 주기를 모니터링하고 사용에 대한 자세한 메트릭을 수집하고자 합니다.",
        "Question": "회사가 신뢰할 수 있고 확장 가능한 API 관리 레이어를 구축하기 위해 어떤 AWS 서비스를 사용해야 하며, 이 서비스의 어떤 특정 기능이 그들의 요구 사항을 지원합니까?",
        "Options": {
            "1": "Amazon API Gateway, 이는 승인, 속도 제한, 캐싱을 처리할 수 있으며 AWS CloudWatch와 원활하게 통합되어 실시간 모니터링 및 메트릭 수집을 지원합니다.",
            "2": "AWS Lambda, 이는 서버리스 컴퓨팅 용량을 제공하며 각 요청을 독립적으로 처리하고 승인하는 데 사용할 수 있습니다.",
            "3": "로드 밸런싱 및 캐싱을 관리하기 위해 NGINX가 있는 Amazon EC2 인스턴스를 사용하고, 메트릭 및 로깅을 위해 CloudWatch 에이전트를 활용합니다.",
            "4": "액세스를 제한하기 위해 서명된 URL이 있는 Amazon S3와 캐싱을 위한 CloudFront를 사용하여 백엔드 서비스의 부하를 줄입니다."
        },
        "Correct Answer": "Amazon API Gateway, 이는 승인, 속도 제한, 캐싱을 처리할 수 있으며 AWS CloudWatch와 원활하게 통합되어 실시간 모니터링 및 메트릭 수집을 지원합니다.",
        "Explanation": "Amazon API Gateway는 대규모로 API를 생성, 배포 및 관리하기 위해 특별히 설계되었습니다. 이는 승인(AWS IAM, Lambda 승인자 또는 Amazon Cognito 사용), 요청 검증, 요청 및 응답 변환, 성능 향상을 위한 캐싱을 위한 내장 기능을 제공합니다. 또한 AWS CloudWatch와 통합되어 플랫폼이 API 사용을 모니터링하고 요청-응답 주기를 추적하며 자세한 메트릭을 수집할 수 있게 하여 높은 트래픽 볼륨을 효율적으로 관리하는 데 필요한 요구 사항과 완벽하게 일치합니다.",
        "Other Options": [
            "AWS Lambda는 요청을 처리할 수 있는 서버리스 컴퓨팅 서비스이지만 전체 API 관리 레이어를 제공하지 않습니다. 요청의 승인 및 처리를 처리할 수 있지만, API Gateway가 제공하는 캐싱, 속도 제한 및 포괄적인 모니터링을 위한 내장 기능이 부족합니다.",
            "NGINX가 있는 Amazon EC2 인스턴스는 로드 밸런싱 및 캐싱을 관리하도록 구성할 수 있지만, 이 접근 방식은 API Gateway에 비해 더 많은 수동 설정 및 관리가 필요합니다. 또한 CloudWatch 에이전트가 메트릭을 제공할 수 있지만, API 관리에 대한 API Gateway와 같은 수준의 통합 및 사용 용이성을 제공하지 않습니다.",
            "서명된 URL이 있는 Amazon S3와 CloudFront는 정적 콘텐츠에 대한 안전한 액세스 및 캐싱을 제공할 수 있지만, 동적 API 요청을 관리하는 데 적합하지 않습니다. 이 솔루션은 승인, 요청 검증 및 API 사용에 대한 자세한 모니터링에 필요한 기능이 부족하여 전자상거래 플랫폼의 요구 사항에 적합하지 않습니다."
        ]
    },
    {
        "Question Number": "50",
        "Situation": "한 회사가 다중 계층 웹 애플리케이션을 위한 여러 서브넷을 가진 VPC를 구성하고 있습니다. 애플리케이션의 공용 서브넷은 인터넷 액세스를 허용해야 하며, 비공용 서브넷은 NAT 게이트웨이를 통해서만 인터넷으로 아웃바운드 트래픽을 허용해야 합니다.",
        "Question": "이 서브넷 간의 트래픽을 올바르게 라우팅하기 위한 가장 효율적인 방법은 무엇입니까?",
        "Options": {
            "1": "인터넷 게이트웨이를 가리키는 기본 경로(0.0.0.0/0)를 가진 공용 서브넷용 라우트 테이블을 생성하고, NAT 게이트웨이를 향하는 경로가 있는 비공용 서브넷용 라우트 테이블을 생성합니다.",
            "2": "공용 및 비공용 서브넷 모두에 대해 단일 라우트 테이블을 생성하고 아웃바운드 인터넷 액세스를 위한 NAT 게이트웨이에 대한 경로를 추가합니다.",
            "3": "외부 트래픽을 위해 인터넷 게이트웨이를 직접 가리키는 비공용 서브넷용 라우트 테이블을 생성합니다.",
            "4": "Amazon Route 53을 사용하여 두 서브넷의 라우팅을 처리하고 모든 트래픽을 내부 DNS 서버로 라우팅합니다."
        },
        "Correct Answer": "인터넷 게이트웨이를 가리키는 기본 경로(0.0.0.0/0)를 가진 공용 서브넷용 라우트 테이블을 생성하고, NAT 게이트웨이를 향하는 경로가 있는 비공용 서브넷용 라우트 테이블을 생성합니다.",
        "Explanation": "이 옵션은 VPC 내의 공용 및 비공용 서브넷에 대한 라우팅을 올바르게 설정합니다. 공용 서브넷은 모든 아웃바운드 트래픽(0.0.0.0/0)을 인터넷 게이트웨이로 라우팅하는 라우트 테이블이 필요하며, 이를 통해 해당 서브넷의 인스턴스가 인터넷에 직접 액세스할 수 있습니다. 반면 비공용 서브넷은 직접 인터넷에 액세스할 수 없어야 하며, 대신 NAT 게이트웨이를 통해 아웃바운드 트래픽을 라우팅해야 하며, 이는 비공용 서브넷의 인스턴스에 대한 인터넷 액세스를 처리합니다. 이 구성은 공용 서브넷이 웹 트래픽을 제공할 수 있도록 하면서 비공용 서브넷의 보안을 유지합니다.",
        "Other Options": [
            "공용 및 비공용 서브넷 모두에 대해 단일 라우트 테이블을 생성하고 NAT 게이트웨이에 대한 경로를 추가하는 것은 잘못된 접근입니다. 공용 서브넷은 인터넷 게이트웨이로 트래픽을 라우팅해야 하며, NAT 게이트웨이는 비공용 서브넷의 아웃바운드 트래픽에만 해당됩니다.",
            "외부 트래픽을 위해 인터넷 게이트웨이를 직접 가리키는 비공용 서브넷용 라우트 테이블을 생성하는 것은 잘못된 접근입니다. 비공용 서브넷은 인터넷에 직접 접근할 수 없어야 하며, NAT 게이트웨이를 통해 트래픽을 라우팅해야 보안을 유지할 수 있습니다.",
            "Amazon Route 53을 사용하여 두 서브넷의 라우팅을 처리하고 모든 트래픽을 내부 DNS 서버로 라우팅하는 것은 잘못된 접근입니다. Route 53은 주로 DNS 서비스이며 VPC 내의 서브넷 간 라우팅을 관리하지 않습니다. 라우팅은 라우트 테이블에 의해 처리됩니다."
        ]
    },
    {
        "Question Number": "51",
        "Situation": "미디어 공유 플랫폼은 사용자가 비디오를 업로드할 수 있도록 하며, 업로드된 비디오는 다양한 장치에서 최적의 재생을 위해 자동으로 여러 형식으로 변환됩니다. 이 플랫폼은 사용자 인증을 위해 Google을 신원 제공자로 사용하며, 로그인에 성공하면 사용자는 Amazon S3 버킷에 비디오를 업로드할 수 있습니다. 비디오를 처리하고 로드하며, 변환 작업을 시작하고 DynamoDB 테이블의 메타데이터를 업데이트하는 일련의 Lambda 함수가 트리거됩니다.",
        "Question": "이 서버리스 아키텍처가 플랫폼에 제공하는 이점은 무엇인가요?",
        "Options": {
            "1": "정해진 기간 내에 비디오 처리가 보장됨",
            "2": "최소한의 서버 관리로 운영 오버헤드가 낮아짐",
            "3": "비디오 변환 작업에 수동 개입이 필요함",
            "4": "높은 업로드 트래픽을 처리하기 위한 전용 서버"
        },
        "Correct Answer": "최소한의 서버 관리로 운영 오버헤드가 낮아짐",
        "Explanation": "서버리스 아키텍처는 플랫폼이 AWS Lambda, S3 및 DynamoDB와 같은 클라우드 서비스를 활용할 수 있게 하여 기본 서버를 관리할 필요가 없습니다. 이로 인해 운영 오버헤드가 낮아지고, 플랫폼은 서버 유지 관리, 프로비저닝 또는 확장 문제에 대해 걱정하지 않고 개발 및 확장에 집중할 수 있습니다. Lambda 함수의 자동 확장과 S3 및 DynamoDB의 관리 특성은 수동 개입 및 서버 관리의 필요성을 더욱 줄여줍니다.",
        "Other Options": [
            "정해진 기간 내에 비디오 처리가 보장됨은 서버리스 아키텍처의 이점이 아닙니다. 서버리스 함수는 자동으로 확장할 수 있지만, 처리 기간에 대한 보장은 없으며 이는 작업량 및 기타 요인에 따라 달라질 수 있습니다.",
            "비디오 변환 작업에 수동 개입이 필요하다는 것은 서버리스 아키텍처의 이점과 모순됩니다. 이 시나리오에서 Lambda 함수의 사용은 변환 작업이 수동 개입 없이 자동화되어 있음을 나타냅니다.",
            "높은 업로드 트래픽을 처리하기 위한 전용 서버는 서버리스 아키텍처의 특성이 아닙니다. 대신, 서버리스 솔루션은 필요에 따라 동적으로 리소스를 할당하여 전용 서버의 필요성을 없애고 더 효율적인 리소스 활용을 가능하게 합니다."
        ]
    },
    {
        "Question Number": "52",
        "Situation": "한 금융 서비스 회사는 여러 AWS 계정에 저장된 민감한 클라이언트 데이터를 위한 암호화 키를 관리하기 위해 AWS Key Management Service (KMS)를 사용하고 있습니다. 보안 팀은 특정 키에 대한 접근을 허가된 인원 및 애플리케이션만 가능하도록 접근 정책을 구현해야 하며, 무단 접근을 방지해야 합니다. 규제 요구 사항을 준수하기 위해 역할, 부서 및 특정 프로젝트에 따라 접근을 제한해야 합니다.",
        "Question": "이 접근 정책을 효과적으로 시행하기 위해 어떤 접근 방식을 취해야 할까요? (두 가지 선택)",
        "Options": {
            "1": "KMS에서 리소스 기반 정책을 사용하여 각 키에 대한 특정 접근 권한을 정의하고 이러한 권한을 관련 IAM 사용자, 그룹 및 역할에 할당합니다.",
            "2": "각 부서에 대한 보안 그룹을 생성하고 관련 암호화 키를 연결한 후 네트워크 수준의 권한을 적용하여 접근을 제어합니다.",
            "3": "AWS S3 버킷 정책을 통해 접근 제어를 구현하여 어떤 사용자가 키로 암호화된 데이터에 접근할 수 있는지를 제어합니다.",
            "4": "각 부서 및 프로젝트에 대해 최소 권한을 가진 AWS Identity and Access Management (IAM) 역할을 활용합니다.",
            "5": "AWS Shield에 의존하여 모든 리소스에 대한 암호화 키 접근 정책을 관리하고 시행합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "KMS에서 리소스 기반 정책을 사용하여 각 키에 대한 특정 접근 권한을 정의하고 이러한 권한을 관련 IAM 사용자, 그룹 및 역할에 할당합니다.",
            "각 부서 및 프로젝트에 대해 최소 권한을 가진 AWS Identity and Access Management (IAM) 역할을 활용합니다."
        ],
        "Explanation": "정답은 KMS에서 리소스 기반 정책을 사용하고 최소 권한을 가진 IAM 역할을 활용하는 것입니다. KMS의 리소스 기반 정책을 사용하면 누가 어떤 키에 접근할 수 있는지를 지정할 수 있으며, 이러한 권한을 관련 IAM 사용자, 그룹 및 역할에 할당할 수 있습니다. 이는 역할, 부서 및 특정 프로젝트에 따라 접근을 제한해야 하는 요구 사항과 일치합니다. 최소 권한을 가진 IAM 역할은 각 부서와 프로젝트가 필요한 리소스에만 접근할 수 있도록 보장하여 무단 접근의 위험을 줄이는 좋은 접근 방식입니다.",
        "Other Options": [
            "각 부서에 대한 보안 그룹을 생성하고 관련 암호화 키를 연결하는 것은 올바른 접근 방식이 아닙니다. AWS의 보안 그룹은 인스턴스 수준에서 수신 및 송신 트래픽을 제어하는 데 사용되며, 암호화 키에 대한 접근을 관리하는 데 사용되지 않습니다.",
            "AWS S3 버킷 정책을 통해 접근 제어를 구현하는 것은 올바른 접근 방식이 아닙니다. S3 버킷 정책은 버킷 내 데이터에 접근할 수 있는 사용자를 제어할 수 있지만, KMS 암호화 키에 대한 접근을 관리하지 않습니다.",
            "AWS Shield에 의존하여 암호화 키 접근 정책을 관리하고 시행하는 것은 올바른 접근 방식이 아닙니다. AWS Shield는 관리형 분산 서비스 거부(DDoS) 보호 서비스이지 암호화 키 접근을 관리하는 서비스가 아닙니다."
        ]
    },
    {
        "Question Number": "53",
        "Situation": "한 회사는 시스템이 장애에서 신속하게 복구되도록 보장하는 재해 복구(DR) 전략이 필요하며, 다운타임을 최소화하고자 합니다. 이 회사는 복구 시간 목표(RTO)와 복구 지점 목표(RPO)를 최소화하고, 애플리케이션이 최소한의 성능 영향으로 계속 실행될 수 있도록 보조 지역에 추가 인프라를 구현할 의향이 있습니다.",
        "Question": "회사가 어떤 DR 전략을 구현해야 할까요?",
        "Options": {
            "1": "두 지역에서 활성-활성 장애 조치 전략을 구현하여 애플리케이션이 항상 두 지역에서 실행되고 트래픽이 동적으로 분산되도록 합니다.",
            "2": "보조 지역에서 최소한의 인프라를 운영하는 따뜻한 대기 전략을 구현하고, 장애 조치가 발생할 때 리소스를 확장합니다.",
            "3": "데이터를 Amazon S3에 백업하고 장애 발생 시 수동으로 복원하는 백업 및 복원 전략을 구현합니다.",
            "4": "보조 지역에서 최소한의 인프라를 운영하고 필요할 때만 전체 용량으로 확장하는 파일럿 라이트 전략을 구현합니다."
        },
        "Correct Answer": "두 지역에서 활성-활성 장애 조치 전략을 구현하여 애플리케이션이 항상 두 지역에서 실행되고 트래픽이 동적으로 분산되도록 합니다.",
        "Explanation": "활성-활성 장애 조치 전략은 애플리케이션이 두 지역에서 동시에 실행되도록 하여 두 지역 모두 항상 트래픽을 처리할 수 있게 합니다. 이 설정은 장애 발생 시 보조 지역으로 전환할 필요가 없으므로 다운타임을 크게 줄입니다. 이 접근 방식은 데이터가 두 지역 간에 지속적으로 동기화되므로 복구 시간 목표(RTO)와 복구 지점 목표(RPO)를 효과적으로 최소화합니다.",
        "Other Options": [
            "따뜻한 대기 전략을 구현하는 것은 보조 지역에서 최소한의 인프라를 유지하고 장애 조치가 발생할 때 리소스를 확장하는 것입니다. 이는 차가운 대기보다 복구 시간을 개선하지만, 리소스를 확장하는 데 시간이 필요하므로 다운타임이 증가하고 RTO가 높아질 수 있습니다.",
            "백업 및 복원 전략은 데이터의 주기적인 백업에 의존하며, 이러한 백업에서 수동으로 시스템을 복원해야 합니다. 이 접근 방식은 애플리케이션과 데이터를 복원하는 데 상당한 시간이 걸릴 수 있으므로 최소한의 다운타임이 중요한 시나리오에는 적합하지 않습니다.",
            "파일럿 라이트 전략은 보조 지역에서 애플리케이션의 최소 버전을 유지하고 장애 조치 시 전체 용량으로 확장할 수 있도록 합니다. 이는 차가운 대기보다 더 효율적이지만, 여전히 확장하는 데 시간이 필요하므로 활성-활성 전략에 비해 RTO가 더 길어질 수 있습니다."
        ]
    },
    {
        "Question Number": "54",
        "Situation": "한 금융 기관은 AWS에 저장된 고객 데이터를 보호하기 위해 암호화를 사용하며, 규제 요구 사항을 준수하기 위해 정기적으로 암호화 키를 회전하고 SSL 인증서를 갱신해야 합니다. 이 기관은 수동 개입을 피하고 인적 오류의 위험을 줄이기 위해 키 회전 및 인증서 갱신을 자동화해야 합니다.",
        "Question": "이 기관이 AWS 환경에서 키 회전 및 인증서 갱신을 효율적으로 관리하기 위해 어떤 접근 방식을 취해야 할까요?",
        "Options": {
            "1": "AWS KMS에서 자동 키 회전을 활성화하고 AWS Certificate Manager (ACM)를 사용하여 관리 도메인에 대한 SSL/TLS 인증서를 자동으로 갱신합니다.",
            "2": "KMS 키를 90일마다 수동으로 회전하고 SSL 인증서를 제3자 제공업체에 요청하여 새 인증서를 갱신합니다.",
            "3": "IAM 정책을 사용하여 AWS 계정 전반에 걸쳐 정기적인 키 회전 및 인증서 갱신을 시행합니다.",
            "4": "AWS CloudTrail을 설정하여 암호화 키를 자동으로 회전하고 만료가 가까워지면 인증서를 갱신합니다."
        },
        "Correct Answer": "AWS KMS에서 자동 키 회전을 활성화하고 AWS Certificate Manager (ACM)를 사용하여 관리 도메인에 대한 SSL/TLS 인증서를 자동으로 갱신합니다.",
        "Explanation": "이 접근 방식은 자동화 및 규정 준수를 위해 설계된 AWS 서비스를 활용합니다. AWS Key Management Service (KMS)는 자동 키 회전을 허용하여 암호화 키가 정기적으로 수동 개입 없이 회전되도록 하여 인적 오류의 위험을 줄입니다. 또한, AWS Certificate Manager (ACM)는 관리 도메인에 대한 SSL/TLS 인증서를 자동으로 갱신하여 프로세스를 간소화하고 인증서가 항상 최신 상태를 유지하도록 합니다. 이 조합은 기관의 규정 준수 및 보안 요구 사항을 효과적으로 충족합니다.",
        "Other Options": [
            "KMS 키를 90일마다 수동으로 회전하고 SSL 인증서를 제3자 제공업체에 요청하여 새 인증서를 갱신하는 것은 비효율적이며 인적 오류의 위험이 있습니다. 이 접근 방식은 프로세스를 자동화하지 않으므로 규정 준수를 유지하고 간과의 위험을 줄이는 데 중요합니다.",
            "IAM 정책을 사용하여 AWS 계정 전반에 걸쳐 정기적인 키 회전 및 인증서 갱신을 시행하는 것은 프로세스를 직접 자동화하지 않습니다. IAM 정책은 권한 및 접근 제어를 시행할 수 있지만 실제 회전 또는 갱신 작업을 처리하지 않으므로 기관의 요구 사항에 덜 효과적입니다.",
            "AWS CloudTrail을 설정하여 암호화 키를 자동으로 회전하고 만료가 가까워지면 인증서를 갱신하는 것은 잘못된 접근입니다. CloudTrail은 AWS에서 API 호출 및 활동을 추적하는 주로 로깅 서비스이며, 자동 키 회전이나 인증서 갱신을 수행할 수 있는 기능이 없습니다."
        ]
    },
    {
        "Question Number": "55",
        "Situation": "여러 AWS 계정을 보유한 대기업이 청구 프로세스를 간소화하고 AWS 계정의 중앙 집중 관리를 보장하고자 합니다. 조직은 또한 부서 간 보안 및 규정 준수 기준을 시행하기 위해 특정 계정 그룹에 대한 정책을 설정하고자 합니다.",
        "Question": "이 요구 사항을 달성하기 위해 어떤 AWS 기능을 사용해야 하며, 관리 계정은 이 설정에서 어떤 역할을 하나요? (두 가지 선택)",
        "Options": {
            "1": "계정 관리를 위해 AWS Control Tower를 사용하고, 관리 계정이 신원 연합을 처리합니다.",
            "2": "AWS Organizations를 설정하고 통합 청구를 사용하여 관리 계정이 청구를 담당하고 다른 계정을 회원 계정으로 초대할 수 있습니다.",
            "3": "AWS Identity and Access Management (IAM)를 사용하여 모든 계정의 권한을 관리하며, 루트 계정이 각 계정의 청구를 처리합니다.",
            "4": "AWS Single Sign-On (SSO)을 활성화하고 각 계정을 연결하여 관리 계정이 모든 연결된 계정의 사용자 접근 및 청구를 관리할 수 있도록 합니다.",
            "5": "AWS Organizations 내에서 AWS 서비스 제어 정책(SCP)을 구현하여 회원 계정 간 보안 및 규정 준수 기준을 시행합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "AWS Organizations를 설정하고 통합 청구를 사용하여 관리 계정이 청구를 담당하고 다른 계정을 회원 계정으로 초대할 수 있습니다.",
            "AWS Organizations 내에서 AWS 서비스 제어 정책(SCP)을 구현하여 회원 계정 간 보안 및 규정 준수 기준을 시행합니다."
        ],
        "Explanation": "AWS Organizations를 설정하고 통합 청구를 사용하면 조직이 청구 프로세스를 중앙 집중화할 수 있습니다. 이 설정에서 관리 계정은 회원 계정이 발생시키는 모든 요금을 지불할 책임이 있으며, 다른 계정을 초대하거나 제거할 수 있습니다. 이 기능은 또한 조직이 결제 방법을 통합할 수 있게 하여 청구 프로세스를 더 효율적으로 만듭니다. AWS Organizations 내에서 AWS 서비스 제어 정책(SCP)을 구현하면 조직이 여러 AWS 계정 간의 권한을 중앙에서 관리할 수 있습니다. SCP는 모든 회원 계정에 대한 보안 및 규정 준수 기준을 시행하는 데 사용할 수 있으며, 이는 특정 계정 그룹에 대한 정책을 설정하려는 조직의 요구 사항과 일치합니다.",
        "Other Options": [
            "AWS Control Tower는 계정 관리에 사용할 수 있지만 신원 연합을 처리하지 않습니다. 신원 연합은 일반적으로 AWS Identity and Access Management (IAM) 또는 AWS Single Sign-On (SSO)에 의해 처리됩니다.",
            "AWS Identity and Access Management (IAM)는 권한을 관리하는 데 사용할 수 있지만, 루트 계정이 각 계정의 청구를 처리하지 않습니다. 청구는 일반적으로 AWS Organizations의 관리 계정이 처리합니다.",
            "AWS Single Sign-On (SSO)은 사용자 접근을 관리하는 데 사용할 수 있지만, 모든 연결된 계정의 청구를 직접 처리하지 않습니다. 청구는 일반적으로 AWS Organizations의 관리 계정이 처리합니다."
        ]
    },
    {
        "Question Number": "56",
        "Situation": "한 회사는 온프레미스 데이터 센터와 AWS 환경 간에 안전하고 전용 네트워크 연결이 필요하며, 이는 중요한 애플리케이션에 대한 저지연 액세스를 제공합니다. 그들은 민감한 데이터를 인터넷을 통해 전송하는 것에 대한 잠재적인 보안 위험에 대해 우려하고 있습니다.",
        "Question": "안전하고 전용 연결과 일관된 네트워크 성능을 제공하는 AWS 솔루션은 무엇입니까?",
        "Options": {
            "1": "인터넷 게이트웨이(IGW)를 설정하고 보안 그룹을 사용하여 온프레미스 애플리케이션에 대한 액세스를 제한합니다.",
            "2": "AWS VPN을 사용하여 인터넷을 통해 안전한 IPsec 터널을 설정하여 암호화된 통신을 허용합니다.",
            "3": "AWS Direct Connect를 구현하여 온프레미스 데이터 센터와 AWS 간에 개인 전용 네트워크 링크를 제공하며, 필요 시 추가 VPN 계층을 통한 암호화를 지원합니다.",
            "4": "Elastic Load Balancer(ELB)를 배포하고 온프레미스 데이터 센터로의 라우팅을 구성하여 안전한 액세스를 제공합니다."
        },
        "Correct Answer": "AWS Direct Connect를 구현하여 온프레미스 데이터 센터와 AWS 간에 개인 전용 네트워크 링크를 제공하며, 필요 시 추가 VPN 계층을 통한 암호화를 지원합니다.",
        "Explanation": "AWS Direct Connect는 온프레미스 데이터 센터와 AWS 간에 전용 개인 연결을 제공하며, 이는 중요한 애플리케이션에 대한 저지연 액세스에 이상적입니다. 이 솔루션은 공용 인터넷을 우회하여 민감한 데이터를 인터넷을 통해 전송하는 것과 관련된 보안 위험을 크게 줄입니다. 또한, Direct Connect는 추가 암호화를 위한 VPN과 결합할 수 있어 데이터가 전송 중에도 안전하게 유지됩니다.",
        "Other Options": [
            "인터넷 게이트웨이(IGW)를 설정하고 보안 그룹을 사용하는 것은 전용 연결을 제공하지 않으며, 대신 공용 인터넷을 통해 AWS 리소스에 대한 액세스를 허용하여 민감한 데이터에 대한 보안 위험을 초래합니다.",
            "AWS VPN을 사용하면 인터넷을 통해 안전한 IPsec 터널을 설정하여 전송 중인 데이터를 암호화합니다. 그러나 여전히 공용 인터넷에 의존하므로 전용 연결에 비해 지연 및 잠재적인 보안 취약점이 발생할 수 있습니다.",
            "AWS Direct Connect가 올바른 선택이지만, Elastic Load Balancer(ELB)를 배포하는 옵션은 전용 네트워크 연결을 설정하는 데 관련이 없습니다. ELB는 여러 대상 간에 수신 애플리케이션 트래픽을 분산하는 데 사용되며, 온프레미스 데이터 센터와 AWS 간의 직접 연결을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "57",
        "Situation": "귀하의 팀은 여러 애플리케이션이 사용자와의 상호작용에 대한 실시간 분석과 같은 고주파수 데이터의 지속적인 스트림을 읽고 처리 및 분석할 수 있도록 하는 메시징 서비스를 구현해야 합니다. 이 서비스는 여러 소비자를 동시에 지원해야 하며, 각 소비자는 정의된 롤링 윈도우 내에서 데이터를 읽을 수 있어야 합니다.",
        "Question": "이러한 요구 사항에 가장 적합한 서비스는 무엇이며, 그 이유는 무엇입니까?",
        "Options": {
            "1": "Amazon SQS, 비동기 통신을 위한 분리를 제공하고 메시지의 지속성을 보장합니다.",
            "2": "Amazon Kinesis, 대규모 데이터 수집 및 롤링 윈도우를 통한 여러 소비자에 최적화되어 있습니다.",
            "3": "Amazon SNS, 여러 소비자를 지원하고 다양한 엔드포인트에 실시간으로 전달합니다.",
            "4": "AWS Lambda와 S3, 이벤트 기반 트리거를 사용하여 실시간으로 데이터를 수집하고 처리합니다."
        },
        "Correct Answer": "Amazon Kinesis, 대규모 데이터 수집 및 롤링 윈도우를 통한 여러 소비자에 최적화되어 있습니다.",
        "Explanation": "Amazon Kinesis는 실시간 데이터 스트림을 처리하도록 특별히 설계되었으며, 고처리량 데이터 수집에 최적화되어 있습니다. 여러 소비자가 동일한 데이터 스트림에서 동시에 읽을 수 있도록 하여 여러 애플리케이션이 데이터를 동시에 처리할 수 있는 요구 사항에 필수적입니다. 또한, Kinesis는 롤링 윈도우 개념을 지원하여 애플리케이션이 지정된 시간 프레임 내에서 데이터를 분석할 수 있도록 하여 사용자 상호작용에 대한 실시간 분석에 이상적입니다.",
        "Other Options": [
            "Amazon SQS는 주로 마이크로서비스와 비동기 통신을 위한 분리를 위해 설계되었습니다. 메시지 지속성을 제공하지만, 실시간 데이터 스트리밍이나 여러 소비자를 위한 롤링 윈도우 개념을 지원하지 않으므로 설명된 사용 사례에 적합하지 않습니다.",
            "Amazon SNS는 메시지를 여러 구독자에게 푸시할 수 있는 퍼블리시/구독 메시징 서비스입니다. 그러나 정의된 롤링 윈도우 내에서 소비자가 데이터를 읽거나 고주파수 데이터 스트림을 효과적으로 처리할 수 있는 기능을 제공하지 않으므로 실시간 분석에 필수적입니다.",
            "AWS Lambda와 S3는 메시징 서비스가 아니라 이벤트에 응답하여 데이터를 처리할 수 있는 서버리스 컴퓨팅 서비스입니다. 실시간 처리를 위해 사용할 수 있지만, S3에 저장을 의존하므로 고주파수 데이터 스트림이나 여러 소비자가 동시에 동일한 데이터에 접근하는 데 최적화되어 있지 않습니다."
        ]
    },
    {
        "Question Number": "58",
        "Situation": "한 미디어 회사는 대용량 비디오 파일을 온프레미스에 저장하고 있으며, 이러한 파일을 Amazon S3로 마이그레이션하여 확장 가능한 저장소와 글로벌 액세스를 확보해야 합니다. 마이그레이션은 자동화되어야 하며 수동 개입을 최소화해야 합니다.",
        "Question": "이 데이터 전송을 용이하게 하기 위해 솔루션 아키텍트가 사용해야 하는 AWS 서비스는 무엇입니까?",
        "Options": {
            "1": "AWS Snowball",
            "2": "AWS DataSync",
            "3": "Amazon S3 Transfer Acceleration",
            "4": "AWS Direct Connect"
        },
        "Correct Answer": "AWS DataSync",
        "Explanation": "AWS DataSync는 온프레미스 저장소와 Amazon S3와 같은 AWS 서비스 간에 대량의 데이터를 자동으로 전송하도록 특별히 설계되었습니다. 데이터 전송을 효율적으로 처리하여 마이그레이션 프로세스를 단순화하고 가속화하며, 전송 작업의 예약 및 모니터링을 가능하게 합니다. 이는 수동 개입을 최소화하며, 미디어 회사가 대용량 비디오 파일을 S3로 마이그레이션해야 하는 시나리오에 이상적입니다.",
        "Other Options": [
            "AWS Snowball은 네트워크 전송이 불가능할 때 대량의 데이터를 AWS로 전송하는 데 사용되는 물리적 데이터 전송 솔루션입니다. 대량 데이터 마이그레이션에 사용할 수 있지만, 장치의 물리적 배송이 필요하며 DataSync와 같은 방식으로 자동화되지 않습니다.",
            "Amazon S3 Transfer Acceleration은 Amazon CloudFront의 전 세계적으로 분산된 엣지 위치를 사용하여 S3에 대한 업로드 속도를 높이는 기능입니다. 그러나 온프레미스 저장소에서 전송 프로세스를 자동화하지 않으며, 시작된 후에만 전송을 가속화합니다.",
            "AWS Direct Connect는 온프레미스에서 AWS로의 전용 네트워크 연결을 제공하여 데이터 전송의 대역폭을 개선하고 지연을 줄일 수 있습니다. 그러나 마이그레이션 프로세스를 자동화하지 않으며, 일회성 마이그레이션보다는 지속적인 데이터 전송 요구에 더 적합합니다."
        ]
    },
    {
        "Question Number": "59",
        "Situation": "한 SaaS 회사는 여러 애플리케이션이 중앙 데이터베이스에 연결되어 피크 시간 동안 높은 연결 수를 초래하고 있습니다. 그들은 연결을 열고 유지하는 데 드는 비용을 줄이면서 데이터베이스 성능을 원활하게 유지하고자 합니다.",
        "Question": "이러한 요구 사항을 가장 잘 충족하는 솔루션은 무엇입니까?",
        "Options": {
            "1": "연결을 분산하기 위해 더 많은 데이터베이스 인스턴스를 추가합니다.",
            "2": "연결 풀링을 위해 데이터베이스 프록시를 구현합니다.",
            "3": "장애 조치를 위해 다중 AZ 배포를 활성화합니다.",
            "4": "연결을 처리하기 위해 캐싱 레이어를 사용합니다."
        },
        "Correct Answer": "연결 풀링을 위해 데이터베이스 프록시를 구현합니다.",
        "Explanation": "연결 풀링을 위해 데이터베이스 프록시를 구현하는 것은 연결을 열고 유지하는 데 드는 비용을 줄이면서 데이터베이스 성능을 원활하게 유지하는 가장 좋은 솔루션입니다. 데이터베이스 프록시는 기존 연결을 관리하고 재사용할 수 있어 새로운 연결을 설정하는 오버헤드를 최소화하고 데이터베이스에 대한 총 연결 수를 줄입니다. 이는 자원 활용을 개선하고 피크 시간 동안 애플리케이션이 연결을 효율적으로 공유할 수 있도록 하여 성능을 크게 향상시킬 수 있습니다.",
        "Other Options": [
            "더 많은 데이터베이스 인스턴스를 추가하여 연결을 분산하는 것은 로드 밸런싱에 도움이 될 수 있지만, 높은 연결 수 문제를 직접적으로 해결하지는 않습니다. 이는 연결 관리의 근본적인 문제를 해결하지 않고 비용을 증가시킬 수 있습니다.",
            "장애 조치를 위해 다중 AZ 배포를 활성화하는 것은 주로 가용성과 재해 복구를 개선하기 위한 전략입니다. 이는 복원력을 향상시키지만, 연결 수나 연결 관리와 관련된 비용을 직접적으로 줄이지는 않습니다.",
            "연결을 처리하기 위해 캐싱 레이어를 사용하는 것은 데이터베이스의 부하를 줄여 성능을 개선할 수 있지만, 연결 풀링 문제를 구체적으로 해결하지는 않습니다. 캐싱은 자주 접근하는 데이터를 저장하는 것과 관련이 있으며, 데이터베이스 연결 관리와는 다릅니다."
        ]
    },
    {
        "Question Number": "60",
        "Situation": "한 회사는 보안을 강화하기 위해 AWS 사용자에게 다단계 인증(MFA)을 구현하도록 요구합니다. 각 사용자는 모바일 전화 앱과 같은 고유한 장치를 사용하여 시간 기반 일회용 코드를 생성해야 합니다. 이 코드는 주기적으로 변경되며, 사용자 이름과 비밀번호 외에도 로그인할 때마다 필요합니다.",
        "Question": "다음 중 이 유형의 MFA 설정이 제공하는 보안 이점을 가장 잘 설명하는 것은 무엇입니까?",
        "Options": {
            "1": "AWS 루트 계정 비밀번호를 아는 사용자만 로그인할 수 있도록 보장합니다.",
            "2": "사용자가 알고 있는 것과 가지고 있는 것으로 인증하도록 요구하여 무단 액세스 가능성을 줄입니다.",
            "3": "사용자가 올바른 MFA 코드를 사용하는 경우 비밀번호를 우회할 수 있도록 합니다.",
            "4": "AWS 관리 콘솔에 물리적으로 접근할 수 있는 사용자에게만 작동합니다."
        },
        "Correct Answer": "사용자가 알고 있는 것과 가지고 있는 것으로 인증하도록 요구하여 무단 액세스 가능성을 줄입니다.",
        "Explanation": "이 진술은 다단계 인증(MFA)의 보안 이점을 정확하게 설명합니다. MFA는 두 가지 형태의 검증을 요구하여 보안을 강화합니다: 사용자가 알고 있는 것(비밀번호)과 사용자가 가지고 있는 것(모바일 장치에서 생성된 시간 기반 일회용 코드). 이 이중 요구 사항은 무단 액세스의 위험을 크게 줄이며, 공격자가 비밀번호와 사용자의 장치에 대한 접근을 모두 필요로 하게 만듭니다.",
        "Other Options": [
            "이 진술은 잘못되었습니다. MFA는 AWS 루트 계정 비밀번호를 아는 사용자만 로그인할 수 있도록 보장하지 않습니다. MFA는 모든 사용자에게 적용되며 루트 계정 이상의 보안을 강화합니다.",
            "이 진술은 잘못되었습니다. 이는 올바른 답변이기 때문입니다. MFA의 보안 이점을 정확하게 설명하며, 사용자가 알고 있는 것(비밀번호)과 가지고 있는 것(MFA 코드)을 결합합니다.",
            "이 진술은 잘못되었습니다. MFA는 사용자가 비밀번호를 우회할 수 있도록 하지 않습니다. MFA 코드는 성공적인 인증을 위해 비밀번호와 함께 제공해야 하는 추가 보안 계층입니다."
        ]
    },
    {
        "Question Number": "61",
        "Situation": "조직이 AWS CloudFormation을 사용하여 IAM 역할, 보안 그룹 및 암호화된 스토리지 볼륨과 같은 보안 관련 리소스를 포함한 인프라의 배포를 자동화하고 있습니다. 그들은 모든 배포가 보안 정책을 준수하고 중요한 리소스에 대한 무단 변경을 방지하도록 보장하고자 합니다.",
        "Question": "CloudFormation으로 관리되는 리소스를 보호하기 위해 따라야 할 모범 사례는 무엇입니까? (두 가지 선택)",
        "Options": {
            "1": "CloudFormation 드리프트 감지를 사용하여 배포된 리소스의 변경 사항을 모니터링하고 IAM 정책을 사용하여 스택을 수정할 수 있는 사람을 제한하기 위해 StackSets를 활성화합니다.",
            "2": "업데이트 및 수정을 단순화하기 위해 모든 CloudFormation 템플릿을 S3에 버전 관리 없이 저장합니다.",
            "3": "CloudFormation을 사용하여 리소스를 공용 서브넷에만 배포하여 조직의 모든 사용자가 쉽게 접근할 수 있도록 합니다.",
            "4": "배포 중 CloudFormation 스택을 보안 정책에 대해 검증하기 위해 AWS Config 규칙을 구현합니다.",
            "5": "보안을 단순화하기 위해 CloudFormation 스택에서 IAM 역할 사용을 피하고 대신 EC2 키 쌍에 의존합니다."
        },
        "Is_Multiple": true,
        "Correct Answer": [
            "CloudFormation 드리프트 감지를 사용하여 배포된 리소스의 변경 사항을 모니터링하고 IAM 정책을 사용하여 스택을 수정할 수 있는 사람을 제한하기 위해 StackSets를 활성화합니다.",
            "배포 중 CloudFormation 스택을 보안 정책에 대해 검증하기 위해 AWS Config 규칙을 구현합니다."
        ],
        "Explanation": "StackSets와 CloudFormation 드리프트 감지를 활성화하면 조직이 배포된 리소스의 변경 사항을 모니터링할 수 있습니다. 이는 중요한 리소스에 대한 무단 변경을 식별하는 데 도움이 됩니다. IAM 정책을 사용하여 스택을 수정할 수 있는 사람을 제한하면 인프라에 대한 변경을 승인된 인원만 수행할 수 있도록 보장하여 보안을 강화합니다. 배포 중 CloudFormation 스택을 보안 정책에 대해 검증하기 위해 AWS Config 규칙을 구현하면 모든 배포가 조직의 보안 정책을 준수하도록 보장합니다. 이는 보안 위반을 방지하는 데 도움이 됩니다.",
        "Other Options": [
            "모든 CloudFormation 템플릿을 S3에 버전 관리 없이 저장하는 것은 업데이트 및 수정을 단순화하지만, 변경 사항을 추적하거나 문제가 발생했을 때 이전 버전으로 되돌릴 방법을 제공하지 않습니다. 이는 보안 취약점을 초래할 수 있으므로 모범 사례가 아닙니다.",
            "CloudFormation을 사용하여 리소스를 공용 서브넷에만 배포하는 것은 보안을 보장하지 않습니다. 이는 조직의 모든 사용자가 쉽게 접근할 수 있도록 하지만, 리소스를 잠재적인 외부 위협에 노출시킵니다. 따라서 CloudFormation으로 관리되는 리소스를 보호하기 위한 모범 사례가 아닙니다.",
            "CloudFormation 스택에서 IAM 역할 사용을 피하고 EC2 키 쌍에 의존하는 것은 보안을 단순화하지만 IAM 역할이 제공하는 세분화된 제어를 제공하지 않습니다. IAM 역할은 누가 어떤 리소스에 접근할 수 있는지에 대한 더 많은 유연성과 제어를 제공하므로 보안에 더 나은 선택입니다. 따라서 이는 모범 사례가 아닙니다."
        ]
    },
    {
        "Question Number": "62",
        "Situation": "한 회사가 새로운 다중 계정 AWS 환경을 설정하고 있으며, 모든 계정에서 일관된 보안 및 준수 기준을 갖춘 잘 설계된 설정을 보장하고자 합니다. 또한 자동화된 모니터링 및 알림 기능을 원합니다.",
        "Question": "이 프로세스를 간소화하기 위해 어떤 AWS 서비스를 사용해야 하며, 이 환경의 모든 계정에서 규칙과 기준을 시행하는 데 도움이 되는 특정 기능은 무엇입니까?",
        "Options": {
            "1": "AWS Organizations를 사용하고, 계정 간 규칙 시행을 위해 서비스 제어 정책(SCP)을 구현합니다.",
            "2": "AWS Control Tower를 사용하여 다중 계정 환경의 설정 및 관리를 자동화하고, 가드레일을 사용하여 규칙을 시행하고 준수를 모니터링합니다.",
            "3": "각 계정에 대해 AWS Config를 사용하고 리소스를 모니터링하기 위해 준수 규칙을 수동으로 구성합니다.",
            "4": "AWS CloudFormation을 사용하여 사용자 정의 환경을 배포하고, 계정 간 보안 기준을 관리하기 위해 IAM 정책을 구현합니다."
        },
        "Correct Answer": "AWS Control Tower를 사용하여 다중 계정 환경의 설정 및 관리를 자동화하고, 가드레일을 사용하여 규칙을 시행하고 준수를 모니터링합니다.",
        "Explanation": "AWS Control Tower는 조직이 AWS 모범 사례에 따라 안전한 다중 계정 AWS 환경을 설정하고 관리하는 데 도움을 주기 위해 특별히 설계되었습니다. 이는 계정을 생성하고, 거버넌스를 적용하며, 사전 구성된 가드레일을 통해 준수를 보장하는 간소화된 방법을 제공합니다. 이 서비스는 설정 프로세스를 자동화하고 환경이 정의된 기준을 준수하도록 보장하는 모니터링 기능을 포함하고 있어 회사의 요구 사항에 가장 적합한 선택입니다.",
        "Other Options": [
            "AWS Organizations와 서비스 제어 정책(SCP)을 사용하는 것은 계정 간 권한 관리를 위한 유효한 접근 방식이지만, AWS Control Tower가 제공하는 포괄적인 자동화 및 거버넌스 기능을 제공하지 않습니다. SCP는 준수를 시행하고 모니터링하기보다는 접근 제어에 더 중점을 둡니다.",
            "AWS Config는 AWS 리소스의 구성을 평가, 감사 및 평가할 수 있는 서비스입니다. 준수 모니터링에 도움이 될 수 있지만, 각 계정에 대해 규칙을 수동으로 구성해야 하므로 회사의 자동화된 설정 및 일관된 시행 요구 사항과 일치하지 않습니다.",
            "AWS CloudFormation은 인프라를 코드로 배포하는 서비스로, 환경을 일관되게 설정하는 데 도움이 될 수 있습니다. 그러나 여러 계정 간의 거버넌스 또는 준수 모니터링 기능을 본질적으로 제공하지 않습니다. IAM 정책은 보안 기준을 관리할 수 있지만, AWS Control Tower와 같은 준수를 시행하거나 자동화된 모니터링 기능을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "63",
        "Situation": "미디어 스트리밍 플랫폼인 MediaStream은 전 세계 수백만 명의 동시 사용자 지원을 위해 AWS에 크게 의존하고 있습니다. 그들은 스트리밍 서비스에 방해가 될 수 있는 분산 서비스 거부(DDoS) 공격의 위험에 대해 우려하고 있습니다. MediaStream은 기본 DDoS 보호와 추가 보호 및 DDoS 이벤트에 대한 실시간 가시성을 제공하는 고급 계층을 제공하는 솔루션을 원합니다. 그들은 네트워크, 전송 및 애플리케이션 계층을 포함한 다양한 계층에서 잠재적인 공격으로부터 애플리케이션을 보호하기 위해 AWS Shield Standard와 AWS Shield Advanced를 고려하고 있습니다. MediaStream은 또한 공격이 AWS 사용량을 크게 증가시킬 경우 발생할 수 있는 비용 문제에 대한 보호를 원합니다.",
        "Question": "AWS Shield Standard와 AWS Shield Advanced의 DDoS 완화에 대한 보호 및 제공되는 기능의 차이를 가장 잘 설명하는 다음 설명은 무엇입니까?",
        "Options": {
            "1": "AWS Shield Standard는 모든 AWS 고객에게 무료로 기본 DDoS 보호를 제공하며, 주로 AWS 서비스의 경계에서 보호하는 데 중점을 두지만, 사전 참여 또는 고급 건강 기반 감지 기능은 포함되지 않습니다.",
            "2": "AWS Shield Advanced는 모든 AWS 고객에게 제공되는 무료 서비스로, 애플리케이션 계층 공격(L7)에 대한 향상된 DDoS 보호를 제공하며, AWS WAF와 긴밀하게 통합되어 비용 보호 및 DDoS 이벤트에 대한 실시간 가시성을 제공합니다.",
            "3": "AWS Shield Standard는 모든 AWS 서비스에 대해 애플리케이션 계층(L7) DDoS 공격에 대한 자동 보호를 제공하는 유료 서비스로, AWS Shield 대응 팀의 사전 참여를 포함합니다.",
            "4": "AWS Shield Advanced는 Elastic IP가 있는 모든 AWS 리소스에 대해 자동으로 활성화되며, 무료 웹 ACL 구성을 제공하고, 모든 DDoS 이벤트에 대해 AWS Shield 대응 팀의 즉각적인 대응을 제공합니다."
        },
        "Correct Answer": "AWS Shield Standard는 모든 AWS 고객에게 무료로 기본 DDoS 보호를 제공하며, 주로 AWS 서비스의 경계에서 보호하는 데 중점을 두지만, 사전 참여 또는 고급 건강 기반 감지 기능은 포함되지 않습니다.",
        "Explanation": "AWS Shield Standard는 모든 AWS 고객에게 기본 DDoS 보호를 제공하는 무료 서비스입니다. 이는 주로 네트워크 및 전송 계층에서 발생하는 일반적이고 가장 빈번한 DDoS 공격으로부터 보호합니다. 그러나 AWS Shield Advanced에서만 제공되는 AWS Shield 대응 팀의 사전 참여 또는 고급 건강 기반 감지 기능과 같은 고급 기능은 제공하지 않습니다. 이는 AWS Shield Standard와 AWS Shield Advanced의 한계를 설명하는 데 있어 이 설명이 정확하다는 것을 의미합니다.",
        "Other Options": [
            "AWS Shield Advanced는 무료 서비스가 아니며, 애플리케이션 계층(L7) 공격을 포함한 향상된 DDoS 보호를 제공하는 유료 서비스입니다. 그러나 비용 보호 및 실시간 가시성을 제공하지만, 모든 AWS 고객에게 무료로 제공되지 않습니다.",
            "AWS Shield Standard는 유료 서비스가 아니며, 무료로 제공되며 애플리케이션 계층(L7) DDoS 공격에 대한 자동 보호를 제공하지 않습니다. AWS Shield 대응 팀의 사전 참여는 AWS Shield Advanced의 기능이지 Standard의 기능이 아닙니다.",
            "AWS Shield Advanced는 Elastic IP가 있는 모든 AWS 리소스에 대해 자동으로 활성화되지 않으며, 구독해야 합니다. 또한, AWS Shield Advanced는 모든 DDoS 이벤트에 대해 AWS Shield 대응 팀의 즉각적인 대응을 제공하지만, 서비스의 일환으로 무료 웹 ACL 구성을 제공하지 않습니다."
        ]
    },
    {
        "Question Number": "64",
        "Situation": "한 회사가 컨테이너를 사용하여 마이크로서비스 기반 애플리케이션을 구축하고 있으며, AWS에서 이러한 컨테이너를 확장 가능한 방식으로 관리하고 오케스트레이션하고자 합니다. 이 회사는 오케스트레이션을 위해 Amazon ECS와 Amazon EKS를 고려하고 있지만, 어떤 서비스가 그들의 요구에 가장 적합할지 확신이 없습니다. 그들은 오케스트레이션에 대한 세분화된 제어, 사용자 정의 네트워킹 및 컨테이너 관리가 필요합니다.",
        "Question": "회사가 Amazon ECS 대신 Amazon EKS를 사용해야 하는 경우를 가장 잘 설명하는 것은 무엇입니까?",
        "Options": {
            "1": "사용자가 사용자 정의 오케스트레이션 및 복잡한 네트워킹 기능과 같은 Kubernetes 네이티브 기능이 필요한 경우 Amazon EKS를 사용합니다.",
            "2": "모든 컨테이너 오케스트레이션 요구에 대해 Amazon ECS를 사용합니다. 이는 컨테이너화된 애플리케이션에 대해 더 간단하고 비용 효율적입니다.",
            "3": "회사가 모든 컨테이너화된 워크로드에 대해 자동으로 확장 및 로드 밸런싱을 처리하는 완전 관리형 컨테이너 서비스가 필요한 경우 Amazon EKS를 사용합니다.",
            "4": "회사가 서버리스 컨테이너를 사용하는 경우에만 Amazon ECS를 사용합니다. Amazon EKS는 서버리스 워크로드를 지원하지 않습니다."
        },
        "Correct Answer": "사용자가 사용자 정의 오케스트레이션 및 복잡한 네트워킹 기능과 같은 Kubernetes 네이티브 기능이 필요한 경우 Amazon EKS를 사용합니다.",
        "Explanation": "Amazon EKS(Elastic Kubernetes Service)는 Kubernetes가 제공하는 고급 기능과 유연성이 필요한 사용자를 위해 설계되었습니다. 여기에는 오케스트레이션에 대한 세분화된 제어, 사용자 정의 네트워킹 솔루션 구현 능력 및 Kubernetes 네이티브 도구와 API 사용이 포함됩니다. 회사가 이러한 기능을 찾고 있다면 EKS가 ECS(Elastic Container Service)보다 더 나은 선택입니다. ECS는 더 간단하고 컨테이너 오케스트레이션에 대한 접근 방식이 더 명확합니다.",
        "Other Options": [
            "이 옵션은 잘못되었습니다. Amazon EKS는 Kubernetes 네이티브 기능을 제공하지만, 단순성이나 비용 효율성만을 위한 것이 아닙니다. ECS는 더 간단하고 직관적일 수 있지만, EKS가 제공하는 고급 기능이 부족합니다.",
            "이 옵션은 오해의 소지가 있습니다. Amazon EKS는 관리형 서비스이지만, 모든 워크로드에 대해 ECS와 같은 방식으로 자동으로 확장 및 로드 밸런싱을 처리하지 않습니다. EKS는 유사한 결과를 얻기 위해 더 많은 구성 및 Kubernetes에 대한 이해가 필요합니다.",
            "이 옵션은 잘못되었습니다. Amazon EKS는 AWS Fargate를 통해 서버리스 워크로드를 지원하며, Amazon ECS와 마찬가지로 서버리스 워크로드를 지원합니다. 따라서 EKS가 서버리스 워크로드를 지원하지 않는다는 주장은 사실이 아닙니다."
        ]
    },
    {
        "Question Number": "65",
        "Situation": "한 회사가 다중 계층 애플리케이션을 지원하기 위해 AWS에서 가상 사설 클라우드(VPC) 아키텍처를 설계하고 있습니다. 이 아키텍처는 향후 성장을 위한 추가 예비 영역과 함께 세 개의 가용 영역(AZ)이 필요합니다. 각 가용 영역에는 웹, 애플리케이션 및 데이터베이스 계층을 위한 별도의 서브넷과 향후 확장을 위해 예약된 추가 서브넷이 필요합니다. 회사는 각 계층에서 애플리케이션을 확장할 수 있는 충분한 IP 주소를 보장하고자 합니다.",
        "Question": "향후 성장을 허용하면서 이러한 요구 사항을 가장 잘 충족하는 VPC 구성은 무엇입니까?",
        "Options": {
            "1": "VPC에 /28 CIDR 블록을 사용하고 각 가용 영역을 /30 서브넷으로 나누어 각 서브넷 내에서 IP 주소 사용을 극대화합니다.",
            "2": "/16 CIDR 블록을 설정하여 VPC에 총 65,536개의 IP 주소를 제공하고, 각 가용 영역의 각 계층에 대해 /20 서브넷을 할당하여 각 계층에 충분한 IP 주소를 보장합니다.",
            "3": "VPC에 /24 CIDR 블록을 선택하여 총 256개의 IP 주소를 제공하고, 각 가용 영역의 각 계층에 대해 /26 서브넷을 사용하여 주소 공간을 최적화합니다.",
            "4": "VPC에 /22 CIDR 블록을 구성하여 1,024개의 IP 주소를 지원하고, 각 계층에 대해 /25 서브넷으로 각 가용 영역을 나누어 주소 공간과 확장성을 균형 있게 유지합니다."
        },
        "Correct Answer": "VPC에 /16 CIDR 블록을 설정하여 총 65,536개의 IP 주소를 제공하고, 각 가용 영역의 각 계층에 대해 /20 서브넷을 할당하여 각 계층에 충분한 IP 주소를 보장합니다.",
        "Explanation": "/16 CIDR 블록을 선택하면 VPC에 65,536개의 IP 주소라는 큰 주소 공간을 허용하여, 웹, 애플리케이션 및 데이터베이스 계층을 위한 별도의 서브넷이 필요한 다중 계층 애플리케이션에 충분합니다. /20 서브넷을 할당하면 각 서브넷에 4,096개의 IP 주소(2^(32-20))가 제공되어 각 계층 내에서 확장할 수 있는 충분한 공간을 제공하며, 향후 확장을 위한 여유도 남깁니다.",
        "Other Options": [
            "/28 CIDR 블록을 VPC에 사용하는 것은 16개의 IP 주소만 제공하므로 세 개의 가용 영역에서 여러 서브넷이 필요한 다중 계층 애플리케이션에는 너무 제한적입니다. 각 AZ를 /30 서브넷으로 나누면 사용 가능한 IP 주소 수가 더 줄어들어 이 옵션은 비현실적입니다.",
            "/24 CIDR 블록은 256개의 IP 주소만 제공하므로 애플리케이션의 요구 사항에 부족합니다. /26 서브넷을 사용하면 서브넷당 64개의 IP 주소만 허용되므로 웹, 애플리케이션 및 데이터베이스 계층에 충분하지 않으며, 향후 성장도 고려해야 합니다.",
            "/22 CIDR 블록을 구성하면 1,024개의 IP 주소를 허용하지만, 여전히 확장을 위한 충분한 공간을 제공하지 않을 수 있습니다. 각 가용 영역을 /25 서브넷으로 나누면 서브넷당 128개의 IP 주소가 제공되므로, 특히 회사가 향후 확장을 계획하고 있는 경우 애플리케이션 계층에 제한적일 수 있습니다."
        ]
    }
]